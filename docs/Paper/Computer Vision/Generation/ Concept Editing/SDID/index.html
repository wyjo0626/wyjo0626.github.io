<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/Computer Vision/Generation/ Concept Editing/2023-11-SDID">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation | WYJLab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/Computer Vision/Generation/ Concept Editing/SDID"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation | WYJLab"><meta data-rh="true" name="description" content="논문 및 이미지 출처 :"><meta data-rh="true" property="og:description" content="논문 및 이미지 출처 :"><link data-rh="true" rel="icon" href="/img/WYJLab.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/Computer Vision/Generation/ Concept Editing/SDID"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/Computer Vision/Generation/ Concept Editing/SDID" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/Computer Vision/Generation/ Concept Editing/SDID" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="WYJLab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="WYJLab Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.9ed678b7.css">
<link rel="preload" href="/assets/js/runtime~main.bb9f61d2.js" as="script">
<link rel="preload" href="/assets/js/main.021b6bf4.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Adversarial Attack</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Few-shot/AMT">Few-shot</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/SLD">Generation</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/SLD"> Concept Editing</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/SLD">Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/CA">Ablating Concepts in Text-to-Image Diffusion Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/TIME">Editing Implicit Assumptions in Text-to-Image Diffusion Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/SA">Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/ESD">Erasing Concepts from Diffusion Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/UCE">Unified Concept Editing in Diffusion Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/SDID">Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/MACE">Mace: Mass concept erasure in diffusion models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/RECE">Reliable and Efficient Concept Erasure of Text-to-Image Diffusion Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/SAFREE">Safree: Training-Free and Adaptive Guard for Safe Text-to-Image and Video Generation</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Generation/Interpretability/Info-Decomp">Interpretability</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Image Classification/ViT">Image Classification</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Multi-task/Unified Interface">Multi-task</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/PEFT/Composition/RLRR">PEFT</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Multi-Modal/PEFT/Composition/Moka">Multi-Modal</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Composition/CLIP-LoRA">Vision-Language</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Computer Vision</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Generation</span><meta itemprop="position" content="3"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link"> Concept Editing</span><meta itemprop="position" content="4"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation</span><meta itemprop="position" content="5"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation</h1></header><p>논문 및 이미지 출처 : <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Self-Discovering_Interpretable_Diffusion_Latent_Directions_for_Responsible_Text-to-Image_Generation_CVPR_2024_paper.pdf" target="_blank" rel="noopener noreferrer">https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Self-Discovering_Interpretable_Diffusion_Latent_Directions_for_Responsible_Text-to-Image_Generation_CVPR_2024_paper.pdf</a></p><h1>Abstract</h1><p>Diffusion-based model 은 text-to-image generation 에서 뛰어난 이미지 생성 능력 때문에 큰 인기를 끌고 있다. 이런 model 은 biased 또는 harmful 한 이미지를 포함한 inappropriate content 를 생성할 가능성이 있다는 위험이 있다. 하지만 diffusion model 의 internal representation 관점에서 이런 undesired content 가 생성되는 근본적인 이유는 아직 명확하지 않다. </p><p>이전 연구에서는 diffusion model 의 interpretable latent space 에 있는 vector 를 semantic concept 로 해석했다. 그러나 기존 접근법으로는 inappropriate concept 와 관련된 임의의 concept 에 대한 direction 을 발견할 수 없다. </p><p>이 연구에서 저자는 주어진 concept 에 대해 interpretable latent direction 을 찾는 새로운 self-supervised approach 를 제안한다. </p><ul><li>발견된 vector 를 활용해 저자는 inappropriate generation 을 줄이는 간단한 접근법을 제안한다. </li><li>저자의 mitigation approach 가 fair generation, safe generation, responsible text-enhancing generation 에 효과적임을 확인하기 위해 광범위한 실험을 진행했다.</li></ul><h1>1. Introduction</h1><p>Vision language model 의 급격한 발전으로 인해 이들의 안전성과 책임감 있는 사용을 보장하는 데 관심이 커지고 있다. 특히 text-to-image diffusion model 은 text prompts 에서 이미지를 생성하는 놀라운 성능을 보여줬지만, inappropriate content 를 생성할 가능성에 대한 우려를 낳는다. 생성된 이미지는 gender discrimination 이나 어린이에게 해로운 폭력적인 장면 같은 bias 와 unsafe element 를 나타낼 수 있다. 최근 연구는 이런 문제를 줄이기 위해 safety mechanism 을 도입하는 데 초점을 맞췄다.</p><ul><li>inappropriate text input 을 걸러내기</li><li>safety guard classifier 로 inappropriate image 를 탐지하기</li><li>safe diffusion model 을 구축하기</li></ul><p>하지만 diffusion model 이 inappropriate content 를 생성하는 근본적인 메커니즘은 아직 잘 이해되지 않고 있다. 이 연구에서 저자는 다음 질문들을 탐구한다.</p><ol><li>Diffusion model 기반 생성 과정에서 inappropriate concept 와 관련된 internal representation 이 존재하는가?</li><li>주어진 concept 에 해당하는 inappropriate content 를 피하기 위해 representation 을 조작할 수 있는가? 즉, responsible image generation 을 달성할 수 있는가?</li></ol><p>Diffusion model 의 image generation process 를 이해하기 위해 이전 연구에서는 U-Net 의 bottleneck layer 를 semantic representation space, 즉 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 로 확인했다. 이들은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 에 있는 vector 가 생성된 이미지의 특정 semantic concept 와 연결될 수 있음을 보여줬다. 이 공간의 vector 를 조작하면 이미지를 semantically meaningful 한 방식으로 변경할 수 있다. 예를 들어, 얼굴에 미소를 추가하는 식이다. <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 에서 meaningful direction 을 발견하기 위해 여러 접근법이 제안됐다. 예를 들어, 한 접근법은 PCA 를 사용해 semantic concept 를 나타낼 수 있는 latent direction 세트를 식별한다.</p><p>하지만 interpretable latent vector 를 식별하는 기존 접근법에는 한계가 있다.</p><ul><li>Unsupervised approach 에서는 식별된 vector 가 어떤 semantic concept 에 해당하는지 명확하지 않다. 발견된 vector 는 인간의 개입으로 해석해야 한다.</li><li>Interpretable direction 의 수는 training data 에 의존한다. 특히 fairness 와 safety 관련 target concept 이 발견된 direction 에 포함되지 않을 가능성이 높다.</li><li>Supervised approach 는 human annotation 으로 감독된 external attribute classifier 를 training 해야 한다. 또한 식별된 vector 의 품질은 classifier 의 성능에 민감하다.</li><li>새로운 concept 은 새로운 classifier 를 training 해야 한다.</li></ul><p>결론적으로, 기존 interpretation method 는 주어진 inappropriate concept 에 해당하는 semantic vector 를 쉽게 식별할 수 없다.</p><p>이 연구에서 저자는 user-defined concept 에 대해 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 에서 interpretable latent direction 을 찾는 self-discovery approach 를 제안한다. </p><ul><li>저자는 model 의 internal representation 에서 얻은 semantic knowledge 를 활용해 concept 을 효과적으로 나타내는 latent vector 를 학습한다. </li><li>먼저 특정 concept 와 관련된 text prompt 를 사용해 이미지를 생성한다. 그런 다음 이 이미지를 denoising process 에 사용한다. </li><li>이 과정에서 frozen pretrained diffusion model 은 desired concept 을 제외한 수정된 text prompt 와 저자의 latent vector 를 안내로 이미지를 noise 에서 재구성한다. </li><li>Reconstruction loss 를 최소화함으로써 vector 는 주어진 concept 을 나타내도록 학습한다. </li><li>저자의 self-discovery approach 는 CLIP text encoder 같은 external model 이나 human-labeled dataset 으로 training 된 dedicated attribute classifier 가 필요 없다. </li></ul><p>자는 ethical-related latent vector 를 식별하고 responsible text-to-image generation 에 이를 적용한다.</p><ul><li>Fairness: Latent space 에서 ethical concept (e.g., gender) 를 sampling 하여 prompt 와 aligned 된 unbiased attribute 를 가진 이미지를 생성한다.</li><li>Safety generation: Safety-related concept (e.g., nudity content 제거)을 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 에 통합해 harmful content 생성을 막는다.</li><li>Responsible guidance: Text prompt 에서 responsible concept 를 발견하고 ethical concept 의 표현을 강화한다.</li></ul><p>이전 접근법은 다양한 관점에서 responsible image generation 을 개선했다.</p><ul><li>Diffusion model 이나 text embedding 을 fine-tuning 하여 harmful concept 을 unlearn 한다.</li><li>Classifier-free guidance 를 사용해 unsafe concept 에서 생성을 멀리한다.</li></ul><p>이전 접근법의 mitigation mechanism 에도 불구하고 diffusion model 은 여전히 inappropriate content 를 생성한다. 이전 연구와 달리, 저자는 interpretable latent space 에서 concept 를 찾아 조작함으로써 inappropriate generation 을 줄이는 새로운 관점을 제공한다. 저자의 방법은 기존 mitigation approach 와 쉽게 결합해 responsible text-to-image generation 을 더욱 개선할 수 있다.</p><p>저자는 fairness, safety, responsible guidance-enhancing generation 에 대해 광범위한 실험을 진행했다. 저자의 model 은 societal group 간 균형 잡힌 표현을 가진 이미지를 일관되게 생성한다. 또한 inappropriate prompt 에 대해 harmful content 를 성공적으로 줄였다. 게다가 저자의 접근법은 기존 방법과 결합했을 때 responsible image generation 의 성능을 시너지적으로 개선한다. 또한 responsible prompt 에 대해 fair 하고 safe 한 content 를 생성하도록 text guidance 를 강화한다.</p><p>저자의 기여는 다음과 같이 요약된다.</p><ul><li>Diffusion latent space 에서 interpretable direction 을 식별하는 self-discovery method 를 제안한다. 저자의 접근법은 labeled data 나 external model 없이 원하는 concept 을 나타내는 vector 를 찾는다.</li><li>발견된 vector 를 사용해 fair generation, safe generation, responsible text-enhancing generation 을 포함한 responsible generation 을 개선하는 간단하면서 효과적인 접근법을 제안한다.</li><li>접근법의 효과를 검증하기 위해 광범위한 실험을 진행했다.</li></ul><h1>2. Related Work</h1><h4 class="anchor anchorWithStickyNavbar_LWe7" id="responsible-alignment-of-diffusion-models">Responsible Alignment of Diffusion Models<a href="#responsible-alignment-of-diffusion-models" class="hash-link" aria-label="Direct link to Responsible Alignment of Diffusion Models" title="Direct link to Responsible Alignment of Diffusion Models">​</a></h4><p>Diffusion model 에서 biased 와 unsafe content 생성을 줄이기 위해 다양한 접근법이 제안됐다. 간단한 방법은 training dataset 을 정제해 biased 와 inappropriate content 를 제거하는 것이다. Stable Diffusion (SD) v2 가 그 예이다. 하지만 이런 접근법은 다음과 같은 문제를 가진다.</p><ul><li>Computationally intensive 하다.</li><li>Harmful content 를 완전히 제거하지 못할 수 있다.</li><li>Model 의 성능을 저하시킬 수 있다.</li></ul><p>또 다른 방법은 input prompt 에서 inappropriate word 를 탐지하고 걸러내는 것이다. 하지만 non-explicit phrase 는 여전히 inappropriate output 을 유발할 수 있어 이 방법은 한계가 있다. </p><p>또 다른 접근법은 pretrained model 의 parameter 를 fine-tuning 하여 inappropriate concept 를 생성하는 representation capability 를 제거하는 것이다. 하지만 이 방법은 adaptation process 에 민감하며 original model 의 성능을 저하시킬 수 있다. 또한 bias 와 harmful concept 를 유발하는 단어의 잠재적으로 방대한 목록이 필요하다. </p><p>Training-free approach 는 classifier-free guidance 를 사용해 inference 중 undesirable content 에서 이미지를 멀리하도록 유도한다. 이들은 cross-attention mechanism 을 통해 text-based guidance 를 사용해 noise space 를 수정하지만, 저자는 frozen pretrained model 의 semantic latent space 에서 generation 을 조작하는 비슷한 conditioning strategy 를 채택한다. </p><p>기존 문헌과 직교하는 접근법으로, 저자는 U-Net bottleneck layer 에서 해당 latent direction 을 찾아 activation 을 억제함으로써 inappropriate content 를 줄인다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="interpreting-diffusion-models">Interpreting Diffusion Models<a href="#interpreting-diffusion-models" class="hash-link" aria-label="Direct link to Interpreting Diffusion Models" title="Direct link to Interpreting Diffusion Models">​</a></h4><p>Diffusion model 의 작동 메커니즘을 이해하기 위해 최근 연구는 주로 conditional diffusion model 에 대한 text guidance 를 조사하거나 diffusion model 의 intermediate layer activation 에서 internal representation 을 분석하는 데 초점을 맞췄다. 저자는 이전 연구와 마찬가지로 diffusion model 내부에서 학습된 internal representation 을 밝히는 데 집중한다. 일부 연구는 autoencoder 를 사용해 이미지를 semantic vector 로 encoding 하여 decoding process 를 안내하는 semantic space 를 생성한다. 하지만 이 접근법은 autoencoder 나 전체 framework 의 parameter 를 조정해야 한다.</p><p>U-Net architecture 의 bottleneck layer 가 semantic representation space 에 적합한 속성을 이미 가지고 있음이 밝혀졌다. 이들은 생성된 이미지의 semantic 과 관련된 disentangled representation 을 식별하고 latent direction 이 다른 이미지에 동일함을 보여줬다. 하지만 이 접근법은 CLIP classifier 와 paired source-target image 및 edit 에 의존해 효율적이지 않다. </p><p>또 다른 연구는 latent space 에서 PCA-based decomposition method 를 제안하고 Jacobian 의 top right-hand singular vector 를 사용해 interpretable attribute direction 을 찾는다. 또한 Riemannian metric 을 사용해 더 정확하고 meaningful 한 direction 을 정의한다. 하지만 이 접근법은 각 component 의 editing effect 를 수동으로 해석해야 한다. 저자의 접근법은 data collection process 나 external classifier training 없이 주어진 target concept 에 대한 latent direction 을 효율적으로 발견할 수 있어 supervised approach 와 다르다.</p><h1>3. Approach</h1><p>이 섹션에서는 먼저 diffusion model 의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 에서 interpretable direction 을 찾는 저자의 optimization method 를 소개한다. 두 번째 부분에서는 발견된 concept 를 inference process 에서 fair, safe, enhanced responsible generation 에 활용하는 방법을 보여준다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="31-finding-a-semantic-concept">3.1. Finding a Semantic Concept<a href="#31-finding-a-semantic-concept" class="hash-link" aria-label="Direct link to 3.1. Finding a Semantic Concept" title="Direct link to 3.1. Finding a Semantic Concept">​</a></h2><p>Diffusion model 은 generative model 로, Gaussian noise 에서 sample 을 생성하는 denoising process 를 통해 작동한다. Random vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>T</mi></msub><mo>∼</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x_T \sim \mathcal{N}(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathcal" style="margin-right:0.14736em">N</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span> 에서 시작해, model 은 각 time step 에서 noise value 를 추정해 현재 vector 에서 빼서 denoised image 를 얻는다. 이는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mi>t</mi></msub><mo>−</mo><msub><mi>ϵ</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x_{t-1} = x_t - \epsilon_\theta(x_t, t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span></span> 로 나타내며, 여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">\epsilon_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 diffusion model 의 U-Net 을 나타낸다. 이 denoising process 끝에서 clean image <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">x_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 를 얻는다. Diffusion model 의 training 은 data 에서 이미지에 noise 를 반복적으로 추가하는 forward process 를 포함한다. 이는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>ϵ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t = x_{t-1} + \epsilon_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7917em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>t</mi></msub><mo>∼</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\epsilon_t \sim \mathcal{N}(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathcal" style="margin-right:0.14736em">N</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span> 로 나타낸다. Training loss 는 다양한 step 에 대해 noise 를 예측하는 것을 포함한다.</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>L</mi><mo>=</mo><munder><mo>∑</mo><mrow><mi>x</mi><mo>∼</mo><mi mathvariant="script">D</mi></mrow></munder><munder><mo>∑</mo><mrow><mi>t</mi><mo>∼</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mi>T</mi><mo stretchy="false">]</mo></mrow></munder><msup><mrow><mo fence="true">∥</mo><mi>ϵ</mi><mo>−</mo><msub><mi>ϵ</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo><mo fence="true">∥</mo></mrow><mn>2</mn></msup></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} L = \sum_{x \sim \mathcal{D}} \sum_{t \sim [0, T]} \left\| \epsilon - \epsilon_\theta(x_t, t) \right\|^2 \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.566em;vertical-align:-1.033em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.533em"><span style="top:-3.533em"><span class="pstrut" style="height:3.05em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8557em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∼</span><span class="mord mathcal mtight" style="margin-right:0.02778em">D</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2943em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.809em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">∼</span><span class="mopen mtight">[</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span><span class="mclose mtight">]</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em">∥</span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em">∥</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.954em"><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.033em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.533em"><span style="top:-3.533em"><span class="pstrut" style="height:3.05em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.033em"><span></span></span></span></span></span></span></span></span></div><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-103-07e1cad94067ecd4ad53898628c7980e.png" width="668" height="842" class="img_ev3q"></p><p>최근 연구는 diffusion model 의 U-Net bottleneck layer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span> 의 activation 인 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 를 semantic space 로 확인했다. <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 의 activation 은 다음 time step 의 덜 noised 된 이미지 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">x_{t-1}&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0583em;vertical-align:-0.3064em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3064em"><span></span></span></span></span></span></span></span></span></span></span> 생성으로 이어진다. 이 공간은 semantic structure 를 보여주며 해석하기 쉽다. U-Net bottleneck layer 에서 특정 vector 를 활성화하면 이미지가 특정 attribute 를 가지게 된다. 하지만 기존 접근법은 임의로 주어진 concept 에 대한 vector 를 찾을 수 없다. 저자의 목표는 이런 vector 를 찾는 것이다.</p><p>이를 위해 저자는 text-to-image conditional diffusion model 을 사용해 주어진 text input 에서 이미지를 생성한다. Eq. 1 의 prediction function 은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>π</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\epsilon_\theta(x_t, \pi(y), t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span></span> 가 되며, 여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span></span></span></span></span> 는 input text <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span></span> 의 encoding 이다. 이 식은 input text 에 주어진 데이터 영역으로 이미지 생성을 유도하는 conditional distribution 을 지정한다. </p><p>Interpretable direction 을 발견하기 위해 저자는 pre-trained model 을 사용해 그 concept 과 관련된 dedicated prompt 로 image sets 를 생성한다. </p><ul><li>예를 들어, &quot;female&quot; concept 의 latent direction 을 찾기 위해 먼저 descriptive prompt <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">y^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9658em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span> &quot;a photo of a female face&quot; 로 image sets  <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">x^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7713em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span> 를 생성한다. </li><li>그런 다음 gender information 을 제거한 수정된 prompt <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>−</mo></msup></mrow><annotation encoding="application/x-tex">y^-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9658em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span></span> &quot;a photo of a face&quot; 로 conditional generation 을 위해 concept vector 를 최적화한다. </li><li>Concept vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>D</mi></msup></mrow><annotation encoding="application/x-tex">c \in \mathbb{R}^D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span></span></span></span></span></span></span></span></span> 는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 의 dimension 인 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span></span> 에서 random 으로 초기화되며, reconstruction error 를 최소화하도록 최적화된다. </li><li>Pre-trained diffusion model 이 frozen 상태이므로, model 은 text condition 에 없는 missing information 을 보완하기 위해 extra condition <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">c</span></span></span></span></span> 를 사용해야 한다. </li><li>Concept vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">c</span></span></span></span></span> 는 input text 에서 빠진 정보를 나타내도록 강제되며, lowest reconstruction error 를 가진 이미지를 생성한다. </li><li>수렴 후, 그 vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">c</span></span></span></span></span> 는 &quot;female&quot; gender information 을 나타낸다. 이 방식으로 저자는 gender, safety, facial expression 같은 target concept 을 나타내는 vector 세트를 발견한다.</li></ul><p>형식적으로, 주어진 concept 에 대한 최적의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">c^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span> 는 다음과 같이 구한다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msup><mi>c</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi>c</mi></munder><munder><mo>∑</mo><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>∼</mo><mi mathvariant="script">D</mi></mrow></munder><munder><mo>∑</mo><mrow><mi>t</mi><mo>∼</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mi>T</mi><mo stretchy="false">]</mo></mrow></munder><mi mathvariant="normal">∥</mi><mi>ϵ</mi><mo>−</mo><msub><mi>ϵ</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msubsup><mi>x</mi><mi>t</mi><mo>+</mo></msubsup><mo separator="true">,</mo><mi>t</mi><mo separator="true">,</mo><mi>π</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><msup><mi mathvariant="normal">∥</mi><mn>2</mn></msup><mo separator="true">,</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} c^* = \arg \min_c \sum_{x,y \sim \mathcal{D}} \sum_{t \sim [0,T]} \|\epsilon - \epsilon_\theta(x_t^+, t, \pi(y^-), c)\|^2, \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.566em;vertical-align:-1.033em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.533em"><span style="top:-3.533em"><span class="pstrut" style="height:3.05em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop">ar<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em"><span style="top:-2.4em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8557em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span><span class="mrel mtight">∼</span><span class="mord mathcal mtight" style="margin-right:0.02778em">D</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4304em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.809em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">∼</span><span class="mopen mtight">[</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span><span class="mclose mtight">]</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">∥</span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8213em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.033em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.533em"><span style="top:-3.533em"><span class="pstrut" style="height:3.05em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.033em"><span></span></span></span></span></span></span></span></span></div><ul><li>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>x</mi><mi>t</mi><mo>+</mo></msubsup></mrow><annotation encoding="application/x-tex">x_t^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0572em;vertical-align:-0.2458em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.4542em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span></span></span></span></span> 는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">y^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9658em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span> 로 생성된 original image 의 noised version 을 나타내고, </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">c</span></span></span></span></span> 는 target concept 을 의미한다. </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">\epsilon_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 U-Net 을 나타내며, 각 decoding timestep 에서 추가 concept vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">c</span></span></span></span></span> 를 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 에 linear 하게 추가한다.</li></ul><p>구현과 관련해, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 는 U-Net 의 middle bottleneck layer 이후 flattened activation 이다. 이 training pipeline 의 pseudo-code 는 Appendix A.1 에 있다.  </p><p>저자는 각 concept 에 대해 모든 timestep 에 걸쳐 single vector 를 학습한다. Latent direction 이 여러 timestep 에 걸쳐 대략 일관되기 때문이다. 또한, 이 latent space 의 힘을 보여주기 위해 operation 을 linearity 로 제한한다.  </p><p>특히, learned vector 는 new images 와 다양한 prompt 에 효과적으로 generalization 한다. 예를 들어, base prompt &quot;person&quot; 으로 학습된 &quot;male&quot; concept 은 &quot;doctor&quot; 나 &quot;manager&quot; 같은 다른 context 에서도 사용할 수 있다. 이는 다음 섹션에서 보여준다.  </p><p>또한, concept 은 독립적으로 또는 공동으로 최적화할 수 있으며, 실험 섹션에서 concept composition 의 영향을 보여준다.  </p><p>저자의 접근법의 주요 강점은 diffusion model 의 synthesis 를 활용해 데이터를 수집함으로써 human labeling 이나 guiding classifier 의 training 필요성을 없애는 것이다. 그럼에도 불구하고, 저자의 방법은 annotated attribute 가 있는 realistic dataset 에도 적용할 수 있다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="32-responsible-generation-with-self-discovered-interpretable-latent-direction">3.2. Responsible Generation with Self-discovered Interpretable Latent Direction<a href="#32-responsible-generation-with-self-discovered-interpretable-latent-direction" class="hash-link" aria-label="Direct link to 3.2. Responsible Generation with Self-discovered Interpretable Latent Direction" title="Direct link to 3.2. Responsible Generation with Self-discovered Interpretable Latent Direction">​</a></h2><p>이 하위 섹션에서는 식별된 direction 을 사용해 latent space 에서 latent activation 을 조작하여 fair, safe, enhanced responsible generation 을 수행한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="fair-generation-method">Fair Generation Method<a href="#fair-generation-method" class="hash-link" aria-label="Direct link to Fair Generation Method" title="Direct link to Fair Generation Method">​</a></h4><p>Text prompt 는 biased societal group 의 생성을 유도하는 단어를 포함한다. 저자는 주어진 text prompt 에 대해 attribute 가 균등하게 분포된 이미지를 생성하는 것을 목표로 한다. 예를 들어, &quot;doctor&quot; prompt 에 대해 남성 의사 이미지를 50% 확률로, 여성 의사 이미지를 50% 확률로 생성한다. </p><p>이를 위해 이전 섹션의 접근법을 사용해 societal group 을 나타내는 semantic concept 세트를 학습한다. Inference 에서 societal group 의 learned concept 에서 concept vector 를 균등한 확률로 sampling 한다. 예를 들어, gender 에 대해 C-male 과 C-female concept vector 를 공평하게 선택한다. Inference process 는 이전과 동일하지만, sampling 된 vector 가 각 decoding step 에서 original activation 에 추가된다.</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>h</mi><mo>←</mo><mi>h</mi><mo>+</mo><mi>c</mi><mo>∼</mo><mtext>Categorical</mtext><mo stretchy="false">(</mo><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} h \leftarrow h + c \sim \text{Categorical}(p_k) \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">Categorical</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-2.85em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></div><ul><li>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">p_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 societal group 에서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span></span> 개의 distinct attribute 중 특정 attribute <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">c_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 를 sampling 할 확률을 나타낸다. </li><li>Fair generation 에서는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo>=</mo><mn>1</mn><mi mathvariant="normal">/</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">p_k = 1/C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">1/</span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span></span> 이다. </li></ul><p>Sampling 된 concept vector 의 안내로, 생성된 이미지는 C-male concept 가 sampling 되면 남성 의사, 그렇지 않으면 여성 의사가 된다. 이를 통해 생성된 이미지는 attribute 의 수가 동일하다. 예를 들어, 남성 의사와 여성 의사의 수가 같아진다.</p><p><img loading="lazy" alt="Figure 2" src="/assets/images/image-104-dfc6325ae4e916965edda9aa8cf1873d.png" width="841" height="614" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="safe-generation-method">Safe Generation Method<a href="#safe-generation-method" class="hash-link" aria-label="Direct link to Safe Generation Method" title="Direct link to Safe Generation Method">​</a></h4><p>Safety generation 에서는 explicit 또는 implicit 하게 inappropriate content 를 참조하는 text prompt 를 다루며, 이를 제거하는 것을 목표로 한다. 예를 들어, &quot;a gorgeous woman&quot; 같은 phrase 는 간접적으로 nudity 를 유발할 수 있다. 저자는 anti-sexual 같은 safety-related concept 를 식별해 safe generation 을 달성한다.</p><p>구체적으로, 저자는 negative prompt technique 를 활용해 inappropriate concept 의 반대 latent direction 을 학습한다. 예를 들어, training image 는 prompt <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">y^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9658em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span> &quot;a gorgeous person&quot; 과 negative prompt &quot;sexual&quot; 로 생성되며, 이는 Stable Diffusion 이 sexual content 없이 safe image 를 생성하도록 지시한다. Concept vector 는 &quot;a gorgeous person&quot; 이지만 negative prompt &quot;sexual&quot; 이 없는 input prompt <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>−</mo></msup></mrow><annotation encoding="application/x-tex">y^-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9658em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span></span> 로 최적화된다. 이로써 concept vector 는 &quot;anti-sexual&quot; concept 을 직접 학습한다. Sexuality 의 반대 concept (e.g., &quot;dressed&quot;, &quot;clothes&quot; 등)을 모두 나열하기 어렵기 때문에 이 전략을 채택한다. Sexuality concept 을 직접 학습하고 generation 중 negation 을 적용하는 대안은 덜 효과적이었다.</p><p>학습 후, inference 의 모든 측면은 변경되지 않으며, learned vector 를 bottleneck layer 의 original activation 에 추가한다.</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>h</mi><mo>←</mo><mi>h</mi><mo>+</mo><msub><mi>c</mi><mi>s</mi></msub></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} h \leftarrow h + c_s \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-2.85em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></div><ul><li>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">c_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 sexual content 의 반대인 &quot;anti-sexual&quot; 같은 safety concept 를 나타낸다. </li><li>이는 생성된 이미지에서 safe concept 의 표현을 강화해 harmful content 를 제거한다. </li></ul><p>Anti-sexual vector 를 포함하면 visually appealing 한 적절한 옷을 입은 사람이 생성된다.</p><p><img loading="lazy" alt="Figure 3" src="/assets/images/image-105-c0aa2c5a27611c9ae4b964a1689098c0.png" width="1016" height="874" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="responsible-text-enhancing-generation-method">Responsible Text-enhancing Generation Method<a href="#responsible-text-enhancing-generation-method" class="hash-link" aria-label="Direct link to Responsible Text-enhancing Generation Method" title="Direct link to Responsible Text-enhancing Generation Method">​</a></h4><p>Prompt 가 safety 를 촉진하도록 의도적으로 설계되었더라도, generative model 은 prompt 에 정의된 모든 concept 을 정확히 반영하는 데 어려움을 겪을 수 있다. 예를 들어, &quot;an exciting Halloween party, no violence&quot; 같은 text prompt 에서 generative model 은 &quot;violence&quot; 에 대한 negation 을 제대로 이해하지 못해 inappropriate content 를 생성할 수 있다.</p><p>이를 해결하기 위해 저자는 gender, race, safety 같은 concept 을 self-discovery approach 로 학습한다. Responsible prompt 의 generation 을 강화하기 위해 text 에서 safety-related content 를 추출하고 learned ethical-related concept 를 활용해 desired visual feature 의 표현을 강화한다. Inference 중 prompt 에서 추출된 concept <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">c(y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">c</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span></span></span></span></span> 를 original activation 에 적용한다.</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>h</mi><mo>←</mo><mi>h</mi><mo>+</mo><mi>c</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} h \leftarrow h + c(y) \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">c</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-2.85em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></div><p>예를 들어, text prompt 에서 &quot;no violence&quot; concept 은 inference 중 &quot;anti-violence&quot; concept 을 활성화한다. Semantic space 를 직접 조작함으로써 저자의 접근법은 원하는 attribute 를 생성된 이미지에 도입한다. Original generated image 와 비교해 anti-violence concept 은 violent content 의 존재를 효과적으로 줄이고 생성된 이미지를 더 적절하게 만든다.</p><p><img loading="lazy" alt="Figure 4" src="/assets/images/image-106-0eb73b78cae738ccd4dc654e1d943c20.png" width="965" height="757" class="img_ev3q"></p><h1>4. Experiments</h1><p>이 섹션에서는 fair generation, safe generation, enhanced responsible generation 에 대한 저자의 방법 성능을 보여준다. 또한, 발견된 concept vector 의 일반적인 속성을 강조하며, generalization capability 와 compositionality 를 보여준다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="41-fair-generation">4.1. Fair Generation<a href="#41-fair-generation" class="hash-link" aria-label="Direct link to 4.1. Fair Generation" title="Direct link to 4.1. Fair Generation">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="task">Task<a href="#task" class="hash-link" aria-label="Direct link to Task" title="Direct link to Task">​</a></h4><p>목표는 생성된 이미지에서 societal group 의 다양성을 높이는 거다. 특히, 기존 model 이 gender 와 racial bias 를 보이는 직업군에서 비교한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="dataset">Dataset<a href="#dataset" class="hash-link" aria-label="Direct link to Dataset" title="Direct link to Dataset">​</a></h4><p>Winobias benchmark 를 사용해 평가한다. 이건 gender bias 가 알려진 36개 직업으로 구성된 데이터셋이다. 각 직업마다 &quot;a portrait of a doctor&quot; 같은 다양한 template 을 사용해 5개의 다른 prompt 를 만든다.  </p><p>또한, 기존 데이터셋에 stereotype 을 유발할 가능성이 높은 prompt 를 추가해 hard dataset 을 만든다. 이 확장된 데이터셋은 original prompt 에 &quot;successful&quot; 이라는 단어를 추가한다. 예를 들어, &quot;a portrait of a successful doctor&quot; 같은 식이다. &quot;Successful&quot; 이라는 단어는 종종 남성 이미지를 생성하게 만들기 때문에 fair generation 에 도전이 된다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation-metric">Evaluation Metric<a href="#evaluation-metric" class="hash-link" aria-label="Direct link to Evaluation Metric" title="Direct link to Evaluation Metric">​</a></h4><p>CLIP classifier 를 사용해 attribute 를 예측한다. Concept (e.g., female, male) 의 text embedding 과 생성된 이미지의 embedding 간 similarity 를 측정하는 방식이다.  </p><p>다양한 attribute 의 imbalance 를 정량화하기 위해 deviation ratio 를 사용한다. 임의의 attribute 수를 수용하기 위해 이 metric 은 다음과 같이 수정된다: <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo>=</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mrow><mi>c</mi><mo>∈</mo><mi>C</mi></mrow></msub><mfrac><mrow><mi mathvariant="normal">∣</mi><msub><mi>N</mi><mi>c</mi></msub><mi mathvariant="normal">/</mi><mi>N</mi><mo>−</mo><mn>1</mn><mi mathvariant="normal">/</mi><mi>C</mi><mi mathvariant="normal">∣</mi></mrow><mn>1</mn></mfrac></mrow><annotation encoding="application/x-tex">\Delta = \max_{c \in C} \frac{|N_c / N - 1 / C|}{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.355em;vertical-align:-0.345em"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mbin mtight">−</span><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>,  </p><ul><li>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span></span> 는 societal group 내 attribute 의 총 개수, </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span></span></span> 은 생성된 이미지의 총 개수, </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">N_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 최대 예측 attribute 가 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">c</span></span></span></span></span> 인 이미지 개수를 뜻한다.  </li></ul><p>특히, 직업과 관련된 gender (male, female) 와 racial (black, white, Asian) bias 를 테스트한다. 이 race 들은 CLIP classifier 가 비교적 신뢰할 만한 예측을 하기 때문에 선택됐다. 평가 중에는 각 직업당 150개의 이미지를 생성한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="approach-setting">Approach Setting<a href="#approach-setting" class="hash-link" aria-label="Direct link to Approach Setting" title="Direct link to Approach Setting">​</a></h4><p>모든 실험에서 Stable Diffusion v1.4 checkpoint 를 사용하고, text-to-image generation 의 guidance scale 은 7.5 로 설정한다.<br>
<!-- -->Base prompt &quot;person&quot; 을 사용해 5개의 concept vector 를 찾는다. 예를 들어, $y^+ = $ &quot;a photo of a woman&quot;, $y^- = $ &quot;a photo of a person&quot; 을 사용해 &quot;female&quot; concept 을 학습한다. </p><p>Concept vector 는 각 concept 당 1K 개의 합성 이미지로 10K step 동안 최적화된다. Inference 중에는 학습된 vector 를 scaling 없이 바로 사용한다.</p><p>Baseline approach 인 UCE 와 달리, 저자의 방법은 Winobias 의 각 직업을 debiasing 할 필요 없이 &quot;person&quot; prompt 에서만 male 과 female concept 을 학습해 모든 직업에 generalization 한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="results-and-analysis">Results and Analysis<a href="#results-and-analysis" class="hash-link" aria-label="Direct link to Results and Analysis" title="Direct link to Results and Analysis">​</a></h4><p><img loading="lazy" alt="Table 1" src="/assets/images/image-107-dafdd76f762f1a66849b13c99c035e54.png" width="1727" height="569" class="img_ev3q"></p><p>Tab. 1 은 저자의 방법이 원래 SD 보다 훨씬 낫고, state-of-the-art debiasing approach 인 UCE 를 능가함을 보여준다. 테이블의 직업들은 36개 직업 리스트에서 무작위로 선택됐다 (Appendix B.2 참조).</p><p>Fig. 5 는 저자의 방법과 원래 SD 로 생성된 이미지를 비교한다.  </p><p><img loading="lazy" alt="Figure 5" src="/assets/images/image-108-bee7f40cae2072e95c4cbb3bc174d7dd.png" width="1727" height="530" class="img_ev3q"></p><ul><li>확장된 Winobias 데이터셋을 사용해 저자의 방법이 다양한 text prompt 에 대한 generalization capability 를 강조한다 (Tab. 1 의 두 번째와 네 번째 column block).</li><li>Text prompt 에 bias 가 있음에도 불구하고, 저자의 방법은 latent visual space 에서 직접 작동하기 때문에 일관되게 잘 수행한다. 반면, UCE 는 이 어려운 데이터셋에서 성능이 떨어진다. </li><li>UCE 는 prompt 의 각 단어를 debiasing 하는데, training set 에 포함되지 않은 biased 단어에 의해 효과가 쉽게 약해진다.  </li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="42-safe-generation">4.2. Safe Generation<a href="#42-safe-generation" class="hash-link" aria-label="Direct link to 4.2. Safe Generation" title="Direct link to 4.2. Safe Generation">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="task-1">Task<a href="#task-1" class="hash-link" aria-label="Direct link to Task" title="Direct link to Task">​</a></h4><p>이 섹션은 inappropriate prompt 에 명시된 harmful content 를 제거한 이미지 생성에 초점을 맞춘다. 기존 방법과 직교하는 접근법으로, 저자의 방법은 현재 safety method 인 SLD 와 ESD 와 결합해 inappropriate generation 을 더 줄인다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="dataset-and-evaluation-metric">Dataset and Evaluation Metric<a href="#dataset-and-evaluation-metric" class="hash-link" aria-label="Direct link to Dataset and Evaluation Metric" title="Direct link to Dataset and Evaluation Metric">​</a></h4><p>I2P benchmark 는 real-world user prompt 에서 수집된 4703개의 inappropriate prompt 로 구성된다. Inappropriateness 는 illegal activity, sexual, violence 등 7개 category 를 포함한다. </p><p>평가에는 Nudenet detector 와 Q16 classifier 를 사용해 이미지에서 nudity 또는 violent content 를 탐지한다. Classifier 중 하나라도 positive 를 예측하면 이미지는 inappropriate 로 분류된다. 평가를 위해 각 prompt 당 5개의 이미지를 생성한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="approach-setting-1">Approach Setting<a href="#approach-setting-1" class="hash-link" aria-label="Direct link to Approach Setting" title="Direct link to Approach Setting">​</a></h4><p>&quot;Safety&quot; 를 위한 single concept vector 를 최적화하는 건 어렵다는 걸 발견했다. 그래서 I2P dataset 에 정의된 각 inappropriate concept (e.g., &quot;anti-sexual&quot;) 에 대해 concept vector 를 학습한다.</p><p>발견된 concept vector 들은 linear 하게 결합돼 final vector 로 사용되며, generation process 를 조절한다. Concept vector 를 linear 하게 결합하는 효과는 다음 섹션에서 더 논의된다.</p><p>&quot;Hate&quot; 같은 특정 concept 은 추상적이고 다양한 visual category 를 포함한다. 이런 concept 을 추가하면 safety 는 개선되지만 image quality degradation 비용이 더 크다. 따라서, 다른 concept 을 밑바탕으로 하는 두 가지 주요 concept, 즉 anti-sexual 과 anti-violence 를 최종 model 로 사용한다.</p><p>Baseline 으로는 SLD 와 ESD 를 사용하며, 공개된 model weight 를 활용한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="results-and-analysis-1">Results and Analysis<a href="#results-and-analysis-1" class="hash-link" aria-label="Direct link to Results and Analysis" title="Direct link to Results and Analysis">​</a></h4><p>Tab. 2 는 저자의 방법이 inappropriate content 를 제거하는 데 효과적임을 보여준다. </p><p><img loading="lazy" alt="Table 2" src="/assets/images/image-109-0e3bde8a4079a3cd7c3aacd2666e6a56.png" width="1727" height="496" class="img_ev3q"></p><ul><li>특히, 저자의 safety vector 는 기존 접근법이 제거하지 못한 inappropriate concept 을 억제할 수 있다. 이는 기존 접근법에 비해 향상된 성능으로 증명된다.  </li><li>특히, SLD 와 저자의 제안된 방법을 결합하면 nudity 제거에서 40% 의 상대적 개선을 보인다. </li><li>또한, ESD 는 nudity 제거를 위해 model weight 를 retraining 했음에도 inappropriate 이미지를 생성하는데, 저자의 방법은 이를 완화할 수 있다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="43-enhancing-responsible-text-guidance">4.3. Enhancing Responsible Text Guidance<a href="#43-enhancing-responsible-text-guidance" class="hash-link" aria-label="Direct link to 4.3. Enhancing Responsible Text Guidance" title="Direct link to 4.3. Enhancing Responsible Text Guidance">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="task-2">Task<a href="#task-2" class="hash-link" aria-label="Direct link to Task" title="Direct link to Task">​</a></h4><p>Responsible text 로 분류된 user prompt 에 대해, prompt 에 있는 responsible phrase 를 생성된 이미지에 정확히 반영하는 걸 목표로 한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="dataset-1">Dataset<a href="#dataset-1" class="hash-link" aria-label="Direct link to Dataset" title="Direct link to Dataset">​</a></h4><p>200개의 prompt 로 구성된 데이터셋을 만들었다. 이 dataset 은 gender 와 race fairness, 그리고 sexual 및 violent content 제거에 초점을 맞춘다.  </p><p>예를 들어, &quot;a fair-gender doctor is operating a surgery&quot; 같은 prompt 는 &quot;fair-gender&quot; 라는 text cue 에 따라 균형 잡힌 gender 이미지를 생성할 수 있는지 평가한다.  </p><p>또한, &quot;a picture of a loved couple, without sexual content&quot; 같은 prompt 는 safety concern 을 다룬다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="results-and-analysis-2">Results and Analysis<a href="#results-and-analysis-2" class="hash-link" aria-label="Direct link to Results and Analysis" title="Direct link to Results and Analysis">​</a></h4><p>평가에는 이전에 소개된 metric 을 사용한다. Fairness 에는 deviation ratio, sexual content 에는 NudeNet, violent content 에는 Q16 을 사용한다. 데이터셋에 대해 3500개의 이미지를 생성해 평가한다.</p><p>저자의 방법에서는 input prompt 와 관련된 concept 을 model 에 제공한다. 예를 들어, prompt 에 &quot;no sexual&quot; 이 언급되면 anti-sexual vector 를 generation process 에 추가한다.</p><p>Tab. 3 은 safety concept 을 사용하지 않는 원래 model 과 저자의 방법을 비교한다. </p><p><img loading="lazy" alt="Table 3" src="/assets/images/image-110-6fbe64398cc6086f70495da83de0bbb3.png" width="835" height="297" class="img_ev3q"></p><p>저자의 방법은 responsible instruction 에 대한 text guidance 를 효과적으로 강화한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="44-semantic-concepts">4.4. Semantic Concepts<a href="#44-semantic-concepts" class="hash-link" aria-label="Direct link to 4.4. Semantic Concepts" title="Direct link to 4.4. Semantic Concepts">​</a></h2><p>이전 실험에서 저자는 발견된 concept vector 의 responsible generation 에 대한 구체적인 적용을 보여줬다. 이 하위 섹션에서는 semantic space 와 관련된 발견된 vector 의 일반적인 속성을 소개한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="interpolation">Interpolation<a href="#interpolation" class="hash-link" aria-label="Direct link to Interpolation" title="Direct link to Interpolation">​</a></h4><p>Fig. 6 은 concept vector 의 strength 를 linear 하게 조절해 이미지 semantics 를 조작하는 영향을 보여준다. 이는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>←</mo><mi>h</mi><mo>+</mo><mi>λ</mi><mi>c</mi></mrow><annotation encoding="application/x-tex">h \leftarrow h + \lambda c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span><span class="mord mathnormal">c</span></span></span></span></span> 식에서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 로 나타낸다.</p><p><img loading="lazy" alt="Figure 6" src="/assets/images/image-111-d1d5303aed53dbe71578f7e36886c4ba.png" width="860" height="590" class="img_ev3q"></p><ul><li>이미지는 추가된 vector 의 strength 를 조정함으로써 점진적으로 도입된 concept 으로 수정된다. </li><li>부드러운 전환은 발견된 vector 가 target semantic concept 을 나타내면서 다른 semantic factor 와 대략적으로 disentangled 됨을 보여준다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="composition">Composition<a href="#composition" class="hash-link" aria-label="Direct link to Composition" title="Direct link to Composition">​</a></h4><p>Fig. 7 은 독립적으로 학습된 concept vector 의 composability 를 보여준다. &quot;A photo of a doctor&quot; prompt 에서 이미지를 생성한다.</p><p><img loading="lazy" alt="Figure 7" src="/assets/images/image-112-eedb56dbfc2835026a2292526cbb677e.png" width="841" height="547" class="img_ev3q"></p><p>이 concept vector 들을 linear 하게 결합함으로써 생성된 이미지의 해당 attribute 를 제어할 수 있다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="generalization">Generalization<a href="#generalization" class="hash-link" aria-label="Direct link to Generalization" title="Direct link to Generalization">​</a></h4><p>Fig. 8 은 발견된 concept vector 의 universal semantic concept 에 대한 generalization capability 를 보여준다.</p><p><img loading="lazy" alt="Figure 8" src="/assets/images/image-113-14536f52585da482129259b829aa3ec5.png" width="849" height="576" class="img_ev3q"></p><ul><li>&quot;Running&quot; concept 에 대한 latent vector 를 dog 이미지로 학습하고, &quot;a photo of a cat&quot; 같은 prompt 를 사용해 다른 객체에 대한 효과를 테스트한다.  </li><li>그림의 각 이미지 쌍은 동일한 random seed 로 생성됐다. &quot;Running&quot; vector 는 dog 에서 학습됐지만, 다른 동물과 심지어 인간에게도 성공적으로 확장된다.  </li><li>또한, 저자의 방법은 &quot;an elephant wearing glasses&quot; prompt 에 대한 원래 text guidance 를 강화한다. original SD 는 정확한 이미지를 생성하지 못한다 (Fig. 8 의 첫 번째와 세 번째 이미지).  </li><li>&quot;Glasses&quot; concept vector 를 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-space 에 추가하면 올바른 이미지를 생성할 수 있다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="impact-on-image-quality">Impact on Image Quality<a href="#impact-on-image-quality" class="hash-link" aria-label="Direct link to Impact on Image Quality" title="Direct link to Impact on Image Quality">​</a></h4><p>저자는 생성된 이미지 품질이 원래 SD 와 거의 같은 수준임을 발견했다 (Tab. 4). </p><p><img loading="lazy" alt="Table 4" src="/assets/images/image-114-8071db6074e13523ef9208c098bd25f6.png" width="791" height="397" class="img_ev3q"></p><p>보고된 score 와 실험 간 차이는 이미지 생성과 caption sampling 중 randomness 때문일 수 있다. 이는 다른 연구에서도 보고된 불일치와 일치한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="sensitivity-to-hyperparameters">Sensitivity to Hyperparameters<a href="#sensitivity-to-hyperparameters" class="hash-link" aria-label="Direct link to Sensitivity to Hyperparameters" title="Direct link to Sensitivity to Hyperparameters">​</a></h4><ul><li>Appendix F 에서 저자는 hyperparameter 에 대한 저자의 방법의 민감도를 조사한다. Training 이미지 수나 다른 input prompt 같은 요소에 덜 영향을 받는다는 걸 발견했다. </li><li>또한, 저자의 방법이 기존 데이터셋을 활용해 concept vector 를 발견할 수 있음을 보여준다.</li></ul><h1>5. Conclusion</h1><p>이 연구에서 저자는 text-to-image diffusion model 의 latent space 에서 semantic concept 을 식별하는 self-discovery approach 를 소개했다. 연구 결과는 diffusion model 의 internal semantic space 에 있는 ethical-related concept 때문에 inappropriate content 가 생성될 수 있음을 강조한다.  </p><p>이 concept vector 를 활용해 저자는 responsible generation 을 가능하게 한다.  </p><ul><li>Societal group 간 평등을 촉진  </li><li>Inappropriate content 제거  </li><li>Responsible prompt 에 대한 text guidance 강화</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/text-to-image">Text-to-Image</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/diffusion">Diffusion</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/concept-editing">Concept Editing</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/sdid">SDID</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/Computer Vision/Generation/ Concept Editing/2023-11-SDID.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/UCE"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Unified Concept Editing in Diffusion Models</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/Computer Vision/Generation/ Concept Editing/MACE"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Mace: Mass concept erasure in diffusion models</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#31-finding-a-semantic-concept" class="table-of-contents__link toc-highlight">3.1. Finding a Semantic Concept</a></li><li><a href="#32-responsible-generation-with-self-discovered-interpretable-latent-direction" class="table-of-contents__link toc-highlight">3.2. Responsible Generation with Self-discovered Interpretable Latent Direction</a></li><li><a href="#41-fair-generation" class="table-of-contents__link toc-highlight">4.1. Fair Generation</a></li><li><a href="#42-safe-generation" class="table-of-contents__link toc-highlight">4.2. Safe Generation</a></li><li><a href="#43-enhancing-responsible-text-guidance" class="table-of-contents__link toc-highlight">4.3. Enhancing Responsible Text Guidance</a></li><li><a href="#44-semantic-concepts" class="table-of-contents__link toc-highlight">4.4. Semantic Concepts</a></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.bb9f61d2.js"></script>
<script src="/assets/js/main.021b6bf4.js"></script>
</body>
</html>