<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2023-04-HintAug">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Hint-Aug: Drawing Hints from Foundation Vision Transformers towards Boosted Few-shot Parameter-Efficient Tuning | WYJLab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/HinTAug"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Hint-Aug: Drawing Hints from Foundation Vision Transformers towards Boosted Few-shot Parameter-Efficient Tuning | WYJLab"><meta data-rh="true" name="description" content="논문 및 image 출처 :"><meta data-rh="true" property="og:description" content="논문 및 image 출처 :"><link data-rh="true" rel="icon" href="/img/WYJLab.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/HinTAug"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/HinTAug" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/HinTAug" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="WYJLab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="WYJLab Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.9ed678b7.css">
<link rel="preload" href="/assets/js/runtime~main.78cc6745.js" as="script">
<link rel="preload" href="/assets/js/main.50337039.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Multi-Modal/PEFT/Composition/Moka">Multi-Modal</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Composition/CLIP-LoRA">Vision-Language</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Composition/CLIP-LoRA">CLIP</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Composition/CLIP-LoRA">Few-shot</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Composition/CLIP-LoRA">Composition</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Module/CLIP-Adapter">Module</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Multi-Modality/MaPLe">Multi-Modality</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/CMAR">Prompting</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/CMAR">Pixel-Level</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/CMAR">Cross-modal Adversarial Reprogramming</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/VP">Exploring Visual Prompts for Adapting Large-Scale Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/Watermarking">Watermarking for Out-of-distribution Detection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/ILM-VP">Understanding and Improving Visual Prompting: A Label-Mapping Perspective</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/EVP">Unleashing the Power of Visual Prompting At the Pixel Level</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/DAM-VP">Diversity-Aware Meta Visual Prompting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/EVP-L">Explicit Visual Prompting for Low-Level Structure Segmentations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/HinTAug">Hint-Aug: Drawing Hints from Foundation Vision Transformers towards Boosted Few-shot Parameter-Efficient Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/AutoVP">AutoVP: An Automated Visual Prompting Framework and Benchmark</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/A2XP">A2XP: Towards Private Domain Generalization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/InMeMo">Instruct Me More! Random Prompting for Visual In-Context Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/LaViP">LaViP: Language-Grounded Visual Prompts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/AdaViPro">AdaViPro: Region-Based Adaptive Visual Prompt For Large-Scale Models Adapting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/TVP">Exploring the Transferability of Visual Prompting for Multimodal Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/SMM">Sample-specific Masks for Visual Reprogramming-based Prompting</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Textual-Token/CoOp">Textual-Token</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Visual-Token/VPT">Visual-Token</a></div></li></ul></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/Foundation/Contrastive Learning/ALIGN">Foundation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/VQA-IC/Few-shot/VQA Few-shot">VQA-IC</a></div></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Vision-Language</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">CLIP</span><meta itemprop="position" content="3"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Few-shot</span><meta itemprop="position" content="4"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Prompting</span><meta itemprop="position" content="5"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Pixel-Level</span><meta itemprop="position" content="6"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Hint-Aug: Drawing Hints from Foundation Vision Transformers towards Boosted Few-shot Parameter-Efficient Tuning</span><meta itemprop="position" content="7"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Hint-Aug: Drawing Hints from Foundation Vision Transformers towards Boosted Few-shot Parameter-Efficient Tuning</h1></header><p>논문 및 image 출처 : <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Hint-Aug_Drawing_Hints_From_Foundation_Vision_Transformers_Towards_Boosted_Few-Shot_CVPR_2023_paper.pdf" target="_blank" rel="noopener noreferrer">https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Hint-Aug_Drawing_Hints_From_Foundation_Vision_Transformers_Towards_Boosted_Few-Shot_CVPR_2023_paper.pdf</a></p><h1>Asbtract</h1><p>foundation vision transformers (FViTs)를 downstream task 에 맞게 tuning 하는 수요가 증가하고 있음에도 불구하고, data-limited scenarios (e.g., few-shot tuning)에서 FViTs 의 잠재력을 완전히 발휘하는 것은 data-hungry nature 로 인해 여전히 어려운 과제이다.</p><p>Common data augmentation 기술은 few-shot tuning data 에 포함된 limited features 때문에 이 상황에서 효과가 부족하다.</p><p>이 문제를 해결하기 위해, 저자는 few-shot tuning 에서 FViTs 의 가능성을 발견했다: </p><ul><li>pre-trained FViTs 는 large-scale pretraining data 로부터 이미 매우 대표적인 특징들을 학습했으며, 이는 널리 사용되는 parameter-efficient tuning 에서 완전히 보존된다.</li><li>저자는 이러한 learned features 를 활용하여 tuning data 를 augment 하면 few-shot FViT tuning 의 효과를 높일 수 있다고 가정한다.</li></ul><p>이를 위해 저자는 <strong>Hint</strong>-based Data <strong>Aug</strong>mentation (Hint-Aug)이라는 framework 를 제안하며, 이는 tuning samples 의 over-fitted parts 를 pre-trained FViTs 의 learned features 로 augmenting 하여 FViT 의 few-shot tuning 을 강화하는 것을 목표로 한다.</p><p>구체적으로, Hint-Aug 는 two enablers 를 통합:</p><ol><li>foundation ViTs 에서 over-confident patches 를 탐지하여 few-shot tuning data 에서 over-fitting 을 잠재적으로 완화할 수 있는 <strong>A</strong>ttentive <strong>O</strong>ver-fitting <strong>D</strong>etector (AOD)</li><li>위의 AOD 에 의해 탐지된 over-confident patches 에 pre-trained FViTs 의 easy-to-confuse features 를 주입하여 tuning 중에 feature diversity 를 강화하는 <strong>C</strong>onfusion-based <strong>F</strong>eature <strong>I</strong>nfusion (CFI) module 이다.</li></ol><p>5 datasets 과 3 parameter-efficient tuning 기술에 대한 광범위한 실험과 ablation study 를 통해 Hint-Aug 의 효과가 일관되게 입증되었다:</p><ul><li>various low-shot setting 에서 SOTA 의 data augmentation 방법보다 0.04% ∼ 32.91% 더 높은 정확도를 기록.</li><li>예로, Pet dataset 에서 Hint-Aug 는 50% less training data 로 SOTA data augmentation 보다 2.22% 더 높은 정확도를 달성.</li></ul><h1>1. Introduction</h1><p>Foundation Vision Transformers (FViTs)은 최근 다양한 downstream task 에서 큰 잠재력을 보여주고 있다. </p><p>FViTs 의 성공은 deep learning 의 새로운 패러다임을 안내한다: large-scale dataset 에 FViT 를 pre-training 후, 최근 개발된 parameter-efficient tuning 방법들 (e.g., visual prompt tuning (VPT), visual prompting, LoRA 및 Adapter)을 사용해 limited tuning data 로 pre-trained FViT 를 tuning.</p><p>그러나, real-world applications, 특히 few-shot tuning scenarios 에서 pre-trained FViTs 를 효과적으로 tuning 하는 것은 여전히 어려운 과제이다.</p><p>그 이유는 parameter-efficient tuning 이 FViT 전용으로 설계되었으며 trainable parameters 를 줄여 overfitting 을 완화할 수 있지만, FViTs 의 data-hungry nature 는 완화되지 않으므로 data-limited scenarios (e.g., few-shot tuning scenarios) 에서 달성 가능한 정확도는 여전히 제한적이기 때문이다.</p><p>따라서 various downstream task 에서 few-shot tuning 으로 pre-trained FViTs 를 효과적으로 tuning 하는 방법은 여전히 해결되지 않은 질문이다.</p><hr><p>few-shot scenarios 에서 parameter-efficient FViT tuning 의 효과를 높이기 위해, data augmentation 기술을 활용하여 tuning 중 모델의 data diversity 와 feature diversity 를 증가시키는 것이 유망한 방향이다.</p><p>그러나 기존의 data augmentation 기술은 few-shot tuning scenarios 에서 모델 정확도를 높이는 데 한계가 있다.</p><p>기존의 data augmentation 기술은 대부분 random-based (e.g., RandAugment, AutoAugment, color jitter, mixup 및 cutmix) 로, training data 에서 기존의 특징들을 무작위로 조합하기 때문에 new 및 meaningful features 를 생성할 수 없다.</p><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-169-7c9c7e4ee7a9fcee9b259a702d7712f5.png" width="846" height="784" class="img_ev3q"></p><p>Fig. 1 처럼, 저자는 널리 사용되는 random-based data augmentation 기술 (e.g., RandomAugment, color jitter 및 random erasing 을 포함한 전용 조합) 또는 data augmentation 없는 training 이 few-shot tuning 의 다양한 datasets 에서 만족스러운 정확도에 일관적으로 달성할 수 없는 것을 관찰한다.</p><p>특히, fine-grained classification tasks (e.g., Aircraft dataset) 에 적용될 때, 이러한 random-based data augmentation 기술들은 정확도를 떨어뜨리기도 한다.</p><p>그 이유는 random-based data augmentation 기술들이 out-of-manifold sample 을 쉽게 생성할 수 있으며, 이는 few-shot tuning scenarios 에서 limited training samples 로 인해 정확도를 크게 저하시킬 수 있다.</p><p>따라서, various downstream task 에서 FViT tuning 의 효과를 높이기 위해서는 주어진 training sample 을 다양한, 하지만 여전히 in-manifold 인 특징으로 adaptively augment 할 수 있는 data augmentation 기술을 개발하는 것이 중요하다.</p><p>이 연구는 효과적인 few-shot FViT tuning 에 대한 증가하는 수요와 기존 기술로 달성 가능한 정확도 사이의 격차를 좁히기 위해 시작되었다.</p><p>특히, few-shot parameter-efficient tuning 에서 pre-trained FViT 의 wegiht 는 tuning 동안 고정된다.</p><p>기존 연구에서는: (1) pre-trained transformer model 이 이미 복잡하지만 generalizable features 를 학습했다는 사실과, (2) gradient-based 방법이 pre-trained model 에서 learned features 를 추출한 후 이를 input images 에 추가할 수 있다는 사실에 주목했다.</p><p>따라서, FViT 의 few-shot tuning 정확도는 pre-trained FViT 의 learned feautres 를 활용함으로써 크게 향상될 수 있다고 가정했다.</p><p>구체적으로, 저자는 다음과 같은 기여를 했다:</p><ul><li>pre-trained FViT 의 learned features 을 활용하여 data augmentation 전략이 사용된 input-adative manner 의 training  dataset 을 guiding 하여 few-shot tuning scenarios 에서 FViT 의 달성 가능한 정확도를 높이는 것을 목표로 하는 <strong>Hint</strong>-based Data <strong>Aug</strong>mentation (Hint-Aug) framework 를 제안했다.</li><li>Hint-Aug framework 는 두 가지 주요 요소를 통합했다:<ul><li>(1) 주어진 training dataset 에서 over-fitting sample 과 patches 를 pre-trained FViT 의 attention map 을 이용해 식별하는 <strong>A</strong>ttentive <strong>O</strong>ver-fitting <strong>D</strong>etector(AOD)와,</li><li>(2) pre-trained FViT 의 learned features 들을 training data 에 adaptively infuse 하여 downstream 에 better tuning 을 효과적으로 하는 <strong>C</strong>onfusion-based <strong>F</strong>eature <strong>I</strong>nfusion(CFI) module</li></ul></li><li>5 dataset 과 3 parameter-efficient tuning 기술에 대한 광범위한 실험과 ablation study 를 통해 제안된 Hint-Aug framework 의 효과가 일관되게 검증되었음.<ul><li>다양한 few-shot 설정에서 최신 data augmentation 방법들보다 0.04% ∼ 32.91% 더 높은 정확도를 기록했다. </li><li>예로, Pets dataset 에서는 SOTA augmentation 방법에 비해 50% less training data로 2.22% 더 높은 정확도를 달성했다.</li></ul></li></ul><h1>2. Related Works</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="21-fvits">2.1. FViTs<a href="#21-fvits" class="hash-link" aria-label="Direct link to 2.1. FViTs" title="Direct link to 2.1. FViTs">​</a></h2><p>최근 Vision Transformers (ViTs)의 성공에 영감을 받아, ViTs 의 model size 를 확장해 FViTs 를 구축하는 것이 주목받고 있다.</p><p>이는 large-scale neural language processing 의 성공을 CV 분야에 복제하려는 목표를 가지고 있다.</p><p>FViTs 개발에 대한 기존 연구는 크게 두 가지로 나뉜다: (1) ViTs 의 architecture 를 확장해 강력한 FViTs 를 구축하는 연구와, (2) FViTs 의 learned representations 를 downstream task 에 효과적으로 generalization 될 수 있도록 하는 self-supervised learning 기법을 개발하는 연구이다.</p><p>기존의 Convolutional Neural Networks (CNNs)와 달리, FViTs 는 global featuress= 를 추출하기 위해 self-attention 메커니즘을 광범위하게 사용하여 larger model (e.g., 10G FLOPs 이상)으로도 향상된 작업 정확도를 얻는다.</p><p>구체적으로, ViTs 에서는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>x</mi><mi>N</mi></msub><msup><mo stretchy="false">]</mo><mi mathvariant="normal">⊤</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mi>D</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X = [x_1, \cdots, x_N]^\top \in \mathbb{R}^{N \times D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span></span></span></span></span></span></span></span></span></span> 에서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span></span> 가 embedding dimension 인 input image patches <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span></span></span> 가 ViT block 에 의해 순차적으로 처리된다.</p><p>각 블록에서 input 은 linear projection 을 통해 query <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">Q \in \mathbb{R}^{N \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span>, key <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">K \in \mathbb{R}^{N \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span>, value <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">V \in \mathbb{R}^{N \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span> 로 변환된 후 self-attention 을 계산한다.</p><p>self-attention 은 다음과 같이 계산된다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo fence="true">)</mo></mrow><mi>V</mi></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \text {Attention}(Q,K,V) = \text{softmax} \left(\frac{QK^T}{\sqrt{d}}\right) V \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.4684em;vertical-align:-0.9842em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4842em"><span style="top:-3.4842em"><span class="pstrut" style="height:3.5183em"></span><span class="mord"><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em"><span style="top:-2.1778em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord mathnormal">d</span></span></span><span style="top:-2.8922em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1078em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9842em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4842em"><span style="top:-3.4842em"><span class="pstrut" style="height:3.5183em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9842em"><span></span></span></span></span></span></span></span></span></div><p>이 output 은 feed-forward network 로 전달되어 channel dimesion 에서 정보를 추출하게 된다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="22-parameter-efficient-tuning">2.2. Parameter-efficient Tuning<a href="#22-parameter-efficient-tuning" class="hash-link" aria-label="Direct link to 2.2. Parameter-efficient Tuning" title="Direct link to 2.2. Parameter-efficient Tuning">​</a></h2><p>FViTs 의 large-scale dataset 에 대한 인상적인 pre-training 성능에 힘입어, FViTs 를 real-world applications 에 적용하려는 관심이 커지고 있다.</p><p>일반적으로 pretraining-then-tuning 패러다임을 따라 pre-trained FViTs 를 다양한 downstream task 에 맞춰 tuning 한다. 그러나 conventional weight tuning 방식에서는 각 task 마다 additional model weight set 을 저장해야 하므로 storage overhead 가 과도해질 수 있다.</p><p>이를 해결하기 위해 various parameter-efficient tuning 방법이 제안되었다. parameter-efficient tuning 에선 pre-trained FViTs 에 tiny learnable module 을 추가하는 반면, tuning 중에는 FViTs 의 backbone weights 는 변경되지 않는다.</p><p>이 approach 는 두 가지 이점을 제공: (1) negligible additional parameters 로 FViTs 를 new downstream task 에 맞춰 tuning 할 수 있으며, (2) 추가된 parameter-efficient tuning module 을 제거하기만 하면 pre-trained FViTs 를 쉽게 복원할 수 있다.</p><p>최근 parameter-efficient tuning 기술 중, LoRA 는 backbone weight 위에 low-dimension 의 weight 를 학습하고, VPT 는 prompt tuning 아이디어를 사용해a dditional token 으로 task-specific prompt 를 삽입한다. </p><p>더 최근에는 NPS 가 parameter-efficient tuning 기술과 해당 hyper-parameter 의 optimal combination 을 neural architecture search 를 통해 탐색하는 방법을 제안했다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="23-few-shot-tuning">2.3. Few-shot Tuning<a href="#23-few-shot-tuning" class="hash-link" aria-label="Direct link to 2.3. Few-shot Tuning" title="Direct link to 2.3. Few-shot Tuning">​</a></h2><p>Few-shot tuning 은 class 당 limited samples 로 pre-trained model 을 new tasks 에 tuning 을 목표로 한다.</p><p>이는 많은 real-world applications 에서 high-quality data 가 부족하기 때문에 최근 몇 년간 점점 더 많은 주목을 받고 있다.</p><p>최근 몇 가지 선도적인 연구들은 ViTs 의 few-shot tuning 을 목표로 하여, self-attention module 의 지침 하에 meta-learning tasks 와 learning objectives 를 사용자 정의하는 방법을 제안했다.</p><p>본 논문에서는 few-shot tuning sample 을 adaptively augmenting 하여 부족한 다양한 특징을 보완함으로써 FViTs 의 few-shot tuning 정확도를 높이는 것을 목표로 한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="24-data-augmentation">2.4. Data Augmentation<a href="#24-data-augmentation" class="hash-link" aria-label="Direct link to 2.4. Data Augmentation" title="Direct link to 2.4. Data Augmentation">​</a></h2><p>data augmentation 은 data diversity 을 높이고, 따라서 model 의 feature diversity 를 증가시키는 것을 목표로 한다.</p><p>효과적인 data augmentation 전략은 data diversity 를 적절히 향상시키면서 동시에 과도한 augmentation intensity 에 의해 생성된 out-of-manifold data 를 생성하지 않아야 한다.</p><p>다양한 data augmentation 기술이 제안되었지만, few-shot tuning 환경에서 data 를 효과적으로 augmenting 하는 방법은 여전히 풀리지 않은 질문이다.</p><p>few-shot data 의 limited data diversity 에는 novel meaningful features 를 생성할 수 있는 기술이 필요하다.</p><p>이를 위해 대부분의 기존 few-shot data augmentation 기술은 in-domain data 를 생성하기 위해 generative models 를 채택하지만, 이는 FViTs tuning 의 memory 및 storage overhead 를 더욱 증가시킨다.</p><p>앞서 언급한 문제를 완화하는 한 가지 잠재적인 방법은 beneficial features 을 가진 sample 을 생성하기 위해 adversarial 기법을 사용하는 것이다.</p><p>그러나 이러한 연구의 대다수는 clean accuracy 향상이 아닌 adversarial robustness 를 향상시키는 데 초점을 맞추고 있다.</p><p>반면, 본 연구는 few-shot parameter-efficient tuning 중 clean accuracy 를 높이기 위해 beneficial features 을 생성할 수 있는 adversarial training 을 활용할 기회를 탐구한다.</p><h1>3. The Proposed Hint-Aug Framework</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="31-hint-aug-motivation">3.1. Hint-Aug: Motivation<a href="#31-hint-aug-motivation" class="hash-link" aria-label="Direct link to 3.1. Hint-Aug: Motivation" title="Direct link to 3.1. Hint-Aug: Motivation">​</a></h2><p>저자는 먼저 parameter-efficient tuning 과 pre-trained FViTs 의 특성이 FViTs 의 parameter-efficient tuning 에 독특한 기회를 제공한다는 것을 확인했다.</p><p>이 관찰에 기반하여, 이러한 특성을 활용하여 tuning 효과를 향상시키기 위한 Hint-Aug framework 를 제안한다. </p><p>각 특성에 대해 자세히 설명하면 다음과 같다:</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="characteristics-of-parameter-efficient-tuning">Characteristics of parameter-efficient tuning:<a href="#characteristics-of-parameter-efficient-tuning" class="hash-link" aria-label="Direct link to Characteristics of parameter-efficient tuning:" title="Direct link to Characteristics of parameter-efficient tuning:">​</a></h4><p>Sec 2.1 및 2.2 에서 언급했듯이, pre-trained FViTs 의 weights 는 tuning 중에 고정된다.</p><p>따라서, added tuning modules (e.g., Adapter, VPT, LoRA 등)이 제거되면 tuning 된 FViTs 는 pre-trained 버전과 동일하게 동작한다.</p><p>이 특성을 활용하여 pre-trained FViTs 를 활용해 few-shot tuning 정확도를 향상시킬 수 있는지를 고려하게 되었다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="characteristics-of-pretrained-fvits">Characteristics of pretrained FViTs:<a href="#characteristics-of-pretrained-fvits" class="hash-link" aria-label="Direct link to Characteristics of pretrained FViTs:" title="Direct link to Characteristics of pretrained FViTs:">​</a></h4><p>기존 연구에 따르면, pre-trained FViTs 는 learned features 에 관해 두 가지 유망한 특성을 가진다: </p><ol><li>pre-trained FViTs 는 복잡하지만 meaningful features 식별할 수 있다, 심지어 tuning 하지 않은 unseen dataset 에 대해서도; </li><li>FViTs 에서 learned features 는 gradient-based 방법을 사용하여 input image space 로 reversely project 될 수 있다.</li></ol><p>이러한 parameter-efficient tuning 과 pre-trained FViTs 의 특성을 고려할 때, 저자는 pre-trained FViTs 를 효과적으로 활용하여 few-shot tuning data 를 augmenting 할 수 있는 독특한 기회를 제공할 것이라고 가정했다.</p><p>이 가설을 검증하기 위해, pre-trained FViTs 에서 learned features 을 활용하여 few-shot tuning 의 효과를 높일 수 있는 적절한 방법을 탐구하고자 한다. 특히, few-shot tuning 의 두 가지 주요 과제인 overfitting 과 tuning data 의 diversity lack 에 대해 다음과 같은 질문을 설정했다:</p><ul><li><strong>Q1</strong>: pre-trained FViTs 가 few-shot tuning 중에 발생할 수 있는 overfitting 문제를 감지할 수 있는가?</li><li><strong>Q2</strong>: pre-trained FViTs 를 활용하여 data diversity 을 향상시킬 수 있는 meaningful features 를 생성할 수 있는가?</li></ul><p>저자의 Hint-Aug framework 는 이러한 두 가지 질문에 대한 효과적인 솔루션을 제공한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="32-hint-aug-overview">3.2. Hint-Aug: Overview<a href="#32-hint-aug-overview" class="hash-link" aria-label="Direct link to 3.2. Hint-Aug: Overview" title="Direct link to 3.2. Hint-Aug: Overview">​</a></h2><p>저자는 먼저 제안하는 Hint-Aug framework 의 개요를 제공한다.</p><p>이 framework 는 parameter-efficient tuning 의 특성을 활용하여, tuning 중에 pre-trained FViTs 의 weight 가 업데이트되지 않으므로 pre-trained FViTs 에서 learned features 를 tuning data augmentation 에 활용하는 few-shot parameter-efficient tuning 을 위해 설계되었다. </p><p><img loading="lazy" alt="Figure 2" src="/assets/images/image-170-f349bb310fd95a5165942268c5bc21b4.png" width="2086" height="835" class="img_ev3q"></p><p>Fig. 2 에서 볼 수 있듯이, Hint-Aug 는 두 단계로 이루어진 detect-then-augment pipeline 을 채택했다.</p><ul><li>특히, <strong>Q1</strong> 에 답하기 위해 Hint-Aug 는 AOD 를 사용하여 (1) tuned FViT 가 이 image 에 대해 overfitting 이 발생했는지, (2) image 의 어떤 patch 가 overfitting 에 더 취약한지를 탐지한다.</li><li><strong>Q2</strong> 에 대응하여, Hint-Aug 는 CFI module 에 easy-to-confuse features 를 주입하여 AOD 의 detected patch 를 augmenting 한다</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="33-enabler-1-attentive-over-fitting-detector">3.3. Enabler 1: Attentive Over-fitting Detector<a href="#33-enabler-1-attentive-over-fitting-detector" class="hash-link" aria-label="Direct link to 3.3. Enabler 1: Attentive Over-fitting Detector" title="Direct link to 3.3. Enabler 1: Attentive Over-fitting Detector">​</a></h2><p>Over-fitting 은 few-shot tuning scenarios 에서 잘 알려진 문제이며, few-shot FViT tuning 동안 model size 와 data size 의 제한으로 인해 이 문제가 더욱 심화된다.</p><p>따라서 AOD 는 FViTs 의 parameter-efficient tuning 중 각 tuning sample 에 대해 실시간으로 overfitting 문제를 감지할 수 있는지 탐구하는 것을 목표로 한다.</p><p>이전 연구에서 FViTs 의 attention distribution 을 다양한 방식으로 시각화한 것을 참고하여, tuning 과정에서 attention distribution 의 변화가 overfitting 의 존재를 식별하는 숨겨진 단서를 포함하고 있다고 가정했다.</p><p>이 가설을 검증하기 위해, 저자는 FViT 의 attention distribution 에 대한 각 input image patch 의 영향을 정량화하기 위해 attention-score map 을 사용했다.</p><p>구체적으로, attention-score map 은 input image 의 각 patch 에 해당하는 attention-score 로 구성되며, attention-score 는 다음과 같이 정의하였다:</p><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span></span></span></span></span>-th layer 의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>-th head 의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span></span>-th patch 에 대한 attention distribution <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msubsup><mi>a</mi><mn>1</mn><mrow><mo stretchy="false">(</mo><mi>l</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msubsup><mi>a</mi><mi>N</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a^{(l,h,i)}_1, \dots, a^{(l,h,i)}_N]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3383em;vertical-align:-0.2935em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4337em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">h</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2663em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4065em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">h</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2935em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> 가 주어졌을 때, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span>-query patch 에 대한 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05724em">j</span></span></span></span></span>-th patch 의 attention-score <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>s</mi><mi>j</mi><mrow><mi>l</mi><mo separator="true">,</mo><mi>k</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">s^{l,k}_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.38em;vertical-align:-0.413em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.967em"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span style="top:-3.1809em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em"><span></span></span></span></span></span></span></span></span></span></span> 는 다음과 같이 정의된다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msubsup><mi>s</mi><mi>j</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><munder><mo>∑</mo><mi>h</mi></munder><msubsup><mi>a</mi><mi>j</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} s_j^{(l,k)} = \sum _{h}a_j^{(l,h,k)} \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3521em;vertical-align:-0.9261em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4261em"><span style="top:-3.4261em"><span class="pstrut" style="height:3.05em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8479em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">h</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9261em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4261em"><span style="top:-3.4261em"><span class="pstrut" style="height:3.05em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9261em"><span></span></span></span></span></span></span></span></span></div><p>간단히 하기 위해, 이후 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span></span></span></span></span> 과 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> 의 상첨자를 생략했다.</p><hr><p><img loading="lazy" alt="Figure 3" src="/assets/images/image-171-89a224fcd822697749355e4939ca09fc.png" width="743" height="734" class="img_ev3q"></p><p>tuning 의 different stages 에서 attention-score 를 시각화함으로써, Fig. 3 에서 볼 수 있듯이 두 가지 관찰을 할 수 있다: </p><ol><li>pre-trained FViT 자체의 attention-score map (Fig. 3(a))은 half-tuned FViT model 의 map 과 높은 상관 관계를 가지며 (Fig. 3(b)), 상대적으로 higher tuning 정확도(e.g., 64.37%)는 해당 tuning stage 에서 overfitting 문제가 심각하지 않음을 시사한다;</li><li>tuning 이 완료된 후의 attention-score map (Fig. 3(c) 참조)은 pre-trained FViT 가 집중하지 않은 특정 patches(red)에 더 집중하며, lower tuning 정확도(e.g., 61.55%)는 overfitting 문제가 존재함을 나타낸다.</li><li>추가적으로, newly attracted higher attention-score 를 얻은 patches(red)는 식별을 위한 human-readable information 을 포함하지 않는다는 점을 발견했다.<ul><li>예로, 일부 patches 는 단지 검은색 배경으로만 구성되어 있어 target class 를 식별하는 데 기여하지 않는다.</li><li>이 발견은 이러한 patches 가 overfitting 의 원인이 될 수 있음을 시사한다.</li></ul></li></ol><p>위의 관찰을 바탕으로, 저자는 pre-trained FViT 와 해당 tuned model 의 attention-score map 차이를 사용하여 overfitting 의 존재와 overfitting 문제에 가장 크게 기여하는 patches 를 식별하기 위한 AOD module 을 제안했다.</p><p>구체적으로, pre-trained FViT(이하 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span></span>)에서 생성된 attention-score map <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>S</mi><mi>P</mi></msup><mo>=</mo><mo stretchy="false">[</mo><msubsup><mi>s</mi><mn>1</mn><mi>P</mi></msubsup><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msubsup><mi>s</mi><mi>N</mi><mi>P</mi></msubsup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">S^P = [s^P_1, \cdots, s^P_N]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1167em;vertical-align:-0.2753em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2753em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> 와 tuning 될 FViT model(이하 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span></span>)에서 생성된 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>S</mi><mi>T</mi></msup><mo>=</mo><mo stretchy="false">[</mo><msubsup><mi>s</mi><mn>1</mn><mi>T</mi></msubsup><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msubsup><mi>s</mi><mi>N</mi><mi>T</mi></msubsup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">S^T = [s^T_1, \cdots, s^T_N]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1167em;vertical-align:-0.2753em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2753em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> 에 대해, over-fitting 지표를 다음과 같이 정의한다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>I</mi><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.16em" columnalign="right left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>∑</mo><mi>i</mi></msub><mi mathvariant="normal">∥</mi><msubsup><mi>s</mi><mi>i</mi><mi>P</mi></msubsup><mo>−</mo><msubsup><mi>s</mi><mi>i</mi><mi>T</mi></msubsup><mi mathvariant="normal">∥</mi><mo>&lt;</mo><mi>λ</mi><msub><mo>∑</mo><mi>i</mi></msub><mi mathvariant="normal">∥</mi><msubsup><mi>s</mi><mi>i</mi><mi>P</mi></msubsup><mi mathvariant="normal">∥</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} I=\left \{ \begin {array}{rl} 0, &amp; \sum _{i}\|s_i^P - s_i^T\| &lt; \lambda \sum _{i}\|s_i^P\| \\ 1, &amp; \text {otherwise} \end {array} \right . \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.4013em;vertical-align:-0.9507em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4507em"><span style="top:-3.4507em"><span class="pstrut" style="height:3.4507em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">{</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4507em"><span style="top:-3.6093em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span><span class="mpunct">,</span></span></span><span style="top:-2.4093em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9507em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4507em"><span style="top:-3.6093em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">∥</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span><span class="mord">∥</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">∥</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span><span class="mord">∥</span></span></span><span style="top:-2.4093em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord">otherwise</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9507em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9507em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4507em"><span style="top:-3.4507em"><span class="pstrut" style="height:3.4507em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9507em"><span></span></span></span></span></span></span></span></span></div><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> : overfitting 감지의 민감도를 조절하는 hyper-parameter.</li></ul><p>over-fitting 이 발생하면 (i.e., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">I = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>), attention-score map 을 크게 변화시킨 patches 를 overfitting 문제를 완화하기 위해 augmenting 할 target patches 로 선택한다.</p><p>따라서 augmenting 할 patch <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span></span></span></span></span> 는 다음과 같이 정의된다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>p</mi><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>i</mi></munder><mo stretchy="false">(</mo><mi mathvariant="normal">∥</mi><msubsup><mi>s</mi><mi>i</mi><mi>P</mi></msubsup><mo>−</mo><msubsup><mi>s</mi><mi>i</mi><mi>T</mi></msubsup><mi mathvariant="normal">∥</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} p = \arg \max _i (\|s_i^P - s_i^T \|) \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.619em;vertical-align:-0.5595em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0595em"><span style="top:-3.1682em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop">ar<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em"><span style="top:-2.3723em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7277em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord">∥</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mord">∥</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5595em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0595em"><span style="top:-3.0595em"><span class="pstrut" style="height:2.8913em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5595em"><span></span></span></span></span></span></span></span></span></div><p>반면, over-fitting 문제가 감지되지 않은 경우, 해당 image 에서 attention-score 가 가장 높은 patch 를 augmenting 할 target patches 로 선택한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="34-enabler-2-confusion-based-feature-infusion">3.4. Enabler 2: Confusion-based Feature Infusion<a href="#34-enabler-2-confusion-based-feature-infusion" class="hash-link" aria-label="Direct link to 3.4. Enabler 2: Confusion-based Feature Infusion" title="Direct link to 3.4. Enabler 2: Confusion-based Feature Infusion">​</a></h2><p>위에서 AOD 로 선택된 over-fitted patch 를 강화하여 (1) over-fitting 문제를 완화하고 (2) meaningful features 로 tuning data 의 diversity 를 augmenting 하는 방법에 대한 남은 질문은 무엇인가? 이에 저자는 CFI 를 제안한다. </p><p>이는 pre-trained FViT model 에서 learned features 을 추출하고 selected patch 에 주입하여 tuning data 의 feature diversity 을 meaningful way 로 향상시키는 목적으로 attack-based methods 를 사용한다.</p><p>그러나 few-shot tuning 정확도를 향상시킬 수 있는 meaningful features extraction 및 infusion 은 쉽지 않다.</p><p>흔히 사용되는 attack objectives (e.g., image 를 왜곡하여 correct class 의 model output logit 을 감소시키는 것)으로 samples 를 단순히 augmening 하면 결과적으로 out-of-manifold sample 이 발생할 수 있다.</p><p>이는 Sec. 4.3.2 에서의 실험 결과로 나타났다.\</p><p>이를 극복하기 위해 CFI module 은 injected features 를 활용하여 model prediction 을 synthetic target label 방향으로 유도한다.</p><p>이 target label 은 model 이 classes pair 간의 confusion 하기 쉬운 정도를 정량화하는 confusion matrix 를 사용하여 결정된다.</p><p>구체적으로, CFI 에서 confusion matrix <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>∈</mo><msubsup><mi mathvariant="double-struck">R</mi><mrow><mo>≥</mo><mn>0</mn></mrow><mrow><mi>M</mi><mo>×</mo><mi>M</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">C \in \mathbb{R}^{M \times M}_{\geq 0}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2429em;vertical-align:-0.3615em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8815em"><span style="top:-2.4337em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">≥</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3615em"><span></span></span></span></span></span></span></span></span></span></span> 을 구성한다. </p><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span></span> : total number of classes</li></ul><p>최근 open set detection 에 대한 연구에서 보여준 바와 같이, pre-softmax model output 은 sample 의 모델 불확실성을 보다 잘 보존할 수 있다.</p><p>따라서 저자는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span></span> 를 다음과 같이 정의한다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>C</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><munder><mo>∑</mo><mrow><mi>X</mi><mo>:</mo><mi>y</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>j</mi></mrow></munder><mrow><mo fence="true">(</mo><msub><mi>f</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>−</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><msup><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></munder><msub><mi>f</mi><msup><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} C_{i,j} = \sum_{X:y(X)=j} \left( f_i(X) - \min_{i&#x27;} f_{i&#x27;}(X) \right) \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.666em;vertical-align:-1.083em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.583em"><span style="top:-3.583em"><span class="pstrut" style="height:3.15em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.809em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em">X</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.07847em">X</span><span class="mclose mtight">)</span><span class="mrel mtight">=</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em"><span style="top:-2.356em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.744em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size2">)</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.083em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.583em"><span style="top:-3.583em"><span class="pstrut" style="height:3.15em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.083em"><span></span></span></span></span></span></span></span></span></div><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span></span> 와 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05724em">j</span></span></span></span></span> 는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span></span> 의 좌표로, two classes 를 나타냄</li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span></span> 와 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>M</mi></msup></mrow><annotation encoding="application/x-tex">f ∈ \mathbb{R}^M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span></span></span></span></span></span></span></span></span></span></span></span> 은 input image <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span></span> 에 대한 각각의 ground truth label 과 pre-softmax output 을 의미.</li><li>generated confusion matrix <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span></span> 는 model 로 학습된 class-wise similarity 를 식별하고 model 이 쉽게 혼동하는 class pairs 를 구별하는 데 도움을 준다.</li></ul><p>patch 에 easy-to-confuse feature 를 주입하기 위해, input <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span></span> 와 label <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span></span> 가 주어졌을 때, 저자는 attack label <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>f</mi><mo>~</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>∈</mo><msubsup><mi mathvariant="double-struck">R</mi><mrow><mo>≥</mo><mn>0</mn></mrow><mi>M</mi></msubsup></mrow><annotation encoding="application/x-tex">\tilde{f}(X) \in \mathbb{R}^M_{\geq 0}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1813em;vertical-align:-0.25em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9313em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span></span><span style="top:-3.6134em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.0833em"><span class="mord">~</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1846em;vertical-align:-0.3433em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">≥</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3433em"><span></span></span></span></span></span></span></span></span></span></span> 을 설계하기로 한다.</p><p>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span></span>-th element 는 다음과 같이 계산된다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mover accent="true"><mi>f</mi><mo>~</mo></mover><mi>i</mi></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.16em" columnalign="left right" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mfrac><msub><mi>C</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub><mrow><msub><mo>∑</mo><mi>j</mi></msub><msub><mi>C</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub><mo>−</mo><msub><mi>C</mi><mrow><mi>y</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub></mrow></mfrac><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><mi>i</mi><mo mathvariant="normal">≠</mo><mi>y</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><mi>i</mi><mo>=</mo><mi>y</mi></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \tilde{f}_i(X) = \left\{ \begin{array}{lr} \frac{C_{i,y}}{\sum_{j} C_{j, y} - C_{y,y}}, &amp; \text{if } i \neq y \\ 0, &amp; \text{if } i = y \end{array} \right. \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em"><span style="top:-3.75em"><span class="pstrut" style="height:3.75em"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9313em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span></span><span style="top:-3.6134em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.0833em"><span class="mord">~</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6764em"><span style="top:-3.6908em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9857em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1496em"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4603em"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.5073em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6672em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span></span></span><span style="top:-2.1836em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1764em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6764em"><span style="top:-3.6908em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord">if </span></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span><span style="top:-2.1836em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord">if </span></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1764em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em"><span style="top:-3.75em"><span class="pstrut" style="height:3.75em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span></span></span></span></div><p>loss function 은 다음과 같이 정의된다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi mathvariant="script">L</mi><mrow><mi>t</mi><mi>a</mi><mi>r</mi></mrow></msub><mo>=</mo><mtext>CrossEntropy</mtext><mo stretchy="false">(</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mover accent="true"><mi>f</mi><mo>~</mo></mover><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \mathcal{L}_{tar} = \text{CrossEntropy}(\text{softmax}(f), \text{softmax}(\tilde{f})) \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2913em;vertical-align:-0.3956em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8957em"><span style="top:-2.9644em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">CrossEntropy</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9313em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span></span><span style="top:-3.6134em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.0833em"><span class="mord">~</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mclose">))</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3956em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8957em"><span style="top:-2.8956em"><span class="pstrut" style="height:2.9313em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3956em"><span></span></span></span></span></span></span></span></span></div><p>위 loss 를 minimizing 하기 위해 patch 를 optimizing 함으로써, generted features 는 모델이 current class 의 easy-to-confuse 를 고려하는 방향으로 shift 해준다.</p><p>이러한 shift 는 current class 와 easy-to-confuse 간의 구분을 학습하도록 하여, current class 의 decision boundary 를 효과적으로 확장한다.</p><h1>4. Experimental Results</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="41-experimental-setup">4.1. Experimental Setup<a href="#41-experimental-setup" class="hash-link" aria-label="Direct link to 4.1. Experimental Setup" title="Direct link to 4.1. Experimental Setup">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="datasets-few-shot-settings-models-and-parameter-efficient-tuning-techniques">Datasets, Few-Shot Settings, Models, and Parameter-Efficient Tuning Techniques.<a href="#datasets-few-shot-settings-models-and-parameter-efficient-tuning-techniques" class="hash-link" aria-label="Direct link to Datasets, Few-Shot Settings, Models, and Parameter-Efficient Tuning Techniques." title="Direct link to Datasets, Few-Shot Settings, Models, and Parameter-Efficient Tuning Techniques.">​</a></h4><p><strong><em>Datasets and Few-Shot Settings</em>.</strong></p><p>저자는 Food, Pet, Cars, Flowers, Aircraft 의 5 datasets 를 채택하여 Hint-Aug 을 다양한 few-shot tuning scenarios 에서 평가한다. </p><p>각 dataset 에서 1/2/4/8/12/16-shot scenarios 를 기준으로 정확도를 평가한다.</p><p><strong><em>Models</em>.</strong></p><p>실험은 널리 사용되는 FViT MODEL 인 ViT-Base 를 기반으로 진행한다.</p><p><strong><em>Adopted Parameter-Efficient Tuning Methods</em>.</strong></p><p>Adapter, LoRA, VPT 등 세 가지 널리 사용되는 parameter-efficient tuning 방법을 고려한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="baselines">Baselines.<a href="#baselines" class="hash-link" aria-label="Direct link to Baselines." title="Direct link to Baselines.">​</a></h4><p>제안된 Hint-Aug 을 두 가지 baselines 와 비교한다.</p><p>하나는 parameter-efficient FViT tuning 을 위한 SOTA data augmentation 기법인 NPS 이며, 다른 하나는 augmentation 없는 vanilla tuning (No-Aug) 를 수행한다.</p><p>data diversity 의 한계가 있는 few-shot tuning scenarios 에서, SOTA data augmentation 기법인 NPS 조차도 No-Aug 보다 성능이 떨어질 수 있기 때문에 No-Aug 을 baselines 으로 포함하는 것이 필요하다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="tuning-settings">Tuning Settings.<a href="#tuning-settings" class="hash-link" aria-label="Direct link to Tuning Settings." title="Direct link to Tuning Settings.">​</a></h4><p>실험에서 저자는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">l = 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">5</span></span></span></span></span> 로 설정하고, 각 image 의 center patch 를 query patch 로 사용한다 (i.e., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>90</mn></mrow><annotation encoding="application/x-tex">k = 90</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">90</span></span></span></span></span>).</p><p>저자는 mixup 의 널리 채택된 few-shot tuning 설정을 따른다. </p><p>구체적으로,</p><ul><li>model 을 100 epochs 동안 tuning</li><li>batch size 256</li><li>learning rate 0.01</li><li>SGD optimizer</li><li>ImageNet-pre-trained ViT-Base 사용</li><li>NPS 를 따르며, data augmentation 기법으로 color-jitter (factor 0.4)와 RandAugment (9 의 크기와 0.5 의 표준 편차)을 사용</li><li>Eq. (3) 에서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 는 0.1 로 설정하고, FGSM 을 사용하여 attack radius <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>0.001</mn></mrow><annotation encoding="application/x-tex">\epsilon = 0.001</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.001</span></span></span></span></span> 의 adversarial samples 을 생성한다.</li><li>모든 실험은 세 번 실행하여 평균 정확도를 보고한다, NPS 를 따른다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="42-benchmark-on-few-shot-image-classification">4.2. Benchmark on Few-Shot Image Classification<a href="#42-benchmark-on-few-shot-image-classification" class="hash-link" aria-label="Direct link to 4.2. Benchmark on Few-Shot Image Classification" title="Direct link to 4.2. Benchmark on Few-Shot Image Classification">​</a></h2><p>저자는 제안된 방법을 5 few-shot image classification datasets 에서 다양한 parameter-efficient tuning 기법과 few-shot settings 로 벤치마킹한다.</p><p><img loading="lazy" alt="Figure 4" src="/assets/images/image-172-0dbd83eaa96ebd667da836e81d13c47d.png" width="1442" height="1136" class="img_ev3q"></p><p>Fig. 4 에서 보이듯.</p><ul><li>SOTA augmentation baselines 인 NPS 는 fine-grained image classification dataset (e.g., Aircraft 에서 5.55% 정확도 감소)에서 Vanilla tuning 방법인 No-Aug 에 비해 상당한 정확도 감소를 겪는 반면,</li><li>Hint-Aug 은 Adapter, VPT, LoRA tuning 을 사용할 때 baselines 보다 0.25% ~ 6.10%, 0.10% ~ 32.91%, 0.04% ~ 6.17% 더 높은 정확도를 기록.</li></ul><p>특히, 두 가지 흥미로운 관찰 결과를 도출:</p><ol><li>Hint-Aug 로 생성된 feature 는 부족한 tuning data 로 인한 문제를 보완하고, 더 엄격한 few-shot 설정에서 정확도를 향상시킬 수 있다.<ul><li>예로, Food 와 Pets dataset 에서 Adapter 와 LoRA 를 tuning 할 때 8-shot tuning 의 정확도를 2.45% ~ 4.96% 향상시키며, 12-shot tuning 에서 NPS 보다 0.73% ~ 2.22% 더 높은 정확도를 기록.</li></ul></li><li>Hint-Aug 의 pre-trained FViT 에서 추출한 features 를 tuning data 로 주입하는 능력은 extreme few-shot scenarios (e.g., 1-shot tuning)에서 정확도를 상당히 향상시킬 수 있다.<ul><li>예로, Pets dataset 에서 Hint-Aug 을 사용하여 VPT 를 1-shot setting 으로 tuning 하면 NPS 보다 32.91% 높은 정확도를 달성했다.</li></ul></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="43-ablation-studies">4.3. Ablation Studies<a href="#43-ablation-studies" class="hash-link" aria-label="Direct link to 4.3. Ablation Studies" title="Direct link to 4.3. Ablation Studies">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="431-accuracy-improvement-breakdown">4.3.1 Accuracy Improvement Breakdown<a href="#431-accuracy-improvement-breakdown" class="hash-link" aria-label="Direct link to 4.3.1 Accuracy Improvement Breakdown" title="Direct link to 4.3.1 Accuracy Improvement Breakdown">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="setup">Setup.<a href="#setup" class="hash-link" aria-label="Direct link to Setup." title="Direct link to Setup.">​</a></h4><p>Hint-Aug 의 각 구성 요소인 AOD 와 CFI 가 최종 정확도에 기여하는 정도를 이해하기 위해, 저자는 Adapter 를 사용하여 Food, Pets, Cars dataset 에서 8-shot tuning 을 수행하는 ablation study 를 진행한다.</p><p>이 실험은 다음과 같이 구성된다:</p><ol><li>AOD 만 사용하는 경우, mixup 에서 제안된 data augmentation 방법을 사용하여 선택된 patch 를 augment.</li><li>CFI 만 사용하는 경우, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">L</mi><mtext>tar</mtext></msub></mrow><annotation encoding="application/x-tex">\mathcal{L}_\text{tar}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">tar</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> loss 를 사용하여 sample 을 생성하고, 각 image 에서 무작위로 patch 를 선택하여 augment.</li></ol><h4 class="anchor anchorWithStickyNavbar_LWe7" id="observations">Observations.<a href="#observations" class="hash-link" aria-label="Direct link to Observations." title="Direct link to Observations.">​</a></h4><p><img loading="lazy" alt="Table 1" src="/assets/images/image-173-e9c30cca06947d975fe290ba0e81f259.png" width="817" height="314" class="img_ev3q"></p><p>Tab. 1 에 나타난 바와 같이, selected patch 를 augment 할 때 다음과 같은 결과를 관찰할 수 있다:</p><ol><li>AOD 또는 CFI 중 하나만 사용해도, 각각 1.04% ~ 2.28% 및 2.10% ~ 4.27% 의 정확도 향상이 이루어진다 (baselines: AOD 와 CFI 모두 비활성화).<ul><li>이는 두 가지 주요 문제 (i.e., over-fitting 문제와 feature diversity lack)가 실제로 few-shot tuning 의 정확도에 악영향을 미치며, 제안된 두 가지 방법이 효과적으로 이러한 문제를 완화할 수 있음을 나타낸다.</li></ul></li><li>AOD 와 CFI 를 모두 결합하면 두 방법의 장점을 모두 활용할 수 있어, 각각의 AOD 또는 CFI 만 활성화했을 때보다 0.35% ~ 2.63% 더 높은 정확도를 달성할 수 있다.</li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="432-ablation-on-adversarial-objectives">4.3.2 Ablation on Adversarial Objectives<a href="#432-ablation-on-adversarial-objectives" class="hash-link" aria-label="Direct link to 4.3.2 Ablation on Adversarial Objectives" title="Direct link to 4.3.2 Ablation on Adversarial Objectives">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="setup-1">Setup.<a href="#setup-1" class="hash-link" aria-label="Direct link to Setup." title="Direct link to Setup.">​</a></h4><p>저자는 feature infusion 을 위해 adversarial sample 을 생성할 때 사용되는 loss function 의 선택을 검증하기 위해 ablation study 를 진행한다.</p><p>앞서 설명한 바와 같이, 서로 다른 loss function 이 tuning 정확도에 미치는 영향이 다를 수 있으며, 부적절한 loss function 는 clean accuracy 에 악영향을 미칠 수 있다.</p><p>Tab. 2 에서는 </p><ul><li>Food dataset 에서 Adapter 를 사용하여 tuning 할 때 &quot;Full&quot; 은 whole image 로 adversarial sample 을 생성하는 방법을 의미하며, </li><li>&quot;Untarget&quot; 은 correct class 의 model output logits 을 줄이는 conventional attack target 을 사용하여 선택된 patch 를 augmenting 하는 방법을 의미한다.</li><li>&quot;Random&quot; 은 무작위로 선택된 class 쪽의 augmented image 의 output 으로 오도하도록 선택된 patch 를 augmenting 하는 방법을 의미한다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="observations-1">Observations.<a href="#observations-1" class="hash-link" aria-label="Direct link to Observations." title="Direct link to Observations.">​</a></h4><p><img loading="lazy" alt="Table 2" src="/assets/images/image-174-69cab7def9ef33db84187f7fdc507fe3.png" width="678" height="230" class="img_ev3q"></p><p>Tab. 2 에 나타난 바와 같이,</p><ul><li>&quot;Full&quot; 방법은 가장 낮은 정확도(0.80% ~ 1.72% 낮음)를 기록하며, &quot;Untarget&quot; 방법이 두 번째로 낮은 정확도를 기록한다.</li><li>&quot;Untarget&quot; 은 또한 제안된 방법에 비해 3.32% ~ 5.71% 낮은 정확도를 기록한다.</li><li>이러한 두 가지 관찰 결과는 <ol><li>whole image attacking 이 FViT tuning 에 효과적이지 않으며, </li><li>&quot;Untarget&quot; attack 을 단순히 사용하는 것은 out-of-manifold data 로 이어질 수 있음을 시사한다.</li></ol></li><li>또한, &quot;Random&quot; 방법이 &quot;Untarget&quot; 보다 1.78% ~ 3.14% 높은 정확도를 기록한 것은, other classes 에서 특징을 추가하는 간단한 방법이 tuning 에 도움이 될 수 있음을 나타낸다.</li><li>그러나 &quot;Random&quot; adversarial objective 는 more precise augmentation direction 의 부족으로 인해 정확도 향상이 제한되며, Hint-Aug 에서 사용된 adversarial objectives 보다 1.05% ~ 2.57% 낮은 정확도를 기록한다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="433-sensitivity-to-augmentation-intensity">4.3.3 Sensitivity to Augmentation Intensity<a href="#433-sensitivity-to-augmentation-intensity" class="hash-link" aria-label="Direct link to 4.3.3 Sensitivity to Augmentation Intensity" title="Direct link to 4.3.3 Sensitivity to Augmentation Intensity">​</a></h2><p>최근 연구에 따르면, augmentation intensity 는 FViT tuning 에서 중요한 요소다.</p><p>따라서 저자는 adversarial attack radius <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ϵ</span></span></span></span></span> 이 Hint-Aug 의 정확도에 미치는 영향을 조사한다.</p><p>Adapter 를 사용하여 Food dataset 에서 8-shot setting 으로 tuning 할 때, Hint-Aug 은 adversarial radius 가 급격히 변화해도 비교적 안정된 정확도를 달성한다.</p><p>구체적으로, Tab. 3 에 나타난 바와 같이,</p><p><img loading="lazy" alt="Table 3" src="/assets/images/image-175-322ed816cbbe8b6f4118ab4449498683.png" width="920" height="243" class="img_ev3q"></p><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ϵ</span></span></span></span></span> 을 5배 증가시키거나 감소시켜도 정확도 변화는 0.03% ~ 0.21% 에 불과하며, </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ϵ</span></span></span></span></span> 을 10배 변화시키면 0.89% ~ 1.03% 의 정확도 변화가 발생한다.</li><li>이는 Hint-Aug 이 hyper-parameter 선택에 대해 강인함을 입증한다.</li><li>주목할 만한 점은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ϵ</span></span></span></span></span> 을 10배 변화시키는 것이 non-trivial change 라는 것이다</li><li>[Patch-fool]<!-- --> 의 연구에 따르면, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ϵ</span></span></span></span></span> 을 8배 변화시키는 것만으로도 ImageNet 에서 DeiT-Tiny 에 대해 27.94% 이상의 정확도 변화가 발생한다.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="434-number-of-patches-to-augment">4.3.4 Number of Patches to Augment<a href="#434-number-of-patches-to-augment" class="hash-link" aria-label="Direct link to 4.3.4 Number of Patches to Augment" title="Direct link to 4.3.4 Number of Patches to Augment">​</a></h3><p>Hint-Aug 이 달성한 accuracy-data efficiency trade-off 에 영감을 받아, 각 image 에서 하나 이상의 patch 를 augmenting 하면 accuracy-efficient trade-off 를 더욱 개선할 수 있는지에 대한 흥미로운 질문이 제기된다.</p><p>이 질문에 답하기 위해, 저자는 Hint-Aug 을 사용하여 다양한 수의 augmented patches 를 실험하고, 8-shot VPT 로 tuning 할 때의 평균 정확도를 보고한다.</p><p><img loading="lazy" alt="Table 4" src="/assets/images/image-176-37f10955fc7b02f6a9ab8cc715da8c45.png" width="922" height="191" class="img_ev3q"></p><ul><li>주목할 점은, all patches 를 증강하는 것 (Tab. 4 의 “All” column)은 patch information 을 고려하지 않고 whole image 를 augmenting 하는 것과 동등하다는 것이다.</li><li>실험 결과, 각 image 에서 1 ~ 3 patches 를 augmenting 한 경우 평균 정확도가 비슷하게 유지되며 (정확도 변화는 0.1% 미만), 그러나 8 patches 를 augmenting 한 경우 평균 정확도가 0.34% ~ 1.70% 감소한다.</li><li>이는 각 image 에서 over-fitting 되기 쉬운 patch 가 일부에 불과하다는 것을 고려할 때, 너무 많은 patches 를 augmenting 하면 오히려 attention-score map 이 손상되어 정확도가 감소할 수 있다고 추측된다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="44-visualization-of-attention-score-maps">4.4. Visualization of Attention Score Maps<a href="#44-visualization-of-attention-score-maps" class="hash-link" aria-label="Direct link to 4.4. Visualization of Attention Score Maps" title="Direct link to 4.4. Visualization of Attention Score Maps">​</a></h2><p><img loading="lazy" alt="Figure 5" src="/assets/images/image-178-a75e21128fbd68075b5825990a0afa81.png" width="955" height="653" class="img_ev3q"></p><p>Hint-Aug 의 over-fitting 문제 완화 효과를 검증하기 위해, 저자는 pre-trained FViT, FViT tuned by NPS, 그리고 FViT tuned by Hint-Aug 의 attention-score map 을 시각화한다.</p><p>Fig. 5 에서 볼 수 있듯이, </p><ol><li>Hint-Aug 으로 tuning 한 후, NPS 로 tuning 된 attention-score map 에서 일반적으로 관찰되는 over-fitting 된 patch(red)가 성공적으로 제거되었으며</li><li>Hint-Aug 에서 얻은 attention-score map 이 pre-trained FViT 에서 얻은 high-attention score patch 의 localtion 과 유사한 위치를 나타내며, 이는 Hint-Aug 이 효과적으로 over-fitting 문제를 완화했음을 나타낸다.</li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="45-visualization-of-the-confusion-matrix">4.5. Visualization of the Confusion Matrix<a href="#45-visualization-of-the-confusion-matrix" class="hash-link" aria-label="Direct link to 4.5. Visualization of the Confusion Matrix" title="Direct link to 4.5. Visualization of the Confusion Matrix">​</a></h2><p><img loading="lazy" alt="Table 5" src="/assets/images/image-177-4f783cd330b06d073a6dcf96d2e9ffaa.png" width="439" height="382" class="img_ev3q"></p><p>발견된 class-wise similarity 를 이해하기 위해, Pets dataset 에서 4-shot Adapter tuning setting 을 사용하여 confusion matrix 시각화한다.</p><p>저자는 Cats 및 Dogs meta-groups 의 confusion matrix value 를 평균 계산하고 Tab. 5 에 시각화한다.</p><ul><li>FViT 가 Cat 과 Dog meta-groups 간의 구별보다는 Cat 또는 Dog meta-group 내에서 서로 다른 classes 를 구별하는 데 훨씬 더 혼동되는 것을 관찰한다.</li><li>이는 pre-softmax output 만을 사용하는 저자의 전략이 간단함에도 불구하고, 생성된 confusion matrix 이 혼동하기 쉬운 class paris 를 효과적으로 식별할 수 있으며, 따라서 CFI 에 올바른 방향을 제시할 수 있음을 시사한다.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="5-결론">5. 결론<a href="#5-결론" class="hash-link" aria-label="Direct link to 5. 결론" title="Direct link to 5. 결론">​</a></h3><p>이 논문에서는 FViT 의 few-shot parameter-efficient tuning 정확도를 향상시키기 위해 Hint-Aug 이라는 framework 를 제안한다.</p><p>구체적으로, Hint-Aug 은 AOD 와 CFI 라는 두 가지 주요 구성 요소를 특징으로 하며, 각각 over-fitting 문제와 data diversity  부족 문제를 완화하는 데 중점을 둔다.</p><p>광범위한 실험과 ablation study 를 통해 Hint-Aug 이 SOTA data augmentation 방법에 비해 0.04% ~ 32.91% 높은 정확도를 달성하며, pre-trained FViT 를 실제 low-data 환경에서 보다 효과적으로 tuning 할 수 있는 새로운 관점을 열어준다.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/hint-aug">HintAug</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/visual-prompt">Visual Prompt</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/peft">PEFT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/pixel-level">Pixel-Level</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/data-augmentation">Data Augmentation</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/hint">Hint</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2023-04-HintAug.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/EVP-L"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Explicit Visual Prompting for Low-Level Structure Segmentations</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/AutoVP"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">AutoVP: An Automated Visual Prompting Framework and Benchmark</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#21-fvits" class="table-of-contents__link toc-highlight">2.1. FViTs</a></li><li><a href="#22-parameter-efficient-tuning" class="table-of-contents__link toc-highlight">2.2. Parameter-efficient Tuning</a></li><li><a href="#23-few-shot-tuning" class="table-of-contents__link toc-highlight">2.3. Few-shot Tuning</a></li><li><a href="#24-data-augmentation" class="table-of-contents__link toc-highlight">2.4. Data Augmentation</a></li><li><a href="#31-hint-aug-motivation" class="table-of-contents__link toc-highlight">3.1. Hint-Aug: Motivation</a></li><li><a href="#32-hint-aug-overview" class="table-of-contents__link toc-highlight">3.2. Hint-Aug: Overview</a></li><li><a href="#33-enabler-1-attentive-over-fitting-detector" class="table-of-contents__link toc-highlight">3.3. Enabler 1: Attentive Over-fitting Detector</a></li><li><a href="#34-enabler-2-confusion-based-feature-infusion" class="table-of-contents__link toc-highlight">3.4. Enabler 2: Confusion-based Feature Infusion</a></li><li><a href="#41-experimental-setup" class="table-of-contents__link toc-highlight">4.1. Experimental Setup</a></li><li><a href="#42-benchmark-on-few-shot-image-classification" class="table-of-contents__link toc-highlight">4.2. Benchmark on Few-Shot Image Classification</a></li><li><a href="#43-ablation-studies" class="table-of-contents__link toc-highlight">4.3. Ablation Studies</a><ul><li><a href="#431-accuracy-improvement-breakdown" class="table-of-contents__link toc-highlight">4.3.1 Accuracy Improvement Breakdown</a></li><li><a href="#432-ablation-on-adversarial-objectives" class="table-of-contents__link toc-highlight">4.3.2 Ablation on Adversarial Objectives</a></li></ul></li><li><a href="#433-sensitivity-to-augmentation-intensity" class="table-of-contents__link toc-highlight">4.3.3 Sensitivity to Augmentation Intensity</a><ul><li><a href="#434-number-of-patches-to-augment" class="table-of-contents__link toc-highlight">4.3.4 Number of Patches to Augment</a></li></ul></li><li><a href="#44-visualization-of-attention-score-maps" class="table-of-contents__link toc-highlight">4.4. Visualization of Attention Score Maps</a></li><li><a href="#45-visualization-of-the-confusion-matrix" class="table-of-contents__link toc-highlight">4.5. Visualization of the Confusion Matrix</a><ul><li><a href="#5-결론" class="table-of-contents__link toc-highlight">5. 결론</a></li></ul></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.78cc6745.js"></script>
<script src="/assets/js/main.50337039.js"></script>
</body>
</html>