<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/Vision-Language/PEFT/Prompting/Textual-Token/2022-03-CoCoOp">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Conditional Prompt Learning for Vision-Language Models | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/CoCoOp"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Conditional Prompt Learning for Vision-Language Models | My Site"><meta data-rh="true" name="description" content="논문 및 이미지 출처 :"><meta data-rh="true" property="og:description" content="논문 및 이미지 출처 :"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/CoCoOp"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/CoCoOp" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/CoCoOp" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="My Site RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="My Site Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.d2ad26d0.css">
<link rel="preload" href="/assets/js/runtime~main.ed721529.js" as="script">
<link rel="preload" href="/assets/js/main.d22fbe67.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Vision-Language/UPL">Vision-Language</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/UPL">Unsupervised Prompt Learning for Vision-Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/Img2LLM">From Images to Textual Prompts: Zero-shot Visual Question Answering with Frozen Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/Prismer">Prismer: A Vision-Language Model with An Esemble of Experts</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/Contrastive Learning/ALIGN">Contrastive Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Composition/CLIP-LoRA">PEFT</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Composition/CLIP-LoRA">Composition</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Module/CLIP-Adapter">Module</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Multi-Modality/MaPLe">Multi-Modality</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Prompting/Pixel-Level/CMAR">Prompting</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Prompting/Pixel-Level/CMAR">Pixel-Level</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/CoOp">Textual-Token</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/CoOp">Learning to Prompt for Vision-Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/CoCoOp">Conditional Prompt Learning for Vision-Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/ProGrad">Prompt-aligned Gradient for Prompt Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/PLOT">PLOT: Prompt Learning with Optimal Transport for Vision-Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/KgCoOp">Visual-Language Prompt Tuning with Knowledge-guided Context Optimization</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/PEFT/Prompting/Visual-Token/VPT">Visual-Token</a></div></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/Single-Stream/VLBERT">Single-Stream</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/Two-Stream/LXMERT">Two-Stream</a></div></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Vision-Language</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">PEFT</span><meta itemprop="position" content="3"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Prompting</span><meta itemprop="position" content="4"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Textual-Token</span><meta itemprop="position" content="5"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Conditional Prompt Learning for Vision-Language Models</span><meta itemprop="position" content="6"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Conditional Prompt Learning for Vision-Language Models</h1></header><p>논문 및 이미지 출처 : <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Conditional_Prompt_Learning_for_Vision-Language_Models_CVPR_2022_paper.pdf" target="_blank" rel="noopener noreferrer">https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Conditional_Prompt_Learning_for_Vision-Language_Models_CVPR_2022_paper.pdf</a></p><h1>Abstract</h1><p>strong pre-trained vision-language model 인 CLIP 의 부상으로 이런 모델을 downstream dataset 에 적용하는 방법을 조사하는 것이 필수적이다.</p><p>최근 제안된 Context Optimization (CoOp) 은 NLP 의 prompt learning 을 vision domain 에 도입하여 pre-trained vision-language model 을 적용한다.</p><p>구체적으로 CoOp 는 prompt 의 context words 를 learnable vectors set 으로 바꾸며, learning 을 위한 few labeled images 만으로도  intensively-tuned manual prompt 보다 엄청난 향상을 이룰 수 있다.</p><p>저자는 CoOp 의 중요한 문제를 식별했다: learned context 가 같은 dataset 내에서 unseen classes 에 generalization 되지 않는다는 것으로, CoOp 이 training 중에 observed base classes base classes 에 over-fitting 되었음을 시사한다.</p><p>이 문제를 해결하기 위해, Conditional Context Optimization (CoCoOp)을 제안하며, 이는 CoOp 를 확장하여 각 image 에 대한 input-conditioned token (vector)을 생성하는  lightweight neural network 을 추가로 학습한다.</p><p>CoOp 의 static prompts 와 비교하여, dynamic prompts 는 각 instance 에 적응하여 class shift 에 덜 민감하다.</p><p>광범위한 실험은 CoCoOp 가 unseen classes 에 대해 CoOp 보다 훨씬 더 generalization 되며, 심지어 single dataset 을 넘어선 transferable 을 보여주고, stronger domain generalization 성능을 발휘한다는 것을 보여준다.</p><h1>1. Introduction</h1><p>large-scale vision-language pre-training 에 대한 최근 연구는 zero-shot image recognition 에서 놀라운 성능을 보여주며, 이 패러다임의 open-world  visual concepts learning 에 잠재력을 보여준다.</p><p>핵심 설계는 visual concepts 을 어떻게 modeling 하는지에 있다. label 이 discreted supervised learning 에선 각 categories 가 같은 category 를 포함하는 image 와의 distance 를 minimizing 하기 위해 학습되는 random initialized weight vectors 와 연관된다.</p><p>이러한 학습 방법은 closed-set visual concepts 에 초점을 맞추어, training 중 new unseen categories 에 대해 모델을 pre-defined categories list 에서 제한하며 확장성을 제한한다.</p><p>반대로, CLIP 과 ALIGN  같은 vision-language model 은 parameterized text encoder (e.g., Transformer)가 prompting 을 통해 classification weights 를 생성한다.</p><ul><li>예로, 다양한 품종의 개와 고양이를 포함하는 pet images 를 구별하기 위해 “ “a photo of a {class}, a type of p” 같은 prompt template 을 text encoder 에 입력으로 채택할 수 있다.</li><li>그 결과 “{class}” token 을 real class name 으로 채워 분류를 위한 class-specific weights 를 합성할 수 있다.</li><li>discrete label 과 비교할 때, vision-language model 의 supervision sources 는 nautral language 에서 나와, open-set visual concepts 을 넓게 탐구할 수 있으며, transferable representation learning 에 효과적임이 입증되었다.</li></ul><p>이러한 strong vision-language model 의 부상으로, 최근 커뮤니티는 이 모델을 downstream dataset 에 효율적으로 적용하는 잠재적 솔루션을 조사하기 시작했다.</p><p>web-scale data 를 맞추기 위해, CLIP 이 사용하는 4M pairs images 와 texts 처럼, vision-language model 은 높은 용량을 갖도록 고안되었고, 이는 모델 크기가 M ~ B parameters 로 매우 클 것이다. 따라서, 흔히 채택되는 entire model fine-tuning 은 실용적이지 않고, 심지어 well-learned representation space 를 손상시킬 수도 있다.</p><hr><p>안전한 approach 은 pet dataset 을 위해 언급된 “a type of pet” 과 같은 task 에 의미 있는 약간의 context 를 추가하여 prompt 를 tuning 하는 것으로, 이는 성능 향상에 효과적임이 밝혀졌다.</p><ul><li>prompt engineering 은 시도와 오류에 기반해야 하므로 time-consuming 이 크고 비효율적이며 optimal prompts 를 보장하지도 않는다.</li><li>prompt engineering 을 자동화하기 위해, CoOp 은 pre-trained vision-language model 을 적용하기 위해 prompt learning 을 탐구했다.</li><li>Context Optimization (CoOp)은 prompt 의 context words 를 learnable vector set 으로 변환하며, neural network 의 differentiable nature 를 활용한다.</li><li>학습을 위한 few labeled images 만으로, CoOp 는 광범위한 image recognition datasets 에서 intensively-tuned manual prompts 보다 엄청난 개선을 이룬다.</li></ul><p>저자는 CoOp 의 중요한 문제를 식별했다: learned context 가 같은 task 내에서 unseen classes 에 generalization 되지 않는다는 것이다.</p><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-12-7997a576794a8c2b8cb2a11fb4708bfe.png" width="1826" height="758" class="img_ev3q"></p><p>Fig. 1 은 이 문제를 보여준다:</p><ul><li>CoOp 가 학습한 context 는 “arrival gate” 와 “cathedral” 같은 base classes 를 구별하는 데는 잘 작동하지만, new (unseen) classes 인 “wind farm” 과 “train railway” 로 transfer 될 때는 정확도가 크게 떨어진다 — task 의 특성이 여전히 같음에도 불구하고, i.e., scenes recognition</li><li>결과는 learned context 가 base classes 에 over-fitting 되었음을 시사하며, broader scene recognition 을 위해 중요한 more generalizable elements 를 포착하는 데 실패한다.</li></ul><p>이러한 문제가 CoOp 의 static design 으로 인해 발생한다고 주장한다:</p><ul><li>context 는 일단 학습되면 고정되어 specific (training) classes set 에 대해서만 optimizing 된다.</li><li>반대로, zero-shot 방법에 채택된 hand-crafted prompt 는 상대적으로 generalization 가능하다.</li></ul><p>generalizability 문제를 해결하기 위해, 새로운 개념인 <em>conditional prompt learning</em> 을 소개한다.</p><ul><li>핵심 아이디어는 prompt 가 학습되면 고정하는 대신, 각 input instance (image)에 따른 conditioned prompt 를 만드는 것이다.</li><li>model 을 parameter-efficient 로 만들기 위해, conditional prompt learning 의 간단하지만 효과적인 구현을 도입한다.<ul><li>구체적으로, CoOp 를 확장하여 각 image 에 대해 input-conditioned token (vector) 을 생성하는 lightweight neural network 을 추가로 학습한다.</li><li>이를 Conditional Context Optimization (CoCoOp)이라 부른다. (Fig. 2) </li><li>흥미롭게도, CoCoOp 의 패러다임은 image captioning 과 유사하여 instance conditional prompts 가 더욱 generalization 이 가능한 이유를 설명한다: 이는 specific classes 에만 서비스를 제공하는 것이 아니라 각 instance 를 characterizing 하도록 optimizing 한다 (class shift 에 더 강력).</li></ul></li></ul><p>다양한 visual recognition tasks 를 다루는 11 datasets 에 대한 종합적인 실험을 제시한다.</p><ul><li>구체적으로, model 이 먼저 base classes 를 사용하여 학습되고 completely new classes 로 테스트되는 base-to-new generalization 설정을 설계했다.</li><li>zero-shot 방법 및 CoOp 과 비교할 때, 저자의 approach 은 최고의 전체 성능을 달성한다 (Tab. 1).</li><li>중요한 것은, CoCoOp 가 CoOp 보다 unseen classes 에서 상당한 개선을 얻어 manual 및 learning-based prompts 간의 격차를 크게 줄일 수 있다는 것이다 (Fig. 3(a)).</li></ul><p>context 가 drastically different classes 를 가진 other tasks 로의 directly transfer 돠는 더 어려운 시나리오에서도, CoCoOp 는 여전히 CoOp 를 명확한 차이로 능가하며 (Tab. 2), instance-conditional prompts 가 more transferable 하고 larger scale 에서 성공할 잠재력이 있음을 시사한다.</p><p>CoCoOp 는 CoOp 보다 stronger domain generalization 성능도 획득하여 (Tab. 3), dynamic prompts 의 강점을 더욱 정당화한다.</p><p>요약하면, </p><ul><li>prompt learning 의 generalization 가능성 문제에 대한 적절한 통찰력을 제공하며, 다양한 문제 시나리오에서 간단한 아이디어의 효과를 입증한다.</li><li>이 연구에서 제시된 발견이 generalizable-transferable-prompt learning 의 길을 열어준다</li></ul><h1>2. Related Work</h1><h4 class="anchor anchorWithStickyNavbar_LWe7" id="vision-language-models">Vision-Language Models<a href="#vision-language-models" class="hash-link" aria-label="Direct link to Vision-Language Models" title="Direct link to Vision-Language Models">​</a></h4><p>저자는 주로 image 를 text 와 align 하여 joint embedding space 를 학습하는 데 초점을 맞춘 연구를 검토한다.</p><p>cross-modality alignment 의 아이디어는 새로운 것이 아니며, 오래 연구되어 왔지만 오늘날과는 매우 다른 기술이 사용되었다.</p><p>일반적인 vision-language model 은 세 가지 주요 요소로 구성된다: image 및 text encoding 와 이의 loss function</p><p>초기엔 images 와 texts 를 처리하는 model 이 종종 독립적으로 설계되고 학습되었으며, 그들의 output 은 align 하기 위한 extra modules (loss)로 연결되었다.</p><p>이미지는 종종 hand-crafted descriptor 또는 neural network 을 사용하여 encoding 되며, text 는 pre-trained word vectors 나 frequency-based  TF-IDF features 등을 사용하여 encoding 된다.</p><p>cross-modality alignments 의 일반적인 approach 로는 metric learning, multi-label classification, n-gram language learning 등이 있다.</p><p>최근 연구에 따르면, image captioning loss 로 vision 부분을 학습하면 visual representation 이 more trasferable 해진다.</p><hr><p>최근 vision-language model 은 two encoders 를 함께 학습하여 two modalities 를 연결한다. 또한, 모델은 이제 훨씬 더 큰 neural network 으로 구축된다.</p><p>CoOp 에서 논의한 바인, 최근 vision-language model 의 성공은 주로 i) Transformers ii) contrastive representation learning iii) web-scale training datasets 의 발전에 기인한다.</p><p>대표적인 approach 은 CLIP 으로, contrastive loss 를 사용하여 image 와 text pairs 을 matching 하기 위해 two neural networks based encoders 를 훈련한다.</p><p>4M data pairs 를 처리한 후, CLIP 모델은 놀라운 zero-shot image recognition 능력을 보여준다.</p><p>CoOp 과 유사하게, 저자의 approach 은 CLIP 과 유사한 모델 연구와 직교하며, pre-trained vision-language model 을 downstream application 에 적용하기 위한 효율적인 솔루션을 제공하는 것을 목표로 한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-learning">Prompt Learning<a href="#prompt-learning" class="hash-link" aria-label="Direct link to Prompt Learning" title="Direct link to Prompt Learning">​</a></h4><p>prompt learning 은 NLP domain 에서 유래한 주제이다.</p><p>pre-trained language model 을 downstream tasks 에 유용한 정보를 끌어내는 knowledge base 로 보는 것이었다.</p><p>구체적으로, pre-trained language model 이 주어진 경우, 종종 &quot;fill-in-the-blank&quot; cloze test 로 공식화되며, 예로 “No reason to watch. It was <!-- -->[MASK]<!-- -->” 에서 masked token 을 &quot;positive&quot; 또는 &quot;negative&quot; 로 예측하도록 모델에게 요청한다.</p><p>hand-crafted prompt 를 설계하는 대신, prompt learning 에 대한 연구는 affordable-sized labeled data 를 활용하여 이 과정을 자동화하는 것을 목표로 한다.</p><ul><li>Jiang et al 은 text mining 과 paraphrasing 를 사용하여 candidate prompt groups 를 생성하고, highest training accuracy 를 가진 optimal prompt 를 선택</li><li>Shin et al 은 AutoPrompt 를 제안했는데, 이는 label likelihood 에 기반하여 gradient 에서 greateest changes 인 optimal tokens 를 vocabulary 에서 선택하는 gradient-based approach </li><li>저자의 연구는 주로 continuous prompt learning 과 관련이 있으며, 여기서 주된 아이디어는 prompt 를 continuous vector set 으로 변환하여 objective function 에 대해 end-to-end 로 optimizing 하는 것이다.</li></ul><p>CV 에서 prompt learning 은 최근에야 탐구된 초기 연구 방향이다.</p><p>저자의 연구는 pre-trained vision-language model 의 adapting 을 위해 continuous prompt learning 을 vision domain 에 도입한 최초의 연구인 CoOp 을 기반으로 한다.</p><p>결정적으로, 저자의 approach 은 CoOp 의 weak generalization 문제를 해결하며, conditional prompt learning 이라는 간단한 아이디어에 기반하고 있다 — 이는 NLP context 에서도 새로운 것으로, NLP 커뮤니티에도 관심을 가질 수 있다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="zero-shot-learning-zsl">Zero-Shot Learning (ZSL)<a href="#zero-shot-learning-zsl" class="hash-link" aria-label="Direct link to Zero-Shot Learning (ZSL)" title="Direct link to Zero-Shot Learning (ZSL)">​</a></h4><p>Zero-Shot Learning (ZSL) 은 저자의 목표와 유사한 또 다른 관련 연구 영역이다.</p><p>즉, base classes 에만 훈련하여 novel classes 를 recognition하는 것이다. 또한, base classes 에서 훈련된 모델이 novel classes 에서 자주 실패하는 generalization 문제는 ZSL 문헌에서 제기된 &quot;seen-class bias&quot; 와 관련이 있다.</p><p>ZSL 에 가장 일반적인 approach 은 attributes 또는 word embeddings 같은 auxiliary information 을 기반으로 semantic space 을 학습하는 것이다.</p><p>기존 ZSL 방법과 달리, 저자의 연구는 large-scale vision-language model 의 adapting 이란 새롭게 부상하는 문제를 다루고 있으며, prompt 를 기반으로한 drastically different 기술을 사용한다.</p><h1>3. Methodology</h1><p><img loading="lazy" alt="Figure 2" src="/assets/images/image-13-2ec414b08cc57030cb3dd8995ee3e23f.png" width="1004" height="703" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="31-reviews-of-clip-and-coop">3.1. Reviews of CLIP and CoOp<a href="#31-reviews-of-clip-and-coop" class="hash-link" aria-label="Direct link to 3.1. Reviews of CLIP and CoOp" title="Direct link to 3.1. Reviews of CLIP and CoOp">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="contrastive-language-image-pre-training">Contrastive Language-Image Pre-training<a href="#contrastive-language-image-pre-training" class="hash-link" aria-label="Direct link to Contrastive Language-Image Pre-training" title="Direct link to Contrastive Language-Image Pre-training">​</a></h4><p>CLIP 은 open-set visual concepts learning 의 잠재력을 잘 보여주었다.</p><p>CLIP 는 Fig. 2에 보여진 대로 image 와 text 를 위한 two encoders 를 사용하여 구축된다.</p><ul><li>image encoder 는 ResNet 또는 ViT 가 될 수 있으며, image 를 feature vector 로 변환한다.</li><li>text encoder 는 Transformer 로, word tokens 의 sequence 를 입력으로 받아 다시 vectorized representation 을 생성한다.</li></ul><p>training 동안 CLIP 는 contrastive loss 을 사용하여 two modalities 를 위한 joint embedding space 을 학습한다.</p><p>구체적으로,</p><ul><li>image-text pair 의 minibatch 에 대해, CLIP 은 각 image 와 matched text 간의 cosine similarity 를 maximization 하는 한편, all other unmatched text 와의 cosine similarity 를 minimizing 하며, loss 는 각 text 에 대해서도 유사하게 계산된다.</li><li>training 후, CLIP 는 zero-shot image recognition 에 사용할 수 있다.</li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span></span> 를 image encoder 가 생성한 image features 로, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>w</mi><mi>i</mi></msub><msubsup><mo stretchy="false">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup></mrow><annotation encoding="application/x-tex">\{w_i\}_{i=1}^K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1em;vertical-align:-0.2587em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span></span></span></span></span> 를 text encoder 가 생성한 weight vectors (총 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span></span></span></span></span> categories 가 있다 가정)로 두면, 각각의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">w_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 “a photo of a {class}” 같은 prompt 로부터 파생된다.<ul><li>“{class}” token 은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span></span>-th class name 으로 채워진다.</li></ul></li><li>prediction probability 는 다음과 같다:</li></ul><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mtext>sim</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>w</mi><mi>y</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>τ</mi><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mtext>sim</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>τ</mi><mo stretchy="false">)</mo></mrow></mfrac><mo separator="true">,</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} p(y|x) = \frac{\exp(\text{sim}(x, w_y)/\tau)}{\sum_{i=1}^K \exp(\text{sim}(x, w_i)/\tau)}, \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.5979em;vertical-align:-1.049em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.549em"><span style="top:-3.549em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.1288em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord text"><span class="mord">sim</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord text"><span class="mord">sim</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1709em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.049em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.549em"><span style="top:-3.549em"><span class="pstrut" style="height:3.427em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.049em"><span></span></span></span></span></span></span></span></span></div><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>sim</mtext><mo stretchy="false">(</mo><mo>⋅</mo><mo separator="true">,</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{sim}(\cdot, \cdot)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">sim</span></span><span class="mopen">(</span><span class="mord">⋅</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span> : cosine similarity</li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span></span></span></span></span> : learned temperature parameter</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="context-optimization-coop">Context Optimization (CoOp)<a href="#context-optimization-coop" class="hash-link" aria-label="Direct link to Context Optimization (CoOp)" title="Direct link to Context Optimization (CoOp)">​</a></h4><p>CoOp 은 pre-trained vision-language model 을 downstream application 에 더 잘 적응시키기 위해 prompt engineering 의 inefficiency problem 을 극복하려는 목적을 가진다.</p><p>CoOp 의 핵심 아이디어는 각 context token 을 data 로부터 end-to-end 로 learnable continuous vectors 로 modeling 하는 것이다.</p><p>구체적으로,</p><ul><li>“a photo of a” 대신, CoOp 는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span></span> learnable context vectors <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>v</mi><mi>M</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{v_1, v_2, \ldots, v_M\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span> 를 도입하며, 각각은 word embeddings 과 same dimension 을 가진다.</li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span></span>-th class 에 대한 prompt <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 이제 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub><mo>=</mo><mo stretchy="false">{</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>v</mi><mi>M</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">t_i = \{v_1, v_2, \ldots, v_M, c_i\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span> 가 된다<ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> : class name 의 word embeddings</li><li>context vectors 는 all classes 간에 공유됨.</li></ul></li><li>text encoder <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(\cdot)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span>를 사용하면, prediction probability 은 다음과 같다:</li></ul><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mtext>sim</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>t</mi><mi>y</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>τ</mi><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mtext>sim</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>τ</mi><mo stretchy="false">)</mo></mrow></mfrac><mi mathvariant="normal">.</mi></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} p(y|x) = \frac{\exp(\text{sim}(x, g(t_y))/\tau)}{\sum_{i=1}^K \exp(\text{sim}(x, g(t_i))/\tau)}. \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.5979em;vertical-align:-1.049em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.549em"><span style="top:-3.549em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.1288em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord text"><span class="mord">sim</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord text"><span class="mord">sim</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1709em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.049em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.549em"><span style="top:-3.549em"><span class="pstrut" style="height:3.427em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.049em"><span></span></span></span></span></span></span></span></span></div><p>downstream image recognition dataset 에 CLIP 을 적용하기 위해, cross-entropy loss 를 learning objective 로 사용할 수 있다.</p><p>text encoder <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(\cdot)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span> 는 differentiable 하므로, gradient 는 context vectors 를 업데이트하기 위해 끝까지 전파될 수 있다.</p><p>CLIP 의 base model 은 entire training process 에서 고정되어 있다는 점에 유의해야 한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="32-cocoop-conditional-context-optimization">3.2. CoCoOp: Conditional Context Optimization<a href="#32-cocoop-conditional-context-optimization" class="hash-link" aria-label="Direct link to 3.2. CoCoOp: Conditional Context Optimization" title="Direct link to 3.2. CoCoOp: Conditional Context Optimization">​</a></h2><p>CoOp 는 downstream dataset 에서 few labeled images 만으로 context vectors 를 학습할 수 있는 data-efficient\ approach 다.</p><p>그러나 CoOp 는 동일한 작업 내에서 unseen classes 에 generalization 할 수 없다는 것이 논의되었다.</p><p>저자는 instance-conditional context 가 specific classes set 에 포커스를 벗어나 input instance 마다, 그리고 entire task 로 포커스를 옮기므로 더 잘 generalization 할 수 있다고 주장한다.</p><hr><p>CoCoOp 을 구현하는 간단한 방법은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span></span> neural network 을 구축하여 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span></span> context token 을 얻는 것이다.</p><p>그러나 이러한 설계는 CoOp 에서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span></span> context vectors 를 갖는 것보다 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span></span> X neural network 이 필요할 것이며, 이는 훨씬 큰 규모가 된다.</p><p>여기서 저자는 실질적으로 잘 작동하는 parameter-efficient 인 설계를 제안한다.</p><p>구체적으로,</p><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span></span> context vectors 외에도, 저자는 Meta-Net 이라는 lightweight neural network 을 학습하여 각 input 에 대한 conditional token (vector)을 생성하고, 이를 context vectors 와 결합한다. (Fig. 2)</li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span></span></span></span></span> 로 parameterizing 된 Meta-Net 을 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_\theta(\cdot)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span> 로 두면, 각 context token 은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>m</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>v</mi><mi>m</mi></msub><mo>+</mo><mi>π</mi></mrow><annotation encoding="application/x-tex">v_m(x) = v_m + \pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span></span></span></span></span> 로 얻어진다.<ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo>=</mo><msub><mi>h</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi = h_\theta(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>M</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">m \in \{1, 2, \ldots, M\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mclose">}</span></span></span></span></span></li></ul></li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span></span>-th class 에 대한 prompt 는 inputr 에 따라 조정되며, i.e., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><msub><mi>v</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>v</mi><mi>M</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>c</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">t_i(x) = \{v_1(x), v_2(x), \ldots, v_M(x), c_i\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span> 이다.</li><li>prediction probability 은 다음과 같이 계산된다:</li></ul><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mtext>sim</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>t</mi><mi>y</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>τ</mi><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mtext>sim</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>τ</mi><mo stretchy="false">)</mo></mrow></mfrac><mi mathvariant="normal">.</mi></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} p(y|x) = \frac{\exp(\text{sim}(x, g(t_y(x)))/\tau)}{\sum_{i=1}^K \exp(\text{sim}(x, g(t_i(x)))/\tau)}. \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.5979em;vertical-align:-1.049em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.549em"><span style="top:-3.549em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.1288em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord text"><span class="mord">sim</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)))</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord text"><span class="mord">sim</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)))</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1709em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.049em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.549em"><span style="top:-3.549em"><span class="pstrut" style="height:3.427em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.049em"><span></span></span></span></span></span></span></span></span></div><ul><li>training 중, 저자는 context vectors <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>v</mi><mi>m</mi></msub><msubsup><mo stretchy="false">}</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></msubsup></mrow><annotation encoding="application/x-tex">\{v_m\}_{m=1}^M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em"><span></span></span></span></span></span></span></span></span></span></span> 와 Meta-Net 의 parameters <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span></span></span></span></span> 를 함께 업데이트한다.</li><li>본 연구에서는 Meta-Net 을 two-layer bottleneck structure (Linear-ReLU-Linear) 로 구축하며, hidden layer 는 input dimension 의 16X 줄인다.</li><li>Meta-Net 의 input 은 image encoder 가 생성한 output feature</li></ul><h1>4. Experiments</h1><p>저자의 approach 은 주로 다음 세 가지 문제 설정에서 평가된다: 1) dataset 내의 base-to-novel classes 에 대한 generalization; 2) cross-dataset transfer; 3) domain generalization.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="datasets">Datasets<a href="#datasets" class="hash-link" aria-label="Direct link to Datasets" title="Direct link to Datasets">​</a></h4><ul><li>base-to-novel classes 에 대한 generalization 와 cross-dataset transfer 을 위한 two settings 는 CoOp 에서 사용된 11 image recognition datasets 사용.<ul><li>general objects classification 를 위한 ImageNet 과 Caltech101; fine-grained classification 를 위한 OxfordPets, StanfordCars, Flowers102, Food101, FGVCAircraft; scene recognition 을 위한 SUN397; action recognition 을 위한 UCF101; texture classification 을 위한 DTD; satellite image recognition 을 위한 EuroSAT 를 포함한다.</li></ul></li><li>domain generalization 실험에서는 ImageNet 을 source dataset 으로 사용하고, domain shift 가 다른 ImageNet 의 네 가지 variants 인 ImageNetV2, ImageNet-Sketch, ImageNet-A, ImageNet-R 를 target dataset 으로 사용한다.</li></ul><p>CoOp 을 따라 각 dataset 에서 few-shot training set 을 무작위로 추출하고, teset set 은 original test set 을 사용한다.</p><p>저자는 CoOp 에서 연구한 highest shot i.e., 16-shot 만 평가하며, 이는 저자의 approach 을 정당화하기에 충분하다.</p><p>learning-based model 의 경우, 3 runs 에서 평균한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="baselines">Baselines<a href="#baselines" class="hash-link" aria-label="Direct link to Baselines" title="Direct link to Baselines">​</a></h4><p>저자의 approach 과 직접적인 경쟁 상대는 CoOp 으로, 본질적으로 static prompts 를 학습한다(dynamic prompts 와 비교하여).</p><p>zero-shot 방식인 CLIP 도 비교 대상으로 사용되며, 이는 manual prompt 를 기반으로 한다.</p><p>각 dataset 에 대한 manual prompt 는 test data 의 all classes 를 사용하여 intensively tuning 되는 점을 언급한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="training-details">Training Details<a href="#training-details" class="hash-link" aria-label="Direct link to Training Details" title="Direct link to Training Details">​</a></h4><ul><li>구현은 CoOp 의 코드를 기반으로 한다.</li><li>실험 전반에 걸쳐, 저자는 CLIP 에서 ViT-B/16 을 사용한다.</li><li>CoOp 은 shorter context length 와 good initialization 이 더 나은 성능과 domain shift 에 대한 strong 내구성을 가져올 수 있다고 제안했다. 따라서 저자는 context length 4 로 고정하고, CoOp 와 CoCoOp 모두를 위해 “a photo of a” 의 pre-trained word embeddings 을 사용하여 context vectors 를 초기화한다.</li><li>instance-conditional 설계로 인해, 저자의 approach 은 training 이 느리고 CoOp 보다 훨씬 더 많은 GPU 메모리를 소비한다. 따라서 모델이 GPU 에 맞도록 하고 training time 을 줄이기 위해, 저자는 CoCoOp 를 batch size 1 로 10 epochs 동안 훈련한다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="41-generalization-from-base-to-new-classes">4.1. Generalization From Base to New Classes<a href="#41-generalization-from-base-to-new-classes" class="hash-link" aria-label="Direct link to 4.1. Generalization From Base to New Classes" title="Direct link to 4.1. Generalization From Base to New Classes">​</a></h2><p>CoOp 의 weak generalization 가능성 문제를 해결하는 것이 본 연구의 주요 초점이다.</p><ul><li>11 datasets 각각에서 class 를 two groups 로 균등하게 나누어, 하나는 base classes , 다른 하나는 novel classes 로 설정한다.</li><li>learning-based model, i.e., CoOp 와 CoCoOp 는 base classes 만을 사용하여 훈련하고, generalization 를 테스트하기 위해 base 와 novel classes 에서 각각 평가한다.</li></ul><p><img loading="lazy" alt="Table 1" src="/assets/images/image-14-906954bedf6fd7d2c8dae8d59195f52e.png" width="1318" height="908" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="failures-of-coop-in-unseen-classes">Failures of CoOp in Unseen Classes<a href="#failures-of-coop-in-unseen-classes" class="hash-link" aria-label="Direct link to Failures of CoOp in Unseen Classes" title="Direct link to Failures of CoOp in Unseen Classes">​</a></h4><p>이 split 은 two class groups 가 동일하게 어렵다는 것을 보장하지 못한다.</p><ul><li>CLIP 의 울퉁불퉁한 결과에서 알 수 있듯이, base 와 novel classes 의 정확도 수치는 극적으로 다르다.</li><li>CoOp 의 novel classes 정확도는 거의 모든 dataset 에서 base 정확도보다 일관되게 약하며, 평균적으로 거의 20% 의 큰 격차(82.69% 대 63.22%)를 남긴다. </li><li>CoOp 는 평균 성능 측면에서 CLIP 보다 우위를 유지하고 있지만, base classes 에서의 CoOp 의 이득은 novel classes 에서의 치명적인 실패로 거의 무효화된다.<ul><li>이는 learning-based prompt 의 generalization 가능성을 향상시킬 필요성을 강조한다.</li></ul></li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="cocoop-significantly-narrows-generalization-gap">CoCoOp Significantly Narrows Generalization Gap<a href="#cocoop-significantly-narrows-generalization-gap" class="hash-link" aria-label="Direct link to CoCoOp Significantly Narrows Generalization Gap" title="Direct link to CoCoOp Significantly Narrows Generalization Gap">​</a></h4><p>Tab. 1(a) 에 표시된 바와 같이,</p><ul><li>CoCoOp 는 unseen classes 에서의 정확도를 63.22% 에서 71.69% 로 향상시켰으며, 이는 manual prompt 와의 격차를 크게 줄였다.</li><li>결과는 instance-conditional prompt 가 더 generalization  가능하다는 것을 확인한다.</li><li>dataset 별 개선 사항에 대한 보다 자세한 분석은 Fig. 3(a) 에 시각화되어 있으며, 5/11 datasets 에서 정확도가 10% 이상 증가한 것을 관찰할 수 있다.</li><li>특히, 도전적인 ImageNet dataset 에서 CoCoOp 의 67.88% 에서 70.43% 로의 상승은 비중이 큰 진전이다(70.43% 의 정확도는 CLIP 의 68.14% 를 능가).</li></ul><p><img loading="lazy" alt="Figure 3" src="/assets/images/image-15-a5ebe8afecccee5d745f98a6fd131292.png" width="1654" height="806" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="cocoops-gains-in-generalization-far-outweigh-losses-in-base-accuracy">CoCoOp’s Gains in Generalization Far Outweigh Losses in Base Accuracy<a href="#cocoops-gains-in-generalization-far-outweigh-losses-in-base-accuracy" class="hash-link" aria-label="Direct link to CoCoOp’s Gains in Generalization Far Outweigh Losses in Base Accuracy" title="Direct link to CoCoOp’s Gains in Generalization Far Outweigh Losses in Base Accuracy">​</a></h4><p>CoOp 과 비교할 때, CoCoOp 는 대부분의 dataset 에서 base classes 의 성능이 떨어진다 (Fig. 3(b))</p><ul><li>이는 CoOp 가 base classes 에 특히 최적화된 반면, CoCoOp 는 entire tasks 에 대한 더 많은 generalization 를 얻기 위해 각 instance 에 최적화되기 때문에 합리적이다.</li><li>하지만 CoCoOp 의 base 정확도가 CoOp 보다 떨어지는 9 datasets 중, 대부분의 loss 는 3% 이하(정확히는 6/)로, Fig. 3(a) 에 표시된 unseen classes 에서의 이득을 훨씬 능가한다.</li><li>심지어 CoCoOp 가 biggest loss 를 겪는 경우에도, generalization 에서의 향상은 대부분 평균을 긍정적으로 돌릴 만큼 충분히 크다.<ul><li>예로, StanfordCars 에서는 -7.63% 의 worst base accuracy 를 보였지만, novel classes 에서 +13.19% 의 third-highest accuracy 향상을 가져와, CoCoOp 의 경우 5.56% 의 긍정적인 개선을 가져왔다.</li></ul></li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="cocoop-is-more-compelling-than-clip">CoCoOp Is More Compelling Than CLIP<a href="#cocoop-is-more-compelling-than-clip" class="hash-link" aria-label="Direct link to CoCoOp Is More Compelling Than CLIP" title="Direct link to CoCoOp Is More Compelling Than CLIP">​</a></h4><p>base 와 novel classes 를 모두 고려할 때, CoCoOp 는 CLIP 보다 4% 이상 향상된 성능을 보여주며(75.83% 대 71.70%), instance-conditional prompt 가 recognition task 에 관련된 보다 generalization 가능한 요소를 포착할 수 있는 더 나은 잠재력을 가진다는 것을 시사한다.</p><p>이론적으로, learning-based prompt 는 manual prompt 보다 base classes 에 over-fitting 할 위험이 훨씬 높다. 따라서, CLIP 는 unseen classes 에서 이기기 어려운 strong 경쟁자이다.</p><p>CoOp 과는 달리, 저자는 CoCoOp 에 대해 유망한 결과를 얻었다: new accuracy 는 4/11 datasets 에서 CLIP 보다 더 우수하다(즉, ImageNet, OxfordPets, Food101, SUN397) 및 FGVCAircraft 를 제외한 나머지 dataset 에서는 CLIP 와 크게 차이나지 않는다.</p><p>context length 에 대한 ablation study 에서, FGVCAircraft 는 CoOp 의 연구 결과와 일치하게 더 긴 문맥으로부터 이익을 얻는 것으로 나타났다.</p><p>manual prompt 와 learning-based prompt 간의 격차를 unseen classes 에서 좁히거나 심지어 뒤집기 위해서는 더 많은 노력이 필요하다. </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="42-cross-dataset-transfer">4.2. Cross-Dataset Transfer<a href="#42-cross-dataset-transfer" class="hash-link" aria-label="Direct link to 4.2. Cross-Dataset Transfer" title="Direct link to 4.2. Cross-Dataset Transfer">​</a></h2><p>CoCoOp 의 한 dataset 내에서의 generalization 능력을 증명한 후, 이제 CoCoOp 이 single dataset 을 넘어 transferable 잠재력을 가지고 있음을 보여준다. </p><p>이는 다른 dataset 들 사이에서의 근본적인 차이가 있을 수 있기 때문에 (e.g., object recognition 에서 texture classification 으로 transfer) 훨씬 더 도전적인 문제이다.</p><p>이 설정에서는 prompt learning 방법만을 고려한다.</p><p>저자는 ImageNet 에서 learned context 를 1,000 all classes 에 대해 다른 10 dataset 으로 trasfner 하면서 CoOp 과 CoCoOp 을 비교한다.</p><p>자세한 결과는 Table 2에 제시되어 있다. </p><p><img loading="lazy" alt="Table 2" src="/assets/images/image-16-d2f7d7cea5a597193856c317e420c782.png" width="1633" height="561" class="img_ev3q"></p><ul><li>source dataset 에서는 두 모델이 유사하게 작동한다. 반면에 target dataset 에서는 CoCoOp 이 CoOp 보다 대부분 명확하게 우수한 성능을 보인다.</li><li>ImageNet 클래스가 주로 objects 와, 많은 수의 pet breeds 를 포함하고 있기 때문에, Caltech101 과 OxfordPets 같은 관련 target dataset 에서 높은 정확도를 보이는 것은 합리적이다.</li><li>이에 비해, 보다 fine-grained 및 specialized categories 를 가진 다른 dataset (e.g., FGVCAircraft 와 DTD 같은 다양한 texture 를 포함한 dataset)에서의 성능은 상당히 낮다.</li><li>그럼에도 불구하고 CoCoOp 은 언급된 두 datasets 뿐만 아니라 대부분의 fine-grained 및 specialized dataset 에서도 CoOp 보다 stonger transferability 를 보여준다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="43-domain-generalization">4.3. Domain Generalization<a href="#43-domain-generalization" class="hash-link" aria-label="Direct link to 4.3. Domain Generalization" title="Direct link to 4.3. Domain Generalization">​</a></h2><p>out-of-distribution data 에 대한 generalization 는 real-world application 에 성공하기 위해 machine learning model 이 가져야 하는 능력이다.</p><p>CoOp 은 learnable prompt 가 domain shift 에 대해 manual prompt 보다 more robust 함을 밝혔다.</p><p>저자는 이전 실험에서처럼 instance-conditional prompt 가 여전히 이점을 유지하는지 알아보고자 한다.</p><p>CoOp 를 따르며, 저자는 ImageNet 에서 learned context 를 4 benchmarks 로 transfer 하여 CoCoOp 의 domain generalization  성능을 평가한다. 또한 CLIP 과의 비교도 포함한다.</p><p>Tab. 3 은 결과를 보여준다.</p><p><img loading="lazy" alt="Table 3" src="/assets/images/image-17-ee0c9c95b4ef43179a4aed725a23ed79.png" width="1649" height="367" class="img_ev3q"></p><ul><li>both prompt learning 방법은 all target datasets 에서 CLIP 을 분명히 능가한다. </li><li>CoOp 과 비교했을 때, CoCoOp 은 ImageNetV2 에서 약간 낮은 성능을 보이지만 다른 세 곳에서 더 나은 성능을 보인다. </li><li>결과는 instance-conditional prompt 가 더 domain generalization 가 가능하다는 것을 확인시켜 준다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="44-further-analysis">4.4. Further Analysis<a href="#44-further-analysis" class="hash-link" aria-label="Direct link to 4.4. Further Analysis" title="Direct link to 4.4. Further Analysis">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="class-incremental-test">Class-Incremental Test<a href="#class-incremental-test" class="hash-link" aria-label="Direct link to Class-Incremental Test" title="Direct link to Class-Incremental Test">​</a></h4><p>base classes 들로 구성된 recognition target 이 완전히 novel classes 를 포함하도록 확장되는 실용적인 문제 시나리오를 고려한다.</p><p>이 문제는 기존의 지속적 continual learning 과 관련이 있지만, 여기서는 모델이 novel classes 의 어떤 training data 도 접근할 수 없고 zero-shot recognition 을 수행해야 한다는 점에서 다르다.</p><p>저자는 11 datasets 를 사용하여 CLIP, CoOp 및 CoCoOp 을 비교한다.</p><p>평균 결과는 Tab. 4 에 보고되어 있다.</p><p><img loading="lazy" alt="Table 4" src="/assets/images/image-18-d78523b5042c66fe8e753f397842eda6.png" width="793" height="351" class="img_ev3q"></p><ul><li>CoOp 는 CLIP 과의 경쟁력을 잃는데, 그들의 성능은 비슷하지만 전자는 training data 가 필요하기 때문이다. </li><li>다시 한번, CoCoOp 은 두 경쟁자를 상당한 차이로 능가한다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="initialization">Initialization<a href="#initialization" class="hash-link" aria-label="Direct link to Initialization" title="Direct link to Initialization">​</a></h4><p>저자는 word embedding-based initialization 와 random initialization 을 비교하는 ablation study 를 수행한다.</p><p>random initialization 의 경우, 저자는 CoOp 를 따라 0.02 표준 편차의 0-mean Gaussian distribution 에서 smapling 한다.</p><p><img loading="lazy" alt="Figure 4" src="/assets/images/image-19-b15a80f7c2b163f31d664380fffb052c.png" width="796" height="443" class="img_ev3q"></p><p>Fig. 4(a) 는 proper initialization 가 base 및 new classes 모두에 더 유익하다는 것을 시사한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="context-length">Context Length<a href="#context-length" class="hash-link" aria-label="Direct link to Context Length" title="Direct link to Context Length">​</a></h4><p>CoOp 을 따라 저자는 4, 8, 16 의 context tokens 을 연구한다.</p><p>공정한 비교를 위해, 모든 context tokens 에 대해 random initialization 를 사용한다.</p><p>Figure 4(b) 는 11 datasets 에 대한 결과를 요약한다.</p><p>base classes 에서의 차이는 상당히 적은 반면, new classes 에서는 longer context length 를 가진 모델이 명확히 더 좋은 성능을 보인다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="cocoop-vs-a-bigger-coop">CoCoOp vs a Bigger CoOp<a href="#cocoop-vs-a-bigger-coop" class="hash-link" aria-label="Direct link to CoCoOp vs a Bigger CoOp" title="Direct link to CoCoOp vs a Bigger CoOp">​</a></h4><p>CoCoOp 은 Meta-Net 을 포함함으로써 CoOp 보다 더 많은 parameters 를 도입하기 때문에, 향상된 성능이 단순히 learning capacity 증가로 인한 것인지 의문이 들 수 있다.</p><p>이를 해소하기 위해, 저자는 Meta-Net 을 제거하고 CoOp 의 context tokens 수를 최대한 늘려 CoOp 과 CoCoOp 의 크기를 유사하게 만든다.</p><p><img loading="lazy" alt="Table 5" src="/assets/images/image-20-6aff951066519cce6c2db6faa607fd24.png" width="668" height="251" class="img_ev3q"></p><p>Tab. 5 의 결과는 parameter size 를 늘리는 것이 핵심이 아니라는 것을 보여준다.</p><h1>5. Limitations</h1><ol><li>training efficiency: CoCoOp 은 학습이 느리고 batch size 가 1 보다 크면 상당한 양의 GPU 메모리를 소비한다. <ul><li>그 이유는 CoCoOp 이 각 image 에 대해 독립적인 instance-specific prompt 를 text encoder 를 통해 forward pass 해야 하는 instance-conditional 설계를 기반으로 하기 때문이다.</li><li>이는 minibatch 전체에 대해 prompt 를 text encoder 를 통해 한 번만 forward pass 하면 되는 CoOp 보다 훨씬 비효율적이다.</li></ul></li><li>7/11 datasets 에서 (Tab. 1) CoCoOp 의 unseen class 에 대한 성능이 여전히 CLIP 보다 뒤쳐져 있다는 것이다.<ul><li>이는 커뮤니티가 manual prompt 와 learning-based prompt 사이의 격차를 완전히 좁히거나 뒤집기 위해 더 많은 노력이 필요하다는 것을 나타낸다.</li></ul></li></ol><h1>6. Discussion and Conclusion</h1><p>저자의 연구는 large pre-trained AI 모델의 가용성으로 인해 발생하는 중요한 문제를 다룬다. 즉, 이러한 모델을 downstream  응용 프로그램에 어떻게 적응시키는가에 관한 것이다.</p><p>이러한 모델, i.e., foundation model 은 다양한 downstream tasks 에 대한 능력 때문에 vision 및 NLP 에서 주목받고 있다.</p><p>그러나 foundation model 은 data scale 과 computing resource 측면에서 pre-training 하는데 비용이 많이 들며, 충분한 용량을 개발하기 위해 일반적으로 엄청난 수의 parameter 를 포함한다.</p><p>예로, 저자의 실험에서 사용된 ViT-B/16 에 기반한 CLIP 모델은 150M parameter size 를 가지고 있다. 이러한 요인들은 foundation model 를 효율적인 적응 방법의 연구 필요성을 강조한다.</p><p>저자가 따라가는 parameter-efficient prompt learning 의 연구는 static prompt 의 generalization 문제에 대한 적절한 통찰력을 제공하고, 더 중요하게는 conditional prompt learning 을 기반으로 한 간단한 디자인이 다양한 문제 시나리오에서 탁월한 성능을 발휘한다는 것을 보여준다.</p><p>여기에는 base-to-new class generalization, cross-dataset prompt transfer 및 domain generalization 이 포함된다.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/co-co-op">CoCoOp</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/prompt">Prompt</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/peft">PEFT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/textual-prompt">Textual Prompt</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/conditional-context-optimization">Conditional Context Optimization</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/2022-03-CoCoOp.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/CoOp"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Learning to Prompt for Vision-Language Models</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/Vision-Language/PEFT/Prompting/Textual-Token/ProGrad"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Prompt-aligned Gradient for Prompt Tuning</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#31-reviews-of-clip-and-coop" class="table-of-contents__link toc-highlight">3.1. Reviews of CLIP and CoOp</a></li><li><a href="#32-cocoop-conditional-context-optimization" class="table-of-contents__link toc-highlight">3.2. CoCoOp: Conditional Context Optimization</a></li><li><a href="#41-generalization-from-base-to-new-classes" class="table-of-contents__link toc-highlight">4.1. Generalization From Base to New Classes</a></li><li><a href="#42-cross-dataset-transfer" class="table-of-contents__link toc-highlight">4.2. Cross-Dataset Transfer</a></li><li><a href="#43-domain-generalization" class="table-of-contents__link toc-highlight">4.3. Domain Generalization</a></li><li><a href="#44-further-analysis" class="table-of-contents__link toc-highlight">4.4. Further Analysis</a></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.ed721529.js"></script>
<script src="/assets/js/main.d22fbe67.js"></script>
</body>
</html>