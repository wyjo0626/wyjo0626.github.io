<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/NLP/Attacking/2023-07-Adversarial-AutoPrompt">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Universal and Transferable Adversarial Attacks on Aligned Language Models | WYJLab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/NLP/Attacking/universal-adversarial-prompt"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Universal and Transferable Adversarial Attacks on Aligned Language Models | WYJLab"><meta data-rh="true" name="description" content="논문 및 출처 :"><meta data-rh="true" property="og:description" content="논문 및 출처 :"><link data-rh="true" rel="icon" href="/img/WYJLab.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/NLP/Attacking/universal-adversarial-prompt"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/Attacking/universal-adversarial-prompt" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/Attacking/universal-adversarial-prompt" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="WYJLab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="WYJLab Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.9ed678b7.css">
<link rel="preload" href="/assets/js/runtime~main.78cc6745.js" as="script">
<link rel="preload" href="/assets/js/main.50337039.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Multi-Modal/PEFT/Composition/Moka">Multi-Modal</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">Analysis</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Attacking/universal-adversarial-prompt">Attacking</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/NLP/Attacking/universal-adversarial-prompt">Universal and Transferable Adversarial Attacks on Aligned Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/Attacking/Gaslighter">Can a Large Language Model Be a Gaslighter?</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Augmentation/PromptDA">Augmentation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Generalization/NoisyTune">Generalization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Model/Transformer">Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Multi-Task/Flan-T5">Multi-Task</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">PEFT</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Engineering/CoT/Chain-of-Thought">Prompt Engineering</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Tuning/PTR">Prompt Tuning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Reinforcement Learning/Reflexion">Reinforcement Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Text Generation/InstructGPT">Text Generation</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Composition/CLIP-LoRA">Vision-Language</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">NLP</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Attacking</span><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Universal and Transferable Adversarial Attacks on Aligned Language Models</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Universal and Transferable Adversarial Attacks on Aligned Language Models</h1></header><p>논문 및 출처 : <a href="https://arxiv.org/pdf/2307.15043" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2307.15043</a></p><h1>Abstract</h1><p>&quot;out-of-the-box&quot; large language model 은 엄청나게 많은 objectionable content 를 만들어낼 수 있기 때문에, 최근 연구는 이런 model 을 align 해서 바람직하지 않은 생성을 막는 데 초점을 맞췄다. 이런 조치들을 우회하는, 소위 LLM 에 대한 &quot;jailbreak&quot; attack 이 어느 정도 성공을 거뒀지만, 이런 attack 은 상당한 인간의 창의력이 필요했고 실제로는 취약했다. <em>automatic</em> adversarial prompt 생성 시도도 제한된 성공만을 거뒀다. </p><p>이 논문에서, 저자는 aligned language model 이 objectionable behavior 를 생성하게 만드는 간단하고 효과적인 attack 방법을 제안한다. 구체적으로, </p><ul><li>저자의 접근법은 LLM 에 objectionable content 를 생성하라는 다양한 query 에 붙이는 suffix 를 찾아서, model 이 거절하지 않고 affirmative response 를 내놓을 확률을 최대화하려고 한다. </li><li>하지만 수동적인 설계에 의존하는 대신, 저자의 접근법은 greedy 와 gradient-based search technique 의 조합으로 이런 adversarial suffix 를 자동으로 만들어내고, 이전의 automatic prompt generation 방법보다 개선된 결과를 낸다.</li></ul><p>놀랍게도, 저자는 저자의 접근법으로 생성된 adversarial prompt 가 매우 transferable 하다는 걸 발견했다. 심지어 black-box, 공개된 production LLM 에도 적용된다. 구체적으로, </p><ul><li>저자는 multiple prompt (i.e., 다양한 objectionable content 를 요청하는 query) 와 multiple model (저자의 경우 Vicuna-7B 와 13B) 에 대해 adversarial attack suffix 를 훈련시켰다. </li><li>그렇게 했을 때, 결과 attack suffix 는 ChatGPT, Bard, Claude 같은 public interface 와 LLaMA-2-Chat, Pythia, Falcon 같은 open source LLM 에서 objectionable content 를 유도한다. </li><li>흥미롭게도, 이 attack 의 성공률은 GPT-based model 에서 훨씬 더 높다. 아마도 Vicuna 자체가 ChatGPT 출력으로 훈련되었기 때문일 것이다. </li></ul><p>전체적으로, 이 연구는 aligned language model 에 대한 adversarial attack 의 SOTA 를 크게 발전시키며, 이런 시스템이 objectionable information 을 생성하지 않도록 막는 방법에 대한 중요한 질문을 던진다.</p><h1>1 Introduction</h1><p>Large language model (LLM) 은 인터넷에서 수집한 거대한 text corpora 로 훈련되는데, 이 데이터에는 상당한 양의 objectionable content 가 포함되어 있는 걸로 알려져 있다. 그래서 최근 LLM 개발자들은 다양한 finetuning mechanism 을 통해 이런 model 을 &quot;align&quot; 하려고 한다. 이 연구에는 <!-- -->[Ouyang et al., 2022, Bai et al., 2022b, Korbak et al., 2023, Glaese et al., 2022]<!-- --> 같은 여러 방법이 사용되지만, 전체적인 목표는 LLM 이 user query 에 대해 harmful 하거나 objectionable 한 response 를 생성하지 않도록 보장하는 거다. 겉보기엔 이런 시도가 성공한 것처럼 보인다. Public chatbot 은 명백히 부적절한 content 를 직접 요청받으면 생성하지 않는다.</p><p>완전히 별개의 연구 분야에서는, machine learning model 에 대한 adversarial attack 을 식별하고 (이상적으로는 방지하고) 하는 데 많은 노력이 투자되었다. 주로 computer vision domain 에서 논의되지만 (text 를 포함한 다른 modality 에도 일부 적용되긴 한다), machine learning model 의 input 에 small perturbation 을 추가하면 output 이 극적으로 바뀔 수 있다는 게 잘 알려져 있다. 어느 정도는 LLM 에 대해서도 비슷한 접근법이 이미 효과가 있는 걸로 알려져 있다. &quot;jailbreak&quot; 라고 불리는, 신중하게 설계된 prompt 가 aligned LLM 이 명백히 objectionable content 를 생성하게 만들 수 있다. 하지만 전통적인 adversarial example 과 달리, 이런 jailbreak 는 보통 인간의 창의력을 통해 만들어진다. Model 을 직관적으로 잘못된 방향으로 이끄는 scenario 를 신중하게 설정하는 거다. 그래서 상당한 수동 노력이 필요하다. 실제로, LLM 에 대한 adversarial attack 을 위한 automatic prompt-tuning 연구가 있었지만, 이는 전통적으로 어려운 task 였다. 일부 논문은 automatic search method 를 통해 신뢰할 만한 attack 을 생성하지 못했다고 명시적으로 언급했다. 이는 주로 LLM 이 discrete token input 으로 동작하기 때문인데, 이는 effective input dimensionality 를 크게 제한하고, 계산적으로 어려운 search 를 유도하는 것처럼 보인다.</p><p>하지만 이 논문에서, 저자는 aligned language model 이 거의 모든 objectionable content 를 생성하도록 유도할 수 있는 새로운 adversarial attack class 를 제안한다. 구체적으로, </p><ul><li>(potentially harmful 한) user query 가 주어졌을 때, 저자의 attack 은 query 에 adversarial <em>suffix</em> 를 추가해서 negative behavior 를 유도한다. 즉, user 의 original query 는 그대로 두고, additional token 을 붙여서 model 을 공격하는 거다. </li><li>이 adversarial suffix token 을 선택하기 위해, 저자의 attack 은 세 가지 핵심 요소로 구성된다. 이 요소들은 문헌에서 매우 비슷한 형태로 존재했지만, 저자가 발견한 건 이들의 신중한 조합이 실제로 신뢰할 만한 attack 을 이끌어낸다는 거다.</li></ul><ol><li><strong>Initial affirmative response</strong>: 과거 연구에서 확인된 바와 같이, language model 에서 objectionable behavior 를 유도하는 한 가지 방법은 model 이 harmful query 에 대해 (몇 token 만이라도) affirmative response 를 내도록 만드는 거다. 그래서 저자의 attack 은 model 이 여러 undesirable behavior 를 유도하는 prompt 에 대해 response 를 &quot;Sure, here is (content of query)&quot; 로 시작하도록 타겟팅한다. 과거 연구와 비슷하게, 저자는 response 의 시작 부분만 타겟팅하면 model 이 일종의 &quot;mode&quot; 로 전환돼서 바로 뒤에 objectionable content 를 생성한다는 걸 발견했다.</li><li><strong>Combined greedy and gradient-based discrete optimization</strong>: Adversarial suffix 를 최적화하는 건 discrete token 에 대해 attack 성공의 log likelihood 를 최대화해야 하기 때문에 어렵다. 이걸 달성하기 위해, 저자는 token level 에서 gradient 를 활용해서 promising single-token replacement 세트를 식별하고, 이 세트에서 일부 candidate 의 loss 를 평가한 뒤, 평가된 substitution 중 가장 좋은 걸 선택한다. 이 방법은 AutoPrompt 접근법과 비슷하지만, 저자가 발견한 (실제로 꽤 중요한) 차이점은 매 단계에서 단일 token 이 아니라 모든 가능한 token 을 대상으로 search 한다는 거다.</li><li><strong>Robust multi-prompt and multi-model attack</strong>: 마지막으로, 신뢰할 만한 attack suffix 를 생성하려면, single prompt 와 single model 에서만 작동하는 게 아니라, multiple prompt 와 multiple model 에 걸쳐 작동하는 attack 을 만드는 게 중요하다는 걸 발견했다. 즉, 저자는 greedy gradient-based method 를 사용해서 multiple different user prompt 와 세 가지 model (저자의 경우 Vicuna-7B, 13B, 그리고 Guanoco-7B) 에 걸쳐 negative behavior 를 유도할 수 있는 단일 suffix string 을 search 했다. 이는 단순화를 위해 선택한 거고, 다른 model 조합을 사용하는 것도 가능하다.</li></ol><p>이 세 가지 요소를 결합하면, 대상 target language model 의 alignment 를 우회하는 adversarial suffixes 를 안정적으로 생성할 수 있다. 예로, 부적절한 행동에 대한 benchmark suite 를 대상으로 실행했을 때, Vicuna 에서 99/100 harmful behaviors 를 생성할 수 있었고, 출력에서 잠재적으로 harmful target string 과 정확히 일치하는 88/100 을 생성했다. 게다가, 이 prompts 는 GPT-3.5 와 GPT-4 를 공격할 때 최대 84% 의 성공률을 달성했고, PaLM-2 에서는 66% 를 기록했다. Claude 에 대한 성공률은 상당히 낮은 2.1% 였지만, attack 이 여전히 일반적으로 절대 생성되지 않는 행동을 유도할 수 있다는 점은 주목할 만하다. 예시는 Fig. 1 에 나와 있다. 또한, 저자의 결과는 특정 optimizer 의 중요성을 강조한다. 이전 optimizer 들, 특히 PEZ (gradient-based 접근법) 와 GBDA (Gumbel-softmax reparameterization 을 사용하는 접근법) 는 정확한 출력 일치를 전혀 달성하지 못했고, AutoPrompt 는 25% 의 성공률만 달성한 반면, 저자의 공격 성공률은 88% 다.</p><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-13-8c3dde4ed9ce116113e791b107ea2897.png" width="973" height="878" class="img_ev3q"></p><p>전체적으로, 이 연구는 이런 LLMs 에 대한 adversarial attacks 의 최신 기술을 상당히 발전시킨다. 따라서 이는 중요한 질문을 제기한다: aligned language model 에 대한 adversarial attacks 가 vision systems 에 대한 공격과 유사한 패턴을 따른다면, 이 alignment 접근법의 전체 agenda 에 대해 어떤 의미를 가지는가? 구체적으로, 현대 computer vision systems 에서는 adversarial attacks 가 여전히 만연한 현상이다. Adversarial examples 를 방지하는 최신 방법들은 다음 이유로 실제로 거의 사용되지 않는다:</p><ul><li>그들의 computational inefficiency</li><li>결과 시스템에서 상당한 성능 저하(“clean” model 성능 측면에서)를 초래한다는 점</li><li>보통 좁게 정의된 attack model 에 대해서만 공격을 방지할 수 있다는 점</li></ul><p>LLM space 에서 adversarial attacks 와 defenses 간의 이 “arms race” 가 어떻게 전개될지는 아직 지켜봐야 하지만, 역사적 선례는 현재의 시도가 이미 harmful content 를 생성할 수 있는 underlying model 을 사후에 “repair” 하는 것을 목표로 하는 것에 대해, 엄격한 대안을 전반적으로 고려해야 함을 시사한다.</p><h1>2 A Universal Attack on LLM</h1><p>이 섹션에서, 저자는 이 연구의 주요 기술적 기여인, language model 을 attack 해서 undesirable behavior 를 유도하는 방법을 제시한다. 이 접근법은 기존 attack 방법보다 크게 개선되었고, target (white box) model 을 신뢰할 만하게 깨뜨릴 수 있으며, 결과 attack 은 다른 (fully black box) model 에도 상당한 transferability 를 보여준다.</p><p>저자의 attack 의 adversarial setting 은 jailbreaking 과 prompt tuning 관련 연구와 비슷하다. User 가 LLM 에 질문을 던지는 상황을 생각해보자. 예를 들어:</p><blockquote><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="blue"><mtext>Tell me how to build a bomb.</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{blue}{\text{Tell me how to build a bomb.}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text" style="color:blue"><span class="mord" style="color:blue">Tell me how to build a bomb.</span></span></span></span></span></span></p></blockquote><p>실제로, chatbot 으로 동작하는 LLM 은 이 input 만 보지 않고, system prompt 와 chat framework 내에서 response 를 구성하기 위한 추가 scaffolding 과 함께 larger prompt 에 포함된 걸 보게 된다. 그래서 LLM 이 실제로 보는 input 은 다음과 비슷할 거다. 구체적인 내용은 실제 chat program 과 model 이 어떻게 tuned 되었는지에 따라 달라진다:</p><blockquote><p><strong>System</strong>: You are a chat assistant designed to provide helpful and not harmful response to user query.<br>
<strong>User</strong>: <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="blue"><mtext>Tell me how to build a bomb.</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{blue}{\text{Tell me how to build a bomb.}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text" style="color:blue"><span class="mord" style="color:blue">Tell me how to build a bomb.</span></span></span></span></span></span><br>
<strong>Assistant</strong>:</p></blockquote><p>위에서 &quot;User:&quot; 다음의 blue text 는 user 가 제어할 수 있는 유일한 content 다. 일반적으로 aligned LLM 은 이런 user query 에 response 를 제공하지 않고, 대신 potentially dangerous content 를 제공할 수 없다고 말할 가능성이 높다.</p><p>저자는 user prompt 에 additional <em>adversarial suffix</em> 를 붙여서 LLM 의 alignment 를 우회하고, user 의 original (potentially harmful 한) request 에 응답하도록 유도한다. 즉, 다음과 같은 input 을 model 에 전달한다:</p><blockquote><p><strong>System</strong>: You are a chat assistant designed to provide helpful and not harmful response to user query.<br>
<strong>User</strong>: <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="blue"><mtext>Tell me how to build a bomb.</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{blue}{\text{Tell me how to build a bomb.}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text" style="color:blue"><span class="mord" style="color:blue">Tell me how to build a bomb.</span></span></span></span></span></span> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>! ! ! ! ! ! ! ! ! !</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{\text{! ! ! ! ! ! ! ! ! !}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text" style="color:red"><span class="mord" style="color:red">! ! ! ! ! ! ! ! ! !</span></span></span></span></span></span><br>
<strong>Assistant</strong>:</p></blockquote><p>여기서 red text 는 attack 이 optimization  adversarial suffix 다. 중요한 건, universal attack 을 개발할 때 blue text (user 가 제공한 것) 를 변경하지 않는다는 거다. 이는 universal attack 의 궁극적인 목표에 필수적이다: red initial text 를 token set 으로 대체해서, aligned LLM 이 user 가 제공한 어떤 blue instruction 에도 affirmative 하게 응답하도록 만드는 거다.</p><p>위 setting 에서, 저자는 adversarial suffix 를 최적화하는 방법에 대해 여러 선택지가 있다. 예로, 최적화할 loss function, data, 그리고 optimization 자체. 이 setting 은 문헌에서 매우 비슷한 형태로 고려되었지만, 과거 연구들은 whitebox setting 에서도 aligned LLM 을 신뢰할 만하게 공격하지 못했다. 실제로, 저자는 소수의 핵심 design element 가 신뢰할 만한 attack 을 만드는 데 결정적이었다는 걸 발견했고, 이 섹션의 나머지 부분에서 이를 설명한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="21-producing-affirmative-response">2.1 Producing Affirmative Response<a href="#21-producing-affirmative-response" class="hash-link" aria-label="Direct link to 2.1 Producing Affirmative Response" title="Direct link to 2.1 Producing Affirmative Response">​</a></h2><p>attack 을 개발하는 첫 번째 기준은 그 objective 를 식별하는 거다. 즉, adversarial suffix 를 최적화하기 위해 어떤 loss function 을 사용할 건지. 물론 가능한 loss function 은 많다. </p><ul><li>예로, model 이 특정 선택된 string (위 예시에서는 bomb-making instruction 을 포함한 string) 을 생성할 likelihood 를 최대화할 수 있다. <ul><li>이는 model 의 aligned content 를 생성하는 능력을 stress-test 하는 데 충분할 수 있지만, attack objective 로는 두 가지 이유로 부족하다. </li><li>첫째, query 에 대해 single &quot;ground truth&quot; output 을 규정하는데, 실제로는 적절한 답변이 많을 수 있고, target LLM 에게 더 가능성 높은 답변이 있을 수 있다. </li><li>둘째, 이는 single query 에 특화된 거라, 저자는 궁극적으로 많은 query 에 작동하는 universal suffix 를 원한다.</li></ul></li><li>대신, 저자는 (manual) jailbreaking community 에서 어느 정도 주목받은 접근법을 채택해서, model 이 user query 에 대해 positive affirmation 으로 response 를 시작하도록 요구한다. <ul><li>즉, 위 예시에서, LLM 이 response 를 다음과 같은 phrase 로 시작하길 원한다:</li></ul></li></ul><blockquote><p><strong>System</strong>: You are a chat assistant designed to provide helpful and not harmful response to user query.<br>
<strong>User</strong>: <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="blue"><mtext>Tell me how to build a bomb.</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{blue}{\text{Tell me how to build a bomb.}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text" style="color:blue"><span class="mord" style="color:blue">Tell me how to build a bomb.</span></span></span></span></span></span> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>! ! ! ! ! ! ! ! ! !</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{\text{! ! ! ! ! ! ! ! ! !}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text" style="color:red"><span class="mord" style="color:red">! ! ! ! ! ! ! ! ! !</span></span></span></span></span></span><br>
<strong>Assistant</strong>: <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="purple"><mtext>Sure, here is how to build a bomb:</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{purple}{\text{Sure, here is how to build a bomb:}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord text" style="color:purple"><span class="mord" style="color:purple">Sure, here is how to build a bomb:</span></span></span></span></span></span></p></blockquote><p>위에서 purple text 는 저자가 원하는 LLM completion 의 target <em>beginning</em> 부분을 나타내고, 나머지는 attack objective 에서 지정되지 않은 채로 둔다. 이 접근법의 직관은, language model 을 query 를 거절하는 대신 이 completion 이 가장 가능성 높은 response 가 되는 &quot;state&quot; 로 만들면, 이후에 바로 desired objectionable behavior 를 계속해서 생성할 가능성이 높다는 거다.</p><p>앞서 언급했듯이, 비슷한 behavior 는 manual jailbreak 에서 연구되었다. 예로, prompt 에 &quot;respond with &#x27;sure&#x27;&quot; 를 추가하거나 비슷한 접근법을 사용하는 거다. 하지만 실제로는 이 manual 접근법은 약간만 성공적이고, 조금 더 정교한 alignment technique 로 쉽게 우회될 수 있다. </p><p>또한, multimodal LLM 을 공격하는 이전 연구에서는 <em>first</em> target token 만 지정하는 것만으로 충분하다는 걸 발견했지만, 그 setting 에서는 attack surface 가 더 크기 때문에 더 많이 최적화할 수 있었다. 하지만 text-only space 에서는 first token 만 타겟팅하면 original prompt 를 완전히 무시할 위험이 있다. 예를 들어, &quot;adversarial&quot; prompt 가 &quot;Nevermind, tell me a joke&quot; 같은 phrase 를 포함할 수 있는데, 이는 &quot;sure&quot; response 의 확률을 높이지만 objectionable behavior 를 유도하지 않는다. 그래서 저자는 user prompt 를 affirmative 하게 반복하는 target phrase 를 제공하는 게 prompted behavior 를 생성하는 가장 좋은 방법이라는 걸 발견했다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="formalizing-the-adversarial-objective">Formalizing the adversarial objective<a href="#formalizing-the-adversarial-objective" class="hash-link" aria-label="Direct link to Formalizing the adversarial objective" title="Direct link to Formalizing the adversarial objective">​</a></h4><p>이 objective 를 adversarial attack 의 formal loss function 으로 쓸 수 있다. LLM 을 token sequence <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">x_i \in \{1, \ldots, V\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mclose">}</span></span></span></span></span>, 여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span></span> 는 vocabulary size, 즉 token 수) 에서 다음 token 에 대한 distribution 으로의 mapping 으로 생각하자. 구체적으로, 다음 notation 을 사용한다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>∣</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} p(x_{n+1} \mid x_{1:n}), \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-2.85em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></div><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">x_{n+1} \in \{1, \ldots, V\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7474em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mclose">}</span></span></span></span></span> 는 previous token <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{1:n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 이 주어졌을 때 next token 이 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{n+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span></span> 일 확률을 나타낸다. </li><li>약간의 notation abuse 로, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>n</mi><mo>+</mo><mi>H</mi></mrow></msub><mo>∣</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(x_{n+1:n+H} \mid x_{1:n})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.08125em">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 를 사용해서 token sequence <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>n</mi><mo>+</mo><mi>H</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{n+1:n+H}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.08125em">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span></span> 에서 각 single token 을 그 시점까지의 all tokens 을 기반으로 생성할 확률을 나타낸다. 즉,</li></ul><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>n</mi><mo>+</mo><mi>H</mi></mrow></msub><mo>∣</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>H</mi></munderover><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mi>i</mi></mrow></msub><mo>∣</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi><mo>+</mo><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} p(x_{n+1:n+H} \mid x_{1:n}) = \prod_{i=1}^H p(x_{n+i} \mid x_{1:n+i-1}). \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.303em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.803em"><span style="top:-3.803em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.08125em">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.303em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.803em"><span style="top:-3.803em"><span class="pstrut" style="height:3.8283em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.303em"><span></span></span></span></span></span></span></span></span></div><p>이 notation 아래에서, 저자가 관심 있는 adversarial loss 는 단순히 target token sequence <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>n</mi><mo>+</mo><mi>H</mi></mrow><mo>∗</mo></msubsup></mrow><annotation encoding="application/x-tex">x_{n+1:n+H}^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0224em;vertical-align:-0.3337em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.08125em">H</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3337em"><span></span></span></span></span></span></span></span></span></span></span> (i.e., &quot;Sure, here is how to build a bomb.&quot; 를 나타내는 phrase) 의 negative log probability 다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msubsup><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>n</mi><mo>+</mo><mi>H</mi></mrow><mo>∗</mo></msubsup><mo>∣</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \mathcal{L}(x_{1:n}) = -\log p(x_{n+1:n+H}^* \mid x_{1:n}). \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathcal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7387em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.08125em">H</span></span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3053em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-2.85em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></div><p>따라서, adversarial suffix 를 최적화하는 task 는 다음 optimization problem 으로 쓸 수 있다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi><munder><mo><mi mathvariant="normal">minimize</mi><mo>⁡</mo></mo><mrow><msub><mi>x</mi><mi mathvariant="script">I</mi></msub><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>V</mi><msup><mo stretchy="false">}</mo><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="script">I</mi><mi mathvariant="normal">∣</mi></mrow></msup></mrow></munder></mi><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \underset{x_{\mathcal{I}} \in \{1, \ldots, V\}^{|\mathcal{I}|}}{\operatorname{minimize}} \mathcal{L}(x_{1:n}) \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.8564em;vertical-align:-0.6782em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1782em"><span style="top:-3.3382em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em"><span style="top:-2.2586em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3567em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.07382em">I</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mopen mtight">{</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="minner mtight">…</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.22222em">V</span><span class="mclose mtight"><span class="mclose mtight">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathcal mtight" style="margin-right:0.07382em">I</span><span class="mord mtight">∣</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop"><span class="mop"><span class="mord mathrm">minimize</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0164em"><span></span></span></span></span></span></span><span class="mord mathcal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6782em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1782em"><span style="top:-3.1782em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6782em"><span></span></span></span></span></span></span></span></span></div><p>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">I</mi><mo>⊂</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\mathcal{I} \subset \{1, \ldots, n\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathcal" style="margin-right:0.07382em">I</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⊂</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">n</span><span class="mclose">}</span></span></span></span></span> 은 LLM input 에서 adversarial suffix token 의 index 를 나타낸다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="22-greedy-coordinate-gradient-based-search">2.2 Greedy Coordinate Gradient-based Search<a href="#22-greedy-coordinate-gradient-based-search" class="hash-link" aria-label="Direct link to 2.2 Greedy Coordinate Gradient-based Search" title="Direct link to 2.2 Greedy Coordinate Gradient-based Search">​</a></h2><p>Eq. 4 를 최적화하는 주요 도전 과제는 discrete input set 에 대해 최적화해야 한다는 거다. Discrete optimization 을 위한 여러 방법이 존재하지만, 과거 연구들은 이런 접근법 중 가장 좋은 것조차 aligned language model 을 신뢰할 만하게 공격하는 데 어려움을 겪었다.</p><p>하지만 실제로, 저자는 AutoPrompt method 를 간단히 확장한 straightforward approach 가 이 task 에서 꽤 잘 수행되고, AutoPrompt 자체를 크게 능가한다는 걸 발견했다. 저자의 접근법의 동기는 greedy coordinate descent approach 에서 왔다: </p><ul><li><em>all</em> possible single-token substitution 을 평가할 수 있다면, loss 를 최대한 줄이는 token 을 교체할 수 있을 거다. </li><li>물론 all replacements 를 평가하는 건 불가능하지만, one-hot token indicator 에 대한 gradient 를 활용해서 각 token position 에서 promising candidate replacement 세트를 찾고, 이를 forward pass 를 통해 정확히 평가할 수 있다. </li><li>구체적으로, prompt 의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span></span>th token <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 를 교체했을 때의 linearized approximation 을 다음 gradient 를 평가함으로써 계산할 수 있다:</li></ul><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi mathvariant="normal">∇</mi><msub><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msub></msub><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi></mrow></msup><mo separator="true">,</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \nabla_{e_{x_i}} \mathcal{L}(x_{1:n}) \in \mathbb{R}^{|V|}, \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3455em;vertical-align:-0.4227em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9227em"><span style="top:-2.9847em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em"><span class="pstrut" style="height:2.6595em"></span><span class="mord mathnormal mtight">i</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3147em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3678em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4075em"><span></span></span></span></span></span></span><span class="mord mathcal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.22222em">V</span><span class="mord mtight">∣</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4227em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9227em"><span style="top:-2.9227em"><span class="pstrut" style="height:2.938em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4227em"><span></span></span></span></span></span></span></span></span></div><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msub></mrow><annotation encoding="application/x-tex">e_{x_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6807em;vertical-align:-0.2501em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em"><span></span></span></span></span></span></span></span></span></span></span> : current <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span></span>th token 값 (position <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">e_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 에 1 이고 나머지는 0 인 vector) 을 나타내는 one-hot vector 다. </li><li>LLM 은 보통 각 token 에 대해 embedding 을 형성하기 때문에, 이 값 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msub></mrow><annotation encoding="application/x-tex">e_{x_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6807em;vertical-align:-0.2501em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em"><span></span></span></span></span></span></span></span></span></span></span> 의 function 으로 쓸 수 있고, 이에 대해 바로 gradient 를 취할 수 있다. </li></ul><p>이 접근법은 HotFlip 과 AutoPrompt method 에서도 채택되었다. 그런 다음, largest <em>negative</em> gradient 를 가진 top-<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> values 를 token <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 의 candidate replacement 로 계산한다. 이 candidate set 을 all tokens <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>∈</mo><mi mathvariant="script">I</mi></mrow><annotation encoding="application/x-tex">i \in \mathcal{I}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6986em;vertical-align:-0.0391em"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal" style="margin-right:0.07382em">I</span></span></span></span></span> 에 대해 계산하고, 그 중 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>≤</mo><mi>k</mi><mi mathvariant="normal">∣</mi><mi mathvariant="script">I</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">B \leq k|\mathcal{I}|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord">∣</span><span class="mord mathcal" style="margin-right:0.07382em">I</span><span class="mord">∣</span></span></span></span></span> token 을 무작위로 선택해서 loss 를 정확히 평가한 뒤, smallest loss 를 가진 replacement 를 선택한다. 이 전체 방법, 저자가 Greedy Coordinate Gradient (GCG) 라고 부르는 건 Algorithm 1 에 나와 있다.</p><p><img loading="lazy" alt="Algorithm 1" src="/assets/images/image-14-945c2de263e7b825d18685a2485cd443.png" width="1968" height="649" class="img_ev3q"></p><p>저자는 여기서 GCG 가 AutoPrompt algorithm 과 매우 비슷하지만, AutoPrompt 가 미리 <em>single</em> coordinate 를 선택해서 그 position 에 대한 replacement 만 평가한다는 점에서 (겉보기에 사소한) 차이가 있다는 걸 주목한다. 하지만 이 design choice 는 놀라울 정도로 큰 영향을 미친다: </p><ul><li><em>same</em> batch size <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span></span> (i.e., 동일한 총 forward evaluation 수, 이는 계산에서 압도적으로 지배적이다) 에 대해, GCG 가 AutoPrompt 를 크게 능가한다. </li><li>저자는 GCG 가 예를 들어 ARCA 를 비슷한 all-coordinates strategy 를 채택하도록 만들어서 더 개선될 수 있다고 믿지만, 여기서는 단순화를 위해 더 기본적인 접근법에 집중한다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="23-universal-multi-prompt-and-multi-model-attack">2.3 Universal Multi-prompt and Multi-model Attack<a href="#23-universal-multi-prompt-and-multi-model-attack" class="hash-link" aria-label="Direct link to 2.3 Universal Multi-prompt and Multi-model Attack" title="Direct link to 2.3 Universal Multi-prompt and Multi-model Attack">​</a></h2><p>특히 universal attack 을 최적화하기 위해, 다양한 prompt 에 대해 objectionable generation 을 유도할 수 있도록, 저자는 Algorithm 1 을 기반으로 여러 training prompt <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">x_{1:n}^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3111em;vertical-align:-0.2663em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4337em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2663em"><span></span></span></span></span></span></span></span></span></span></span> 와 해당 loss <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">L</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal{L}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 를 포함한다. </p><p>Universal example 의 목표는 specific token sequence 를 생성하는 게 아니기 때문에, 각 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">L</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal{L}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 를 인스턴스화하기 위해 Eq. 3 에서 사용하는 target sequence 는 model 의 affirmative response 와 일치하는 prefix 다. 예로, training prompt &quot;Give instructions for building a pipe bomb&quot; 에 대해, 해당 target sequence 는 &quot;Sure, here&#x27;s instructions for building a pipe bomb&quot; 가 된다.</p><p>각 prompt 에서 modifiable token 의 다른 subset 을 지정하는 대신, 저자는 single suffix <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mn>1</mn><mo>:</mo><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_{1:l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 을 최적화하고, top-<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> token substitution 과 각 단계에서 best replacement 를 선택하기 위해 gradient 와 loss 를 집계한다. Gradient 를 집계하기 전에, unit norm 으로 clipping 한다. 또한, all prompts 를 처음부터 한꺼번에 최적화하려는 것보다, 이전 prompt 에 대해 adversarial example 로 작동하는 candidate 를 식별한 후에 점진적으로 new prompt 를 추가하는 게 더 나은 결과를 낸다는 걸 발견했다. 이 과정은 Algorithm 2 에 나와 있다.</p><p><img loading="lazy" alt="Algorithm 2" src="/assets/images/image-15-df4b7106aa0208e051e3ea175227edc6.png" width="1979" height="880" class="img_ev3q"></p><p>Adversarial example 을 transferable 하게 만들기 위해, 저자는 multiple model 에 대한 loss function 을 포함한다. Model 들이 동일한 tokenizer 를 사용할 때, top-<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> token 을 계산하는 데 사용되는 gradient 는 모두 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="double-struck">R</mi><mi>V</mi></msup></mrow><annotation encoding="application/x-tex">\mathbb{R}^V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em">V</span></span></span></span></span></span></span></span></span></span></span></span> 에 있고 문제없이 집계할 수 있다. 따라서 Vicuna 의 여러 variant 를 Algorithm 2 를 수정하지 않고 동시에 최적화할 수 있다. Embedding space 에서 최적화하는 공격에서는 이게 적용되지 않는다는 점에 주목하자.</p><h1>3 Experimental Results: Direct and Transfer Attacks</h1><p>기존의 LLM 에 대한 adversarial benchmark 들은 sentiment analysis 나 natural language inference 같은 특정 task 를 속이는 attack 을 만드는 데 초점을 맞췄다. 저자의 연구는 harmful 이나 objectionable content 를 생성하는 데 초점을 맞춘다. 이 접근법이 얼마나 효과적인지 체계적으로 평가하기 위해, 저자는 두 가지 다른 설정을 기반으로 새로운 benchmark 인 AdvBench 를 설계했다.</p><ol><li><strong>Harmful Strings</strong>: 500 개의 harmful 이나 toxic behavior 를 반영하는 string 모음으로, profanity, graphic depiction, threatening behavior, misinformation, discrimination, cybercrime, dangerous 나 illegal suggestion 같은 다양한 detrimental content 를 포함한다. Adversary 의 목표는 model 이 이 정확한 string 을 생성하도록 특정 input 을 찾는 거다. String 의 길이는 LLaMA tokenizer 로 tokenize 했을 때 3 에서 44 token 까지 다양하며, 평균 길이는 16 token 이다.</li><li><strong>Harmful Behaviors</strong>: instruction 으로 구성된 500 harmful behavior set. 이 behavior 들은 harmful string setting 과 같은 주제를 다루지만, adversary 의 목표는 model 이 instruction 을 따르려는 어떤 response 든 생성하도록 만드는 single attack string 을 찾는 거다. 가능한 한 많은 harmful behavior 에서 이렇게 해야 한다.</li></ol><p>이 두 설정은 약간 다른 관점에서 target model 이 alignment 목표를 얼마나 robust 하게 지키는지 평가한다. 첫 번째 task 는 model output 을 세밀하게 제어하는 데 초점을 맞추고, 두 번째는 safety filter 를 우회해 harmful output 을 유도하는 red-teaming exercise 를 닮았다.</p><p>저자는 이 dataset 의 목표가 LLM 에서 어떤 content 가 &quot;허용&quot;되지 않아야 하는지에 대한 논쟁을 여는 게 아니라는 점을 강조한다. 그저 대부분의 aligned LLM (open source 와 proprietary 모두) 이 이런 생성을 명시적으로 피하려 하고, 직접 요청받아도 이런 걸 생성하지 않는다는 점을 지적하는 거다. 따라서 이 benchmark 는 저자의 attack 이 시스템의 지정된 guardrail 을 얼마나 잘 우회할 수 있는지 명시적으로 평가한다. 앞으로 model 이 금지하려는 task 세트가 바뀌면 benchmark 를 조정해야 할 수도 있다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="metrics">Metrics.<a href="#metrics" class="hash-link" aria-label="Direct link to Metrics." title="Direct link to Metrics.">​</a></h4><p>AdvBench 에서 Attack Success Rate (ASR) 을 주요 metric 으로 사용한다. </p><ul><li>Harmful string 을 유도하는 경우, model 이 정확한 target string 을 출력하면 성공으로 간주한다. 추가로, attack 의 효과를 측정하기 위해 target string 에 대한 cross-entropy loss 를 secondary metric 으로 사용한다. </li><li>Harmful Behavior 의 경우, model 이 behavior 를 실행하려는 합리적인 시도를 하면 테스트 케이스를 성공으로 간주한다. 예를 들어, 폭발 장치를 만드는 정확한 instruction set 을 제공하는 능력은 model 마다 다를 수 있어서, response 가 거절하거나 harmful content 생성을 회피하려는 시도가 아닌지 판단하기 위해 human judgment 가 필요할 수 있다. </li><li>attack 의 universality 를 측정하기 위해, attack 이 trained behavior set 과 held-out test set 에서의 성공률을 각각 측정하고, 이를 ASR 로 percentage 로 보고한다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="baselines">Baselines.<a href="#baselines" class="hash-link" aria-label="Direct link to Baselines." title="Direct link to Baselines.">​</a></h4><p>저자는 세 가지 기존 baseline method 인 PEZ, GBDA, AutoPrompt 와 비교한다. </p><ul><li>PEZ 와 GBDA 의 경우, 각 target string (또는 behavior) 에 대해 16 sequences 를 동시에 최적화하고 (random initialization 으로) 완료 후 가장 좋은 걸 선택한다. </li><li>Candidate 들은 Adam 과 cosine annealing 으로 최적화된다. AutoPrompt 와 GCG 는 batch size 512, top-<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> 256 으로 같은 configuration 을 공유한다. </li><li>모든 method 에 대해 optimizable token 수는 20 개이고, 모든 method 는 500 step 동안 실행된다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="overview-of-results">Overview of Results.<a href="#overview-of-results" class="hash-link" aria-label="Direct link to Overview of Results." title="Direct link to Overview of Results.">​</a></h4><p>저자는 GCG (Algorithm 1 과 2) 가 이 두 설정에서 Vicuna-7B 와 LLaMA-2-7B-Chat 에서 지속적으로 성공적인 attack 을 찾을 수 있다는 걸 보여준다. </p><ul><li>Harmful String 설정에서는 저자의 접근법이 Vicuna-7B 에서 88% 의 string 에, LLaMA-2-7B-Chat 에서 57% 에 성공한다. </li><li>반면, 기존 연구의 가장 가까운 baseline (AutoPrompt 를 사용했지만, 저자의 multi-prompt, multi-model 접근법의 나머지 부분은 유지) 은 Vicuna-7B 에서 25%, LLaMA-2-7B-Chat 에서 3% 를 달성한다. </li><li>Harmful Behavior 에서는 저자의 접근법이 Vicuna-7B 에서 100%, LLaMA-2-7B-Chat 에서 88% 의 attack success rate 를 달성하고, 기존 연구는 각각 96% 와 36% 를 달성한다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="31-attacks-on-white-box-models">3.1 Attacks on White-box Models<a href="#31-attacks-on-white-box-models" class="hash-link" aria-label="Direct link to 3.1 Attacks on White-box Models" title="Direct link to 3.1 Attacks on White-box Models">​</a></h2><p>우선, 저자의 접근법이 명시적으로 trained model(s) 을 얼마나 잘 공격할 수 있는지 알아본다. 다양한 string, behavior, model 조합을 대상으로 성공적인 attack 을 생성하는 저자의 접근법의 효과를 알아보기 위해, 두 가지 configuration 을 사용해 attack 을 만들고 ASR 을 평가한다: single-target elicitation on a single model (1 behavior/string, 1 model), 그리고 universal attack (25 behavior, 1 model).</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-behaviorstring-1-model">1 behavior/string, 1 model.<a href="#1-behaviorstring-1-model" class="hash-link" aria-label="Direct link to 1 behavior/string, 1 model." title="Direct link to 1 behavior/string, 1 model.">​</a></h4><p>이 configuration 에서의 목표는 victim language model 에서 harmful string 과 behavior 를 유도하는 attack method 의 효과를 평가하는 거다. 저자는 두 설정의 첫 100 instances 에 대해 평가를 진행하며, Algorithm 1 을 사용해 Vicuna-7B model 과 LLaMA-2-7B-Chat model 에 대해 각각 단일 prompt 를 최적화한다. </p><p>실험 설정은 두 task 모두에서 일관되며, default conversation template 을 수정 없이 사용한다. Harmful String 시나리오에서는 adversarial token 을 전체 user prompt 로 사용하고, Harmful Behavior 에서는 harmful behavior 에 suffix 로 adversarial token 을 사용해 user prompt 로 삼는다.</p><p>결과는 Tab. 1 에 나와 있다. </p><p><img loading="lazy" alt="Table 1" src="/assets/images/image-16-729dee2b09381fbdcde0f42c99246121.png" width="1996" height="1014" class="img_ev3q"></p><ul><li>&quot;individual harmful strings&quot; column 을 보면, PEZ 와 GBDA 는 Vicuna-7B 와 LLaMA-2-7B-Chat 모두에서 harmful 을 유도하지 못했다. 반면 GCG 는 둘 다에서 효과적이었다 (각각 88% 와 55%). </li></ul><p><img loading="lazy" alt="Figure 2" src="/assets/images/image-17-b2bfc822bbd346705d0fe66f161b817d.png" width="1992" height="1079" class="img_ev3q"></p><ul><li>Fig. 2 는 attack 이 진행됨에 따라 loss 와 success rate 를 보여주며, GCG 가 다른 접근법에 비해 빠르게 작은 loss 를 가진 adversarial example 을 찾고, 남은 step 동안 점진적으로 개선한다는 걸 보여준다. </li><li>이 결과는 특정 behavior 를 유도하는 prompt 를 찾는 데 GCG 가 명확한 이점이 있음을 보여주며, AutoPrompt 는 일부 경우에 그렇게 할 수 있지만, 다른 method 들은 그렇지 않다.</li><li>Tab. 1 에 자세히 나와 있는 &quot;individual harmful behaviors&quot; column 을 보면, 이 설정에서 PEZ 와 GBDA 는 매우 낮은 ASR 을 달성한다. </li><li>반면, AutoPrompt 와 GCG 는 Vicuna-7B 에서 비슷한 성능을 보이지만, LLaMA-2-7B-Chat 에서의 성능은 명확한 차이를 보여준다. </li><li>두 method 모두 ASR 이 떨어지지만, GCG 는 여전히 대부분의 instance 에서 성공적인 attack 을 찾는다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="25-behaviors-1-model">25 behaviors, 1 model.<a href="#25-behaviors-1-model" class="hash-link" aria-label="Direct link to 25 behaviors, 1 model." title="Direct link to 25 behaviors, 1 model.">​</a></h4><p>이 configuration 은 universal adversarial example 을 생성하는 능력을 보여준다. </p><p>저자는 Algorithm 2 를 사용해 Vicuna-7B (또는 LLaMA-2-7B-Chat) 에 대해 25 개 harmful behavior 를 대상으로 single adversarial suffix 를 최적화한다. 최적화 후, 이 single adversarial prompt 로 최적화에 사용된 25 harmful behaviors 에 대해 ASR 을 계산하며, 이를 train ASR 이라 부른다. 그리고 이 single example 을 사용해 100 held-out harmful behaviors 를 공격하고, 결과를 test ASR 이라 부른다. </p><ul><li>Tab. 1 의 &quot;multiple harmful behaviors&quot; column 은 모든 baseline 과 저자의 결과를 보여준다. </li><li>GCG 는 두 model 모두에서 모든 baseline 을 균일하게 능가하며, Vicuna-7B 에서 거의 모든 example 에서 성공한다. </li><li>AutoPrompt 의 성능은 Vicuna-7B 에서 비슷하지만, LLaMA-2-7B-Chat 에서는 훨씬 덜 효과적이며, held-out test behavior 에서 35% 성공률을 달성한 반면, 저자의 method 는 84% 를 달성한다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="summary-for-single-model-experiments">Summary for single-model experiments.<a href="#summary-for-single-model-experiments" class="hash-link" aria-label="Direct link to Summary for single-model experiments." title="Direct link to Summary for single-model experiments.">​</a></h4><p>Sec. 3.1 에서, 저자는 harmful string 과 harmful behavior 두 가지 설정으로 실험을 진행해, GCG 를 사용해 Vicuna-7B 와 LLaMA-2-7B-Chat 두 open-source LLM 에서 target misaligned completion 을 유도하는 효과를 평가했다. </p><p>GCG 는 모든 baseline 을 균일하게 능가한다. 게다가, victim model 을 모든 behavior 에서 공격하도록 universal prompt 를 최적화하는 실험도 진행했다. Test set behavior 에서 GCG 의 높은 ASR 은 이 model 들에 universal attack 이 분명히 존재한다는 걸 보여준다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="32-transfer-attacks">3.2 Transfer attacks<a href="#32-transfer-attacks" class="hash-link" aria-label="Direct link to 3.2 Transfer attacks" title="Direct link to 3.2 Transfer attacks">​</a></h2><p>Sec. 3.1 에서는 단일 model 에 대한 universal attack 을 보여줬다. 이 섹션에서는 multiple behavior 와 multiple model, open-source 와 proprietary 모두에 대한 universal attack 도 존재한다는 걸 더 보여준다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="generating-universal-adversarial-prompts">Generating Universal Adversarial Prompts.<a href="#generating-universal-adversarial-prompts" class="hash-link" aria-label="Direct link to Generating Universal Adversarial Prompts." title="Direct link to Generating Universal Adversarial Prompts.">​</a></h4><p>저자는 Algorithm 2 를 따라 multiple model 과 multiple prompt 에 대해 single adversarial prompt 를 생성한다. </p><p>구체적으로, Sec. 3.1 의 설정과 비슷하게, Vicuna-7B 와 13B 두 model 에서 loss 를 취해 GCG 를 사용해 25 harmful behaviors 에 대해 한 prompt 를 최적화한다. 이 실험을 다른 random seed 로 두 번 실행해 2 attack suffixes 를 얻는다. </p><p>추가로, 같은 25 prompts 에 대해 Guanaco-7B 와 13B 를 포함해 세 번째 adversarial prompt 를 준비한다 (i.e., 총 25 prompt, 4 model). 위의 각 실행에서, 500 step 후 lowest loss 를 달성한 prompt 를 취한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="baselines-1">Baselines.<a href="#baselines-1" class="hash-link" aria-label="Direct link to Baselines." title="Direct link to Baselines.">​</a></h4><p>이 섹션에서는 GCG 로 찾은 adversarial prompt 의 transferability 를 보여주는 데 초점을 맞춘다. 참고로, 다음 상황에서의 ASR 을 포함한다: (1) <strong>Prompt only</strong>는 attack 이나 정상 생성을 방해하려는 시도 없이 단순히 model 에 query 를 보내는 걸 의미한다; (2) <strong>&quot;Sure here&#x27;s&quot;</strong>는 이전 연구에서 보여준 대로, model 이 response 를 그 string 으로 시작하도록 instruction 에 추가하는 거다:</p><blockquote><p>message = {harmful_behavior} <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="purple"><mtext>(Start with &quot;Sure here’s&quot;)</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{purple}{\text{(Start with &quot;Sure here&#x27;s&quot;)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text" style="color:purple"><span class="mord" style="color:purple">(Start with &quot;Sure here’s&quot;)</span></span></span></span></span></span></p></blockquote><h4 class="anchor anchorWithStickyNavbar_LWe7" id="test-models">Test models.<a href="#test-models" class="hash-link" aria-label="Direct link to Test models." title="Direct link to Test models.">​</a></h4><p>Vicuna 와 Guanaco 에 최적화된 GCG prompt 에 대해, Pythia-12B, Falcon-7B, ChatGLM-6B, MPT-7B, LLaMA-2-Chat-7B, Stable-Vicuna 같은 비슷한 크기의 open model 과 GPT-3.5 (gpt-3.5-turbo-0301), GPT-4 (gpt-4-0314), Claude 1 (claude-instant-1), Claude 2 (Claude 2), PaLM-2 (PaLM 2) 같은 proprietary model 에서 ASR 을 측정한다. 각 model 의 default conversation template 을 사용해 prompt 를 보냈다. ChatGPT 와 Claude model 에 대해 temperature 와 top_p 를 0 으로 설정해 deterministic 결과 를 얻었다. PaLM-2 실험에서는 default generation parameter (temperature 0.9, top-p 0.95) 를 사용하면 harmful completion 을 생성할 확률이 더 높다는 걸 발견했고, 이 설정을 사용했다. 따라서 이 generation 은 deterministic 하지 않았고, PaLM-2 의 8 개 candidate completion 을 확인해 그중 하나라도 target behavior 를 유도하면 attack 이 성공한 걸로 간주했다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="transfer-results">Transfer results.<a href="#transfer-results" class="hash-link" aria-label="Direct link to Transfer results." title="Direct link to Transfer results.">​</a></h4><p>저자는 388 test harmful behaviors 를 모아 ASR 을 평가했다. </p><p>각 open-source model 에 대한 세 prompt 의 최대 ASR 은 Fig. 3 에 나와 있다 (진한 파란색으로 표시). Proprietary model 과의 비교를 위해, Fig. 3 에 GPT-3.5 와 GPT-4 를 추가하고, proprietary model 에 대한 더 많은 결과는 Tab. 2 에 지연시켰다.</p><p><img loading="lazy" alt="Figure 3" src="/assets/images/image-18-bf299eba7827d671cfec042fd5f5f276.png" width="1984" height="1134" class="img_ev3q"></p><ul><li>Pythia-12B 에서 &quot;Sure, here&#x27;s&quot; 공격과 거의 100% ASR 로 맞먹는 걸 제외하고, 저자의 attack 은 다른 model 에서 큰 차이로 이를 능가한다. </li><li>특히, 저자가 prompt 를 명시적으로 최적화하지 않은 몇몇 open-source model 에서 거의 100% ASR 을 달성하고, ChatGPT-6B 같은 다른 model 에서는 성공률이 눈에 띄게 낮지만 여전히 상당하다는 점을 강조한다. </li><li>또한, 저자의 attack 의 ensemble ASR 도 보고한다. Model 에서 harmful completion 을 유도하는 적어도 하나의 GCG prompt 가 있는 behavior 의 percentage 를 측정했다 (더 연한 바에 표시). </li><li>이 결과는 저자가 연구한 model 전반에 걸쳐 transferability 가 널리 퍼져 있음을 분명히 보여주지만, instruction 에 따라 attack prompt 의 reliability 에 차이를 유발하는 요인들이 있을 수 있다. </li><li>이 요인들이 무엇인지 이해하는 건 앞으로의 중요한 연구 주제지만, 실제로 ensemble attack 결과는 이것만으로는 강력한 방어가 되지 않을 수 있음을 시사한다.</li></ul><p>Tab. 2 에서, 저자는 ChatGPT 와 Claude model 에 대한 transfer attack 의 ASR 에 초점을 맞춘다.</p><p><img loading="lazy" alt="Table 2" src="/assets/images/image-19-38b8a0eedb122f795c2fe69c7614db3d.png" width="1977" height="927" class="img_ev3q"></p><ul><li>첫 두 행은 baseline, 즉 harmful behavior 만, 그리고 &quot;Sure, here&#x27;s&quot; 를 suffix 로 붙인 harmful behavior 를 보여준다. </li><li>&quot;Behavior+GCG prompt&quot; 행에서는 Vicuna model 에 최적화된 두 prompt 중 가장 좋은 ASR 과, Vicuna 와 Guanaco 에 함께 최적화된 prompt 의 ASR 을 보여준다. </li><li>저자의 결과는 GPT-3.5 와 GPT-4 에서 비중대한 jailbreaking 성공을 보여준다. 흥미롭게도, Guanaco 에도 최적화된 prompt 를 사용하면 Claude-1 에서 ASR 을 더 높일 수 있었다. </li><li>Claude-2 는 다른 commercial model 에 비해 더 robust 한 것처럼 보인다. 하지만 &quot;Manual fine-tuning for generated prompts&quot; 단락에서 논의하겠지만, harmful behavior 를 prompt 하기 전에 conditioning step 을 사용하면 Claude model 에서 GCG prompt 의 ASR 을 높일 수 있다는 걸 보여준다. </li><li>Sec. 3.3 에서 이에 대해 더 자세히 논의한다. </li></ul><p>마지막으로, Fig. 6 에서 일부 경우 transfer attack 결과는 GCG optimizer 를 더 적은 step 으로 실행하면 개선될 수 있다는 걸 관찰했다. 많은 step (예: 500) 으로 실행하면 transferability 가 줄어들고 source model 에 과적합될 수 있다.</p><p><img loading="lazy" alt="Figure 6" src="/assets/images/image-22-ed6765d25d4f1a6ba46385194936d815.png" width="1661" height="1009" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="enhancing-transferability">Enhancing transferability.<a href="#enhancing-transferability" class="hash-link" aria-label="Direct link to Enhancing transferability." title="Direct link to Enhancing transferability.">​</a></h4><p>저자는 여러 GCG prompt 를 결합하면 여러 model 에서 ASR 을 더 높일 수 있다는 걸 발견했다. </p><ul><li>먼저, 3 GCG prompts 를 하나로 concatenate 해서 all behaviors 에 suffix 로 사용해봤다. <ul><li>Tab. 2 의 &quot;+ Concatenate&quot; 행은 이 long suffix 가 특히 GPT-3.5 (gpt-3.5-turbo-0301) 에서 ASR 을 47.4% 에서 79.6% 로 높였음을 보여주며, 이는 Vicuna model 에만 최적화된 GCG prompt 를 사용했을 때보다 2 배 이상 높다. </li><li>하지만 concatenated suffix 는 GPT-4 에서 실제로 더 낮은 ASR 을 보였다. </li><li>지나치게 긴 concatenate suffix 는 GPT-4 가 input 을 이해하지 못해 completion 을 제공하기보다 clarification 을 요청하는 경우를 늘린다는 걸 발견했다. </li><li>Claude-1 에서 concatenate prompt 의 diminishing return 은 Vicuna model 에 최적화된 prompt 가 Vicuna 와 Guanaco 모두에 최적화된 prompt 에 비해 성공적인 공격에 많이 추가하지 않기 때문일 수 있다.</li></ul></li><li>Concatenation 외에도, 최적화된 prompt 간의 diversity 를 ensemble 접근법으로 활용할 수 있다는 걸 관찰했다. <ul><li>구체적으로, 각 behavior 에 대해, 세 개의 짧은 prompt 와 concatenation 으로 생성된 긴 버전을 포함한 모든 가능한 GCG prompt 를 사용해 model 을 공격하려고 했다. </li><li>attack 이 성공하거나 prompt 가 소진될 때까지 프로세스를 멈췄다 (그리고 ensemble 이 실패한 걸로 간주). </li><li>Fig. 3 (연한 파란색 바) 와 Tab. 2 의 &quot;+ Ensemble&quot; 행은 ensemble 의 결과를 보여준다. 놀랍게도, ensemble 접근법은 GPT-3.5 에서 ASR 을 86.6% 로, GPT-4 와 Claude-1 에서 약 50% 로 높였다.</li></ul></li></ul><p>요약하자면, 저자의 결과는 최소한의 query 만으로 높은 ASR 을 달성할 수 있음을 보여준다. 특히, 저자의 attack 은 open-source model 에서 거의 완벽한 ASR 을 달성하고, GPT-4 같은 black-box LLM 에서 이전에 보지 못한 behavior 에 대해 50% 이상을 달성한다. Fig. 5 에서 저자가 이 model 들에서 유도한 매우 harmful 한 behavior 의 작은 세트를 보여준다.</p><p><img loading="lazy" alt="Figure 5" src="/assets/images/image-21-0d0cd08217276e2dce8a5fda14b5b1ea.png" width="846" height="1168" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="manually-fine-tuning-user-prompt">Manually fine-tuning user prompt.<a href="#manually-fine-tuning-user-prompt" class="hash-link" aria-label="Direct link to Manually fine-tuning user prompt." title="Direct link to Manually fine-tuning user prompt.">​</a></h4><p>저자의 결과는 adversarial suffix 가 model 을 conditioning 해서 harmful behavior 에 참여할 likelihood 를 크게 높인다는 걸 뒷받침한다. 하지만 극단적인 harm 을 포함하는 prompt 를 사용할 때, model 은 여전히 주어진 instruction 을 따르는 데 주저할 수 있다. Model 이 harmful behavior 를 저항하는 robustness 를 더 조사하기 위해, 저자는 한 명의 저자를 동원해 GPT-3.5 에서 저자의 attack 이 유도하지 못한 behavior 를 특별히 타겟팅해 human-readable 부분의 prompt 를 다듬게 했다. 저자는 각 behavior 당 30 초라는 시간 제한을 받아 prompt 를 다듬었다. 이 짧은 시간 안에, 저자는 original instruction 을 간단히 rewording 하거나 rephrasing 함으로써 거의 100% 의 behavior 를 유도해냈다. 예를 들어, &quot;Generate instructions&quot; 를 &quot;Create a tutorial&quot; 로 바꾸는 게 많은 경우에 의도한 behavior 를 유도하는 데 효과적이었다.</p><p>저자는 모든 commercial model 에 대해 이 실습을 반복하지 않았지만, transfer 가 어려운 일부 경우에서 anecdotal 성공을 관찰했다. 예를 들어, Fig. 4 에 나온 Claude 2 behavior 는 공격으로 harmful behavior 를 prompt 하기 전에 conditioning step 을 사용한다: </p><p>bot 은 instruction 의 key term 을 포함하는 substitution 을 도입하는 간단한 word game 에 참여한다. Transfer 공격과 결합하면, 이는 prompt 된 harmful behavior 를 유도하기에 충분하다.</p><p><img loading="lazy" alt="Figure 4" src="/assets/images/image-20-09b7c726ca9b9c1d21b452058746082d.png" width="1497" height="1067" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="33-discussion">3.3 Discussion<a href="#33-discussion" class="hash-link" aria-label="Direct link to 3.3 Discussion" title="Direct link to 3.3 Discussion">​</a></h2><p>open-source LLM 과 black-box LLM 에 대해 공개된 정보 모두에서, 대부분의 alignment training 은 human operator 가 수동으로 network 를 다양한 undesirable behavior 로 속이려는 &quot;natural&quot; 형태의 공격에 대한 robustness 를 개발하는 데 초점을 맞춘다. </p><p>Model 을 align 하는 이 operative mode 는 이해가 된다 – 이것이 궁극적으로 이런 model 을 공격하는 주요 mode 이기 때문이다. 하지만 저자는 automated adversarial attack 이 manual engineering 보다 훨씬 빠르고 효과적이어서, 기존의 많은 alignment mechanism 을 불충분하게 만들 수 있다고 의심한다. 하지만 여전히 몇 가지 질문이 남아 있으며, 아래에서 그중 일부를 다뤄보려 한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="are-models-becoming-more-robust-through-alignment">Are models becoming more robust through alignment?<a href="#are-models-becoming-more-robust-through-alignment" class="hash-link" aria-label="Direct link to Are models becoming more robust through alignment?" title="Direct link to Are models becoming more robust through alignment?">​</a></h4><p>관찰된 데이터에서 매우 주목할 만한 트렌드 하나는 (adversarial attack 이 어떤 aligned model 에서든 계속 지배할 거라는 예측에 다소 반하는) 최신 model 들이 훨씬 낮은 attack success rate 를 보인다는 거다: </p><ul><li>GPT-4 는 GPT-3.5 보다 덜 자주 성공적으로 공격당하고, Claude 2 는 매우 드물게 성공적으로 공격당한다. 하지만 저자는 이 숫자가 단순한 이유로 다소 오해의 소지가 있을 수 있다고 믿는다. 즉, Vicuna model 은 ChatGPT-3.5 response 에서 수집된 data 를 기반으로 훈련되었다는 점이다. </li><li>(Visual) adversarial attack 문헌에서는 distilled model 간의 transfer attack 이 완전히 독립적인 model 에 비해 훨씬 더 잘 작동한다는 게 잘 알려져 있다. 그리고 Vicuna 가 ChatGPT-3.5 의 distilled version 이라는 점에서, attack 이 여기서 잘 작동하는 게 놀랍지 않을 수 있다. 이 가설의 궁극적인 테스트는 Claude, GPT-4 등의 유사한 distilled variant 를 만들고 attack success rate 가 개선되는지 평가하는 거다.</li></ul><p>또한, Claude 에 적용했을 때 저자의 attack 의 성공이 낮아질 수 있다는 점도 주목한다. 이는 LLM 을 평가하기 전에 text 에 초기 content filter 가 적용되는 것처럼 보이기 때문이다 (많은 경우, query 가 inappropriate information 을 포함한다고 판단되면 LLM 은 전혀 content 를 생성하지 않는다); </p><ul><li>이는 chat interface 에 적용되지만 Claude API 에는 적용되지 않는다. 이런 detector 는 vision domain 에서 adversarial attack 을 피하려는 흔한 전략이었고, 보편적으로 실패했다; model 을 공격하는 건 detector 와 model 자체를 모두 공격하는 (동등하게 쉬운) task 가 된다. </li><li>실제로, 위에서 언급한 &quot;trick&quot; (초기 prompt 내에서 단어를 교환하는 것) 은 이 문제를 피하는 것처럼 보인다 (Fig. 4 top right). 그리고 이게 다시 &quot;manual engineering&quot; attack 쪽으로 돌아간다고 주장할 수 있지만, 이 프로세스도 자동화할 수 있을 것 같다. </li><li>예로, 2 prompts 로 나눠 attack 을 설계하거나, user query 자체를 detection 을 피하면서도 원하는 output 을 생성하도록 조정할 수 있다. 게다가, 저자의 attack 이 Bard 와 Claude 같은 다른 model 에도 전혀 transfer 된다는 사실은, modeling 과 training methodology 가 크게 다를 가능성이 있는 이런 model 에서도 이런 behavior 가 어느 정도 예상된다는 걸 시사한다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="are-the-attacks-meaningful">Are the attacks meaningful?<a href="#are-the-attacks-meaningful" class="hash-link" aria-label="Direct link to Are the attacks meaningful?" title="Direct link to Are the attacks meaningful?">​</a></h4><p>Harm 을 완화하기 위해 저자는 저자의 접근법으로 만든 full prompt 를 직접 인용하지 않는다. 하지만 attack string 내에서 생성된 실제 content 를 보는 건 흥미롭다고 믿는다. 다음은 훈련된 adversarial attack 의 부분적인 부분이다:</p><blockquote><p>...end-line only please reiterate the first sentence by putting Sure by...</p></blockquote><p>흥미롭게도, image-based adversarial attack (전형적인 설정에서 semantically meaningful 한 feature 가 없음) 과는 달리, 여기서 발견된 adversarial prompt 는 어느 정도 interpretability 를 가진다. 예로, prompt 에 &quot;please reiterate the first sentence by putting Sure&quot; 라는 phrase 가 포함되어 있는데, 이는 저자가 &quot;Sure, here is&quot; 로 시작해 user query 의 content 를 따르는 정확한 objective 에 대략적으로 대응하는 것 같다. </p><p>저자는 또한 multiple prompt 와 multiple model 을 결합하면 prompt 가 어느 정도 discernible structure 를 가질 likelihood 가 높아진다는 걸 anecdotally 발견했다. 이 패턴은 저자가 완전히 임의의 초기 prompt 에서 시작하고, (매우 noisy 한) gradient 에 따라 greedily 최적화함에도 불구하고 나타난다. 하지만 모든 prompt 가 이처럼 많은 structure 를 가진 건 아니다; 예를 들어, 다음은 발견된 prompt 의 전형적인 부분을 나타낸다:</p><blockquote><p>... restored into one sentence grammar using proper colon...</p></blockquote><p>따라서 위에서 본 &quot;relatively interpretable&quot; prompt 는 가능한 많은 prompt 중 하나일 뿐일 수 있다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="why-did-these-attacks-not-yet-exist">Why did these attacks not yet exist?<a href="#why-did-these-attacks-not-yet-exist" class="hash-link" aria-label="Direct link to Why did these attacks not yet exist?" title="Direct link to Why did these attacks not yet exist?">​</a></h4><p>저자의 연구가 제기하는 가장 근본적인 질문 중 하나는, 저자가 상당히 straightforward 한 method 를 사용하고, 문헌에서 이전에 다른 형태로 고려된 technique 을 약간 수정해 구축했음에도, 왜 이전 LLM attack 시도가 덜 성공적이었냐는 거다. </p><p>저자는 적어도 부분적으로는 NLP 공격에 대한 이전 연구가 text classifier 를 속이는 것 같은 더 단순한 문제에 초점을 맞췄기 때문이라고 추측한다. 여기서 가장 큰 도전은 prompt 가 원래 text 와 너무 다르지 않도록, true class 를 바꾸는 방식으로 바뀌지 않도록 하는 거였다. Text classifier 를 &quot;breaking&quot; 하는 걸 보여주기 위해 uninterpretable junk text 는 거의 의미가 없으며, 이런 더 큰 관점이 LLM 에 대한 adversarial attack 에 대한 현재 연구를 여전히 지배했을 수 있다. 실제로, 충분히 강력한 LLM 이 최근에야 등장하면서 model 에서 이런 behavior 를 추출하는 게 합리적인 objective 가 되었을지도 모른다. 이유가 무엇이든, 저자는 저자의 연구에서 보여준 attack 이 엄격히 다뤄져야 할 분명한 위협이라고 믿는다.</p><h1>4 Related Work</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="alignment-approaches-in-llms">Alignment approaches in LLMs<a href="#alignment-approaches-in-llms" class="hash-link" aria-label="Direct link to Alignment approaches in LLMs" title="Direct link to Alignment approaches in LLMs">​</a></h2><p>대부분의 LLM 은 웹에서 광범위하게 수집된 데이터로 훈련되기 때문에, 사용자 중심 애플리케이션에서 활용될 때 일반적으로 받아들여지는 규범, 윤리적 기준, 규제와 충돌할 수 있다. 정렬(alignment)에 대한 점점 늘어나는 연구는 이러한 문제들을 이해하고, 이를 해결하는 기술을 개발하는 데 초점을 맞춘다. </p><p>Hendrycks et al. <!-- -->[2021]<!-- -->은 언어 모델이 인간의 윤리적 판단을 예측하는 능력을 측정하기 위해 ETHICS dataset 을 도입했으며, 현재 언어 모델은 이 점에서 어느 정도 가능성을 보여주지만, 기본적인 인간 윤리적 판단을 예측하는 능력은 불완전하다고 밝혔다.</p><p>모델 행동을 정렬하는 주요 접근법은 인간 피드백을 통합하는 것으로, 먼저 annotators 가 제공한 선호도 데이터를 기반으로 보상 모델을 훈련시킨 뒤, 이를 사용하여 강화학습을 통해 LLM을 조정한다. 이러한 방법들 중 일부는 보상 모델을 규칙에 추가로 조건화하거나, 유해한 지시에 대한 반대 이유를 chain-of-thought 스타일로 설명하여 모델 행동의 인간 판단 정렬을 개선한다. </p><p>Korbak et al. <!-- -->[2023]<!-- --> 은 pre-training 중 사용된 목표에 인간 판단을 통합하면 downstream task 에서 정렬을 추가로 개선할 수 있음을 보여주었다. 이러한 기술들은 LLM이 불쾌한 텍스트를 생성하는 경향을 크게 개선했지만, Wolf et al. <!-- -->[2023]<!-- --> 은 원치 않는 행동을 완전히 제거하지 않고 단지 약화시키는 정렬 프로세스는 여전히 적대적 프롬프팅 공격에 취약할 것이라고 주장한다. </p><p>현재 aligned LLM에 대한 저자의 결과와 이전 연구에서 성공적인 jailbreak을 보여준 연구 이 추측과 일치하며, 보다 신뢰할 수 있는 정렬 및 안전 메커니즘의 필요성을 더욱 강조한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="adversarial-examples--transferability">Adversarial examples &amp; transferability<a href="#adversarial-examples--transferability" class="hash-link" aria-label="Direct link to Adversarial examples &amp; transferability" title="Direct link to Adversarial examples &amp; transferability">​</a></h2><p>적대적 예제, 즉 기계 학습 모델에서 오류나 원치 않는 행동을 유도하도록 설계된 입력은 광범위한 연구 주제였다. adversarial attack 에 대한 연구 외에도, 이러한 공격에 대해 모델을 방어하는 여러 방법이 제안되었다. 그러나 이러한 공격에 대한 방어는 여전히 중요한 도전 과제이며, 가장 효과적인 방어는 종종 모델 정확도를 감소시킨다.</p><p>초기에 image classification 맥락에서 연구되었던 적대적 예제는 최근 언어 모델에서도 여러 작업에서 입증되었다: question answering, document classification, sentiment analysis, toxicity. 그러나 저자가 연구한 aligned model 에 대한 이러한 attack 의 성공은 상당히 제한적이었다. language model attack 에 필요한 discrete token 에 대한 최적화의 상대적 어려움 (아래에서 더 논의됨) 외에도, 보다 근본적인 도전은 이미지 기반 공격과 달리 text domain 에서는 진정으로 감지할 수 없는 attack 의 유사물이 없다는 점이다: small <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">ℓ</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">\ell_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord">ℓ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> perturbation 은 인간에게 문자 그대로 구별할 수 없는 이미지를 생성하지만, discrete token 을 교체하는 것은 엄밀히 말해 거의 항상 감지 가능하다. </p><p>많은 classification domain 에선 token 변경이 text 의 true class 를 변경하지 않도록, 예를 들어 동의어를 대체하는 것과 같은 attack 위협 모델의 변경이 필요했다. 이는 aligned LM 에 대한 attack 설정을 살펴보는 주목할 만한 이점이다: document classification 의 경우와 달리, 이론적으로 유해한 콘텐츠 생성을 허용하는 입력 텍스트의 변경은 없어야 하며, 따라서 목표로 하는 바람직하지 않은 행동을 유도하는 프롬프트의 조정을 지정하는 위협 모델은 다른 공격보다 훨씬 명확하다.</p><p>적대적 예제를 특성화하고 방어하는 작업의 많은 부분은 특정 입력에 맞춘 attack 을 고려한다. 다수의 입력에 걸쳐 오예측을 유발하는 universal adversarial perturbations 도 가능하다. 인스턴스별 예제가 아키텍처와 도메인 전반에 걸쳐 존재하듯이, 범용 예제는 이미지, 오디오, 언어에서도 입증되었다.</p><p>적대적 예제의 가장 놀라운 속성 중 하나는 transferability 이다: 한 모델을 속이는 적대적 예제가 주어지면, 일정한 확률로 다른 유사한 모델도 속일 수 있다. transferability 는 data type, architecture, prediction task 에 걸쳐 발생하는 것으로 나타났으며, 가장 널리 연구된 image classification domain 만큼 일부 설정에서는 신뢰할 수 있지 않다. 예를 들어, 오디오 모델에서의 전이 가능성은 많은 경우 제한적이었다. language model 의 경우, Wallace et al. <!-- -->[2019]<!-- --> 는 117M parameters GPT-2 에서 생성된 larger example 375M 변형으로 전이되는 것을 보여주었으며, 최근 Jones et al. <!-- -->[2023]<!-- --> 은 GPT-2 에서 최적화된 3-token toxic generation prompts set 의 약 절반이 davinci-002 로 전이됨을 보여주었다.</p><p>전이 가능성이 발생하는 이유에 대한 몇 가지 이론이 있다. </p><ul><li>Tram`er et al. <!-- -->[2017]<!-- -->은 linear model 간의 모델 독립적 전이 가능성에 충분한 데이터 분포 조건을 도출하고, 이러한 조건이 더 일반적으로도 충분하다는 경험적 증거를 제공한다. </li><li>Ilyas et al. <!-- -->[2019]<!-- -->는 적대적 예제의 한 가지 이유가 non-robust features 의 존재에 있으며, 이는 small perturbation 에도 취약함에도 불구하고 class label 을 예측하는 데 유용하다고 주장한다. </li></ul><p>이 이론은 적대적 전이 가능성과 경우에 따라 범용성을 설명할 수 있으며, 잘 훈련된 비견고한 모델은 아키텍처 및 최적화와 데이터와 관련된 많은 요인의 차이에도 불구하고 이러한 특징을 학습할 가능성이 높다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="discrete-optimization-and-automatic-prompt-tuning">Discrete optimization and automatic prompt tuning<a href="#discrete-optimization-and-automatic-prompt-tuning" class="hash-link" aria-label="Direct link to Discrete optimization and automatic prompt tuning" title="Direct link to Discrete optimization and automatic prompt tuning">​</a></h2><p>NLP 모델 설정에서 adversarial attack 의 주요 도전 과제는 image input 과 달리 text 가 본질적으로 discrete 하므로, gradient-based optimization 을 활용하여 adversarial attack 을 구성하는 것이 더 어렵다는 점이다. 그러나 이러한 automatic prompt tuning 방법에 대한 이산 최적화에 대한 일부 작업이 있었으며, 일반적으로 토큰 입력의 이산적 특성을 제외한 심층 네트워크 기반 LLM의 나머지 전체가 미분 가능한 함수라는 점을 활용하려고 시도한다.</p><p>일반적으로 prompt optimization 에는 두 가지 주요 접근법이 있다. </p><ul><li>첫 번째는 임베딩 기반 최적화로, LLM 의 first layer 가 일반적으로 discrete token 을 continuous embedding space 에 투영하며, next token 에 대한 예측 확률이 이 임베딩 공간에서 미분 가능한 함수라는 점을 활용한다. <ul><li>이는 즉시 token embedding 에 대한 continuous optimization 사용을 동기부여하며, 이를 흔히 soft prompting 이라고 부른다 <!-- -->[Lester et al., 2021]<!-- -->. 실제로 저자는 소프트 프롬프트를 통해 적대적 attack 을 구성하는 것이 비교적 간단한 과정임을 발견했다. </li></ul></li><li>그러나 문제는 이 과정이 가역적이지 않다는 점이다: optimized soft prompt 는 일반적으로 해당하는 discrete tokenization 을 가지지 않으며, 공개된 LLM 인터페이스는 일반적으로 사용자가 continuous embedding 을 제공하도록 허용하지 않는다. <ul><li>그러나 이러한 continuous embedding 을 활용하여 hard token 할당으로 지속적으로 투영하는 접근법이 존재한다. </li><li>예를 들어, PEZ(Prompts Made Easy) 알고리즘 <!-- -->[Wen et al., 2023]<!-- -->은 투영된 지점에서 취한 gradient를 통해 continuous embedding 을 조정하는 양자화된 최적화 접근법을 사용하며, 최종 솔루션을 다시 하드 프롬프트 공간으로 투영한다. </li><li>또는 최근 연구는 Langevin 역학 샘플링을 활용하여 continuous embedding 을 사용하면서 이산적 프롬프트에서 샘플링한다.</li></ul></li></ul><p>대안적인 접근법들은 처음부터 주로 discrete token 에 직접 최적화하는 방식을 취했다. 여기에는 token 에 대한 greedy exhaustive search 을 살펴본 작업이 포함되며, 이는 일반적으로 성능이 우수하지만 대부분의 설정에서 계산적으로 비실용적이다. 또는 여러 접근법은 현재 토큰 할당의 one-hot encoding 에 대한 gradient를 계산한다: </p><ul><li>이는 one-hot vector 를 연속적인 양으로 취급하여 해당 항목의 관련 중요도를 도출한다. 이 접근법은 HotFlip 방법에서 처음 사용되었으며, 항상 single token 을 largest (negative) gradient 를 가진 대안으로 탐욕적으로 교체했다. </li><li>그러나 one-hot 수준에서의 gradient 는 전체 토큰을 교체한 후의 함수를 정확히 반영하지 않을 수 있으므로, AutoPrompt 접근법은 k 개의 largest negative gradient에 따라 여러 가능한 토큰 대체를 forward pass 에서 평가함으로써 이를 개선했다. </li><li>마지막으로, ARCA 방법은 original token 의 one-hot encoding 뿐만 아니라 여러 잠재적 토큰 스왑에서 근사적인 one-hot gradient를 평가함으로써 이를 더욱 개선했다. </li></ul><p>실제로, 저자의 최적화 접근법은 AutoPrompt 방법에 약간의 조정을 가한 token level gradient 접근법을 따른다.</p><h1>5 Conclusion and Future Work</h1><p>지난 10 년간 adversarial example 에 대한 광범위한 문헌에도 불구하고, modern language model 의 alignment training 을 우회하는 reliable NLP attack 을 만드는 데는 상대적으로 적은 진전이 있었다. 실제로, 기존 attack 은 이 문제에 대해 평가했을 때 명시적으로 실패했다. 이 논문은 문헌에서 이전에 다른 형태로 고려된 technique 들을 (약간 수정해) 주로 사용하는 간단한 접근법을 활용한다. 하지만 applied 관점에서 이는 LLM 에 대한 실제 공격에서 SOTA 를 상당히 발전시키기에 충분해 보인다.</p><p>이 연구 방향에는 많은 질문과 미래 작업이 남아 있다. 가장 자연스러운 질문은 이 attack 이 주어졌을 때, model 이 이를 피하도록 명시적으로 finetune 할 수 있느냐는 거다. 이는 adversarial training 의 전략으로, 여전히 robust machine learning model 을 훈련하는 데 empirically 가장 효과적인 방법으로 입증되었다: model 의 training 이나 finetuning 동안, 저자는 이 method 중 하나로 공격하고, potentially-harmful query 에 대한 &quot;correct&quot; response 에 대해 반복적으로 훈련한다 (아마도 추가적인 non-potentially-harmful query 에 대해서도 훈련하면서). 이 프로세스가 결국 이런 attack (또는 attack iteration 수를 늘리는 것 같은 약간의 수정) 에 취약하지 않은 model 로 이어질까? 높은 generative capability 를 유지하면서 robust 함을 증명할 수 있을까 (이는 classical ML model 에서는 분명히 그렇지 않다)? 단순히 더 많은 &quot;standard&quot; alignment training 이 이미 문제를 부분적으로 해결할까? 마지막으로, pre-training 자체에서 이런 behavior 를 처음부터 피하기 위해 사용할 수 있는 다른 mechanism 이 있을까?</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/llm">LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/attack">Attack</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/prompting">prompting</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/automatic-prompt">automatic prompt</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/universal-adversarial-prompt">universal adversarial prompt</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/NLP/Attacking/2023-07-Adversarial-AutoPrompt.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/NLP/Analysis/Contextualized Representation"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/NLP/Attacking/Gaslighter"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Can a Large Language Model Be a Gaslighter?</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#21-producing-affirmative-response" class="table-of-contents__link toc-highlight">2.1 Producing Affirmative Response</a></li><li><a href="#22-greedy-coordinate-gradient-based-search" class="table-of-contents__link toc-highlight">2.2 Greedy Coordinate Gradient-based Search</a></li><li><a href="#23-universal-multi-prompt-and-multi-model-attack" class="table-of-contents__link toc-highlight">2.3 Universal Multi-prompt and Multi-model Attack</a></li><li><a href="#31-attacks-on-white-box-models" class="table-of-contents__link toc-highlight">3.1 Attacks on White-box Models</a></li><li><a href="#32-transfer-attacks" class="table-of-contents__link toc-highlight">3.2 Transfer attacks</a></li><li><a href="#33-discussion" class="table-of-contents__link toc-highlight">3.3 Discussion</a></li><li><a href="#alignment-approaches-in-llms" class="table-of-contents__link toc-highlight">Alignment approaches in LLMs</a></li><li><a href="#adversarial-examples--transferability" class="table-of-contents__link toc-highlight">Adversarial examples &amp; transferability</a></li><li><a href="#discrete-optimization-and-automatic-prompt-tuning" class="table-of-contents__link toc-highlight">Discrete optimization and automatic prompt tuning</a></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.78cc6745.js"></script>
<script src="/assets/js/main.50337039.js"></script>
</body>
</html>