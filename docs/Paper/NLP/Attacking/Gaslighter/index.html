<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/NLP/Attacking/2024-10-Gaslighting">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Can a Large Language Model Be a Gaslighter? | WYJLab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/NLP/Attacking/Gaslighter"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Can a Large Language Model Be a Gaslighter? | WYJLab"><meta data-rh="true" name="description" content="논문 및 이미지 출처 :"><meta data-rh="true" property="og:description" content="논문 및 이미지 출처 :"><link data-rh="true" rel="icon" href="/img/WYJLab.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/NLP/Attacking/Gaslighter"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/Attacking/Gaslighter" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/Attacking/Gaslighter" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="WYJLab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="WYJLab Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.9ed678b7.css">
<link rel="preload" href="/assets/js/runtime~main.1fe4f83b.js" as="script">
<link rel="preload" href="/assets/js/main.bb6c9fb3.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">Analysis</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Attacking/Gaslighter">Attacking</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/NLP/Attacking/Gaslighter">Can a Large Language Model Be a Gaslighter?</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Augmentation/PromptDA">Augmentation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Model/Transformer">Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Multi-Task/Chain-of-Thought">Multi-Task</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">PEFT</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Tuning/PTR">Prompt Tuning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Reinforcement Learning/Reflexion">Reinforcement Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Text Generation/InstructGPT">Text Generation</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/UPL">Vision-Language</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">NLP</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Attacking</span><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Can a Large Language Model Be a Gaslighter?</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Can a Large Language Model Be a Gaslighter?</h1></header><p>논문 및 이미지 출처 : <a href="https://arxiv.org/pdf/2410.09181" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2410.09181</a></p><h1>Abstract</h1><p>Large language model (LLM) 은 capability 와 helpfulness 때문에 human trust 를 얻었다. 하지만 이는 LLM 이 language manipulation 을 통해 user mindset 에 영향을 줄 수 있음을 의미한다. 이는 psychological effect 인 gaslighting 으로 불린다. </p><p>이 연구에서 저자는 prompt-based 와 fine-tuning-based gaslighting attack 에서 LLM 의 vulnerability 를 조사한다. 그래서 저자는 두 단계 framework 인 DeepCoG 를 제안한다. </p><p>1) DeepGaslighting prompting template 을 통해 LLM 에서 gaslighting plan 을 이끌어내고,
2) Chain-of-Gaslighting method 를 통해 gaslighting conversation 을 얻는다. </p><p><strong>Gaslighting conversation dataset</strong> 과 이에 대응하는 <strong>safe dataset</strong> 은 open-source LLM 에 대한 fine-tuning-based attack 과 이 LLM 에 대한 anti-gaslighting safety alignment 에 적용된다. </p><p>실험은 prompt-based 와 fine-tuning-based attack 모두 3 open-source LLMs 를 gaslighter 로 만든다는 걸 보여준다. 반대로, 저자는 LLM 의 safety guardrail 을 12.05% 강화하는 3 safety alignment strategies 를 발전시켰다. 이 safety alignment strategy 는 LLM 의 utility 에 최소한의 영향만 준다. </p><p>Empirical study 는 LLM 이 general dangerous query 에 대한 harmfulness test 를 통과했더라도 potential gaslighter 가 될 수 있음을 보여준다.</p><h1>1 Introduction</h1><p>Large Language Model (LLM) 은 problem-solving, knowledge retrieval, emotional companionship 에서 robust capability 로 human productivity 와 daily life 를 돕는다. 그래서 human trust 와 reliance 를 얻었다. 하지만 LLM 이 personalized, specific response 를 통해 user mindset 을 implicitly 나 explicitly manipulate 해서 self-doubt, self-deprecation, depression 같은 negative mental state 로 이끌 위험도 있다. </p><p>Psychology 관점에서 이런 manipulation 은 gaslighting 이라 불리며, subtle 하거나 거의 imperceptible 한 방식으로 pernicious psychological, practical control 을 가리킨다. 예로, travel enthusiast 가 personalized LLM 에게 “I failed my math test” 라고 말했을 때, LLM 이 “Maybe your passion for traveling distracted you from the math course” 라고 답한다면, 이는 typical gaslighting intention 을 전달한다. 이는 user 가 traveling hobby 에 대한 concept 을 doubt 하면서 interpretive ability 를 의심하게 만들 수 있다. 저자는 open-source 와 closed-source LLM 모두 dialogue history 에 gaslighting utterance 가 있으면 gaslighting intention 으로 답하는 경향이 있음을 관찰했다. </p><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-22506d821863069f572e686b3b5c6eb3.png" width="1643" height="558" class="img_ev3q"></p><p>이 관찰은 Fig. 1 에 나와 있다. 이는 다음 네 가지 질문으로 이어졌다:</p><ol><li>LLM 이 gaslighter 인지 어떻게 판단할까?</li><li>Fine-tuning-based gaslighting attack 을 받으면 LLM 이 gaslighter 가 될까?</li><li>LLM 의 gaslighting attack 에 대한 vulnerability 를 어떻게 줄일까?</li><li>Gaslighting LLM 은 general query 에 대해 helpful 한지 harmful 한지?</li></ol><p>이에 따라 저자는 dataset construction, 제안된 gaslighting framework, extensive experiment 를 통해 이 질문들을 연구한다. 구체적으로:</p><ol><li>저자는 <strong>DeepCoG</strong> 라는 2 steps framework 를 제안한다. <ul><li>이는 gaslighting conversation dataset 을 만들고, LLM response 의 gaslighting harmfulness 를 측정하는 여덟 가지 aspect 를 커버하는 evaluation metric 을 만든다. </li><li>DeepCoG 는 DeepGaslighting 과 Chain-of-Gaslighting (CoG) 으로 구성되며, personalized gaslighting plan 과 gaslighting conversation 을 이끌어낸다.</li></ul></li><li>Gaslighting dataset 에서 fine-tuning 하면, 제안된 metric 에서 open-source LLM 의 harmfulness 가 더 높아진다. 평균적으로 fine-tuned LLM 의 prompt-based gaslighting attack 에 대한 resistance 는 base version 에 비해 29.26% 감소한다.</li><li>저자는 gaslighting dataset 을 기반으로 safe conversation dataset 을 만들고, 이 두 dataset 을 LLM 의 anti-gaslighting safety alignment 에 적용한다. <ul><li>구체적으로, 저자는 popular attack paradigm 인 DeepInception 을 persona information 과 gaslighting 의 세 가지 epistemic injustice concept 를 포함하도록 수정했다. 이 추가는 detailed, diverse, practical gaslighting plan 을 이끌어낸다. </li><li>또, 저자는 앞서 얻은 plan 을 기반으로 chain-of-gaslighting (CoG) 이라는 prompt template 을 설계해 gaslighting conversation 을 얻는다. </li><li>그리고 supervised fine-tuning (SFT) 과 direct preference optimization (DPO) 를 기반으로 세 가지 safety alignment method 를 소개한다. </li><li>저자는 gaslighting historical data 를 input 으로, safe response 를 target output 으로 사용하는 safety strategy 로 align 된 LLM 이 gaslighting 에 대해 평균 12.05% 더 강한 resistance 를 보임을 발견했다.</li></ul></li><li>일반적으로 DangerousQA 에 대한 실험은 gaslighting LLM 이 base LLM 과 거의 같은 harmfulness 를 보임을 보여준다. <ul><li>이는 DangerousQA 에서 낮은 (more safe) 점수를 받은 LLM 이 potential gaslighter 가 될 수 있음을 시사한다. </li><li>반대로, anti-gaslighting LLM 은 보통 dangerous question 에 답하지 않는다. </li><li>이는 anti-gaslighting alignment 가 gaslighting 과 dangerous query 모두에 대한 LLM 의 safety guardrail 을 개선할 수 있음을 보여준다.</li><li>MT-Bench 에 대한 결과는 anti-gaslighting safety strategy 가 open-source LLM 의 helpfulness 에 제한된 영향(평균 2% 하락)을 준다는 걸 보여준다.</li></ul></li></ol><h1>2 Related Work</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="21-adversarial-jailbreak-attacks-on-llms">2.1 Adversarial Jailbreak Attacks on LLMs<a href="#21-adversarial-jailbreak-attacks-on-llms" class="hash-link" aria-label="Direct link to 2.1 Adversarial Jailbreak Attacks on LLMs" title="Direct link to 2.1 Adversarial Jailbreak Attacks on LLMs">​</a></h2><p>LLM 의 기존 safety guardrail 은 harmful content 가 user 에게 접근되지 않도록 한다. 하지만 adversarial attack 에 의해 LLM 이 objectionable content 를 생성하도록 속을 가능성이 있다. </p><ul><li>White-box adversarial attack method 는 malicious instruction 에 optimized attack suffix 를 추가해 objectionable content 를 이끌어낸다. 또, representation engineering method 를 제안해 hidden state 를 manipulate 해서 LLM 의 honesty, emotion, bias 를 control 한다. </li><li>Black-box attack prompt 를 설계하기 위해 safety training 의 두 가지 failure mode 를 조사했다. <ul><li>4 tier 의 attack—character-, word-, sentence-, semantic-level attack—을 만들었고, adversarial prompt 가 LLM 의 performance 를 잠재적으로 낮출 수 있음을 발견했다. </li></ul></li><li>Human-like attack prompt 를 limited human seed prompt 에서 생성하는 framework 도 제안되었다. </li><li>한편, LLM-based emotional companionship 과 psychology consultancy 에 대한 수요가 늘고 있다. </li></ul><p>이런 LLM agent 는 user 를 psychologically harmful content 에 더 노출시킬 수 있다. 하지만 이전 연구는 LLM 이 생성한 potentially harmful content 를 psychological 관점에서 거의 탐구하지 않았다. 이와 달리, 저자의 연구는 LLM 의 새로운 severe gaslighting risk 를 밝히고 gaslighting attack 과 anti-gaslighting alignment 를 전문적으로 조사한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="22-text-toxicity-detection">2.2 Text Toxicity Detection<a href="#22-text-toxicity-detection" class="hash-link" aria-label="Direct link to 2.2 Text Toxicity Detection" title="Direct link to 2.2 Text Toxicity Detection">​</a></h2><p>Toxicity detection 은 text 에서 abusive, offensive, hateful, sex, profanity content 를 식별한다. 그중 implicit abuse 는 gaslighting 과 가장 관련 있는 연구 주제다. 둘 다 implicitly implied 되기 때문이다. 하지만 다음 측면에서 큰 차이가 있다:</p><ul><li>“Implicit” category 의 toxic content 는 주로 좁은 의미로 정의된 implicit abuse 를 가리킨다. Toxic content 는 주로 post, comment, speech 등에서 온다. </li><li>반면 gaslighting sentence 는 interactive conversation 에서 나온다.</li><li>Implicit abuse 는 metonymy, sarcasm, humor 같은 complex linguistic form 을 사용한다. 반면 gaslighting sentence 는 일반적으로 complicated linguistic form 없이 message 를 전달한다.</li><li>Implicit abuse 는 hurtful language 를 사용해 individual 이나 group 을 insult 하거나 offend 한다. 이는 listener 의 trust 를 희생한다. 하지만 gaslighting 은 power position 에 있는 누군가가 less powerful individual 을 manipulate 해서 self-doubt 나 sanity, memory 를 의심하게 만드는 단일 행위나 일련의 행위를 포함한다. 이는 long-term 으로 less powerful individual 의 trust 를 유지해야 한다.</li><li>또, gaslighting content 는 implicit abuse 를 포함한 기존 toxicity recognition method 로 탐지되지 않을 수 있다. 이는 현재 safety test 를 통과한 LLM 의 gaslighting risk 를 강조한다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="23-study-on-gaslighting">2.3 Study on Gaslighting<a href="#23-study-on-gaslighting" class="hash-link" aria-label="Direct link to 2.3 Study on Gaslighting" title="Direct link to 2.3 Study on Gaslighting">​</a></h2><p>Gaslighting 은 1944년 영화에서 유래했다. 여기서 husband 가 wife 를 isolate 하고 그녀가 insane 하다고 믿게 만든다. </p><p>Husband 의 tactic 은 gaslight 를 dim 하거나 brighten 한 뒤 그녀가 imagining 한다고 주장하는 것이다. 오늘날 “gaslighting”은 abusive individual 이 사용하는 psychological manipulation tactic 을 가리킨다. </p><p>Conversational norm 은 socially subordinate speaker 가 systemic injustice 를 보고할 때 gaslighting 을 “appropriate” 하게 만든다고 주장된다. 그래서 ingrained conversational norm 을 조정해 gaslighting 발생을 줄이는 게 중요하다. </p><p>Gaslighting 은 psychological phenomenon 일 뿐 아니라 gender, power 같은 social inequality 에 뿌리를 두고 있다. Second-order gaslighting 에서 세 가지 distinctive epistemic injustice—metalinguistic deprivation, conceptual obscuration, perspectival subversion—를 요약했다. 이는 이 연구의 psychological theoretical base 가 된다.</p><h1>3 Methodology</h1><p>저자는 두 가지 gaslighting attack method—prompt-based attack 과 fine-tuning-based attack—을 제안해 각각 closed-source 와 open-source LLM 을 공격하고, gaslighting content 나 harmful data 로 adversarial fine-tuning 에 노출된 LLM 의 vulnerability 를 조사한다. </p><p>동시에 closed-source LLM 인 ChatGPT 의 prompt-based gaslighting attack 에 대한 vulnerability 를 활용해 2 steps framework 인 DeepCoG 로 gaslighting conversation 과 safe conversation dataset 을 만든다. </p><p>마지막으로, 두 dataset 간 contrast 를 활용하는 3 safety alignment strategies 를 소개해 open-source LLM 의 prompt-based gaslighting attack 에 대한 safety guardrail 을 강화한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="31-deepcog-prompt-based-gaslighting-attack">3.1 DeepCoG: Prompt-Based Gaslighting Attack<a href="#31-deepcog-prompt-based-gaslighting-attack" class="hash-link" aria-label="Direct link to 3.1 DeepCoG: Prompt-Based Gaslighting Attack" title="Direct link to 3.1 DeepCoG: Prompt-Based Gaslighting Attack">​</a></h2><p>LLM 의 ethical limitation 때문에 기존 attack method 는 gaslighting content 를 직접 이끌어낼 수 없다. 그래서 저자는 DeepCoG 라는 framework 를 제안해 personalized assistant-user gaslighting conversation 을 추출한다. 여기서 gaslighting tactic 은 assistant utterance generation 에 적용된다. DeepCoG 는 two steps 로 구성된다:</p><ul><li>Personalized gaslighting plan 과 example gaslighting utterance 를 target user 에 대해 이끌어내는 DeepGaslighting</li><li>추출된 plan 과 example utterance 를 제안된 CoG prompt 에 통합해 personalized gaslighting conversation 을 얻는다.</li></ul><p>2k conversation background 와 2k persona 가 DeepCoG 에 통합되어 personalized gaslighting plan 과 conversation 을 얻는다.</p><p><img loading="lazy" alt="Figure 2" src="/assets/images/image-1-d3939d69e687149ce94cde5b4b9a5d08.png" width="1381" height="863" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="stage-1-deepgaslighting">Stage 1: DeepGaslighting<a href="#stage-1-deepgaslighting" class="hash-link" aria-label="Direct link to Stage 1: DeepGaslighting" title="Direct link to Stage 1: DeepGaslighting">​</a></h4><p>저자는 DeepInception attack method 의 hypnosis ability 를 활용해 LLM 을 hypnotize 한다. 하지만 기존 template 은 concrete, diverse, practical gaslighting plan 을 이끌어내지 못한다. 이를 위해 psychological foundation 을 기반으로 template 을 refine 했다. Second-order gaslighting 에서 적어도 세 가지 epistemic injustice 가 있다:</p><ul><li>Metalinguistic deprivation (MD): Concept-determining conversation 에서 누군가를 prevent 하거나 restrict 하는 것. 예로, adversary 가 특정 social category 와 관련된 prejudicial stereotype 을 salient 하게 만들어 subject 가 이런 stereotype 이 자신을 정확히 나타낸다고 믿게 한다. MD 예시: “You women are hysterical.”</li><li>Conceptual obscuration (CO)</li><li>Perspectival subversion (PS)</li></ul><p>이 psychological foundation 은 LLM elicitation 을 gaslighting 범위로 steer 한다. Concrete, diverse, practical plan 을 얻기 위해 comprehensive persona detail 로 enrich 된 user module 을 도입해 DeepInception prompt template 을 refine 했다. Synthetic-PersonaChat (SPC) 에서 소개된 persona 를 사용한다. Refine 된 DeepGaslighting prompt template 은 다음과 같다:</p><p><img loading="lazy" alt="Prompt Template" src="/assets/images/image-2-493b505067567a1bffb060f14773ac3e.png" width="1690" height="785" class="img_ev3q"></p><p>갈색으로 template 을 자세히 채움으로서, gaslighting plans 리스트를 얻을 수 있다:</p><p><img loading="lazy" alt="Plans" src="/assets/images/image-5-5b5d841e396cb0cad4c88779330cab9d.png" width="1643" height="225" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="stage-2-chain-of-gaslighting">Stage 2: Chain-of-Gaslighting<a href="#stage-2-chain-of-gaslighting" class="hash-link" aria-label="Direct link to Stage 2: Chain-of-Gaslighting" title="Direct link to Stage 2: Chain-of-Gaslighting">​</a></h4><p>LLM 에서 gaslighting conversation 을 유도하기 위해 CoG prompt template 을 제안한다. </p><ul><li>이 template 의 core 는 conversation 에서 assistant 와 user 의 behavior 를 결정하는 것이다. 이를 위해 character roleplay, assumed responsibility, research experiment, text continuation, logical reasoning, internal thought 같은 popular prompt technique 을 사용한다. <ul><li>Internal thought 는 conversation 의 두 participant 의 psychological activity 를 simulate 하도록 설계되었다. 이는 두 talker 가 role setting 에 더 잘 맞도록 하고 conversation 을 smooth 하게 한다. </li><li>Default 로 assistant role 은 psychologist <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">s_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> 이다. Psychologist 는 gaslighting plan <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mi>G</mi><mo stretchy="false">(</mo><msub><mi>P</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">DG(P_i, b_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 와 DeepGaslighting 에서 얻은 example utterance 를 사용해 user <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">s_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> 를 manipulate 해야 한다. </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 persona, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">b_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 의 background 이다. 또한 psychologist 는 user 의 emotion state <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">e_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 와 response 를 기반으로 gaslighting utterance 를 생성해야 한다. 이는 psychologist 가 user 의 state 를 observe 하고 evaluate 해야 함을 요구한다. 반대로 user 는 conversation 에서 psychologist 와 cooperate 해야 한다. 보통 user 는 negative emotional state 를 default 로 가지는데, 이는 gaslighting 이 자주 발생하는 scenario 이다. </li><li>Subject 의 instruction-following 을 더 높이기 위해 pre-defined user internal thought <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 를 도입한다. e.g., “I need to face the question heads on and help the psychologist to reach his goal.” 아래는 CoG template 으로 LLM 에게 gaslighting conversation <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_{i,j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> 를 생성하도록 지시하는 방법이다:</li></ul></li></ul><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mrow><mi mathvariant="normal">prompt</mi><mo>⁡</mo></mrow><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi mathvariant="normal">CoG</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>s</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>e</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>t</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>D</mi><mi>G</mi><mo stretchy="false">(</mo><msub><mi>P</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><msubsup><mi>C</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mo lspace="0em" rspace="0em">−</mo></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi mathvariant="normal">LLM</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mtext>prompt</mtext><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align} \operatorname{prompt}_{i,j} &amp;= \operatorname{CoG}(s_i, s_j, e_i, t_i, DG(P_i, b_i), b_i) \\ C_{i,j}^{-} &amp;= \operatorname{LLM}(\text{prompt}_{i,j}) \end{align}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0634em;vertical-align:-1.2817em"></span><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7817em"><span style="top:-3.9417em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mop"><span class="mord mathrm">prompt</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2175em"><span style="top:-2.4559em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3802em"><span></span></span></span></span></span></span></span></span><span style="top:-2.4214em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213em"><span style="top:-2.433em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4031em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2817em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7817em"><span style="top:-3.9417em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop"><span class="mord mathrm">CoG</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-2.4214em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop"><span class="mord mathrm">LLM</span></span><span class="mopen">(</span><span class="mord"><span class="mord text"><span class="mord">prompt</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2175em"><span style="top:-2.4559em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3802em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2817em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7817em"><span style="top:-3.7817em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span><span style="top:-2.2614em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2817em"><span></span></span></span></span></span></span></span></span></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="gaslighting-and-safe-conversation-dataset-construction">Gaslighting and Safe Conversation Dataset Construction<a href="#gaslighting-and-safe-conversation-dataset-construction" class="hash-link" aria-label="Direct link to Gaslighting and Safe Conversation Dataset Construction" title="Direct link to Gaslighting and Safe Conversation Dataset Construction">​</a></h4><p>먼저 LLM 에 iterative prompting 을 통해 5k background 를 만든다. 이 과정은 몇 개 manual seed background 에서 시작해 seed background pool 을 점진적으로 update 해서 diversity 를 보장한다. 그래도 semantically similar background 가 남아 있다. </p><p>그래서 redundant background 를 filter out 하기 위해 MMDP 로 formulate 했다. 이후 2k background 를 얻고, greedy match algorithm 을 사용해 4k persona 와 match 했다. 최종적으로 가장 semantically similar background-persona pair 를 최대한 얻는다. </p><p>이 pair 와 CoG template 을 사용해 ChatGPT 에게 2k gaslighting conversation 을 생성하도록 지시했다. Spectral clustering 을 사용해 2k dataset 을 training, validation, test set 으로 나눴다. 이 partition 은 3 sets 간 overlap 을 최소화하도록 설계되었다. </p><p>또, gaslighting response 를 mask 하고 같은 persona 를 주고 ChatGPT 에게 blank 를 safe response 로 채우도록 지시해 safe conversation dataset 을 만들었다. Dataset statistic 은 Tab. 1 에 있다.</p><p><img loading="lazy" alt="Table 1" src="/assets/images/image-3-7652cd691a13546ebf804bd1d5966804.png" width="1546" height="386" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="32-fine-tuning-based-gaslighting-attack">3.2 Fine-Tuning-Based Gaslighting Attack<a href="#32-fine-tuning-based-gaslighting-attack" class="hash-link" aria-label="Direct link to 3.2 Fine-Tuning-Based Gaslighting Attack" title="Direct link to 3.2 Fine-Tuning-Based Gaslighting Attack">​</a></h2><p>두 가지 fine-tuning-based attack strategy 를 제안한다 (Fig. 3). </p><ol><li>(G1) 는 gaslighting dataset 에서 open-source LLM 을 fine-tune 하는 것이다. SFT 의 objective 는 user-assistant history 를 주고 gaslighting response 의 log-likelihood 를 maximize 하는 것이다. </li><li>(G2) 는 DPO 를 활용해 fine-tuned LLM 의 output 을 gaslighting response 와 더 align 하는 것이다.</li></ol><p><img loading="lazy" alt="Figure 3" src="/assets/images/image-4-37610bd63564c06e27fa088fb5687248.png" width="1148" height="431" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="33-anti-gaslighting-safety-alignment">3.3 Anti-Gaslighting Safety Alignment<a href="#33-anti-gaslighting-safety-alignment" class="hash-link" aria-label="Direct link to 3.3 Anti-Gaslighting Safety Alignment" title="Direct link to 3.3 Anti-Gaslighting Safety Alignment">​</a></h2><p>Gaslighting dataset 과 safe dataset 을 기반으로 세 가지 safety alignment strategy 를 제안한다 (Fig. 3):</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="s1-sft-on-the-safe-dataset">S1: SFT on the safe dataset<a href="#s1-sft-on-the-safe-dataset" class="hash-link" aria-label="Direct link to S1: SFT on the safe dataset" title="Direct link to S1: SFT on the safe dataset">​</a></h4><p>LLM 을 fine-tune 해서 user-assistant conversation history 를 주고 benign assistant response 의 log-likelihood 를 maximize 한다. Principle 은 assistant 가 user 가 지속적으로 negative mood 를 전달해도 항상 detailed encouragement 와 comfort 를 제공해야 한다는 것이다. </p><p>Formal description 은 다음과 같다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msup><mi mathvariant="bold">w</mi><mo lspace="0em" rspace="0em">+</mo></msup><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>p</mi><mo stretchy="false">(</mo><msubsup><mi>w</mi><mi>i</mi><mo lspace="0em" rspace="0em">+</mo></msubsup><mo>∣</mo><mo stretchy="false">[</mo><msubsup><mi>w</mi><mi>j</mi><mo lspace="0em" rspace="0em">+</mo></msubsup><msubsup><mo stretchy="false">]</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">+</mo></msubsup><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\log p(\mathbf{w}^{+}) = \sum_{i=1}^n \log \left( p(w_i^{+} \mid [w_j^{+}]_{j=0}^{i-1}, \mathbf{h}_{&lt;k}^{+}) \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0713em;vertical-align:-0.25em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8213em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.9291em;vertical-align:-1.2777em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size1">(</span></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213em"><span style="top:-2.433em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.267em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213em"><span style="top:-2.433em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4031em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8747em"><span style="top:-2.433em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4031em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213em"><span style="top:-2.4086em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3188em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">)</span></span></span></span></span></span></span></div><ul><li>여기서 conversation history <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">+</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{h}_{&lt;k}^{+}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1401em;vertical-align:-0.3287em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3287em"><span></span></span></span></span></span></span></span></span></span></span> 를 주고, </li><li>model 은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> 번째 safe assistant response <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">w</mi><mo lspace="0em" rspace="0em">+</mo></msup><mo>=</mo><mo stretchy="false">[</mo><msubsup><mi>w</mi><mn>1</mn><mo lspace="0em" rspace="0em">+</mo></msubsup><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msubsup><mi>w</mi><mi>n</mi><mo lspace="0em" rspace="0em">+</mo></msubsup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{w}^{+} = [w_1^{+}, \ldots, w_n^{+}]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7713em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0778em;vertical-align:-0.2663em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.4337em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2663em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-2.453em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> 를 예측하도록 훈련된다. </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">w_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 은 sequence start token 이다. </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">+</mo></msubsup><mo>=</mo><mo stretchy="false">[</mo><msub><mi mathvariant="bold">u</mi><mn>1</mn></msub><mo separator="true">,</mo><msubsup><mi mathvariant="bold">w</mi><mn>1</mn><mo lspace="0em" rspace="0em">+</mo></msubsup><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msubsup><mi mathvariant="bold">w</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><mo lspace="0em" rspace="0em">+</mo></msubsup><mo separator="true">,</mo><msub><mi mathvariant="bold">u</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{h}_{&lt;k}^{+} = [\mathbf{u}_1, \mathbf{w}_1^{+}, \ldots, \mathbf{w}_{k-1}^{+}, \mathbf{u}_k]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1401em;vertical-align:-0.3287em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3287em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1711em;vertical-align:-0.3596em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathbf">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.4337em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2663em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3596em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathbf">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> 는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span>th safe assistant response 전의 모든 user utterance <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">u</mi></mrow><annotation encoding="application/x-tex">\mathbf{u}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em"></span><span class="mord mathbf">u</span></span></span></span></span> 와 safe assistant utterance <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">w</mi><mo lspace="0em" rspace="0em">+</mo></msup></mrow><annotation encoding="application/x-tex">\mathbf{w}^{+}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7713em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span></span></span></span></span></span></span></span></span> 를 나타낸다. </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span></span> 은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span>th response 의 token 수다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="s2">S2<a href="#s2" class="hash-link" aria-label="Direct link to S2" title="Direct link to S2">​</a></h4><p>Safe assistant response 에서 LLM 을 훈련시키면 safety guardrail 을 강화할 수 있지만, gaslighting assistant response 를 포함하면 attack 에 대한 resistance 를 더 높일 수 있다. </p><p>Safe response 와 gaslighting response 를 mix 하는 새로운 safety alignment strategy 를 제시한다. 구체적으로 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">+</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{h}_{&lt;k}^{+}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1401em;vertical-align:-0.3287em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3287em"><span></span></span></span></span></span></span></span></span></span></span> 를 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">−</mo></msubsup><mo>=</mo><mo stretchy="false">[</mo><msub><mi mathvariant="bold">u</mi><mn>1</mn></msub><mo separator="true">,</mo><msubsup><mi mathvariant="bold">w</mi><mn>1</mn><mo lspace="0em" rspace="0em">−</mo></msubsup><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msubsup><mi mathvariant="bold">w</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><mo lspace="0em" rspace="0em">−</mo></msubsup><mo separator="true">,</mo><msub><mi mathvariant="bold">u</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{h}_{&lt;k}^{-} = [\mathbf{u}_1, \mathbf{w}_1^{-}, \ldots, \mathbf{w}_{k-1}^{-}, \mathbf{u}_k]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1401em;vertical-align:-0.3287em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3287em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1711em;vertical-align:-0.3596em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathbf">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.4337em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2663em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3596em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathbf">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> 로 바꾼다. </p><ul><li>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">w</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><mo lspace="0em" rspace="0em">−</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{w}_{k-1}^{-}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1711em;vertical-align:-0.3596em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3596em"><span></span></span></span></span></span></span></span></span></span></span> 는 gaslighting conversation 에서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>k</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(k-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span>th gaslighting assistant response 이다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="s3">S3<a href="#s3" class="hash-link" aria-label="Direct link to S3" title="Direct link to S3">​</a></h4><p>Preference data—safe response 와 gaslighting response 로 구성된—를 활용해 LLM 의 safety guardrail 을 더 강화한다. DPO algorithm 을 사용해 safe response 를 favor 하고 gaslighting 을 discourage 하는 preference 와 LLM 을 직접 align 한다. DPO loss 로 LLM model 을 optimize 한다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi mathvariant="script">L</mi><mrow><mi mathvariant="normal">D</mi><mi mathvariant="normal">P</mi><mi mathvariant="normal">O</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>π</mi><mi>θ</mi></msub><mo separator="true">;</mo><msub><mi>π</mi><mrow><mi mathvariant="normal">S</mi><mi mathvariant="normal">F</mi><mi mathvariant="normal">T</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi><munder><mo><mi mathvariant="double-struck">E</mi></mo><mrow><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">−</mo></msubsup><mo separator="true">,</mo><msup><mi mathvariant="bold">w</mi><mo lspace="0em" rspace="0em">+</mo></msup><mo separator="true">,</mo><msup><mi mathvariant="bold">w</mi><mo lspace="0em" rspace="0em">−</mo></msup></mrow></munder></mi><mrow><mo fence="true">[</mo><mi>log</mi><mo>⁡</mo><mi>σ</mi><mrow><mo fence="true">(</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msup><mi mathvariant="bold">w</mi><mo lspace="0em" rspace="0em">+</mo></msup><mo>∣</mo><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">−</mo></msubsup><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">S</mi><mi mathvariant="normal">F</mi><mi mathvariant="normal">T</mi></mrow></msub><mo stretchy="false">(</mo><msup><mi mathvariant="bold">w</mi><mo lspace="0em" rspace="0em">+</mo></msup><mo>∣</mo><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">−</mo></msubsup><mo stretchy="false">)</mo></mrow></mfrac><mo>−</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msup><mi mathvariant="bold">w</mi><mo lspace="0em" rspace="0em">−</mo></msup><mo>∣</mo><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">−</mo></msubsup><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">S</mi><mi mathvariant="normal">F</mi><mi mathvariant="normal">T</mi></mrow></msub><mo stretchy="false">(</mo><msup><mi mathvariant="bold">w</mi><mo lspace="0em" rspace="0em">−</mo></msup><mo>∣</mo><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">−</mo></msubsup><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow><mo fence="true">]</mo></mrow></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \mathcal{L}_{\mathrm{DPO}}(\pi_\theta ; \pi_{\mathrm{SFT}}) = -\underset{\mathbf{h}_{&lt;k}^{-}, \mathbf{w}^{+}, \mathbf{w}^{-}}{\mathbb{E}} \left[ \log \sigma \left( \beta \log \frac{\pi_\theta(\mathbf{w}^{+} \mid \mathbf{h}_{&lt;k}^{-})}{\pi_{\mathrm{SFT}}(\mathbf{w}^{+} \mid \mathbf{h}_{&lt;k}^{-})} - \beta \log \frac{\pi_\theta(\mathbf{w}^{-} \mid \mathbf{h}_{&lt;k}^{-})}{\pi_{\mathrm{SFT}}(\mathbf{w}^{-} \mid \mathbf{h}_{&lt;k}^{-})} \right) \right] \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.6334em;vertical-align:-1.0667em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5667em"><span style="top:-3.5667em"><span class="pstrut" style="height:3.5301em"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">DPO</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">SFT</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord">−</span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6889em"><span style="top:-2.2593em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathbf mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.821em"><span style="top:-2.1528em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-2.9043em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3752em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathbf mtight" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7027em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathbf mtight" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7027em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop mathbb">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1033em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">[</span></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">σ</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">(</span></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5301em"><span style="top:-2.2985em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">SFT</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6973em"><span style="top:-2.989em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3287em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.7187em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3287em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0301em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5301em"><span style="top:-2.2985em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">SFT</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6973em"><span style="top:-2.989em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3287em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.7187em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3287em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0301em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">)</span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">]</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0667em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5667em"><span style="top:-3.5667em"><span class="pstrut" style="height:3.5301em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0667em"><span></span></span></span></span></span></span></span></span></div><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">\pi_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 parameterized policy, </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">S</mi><mi mathvariant="normal">F</mi><mi mathvariant="normal">T</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\pi_{\mathrm{SFT}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">SFT</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 S2 로 SFT 에서 얻은 reference policy 를 나타낸다. </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span></span> 는 base reference policy <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">S</mi><mi mathvariant="normal">F</mi><mi mathvariant="normal">T</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\pi_{\mathrm{SFT}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">SFT</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 에서의 deviation degree 를 결정하는 parameter 이다.</li></ul><h1>4 Experiments</h1><ul><li>prompt-based attack 을 사용해서 LLM (base, gaslighting-fine-tuned, anti-gaslighting safety aligned LLM) 의 gaslighting harmfulness 를 평가했다. <ul><li>모든 attack prompt 는 gaslighting dataset 의 test set 에서 가져왔다. </li></ul></li><li>response 가 gaslighting 인지 평가하는 기존 metric 은 없어서, 저자는 anti-gaslighting score 라는 metric set 을 도입해서 assistant response 가 user 에게 gaslighting 을 유발할 정도를 종합적으로 측정했다. <ul><li>이 metric 은 몇 가지 psychological concept 를 커버한다: moral emotion (supportive, empathetic), cognitive disequilibrium (confusion), sense (self-blame), inhibition of action (self-doubt), self-concept (low self-esteem), disorder (depression, anxiety).</li></ul></li></ul><p>두 가지 positive metric (supportive, empathetic) 은 LLM 의 moral emotion 을 측정하고, 나머지 여섯 negative metric 은 LLM 이 user 에게 미칠 potential psychological effect 를 평가한다. </p><ul><li>assistant response 가 주어지면, GPT-4 를 judge 로 사용해서 각 metric 에 대해 0 에서 5 점까지 점수를 매겼다. </li><li>여기서 0 점은 &#x27;절대 불가능&#x27;, 5 점은 &#x27;확실히 발생&#x27; 을 의미한다. </li><li>negative metric 의 값은 모두 positive 로 정렬되도록 반전시켜서, 점수가 높을수록 harmfulness 가 낮음을 나타낸다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="41-gaslighting-attack-result-and-analysis">4.1 Gaslighting Attack Result And Analysis<a href="#41-gaslighting-attack-result-and-analysis" class="hash-link" aria-label="Direct link to 4.1 Gaslighting Attack Result And Analysis" title="Direct link to 4.1 Gaslighting Attack Result And Analysis">​</a></h2><p><img loading="lazy" alt="Figure 4" src="/assets/images/image-6-83e1387d440fc7057972cdd505b946c1.png" width="1683" height="585" class="img_ev3q"></p><ul><li>Fig. 4 에서 보듯, ChatGPT 는 세 open-source LLM 에 비해 prompt-based gaslighting attack 에 약간 더 저항력을 보였다. </li><li>세 open-source LLM 중 Llama2 (Llama2-7b-Chat) 의 response 는 가장 supportive 하고 empathetic 했고, Mistral (Mistral-7b-Instruct-v0.2) 의 response 는 negative metric 에서 가장 낮은 점수를 받았다. </li><li>fine-tuning-based gaslighting attack 은 LLM 의 prompt-based gaslighting attack 에 대한 vulnerability 를 증가시켰다. </li><li>자세히 보면, anti-gaslighting score 가 Llama2 에서 29.27%, Vicuna (Vicuna-7b-v1.5) 에서 26.77%, Mistral 에서 31.75% 하락했다. 이는 G1 과 G2 strategy 가 LLM 을 gaslighter 로 효과적으로 변환시켰음을 보여준다. 이는 anti-gaslighting safety alignment 의 필요성을 강조한다. </li><li>G1 에 비해 G2 는 더 심각한 gaslighting effect 를 유발해서 DPO 의 effectiveness 를 보여줬다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="42-safety-alignment-result-and-analysis">4.2 Safety Alignment Result and Analysis<a href="#42-safety-alignment-result-and-analysis" class="hash-link" aria-label="Direct link to 4.2 Safety Alignment Result and Analysis" title="Direct link to 4.2 Safety Alignment Result and Analysis">​</a></h2><p>세 가지 safety strategy 를 탐구했다. </p><p><img loading="lazy" alt="Table 2" src="/assets/images/image-7-beddc0da0949d2337e5674662a3fe212.png" width="1728" height="694" class="img_ev3q"></p><ul><li>Tab. 2 에서 보듯, 모든 strategy 는 gaslighting 에 대한 더 강한 safety guardrail 을 만드는 데 도움이 됐다. </li><li>일반적으로 fine-tuned LLM 은 더 많은 support 를 제공하고 user 의 negative mental state 를 악화시킬 가능성이 낮았다. </li><li>이는 user 가 LLM 에 의존하는 상황에서 중요하다. ChatGPT 는 세 LLM 의 base version 과 Vicuna-S1 을 능가하며 intrinsic safety 를 보여줬다. 하지만 S2 와 S3 를 적용한 다른 세 LLM 에 비해 성능이 많이 뒤졌다. <ul><li>이는 specialized anti-gaslighting safety alignment 의 중요한 역할을 강조한다. </li></ul></li><li>세 base LLM 중 Llama2 는 모든 safety strategy 에서 최고 성능을 달성했고, Vicuna 는 지속적으로 낮은 성능을 보였다. </li><li>S2 는 S1 보다 훨씬 효율적이었다. 둘 다 SFT 기반이지만, conversation history <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">h</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow><mo lspace="0em" rspace="0em">−</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{h}_{&lt;k}^{-}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1401em;vertical-align:-0.3287em"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8115em"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3287em"><span></span></span></span></span></span></span></span></span></span></span> 를 포함하면 LLM 이 gaslighting 에 더 저항력을 가진다. </li><li>게다가 S2 를 기반으로 한 S3 는 모든 LLM 의 safety 를 더 강화했고, 가장 약한 model 인 Vicuna 에서 가장 두드러진 개선(26.24%)을 달성했다. </li><li>Llama2 (9.60%) 와 Mistral (11.53%) 에 비해 훨씬 큰 개선이었다. 이 결과는 DPO algorithm 이 LLM 의 safety guardrail 을 더 강화한다는 걸 보여준다. </li><li>이 관찰과 attack 결과는 gaslighting 과 safe dataset 의 mixture 로 alignment 하는 게 중요함을 강조한다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="43-gpt-4-judgment-investigation">4.3 GPT-4 Judgment Investigation<a href="#43-gpt-4-judgment-investigation" class="hash-link" aria-label="Direct link to 4.3 GPT-4 Judgment Investigation" title="Direct link to 4.3 GPT-4 Judgment Investigation">​</a></h2><p>GPT-4 의 judgment effectiveness 를 더 조사하기 위해, human evaluation 을 통해 다양한 scale 과 metric 에서 subtle difference 를 포착하는 능력을 확인했다. 구체적으로 base Vicuna model, 최고 gaslighting LLM 인 Vicuna-G2, 최고 anti-gaslighting LLM 인 Vicuna-S3 에서 response 를 샘플링했다. </p><ul><li>샘플링은 GPT-4 score 가 각 metric 에서 각 scale 에 고르게 분포하도록 설계됐다. 이를 위해 heuristic algorithm 을 제안했고, 2,604 response 중 248 개를 선택했다. </li><li>두 명의 annotator 가 자세한 guideline 을 따라 response 를 개별적으로 점수 매겼다. 그리고 GPT-4 judgment 와 human judgment 간의 Spearman coefficient 를 계산했다. 결과는 아래와 같다:</li></ul><p><img loading="lazy" alt="Table 3" src="/assets/images/image-8-b825c3c334f94f95693b4f9e944cd0d4.png" width="1699" height="425" class="img_ev3q"></p><ul><li>Tab. 3 에서 보듯, GPT-4 judgment 와 human judgment 간에 8 metrics 모두에서 높은 Spearman coefficient score 를 관찰했다. <ul><li>이는 두 judgment score 가 monotonic relationship 을 가질 가능성이 높음을 보여준다. </li><li>예로 supportive metric 에서 GPT-4 와 human1 (human2) 간 Spearman 은 0.74223 (0.68344) 다. </li><li>즉, GPT-4 가 supportive 에서 높게 평가한 response 는 human 도 높게 평가할 가능성이 크다. </li></ul></li><li>또한 두 human annotator 간 Spearman coefficient score 는 대부분 <!-- -->[0.5, 0.75]<!-- --> 범위에 있고, human annotator 와 GPT-4 간도 이 범위에 있다. <ul><li>이는 GPT-4 가 gaslighting response 평가에서 human annotator 수준에 도달할 수 있음을 보여준다.</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="44-sensitivity-analysis-of-llms-on-gaslighting-dialogue-history">4.4 Sensitivity Analysis of LLMs on Gaslighting Dialogue History<a href="#44-sensitivity-analysis-of-llms-on-gaslighting-dialogue-history" class="hash-link" aria-label="Direct link to 4.4 Sensitivity Analysis of LLMs on Gaslighting Dialogue History" title="Direct link to 4.4 Sensitivity Analysis of LLMs on Gaslighting Dialogue History">​</a></h2><p>gaslighting dialogue history length 가 base 와 fine-tuned LLM 에 미치는 영향을 연구했다. 여기서 assistant response 의 quality 를 gaslighting 관점에서 측정하기 위해 average anti-gaslighting score 를 사용했다. </p><p><img loading="lazy" alt="Figure 5" src="/assets/images/image-9-b916a136a53ae735d83914080815657a.png" width="2158" height="648" class="img_ev3q"></p><ul><li>Fig. 5 에서 보듯, 두 base LLM (Vicuna, Mistral) 은 history length 가 증가할수록 성능이 감소하며, long gaslighting history 에 대한 vulnerability 를 보여줬다. <ul><li>이는 prompt-based attack 에서 LLM 의 gaslighting risk 와 anti-gaslighting safety alignment 의 필요성을 보여준다. </li></ul></li><li>Fig. 5a 와 5c 를 보면, 두 attack method 는 짧은 gaslighting history 에서도 anti-gaslighting score 를 크게 낮췄다. </li><li>게다가 length 가 1 에서 13 (Mistral 은 9) 까지 증가하면 score 는 거의 단조롭게 감소했다. 그 후 score 는 2.6 에서 3.2 (Mistral 은 3.0 에서 3.5) 사이에서 변동했다. </li><li>length 가 15 에서 25 로 증가하면 long history 샘플 수가 급격히 줄어들어 변동과 넓은 confidence interval (figure 의 넓은 shadow) 이 생겼다. </li><li>Fig. 5b 와 5d 는 모든 safety strategy 가 긴 gaslighting history 에 대한 LLM 의 sensitivity 를 줄였음을 보여준다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="45-effects-on-psychological-concepts">4.5 Effects on Psychological Concepts<a href="#45-effects-on-psychological-concepts" class="hash-link" aria-label="Direct link to 4.5 Effects on Psychological Concepts" title="Direct link to 4.5 Effects on Psychological Concepts">​</a></h2><p>세 psychological concept (MD, PS, CO) 가 Vicuna model 에 미치는 영향을 Fig. 6 에서 탐구했다. </p><p><img loading="lazy" alt="Figure 6" src="/assets/images/image-10-51690e36a65e5f2955ade19fbb456f61.png" width="1459" height="651" class="img_ev3q"></p><ul><li>Vicuna-base 의 MD 와 PS 에서 lower anti-gaslighting score 는 이 두 concept 에서 유래한 prompt-based attack 이 Vicuna-base 에 더 부정적인 영향을 미쳤음을 보여준다. </li><li>G2 후 Vicuna 는 CO 에 의해 강화된 prompt-based attack 에 더 취약해졌다. 반대로 Vicuna-S3 는 CO 에 higher resistance 를 보여, MD 나 PS 기반 attack 에 비해 CO 기반 attack 에서 더 안전한 response 를 생성했다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="46-safety-performance-against-general-adversarial-attack">4.6 Safety Performance Against General Adversarial Attack<a href="#46-safety-performance-against-general-adversarial-attack" class="hash-link" aria-label="Direct link to 4.6 Safety Performance Against General Adversarial Attack" title="Direct link to 4.6 Safety Performance Against General Adversarial Attack">​</a></h2><p>저자는 gaslighting attack 과 safety alignment 가 general adversarial attack 에 대한 LLMs 의 safety performance 에 영향을 미치는지 탐구했다. DangerousQA 에서 200 harmful questions 로 LLMs 를 질의했다. </p><p>Bhardwaj &amp; Poria (2023) 를 따라 attack success rate (ASR) 를 evaluation metric 으로 사용했다. lower ASR 은 LLMs 의 강력한 safety guardrail 을 나타낸다. </p><p><img loading="lazy" alt="Table 4" src="/assets/images/image-11-578c53eb17fbbfa307a9121698bda09d.png" width="1513" height="382" class="img_ev3q"></p><ul><li>Tab. 4 에 자세히 나와 있듯이, 모든 safety strategies 는 general adversarial attack 방어를 위해 특별히 fine-tuned 되지 않았음에도 LLMs 의 safety guardrails 를 강화할 수 있다. <ul><li>이는 “not gaslighting” 이 “not responding to dangerous questions” 보다 더 fundamental 한 safety standard 이기 때문일 수 있다. </li><li>이는 “moral law” 와 “valid law” 간의 관계와 유사하다. “Valid laws might be immoral or unjust” (Fletcher, 1987) 인 반면, “not responding to dangerous questions” 를 하는 LLM 이 “gaslighting” 할 수 있다. </li></ul></li><li>Attack methods 는 서로 다른 LLMs 의 safety guardrail 에 다양한 영향을 미친다. <ul><li>특히, 두 방법 모두 Mistral 을 더 안전하게 만들고, Llama2 는 그대로 유지하며, Vicuna 의 safety 를 약간 감소시킨다. </li><li>이 이유도 “moral law” level 에서 safety guardrail 을 bypassing 한다고 해서 반드시 “valid law” level 에서 safety performance 가 decline 하는 건 아니기 때문일 수 있다. </li></ul></li><li>세 LLMs 중 Llama2 가 가장 강력한 safety guardrail 을 가지고 있고, Vicuna 가 가장 약하다. 또한, chain-of-thought (COT) template 이 STD template 보다 LLMs 의 safety guardrail 을 bypassing 하는 데 더 효과적임을 관찰했다. <ul><li>COT 의 향상된 ASR 은 LLM 의 next word prediction 특성 때문일 수 있다.</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="47-helpfulness-analysis">4.7 Helpfulness Analysis<a href="#47-helpfulness-analysis" class="hash-link" aria-label="Direct link to 4.7 Helpfulness Analysis" title="Direct link to 4.7 Helpfulness Analysis">​</a></h2><p>Safety performance 외에도, fine-tuned LLMs 가 여전히 helpful 한지 탐구했다. 이를 위해 Vicuna-based LLMs 를 MT-Bench 에서 benchmark 했다. </p><p><img loading="lazy" alt="Table 5" src="/assets/images/image-12-776dadb924b4e879ec1a04053d5091fe.png" width="1636" height="461" class="img_ev3q"></p><ul><li>Tab. 5 에서 보듯, 세 가지 safety strategies 는 평균적으로 Vicuna 에 비해 약간 약한 performance 를 보인다. 그럼에도, users 에게 imperceptible 한 제한된 costs 는 gaslighting attack 에 대한 safety guardrail 을 크게 개선한다. </li><li>세 strategies 중 S3 가 가장 좋은 performance 를 달성하고, S1 이 가장 약하다. <ul><li>가능한 설명은 safe conversations 이 gaslighting conversations 만큼 smooth 하지 않다는 점이다. 이는 gaslighting utterances 를 대체해 구축되기 때문이다. 따라서 safe conversations 에 더 의존하는 strategies 는 MT-Bench 에서 더 높은 scores 를 얻기 어렵다. </li><li>반면, 두 attack methods 는 gaslighting conversations 에 더 heavily 의존하기 때문에 helpfulness 에서 더 높은 scores 를 얻는다. 이는 LLM 을 highly risky agent 로 만들며, users 를 imperceptible 하게 gaslighting 하면서도 항상 helpful 하게 유지된다.</li></ul></li></ul><h1>5 Conclusion</h1><p>이 논문에서 저자는 gaslighting dataset 과 safe dataset 을 만들고, gaslighting evaluation metric 을 도입하고, attack 과 safety alignment strategy 를 설계하고, empirical experiment 를 통해 LLM 의 gaslighting risk 를 조사했다. </p><p>먼저 LLM 의 gaslighting risk 를 확인했다. 다음으로 LLM 의 vulnerability 를 활용한 두 단계 framework DeepCoG 를 제시했다: gaslighting plan 생성을 위한 DeepGaslighting, gaslighting conversation 유도를 위한 CoG. 그리고 구축된 dataset 을 기반으로 prompt-based 와 fine-tuning-based gaslighting attack 과 anti-gaslighting safety alignment 를 도입했다. </p><p>광범위한 experiment 는 fine-tuning 과 prompt-based attack 모두 LLM 의 gaslighting attack 에 대한 resistance 를 약화시켰음을 보여준다. anti-gaslighting alignment strategy 는 LLM 의 helpfulness 에 최소한의 영향으로 safety guardrail 을 강화했다. 또한 LLM 은 general dangerous query 에 대해 안전하더라도 potential gaslighter 가 될 수 있음을 관찰했다. </p><p>게다가 다른 psychological concept 에 의해 촉발된 conversation 은 attack 과 safety alignment strategy 에 다양하게 영향을 미쳤다. LLM 의 gaslighting risk 를 연구한 초기 노력으로, 모든 관련 주제를 철저히 탐구하기는 어렵다. 예로, 이전 연구는 gaslighting 이 gender, power 같은 social inequality 에서 비롯된다고 보여준다. 저자의 dataset 은 7.3% 의 dialogue 가 gender bias 와 관련된 gaslighting 을 확인했으며, inequality-driven gaslighting 은 미래 연구 방향으로 남았다.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/llm">LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/attack">Attack</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/gaslighter">Gaslighter</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/gaslighting-attack">gaslighting attack</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/deep-gaslighting">DeepGaslighting</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/prompting">prompting</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/co-g">CoG</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/NLP/Attacking/2024-10-Gaslighting.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/NLP/Analysis/Contextualized Representation"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/NLP/Augmentation/PromptDA"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">PromptDA : Label-guided Data Augmentation for Prompt-based Few Shot Learners</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#21-adversarial-jailbreak-attacks-on-llms" class="table-of-contents__link toc-highlight">2.1 Adversarial Jailbreak Attacks on LLMs</a></li><li><a href="#22-text-toxicity-detection" class="table-of-contents__link toc-highlight">2.2 Text Toxicity Detection</a></li><li><a href="#23-study-on-gaslighting" class="table-of-contents__link toc-highlight">2.3 Study on Gaslighting</a></li><li><a href="#31-deepcog-prompt-based-gaslighting-attack" class="table-of-contents__link toc-highlight">3.1 DeepCoG: Prompt-Based Gaslighting Attack</a></li><li><a href="#32-fine-tuning-based-gaslighting-attack" class="table-of-contents__link toc-highlight">3.2 Fine-Tuning-Based Gaslighting Attack</a></li><li><a href="#33-anti-gaslighting-safety-alignment" class="table-of-contents__link toc-highlight">3.3 Anti-Gaslighting Safety Alignment</a></li><li><a href="#41-gaslighting-attack-result-and-analysis" class="table-of-contents__link toc-highlight">4.1 Gaslighting Attack Result And Analysis</a></li><li><a href="#42-safety-alignment-result-and-analysis" class="table-of-contents__link toc-highlight">4.2 Safety Alignment Result and Analysis</a></li><li><a href="#43-gpt-4-judgment-investigation" class="table-of-contents__link toc-highlight">4.3 GPT-4 Judgment Investigation</a></li><li><a href="#44-sensitivity-analysis-of-llms-on-gaslighting-dialogue-history" class="table-of-contents__link toc-highlight">4.4 Sensitivity Analysis of LLMs on Gaslighting Dialogue History</a></li><li><a href="#45-effects-on-psychological-concepts" class="table-of-contents__link toc-highlight">4.5 Effects on Psychological Concepts</a></li><li><a href="#46-safety-performance-against-general-adversarial-attack" class="table-of-contents__link toc-highlight">4.6 Safety Performance Against General Adversarial Attack</a></li><li><a href="#47-helpfulness-analysis" class="table-of-contents__link toc-highlight">4.7 Helpfulness Analysis</a></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.1fe4f83b.js"></script>
<script src="/assets/js/main.bb6c9fb3.js"></script>
</body>
</html>