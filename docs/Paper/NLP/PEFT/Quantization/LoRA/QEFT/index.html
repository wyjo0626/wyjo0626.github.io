<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/NLP/PEFT/Quantization/LoRA/2024-10-QEFT">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">QEFT: Quantization for Efficient Fine-Tuning of LLMs | WYJLab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Quantization/LoRA/QEFT"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="QEFT: Quantization for Efficient Fine-Tuning of LLMs | WYJLab"><meta data-rh="true" name="description" content="논문 및 이미지 출처 :"><meta data-rh="true" property="og:description" content="논문 및 이미지 출처 :"><link data-rh="true" rel="icon" href="/img/WYJLab.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Quantization/LoRA/QEFT"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Quantization/LoRA/QEFT" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Quantization/LoRA/QEFT" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="WYJLab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="WYJLab Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.9ed678b7.css">
<link rel="preload" href="/assets/js/runtime~main.74164ba1.js" as="script">
<link rel="preload" href="/assets/js/main.82abd802.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Multi-Modal/PEFT/Composition/Moka">Multi-Modal</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">Analysis</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Attacking/universal-adversarial-prompt">Attacking</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Augmentation/PromptDA">Augmentation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Generalization/NoisyTune">Generalization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Model/Transformer">Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Multi-Task/Flan-T5">Multi-Task</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">PEFT</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">Composition</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Generalization/Flat-LoRA">Generalization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Mixture/UniPELT">Mixture</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/Adapter">Module</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Pruning/SMP">Pruning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/Fine-Tuning/AlphaTuning">Quantization</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/Fine-Tuning/AlphaTuning">Fine-Tuning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/QLoRA">LoRA</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/QLoRA">QLORA: Efficient Finetuning of Quantized LLMs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/QA-LoRA">QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/LoftQ">LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/LQ-LoRA">LQ-LoRA: Low-Rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/ApiQ">ApiQ: Finetuning of 2-Bit Quantized Large Language Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/IR-QLoRA">Accurate LoRA-Finetuning Quantization of LLMs via Information Retention</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/LR-QAT">Low-Rank Quantization-Aware Training for LLMs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/Q-BaRA">Accurate and Efficient Fine-Tuning Quantized Large Language Models Through Optimal Balance</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/RoLoRA">RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-6 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/QEFT">QEFT: Quantization for Efficient Fine-Tuning of LLMs</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning">Soft Prompt</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Engineering/CoT/Chain-of-Thought">Prompt Engineering</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Tuning/PTR">Prompt Tuning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Reinforcement Learning/Reflexion">Reinforcement Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Text Generation/InstructGPT">Text Generation</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Composition/CLIP-LoRA">Vision-Language</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">NLP</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">PEFT</span><meta itemprop="position" content="3"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Quantization</span><meta itemprop="position" content="4"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">LoRA</span><meta itemprop="position" content="5"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">QEFT: Quantization for Efficient Fine-Tuning of LLMs</span><meta itemprop="position" content="6"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>QEFT: Quantization for Efficient Fine-Tuning of LLMs</h1></header><p>논문 및 이미지 출처 : <a href="https://aclanthology.org/2024.findings-emnlp.811.pdf" target="_blank" rel="noopener noreferrer">https://aclanthology.org/2024.findings-emnlp.811.pdf</a></p><h1>Abstract</h1><p>Large language model (LLM) 의 fine-tuning 사용이 빠르게 늘어나면서 inference efficiency 를 유지하면서 fine-tuning 을 최적화하는 게 매우 중요해졌다. 하지만 이는 inference speed, fine-tuning speed, memory consumption, 그리고 가장 중요한 model quality 등 모든 면에서 개선이 필요한 어려운 과제다. 이전 연구들은 quantization 과 fine-tuning 을 결합해서 이걸 해결하려 했지만, 네 가지 측면을 동시에 향상시키는 데 실패했다. </p><p>이번 연구에서 저자는 <strong>Quantization for Efficient Fine-Tuning (QEFT)</strong> 라는 새로운 가벼운 기술을 제안한다. QEFT 는 inference 와 fine-tuning 을 둘 다 빠르게 하고, 탄탄한 이론적 기반을 제공하며, 높은 유연성을 갖췄고, good hardware compatibility 를 유지한다. </p><p>광범위한 실험을 통해 QEFT 가 full-precision parameter-efficient fine-tuning 의 quality 와 versatility 를 맞추면서도 fewer resources 를 쓴다는 걸 보여준다.</p><h1>1 Introduction</h1><p>Large language model (LLM) 의 뛰어난 zero-shot 성능은 그 인기에 크게 기여하지만, versatility 와 adaptability 도 널리 채택되는 데 중요한 요소다. Transfer learning 과 fine-tuning 을 통해 LLM 은 새로운 데이터 타입을 포함한 unseen 또는 complex tasks 를 처리할 수 있게 확장되는데, 이는 다양한 application 에서 새로운 가능성을 열어준다. Efficient inference 와 fine-tuning 이 점점 중요해지면서, 이 논문은 LLM 의 inference 와 fine-tuning efficiency 를 높이는 방법을 탐구한다.</p><p>과거 연구를 보면 inference efficiency 를 높이기 위해 pruning, speculative decoding, KV caching, 그리고 특히 weight quantization 같은 여러 방법이 제안됐다. 하지만 fine-tuning 에 대한 가벼운 접근법을 다룬 연구는 상대적으로 제한적이다. Fine-tuning 과 inference 를 둘 다 고려할 때 최적화해야 할 요소들, 즉 inference speed, training speed, memory consumption, accuracy 등이 매우 다양해지기 때문이다. 이 모든 조건을 동시에 균형 있게 맞추는 건 큰 도전이다.</p><p>이런 맥락에서 LoRA 는 pre-trained weight 를 freeze 하고 업데이트되는 decomposed path 를 추가함으로써 parameter-efficient fine-tuning (PEFT) 을 가능하게 하는 대표적인 연구다. 이 접근법은 제한된 자원으로 LLM 을 유연하게 업데이트할 수 있는 새로운 기회를 열어주고, 수많은 새로운 application 이 등장하게 했다. 게다가 여러 연구는 weight quantization 과 LoRA 를 조화시켜 두 방법의 장점을 모두 취하려고 발전시켜 왔다. </p><ul><li>예로 QLoRA 와 QA-LoRA 에서는 pre-trained weight 를 quantization 후 고정하고, FP16 low-rank path 만 추가해서 독점적으로 업데이트한다. </li><li>하지만 QLoRA 는 inference speed 가 느리고, 두 방법 모두 fine-tuning overhead 가 눈에 띈다. </li><li>여러 최적화를 병렬로 적용하는 것만으로는 inference 와 fine-tuning 의 모든 면에서 개선을 이루기 쉽지 않다.</li></ul><p>이번 연구에서 저자는 inference 와 training 에서 최적의 성능을 내도록 설계된 새로운 quantization 기술인 <strong>Quantization for Efficient Fine-Tuning (QEFT)</strong> 을 제안한다. 이 방법은 OWQ 의 data format 을 활용해서 quantization 에 취약한 weak column 을 FP16 으로 저장하고, 대부분의 weight 는 4-bit 이하로 저장하며, fine-tuning 중에는 weak column 만 업데이트한다. 이 접근법은 quantization 의 장점을 누리면서 PEFT 를 구현할 수 있게 한다.</p><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-48-e76e11e38d3721a9ffaa9db14a5b892e.png" width="760" height="544" class="img_ev3q"></p><p>하지만 QEFT 는 고유한 혁신을 제공한다.</p><ul><li>먼저 OWQ 는 linear layer 의 weight 에서 column 의 불규칙한 mixed precision 때문에 hardware compatibility 가 낮다. 반면 QEFT 는 새로운 <strong>Offline Global Reordering (OGR)</strong> 을 기반으로 structured mixed precision phenotype 을 달성해서 hardware compatibility 를 개선하고, Fig. 1 에서 보듯 training 과 inference 에서 큰 speed 향상을 가져온다.  </li><li>또한 QEFT 는 fine-tuning 후 loss value 를 최소화하기 위해 weak column 을 선택하는 이론적 framework 를 제공한다.  </li><li>마지막으로 LoRA 와 다르게 구현됐지만, QEFT 가 이전에 LoRA 를 사용한 application 을 대체하고 적용될 수 있다는 걸 검증해서 유연성을 보여준다.</li></ul><p>다양한 실험을 통해 QEFT 가 inference speed, training speed, model quality 면에서 SOTA 방법임을 증명했다. OWQ 보다 약간 더 많은 memory 를 쓰지만, QEFT 는 다른 모든 면에서 OWQ 를 능가하고 다른 baseline 도 모든 영역에서 앞선다.</p><h1>2 Related Work</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="21-weight-only-quantization-of-llms">2.1 Weight-only Quantization of LLMs<a href="#21-weight-only-quantization-of-llms" class="hash-link" aria-label="Direct link to 2.1 Weight-only Quantization of LLMs" title="Direct link to 2.1 Weight-only Quantization of LLMs">​</a></h2><p>Weight-only quantization 은 LLM 의 가장 성공적인 최적화 방법 중 하나로, model 의 footprint 를 크게 줄이고 generation 중 memory bottleneck 을 완화해서 inference 를 눈에 띄게 가속한다. OPTQ 는 OPT-175B model 을 sub-4-bit 로 quantize 해도 accuracy 저하 없이 가능하다는 걸 처음 보여줬다. 게다가 이 low-precision 접근법은 memory bottleneck 을 해결해서 실제 GPU 장치에서 성능 이점을 얻는다. AWQ 와 TEQ 는 fine-grained group-wise quantization 으로 model quality 를 개선한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="22-parameter-efficient-fine-tuning-peft">2.2 Parameter-efficient Fine-tuning (PEFT)<a href="#22-parameter-efficient-fine-tuning-peft" class="hash-link" aria-label="Direct link to 2.2 Parameter-efficient Fine-tuning (PEFT)" title="Direct link to 2.2 Parameter-efficient Fine-tuning (PEFT)">​</a></h2><p>PEFT 는 LLM 의 fine-tuning cost 을 최소화하도록 설계돼 새로운 문제를 저렴하게 해결할 잠재력을 열어준다. LoRA 는 pre-trained weight 를 freeze 하고 low-rank parameter 를 추가해서 fine-tuning 중에만 업데이트하는 대표적인 연구다. LoRA 는 제약된 update scheme 으로 LLM 이 unseen task 에 놀랍게 적응하는 PEFT 의 잠재력을 보여준다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="23-quantization-aware-peft">2.3 Quantization-aware PEFT<a href="#23-quantization-aware-peft" class="hash-link" aria-label="Direct link to 2.3 Quantization-aware PEFT" title="Direct link to 2.3 Quantization-aware PEFT">​</a></h2><p>QLoRA 는 LoRA 개념을 확장해서 weight quantization 을 통합하고, pre-trained weight 를 quantization 으로 압축한다. 이는 fine-tuning 과정을 더 가볍게 하지만, 추가 FP16 path 가 quantized base weight 에 자유롭게 합쳐질 수 없어서 inference 성능이 느려진다.</p><p>QA-LoRA 는 updated weight 를 low-precision weight 의 zero-point 위에 합치는 다른 접근법을 제공한다. 이는 QLoRA 와 달리 fine-tuning 후 high-precision path 가 필요 없고, 비슷한 fine-tuning quality 를 보여주지만, 여전히 큰 fine-tuning overhead 가 있고, PEFT merging 같은 고급 LoRA application 에 대한 유연성은 탐구되지 않았다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="24-outlier-aware-weight-quantization">2.4 Outlier-aware Weight Quantization<a href="#24-outlier-aware-weight-quantization" class="hash-link" aria-label="Direct link to 2.4 Outlier-aware Weight Quantization" title="Direct link to 2.4 Outlier-aware Weight Quantization">​</a></h2><p>최근 OWQ 는 weight-only quantization 을 위한 intra-layer mixed precision quantization scheme 을 도입했다. OWQ 에서 목표는 layer-wise error 를 줄이는 건데, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span></span>-th output channel 에 대한 error 는 다음과 같이 분해된다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>E</mi><mi>i</mi></msub><mo>=</mo><mi mathvariant="normal">∥</mi><msub><mi>W</mi><mrow><mi>i</mi><mo separator="true">,</mo><mo>:</mo></mrow></msub><mi>X</mi><mo>−</mo><msub><mover accent="true"><mi>W</mi><mo>^</mo></mover><mrow><mi>i</mi><mo separator="true">,</mo><mo>:</mo></mrow></msub><mi>X</mi><msubsup><mi mathvariant="normal">∥</mi><mn>2</mn><mn>2</mn></msubsup><mo>≈</mo><mi mathvariant="normal">Δ</mi><msub><mi>W</mi><mrow><mi>i</mi><mo separator="true">,</mo><mo>:</mo></mrow></msub><mi>H</mi><mi mathvariant="normal">Δ</mi><msubsup><mi>W</mi><mrow><mi>i</mi><mo separator="true">,</mo><mo>:</mo></mrow><mi>T</mi></msubsup></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} E_i = \| W_{i,:} X - \hat{W}_{i,:} X \|_2^2 \approx \Delta W_{i,:} H \Delta W_{i,:}^T \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3299em;vertical-align:-0.4149em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9149em"><span style="top:-2.9682em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord">∥</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-2.453em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mrel mtight">:</span></span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4149em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9149em"><span style="top:-2.9149em"><span class="pstrut" style="height:2.9468em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4149em"><span></span></span></span></span></span></span></span></span></div><p>Weight matrix 의 Hessian 은 specific weight 의 sensitivity 를 추정하는 데 중요한 역할을 한다. 하지만 같은 output channel 의 weight 는 동일한 Hessian 값 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>H</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">H^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span> 를 공유한다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msup><mi>H</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mi>H</mi><mo>=</mo><mfrac><mrow><msup><mi mathvariant="normal">∂</mi><mn>2</mn></msup><msub><mi>E</mi><mi>i</mi></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msubsup><mi>W</mi><mrow><mi>i</mi><mo separator="true">,</mo><mo>:</mo></mrow><mn>2</mn></msubsup></mrow></mfrac><mo>=</mo><mn>2</mn><mi>X</mi><msup><mi>X</mi><mi>T</mi></msup></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} H^{(i)} = H = \frac{\partial^2 E_i}{\partial W_{i,:}^2} = 2 X X^T \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.5901em;vertical-align:-1.045em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.545em"><span style="top:-3.545em"><span class="pstrut" style="height:3.4911em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4911em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959em"><span style="top:-2.4231em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mrel mtight">:</span></span></span></span><span style="top:-3.0448em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.099em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.045em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.545em"><span style="top:-3.545em"><span class="pstrut" style="height:3.4911em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.045em"><span></span></span></span></span></span></span></span></span></div><p>이 공식에서 activation outlier 가 weight quantization 만 적용해도 specific weight column 의 sensitivity 를 크게 높인다는 걸 관찰했다. OWQ 에서는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05724em">j</span></span></span></span></span>-th column 의 quantization sensitivity 를 다음과 같이 계산한다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mtext>sensitivity</mtext><mi>j</mi></msub><mo>=</mo><msub><mi>λ</mi><mi>j</mi></msub><msubsup><mrow><mo fence="true">∥</mo><mi mathvariant="normal">Δ</mi><msub><mi>W</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo fence="true">∥</mo></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \text{sensitivity}_j = \lambda_j \left\| \Delta W_{i,j} \right\|_2^2 \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3343em;vertical-align:-0.4171em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9171em"><span style="top:-2.9631em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord text"><span class="mord">sensitivity</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2175em"><span style="top:-2.4559em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3802em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em">∥</span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">∥</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.954em"><span style="top:-2.3642em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3358em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4171em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9171em"><span style="top:-2.9171em"><span class="pstrut" style="height:2.954em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4171em"><span></span></span></span></span></span></span></span></span></div><ul><li>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 는 Hessian 의 diagonal element 다. </li><li>그 후 top-<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> sensitive column (weak column) 을 FP16 으로 보존하고 나머지 robust weight 만 4-bit 또는 3-bit 로 압축한다.</li></ul><p>OWQ 는 평균 0.01 bit 추가로 model quality 를 크게 향상시킨다. 하지만 mixed-precision format 은 GPU 와 non-GPU 환경 모두에서 배포에 어려움을 겪어서 실질적 이점이 제한된다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="25-weak-column-tuning">2.5 Weak Column Tuning<a href="#25-weak-column-tuning" class="hash-link" aria-label="Direct link to 2.5 Weak Column Tuning" title="Direct link to 2.5 Weak Column Tuning">​</a></h2><p>OWQ 는 mixed-precision 으로 PEFT 를 가능하게 하는 개념도 도입했다. Weak Column Tuning (WCT) 라는 이 아이디어는 FP16 weak column 을 task-specific 방식으로 업데이트하고 나머지 quantized data 는 freeze 한다. </p><p>OWQ 의 WCT 는 inference 와 fine-tuning 모두에서 low precision 의 장점을 유지하지만 몇 가지 한계가 있다:  </p><ul><li>WCT 는 weak column 기반 tuning parameter 선택의 최적성을 보장하는 이론적 지원이 부족하다. 특정 task 에 대한 feasibility 만 증명됐을 뿐이다.  </li><li>WCT 의 versatility 는 아직 검증되지 않아 LoRA 기반 접근법보다 덜 선호된다.  </li><li>가장 중요한 건 OWQ 의 불규칙한 mixed-precision weight 가 acceleration 에 어려움을 준다는 점이다.</li></ul><h1>3 Detailed Overview of QEFT</h1><p>이번 연구에서 저자는 QEFT 를 소개한다. 이는 mixed-precision quantization 으로 inference 와 fine-tuning 에서 higher speed 를 달성하고, hardware-friendly 하며 expressiveness 덕분에 better fine-tuned quality 를 제공한다. 이 섹션에서 QEFT 를 자세히 설명하고, Sec. 4 에서 fine-tuning 능력을 다룬다. 그 다음 Sec. 5 에서 versatility 를 검증하는 고급 예시인 PEFT merging 을 논의한다.</p><p><img loading="lazy" alt="Figure 2" src="/assets/images/image-49-2590c067751e5a9757008ee327d9ee8d.png" width="957" height="658" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="31-data-structure-and-quantization-process">3.1 Data Structure and Quantization Process<a href="#31-data-structure-and-quantization-process" class="hash-link" aria-label="Direct link to 3.1 Data Structure and Quantization Process" title="Direct link to 3.1 Data Structure and Quantization Process">​</a></h2><p>QEFT 는 LLM 의 linear layer 의 dense weight 에 mixed-precision quantization 을 적용한다. Quantization 후에는 세 가지 data component 가 생성된다:  </p><ul><li>Dense low-precision matrix  </li><li>Group-wise quantization parameter  </li><li>High-precision weak column  </li></ul><p>Fig. 2(c) 에 나와 있듯이 OWQ 와 비슷하게 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> sensitive columns 를 찾아서 FP16 으로 보존한다. 하지만 구현의 핵심 차이는 QEFT 가 Sec. 3.2 에서 설명하는 새로운 Offline Global Reordering (OGR) 을 써서 OWQ 의 불규칙성(Fig. 2(b))과 달리 structured format 을 보장한다는 점이다.</p><p>그 후 나머지 weight 는 4-bit 이하로 저장된다. OWQ 의 per-channel quantization 기반 quantization error 를 더 줄이기 위해 group-wise quantization 을 도입한다. 그래서 adjacent <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span></span></span></span></span> weights 가 같은 quantization parameter (scaling factor 와 zero-point) 를 공유한다. 각 group 에 대해 truncation 후 weight 의 squared error 를 최소화하는 quantization parameter 를 찾기 위해 grid search 를 한다. 그 다음 searched parameter 를 사용해 OPTQ 를 적용해서 optimal low-precision mapping 을 찾는다. OPTQ 는 original channel-wise min-max quantization 에 의존하지만, 저자는 group-wise quantization 과 truncation 의 장점을 활용해서 high-quality quantized weight 를 얻는다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="32-offline-global-reordering">3.2 Offline Global Reordering<a href="#32-offline-global-reordering" class="hash-link" aria-label="Direct link to 3.2 Offline Global Reordering" title="Direct link to 3.2 Offline Global Reordering">​</a></h2><p>OWQ 에서 mixed-precision 은 acceleration 을 어렵게 한다. Weak column 의 index 는 offline 에서 미리 정해지고 activation outlier 의 위치와 연관되지만(Fig. 2(b)), 불규칙한 mixed-precision format 은 decompression 과정에서 여러 branch 를 도입해서 구현이 복잡해지고 느려진다. 게다가 이런 특성은 in-DRAM accelerator 나 NPU 같은 신흥 hardware 에서 일반적으로 dense computation 만 지원하기 때문에 지원하기 어렵다.</p><p>이 한계를 해결하려면 data representation 을 predictability 와 continuity 를 위해 수정해야 한다. 이전 노력은 inference 중 normalization layer 에서 activation 을 reordering 해서 high-precision weight 를 한쪽으로 모으고 low-precision weight 와 분리했다. 이는 dense matrix multiplication 으로 computation 을 가속하지만, online reordering 은 추가 inference latency 를 발생시켜 quantization 의 이점을 상쇄한다.</p><p>Online 비용 없이 불규칙성을 없애기 위해 저자는 Offline Global Reordering (OGR) 라는 새로운 개념을 도입한다. </p><p><img loading="lazy" alt="Figure 3" src="/assets/images/image-50-2cfacd4ce320bdc4b73c9bd2853d3b07.png" width="545" height="860" class="img_ev3q"></p><ul><li>이는 layer 간 outlier channel index 가 크게 겹친다는 핵심 관찰에서 비롯된다. </li><li>Fig. 3(a) 에서 Llama-2 7B model 의 각 transformer block 에 대해 top-8 weak column 의 layer-wise index 를 시각화한 걸 보면 이 겹침을 알 수 있다. <ul><li>이 겹침은 outlier activation 이 residual connection 을 통해 후속 layer 로 전파되면서 weak column index 가 layer 간에 정렬되기 때문에 생긴다. </li></ul></li><li>이 관찰을 바탕으로 저자는 Fig. 3(a) 에서처럼 전체 network 에 걸친 common (global) weak column 을 식별하고 사용한다. </li><li>Weight perturbation 은 layer 간에 크게 달라질 수 있으므로 Eq. (3) 의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mi>j</mi></msub><msubsup><mrow><mo fence="true">∥</mo><mi mathvariant="normal">Δ</mi><msub><mi>W</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo fence="true">∥</mo></mrow><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">\lambda_j \left\| \Delta W_{i,j} \right\|_2^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2898em;vertical-align:-0.3358em"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em">∥</span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">∥</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.954em"><span style="top:-2.3642em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3358em"><span></span></span></span></span></span></span></span></span></span></span> 대신 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\lambda_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> 만 사용한다. <ul><li>이 metric 의 최적성은 Sec. 4 에서 논의된다.</li></ul></li></ul><p>Global weak column 이 선택되면 Fig. 3(b) 에서처럼 embedding 과 head layer 의 weight 와 transformer block 내 layer 를 offline 으로 재배열할 수 있다. Model 을 global 하게 reordering 하면 각 linear layer 의 weak column 이 structured dense matrix 를 형성하고, 해당 activation 도 연속적으로 위치한다. 예외는 attention output projection layer 인 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>O</mi></msub></mrow><annotation encoding="application/x-tex">W_O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">O</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 다 (Fig. 3(b)). Multi-head attention mechanism 을 유지하려면 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>O</mi></msub></mrow><annotation encoding="application/x-tex">W_O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">O</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> weight 에 reordering 을 적용할 수 없다. 이 경우 mixed-precision format 을 reordering 없이 사용한다.</p><p>Tab. 1 은 QEFT 에서 제안된 component 의 효과를 Llama-2 7B 로 보여준다.</p><p><img loading="lazy" alt="Table 1" src="/assets/images/image-51-7ae890ff4f5de54d55ecf41464e60e4f.png" width="626" height="421" class="img_ev3q"></p><ul><li>참고로 OWQ 설정에서 시작해서 online reordering 과 OGR 의 영향을 각각 측정했다. </li><li>Table 은 online reordering 이 overhead 때문에 제한된 이점만 제공하는 반면, OGR 은 inference 를 크게 가속한다는 걸 나타낸다. </li><li>Weak column 이 대부분 겹치지만, global weak column 을 사용하면 겹치지 않는 column index 가 적어서 약간의 accuracy 저하가 있을 수 있다. </li><li>Pareto-front 솔루션을 실현하려면 이 저하를 해결하고 OWQ 의 channel-wise quantization 대신 group quantization 을 고려한다. </li><li>기본 group size 는 128 을 썼고, 이는 quantization error 를 줄여 fine-tuned 성능을 개선하며, 저자의 최적화된 kernel 덕분에 hardware overhead 는 무시할 만하다. </li><li>Group-wise parameter 수가 늘어나면서 memory usage 가 3923MB 에서 4107MB 로 약간 증가한다. </li><li>결과는 OGR 과 group quantization 을 같이 쓰는 게 최선이고, globally reordered model 은 각 layer 에서 최적 선택과 거의 같은 few-shot score 를 보이면서 inference speed 를 크게 높인다.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="321-gpu-acceleration-kernel-for-qeft">3.2.1 GPU Acceleration Kernel for QEFT<a href="#321-gpu-acceleration-kernel-for-qeft" class="hash-link" aria-label="Direct link to 3.2.1 GPU Acceleration Kernel for QEFT" title="Direct link to 3.2.1 GPU Acceleration Kernel for QEFT">​</a></h3><p>QEFT 의 잠재력을 최대한 끌어내기 위해 reordered format 에 맞춘 customized matrix-vector multiplication GPU kernel 을 개발했다. 이 kernel 은 먼저 quantized dense matrix 를 FP16 format 으로 dequantize 해서 activation 과 곱한다. 그 다음 high-precision dense weight 와 activation 의 multiplication 을 수행한다. OGR 덕분에 두 dense computation 을 매끄럽게 적용할 수 있고, 실제로는 single kernel 로 fusion 된다. 이 customized kernel 이 inference 성능에 미치는 영향은 Sec. 6.4 에서 검증된다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="33-efficient-backward-computation">3.3 Efficient Backward Computation<a href="#33-efficient-backward-computation" class="hash-link" aria-label="Direct link to 3.3 Efficient Backward Computation" title="Direct link to 3.3 Efficient Backward Computation">​</a></h2><p><img loading="lazy" alt="Figure 4" src="/assets/images/image-52-d788a578af9da333f752f71281e374bb.png" width="774" height="583" class="img_ev3q"></p><p>QEFT 를 활용하면 fine-tuning 에 또 다른 큰 장점이 생긴다. </p><ul><li>Fig. 4 에서 보듯이 linear layer 의 backward computation 은 input <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span></span> 와 weight <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span></span> 에 대한 gradient 를 계산하는 두 GeMM operation 을 포함한다. </li><li>LoRA 기반 접근법과 달리 QEFT 는 rectangular-shaped trainable weight 에 대해서만 gradient 를 계산해서 weight gradient 의 전체 FLOPs 를 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mi mathvariant="normal">/</mi><mi>I</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">k/IC</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span></span> 로 줄인다. 이 감소는 fine-tuning 동안 큰 성능 이점을 준다. </li><li>게다가 Fig. 4 에서처럼 weak column 에 해당하는 activation subset 만 저장하면 된다. </li><li>Weak column 의 weight gradient 는 entire activation tensor 없이 계산할 수 있어서 memory footprint 도 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mi mathvariant="normal">/</mi><mi>I</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">k/IC</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span></span> 로 줄어든다. </li><li>QEFT 의 중요한 점은 OGR 기반 구조적 data representation 을 써서 PyTorch 같은 기존 framework 에서 backward 구현이 쉽다는 거다.</li></ul><h1>4 Optimal Weak Column Selection</h1><p>QEFT 는 fine-tuning 과 inference 에 효율적이면서도 뛰어난 fine-tuning quality 를 제공한다. 이 섹션에서 저자는 weak column  را mask 로 선택해서 tunable parameter 로 사용하는 게 sparse PEFT 후 loss value 를 최소화하는 최적 전략이라는 이론적 지원을 증명한다. 조건은 다음과 같다:  </p><ul><li>각 linear layer 에 fixed budget 이 할당된다.  </li><li>Selection 은 per-channel granularity 로 적용된다.  </li></ul><p>먼저 sparse PEFT 를 다음과 같이 공식화한다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mrow><mi mathvariant="normal">Δ</mi><mi>θ</mi><mo separator="true">,</mo><mi>M</mi></mrow></munder><mi>L</mi><mrow><mo fence="true">(</mo><msup><mi>θ</mi><mn>0</mn></msup><mo>+</mo><mi>M</mi><mi mathvariant="normal">Δ</mi><mi>θ</mi><mo fence="true">)</mo></mrow></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \min_{\Delta \theta, M} L\left( \theta^0 + M \Delta \theta \right) \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7523em;vertical-align:-0.6262em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1262em"><span style="top:-3.2621em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em"><span style="top:-2.3479em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Δ</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8882em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">)</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6262em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1262em"><span style="top:-3.1262em"><span class="pstrut" style="height:2.8641em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6262em"><span></span></span></span></span></span></span></span></span></div><ul><li>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>θ</mi><mn>0</mn></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>O</mi><mi>C</mi><mo>×</mo><mi>I</mi><mi>C</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\theta^0 \in \mathbb{R}^{OC \times IC}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8532em;vertical-align:-0.0391em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">OC</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.07847em">I</span><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span></span> 는 pre-trained weight 이고, </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">OC</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">OC</span></span></span></span></span> 와 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">IC</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span></span> 는 각각 output 과 input channel dimension 이다. </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>θ</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>O</mi><mi>C</mi><mo>×</mo><mi>I</mi><mi>C</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\Delta \theta \in \mathbb{R}^{OC \times IC}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">OC</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.07847em">I</span><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span></span> 는 updated weight, </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span></span></span></span></span> 은 target loss function, </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>I</mi><mi>C</mi><mo>×</mo><mi>I</mi><mi>C</mi></mrow></msup></mrow><annotation encoding="application/x-tex">M \in \mathbb{R}^{IC \times IC}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em">I</span><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.07847em">I</span><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span></span> 는 channel-wise parameter mask 다. </li><li>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">M_{i,j} = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span></span> if <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">i \neq j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05724em">j</span></span></span></span></span> 이거나 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">M_{i,j} \in \{0,1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span></span> otherwise 다. </li></ul><p>Fine-tuning 효과를 극대화하려면 loss 를 최소화할 적절한 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span></span> 을 선택해야 한다. Second-order approximation 방법에 따르면 gradient 의 magnitude 를 기반으로 최적 mask 를 찾을 수 있다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="theorem">Theorem.<a href="#theorem" class="hash-link" aria-label="Direct link to Theorem." title="Direct link to Theorem.">​</a></h4><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>if </mtext><msub><mover accent="true"><mi>M</mi><mo>^</mo></mover><mi>u</mi></msub><mo>−</mo><mn>1</mn><mrow><mo fence="true">(</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mn>1</mn><mrow><mo fence="true">(</mo><mrow><mo fence="true">∣</mo><mfrac><mrow><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><msup><mi>θ</mi><mn>0</mn></msup><msubsup><mo stretchy="false">)</mo><mi>j</mi><mn>2</mn></msubsup></mrow><msub><mi>h</mi><mi>i</mi></msub></mfrac><mo fence="true">∣</mo></mrow><mo>&gt;</mo><mrow><mo fence="true">∣</mo><mfrac><mrow><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><msup><mi>θ</mi><mn>0</mn></msup><msubsup><mo stretchy="false">)</mo><mi>j</mi><mn>2</mn></msubsup></mrow><msub><mi>h</mi><mi>j</mi></msub></mfrac><mo fence="true">∣</mo></mrow><mo fence="true">)</mo></mrow><mo>≥</mo><mi>m</mi><mo>−</mo><mi>k</mi><mo fence="true">)</mo></mrow><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\text{if } \hat{M}_u - 1 \left( \sum_{j=1}^m 1 \left( \left| \frac{\nabla L(\theta^0)_j^2}{h_i} \right| &gt; \left| \frac{\nabla L(\theta^0)_j^2}{h_j} \right| \right) \geq m - k \right),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0968em;vertical-align:-0.15em"></span><span class="mord text"><span class="mord">if </span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1667em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:3.1758em;vertical-align:-1.4138em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size4">(</span></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size4">(</span></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.762em"><span style="top:-2.566em"><span class="pstrut" style="height:3.816em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-3.164em"><span class="pstrut" style="height:3.816em"></span><span style="height:1.816em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="1.816em" style="width:0.3333em" viewBox="0 0 333.33000000000004 1816" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V1816 H145z M145 0 H188 V1816 H145z"></path></svg></span></span><span style="top:-4.972em"><span class="pstrut" style="height:3.816em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5989em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.7848em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.836em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.762em"><span style="top:-2.566em"><span class="pstrut" style="height:3.816em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-3.164em"><span class="pstrut" style="height:3.816em"></span><span style="height:1.816em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="1.816em" style="width:0.3333em" viewBox="0 0 333.33000000000004 1816" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V1816 H145z M145 0 H188 V1816 H145z"></path></svg></span></span><span style="top:-4.972em"><span class="pstrut" style="height:3.816em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.762em"><span style="top:-2.566em"><span class="pstrut" style="height:3.816em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-3.164em"><span class="pstrut" style="height:3.816em"></span><span style="height:1.816em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="1.816em" style="width:0.3333em" viewBox="0 0 333.33000000000004 1816" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V1816 H145z M145 0 H188 V1816 H145z"></path></svg></span></span><span style="top:-4.972em"><span class="pstrut" style="height:3.816em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5989em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.7848em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9721em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.762em"><span style="top:-2.566em"><span class="pstrut" style="height:3.816em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-3.164em"><span class="pstrut" style="height:3.816em"></span><span style="height:1.816em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="1.816em" style="width:0.3333em" viewBox="0 0 333.33000000000004 1816" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V1816 H145z M145 0 H188 V1816 H145z"></path></svg></span></span><span style="top:-4.972em"><span class="pstrut" style="height:3.816em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size4">)</span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size4">)</span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span></span></span></span></span></div><p>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><msup><mi>θ</mi><mn>0</mn></msup><msub><mo stretchy="false">)</mo><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\nabla L(\theta^0)_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><msup><mi>θ</mi><mn>0</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\nabla L(\theta^0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span></span>-th element 이므로</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>inf</mi><mo>⁡</mo></mrow><mrow><mi mathvariant="normal">Δ</mi><mi>θ</mi></mrow></munder><mi>L</mi><mrow><mo fence="true">(</mo><msup><mi>θ</mi><mn>0</mn></msup><mo>+</mo><mover accent="true"><mi>M</mi><mo>^</mo></mover><mi mathvariant="normal">Δ</mi><mi>θ</mi><mo fence="true">)</mo></mrow><mo>≤</mo><munder><mrow><mi>inf</mi><mo>⁡</mo></mrow><mrow><mi mathvariant="normal">Δ</mi><mi>θ</mi><mo separator="true">,</mo><mi mathvariant="normal">∥</mi><mi>M</mi><msub><mi mathvariant="normal">∥</mi><mn>0</mn></msub><mo>=</mo><mi>k</mi><mo separator="true">;</mo></mrow></munder><mi>L</mi><mrow><mo fence="true">(</mo><msup><mi>θ</mi><mn>0</mn></msup><mo>+</mo><mi>M</mi><mi mathvariant="normal">Δ</mi><mi>θ</mi><mo fence="true">)</mo></mrow><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\inf_{\Delta \theta} L\left( \theta^0 + \hat{M} \Delta \theta \right) \leq \inf_{\Delta \theta, \|M\|_0 = k;} L\left( \theta^0 + M \Delta \theta \right).</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.9021em;vertical-align:-0.7521em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-2.3479em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Δ</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop">in<span style="margin-right:0.07778em">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7521em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1667em"><span class="mord">^</span></span></span></span></span></span></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.8301em;vertical-align:-0.966em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-2.309em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Δ</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span><span class="mpunct mtight">,</span><span class="mord mtight">∥</span><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span><span class="mord mtight"><span class="mord mtight">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mrel mtight">=</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mpunct mtight">;</span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop">in<span style="margin-right:0.07778em">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.966em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">.</span></span></span></span></span></div><p>이 theorem states 는 loss 의 infimum 을 최소화하는 mask <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>M</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9468em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1667em"><span class="mord">^</span></span></span></span></span></span></span></span></span></span></span> 이 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">∣</mo><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><msup><mi>θ</mi><mn>0</mn></msup><msubsup><mo stretchy="false">)</mo><mi>i</mi><mn>2</mn></msubsup><mo fence="true">∣</mo></mrow><annotation encoding="application/x-tex">\left| \nabla L(\theta^0)_i^2 \right|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.212em;vertical-align:-0.35em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.862em"><span style="top:-2.256em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.854em"><span class="pstrut" style="height:2.606em"></span><span style="height:0.016em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="0.016em" style="width:0.3333em" viewBox="0 0 333.33000000000004 16" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V16 H145z M145 0 H188 V16 H145z"></path></svg></span></span><span style="top:-2.862em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.862em"><span style="top:-2.256em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.854em"><span class="pstrut" style="height:2.606em"></span><span style="height:0.016em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="0.016em" style="width:0.3333em" viewBox="0 0 333.33000000000004 16" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V16 H145z M145 0 H188 V16 H145z"></path></svg></span></span><span style="top:-2.862em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></span></span></span> values 가 가장 큰 top <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> index 를 선택해서 구성될 수 있다는 걸 말한다. Channel-wise parameter mask 제약에서 largest <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">∣</mo><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><msup><mi>θ</mi><mn>0</mn></msup><msubsup><mo stretchy="false">)</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>i</mi></mrow><mn>2</mn></msubsup><mo fence="true">∣</mo></mrow><annotation encoding="application/x-tex">\left| \nabla L(\theta^0)_{i,i}^2 \right|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2568em;vertical-align:-0.3948em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.862em"><span style="top:-2.256em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.854em"><span class="pstrut" style="height:2.606em"></span><span style="height:0.016em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="0.016em" style="width:0.3333em" viewBox="0 0 333.33000000000004 16" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V16 H145z M145 0 H188 V16 H145z"></path></svg></span></span><span style="top:-2.862em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em"><span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.862em"><span style="top:-2.256em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.854em"><span class="pstrut" style="height:2.606em"></span><span style="height:0.016em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="0.016em" style="width:0.3333em" viewBox="0 0 333.33000000000004 16" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V16 H145z M145 0 H188 V16 H145z"></path></svg></span></span><span style="top:-2.862em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></span></span></span> values 인 index 를 골라서 fine-tuning 후 loss 를 최소화하는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>M</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9468em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1667em"><span class="mord">^</span></span></span></span></span></span></span></span></span></span></span> 을 만들 수 있다.</p><p>QEFT 에서 tunable weak column 은 Eq. (3) 에 의해 선택되는데, 이는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\lambda_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 와 weight perturbation 기반이다. 한편 linear layer 의 weight gradient 는 chain rule 로 계산된다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>θ</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow></mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>θ</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow></mfrac><msup><mi>X</mi><mi>T</mi></msup></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \nabla L(\theta) = \frac{\partial L}{\partial \theta} = \frac{\partial L}{\partial y} \frac{\partial y}{\partial \theta} = \frac{\partial L}{\partial y} X^T \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.2519em;vertical-align:-0.8759em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3759em"><span style="top:-3.3759em"><span class="pstrut" style="height:3.3714em"></span><span class="mord"><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8759em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3759em"><span style="top:-3.3759em"><span class="pstrut" style="height:3.3714em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8759em"><span></span></span></span></span></span></span></span></span></div><ul><li>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span></span> 는 activation 이고 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>θ</mi><mi>X</mi></mrow><annotation encoding="application/x-tex">y = \theta X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.07847em">θX</span></span></span></span></span> 다. </li><li>중요한 건 activation outlier 가 weak column 선택 (Eq. (3))과 weight gradient 를 둘 다 지배해서 QEFT 의 selection metric 이 largest <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">∣</mo><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><msup><mi>θ</mi><mn>0</mn></msup><msubsup><mo stretchy="false">)</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>i</mi></mrow><mn>2</mn></msubsup><mo fence="true">∣</mo></mrow><annotation encoding="application/x-tex">\left| \nabla L(\theta^0)_{i,i}^2 \right|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2568em;vertical-align:-0.3948em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.862em"><span style="top:-2.256em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.854em"><span class="pstrut" style="height:2.606em"></span><span style="height:0.016em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="0.016em" style="width:0.3333em" viewBox="0 0 333.33000000000004 16" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V16 H145z M145 0 H188 V16 H145z"></path></svg></span></span><span style="top:-2.862em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em"><span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.862em"><span style="top:-2.256em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.854em"><span class="pstrut" style="height:2.606em"></span><span style="height:0.016em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="0.016em" style="width:0.3333em" viewBox="0 0 333.33000000000004 16" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V16 H145z M145 0 H188 V16 H145z"></path></svg></span></span><span style="top:-2.862em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></span></span></span> values 인 column 을 선택하는 데도 유효하다는 점이다.</li></ul><p><img loading="lazy" alt="Figure 5" src="/assets/images/image-53-14a6733bbdc9695d9df8e682089e02b9.png" width="759" height="467" class="img_ev3q"></p><p>Fig. 5 는 Eq. (3) 와 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">∣</mo><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><msup><mi>θ</mi><mn>0</mn></msup><msubsup><mo stretchy="false">)</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>i</mi></mrow><mn>2</mn></msubsup><mo fence="true">∣</mo></mrow><annotation encoding="application/x-tex">\left| \nabla L(\theta^0)_{i,i}^2 \right|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2568em;vertical-align:-0.3948em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.862em"><span style="top:-2.256em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.854em"><span class="pstrut" style="height:2.606em"></span><span style="height:0.016em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="0.016em" style="width:0.3333em" viewBox="0 0 333.33000000000004 16" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V16 H145z M145 0 H188 V16 H145z"></path></svg></span></span><span style="top:-2.862em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em"><span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.862em"><span style="top:-2.256em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.854em"><span class="pstrut" style="height:2.606em"></span><span style="height:0.016em;width:0.3333em"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="0.016em" style="width:0.3333em" viewBox="0 0 333.33000000000004 16" preserveAspectRatio="xMinYMin"><path d="M145 0 H188 V16 H145z M145 0 H188 V16 H145z"></path></svg></span></span><span style="top:-2.862em"><span class="pstrut" style="height:2.606em"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></span></span></span> 간 상관관계를 보여준다. Quantization sensitivity 로 channel 을 정렬하면 top-<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> channel (weak column) 이 largest gradient magnitude 인 column 과 일치한다. 이는 저자가 quantization sensitivity 를 고려해 weak column 을 선택했지만 fine-tuning quality 도 고려된다는 걸 의미한다.</p><h1>5 Advanced Application: PEFT Merging</h1><p>QEFT 는 efficient inference 와 fine-tuning 을 위해 설계됐지만, LoRA 기반 접근법의 대안이 될 만큼 일반적이어야 한다. 이를 검증하기 위해 LoRA 의 고급 application 인 PEFT merging 에 QEFT 를 적용했다. Fig. 6 은 이 과정의 개요를 보여준다. </p><p><img loading="lazy" alt="Figure 6" src="/assets/images/image-54-3a1479781f7cf7eabe518664d71a9eae.png" width="744" height="788" class="img_ev3q"></p><ul><li>Figure 에서 보듯이 LoRA adapter 는 Open-Platypus dataset 으로 Llama-2 model 에서 fine-tune 된다. </li><li>Fine-tuning 후 updated weight 는 StableBeluga model 에 전송되는데, 이 model 도 Llama-2 로 초기화됐지만 다른 dataset 으로 fine-tune 된 거다. 그러면 Stable-Platypus2 가 만들어진다. </li><li>Semantic 차이가 있을 수 있음에도 Stable-Platypus2 는 놀랍게도 merge 전 각 model 보다 나은 quality 를 보인다.</li></ul><p>QEFT 의 merging 능력을 평가하려고 비슷한 접근법인 QEFT merging 을 시도했다. Quantized Llama-2 model 을 만들고 Open-Platypus dataset 으로 weak column 을 fine-tune 한다. Weak column 의 update (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo>=</mo><mi>B</mi><mo>−</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">\Delta = B - A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>) 는 StableBeluga model 에 합쳐진다. </p><p>Target model 이 full-precision model 이면 weak column index 에 따라 update 를 추가한다. Quantized StableBeluga 면 해당 weak column 에 update 를 추가한다. QEFT merging 도 놀랍게도 잘 작동한다는 걸 보여준다.</p><h1>6 Experiments</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="61-experiments-setting">6.1 Experiments Setting<a href="#61-experiments-setting" class="hash-link" aria-label="Direct link to 6.1 Experiments Setting" title="Direct link to 6.1 Experiments Setting">​</a></h2><p>QEFT 의 우수함을 보여주기 위해 저자는 폭넓은 분석을 진행했다. Fine-tuning 환경은 baseline 인 Platypus 의 설정을 따른다. OpenPlatypus dataset 을 fine-tuning 에 사용했는데, 이는 11 open-source datasets 에서 중복과 불필요한 부분을 걸러낸 거다. Open-Platypus dataset 이 STEM 과 logic question 영역에 초점을 맞췄기 때문에, 저자는 Platypus 의 evaluation 방법도 채택했다. 이는 open-llm-leaderboard 에서 가져온 few-shot task 들을 포함한다.</p><p>최신 leaderboard version 에 맞춰서, 저자는 6 tasks (MMLU, HellaSwag, ARC-c, TruthfulQA, Winogrande, GSM8k) 의 점수와 그 평균을 보고해서 fine-tuning 성능을 평가한다. 추가로, 이전 연구에서 사용된 4 tasks (MMLU, HellaSwag, ARC-c, TruthfulQA) 의 평균 점수도 보고한다. Few-shot accuracy 는 lm-eval-harness 로 측정했다. </p><ul><li>저자는 AdamW optimizer 를 batch size 16 으로 사용했다. </li><li>Learning rate 는 constant 로 설정해서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">k=16</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">16</span></span></span></span></span> 일 때는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">1 \times 10^{-5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span></span>, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>128</mn></mrow><annotation encoding="application/x-tex">k=128</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">128</span></span></span></span></span> 일 때는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>6</mn></mrow></msup></mrow><annotation encoding="application/x-tex">5 \times 10^{-6}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">6</span></span></span></span></span></span></span></span></span></span></span></span></span> 를 썼다. </li><li>70B model 에서 OPTQ reconstruction 이 overfitting 문제를 일으키는 걸 확인했는데, 이는 이전 연구에서도 발견된 거다. 그래서 4-bit Llama-2 70B 결과에는 OPTQ 대신 간단한 round-to-nearest quantization 을 사용했다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="62-overall-fine-tuning-results">6.2 Overall Fine-tuning Results<a href="#62-overall-fine-tuning-results" class="hash-link" aria-label="Direct link to 6.2 Overall Fine-tuning Results" title="Direct link to 6.2 Overall Fine-tuning Results">​</a></h2><p>QEFT 의 우수함을 비교하기 위해 5개 대표적인 방법(LoRA, Platypus, QLoRA, QA-LoRA, OWQ)을 골랐다. </p><ul><li>Platypus 는 base model 에 8-bit quantization 을 쓰고 FFN 에만 LoRA module 을 넣는다. </li><li>QLoRA/QA-LoRA 와 OWQ 는 4-bit quantization 을 사용해서 quality 와 performance 비교에 포함했다. </li><li>QLoRA/QA-LoRA 는 all linear layers 에 LoRA module 을 적용하고, OWQ 는 all linear layers 에서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> 개 weak column 을 FP16 으로 유지한다. </li><li>Tunable parameter 수로 보면 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo>≈</mo><mi>r</mi></mrow><annotation encoding="application/x-tex">k/2 \approx r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord">/2</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span></span></span> 인데, 각 LoRA module 이 두 개의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>×</mo><mi>r</mi></mrow><annotation encoding="application/x-tex">d \times r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span></span></span> adapter 를 쓰기 때문이다.</li></ul><p>저자는 control group (LoRA, Platypus, QLoRA, QA-LoRA, OWQ) 의 결과를 모두 재현했다. 단, Platypus 70B 는 자원이 많이 필요하고(8xA100 GPU 필요) training time 이 길어서 제외했다. 대신 Huggingface 에서 제공하는 공식 pre-trained weight 를 사용했다. OWQ 는 tuning code 가 없어서 저자의 설정으로 구현했다. 그래서 OWQ tuning 도 QEFT 의 customized code 를 써서 가속했다. 게다가 inference 와 달리 fine-tuning 중에는 computation 이 대부분 compute-bound matrix multiplication 이다. 이 경우 OGR 의 speed 이득은 단순한 dequantization 과정에서만 나오는데, OWQ 에 비해 training time 감소가 미미하다 (약 0.1시간 줄어듦).<br>
<!-- -->실험 결과는 Tab. 2 에 자세히 나와 있다. </p><p><img loading="lazy" alt="Table 2" src="/assets/images/image-55-a2dc0b0efe732851423a8f7c3beb62ea.png" width="1254" height="898" class="img_ev3q"></p><ul><li>QEFT 는 13B model 에서 다른 quantization-aware PEFT 들을 확실히 앞선다. 하지만 7B model 에서는 Platypus 가 tuning 성능이 제일 좋다. </li><li>주로 small model 에서 quantization 으로 인한 accuracy 저하가 두드러지기 때문이다. 그래도 base size (6.7GB vs. 4.1GB) 를 고려하면 QEFT 의 성능이 돋보인다. </li><li>심지어 7B 에서도 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>128</mn></mrow><annotation encoding="application/x-tex">k=128</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">128</span></span></span></span></span> 인 QEFT 는 다른 4-bit baseline 보다 나은 결과를 보여주고, 13B 에서는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">k=16</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">16</span></span></span></span></span> 만으로도 다른 방법들을 앞선다.  </li><li>흥미롭게도 Platypus, LoRA, QLoRA 는 7B 와 13B 에서 GSM8k 점수가 계속 낮다. 이는 기존 4개 benchmark 에 지나치게 맞춰진 tuning 때문일 수 있다.</li></ul><hr><ul><li>Platypus 는 70B model fine-tuning 에 4xA100 GPU 를 22시간 썼다고 보고했다. 반면 QEFT 는 single A100 GPU 로 11시간 만에 끝낸다. </li><li>GPU 시간으로 보면 약 8배 가속된 거다. 이는 제안한 방법의 memory-time efficiency 를 잘 보여준다. </li><li>Training cost 가 1/8 에 불과해도 QEFT-based model 의 fine-tuned quality 는 Platypus-70B 와 비슷하거나 더 낫고, baseline Llama-2 70B 를 크게 앞선다. </li><li>다른 4-bit 방법들과 비교해도 QEFT 는 계속 better accuracy 를 보여준다. 특히 QEFT 는 LoRA 기반 접근법보다 tuning time 이 훨씬 짧다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="63-peft-merging-results">6.3 PEFT Merging Results<a href="#63-peft-merging-results" class="hash-link" aria-label="Direct link to 6.3 PEFT Merging Results" title="Direct link to 6.3 PEFT Merging Results">​</a></h2><p>Tab. 3 은 두 개의 fully fine-tuned model (StableBeluga 와 OpenOrca) 에 대한 PEFT merging 결과를 보여준다. </p><p><img loading="lazy" alt="Table 3" src="/assets/images/image-56-48b34f206a95008bed2b6b0d2012f872.png" width="1562" height="540" class="img_ev3q"></p><ul><li>Platypus 연구의 merging 전략 목표를 따라, 저자는 4 tasks (MMLU, HellaSwag, ARC-c, TruthfulQA) 점수를 보고해서 상호보완 효과를 평가한다. </li><li>QEFT merging 은 fully fine-tuned model 의 weak column 에 해당하는 weight 만 수정하지만, all QEFT merging 경우에서 MMLU, ARC, TruthfulQA 점수가 같이 오른다. 그러니까 tuned weak column 을 merging 하면 reasoning 능력과 knowledge 능력이 둘 다 좋아진다는 거다.  </li><li>게다가 quantized target model (표에서 4-bit 로 표시) 과의 QEFT merging 은 FP16 LoRA merging 과 비슷한 accuracy 를 보여준다. </li><li>이 경우 QEFT format 덕분에 merged model size 가 줄어들고 inference 도 더 빨라진다. 두 merging 기술 모두 model quality 를 높이는 데 아주 유용하다. 이 관찰은 QEFT 가 PEFT merging 개념과 잘 맞는다는 걸 확인해준다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="64-inference-acceleration">6.4 Inference Acceleration<a href="#64-inference-acceleration" class="hash-link" aria-label="Direct link to 6.4 Inference Acceleration" title="Direct link to 6.4 Inference Acceleration">​</a></h2><p>이 섹션에서 저자는 QEFT 가 auto-regressive generation 시나리오에서 어떤 performance 이득을 주는지 보여준다. A100 80GB GPU 에서 LLaMA family 의 inference speed 를 benchmark 했다. Full-precision model 과 다른 tuning 방법들을 baseline 으로 썼다. 이 실험에서 저자는 FasterTransformer 의 optimized multi-head attention kernel 과 layer normalization kernel 을 모든 방법에 사용했다. 단, QA-LoRA 는 AutoGPTQ framework 를 쓰기 때문에 예외다. 결과는 batch size 1로 256개 token 을 생성한 초당 토큰 수의 중앙값으로 보고한다.</p><p><img loading="lazy" alt="Figure 7" src="/assets/images/image-57-73792d0a451708eff820221daa2ee725.png" width="962" height="536" class="img_ev3q"></p><ul><li>Tab. 2 에 보듯이 LoRA 기반 방법들의 low-rank path 는 inference 에 bottleneck 을 만든다. </li><li>전체 speed 를 눈에 띄게 줄인다. 게다가 Tab. 2 와 Fig. 7 에서 설명하듯이 OWQ 도 optimized kernel 을 쓰지만, QEFT 는 Llama-1/3 모든 model size 에서 OWQ 대비 약 30% speed-up 을 꾸준히 달성했다. </li><li>이 개선은 OGR 을 통해 mixed-precision 연산의 주요 overhead 인 불규칙한 memory access 를 없앤 덕분이다. 특히 QEFT 는 Llama-3 8B model 에서 OWQ 보다 약 2.4배 빠르다. </li><li>QEFT 의 kernel 이 작은 linear layer 와 group query attention 을 가진 model 에서도 높은 병렬 throughput 을 보여주기 때문이다.</li></ul><h1>7 Conclusion</h1><p>LLM 의 storage 와 computation 요구는 널리 쓰이는 데 큰 장벽을 만든다. Quantization 과 PEFT 가 각각 inference 와 fine-tuning 을 최적화하지만, 이 둘의 조화는 간과되곤 한다. </p><p>이번 연구에서 저자는 QEFT 를 소개한다. </p><ul><li>이는 fine-tuning compatibility 를 보장하면서 hardware compatibility 를 우선시하도록 설계됐다. </li><li>저자의 실험은 QEFT 가 가장 빠른 fine-tuning 을 달성하고 최고 accuracy 를 낸다는 걸 확인했다. </li><li>게다가 QEFT 는 inference 에서도 뛰어난 성능을 보여줘서 모든 면에서 탁월함을 강조한다.</li></ul><h1>Limitations</h1><p>Model quantization 과 parameter-efficient fine-tuning 은 training 중 regularizer 역할을 할 수 있지만, explicit regularization 메커니즘이 fine-tuning 결과 안정화에 종종 도움이 된다. 실제로 LoRA module 에는 stable training 을 보장하기 위해 Dropout 같은 추가 regularizer 가 사용된다. 하지만 QEFT 에는 현재 Dropout 같은 regularizer 가 포함되어 있지 않다. </p><p>저자의 실험에서 overfitting 징후가 뚜렷이 보이진 않았지만, 이 한계는 특정 task 에 따라 해결되지 않은 overfitting 문제를 일으킬 수 있다. 앞으로 regularization 후보를 탐구하는 게 미래 방향이다.</p><p>Performance 면에서 QEFT 는 FP16 을 low-precision 표현으로 바꾸는 데 시간이 걸린다. 보통 Llama-2 13B model 의 변환 과정은 약 1시간 걸리고, 자세한 건 Tab. 8 에 있다. 이 변환 비용은 일회성이라 Tab. 2 에 포함시키지 않았다. Quantized model 을 여러 downstream task 에 재사용하면 비용이 상쇄된다. 하지만 LLM 용량이 더 커지면 이 변환 비용을 고려해야 할 수도 있다.  </p><p>Global weak column 을 정해서 OGR 의 이점을 누릴 수 있지만, ‘out_proj’ weight 는 offline 이나 이전 layer 의 equivalent out channel reordering 으로 재배열되지 않는다. 그래서 ‘out_proj’ 의 reordering 은 OWQ 기반 customized kernel 을 써서 실시간으로 처리해야 한다. 이는 QEFT 의 high-throughput generation 시스템의 장점을 방해한다.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/peft">PEFT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/lo-ra">LoRA</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/low-rank">Low-Rank</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/qeft">QEFT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/quantization">Quantization</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/quantized-ll-ms">Quantized LLMs</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/offline-global-reordering">Offline Global Reordering</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/NLP/PEFT/Quantization/LoRA/2024-10-QEFT.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/NLP/PEFT/Quantization/LoRA/RoLoRA"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Prefix-Tuning: Optimizing Continuous Prompts for Generation</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#21-weight-only-quantization-of-llms" class="table-of-contents__link toc-highlight">2.1 Weight-only Quantization of LLMs</a></li><li><a href="#22-parameter-efficient-fine-tuning-peft" class="table-of-contents__link toc-highlight">2.2 Parameter-efficient Fine-tuning (PEFT)</a></li><li><a href="#23-quantization-aware-peft" class="table-of-contents__link toc-highlight">2.3 Quantization-aware PEFT</a></li><li><a href="#24-outlier-aware-weight-quantization" class="table-of-contents__link toc-highlight">2.4 Outlier-aware Weight Quantization</a></li><li><a href="#25-weak-column-tuning" class="table-of-contents__link toc-highlight">2.5 Weak Column Tuning</a></li><li><a href="#31-data-structure-and-quantization-process" class="table-of-contents__link toc-highlight">3.1 Data Structure and Quantization Process</a></li><li><a href="#32-offline-global-reordering" class="table-of-contents__link toc-highlight">3.2 Offline Global Reordering</a><ul><li><a href="#321-gpu-acceleration-kernel-for-qeft" class="table-of-contents__link toc-highlight">3.2.1 GPU Acceleration Kernel for QEFT</a></li></ul></li><li><a href="#33-efficient-backward-computation" class="table-of-contents__link toc-highlight">3.3 Efficient Backward Computation</a></li><li><a href="#61-experiments-setting" class="table-of-contents__link toc-highlight">6.1 Experiments Setting</a></li><li><a href="#62-overall-fine-tuning-results" class="table-of-contents__link toc-highlight">6.2 Overall Fine-tuning Results</a></li><li><a href="#63-peft-merging-results" class="table-of-contents__link toc-highlight">6.3 PEFT Merging Results</a></li><li><a href="#64-inference-acceleration" class="table-of-contents__link toc-highlight">6.4 Inference Acceleration</a></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.74164ba1.js"></script>
<script src="/assets/js/main.82abd802.js"></script>
</body>
</html>