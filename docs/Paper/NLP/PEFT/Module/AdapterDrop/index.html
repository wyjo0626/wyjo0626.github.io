<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/NLP/PEFT/Module/2021-10-AdapterDrop">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">AdapterDrop: On the Efficiency of Adapters in Transformers | WYJLab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Module/AdapterDrop"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="AdapterDrop: On the Efficiency of Adapters in Transformers | WYJLab"><meta data-rh="true" name="description" content="논문 및 이미지 출처 :"><meta data-rh="true" property="og:description" content="논문 및 이미지 출처 :"><link data-rh="true" rel="icon" href="/img/WYJLab.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Module/AdapterDrop"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Module/AdapterDrop" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Module/AdapterDrop" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="WYJLab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="WYJLab Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.9ed678b7.css">
<link rel="preload" href="/assets/js/runtime~main.4045ea26.js" as="script">
<link rel="preload" href="/assets/js/main.84227156.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Multi-Modal/PEFT/Composition/Moka">Multi-Modal</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">Analysis</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Attacking/universal-adversarial-prompt">Attacking</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Augmentation/PromptDA">Augmentation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Generalization/NoisyTune">Generalization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Model/Transformer">Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Multi-Task/Flan-T5">Multi-Task</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">PEFT</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">Composition</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Generalization/Flat-LoRA">Generalization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Mixture/UF">Mixture</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/Adapter">Module</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/Adapter">Parameter-Efficient Transfer Learning for NLP</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/K-Adapter">K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/MAD-X">MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/AdapterFusion">AdapterFusion: Non-Destructive Task Composition for Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/Compacter">COMPACTER: Efficient Low-Rank Hypercomplex Adapter Layers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/AdapterDrop">AdapterDrop: On the Efficiency of Adapters in Transformers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/MAD-G">MAD-G: Multilingual Adapter Generation for Efficient Cross-Lingual Transfer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/Meta-Adapter">Meta-Adapters: Parameter Efficient Few-shot Fine-tuning through Meta-Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/AdaMix">AdaMix: Mixture-of-Adaptations for Parameter-efficient Model Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/Hyper-X">Hyper-X: A Unified Hypernetwork for Multi-Task Multilingual Transfer</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Pruning/SMP">Pruning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/Fine-Tuning/AlphaTuning">Quantization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning">Soft Prompt</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Engineering/CoT/Chain-of-Thought">Prompt Engineering</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Tuning/PTR">Prompt Tuning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Reinforcement Learning/Reflexion">Reinforcement Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Text Generation/InstructGPT">Text Generation</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Composition/CLIP-LoRA">Vision-Language</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">NLP</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">PEFT</span><meta itemprop="position" content="3"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module</span><meta itemprop="position" content="4"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">AdapterDrop: On the Efficiency of Adapters in Transformers</span><meta itemprop="position" content="5"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>AdapterDrop: On the Efficiency of Adapters in Transformers</h1></header><p>논문 및 이미지 출처 : <a href="https://aclanthology.org/2021.emnlp-main.626.pdf" target="_blank" rel="noopener noreferrer">https://aclanthology.org/2021.emnlp-main.626.pdf</a></p><h1>Abstract</h1><p>Transformer model 은 fine-tuning 비용이 크고, inference 가 느리며, 저장 요구량이 크다. 최근 접근법들은 smaller model 을 학습하거나, model 크기를 동적으로 줄이거나, light-weight adapter 를 학습하는 방식으로 이러한 단점을 해결하고 있다. </p><p>이 논문에서는 <strong>AdapterDrop</strong> 을 제안하는데, 이는 training 및 inference 중 transformer 의 lower layer 로부터 adapter 를 제거하는 방법이며, 위의 세 가지 방향의 개념을 모두 포함한다. </p><p>저자는 AdapterDrop 이 여러 task 에 대해 동시에 inference 를 수행할 때 computational overhead 를 동적으로 줄일 수 있으며, task 성능 저하는 최소화된다는 것을 보인다. 더 나아가 AdapterFusion 에서 adapter 를 가지치기(prune)하여 inference efficiency 를 향상시키면서도 task 성능을 완전히 유지한다.</p><h1>1 Introduction</h1><p>Transfer learning 은 NLP task 를 해결하기 위한 주요 방법으로 자리잡았으나, transformer-based model 은 수백만에서 수십억 개의 parameter 를 요구할 정도로 매우 깊기 때문에 inference 가 느리고 저장 요구량이 크다. 이러한 단점을 해결하기 위해 최근 세 가지 독립적인 연구 흐름이 발전하였다.</p><ol><li>smaller 및 faster model 로, distillation 되거나 처음부터 학습된 경우</li><li>run-time 에 model depth 를 줄여 inference time 을 동적으로 감소시키는 robust transformer</li><li>model 전체를 fine-tuning 하는 대신 각 layer 에 새로 도입된 weight 집합만 학습하여, task 간 대부분의 parameter 를 공유하는 adapter</li></ol><p>Adapter 는 machine translation, cross-lingual transfer, community QA, transfer learning 을 위한 task composition 등 다양한 분야에서 잘 작동하는 것으로 나타났다. 그러나 adapter 의 최근 인기에 비해, parameter efficiency 외의 computational efficiency 는 탐구되지 않았다.</p><p>저자는 이 격차를 메우고 training 및 inference 시 두 가지 adapter architecture 의 computational efficiency 를 확립한다. 또한 앞서 언급한 세 가지 방향의 아이디어를 통합하여 adapter-based model 의 효율성을 더욱 향상시키는 다양한 전략을 탐구한다. 저자의 전략은 training 및 inference 시 transformer 로부터 adapter 를 dropout 하는 방식에 기반하며, 이를 통해 사용 가능한 계산 자원에 따라 동적으로 조정 가능한 model 을 얻는다. 또한 제안한 방법은 pre-trained transformer model (e.g., base, large) 에 독립적이므로 광범위하게 적용 가능하다.</p><p><strong>Contributions:</strong></p><ol><li>Adapter 의 computational efficiency 를 full fine-tuning 과 비교하여 처음으로 확립한다. Adapter 의 training step 은 일반적인 hyperparameter 선택에서 full model fine-tuning 보다 최대 60% 빠르지만, inference 에서는 4–6% 더 느리다는 것을 보인다. 따라서 adapter 는 training 시간을 단축하려는 연구자나, 광범위한 hyperparameter tuning 이 필요한 상황에 적합하다.</li><li>AdapterDrop 을 제안한다. 이는 adapter 를 효율적이고 동적으로 제거하는 방법으로, task 성능에 미치는 영향은 최소화된다. Transformer 의 하위 layer 로부터 adapter 를 제거하면 multi-task setting 에서 inference 속도가 상당히 개선된다. 예를 들어, 처음 5 개 layer 에서 adapter 를 제거하면, AdapterDrop 은 8 개 task 를 동시에 inference 할 때 39% 더 빠르다. 이는 각 input 에 대해 여러 예측을 수행해야 하는 model 을 연구하는 데 유용하다.</li><li>AdapterFusion 에서 adapter composition 중 일부 adapter 를 prune 하고, transfer learning 이후 가장 중요한 adapter 만 유지하여 task 성능을 완전히 보존하면서도 inference 를 더 빠르게 수행한다. 이는 labeled training data 가 적은 상황에서 특히 적합하며, AdapterFusion 은 standard single task model 보다 충분한 개선을 달성할 수 있다.</li></ol><h1>2 Efficiency of Adapters</h1><p>저자는 먼저 AdapterDrop 을 적용하지 않은 adapter 의 computational efficiency 를 확립한다. </p><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-15-d786f0c63510e8dc5a44f272d63ed753.png" width="770" height="804" class="img_ev3q"></p><ul><li>Fig. 1 에 나타난 바와 같이, adapter 를 fine-tuning 할 때와 model 전체를 fine-tuning 할 때 forward pass 와 backward pass 에서 상당한 차이가 존재한다. </li><li>Forward pass 에서는 adapter 가 추가 요소로 인해 복잡성이 증가하지만, backward pass 에서는 전체 model 을 통해 backpropagation 할 필요가 없다. </li><li>저자는 AdapterHub.ml framework 를 사용하여 full model fine-tuning 과 Houlsby et al. adapter, Pfeiffer et al. adapter (Fig. 1 에 나타남) 의 training 및 inference 속도를 비교하였다. </li><li>측정은 BERT base 의 transformer configuration 으로 수행되었으며, 서로 다른 GPU 에서도 검증되었다.</li></ul><p>Tab. 1 은 일반적인 실험 configuration 에 해당하는 측정값을 제공한다.</p><p><img loading="lazy" alt="Table 1" src="/assets/images/image-14-45aad413d30c12e2bb29d547f97c252e.png" width="761" height="510" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="training">Training.<a href="#training" class="hash-link" aria-label="Direct link to Training." title="Direct link to Training.">​</a></h4><p>Adapter 는 full model fine-tuning 과 비교했을 때 상당히 빠를 수 있으며, 일부 configuration 에서는 최대 60% 빠르다. 두 adapter architecture 는 training efficiency 측면에서 큰 차이가 없으나, Pfeiffer adapter 는 구조가 더 단순하여 training step 이 약간 더 빠르다. 차이의 크기는 input size 에 따라 달라지며, 사용 가능한 CUDA core 가 주요한 병목 요소이다. Adapter 와 full fine-tuning 간에 training convergence 에서는 특별한 차이를 관찰하지 못했다.</p><p>Training 속도 향상은 gradient computation overhead 의 감소로 설명할 수 있다. Adapter 를 사용할 때 대부분의 parameter 가 고정(frozen)되며, 초반 component 를 통해 backpropagation 할 필요가 없다 (Fig. 1 참조).</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="inference">Inference.<a href="#inference" class="hash-link" aria-label="Direct link to Inference." title="Direct link to Inference.">​</a></h4><p>두 adapter architecture 는 fully fine-tuned model 대비 94–96% 속도를 보였으며, 이는 input size 에 따라 달라진다. 이는 대규모로 배포될 경우 상당한 영향을 미칠 수 있다.</p><h1>3 AdapterDrop</h1><p>저자는 adapter 가 training time 측면에서 더 효율적이라는 것을 확립했으나, 지속 가능하고 eefficient model 에 대한 필요성은 여전히 존재한다.</p><ul><li>가능한 한 적은 layer 를 통해 backpropagation 하는 것은 adapter training 의 efficiency 를 더욱 향상시킨다. </li><li>Inference efficiency 는 여러 task 에 대해 동시에 inference 를 수행할 때 transformer 의 lower layer 에서 representation 을 공유함으로써 개선될 수 있다. </li><li>즉, 동일한 input 에 대해 여러 개의 independent classification 을 수행하는 경우이다. </li></ul><p>Tab. 2 에서 확인된 바와 같이, 16 개 task 에 대해 layer 하나가 공유될 때마다 model 은 최대 8.4% 빨라졌다.</p><p><img loading="lazy" alt="Table 2" src="/assets/images/image-16-d15f48637b42d27ece74f6962e38176f.png" width="767" height="291" class="img_ev3q"></p><p>이러한 관찰에 동기화되어 저자는 AdapterDrop 을 제안한다. </p><ul><li>이는 transformer 의 lower layer 로부터 adapter 를 동적으로 제거하는 방법이며 (Fig. 1 참조), 전체 transformer layer 를 dropout 하는 방식과 유사하지만 adapter setting 에 특화된 방법이다. </li><li>lower layer 는 task performance 에 미치는 영향이 작다는 것이 일반적이기 때문이다.</li></ul><p>저자는 AdapterDrop 의 두 가지 training 방법을 연구한다.</p><ol><li><strong>Specialized AdapterDrop</strong>: first <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span></span> 개 transformer layer 로부터 adapter 를 제거하며, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span></span> 은 training 동안 고정된다. 이는 각 가능한 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span></span> 에 대해 별도의 model 을 생성한다.</li><li><strong>Robust AdapterDrop</strong>: 각 training batch 마다 integer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span></span> 을 구간 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>11</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0, 11]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">11</span><span class="mclose">]</span></span></span></span></span> 에서 무작위로 추출한다. 이는 다양한 수의 dropped layer 에 적용 가능한 하나의 robust model 을 생성한다.</li></ol><p>AdapterDrop 의 효과성은 RoBERTa base 를 사용하여 GLUE benchmark devset 에서 연구되었다. </p><p><img loading="lazy" alt="Figure 2" src="/assets/images/image-17-4f2578c53596fdf4b3dbf6f1af6fe16b.png" width="770" height="770" class="img_ev3q"></p><ul><li>Fig. 2 에 따르면, Specialized AdapterDrop 은 여러 layer 가 제거되더라도 좋은 성능을 유지한다. </li><li>first 5 개 layer 를 제거했을 때, Specialized AdapterDrop 은 original performance 97.1% 를 유지하였다 (8 GLUE task 평균, Tab. 8 참조). </li><li>또한 Robust AdapterDrop 도 유사한 결과를 보였으며, 5 개 layer 가 제거되었을 때 original performance 95.4% 를 유지하였다. </li><li>Robust AdapterDrop 의 장점은 동적으로 확장 가능하다는 점이다. </li><li>현재 사용 가능한 계산 자원에 따라 동일한 parameter 집합을 사용하면서 layer 를 활성화하거나 비활성화할 수 있다. 반면 Specialized AdapterDrop 은 각 setting 에 대해 별도로 학습해야 한다.</li><li>효율성 향상은 상당히 클 수 있다. 여러 task 에 대해 동시에 inference 를 수행할 때, 5 layers 가 제거되면 inference 속도는 동시에 수행되는 task 수에 따라 21–42% 빨라졌다 (Tab. 2). </li><li>Robust adapter 의 training 역시 더 효율적이며, training step 속도를 26% 향상시켰다.</li></ul><h1>4 Efficiency of AdapterFusion</h1><p>AdapterFusion (AF) 은 여러 task 로부터 학습된 adapter 의 knowledge 를 활용하여, single target task 를 위해 adapter output representation 의 최적 조합을 학습한다 (Fig. 3 참조). </p><ul><li>AF 는 특히 작은 training set 에서 적절한 model 을 학습하기 어려운 상황에 유용하다. </li><li>그러나 AF 는 포함된 모든 adapter 를 순차적으로 거쳐야 하기 때문에 computational cost 가 크다.</li></ul><p>Tab. 3 은 training 과 inference 모두에서 차이가 상당할 수 있음을 보여준다.</p><p><img loading="lazy" alt="Table 3" src="/assets/images/image-18-f85111dfe7363839c88973c6bfd205e8.png" width="763" height="454" class="img_ev3q"></p><ul><li>예를 들어, fully fine-tuned model 과 비교했을 때, 8 개 adapter 를 사용하는 AF 는 training 시 약 47% 느리고 inference 시 62% 느리다.</li></ul><h1>5 AdapterDrop for AdapterFusion</h1><p>AF 의 효율성은 특히 inference 단계에서 개선할 잠재력이 크다. 저자는 AF 를 위한 AdapterDrop 의 두 가지 변형을 제안한다:</p><ol><li>전체 AF layer 제거</li><li>AF model 로부터 중요도가 낮은 adapter pruning</li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="51-removing-adapterfusion-layers">5.1 Removing AdapterFusion Layers<a href="#51-removing-adapterfusion-layers" class="hash-link" aria-label="Direct link to 5.1 Removing AdapterFusion Layers" title="Direct link to 5.1 Removing AdapterFusion Layers">​</a></h2><p>저자는 8 GLUE tasks 로부터 adapter 를 결합(fuse)하고, RTE 와 CoLA 에서 AF 의 가장 큰 성능 향상을 관찰하였다. 또한 §3 과 동일한 절차로 robust AF model 을 학습하였다. Test 시 몇 개의 하위 layer 로부터 AF 를 제거하더라도, AdapterDrop 없이 single-task adapter 보다 더 나은 성능을 유지할 수 있는지를 분석하였다.</p><p><img loading="lazy" alt="Figure 4" src="/assets/images/image-20-aea48be96a67b2fc6353a0094931dc9f.png" width="764" height="511" class="img_ev3q"></p><ul><li>Fig. 4 는 RTE 에서 AF 가 first 5 개 layer 까지 AF 를 제거하더라도 single-task adapter 보다 더 나은 성능을 보임을 나타낸다. </li><li>이는 inference 효율성을 26% 향상시킨다. 반면, CoLA 에서는 다른 경향을 보인다. </li><li>first layer 에서 AF 를 제거하면 성능 저하가 두드러지며, single-task adapter 보다 낮은 성능을 보인다. 이는 일부 linguistic task 가 초기 layer 의 정보에 크게 의존한다는 최근 연구와 일치한다.</li></ul><p>따라서 AdapterDrop 은 모든 task 에 적합하지 않을 수 있음을 명확히 강조한다. 그러나 Fig. 13 은 CoLA 가 가장 극단적인 사례임을 보여준다. 그럼에도 불구하고, AdapterFusion layer 를 제거할 때는 성능과 효율성 간의 trade-off 가 존재하므로 신중할 필요가 있다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="52-adapterfusion-pruning">5.2 AdapterFusion Pruning<a href="#52-adapterfusion-pruning" class="hash-link" aria-label="Direct link to 5.2 AdapterFusion Pruning" title="Direct link to 5.2 AdapterFusion Pruning">​</a></h2><p>AF 의 inference 효율성은 결합된 adapter 의 수에 크게 좌우된다 (Tab. 3 참조). 따라서 학습된 AF model 로부터 adapter 를 pruning 함으로써 효율성을 개선할 수 있다 (Fig. 3 참조).</p><p><img loading="lazy" alt="Figure 3" src="/assets/images/image-19-68d0f6fe206949d25456a52dfb64fa25.png" width="753" height="696" class="img_ev3q"></p><ul><li>저자의 가설은, adapter 가 AF 에 의해 자주 활성화되지 않는다면 output representation 에 크게 기여하지 않으므로 안전하게 제거할 수 있다는 것이다. </li><li>각 fusion layer 에서 AF training set 의 모든 instance 를 사용하여 adapter activation 의 평균값, 즉 상대적 중요도를 기록한 후, activation 이 가장 낮은 adapter 를 제거한다.</li></ul><p>Fig. 5 는 AF 의 대부분의 adapter 를 제거하더라도 task 성능에 영향을 주지 않음을 보여준다.</p><p><img loading="lazy" alt="Figure 5" src="/assets/images/image-21-476c7c83849781caed2613255ca4a284.png" width="756" height="508" class="img_ev3q"></p><ul><li>단 2 개 adapter 만 남겨도, 8 개 adapter 를 사용하는 full AF model 과 유사한 결과를 달성하며 inference 속도를 68% 향상시킨다. </li><li>따라서 실제 배포 전에 AdapterFusion pruning 을 수행할 것을 권장한다. 이는 성능을 완전히 유지하면서도 효율성을 달성할 수 있는 간단하면서 효과적인 기법이다.</li></ul><h1>6 Conclusion</h1><p>Adapter 는 full model fine-tuning 의 적절한 대안으로 부상했으며, 가장 널리 주장된 computational 이점은 smaller model 크기이다. 본 연구에서는 adapter 의 장점이 단순한 parameter efficiency 를 훨씬 넘어선다는 것을 보였다. 두 가지 일반적인 adapter architecture 는 저자의 확장 없이도 training step 이 최대 60% 더 빠르다. 그러나 이러한 개선은 inference 속도가 4–6% 느려지는 비용을 수반한다. 따라서 training 이 더 중요하다면, adapter 는 full model fine-tuning 보다 유리할 수 있다.</p><p>AdapterDrop 은 transformer 하위 layer 로부터 다양한 수의 adapter 를 제거함으로써 이러한 장점을 확장한다. Multi-task inference 수행 시 run-time computational overhead 를 동적으로 줄이면서 task 성능은 대부분 유지된다. 이는 하나의 input 에 대해 여러 독립적인 예측을 수행해야 하는 model 연구자들에게 도움이 된다.</p><p>마지막으로, 저자는 AdapterFusion model 의 computational efficiency 도 조사하였다. 전체 AdapterFusion layer 를 제거하면 성능과 효율성 사이의 상당한 trade-off 가 발생하였으나, 각 layer 에서 가장 적게 활성화된 adapter 를 pruning 하는 것은 성능을 완전히 유지하면서 model 효율성을 개선할 수 있었다.</p><p>저자는 본 연구가 널리 확장될 수 있으며, 효율적인 adapter-based model 을 얻기 위한 더 많은 방향이 존재한다고 믿는다. 예를 들어, 더 효율적인 pre-trained adapter 탐구, layer 간 adapter weight 공유, 학습 단계에서 AdapterFusion adapter pruning 등을 고려할 수 있다. 본 논문의 부록에서는 몇 가지 관련 아이디어에 대한 예비 결과를 제시하며, 이는 향후 연구의 출발점이 될 수 있다.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/peft">PEFT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/adapter">Adapter</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/adapter-drop">AdapterDrop</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/NLP/PEFT/Module/2021-10-AdapterDrop.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/NLP/PEFT/Module/Compacter"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">COMPACTER: Efficient Low-Rank Hypercomplex Adapter Layers</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/NLP/PEFT/Module/MAD-G"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">MAD-G: Multilingual Adapter Generation for Efficient Cross-Lingual Transfer</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#51-removing-adapterfusion-layers" class="table-of-contents__link toc-highlight">5.1 Removing AdapterFusion Layers</a></li><li><a href="#52-adapterfusion-pruning" class="table-of-contents__link toc-highlight">5.2 AdapterFusion Pruning</a></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.4045ea26.js"></script>
<script src="/assets/js/main.84227156.js"></script>
</body>
</html>