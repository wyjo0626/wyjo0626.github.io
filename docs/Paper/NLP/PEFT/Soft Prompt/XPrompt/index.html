<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/NLP/PEFT/Soft Prompt/2022-12-XPrompt">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">XPrompt: Exploring the Extreme of Prompt Tuning | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="XPrompt: Exploring the Extreme of Prompt Tuning | My Site"><meta data-rh="true" name="description" content="논문 및 이미지 출처 :"><meta data-rh="true" property="og:description" content="논문 및 이미지 출처 :"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="My Site RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="My Site Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.d2ad26d0.css">
<link rel="preload" href="/assets/js/runtime~main.c2f88002.js" as="script">
<link rel="preload" href="/assets/js/main.36090bf9.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">Analysis</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Augmentation/PromptDA">Augmentation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Model/Transformer">Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Multi-Task/Chain-of-Thought">Multi-Task</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">PEFT</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">Composition</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Mixture/UniPELT">Mixture</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/Adapter">Module</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Pruning/SMP">Pruning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/Fine-Tuning/SmoothQuant">Quantization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning">Soft Prompt</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning">GPT Understands, Too</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning">The Power of Scale for Parameter-Efficient Prompt Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2">P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT">ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/SPoT">SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt">XPrompt: Exploring the Extreme of Prompt Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter">LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning">Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2">LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning">Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/DEPT">DEPT: Decomposed Prompt Tuning For Parameter-Efficient Fine Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/APrompt">APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/SMoP">SMoP: Towards Efficient and Effective Prompt Tuning with Sparse Mixture-of-Prompts</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Tuning/PTR">Prompt Tuning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Reinforcement Learning/Reflexion">Reinforcement Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Text Generation/InstructGPT">Text Generation</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/UPL">Vision-Language</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">NLP</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">PEFT</span><meta itemprop="position" content="3"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Soft Prompt</span><meta itemprop="position" content="4"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">XPrompt: Exploring the Extreme of Prompt Tuning</span><meta itemprop="position" content="5"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>XPrompt: Exploring the Extreme of Prompt Tuning</h1></header><p>논문 및 이미지 출처 : <a href="https://aclanthology.org/2022.emnlp-main.758.pdf" target="_blank" rel="noopener noreferrer">https://aclanthology.org/2022.emnlp-main.758.pdf</a></p><h1>Abstract</h1><p>Prompt tuning 은 frozen Pre-trained Language Models (PLMs) 를 conditioning 하기 위해 soft prompts 를 학습한다.</p><p>모델 규모가 커짐에 따라 prompt tuning 은 점차 fine-tuning 수준에 도달하지만, moderate 및 small scales (&lt; 11B) 에선 여전히 성능 차이가 발생한다.</p><p>본 논문에서 저자는 trained prompt tokens 는 downstream task 에 negative 영향을 줄 수 있으며 성능 저하를 일으킬 것이라는 것을 경험적으로 보여준다.</p><ul><li>gap 을 줄이기 위해, 저자는 lottery tickets hypothesis 하에, <strong>Prompt</strong> tuning model with an e<strong>X</strong>tremely small scale (<strong>XPrompt</strong>) 를 제안</li><li>구체적으로, XPrompt 는 hierarchical structured pruning 을 통해 다양한 granularity levels 에서 negative prompt tokens 를 제거하여 더욱 parameter-efficient prompt 를 생성하여 competitive 성능 달성</li><li>SuperGLUE task 에서 포괄적 실험으로, smaller model scales 에서 성능 gap 을 줄여줌</li></ul><h1>1. Introduction</h1><p>PLMs 는 <em>pretrain-then-finetune</em> 을 통해 널리 사용되어 큰 성공을 거두지만, memory 공간에 gradient 및 optimizer 저장을 위해 trainable parameter 가 크게 차지하고 있어 fine-tuning 이 parameter-inefficient 하다.</p><hr><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-151-b31498b714d5720521c0cee3d4ffc077.png" width="633" height="663" class="img_ev3q"></p><p>최근 Prompt-Tuning (Lester et al. 2021) 으로 input 에 <em>soft prompt</em> 를 앞에 붙이고 훈련 중 prompt parameter 만 업데이트하여 위 이슈를 해결하는 것을 제안하였다.</p><ul><li>fine-tuning 대체제로, soft prompt scale 은 수만배 적음</li><li>더 간단하고 다른 peft (Adapter) 보다 유연하여 transformer layers 에 직관적으로 수정 가능</li><li>적은 tunable parameter 로 fine-tuning 성능과 competitive</li></ul><hr><p>위 gap 을 채우기 위해, 본 논문은 lottery tickets hypothesis (LTH) 관점에서 작성한다.</p><p>특정 task 에서 all prompt tokens 이 task 성능에 동등하게 기여하지 않는 관찰에 동기를 받아, 특정 prompt tokens 은 때론 negative 영향을 미칠 수 있다는 것이다.</p><p><img loading="lazy" alt="Figure 2" src="/assets/images/image-152-499da0113958fb8df0107b1853bbb6d2.png" width="704" height="726" class="img_ev3q"></p><p>Fig. 2 에서 관찰 결과를 보여준다.</p><ul><li><em>negative prompt tokens</em> 는 LTH 로 피할 수 있다.<ul><li>LTH 는 sub-network 를 포함한 over-parameterized network 가 독립적으로 훈련 및 초기화되면 original network 의 정확도와 맞먹거나 능가</li><li>이 sub-network 를 <strong>Lottery Ticket</strong> 이라 하며, PLMs 에서 이러한 ticket set 을 <strong>winning tickets</strong> 이라 한다.</li></ul></li><li>prompt tuning 에서 저자는 전체 prompt 사용의 성능과 동일하게 달성할 수 있는 <strong>positive prompt tokens</strong> 을 <strong>winning tickets</strong> 으로, <strong>negative prompt tokens</strong> 는 <strong>losing tickets</strong> 로 참조<ul><li>그래서 핵심은 winning tickets 은 식별하고 losing tickets 은 제거하는 것</li></ul></li><li>hierachical structed pruning 을 통해 losing tickets 을 제거하는 것 제안<ul><li><strong>token-level</strong> 에서 negative tokens 을 제거하고 <strong>granularity level (i.e. piece-level)</strong> 에서 남은 것들을 pruning</li></ul></li><li>LTH 와 일치하도록, 식별된 positive soft prompts 를 재훈련하기 위해 <strong>weight rewinding</strong> 채택</li></ul><p>위 과정으로 negative prompt tokens 이 제거되어 parameter-efficient small scale prompt (XPrompt) 를 얻을 수 있다.</p><hr><p>XPrompt 의 효과성 검증을 위해, high-resource 및 low-resource 상황의 SuperGLUE 에서 실험 진행</p><p>Fig. 1 및 Table. 1 에서 모든 task 및 model scale 에서 prompt-tuning 의 향상을 볼 수 있다.</p><ul><li>moderate scale 의 모델의 경우, XPrompt 로 fine-tuning 과 comparable 한 성능 달성 및 gap 줄임</li><li>large scale 의 모델의 경우, XPrompt 가 Prompt-Tuning 을 넘은 성능을 얻었고, 대부분의 task 에서 fine-tuning 도 넘어섰다.</li></ul><h1>2. Related Work</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="21-pre-trained-language-models">2.1 Pre-trained Language Models<a href="#21-pre-trained-language-models" class="hash-link" aria-label="Direct link to 2.1 Pre-trained Language Models" title="Direct link to 2.1 Pre-trained Language Models">​</a></h2><p>PLMs 는 NLP task 에서 큰 성공을 거두었다. </p><ul><li>BERT 및 RoBERTa 는 masked language model (MLM) 으로 context representation 을 학습하는 것을 개척</li><li>GPT-2, GPT-3 , ELECTRA, XLNet, BART 및 T5 같은 large PLMs 도 생겨남</li></ul><p>하지만 parameter 수가 폭발적으로 커지며, fine-tuning model 은 parameter-inefficient 및 computationally expensive 하게 됨</p><p>게다가 다양한 task 에 대해 fine-tuning 하고 각각 저장하기까지 해야 한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="22-prompt-learning-in-nlp">2.2 Prompt Learning in NLP<a href="#22-prompt-learning-in-nlp" class="hash-link" aria-label="Direct link to 2.2 Prompt Learning in NLP" title="Direct link to 2.2 Prompt Learning in NLP">​</a></h2><p>GPT-3 의 개발과 함께, input 에 여러 <em>prompt tokens</em> 를 추가하여 효율적인 학습을 하는 prompt tuning 이 관심을 받고 있다.</p><p>이는 다양한 downstream task 에서 효과적임을 입증했다.</p><ul><li>최근 discrete tokens (token in the vocabularies) 에서 continuous tokens (trainable embedding) 으로 확장<ul><li>예로 (Lester et al. 2021), soft prompt 만 tuning 하고 PLMs 는 freezing 하는 효율적인 prompt tuning 제안</li><li>하지만 여전히 moderate scale 에서는 fine-tuning 과의 gap 이 존재</li></ul></li><li>더 최근 (Vu et al. 2021) prompt-based transfer learning 인 SPoT 은 source task 에 prompt 를 학습하여 target task prompt 에 초기화하여 적용해 성능을 향상시킴</li><li>가장 최근 (He et al. 2022) HyperPrompt 는 hyper-prompts 를 생성하기 위해 hypernetwork 를 사용하여 우수한 성능 얻음</li></ul><p>위는 all parameter 를 조정해야 하며, task-conditioned parameter 만 튜닝하는 것이 multi-task learning 에 대한 fine-tuning 과 competitive 결과를 얻는데 충분치 않다는 것을 보여줌</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="23-lottery-ticket-hypothesis">2.3 Lottery Ticket Hypothesis<a href="#23-lottery-ticket-hypothesis" class="hash-link" aria-label="Direct link to 2.3 Lottery Ticket Hypothesis" title="Direct link to 2.3 Lottery Ticket Hypothesis">​</a></h2><p>lottery ticket hypothesis 는 over-parameterized network 는, 초기화되어 독립적으로 학습하면 기존 network 의 정확도와 일치하거나 능가할 수 있는 subnetwork 를 가진 다는 것을 발견</p><ul><li>이 subnetwork 를 <strong>lottery ticket</strong> 이라 함</li><li>NLP 에서의 lottery ticket set 은 winning ticket 이라 함</li><li>이러한 winning ticket 은 task 및 dataset 간의 transerability 를 입증</li><li>최근 Chen et al. (2021) 에서 PLM 이 lottery ticket 의 존재를 보여줌</li><li>Liang et al. (2021) 에선 winning ticket 의 일반화 성능이 full model 을 능가할 수 있음을 관찰</li></ul><h1>3. Preliminary</h1><p>T5 의 text-to-text 기반으로 한 prompt tuning 은 all task 를 text generation 으로 고려하며 additional <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span></span></span></span></span> tunable soft prompt token 을 input 에 추가하고, inserted soft prompt token 의 parameter 만 업데이트 수행</p><p>구체적으로, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span></span> 개의 input token <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">X = \{ x_1, x_2, \dots, x_n\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span> 이 있을 때, T5 는 먼저 token embeddings <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>e</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>×</mo><mi>e</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X_e \in \mathbb{R}^{n \times e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7713em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">e</span></span></span></span></span></span></span></span></span></span></span></span></span> 을 생성한다.</p><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">e</span></span></span></span></span> : embedding space dimension</li></ul><p>soft prompt embedding <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>e</mi></msub><mo>=</mo><mo stretchy="false">{</mo><msub><mi>p</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>p</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>p</mi><mi>m</mi></msub><mo stretchy="false">}</mo><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>m</mi><mo>×</mo><mi>e</mi></mrow></msup></mrow><annotation encoding="application/x-tex">P_e = \{ p_1, p_2, \dots, p_m \} \in \mathbb{R}^{m \times e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7713em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">e</span></span></span></span></span></span></span></span></span></span></span></span></span> 생성</p><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span></span></span></span></span> : soft prompt length </li></ul><p>이후 soft prompts 는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>P</mi><mi>e</mi></msub><mo separator="true">;</mo><msub><mi>X</mi><mi>e</mi></msub><mo stretchy="false">]</mo><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo stretchy="false">(</mo><mi>m</mi><mo>+</mo><mi>n</mi><mo stretchy="false">)</mo><mo>×</mo><mi>e</mi></mrow></msup></mrow><annotation encoding="application/x-tex">[P_e; X_e] \in \mathbb{R}^{(m+n) \times e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.888em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">m</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">e</span></span></span></span></span></span></span></span></span></span></span></span></span> 형태로 input sequence 앞에 추가</p><p>prompt tuning 목표는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">P_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 를 optimizing 하여 label <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span></span></span></span></span> 의 likelihood 를 최대화 하는 것</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi><munder><mo><mi>arg</mi><mo>⁡</mo><mi>max</mi><mo>⁡</mo></mo><msub><mi>P</mi><mi>e</mi></msub></munder></mi><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mo stretchy="false">[</mo><msub><mi>P</mi><mi>e</mi></msub><mo separator="true">;</mo><msub><mi>X</mi><mi>e</mi></msub><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \underset{P_e}{\arg \max} \log p(Y|[P_e; X_e]) \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.8789em;vertical-align:-0.6894em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1894em"><span style="top:-3.3494em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em"><span style="top:-2.1612em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop"><span class="mop">ar<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">max</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0389em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mord">∣</span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">])</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6894em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1894em"><span style="top:-3.1894em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6894em"><span></span></span></span></span></span></span></span></span></div><p>model scale 이 커짐에 따라 prompt tuning 은 더욱 효과적으로 작동한다.</p><p>하지만 small 및 moderate scale 에 대해서는 fine-tuning 과 성능 gap 이 존재한다.</p><p>저자의 가설은 target task 에 훈련 후 all soft prompt tokens 가 동등하게 성능에 기여하지 않을 것이라는 것이다.</p><p>특정 soft prompt tokens 은 task 에 negative impacts 를 줄 수 있다. 따라서 lottery ticket hypothesis 의 아이디어를 결합하여 저자는 XPrompt 를 제안한다.</p><p>이는 hierarchical structured pruning 을 사용하여 optimal soft prompts 를 식별하고 성능 차이를 줄인다.</p><h1>4. XPrompt</h1><p><img loading="lazy" alt="Figure 3" src="/assets/images/image-153-e50abbb6f6733c83c91033166ddcf29a.png" width="1450" height="606" class="img_ev3q"></p><p>Fig. 3 은 XPrompt 은 전체 과정이며 세 가지 main stages 를 포함한다.</p><ul><li><strong><em>Prompt-Tuning</em></strong></li><li><strong><em>Hierarchical Structured Pruning</em></strong></li><li><strong><em>Rewinding</em></strong></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="41-prompt-tuning">4.1 Prompt Tuning<a href="#41-prompt-tuning" class="hash-link" aria-label="Direct link to 4.1 Prompt Tuning" title="Direct link to 4.1 Prompt Tuning">​</a></h2><p>input 에 soft prompt tokens 을 붙여 PLM 은 fixing 한 채 soft prompt 만 tuning</p><p>Prompt tuning 은 다양한 downstream task 에 효과적이다.</p><p>저자의 prompt tuning 은 Liang et al. (2021) 에 따르며, all soft prompt tokens 에 대한 embeddings 을 얻기 위해 target task 에 완전히 tuning</p><p>위의 trained soft prompts 는 hierarchical structured pruning 에 초기화되어 사용됨</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="42-hierarchical-structured-pruning">4.2 Hierarchical Structured Pruning<a href="#42-hierarchical-structured-pruning" class="hash-link" aria-label="Direct link to 4.2 Hierarchical Structured Pruning" title="Direct link to 4.2 Hierarchical Structured Pruning">​</a></h2><p><img loading="lazy" alt="Figure 4" src="/assets/images/image-154-2a2042d1d10d3d30cca6f4f447edd7e2.png" width="885" height="546" class="img_ev3q"></p><p>Hierarchical Structured Pruning 은 trained prompt tokens 으로 부터 negative prompt tokens 을 분리하도록 설계하며 optimal soft prompt set 을 식별한다.</p><p>Fig. 4 에서 접근법을 보여준다.</p><ul><li>token-level pruning : negative prompt tokens 을 식별하기 위해 먼저 사용<ul><li>하지만, 남은 prompt tokens 에 nagative pieces 가 여전히 남아 있을 수 있다.</li></ul></li><li>piece-level pruning : 그래서, 각 prompt token 의 fine-grained negative prompt pieces 를 식별하기 위해 적용</li></ul><p>두 pruning 을 통해 효과성과 효율성 간의 균형을 더욱 잡아 준다.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="421-token-level-pruning">4.2.1 Token-level Pruning<a href="#421-token-level-pruning" class="hash-link" aria-label="Direct link to 4.2.1 Token-level Pruning" title="Direct link to 4.2.1 Token-level Pruning">​</a></h3><p>trained prompt tokens 의 negative prompt token 을 식별하기 위해, soft prompt token vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 에 <strong>mask variable <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>γ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\gamma_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span></strong> 을 연결</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mover accent="true"><mi>P</mi><mo>^</mo></mover><mi>e</mi></msub><mo>=</mo><mi>γ</mi><mo>⋅</mo><msub><mi>P</mi><mi>e</mi></msub></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \hat{P}_e = \gamma \cdot P_e \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3068em;vertical-align:-0.4034em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9034em"><span style="top:-2.9566em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1667em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4034em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9034em"><span style="top:-2.9034em"><span class="pstrut" style="height:2.9468em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4034em"><span></span></span></span></span></span></span></span></span></div><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>γ</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>γ</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>γ</mi><mi>m</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\gamma = \{\gamma_1, \gamma_2, \dots, \gamma_m\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span></li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>γ</mi><mi>i</mi></msub><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\gamma_i \in \{0,1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span></span></li><li>0 value : soft prompt token 이 제거된 것을 나타냄</li></ul><p>이후, negative prompt tokens 을 구별하기 위해 각 token 의 importance score 계산</p><p>importance score 는 mask variables 에 대한 model output 의 예상 민감도로 정의된다.</p><p>공식화 하면, soft prompt token <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 의 importance score <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><msub><mi>p</mi><mi>i</mi></msub></msub></mrow><annotation encoding="application/x-tex">I_{p_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> 는 다음과 같이 계산된다.</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>I</mi><msub><mi>p</mi><mi>i</mi></msub></msub><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>x</mi><mo>∼</mo><msub><mi>D</mi><mi>x</mi></msub></mrow></msub><mtext> </mtext><mi mathvariant="normal">∣</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>γ</mi><mi>i</mi></msub></mrow></mfrac><mi mathvariant="normal">∣</mi></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} I_{p_i} = \mathbb{E}_{x \sim D_x} \ |\frac{\partial \mathcal{L}(x)}{\partial \gamma_i}| \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3074em;vertical-align:-0.9037em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4037em"><span style="top:-3.4037em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord">∣</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathcal">L</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9037em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4037em"><span style="top:-3.4037em"><span class="pstrut" style="height:3.427em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9037em"><span></span></span></span></span></span></span></span></span></div><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi></mrow><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal">L</span></span></span></span></span> : loss function</li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">D_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> : training data distribution</li></ul><p>본질적으로, 각 soft prompt token 의 importance score 는 해당 token 이 model performance 에 개별적으로 기여하는 정도를 나타낸다.</p><p>낮은 score 는 모델에 small 또는 negative 기여를 나타낸다. 다시 말해, 해당 soft prompt token 은 output 생성에 무시할 만한 prompt information 을 포함하는 것을 의미한다.</p><p>반대로, 높은 score 는 의미 있는 prompt information 을 가진 주요 기여를 나타낸다.</p><p>따라서 importance score 가 낮은 prompt 는 negative prompt token 일 수 있으므로, token-level pruning 에서 제거된다.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="422-piece-level-pruning">4.2.2 Piece-level Pruning<a href="#422-piece-level-pruning" class="hash-link" aria-label="Direct link to 4.2.2 Piece-level Pruning" title="Direct link to 4.2.2 Piece-level Pruning">​</a></h3><p>Token-level pruning 은 soft prompt token 을 찾지만, 각 soft prompt token 의 embedding 에 여전히 negative prompt pieces 가 남아 충분하지 않을 수 있다.</p><p>embedding pieces 는 downstream task 에 다른 영향을 미칠 수 있으므로, 각 token 내의 negative prompt pieces 를 제거하기 위해 Piece-level pruning 을 수행한다.</p><p>특히, 각 soft prompt token 의 embedding vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><msub><mi>i</mi><mi>e</mi></msub></msub></mrow><annotation encoding="application/x-tex">p_{i_e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6807em;vertical-align:-0.2501em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em"><span></span></span></span></span></span></span></span></span></span></span> 를 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> pieces 로 나누어 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>e</mi></msub><mo>=</mo><mo stretchy="false">{</mo><msub><mi>q</mi><msub><mn>1</mn><mi>e</mi></msub></msub><mo separator="true">,</mo><msub><mi>q</mi><msub><mn>2</mn><mi>e</mi></msub></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>q</mi><msub><mi>k</mi><mi>e</mi></msub></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">q_e = \{ q_{1_e}, q_{2_e}, \dots, q_{k_e}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0001em;vertical-align:-0.2501em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:-0.0315em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span> 로 만들고 각 piece 를 gradient updates 로 optimize 가능한 독립적인 단위로 취급</p><p>각 soft prompt token 의 piece 에는 negative prompt pieces 식별을 위한 mask variable <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ζ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\zeta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07378em">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0738em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 가 연결된다</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi>q</mi><mo>^</mo></mover><mi>e</mi></msub><mo>=</mo><mi>ζ</mi><mo>⋅</mo><msub><mi>q</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">\hat{q}_e = \zeta \cdot q_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">q</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1667em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.07378em">ζ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span></div><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ζ</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>ζ</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>ζ</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>ζ</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\zeta = \{\zeta_1, \zeta_2, \dots, \zeta_k\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.07378em">ζ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07378em">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0738em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07378em">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0738em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07378em">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0738em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span></li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ζ</mi><mi>i</mi></msub><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\zeta_i \in \{0,1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07378em">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0738em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span></span></li><li>0 value : soft prompt token 이 제거된 것을 나타냄</li></ul><p>이후, low-imortance pieces 제거를 위해 모든 prompt token embedding 의 각 piece 의 importance score <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><msub><mi>q</mi><mi>i</mi></msub></msub></mrow><annotation encoding="application/x-tex">I_{q_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> 를 계산한다.</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>I</mi><msub><mi>q</mi><mi>i</mi></msub></msub><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>x</mi><mo>∼</mo><msub><mi>D</mi><mi>x</mi></msub></mrow></msub><mtext> </mtext><mi mathvariant="normal">∣</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>ζ</mi><mi>i</mi></msub></mrow></mfrac><mi mathvariant="normal">∣</mi></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} I_{q_i} = \mathbb{E}_{x \sim D_x} \ |\frac{\partial \mathcal{L}(x)}{\partial \zeta_i}| \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3074em;vertical-align:-0.9037em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4037em"><span style="top:-3.4037em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord">∣</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07378em">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0738em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathcal">L</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9037em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4037em"><span style="top:-3.4037em"><span class="pstrut" style="height:3.427em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9037em"><span></span></span></span></span></span></span></span></span></div><p>token-level importance score 와 유사하게, piece 가 모델 성능에 small 또는 negative 기여를 나타낸다.</p><p>저자는 서로 다른 compression ratio 로 sub-prompt tokens 와 pieces 를 얻기 위해 token-level 및 piece-level pruning 을 반복 수행한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="43-rewinding">4.3 Rewinding<a href="#43-rewinding" class="hash-link" aria-label="Direct link to 4.3 Rewinding" title="Direct link to 4.3 Rewinding">​</a></h2><p>LTH 에선 sparse subnetworks (unoruned prompts) 가 original network (all prompt) 와 동일한 정확도로 독립적으로 훈련될 수 있다 하며, pruning 후 unpruned weights 를 rewinding 하는 것을 제안</p><ul><li>LTH 에 따르면, 두 단계의 hierarchical structured pruning 후 soft prompt 를 재훈련하기 위해 weight rewinding 을 채택</li><li>구체적으로, optimal soft prompt 의 parameter 를 prompt tuning 후의 value 로 리셋<ul><li>다른 soft prompt 는 해당 mask values 를 0 으로 설정하여 pruning 된다.</li></ul></li><li>마지막으로 prompt tuning 에서 사용된 original learning 전략을 사용하여 soft prompt 를 다시 훈련</li></ul><h1>5. Experiments</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="51-datasets">5.1 Datasets<a href="#51-datasets" class="hash-link" aria-label="Direct link to 5.1 Datasets" title="Direct link to 5.1 Datasets">​</a></h2><p>저자는 NLP 에서 high-resource 및 low-resource 에서 SuperGLUE 의 다양한 데이터셋으로 평가</p><ul><li>제한된 SuperGLUE testset 으로 인해 (Lester et al. 2-21; Ding et al 2021) 에 따라, training set 에서 고정된 steps 으로 prompt tuning 후 best checkpoint 를 사용하여 validation set 을 report</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="52-baselines">5.2 Baselines<a href="#52-baselines" class="hash-link" aria-label="Direct link to 5.2 Baselines" title="Direct link to 5.2 Baselines">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="fine-tuning">Fine-Tuning<a href="#fine-tuning" class="hash-link" aria-label="Direct link to Fine-Tuning" title="Direct link to Fine-Tuning">​</a></h4><p>T5 의 standard fine-tuning (Raffel et al. 2020; Aribandi et al. 2021) 와 비교.</p><p>all pre-trained parameter 를 각각의 target task 에 개별적으로 fine-tuning</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-tuning">Prompt-Tuning<a href="#prompt-tuning" class="hash-link" aria-label="Direct link to Prompt-Tuning" title="Direct link to Prompt-Tuning">​</a></h4><p>(Lester et al. 2021) 의 vanilla prompt tuning 는 frozen PLMs 를 downstream task 에 adapting 하기 위한 competitive 기술</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="p-tuning">P-Tuning<a href="#p-tuning" class="hash-link" aria-label="Direct link to P-Tuning" title="Direct link to P-Tuning">​</a></h4><p>(Liu et al. 2021c) 의 P-tuning 은 target task 를 cloze problem 으로 변환하깅 위해 masked PLM 을 사용하는 prompt-based 방법이다.</p><p>이는 soft prompting 기술로 continuous space 에서 prompt 를 최적화. 또한 P-Tuning 의 두 번째 버전 P-TuningV2 와도 비교</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prefix-tuning">Prefix-Tuning<a href="#prefix-tuning" class="hash-link" aria-label="Direct link to Prefix-Tuning" title="Direct link to Prefix-Tuning">​</a></h4><p>(Li and Liang. 2021) 은 자연어 생성 작업에 대한 대안으로, small continuous task-specific vector (called prefix) 를 최적화</p><p>prefix 를 각 transformer layer 의 input 에 독립적으로 추가</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="53-implementation">5.3 Implementation<a href="#53-implementation" class="hash-link" aria-label="Direct link to 5.3 Implementation" title="Direct link to 5.3 Implementation">​</a></h2><ul><li>저자는 prompt learning을 위한 툴킷인 OnePrompt library 를 사용하여 구현</li><li>각 SuperGLUE dataset 을 text-to-text 형식으로 변환<ul><li>단, 어느 task 속했는지를 나타내는 task name 은 input</li></ul></li><li>XPrompt 는 pre-trained T5 checkpoint (Large, XL, XXL) 에서 구축<ul><li>Lester et al. 2021; Ding et al. 2021. 에 따라 훈련 설정 <ul><li>learning rate 0.3</li><li>batch size 16</li><li>epoch 100</li><li>token length 20</li><li>sampled vocabulary</li></ul></li><li>token pieces 16</li><li>pruning frequencies <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mn>10</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>20</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>30</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>40</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>50</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>60</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>70</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>80</mn><mi mathvariant="normal">%</mi><mo separator="true">,</mo><mn>90</mn><mi mathvariant="normal">%</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{10\%, 20\%, 30\%, 40\%, 50\%, 60\%, 70\%, 80\%, 90\%\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">10%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">20%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">30%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">40%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">50%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">60%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">70%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">80%</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">90%</span><span class="mclose">}</span></span></span></span></span> 에서 linearly search</li><li>weight rewinding 은 한 번만적용되어 pruned soft prompt 를 re-train</li><li>best checkpoint 는 dev set 에서 early stopping 으로 선택</li><li>Adafactor optimizer 를 사용하여 weight decay <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>e</mi><mo>−</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">1e-5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">5</span></span></span></span></span> 훈</li></ul></li></ul><h1>6. Results</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="61-results-on-high-resource-scenarios">6.1 Results on High-resource Scenarios<a href="#61-results-on-high-resource-scenarios" class="hash-link" aria-label="Direct link to 6.1 Results on High-resource Scenarios" title="Direct link to 6.1 Results on High-resource Scenarios">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="xprompt-는-all-model-scales-에서-prompt-tuning-성능을-향상시키고-fine-tuning-과의-gap-을-줄이는데-도움을-줌">Xprompt 는 all model scales 에서 prompt tuning 성능을 향상시키고 fine-tuning 과의 gap 을 줄이는데 도움을 줌<a href="#xprompt-는-all-model-scales-에서-prompt-tuning-성능을-향상시키고-fine-tuning-과의-gap-을-줄이는데-도움을-줌" class="hash-link" aria-label="Direct link to Xprompt 는 all model scales 에서 prompt tuning 성능을 향상시키고 fine-tuning 과의 gap 을 줄이는데 도움을 줌" title="Direct link to Xprompt 는 all model scales 에서 prompt tuning 성능을 향상시키고 fine-tuning 과의 gap 을 줄이는데 도움을 줌">​</a></h4><p><img loading="lazy" alt="Table 5" src="/assets/images/image-155-87b6405526c48cf9aaa506255e7d509e.png" width="1220" height="646" class="img_ev3q"></p><p>Table 1 및 Table 8 (appendix) 는 SuperGLUE 의 main results</p><ul><li>XPRompt 는 Prompt-Tuning, Prefix-Tuning, P-Tuning 및 P-TuningV2 와 비교<ul><li>vanilla Prompt-Tuning 을 all tasks 및 model scales 에서 능가</li><li>T5-Large, T5-XL 및 T5-XXL 의 average score 각각 3.26%, 2.96% 및 1.88% 의 개선을 보임</li><li>P-TuningV2 가 Prompt-Tuning 및 P-Tuning 을 능가하는데, XPrompt 는 P-TuningV2 보다 탁월한 성과를 거두어 효과적임을 입증</li><li>Prefix-Tuning 은 NLG task 를 위해 설계되어, 대부분의 NLU 에선 성능을 덜 발휘</li></ul></li><li>Table 1 에서 보이듯, XPrompt 는 T5-XL 의 all tasks 에서 fine-tuning 과 맞먹고, T5-XXL 에서의 대부분 task 에서 fine-tuning 을 능가<ul><li>T5-XXL 의 경우 WSC, CB, RTE, Boolq, MultiRC 에서 각각 97.11%, 100.00%, 94.94%, 90.87% 및 88.90% 의 best score 달성하여 fine-tuning 대비 +1.91%, +0.0%, +2.84%, +0.47%, +0.30% 개선</li><li>prompt tuning 과 fine-tuning 사이에 small 및 moderate scales 모델에서 일부 gap 이 있는 것을 볼 수 있다. (Fig. 1) 하지만 XPrompt 는 all model scales 에서 이 gap 을 줄이고, downstream task adapting 에 도움을 주는 효율적인 것을 볼 수 있다.</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="62-results-on-low-resource-scenarios">6.2 Results on Low-resource Scenarios<a href="#62-results-on-low-resource-scenarios" class="hash-link" aria-label="Direct link to 6.2 Results on Low-resource Scenarios" title="Direct link to 6.2 Results on Low-resource Scenarios">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="xprompt-는-low-resource-scenarios-에서-더-좋은-성능">XPrompt 는 low resource scenarios 에서 더 좋은 성능<a href="#xprompt-는-low-resource-scenarios-에서-더-좋은-성능" class="hash-link" aria-label="Direct link to XPrompt 는 low resource scenarios 에서 더 좋은 성능" title="Direct link to XPrompt 는 low resource scenarios 에서 더 좋은 성능">​</a></h4><p><img loading="lazy" alt="Table 2" src="/assets/images/image-156-0928e84e6f4fc42e804d33a2af2e520e.png" width="758" height="537" class="img_ev3q"></p><p>각 task 에 대해 고정된 random seed 를 사용하여 새로운 training set 으로 32 개의 example 을 무작위로 선택</p><p>저자는 32-shot 에서 prompt model 을 tuning 하고 best checkpoint 를 사용하여 report</p><ul><li>Table 2 에서 보이듯, XPrompt 는 prompt tuning 의 성능을 더욱 향상시키고 Boolq, WiC 및 RTE 에서 동일한 규모의 baseline 을 능가<ul><li>WiC 에서 62.85% 의 best score 달성하여 Prompt-Tuning 대비 +2.04% 개선</li><li>이 k-shot 결과는 제한된 데이터로 훈련할 때 overfitting 이 심하더라도, XPrompt 가 일관되게 prompt tuning 의 성능을 향상시킨다는 것을 시사</li></ul></li></ul><h1>7. Analysis and Discussion</h1><p>XPrompt 효과성을 이해하고 다양한 요소의 영향을 탐구하기 위해, ablation 연구 및 분석</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="71-do-positive-prompts-and-negative-prompts-exist">7.1 Do Positive Prompts and Negative Prompts Exist?<a href="#71-do-positive-prompts-and-negative-prompts-exist" class="hash-link" aria-label="Direct link to 7.1 Do Positive Prompts and Negative Prompts Exist?" title="Direct link to 7.1 Do Positive Prompts and Negative Prompts Exist?">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="hierarchical-structured-pruning-을-통한-positive-및-negative-prompts-을-식별">hierarchical structured pruning 을 통한 positive 및 negative prompts 을 식별<a href="#hierarchical-structured-pruning-을-통한-positive-및-negative-prompts-을-식별" class="hash-link" aria-label="Direct link to hierarchical structured pruning 을 통한 positive 및 negative prompts 을 식별" title="Direct link to hierarchical structured pruning 을 통한 positive 및 negative prompts 을 식별">​</a></h4><ul><li>positive prompt 에 대한 첫 번째 증거는 XPrompt 가 all task 및 model scales 에서 vanilla prompt tuning 에 비해 큰 성능 향상을 보여주어 효과를 입증</li><li>다른 증거는 pruning 의 high sparsities. appendix D 의 Fig. 9 와 Fig. 10 에서 WSC task 에 대한 importance score 의 original 과 pruned gradient saliency maps 를 보여준다.<ul><li>즉, Fig. 10 의 회색 요소는 low importance score 로 인해 prompt tokens 나 pieces 가 pruning 되었다는 것을 나타내며, 남은 부분이 winning ticket 이라 할 수 있다.</li></ul></li><li>15% positive sub-prompt 를 사용한 XPrompt 의 성능은 full prompt tuning 보다 4.8% 높다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="negative-prompts-는-prompt-tuning-및-xprompt-보다-낮은-성능">negative prompts 는 Prompt Tuning 및 XPrompt 보다 낮은 성능<a href="#negative-prompts-는-prompt-tuning-및-xprompt-보다-낮은-성능" class="hash-link" aria-label="Direct link to negative prompts 는 Prompt Tuning 및 XPrompt 보다 낮은 성능" title="Direct link to negative prompts 는 Prompt Tuning 및 XPrompt 보다 낮은 성능">​</a></h4><p>negative prompt 의 존재와 효과를 더 조사하기 위해 다른 구성으로 prompt tuning 성능과 비교</p><ul><li>vanilla Prompt-Tuning (all prompts) 와 XPrompt 외에도 세 가지 변형 소개<ul><li>Reversed XPrompt : XPrompt 의 masked sub-prompt structures 를 반전시켜 low score prompt tokens 및 pieces 를 사용</li><li>Random Prompt : rewind stage 에서 tokens 및 pieces 를 무작위로 masking</li><li>Length Prompt : XPrompt results 와 동일한 promptl ength 로 re-train</li></ul></li></ul><p><img loading="lazy" alt="Figure 5" src="/assets/images/image-157-17a134dfb039e7ff132491635750dca8.png" width="761" height="779" class="img_ev3q"></p><ul><li>XPrompt 가 best performance 달성을 보여준다.</li><li>Reversed XPrompt 가 Random Prompt 및 Length Prompt 를 포함한 all prompt tuning 변형보다 현저히 나쁜 성능을 보여줌<ul><li>이는 저자의 기대와 일치하며 negative prompt 의 존재를 더욱 확증</li></ul></li><li>Length Prompt 는 평균적으로 Random Prompt 및 Prompt Tuning 보다 성능이 떨어짐<ul><li>이는 저자의 hierarchical structured pruning 효과를 나타냄</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="72-parameter-efficiency">7.2 Parameter Efficiency<a href="#72-parameter-efficiency" class="hash-link" aria-label="Direct link to 7.2 Parameter Efficiency" title="Direct link to 7.2 Parameter Efficiency">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="xprompt-는-prompt-tuning-보다-parameter-efficient">XPrompt 는 Prompt-Tuning 보다 parameter-efficient<a href="#xprompt-는-prompt-tuning-보다-parameter-efficient" class="hash-link" aria-label="Direct link to XPrompt 는 Prompt-Tuning 보다 parameter-efficient" title="Direct link to XPrompt 는 Prompt-Tuning 보다 parameter-efficient">​</a></h4><p><img loading="lazy" alt="Table 3" src="/assets/images/image-158-444bd93e30f1ac530715d767352916be.png" width="780" height="351" class="img_ev3q"></p><p>Table 3 에서 tunable parameter 수를 비교한다.</p><ul><li>Prompt-Tuning 은 이미 parameter-efficient 이며, full model fine-tuning 에 비해 0.0014% 의 parameter 만을 tuning</li><li>XPrompt 는 hierarchical structured pruning 을 통해 Prompt-Tuning 의 tunable parameter 수를 더욱 감소 시킨다.<ul><li>예로, XPrompt 는 Prompt-Tuning 에 비해 parameter 의 15% 및 37.18% 만 tuning</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="73-granularity-of-pruning">7.3 Granularity of Pruning<a href="#73-granularity-of-pruning" class="hash-link" aria-label="Direct link to 7.3 Granularity of Pruning" title="Direct link to 7.3 Granularity of Pruning">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="token-level-pruning-및-fine-grained-piece-level-pruning-모두-중요">Token-level pruning 및 fine-grained piece-level pruning 모두 중요<a href="#token-level-pruning-및-fine-grained-piece-level-pruning-모두-중요" class="hash-link" aria-label="Direct link to Token-level pruning 및 fine-grained piece-level pruning 모두 중요" title="Direct link to Token-level pruning 및 fine-grained piece-level pruning 모두 중요">​</a></h4><p>two-level pruning 의 효과 조사를 위해 Table 4 에 네 가지 SuperGLUE task 에서 포괄적인 pruning 실험 수행</p><p><img loading="lazy" alt="Table 4" src="/assets/images/image-159-29f5a8108946e013929f593c6e75e5be.png" width="742" height="436" class="img_ev3q"></p><ul><li>two level 의 pruning 은 vanilla Prompt-Tuning 보다 뛰어나며, toke-level 및 piece-level pruning 의 효과 입증</li><li>결과 최적화할 수 있는 trained prompts 의 sub-prompt structures 의 존재를 보여줌</li><li>XPrompt 는 개별적인 pruning 보다 우수한 성능을 보이며, 이는 two-level 의 structured pruning 을 결합하는 것이 더 많은 이점을 준다는 것을 시사</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="74-prompt-length">7.4 Prompt Length<a href="#74-prompt-length" class="hash-link" aria-label="Direct link to 7.4 Prompt Length" title="Direct link to 7.4 Prompt Length">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-length-20-초과-늘리면-xprompt--제한적인-이득만-얻는다">Prompt Length (20 초과) 늘리면 XPrompt  제한적인 이득만 얻는다.<a href="#prompt-length-20-초과-늘리면-xprompt--제한적인-이득만-얻는다" class="hash-link" aria-label="Direct link to Prompt Length (20 초과) 늘리면 XPrompt  제한적인 이득만 얻는다." title="Direct link to Prompt Length (20 초과) 늘리면 XPrompt  제한적인 이득만 얻는다.">​</a></h4><p>Prompt Length 가 XPrompt 에 미치는 영향을 조사하기 위해 T5-XL 모델에 다양한 Prompt Length <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mn>10</mn><mo separator="true">,</mo><mn>20</mn><mo separator="true">,</mo><mn>100</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{10, 20, 100\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">10</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">20</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">100</span><span class="mclose">}</span></span></span></span></span> 으로 XPrompt 훈련</p><p>결과는 Table 5 에서 report </p><p><img loading="lazy" alt="Table 5" src="/assets/images/image-160-ec28e5b82cf4ce4271db12ac3427372c.png" width="754" height="373" class="img_ev3q"></p><ul><li>결과에서 볼 수 있듯, Prompt Length 가 XPrompt 및 Prompt-Tuning 에 중요한 역할을 한다.</li><li>20 tokens 이상으로 늘리면 개선이 제한되는 것을 볼 수 있다.</li><li>이는 Lester et al. 2021 의 발견과 일치하며, 이는 모든 실험에서 20 tokens 으로 설정하는 이유</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="75-prompt-initialization-and-transfer">7.5 Prompt Initialization and Transfer<a href="#75-prompt-initialization-and-transfer" class="hash-link" aria-label="Direct link to 7.5 Prompt Initialization and Transfer" title="Direct link to 7.5 Prompt Initialization and Transfer">​</a></h2><p>soft prompt transfer 접근법인 SPoT 에 영감을 받아 task transfer 및 다양한 prompt initialization 효과를 탐구하여, XPrompt Transer 을 도입</p><ul><li>먼저 source task 에서 XPrompt 를 통해 prompt 훈련</li><li>learned prompts 를 target task 의 prompt 로 초기화</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-initialization-은-xprompt-에서-중요한-역할을-하며-xprompt-transfer-은-성능-향상을-이끌어-냄">Prompt initialization 은 XPrompt 에서 중요한 역할을 하며, XPrompt Transfer 은 성능 향상을 이끌어 냄<a href="#prompt-initialization-은-xprompt-에서-중요한-역할을-하며-xprompt-transfer-은-성능-향상을-이끌어-냄" class="hash-link" aria-label="Direct link to Prompt initialization 은 XPrompt 에서 중요한 역할을 하며, XPrompt Transfer 은 성능 향상을 이끌어 냄" title="Direct link to Prompt initialization 은 XPrompt 에서 중요한 역할을 하며, XPrompt Transfer 은 성능 향상을 이끌어 냄">​</a></h4><p>XPrompt 의 two sample initialization 을 비교하며, 이는 random uniform 및 sampled vocabulary 를 포함하여 Table 6 에 결과가 있다.</p><p><img loading="lazy" alt="Table 6" src="/assets/images/image-161-6445feb13b24a16350fd118e0a7aa1b9.png" width="760" height="354" class="img_ev3q"></p><ul><li>sampled vocabulary 성능이 가장 좋은 것을 관찰</li><li>XPrompt 는 random uniform initialization 에 대한 성능 향상을 이끌어냄</li></ul><p>Task Transfer 과 XPrompt Transfer 을 비교하여, Task Transfer 은 source task prompt 만으로 target prompt 로 초기화하며 Table 7 에 결과가 있다.</p><p><img loading="lazy" alt="Table 7" src="/assets/images/image-162-6df256c6eb348ef9f45aa7ffcf6674f8.png" width="750" height="419" class="img_ev3q"></p><ul><li>XPrompt Transfer 이 rewinding stage 없이 Task Transfer 보다 우수한 성능 보임</li><li>pruning 과 rewinding 을 통해 큰 성능 향상 이끌어냄</li></ul><h1>8. Conclusions</h1><p>본 논문은 small, moderate scales model 에 대한 prompt tuning 과 fine-tuning 간의 큰 성능 차이를 줄이는 것을 목표</p><ul><li>LTH 가설을 탐구하여, novel hierarchical structured pruning 방법인 XPrompt 제안</li><li>이 방법은 token-level 및 piece-level 에서의 positive prompt 와 negative prompt 분리</li><li>SuperGLUE 실험에서 small parameter-efficient 를 제공하며 성능 유지</li></ul><h1>Limitations</h1><p>다양한 단계에서 negative prompt token 제거를 위해선 hierarchical structured pruning을 통해 pruned model 을 다양한 압축 비율로 rewinding 해야 한다.</p><p>다음 질문들에 대해선 아직 해결할 것들이 남아 있다.</p><ul><li>training 없이 optimal compression ratio 찾는 법<ul><li>training process 를 자동화하고 효율성 향상시킬 수 있는 주요한 문제</li></ul></li><li>다양한 시나리오를 추가하여 조사 필요<ul><li>multitask learning 시나리오, out-of-domain (domain shift) 시나리오, 그리고 prompt ensembling 시나리오</li></ul></li></ul><h1>Appendix</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="a-more-results-of-p-tuningv2">A. More Results of P-TuningV2<a href="#a-more-results-of-p-tuningv2" class="hash-link" aria-label="Direct link to A. More Results of P-TuningV2" title="Direct link to A. More Results of P-TuningV2">​</a></h2><p><img loading="lazy" alt="Table 8" src="/assets/images/image-163-612603793e61c9fee9ad50cc5e54ee20.png" width="773" height="585" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="b-token-and-piece-importance-score">B. Token and Piece Importance Score<a href="#b-token-and-piece-importance-score" class="hash-link" aria-label="Direct link to B. Token and Piece Importance Score" title="Direct link to B. Token and Piece Importance Score">​</a></h2><p><img loading="lazy" alt="Figure 6" src="/assets/images/image-164-49e5f216dab4720652bc32bc9a43273c.png" width="753" height="534" class="img_ev3q"></p><p><img loading="lazy" alt="Figure 7" src="/assets/images/image-165-ad945209c6bcc0d3c46ce0840861d339.png" width="758" height="590" class="img_ev3q"></p><p>위는 WSC task 에서의 prompt tokens 및 prompt token pieces 분포의 importance scores 를 보여준다.</p><p>대부분의 prompt token 이 importance score 를 가지고 있으며, 일부 prompt token 만이 높은 importance score 를 가지고 있는 것이 명확하다.</p><p>위 결과는 negative prompt 의 존재와 이들의 안정성에 대한 우리의 가설을 더욱 입증</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="c-xprompt-transfer">C. XPrompt Transfer<a href="#c-xprompt-transfer" class="hash-link" aria-label="Direct link to C. XPrompt Transfer" title="Direct link to C. XPrompt Transfer">​</a></h2><p><img loading="lazy" alt="Figure 8" src="/assets/images/image-166-666ed025dd877a7bf9a24fb631debb34.png" width="588" height="831" class="img_ev3q"></p><p>Fig. 8 처럼, source task 와 target task 가 주어지면 XPrompt Transfer 은 먼저 source task 에서 XPrompt 를 사용하여 prompt 훈련 후 얻은 prompt 를 target task 의 prompt 로 초기화하기 위해 사용하며, 이후 target task 에서 XPrompt 를 훈련</p><p>SPoT 와 달리, learned prompt 를 target task 의 prompt 초기화하는 데 사용하지 않고, 저자의 방법은 prompt 에 more cross tasks information 을 제공할 수 있다.</p><p>다양한 prompt initialization 결과는 Table 6 에 있으며, XPrompt Transfer 결과는 Table 7 에 있다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="d-importance-scores-visualization">D. Importance Scores Visualization<a href="#d-importance-scores-visualization" class="hash-link" aria-label="Direct link to D. Importance Scores Visualization" title="Direct link to D. Importance Scores Visualization">​</a></h2><p>Fig. 9 및 Fig. 10 에서 WSC task 에서의 importance scores original 및 pruned gradient saliency maps 을 보여준다.</p><p>Fig. 10 에서 회색 셀은 importance score 가 낮아 prompt token 및 piece 를 잘라내고 나머지는 winning ticket 을 의미한다.</p><p><img loading="lazy" alt="Figure 9" src="/assets/images/image-167-d6c25edee24f72eea4ef1b7f04d0be04.png" width="535" height="711" class="img_ev3q"></p><p><img loading="lazy" alt="Figure 10" src="/assets/images/image-168-cc072f12a604505035867d02b0ad34ef.png" width="550" height="669" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="e-superglue-statistics-metrics-and-soft-prompt-templates">E. SuperGLUE Statistics, Metrics and Soft Prompt Templates<a href="#e-superglue-statistics-metrics-and-soft-prompt-templates" class="hash-link" aria-label="Direct link to E. SuperGLUE Statistics, Metrics and Soft Prompt Templates" title="Direct link to E. SuperGLUE Statistics, Metrics and Soft Prompt Templates">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="superglue-benchmark">SuperGLUE benchmark<a href="#superglue-benchmark" class="hash-link" aria-label="Direct link to SuperGLUE benchmark" title="Direct link to SuperGLUE benchmark">​</a></h4><p>이전 연구에 따라 ReCoRD task 를 제외하고 7개 task 에 중점을 둔다.</p><p>ReCoRD 는 question answering 이기 때문이다.</p><p><img loading="lazy" alt="Table 9" src="/assets/images/image-169-39d7bfda2266c5a2524bc0c456090e22.png" width="1137" height="459" class="img_ev3q"></p><p><img loading="lazy" alt="Table 10" src="/assets/images/image-170-afbe8c30d7aefddadf52d3699579018f.png" width="1104" height="394" class="img_ev3q"></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/peft">PEFT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/prompt-tuning">prompt tuning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/lth">LTH</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/lottery-ticket-hypothesis">lottery ticket hypothesis</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/NLP/PEFT/Soft Prompt/2022-12-XPrompt.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/NLP/PEFT/Soft Prompt/SPoT"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#21-pre-trained-language-models" class="table-of-contents__link toc-highlight">2.1 Pre-trained Language Models</a></li><li><a href="#22-prompt-learning-in-nlp" class="table-of-contents__link toc-highlight">2.2 Prompt Learning in NLP</a></li><li><a href="#23-lottery-ticket-hypothesis" class="table-of-contents__link toc-highlight">2.3 Lottery Ticket Hypothesis</a></li><li><a href="#41-prompt-tuning" class="table-of-contents__link toc-highlight">4.1 Prompt Tuning</a></li><li><a href="#42-hierarchical-structured-pruning" class="table-of-contents__link toc-highlight">4.2 Hierarchical Structured Pruning</a><ul><li><a href="#421-token-level-pruning" class="table-of-contents__link toc-highlight">4.2.1 Token-level Pruning</a></li><li><a href="#422-piece-level-pruning" class="table-of-contents__link toc-highlight">4.2.2 Piece-level Pruning</a></li></ul></li><li><a href="#43-rewinding" class="table-of-contents__link toc-highlight">4.3 Rewinding</a></li><li><a href="#51-datasets" class="table-of-contents__link toc-highlight">5.1 Datasets</a></li><li><a href="#52-baselines" class="table-of-contents__link toc-highlight">5.2 Baselines</a></li><li><a href="#53-implementation" class="table-of-contents__link toc-highlight">5.3 Implementation</a></li><li><a href="#61-results-on-high-resource-scenarios" class="table-of-contents__link toc-highlight">6.1 Results on High-resource Scenarios</a></li><li><a href="#62-results-on-low-resource-scenarios" class="table-of-contents__link toc-highlight">6.2 Results on Low-resource Scenarios</a></li><li><a href="#71-do-positive-prompts-and-negative-prompts-exist" class="table-of-contents__link toc-highlight">7.1 Do Positive Prompts and Negative Prompts Exist?</a></li><li><a href="#72-parameter-efficiency" class="table-of-contents__link toc-highlight">7.2 Parameter Efficiency</a></li><li><a href="#73-granularity-of-pruning" class="table-of-contents__link toc-highlight">7.3 Granularity of Pruning</a></li><li><a href="#74-prompt-length" class="table-of-contents__link toc-highlight">7.4 Prompt Length</a></li><li><a href="#75-prompt-initialization-and-transfer" class="table-of-contents__link toc-highlight">7.5 Prompt Initialization and Transfer</a></li><li><a href="#a-more-results-of-p-tuningv2" class="table-of-contents__link toc-highlight">A. More Results of P-TuningV2</a></li><li><a href="#b-token-and-piece-importance-score" class="table-of-contents__link toc-highlight">B. Token and Piece Importance Score</a></li><li><a href="#c-xprompt-transfer" class="table-of-contents__link toc-highlight">C. XPrompt Transfer</a></li><li><a href="#d-importance-scores-visualization" class="table-of-contents__link toc-highlight">D. Importance Scores Visualization</a></li><li><a href="#e-superglue-statistics-metrics-and-soft-prompt-templates" class="table-of-contents__link toc-highlight">E. SuperGLUE Statistics, Metrics and Soft Prompt Templates</a></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.c2f88002.js"></script>
<script src="/assets/js/main.36090bf9.js"></script>
</body>
</html>