<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/NLP/PEFT/Soft Prompt/2021-03-P-tuning">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">GPT Understands, Too | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="GPT Understands, Too | My Site"><meta data-rh="true" name="description" content="논문 및 이미지 출처 :"><meta data-rh="true" property="og:description" content="논문 및 이미지 출처 :"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="My Site RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="My Site Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.d2ad26d0.css">
<link rel="preload" href="/assets/js/runtime~main.130f03bb.js" as="script">
<link rel="preload" href="/assets/js/main.78c0c0af.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">Analysis</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Augmentation/PromptDA">Augmentation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Model/Transformer">Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Multi-Task/Chain-of-Thought">Multi-Task</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">PEFT</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">Composition</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Mixture/UniPELT">Mixture</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/Adapter">Module</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Pruning/SMP">Pruning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/BitNet">Quantization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning">Soft Prompt</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning">GPT Understands, Too</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning">The Power of Scale for Parameter-Efficient Prompt Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2">P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT">ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/SPoT">SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt">XPrompt: Exploring the Extreme of Prompt Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter">LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning">Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2">LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning">Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/DEPT">DEPT: Decomposed Prompt Tuning For Parameter-Efficient Fine Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/APrompt">APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/SMoP">SMoP: Towards Efficient and Effective Prompt Tuning with Sparse Mixture-of-Prompts</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Tuning/PTR">Prompt Tuning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Reinforcement Learning/Reflexion">Reinforcement Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Text Generation/InstructGPT">Text Generation</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/UPL">Vision-Language</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">NLP</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">PEFT</span><meta itemprop="position" content="3"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Soft Prompt</span><meta itemprop="position" content="4"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">GPT Understands, Too</span><meta itemprop="position" content="5"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>GPT Understands, Too</h1></header><p>논문 및 이미지 출처 : <a href="https://arxiv.org/pdf/2103.10385.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2103.10385.pdf</a></p><h1>Abstract</h1><p>전통적인 fine-tuning 으로는 GPT model 의 natural language understanding (NLU) task 에 좋은 결과를 달성하지 못하는 반면,</p><p>저자는 trainable continuous prompt embeddings 를 사용한 <strong><em>P-tuning</em></strong> 을 통해 나은 결과를 얻을 수 있었다.</p><ul><li>knowledge probing (LAMA) 벤치마크에서 최고인 GPT 는 테스트할 때 additional text 없이 64% (P@1) 복구 (이전 best 의 +20%)</li><li>SuperGlue 벤치마크에서 GPT 모델은 supervised learning 에서, 유사한 크기인 BERT 와 비슷하거나 더 나은 성능 달성</li><li>P-tuning 이 prompt engineering 의 필요성을 줄여, BERT 모델의 성능도 향상시킨다는 것</li></ul><p>결과적으로 P-tuning 이 few-shot SuperGlue 벤치마크에서 SOTA 능가</p><h1>1. Introduction</h1><p>이전 연구들은 pre-training 과정에 text 표현 뿐 아니라 문법, 구문, 상식 및 세계 지식 등의 요소를 학습한다는 증거를 제시하기도 한다.</p><p>training objectives 에 따라 pre-trained language model (LM) 은 세 가지 범주로 나눌 수 있다.</p><ul><li><strong>unidirectional language models</strong> for natural language generation (NLG) (e.g. GPT)</li><li><strong>bidirectional language models</strong> for natural language understanding (NLU) (e.g. BERT)</li><li><strong>hybrid language models</strong> for combining the first two paradigms (e.g. XLNet, UniLM)</li></ul><p>GPT 스타일의 모델이 fine-tuning 으로 NLU task 에 대한 성능이 좋지않아, language undetstanding 에 적합하지 않다고 가정해왔다.</p><p>하지만 manual prompt 사용으로 흥미로운 성능을 보여, large unidirectional model 와 manual prompt 가 NLU 에 적합하게 작용할 수 있음을 시사</p><p>그러나 best-performing prompt 란 사막에서 바늘찾기 이며, 현실적으로 불가능한 매우 큰 검증 데이터셋이 필요하다.</p><p>많은 케이스에서도, prompt engineering 은 테스트셋에 overfitting 하며, 큰 성능 하락을 일으키는 prompt 를 만들 가능성도 있다.</p><p>이러한 연구들을 통해 저자는 discrete prompts 를 자동으로 검색하고, 효과를 입증하는데 초점을 둔다. 하지만 neural networks 는 continuous 하므로 discrete prompts 는 sub-optimal 일 수 있다.</p><hr><p>본 연구는 <strong><em>P-tuning</em></strong> 으로 GPT 와 NLU 간의 간격을 좁히기 위해 continuous space 에서 prompt 를 자동으로 검색하는 방법을 연구</p><ul><li>few continuous free parameters 를 활용하여 pre-trained LM 에 입력으로 제공되는 prompt 역할</li><li>continuous prompt 를 discrete prompt searching 대신 gradient descent 를 활용하여 최적화</li></ul><p>간단한 P-tuning 으로 GPT 에 상당한 개선을 가져왔다.</p><p>저자는 P-tuning 기반 GPT 을 두 가지 NLU 벤치마크에 검토</p><ul><li>LAMA knowledge probing<ul><li>64.2% 달성하여 이전 SOPTA prompt searching 방법인 45.2% 를 크게 능가</li></ul></li><li>SuperGLUE<ul><li>few-shot 및 fine-tuning 을 함께 진행</li><li>동일한 규모의 BERT 와 유사한 성능이거나 일부 데이터셋에선 능가</li><li>BERT 스타일 모델에도 P-tuning 이 이점을 얻을 수 있음을 관찰</li><li>ALBERT 의 P-tuning 은 성능 크게 능가하고 few-shot SuperGLUE 에서 SOTA</li></ul></li></ul><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-46-58069fd0456d6d2b8710363c3e9e0645.png" width="836" height="395" class="img_ev3q"></p><p>위 방법은 GPT 는 언어를 이해하지 못한다는 고정관념을 부쉈다.</p><p>P-tuning 은 pre-trained LM 을 downstream task 에 최상의 성능을 위해 fine-tuning 에도 작동한다.</p><p>본 논문의 기여는 다음과 같다.</p><ul><li>P-tuning 으로 GPT 의 NLU 가 BERT 와 comparable (때론 더 나음)하여, pre-trained LM 의 성능을 향상 시킴</li><li>P-tuning 은 few-shot 및 fine-tuning 설정에서도 GPT 및 BERT 를 모두 개선<ul><li>LAMA knowledge probing 및 few-shot SuperGLUE 에서 SOTA 능가</li><li>LM 이 pre-training 중 생각보다 더 많은 지식을 습득했음을 시사</li></ul></li></ul><h1>2. Motivation</h1><p>GPT-3 및 DALL-E 는 LLM 이 만병통치약임을 시사하지만, transferability 가 낮다는 것.</p><p>downstream task 의 fine-tuning 은 trillion-scale model 에는 거의 작동하지 않는다.</p><p>many-shot fine-tuning 에서도 빠르게 fine-tuning sample 을 메모리에 저장하기엔 너무 크다.</p><p>대안으로 GPT-3 와 DALL-E 는 downstream 을 위해 model fine-tuning 을 위해 manual prompt 를 활용하는 것이 보고 되었다.</p><p>그러나 manual prompt searching 은 큰 검증셋에 지나치게 의존하며 성능도 불안정하다.</p><p><img loading="lazy" alt="Table 1" src="/assets/images/image-47-1061ed99b30e65f7d442423d11a8df70.png" width="835" height="343" class="img_ev3q"></p><p>최근 discrete prompts searching 을 자동으로 하는 것에 집중하며, </p><ul><li>training corpus 를 mining</li><li>gradient searching</li><li>separate model </li></ul><p>저자의 목적은 미분하여 최적화될 수 있는 continuous prompt 를 찾는 것</p><h1>3. Method: P-tuning</h1><p>discrete prompt 와 유사하게 P-tuning 은 input 에 비침범적인 (noninvasive) 수정만 적용</p><p>pre-trained input embeddings 을 differential (미분계수) output embeddings 로 대체</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="31-architecture">3.1 Architecture<a href="#31-architecture" class="hash-link" aria-label="Direct link to 3.1 Architecture" title="Direct link to 3.1 Architecture">​</a></h2><p>pre-trained LM <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">M</mi></mrow><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal">M</span></span></span></span></span> 이 주어졌을 경우</p><ul><li>discrete input token 의 sequence <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>x</mtext><mrow><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\text{x}_{1:n} = \{ x_0, x_1, \dots, x_n \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord text"><span class="mord">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span><ul><li>pre-trained embedding layer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mo>∈</mo><mi mathvariant="script">M</mi></mrow><annotation encoding="application/x-tex">e \in \mathcal{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal">M</span></span></span></span></span> 에 의해 input embeddings <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>e</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>e</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>e</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{ e(x_0), e(x_1), \dots, e(x_n) \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)}</span></span></span></span></span> 으로 매핑</li></ul></li><li>특정 시나리오에선 context <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>x</mtext></mrow><annotation encoding="application/x-tex">\text{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord text"><span class="mord">x</span></span></span></span></span></span> 에 대해, downstream 처리를 위해 target token <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>y</mtext></mrow><annotation encoding="application/x-tex">\text{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord text"><span class="mord">y</span></span></span></span></span></span> 의 output embeddings 사용이 일반적<ul><li>pre-training 에선, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>x</mtext></mrow><annotation encoding="application/x-tex">\text{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord text"><span class="mord">x</span></span></span></span></span></span> 는 unmasked tokens 을 나타내며, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>y</mtext></mrow><annotation encoding="application/x-tex">\text{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord text"><span class="mord">y</span></span></span></span></span></span> 는 <!-- -->[MASK]<!-- --> 를 나타냄</li><li>sentence classification 에선, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>x</mtext></mrow><annotation encoding="application/x-tex">\text{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord text"><span class="mord">x</span></span></span></span></span></span> 는 sentence token 을 나타내며, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>y</mtext></mrow><annotation encoding="application/x-tex">\text{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord text"><span class="mord">y</span></span></span></span></span></span> 는 <!-- -->[CLS]<!-- --> 를 나타냄</li></ul></li></ul><p>prompt <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">p</mi></mrow><annotation encoding="application/x-tex">\bold{p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em"></span><span class="mord mathbf">p</span></span></span></span></span> 의 역할은 context <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>x</mtext></mrow><annotation encoding="application/x-tex">\text{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord text"><span class="mord">x</span></span></span></span></span></span>, target <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>y</mtext></mrow><annotation encoding="application/x-tex">\text{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord text"><span class="mord">y</span></span></span></span></span></span> 및 template <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span></span> 로 구성하는 것</p><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-48-dae496073823ace9f9f9cf4a85cf8a4d.png" width="824" height="293" class="img_ev3q"></p><p>예로, 국가 수도를 예측하는 작업 (LAMA-TREx P36)</p><ul><li>template &quot;The capital of Britain is <!-- -->[MASK]<!-- -->.&quot;</li><li>prompt &quot;The capital of ... is ... .&quot;</li><li>context &quot;Britain&quot;</li><li>target &quot;<!-- -->[MASK]<!-- -->&quot;</li></ul><p>prompt 는 context 또는 target 로 삽입할 수 있는 유연성을 지닐 수 있다.</p><p>LM <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">M</mi></mrow><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal">M</span></span></span></span></span> 의 vocabulary 를 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">V</mi></mrow><annotation encoding="application/x-tex">\mathcal{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal" style="margin-right:0.08222em">V</span></span></span></span></span>, template <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span></span> 의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding="application/x-tex">i^{th}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">h</span></span></span></span></span></span></span></span></span></span></span></span></span> prompt token 을 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mtext>P</mtext><mi>i</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[\text{P}_i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord text"><span class="mord">P</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> 라 하자.</p><p>간단하게, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">[</mo><msub><mtext>P</mtext><mrow><mn>0</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false">]</mo><mo separator="true">,</mo><mtext>x</mtext><mo separator="true">,</mo><mo stretchy="false">[</mo><msub><mtext>P</mtext><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>m</mi></mrow></msub><mo stretchy="false">]</mo><mo separator="true">,</mo><mtext>y</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">T = \{ [\text{P}_{0:i}], \text{x}, [\text{P}_{i+1:m}],\text{y} \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{[</span><span class="mord"><span class="mord text"><span class="mord">P</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord text"><span class="mord">x</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mopen">[</span><span class="mord"><span class="mord text"><span class="mord">P</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord text"><span class="mord">y</span></span><span class="mclose">}</span></span></span></span></span> 가 주어졌다고 하자. </p><p>traditional discrete prompts 와 비교하며, 이는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mtext>P</mtext><mi>i</mi></msub><mo stretchy="false">]</mo><mo>∈</mo><mi mathvariant="script">V</mi></mrow><annotation encoding="application/x-tex">[\text{P}_i] \in \mathcal{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord text"><span class="mord">P</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal" style="margin-right:0.08222em">V</span></span></span></span></span> 를 만족시키고 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span></span> 를 다음과 같이 매핑</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">{</mo><mi>e</mi><mo stretchy="false">(</mo><mo stretchy="false">[</mo><msub><mtext>P</mtext><mrow><mn>0</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>e</mi><mo stretchy="false">(</mo><mtext>x</mtext><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>e</mi><mo stretchy="false">(</mo><mo stretchy="false">[</mo><msub><mtext>P</mtext><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>m</mi></mrow></msub><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>e</mi><mo stretchy="false">(</mo><mtext>y</mtext><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \{ e([\text{P}_{0:i}]), e(\text{x}), e([\text{P}_{i+1:m}]), e(\text{y}) \} \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">{</span><span class="mord mathnormal">e</span><span class="mopen">([</span><span class="mord"><span class="mord text"><span class="mord">P</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">])</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord text"><span class="mord">x</span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">e</span><span class="mopen">([</span><span class="mord"><span class="mord text"><span class="mord">P</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mclose">])</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord text"><span class="mord">y</span></span><span class="mclose">)}</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-2.85em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></div><p>반면, P-tuning 은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mtext>P</mtext><mi>i</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[\text{P}_i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord text"><span class="mord">P</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> 를 pseudo tokens 로 간주하고 template 를 다음과 같이 매핑</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">{</mo><msub><mi>h</mi><mn>0</mn></msub><mo separator="true">,</mo><mo>…</mo><msub><mi>h</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>e</mi><mo stretchy="false">(</mo><mtext>x</mtext><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>h</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mo>…</mo><msub><mi>h</mi><mi>m</mi></msub><mo separator="true">,</mo><mi>e</mi><mo stretchy="false">(</mo><mtext>y</mtext><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \{ h_0, \dots h_i, e(\text{x}), h_{i+1}, \dots h_m, e(\text{y}) \} \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord text"><span class="mord">x</span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord text"><span class="mord">y</span></span><span class="mclose">)}</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-2.85em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></div><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mn>0</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_i (0 \leq i \leq m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7955em;vertical-align:-0.136em"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">m</span><span class="mclose">)</span></span></span></span></span> : trainable embedding tensors<ul><li>이를 통해 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">M</mi></mrow><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal">M</span></span></span></span></span> 의 original vocabulary <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">V</mi></mrow><annotation encoding="application/x-tex">\mathcal{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal" style="margin-right:0.08222em">V</span></span></span></span></span> 를 넘어 더 나은 continuous prompts 를 찾을 수 있게 됨</li></ul></li></ul><p>downstream loss function <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi></mrow><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal">L</span></span></span></span></span> 를 사용하여 continuous prompt <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mn>0</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_i (0 \leq i \leq m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7955em;vertical-align:-0.136em"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">m</span><span class="mclose">)</span></span></span></span></span> 를 미분으로 최적화할 수 있다.</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mover accent="true"><mi>h</mi><mo>^</mo></mover><mrow><mn>0</mn><mo>:</mo><mi>m</mi></mrow></msub><mo>=</mo><mi><munder><mo><mtext>arg</mtext><mi>min</mi><mo>⁡</mo></mo><mi>h</mi></munder></mi><mtext> </mtext><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi mathvariant="script">M</mi><mo stretchy="false">(</mo><mtext>x</mtext><mo separator="true">,</mo><mtext>y</mtext><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \hat{h}_{0:m} = \underset{h}{\text{arg} \min}\ \mathcal{L} (\mathcal{M}(\text{x}, \text{y})) \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.9044em;vertical-align:-0.7022em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2022em"><span style="top:-3.2443em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">h</span></span><span style="top:-3.2634em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em"><span style="top:-2.1535em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop"><span class="mord text"><span class="mord">arg</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">min</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9465em"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord mathcal">L</span><span class="mopen">(</span><span class="mord mathcal">M</span><span class="mopen">(</span><span class="mord text"><span class="mord">x</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord text"><span class="mord">y</span></span><span class="mclose">))</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7022em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2022em"><span style="top:-3.2022em"><span class="pstrut" style="height:2.9579em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7022em"><span></span></span></span></span></span></span></span></span></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="32-optimization">3.2 Optimization<a href="#32-optimization" class="hash-link" aria-label="Direct link to 3.2 Optimization" title="Direct link to 3.2 Optimization">​</a></h2><p>continuous prompts 의 training idea 는 간단하지만 실제로 두 가지 최적화 문제를 직면</p><ol><li>Discreteness<ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">M</mi></mrow><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal">M</span></span></span></span></span> 의 original word embedding <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">e</span></span></span></span></span> 은 pre-training 후 높은 discrete 성질을 가짐</li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span> 가 random distribution 된 후 stochastic gradient descent (SGD) 로 최적화될 경우, small neighborhood 의 parameter 만 변경될 수 있음</li><li>위 optimizer 는 쉽게 local minima 에 빠질 수 있음</li></ul></li><li>Association<ul><li>prompt embeddings <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 의 값이 독립적이 아닌 서로 종속되어야 한다는 것. prompt embeddings 를 서로 연관시키기 위한 매커니즘 필요</li></ul></li></ol><p>위 어려움을 대응하여 P-tuning 에선 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 를 <strong><em>서로 종속적인 시퀀스로 모델링</em></strong> 하는 것을 제안</p><ul><li>이를 위해 매우 가벼운 신경망으로 구성된 prompt encoder 를 사용하여 discreteness 및 association 해결</li><li>양방향 LSTM 을 선택하고 ReLU activated two-layer MLP 를 사용하여 discreteness 촉진</li></ul><p>LM <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">M</mi></mrow><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal">M</span></span></span></span></span> 에 대한 실제 input embeddings <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">h_i&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0106em;vertical-align:-0.2587em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span></span></span></span></span> 는 다음과 같이 유도</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>h</mi><mi>i</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>MLP</mtext><mo stretchy="false">(</mo><mo stretchy="false">[</mo><msub><mover accent="true"><mi>h</mi><mo stretchy="true">→</mo></mover><mi>i</mi></msub><mtext> </mtext><mo>:</mo><mtext> </mtext><msub><mover accent="true"><mi>h</mi><mo stretchy="true">←</mo></mover><mi>i</mi></msub><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>MLP</mtext><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mtext>LSTM</mtext><mo stretchy="false">(</mo><msub><mi>h</mi><mrow><mn>0</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mtext> </mtext><mo>:</mo><mtext> LSTM</mtext><mo stretchy="false">(</mo><msub><mi>h</mi><mrow><mi>i</mi><mo>:</mo><mi>m</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \begin{align*} h_i &amp; = \text{MLP}([\overrightarrow{h}_i \ : \ \overleftarrow{h}_i]) \\ &amp; = \text{MLP}([\text{LSTM}(h_{0:i}) \ : \ \text{LSTM}(h_{i:m})]) \end{align*} \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.3764em;vertical-align:-1.4382em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9382em"><span style="top:-3.9382em"><span class="pstrut" style="height:3.9382em"></span><span class="mord"><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9382em"><span style="top:-3.9382em"><span class="pstrut" style="height:3.2164em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.4382em"><span class="pstrut" style="height:3.2164em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9382em"><span style="top:-3.9382em"><span class="pstrut" style="height:3.2164em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">MLP</span></span><span class="mopen">([</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.2164em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">h</span></span><span class="svg-align" style="top:-3.6944em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="height:0.522em;min-width:0.888em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.522em" viewBox="0 0 400000 522" preserveAspectRatio="xMaxYMin slice"><path d="M0 241v40h399891c-47.3 35.3-84 78-110 128
-16.7 32-27.7 63.7-33 95 0 1.3-.2 2.7-.5 4-.3 1.3-.5 2.3-.5 3 0 7.3 6.7 11 20
 11 8 0 13.2-.8 15.5-2.5 2.3-1.7 4.2-5.5 5.5-11.5 2-13.3 5.7-27 11-41 14.7-44.7
 39-84.5 73-119.5s73.7-60.2 119-75.5c6-2 9-5.7 9-11s-3-9-9-11c-45.3-15.3-85
-40.5-119-75.5s-58.3-74.8-73-119.5c-4.7-14-8.3-27.3-11-40-1.3-6.7-3.2-10.8-5.5
-12.5-2.3-1.7-7.5-2.5-15.5-2.5-14 0-21 3.7-21 11 0 2 2 10.3 6 25 20.7 83.3 67
 151.7 139 205zm0 0v40h399900v-40z"></path></svg></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.2164em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">h</span></span><span class="svg-align" style="top:-3.6944em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="height:0.522em;min-width:0.888em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.522em" viewBox="0 0 400000 522" preserveAspectRatio="xMinYMin slice"><path d="M400000 241H110l3-3c68.7-52.7 113.7-120
 135-202 4-14.7 6-23 6-25 0-7.3-7-11-21-11-8 0-13.2.8-15.5 2.5-2.3 1.7-4.2 5.8
-5.5 12.5-1.3 4.7-2.7 10.3-4 17-12 48.7-34.8 92-68.5 130S65.3 228.3 18 247
c-10 4-16 7.7-18 11 0 8.7 6 14.3 18 17 47.3 18.7 87.8 47 121.5 85S196 441.3 208
 490c.7 2 1.3 5 2 9s1.2 6.7 1.5 8c.3 1.3 1 3.3 2 6s2.2 4.5 3.5 5.5c1.3 1 3.3
 1.8 6 2.5s6 1 10 1c14 0 21-3.7 21-11 0-2-2-10.3-6-25-20-79.3-65-146.7-135-202
 l-3-3h399890zM100 241v40h399900v-40z"></path></svg></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">])</span></span></span><span style="top:-2.4382em"><span class="pstrut" style="height:3.2164em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">MLP</span></span><span class="mopen">([</span><span class="mord text"><span class="mord">LSTM</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">LSTM</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)])</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9382em"><span style="top:-3.9382em"><span class="pstrut" style="height:3.9382em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em"><span></span></span></span></span></span></span></span></span></div><p>LSTM head 사용은 continuous prompts 의 training 에 일부 파라미터를 추가하지만, LSTM head 는 pre-training 보다 훨씬 작으며, inference 에서는 output embedding <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span> 만 필요하므로 LSTM head 를 폐기할 수 있다.</p><p>또한 몇 개의 anchor tokens 추가하는 것이 SuperGLUE 의 일부 NLU task 에 도움되는 것을 발견</p><ul><li>RTE task 의 경우, prompt template &quot;<!-- -->[PRE][prompt tokens]<!-- -->[HYP]<!-- -->?<!-- -->[prompt tokens][MASK]<!-- -->&quot; 내의 &quot;?&quot; token 은 anchor token 으로 특별히 추가되어 성능에 큰 영향을 미친다.</li><li>이러한 anchor tokens 는 각 구성 요소를 나타내며, 이 경우 &quot;?&quot; 는 &quot;<!-- -->[HYP]<!-- -->&quot; 가 의문문 부분으로 작용</li></ul><h1>4. Experiments</h1><p>NLU 벤치마크인 LAMA knowledge probing 및 SuperGLUE 에 포괄적으로 실험</p><p>결과, P-tuning 이 GPT 의 NLU 능력을 향상시키고 BERT 스타일 모델에도 이점이 있음을 보여줌</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="41-knowledge-probing">4.1 Knowledge Probing<a href="#41-knowledge-probing" class="hash-link" aria-label="Direct link to 4.1 Knowledge Probing" title="Direct link to 4.1 Knowledge Probing">​</a></h2><p>knowledge probing 또는 fact retrieval 은 LM 이 pre-training 에서 얼마나 세계 지식을 습득했는지 평가</p><p>LAMA dataset 은 knoledge base 에서 선택한 triple 에서 생성된 cloze test 로 평가</p><p>예로 triple 을 &quot;Dante was born in <!-- -->[MASK]<!-- -->.&quot; 라는 handcraft prompt 로 변환한 다음 LM 에게 추론하도록 요청</p><p>pre-trained model 의 parameter 는 고정되어 있으므로, pre-training 에서 얻은 지식으로 평가</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="411-datasets-and-formulation">4.1.1 Datasets And Formulation<a href="#411-datasets-and-formulation" class="hash-link" aria-label="Direct link to 4.1.1 Datasets And Formulation" title="Direct link to 4.1.1 Datasets And Formulation">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="datasets">Datasets<a href="#datasets" class="hash-link" aria-label="Direct link to Datasets" title="Direct link to Datasets">​</a></h4><p>LAMA 의 모든 answers 를 single-token 으로 강제함</p><p>41개의 Wikidata relations 및 34,039개의 texting triples (즉, LAMA-34K) 로 구성된 original LAMA-TREx dataset 채택 (모두 BERT vocabulary 에 포함)</p><p>GPT 와 BERT 의 vocabulary 가 서로 다르므로 교집합을 포함하는 다른 버전의 LAMA 를 설정</p><p>이 subset 은 약 29,000 tasting triples 를 추가하고, 이를 LAMA-29K 라고 명명</p><p>training 에 대해선 all prompt searching approaches 가 prompt 를 훈련하거나 찾기 위해 일부 추가 데이터가 필요.</p><p>저자는 AutoPrompt 설정을 따르며, original TRE-x dataset 에 training set 구축.</p><p>이 training set 은 test set 과 유사하지만 약간 다른 answer distribution 을 가지고 있다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation">Evaluation<a href="#evaluation" class="hash-link" aria-label="Direct link to Evaluation" title="Direct link to Evaluation">​</a></h4><p>원래, LAMA 는 Table 1 처럼 각 관계에 대한 handcraft prompt 를 제공했으며 이러한 prompt 는 효과적이지만 sub-optimal 이다.</p><p>bidirectional masked language models 의 경우, &quot;<!-- -->[X]<!-- -->&quot; 를 subject entity 로, &quot;<!-- -->[Y]<!-- -->&quot; 를 <!-- -->[MASK]<!-- --> token 으로 데체</p><p>GPT 같은 unidirectional language model 의 경우, LAMA 의 원래 설정에 따라 Transformer-XL 에서 target position 앞의 network output 을 사용</p><p>P-tuning 진행 시, bidirectional models 에는 (3, sub, 3, obj, 3) template 을 사용</p><p>unidirectional models 에는 (3, sub, 3, obj) 을 사용</p><p>숫자는 prompt tokens 수를 나타낸다.</p><p>이 knowledge probing task 에서는 어떠한 anchor token 도 사용하지 않으며, training 중 learning rate 1e-5 및 Adam optimizer 사용</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="412-results">4.1.2 Results<a href="#412-results" class="hash-link" aria-label="Direct link to 4.1.2 Results" title="Direct link to 4.1.2 Results">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="general-performance">General performance<a href="#general-performance" class="hash-link" aria-label="Direct link to General performance" title="Direct link to General performance">​</a></h4><p><img loading="lazy" alt="Table 2" src="/assets/images/image-49-b6b5cd8e380ea81d4582f9c27a8f17a6.png" width="1724" height="693" class="img_ev3q"></p><ul><li>P-tuning 은 LAMA-34K 에서 43.3% 를 50.6% 로 끌어 올림</li><li>LAMA-29K 에서 45.2% 를 64.2% 까지 향상</li><li>AutoPrompt 및 LPAQA 같은 discrete prompt searching approach 보다 뛰어남</li></ul><p>위 결과는 prompt 를 개선하고 fine-tuning 없이 단순히 더 나은 prompt 를 찾음으로써, LM 이 생각보다 훨씬 더 많은 knowledge 를 capture 했다는 것을 시사</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="p-tuning-vs-fine-tuning">P-tuning v.s. Fine-tuning<a href="#p-tuning-vs-fine-tuning" class="hash-link" aria-label="Direct link to P-tuning v.s. Fine-tuning" title="Direct link to P-tuning v.s. Fine-tuning">​</a></h4><p>저자는 pre-training 중 LM 이 얼마나 많은 지식을 습득하는지 평가</p><p>주요 연구는 GPT 같은 unidirectional model 에서 P-tuning 과 fine-tuning 을 비교하는 것</p><p>하지만 다음 질문이 발생할 수 있다. &quot;unidirectional 및 bidirectional model 은 P-tuning 에서 유사한 개선을 얻을까?&quot;</p><p>기존의 tuning 방법을 포괄적으로 검토하고자 다음 approach 포함</p><ol><li>Manual Prompt (MP) : LAMA 의 original manual prompt 사용</li><li>Fine-tuning (FT) : subject 를 제시하고 object 를 예측하기 위해 모델을 FT</li><li>Manual Prompt with Fine-tuning (MP + FT) : manual prompt 로 LM 을 FT</li><li>P-tuning : continuous prompt 를 사용하면서 LM parameter freezing</li></ol><p>LAMA-29K 에서 네 가지 전략을 구현 (Table 2 오른쪽)</p><ul><li>놀라운 점은 FT 가 LM 의 all parameter 를 tuning 하지만, P-tuning 은 그렇지 않으니 더 강력해야 한다는 것. 하지만 P-tuning 이 FT 기반 방법과 비슷하거나 더 나은 결과<ul><li>knowledge probing 에선 reasoning 보다는 hard-coding 이 되야하는 경우가 많아, FT 는 치명적인 망각을 초래할 수 있음</li><li>반면 P-tuning 은 pre-trained LM&#x27;s parameter 를 변경하지 않고, continuous prompt 로 저장된 knowledge 활용</li></ul></li><li>BERT 와 GPT 의 P-tuning 에 대한 개선 사항 사이에 명확한 격차가 있다는 놀라운 점<ul><li>high-quality MP + FT 를 사용한 fine-tuning 의 효과가 관찰되지만, GPT 는 BERT 만큼 MP+FT 에서 이점을 얻지 못함</li><li>P-tuning 은 unidirectional LM 과 더 어울린다는 것을 시사</li><li>11B 의 큰 모델인 MegatronLM2 의 경우, FT 가 거의 작동하지 않는 반면, P-tuning 은 여전히 적용 가능하여 SOTA 달성</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="42-superglue">4.2 SuperGLUE<a href="#42-superglue" class="hash-link" aria-label="Direct link to 4.2 SuperGLUE" title="Direct link to 4.2 SuperGLUE">​</a></h2><p>P-tuning 평가를 위해 SuperGLUE 에서 실험 수행</p><ul><li>SuperGLUE 는 총 8개의 NLU task 를 지님</li><li>ReCoRD 는 prompt 가 없으므로 P-tuning 이 불가능하여 포함하지 않아 7개의 task 를 다룸<ul><li>question answering</li><li>MultiRC</li><li>textual entailment</li><li>RTE</li><li>co-reference resolution</li><li>causal reasoning</li><li>word sense disambiguation</li></ul></li></ul><p>실험 설정에서 fully-supervised 및 few-shot 모두 고려</p><ul><li>fully-supervised 에선 전체 훈련셋 (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_{train}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span><span class="mord mathnormal mtight">ain</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>) 사용하고 모델 선택 및 hyperparameter tuning 을 위해 개발셋 (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mrow><mi>d</mi><mi>e</mi><mi>v</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_{dev}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>) 사용</li><li>few-shot 에선 SuperGLUE 의 few-shot 버전 (FewGlue) 채택<ul><li>SuperGLUE 의 subset, 각 task 는 32개의 훈련 데이터 (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi><mn>32</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_{train32}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span><span class="mord mathnormal mtight">ain</span><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>) 및 크기가 400~20000 까지 다양한 unlabeled 구성 (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mrow><mi>u</mi><mi>n</mi><mi>l</mi><mi>a</mi><mi>b</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_{unlabeled}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mord mathnormal mtight">ab</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>)</li></ul></li></ul><p>이전 연구에서 개발셋이 없고 고정된 hyperparameter 를 채택하여 테스트셋에 과적합되었음.</p><p>저자는 적절한 few-dev set (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mrow><mi>d</mi><mi>e</mi><mi>v</mi><mn>32</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_{dev32}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>) 구성. 더 큰 개발셋은 추가적인 이점을 제공한다는 것이 입증되었기 때문</p><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mrow><mi>d</mi><mi>e</mi><mi>v</mi><mn>32</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_{dev32}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 사용되지 않은 훈련셋에서 random sample 로 선택하여 구성되며, few-training set 의 크기보다 크지 않도록 제한</p><p>[Small language models are also few-shot learners]<!-- --> 와 동일한 matric 사용</p><hr><p>저자는 NLU task 를 blank filling task 로 재구성.</p><p>[Small language models are also few-shot learners]<!-- --> 와 달리 P-tuning 은 initial prompt embeddings 을 패턴 내의 다른 position 에 배치한 후 pre-trained model 과 함께 prompt embedding 을 FT</p><ul><li>fully-supervised 설정<ul><li>linearly decayed learning rate 를 사용하는 AdamW optimizer 사용</li><li>hyperparameter 에 대해 greedy search 를 수행하고 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mrow><mi>d</mi><mi>e</mi><mi>v</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_{dev}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 또는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mrow><mi>d</mi><mi>e</mi><mi>v</mi><mn>32</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_{dev32}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 에서 최상의 조합 선택</li><li>구체적으로 learning rate 1e-5, 2e-5, 3e-5 선택하고 batch size 16, 32</li></ul></li><li>small datasets 의 경우<ul><li>pre-trained model 을 20 epoch fine-tuning</li><li>larger datasets 의 경우, 모델의 빠른 수렴을 위해 training epoch 을 10 으로 줄임.</li><li>overfitting 피하기 위해 early stop 사용</li></ul></li><li>few-shot learning 의 경우<ul><li>동일한 hyperparameter</li><li>prompt embeddings 의 FT 에 더 많은 단계가 필요하여 3500 으로 확장</li><li></li></ul></li></ul><hr><p>P-tuning 은 bidirectional 및 unidirectional model 에 사용 가능</p><p>공정한 비교를 위해 연산량이 유사한 BERT-base 3 과 GPT2-base, BERT-large 와 GPT2-medium 비교</p><p>few-shot learning 을 위해 albert-xxlarge-v2 모델도 실험</p><p>각 사전 훈련 모델에 대한 결과로 표준 FT (즉, <!-- -->[CLS]<!-- --> 임베딩을 사용한 분류), PET FT <!-- -->[Small language models are also few-shot learners]<!-- -->, PET zero-shot 및 P-tuning의 성능을 보고</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="421-fully-supervised-learning">4.2.1 Fully-Supervised Learning<a href="#421-fully-supervised-learning" class="hash-link" aria-label="Direct link to 4.2.1 Fully-Supervised Learning" title="Direct link to 4.2.1 Fully-Supervised Learning">​</a></h3><p><img loading="lazy" alt="Table 3" src="/assets/images/image-50-228b79061d499bdfc0179f1f73b14cb9.png" width="1724" height="693" class="img_ev3q"></p><p><img loading="lazy" alt="Table 4" src="/assets/images/image-51-ea1a9e7f53be30455f9138736efca71b.png" width="1754" height="694" class="img_ev3q"></p><ul><li>bert-base-cased 및 bert-large-cased model 모두 P-tuning 으로 7개 task 중 5개 task 가 우수한 결과</li><li>WiC 및 MultiRC 는 큰 훈련셋을 가져, FT 가 더 큰 이점을 취함</li><li>gpt2-base 및 gpt2-medium model 에 대해 P-tuning 은 모든 gpt2-base 중 가장 유망한 결과</li></ul><p>위 결과로 bert 및 gpt 기반 모델의 NLU 성능 효과적으로 향상</p><ul><li>gpt2-base with P-tuning 은 7개 task 중 6개에서 BERT-base 의 best 결과 능가하고 WiC task 에서 comparable</li><li>BERT-large 와 비교하면 P-tuning 을 사용한 GPT2-medium 은 7개 task 중 4개에서 우위, RTE 와 WSC task 에선 comparable, 유일한 예외는 WiC</li><li>WiC task 에선 FT 가 우수하며, 이는 word sense disambiguation task 가 prompt-based MLM prediction 에 적합하지 않음을 추측</li></ul><p>모두 종합하여 P-tuning 을 사용하면 GPT2 가 BERT-based model 과 comparable 하거나 더 나은 성능 달성</p><p>이는 BERT 같은 bidirectional model 이 NLU task 에서 항상 GPT2 와 같은 unidirectional model 보다 더 우수하다는 것을 뒤엎음</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="422-few-shot-learning">4.2.2 Few-Shot Learning<a href="#422-few-shot-learning" class="hash-link" aria-label="Direct link to 4.2.2 Few-Shot Learning" title="Direct link to 4.2.2 Few-Shot Learning">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="sub-optimal-and-sensitive-manual-prompts">Sub-optimal and Sensitive Manual Prompts<a href="#sub-optimal-and-sensitive-manual-prompts" class="hash-link" aria-label="Direct link to Sub-optimal and Sensitive Manual Prompts" title="Direct link to Sub-optimal and Sensitive Manual Prompts">​</a></h4><p>PEFT/iPET 는 manual prompt 로 SuperGLUE few-shot learning task 에 SOTA 달성</p><p>이 prompt 는 효과적이지만 sub-optimal 이며 노동이 필요하다.</p><p>manual prompt 의 종합적 이해를 위해 비교 실험 진행</p><p><img loading="lazy" alt="Table 6" src="/assets/images/image-52-86fe0009a8d5ad1ba54b28ee6661d7a3.png" width="1685" height="465" class="img_ev3q"></p><p>다양한 manual prompt 와 P-tuning 을 사용한 결과 (Table 6)</p><ol><li>결과는 prompt 의 의미, 형식, 문법과 few-shot learning 성능 간에 명확한 상관 관계가 없음<ul><li>합리적으로 여기는 prompt 가 LM 에 효과적이지 않을 수 있음</li></ul></li><li>manual prompt 의 작은 변경 사항이 큰 성능 차이 일으킴<ul><li>pre-trained LM 은 prompt 선택에 있어 민감</li><li>manual prompt 는 복잡하다 결론</li><li>Table 6 에서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mrow><mi>d</mi><mi>e</mi><mi>v</mi><mn>32</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_{dev32}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 사용으로 best manual prompt 찾는 것은 불가능</li><li>few-shot 환경에서도 optimal manual prompt 선택은 어려움</li><li>반면 P-tuning 은 훨씬 적은 수동 작업으로 더 나은 prompt 를 자동으로 검색하는 데 유망</li></ul></li></ol><h4 class="anchor anchorWithStickyNavbar_LWe7" id="updated-sota-for-superglue-few-shot-learning">Updated SOTA for SuperGLUE Few-shot Learning<a href="#updated-sota-for-superglue-few-shot-learning" class="hash-link" aria-label="Direct link to Updated SOTA for SuperGLUE Few-shot Learning" title="Direct link to Updated SOTA for SuperGLUE Few-shot Learning">​</a></h4><p><img loading="lazy" alt="Table 5" src="/assets/images/image-53-c10d81656bedccefc5103e1e93b53bab.png" width="1691" height="798" class="img_ev3q"></p><ul><li>P-tuning 에 의해 SuperGLUE few-shot SOTA 달성함을 보여줌</li><li>유의할 점은  PET 는 manual prompt fine-tuning 외에도 데이터 증강, 앙상블 및 distillation 으로 성능 향상하고 있으며, 모델 선택 및 hyperparameter tuning 을 테스트셋에 overfitting 하여 수행<ul><li>공정성을 위해 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mrow><mi>d</mi><mi>e</mi><mi>v</mi><mn>32</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_{dev32}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 에서 재실험하며 모든 보조 기술 제거</li></ul></li><li>Table 5 는 P-tuning 이 모든 작업에서 manual prompt 로 비교하여 PET 및 PET-best 보다 우수한 성능<ul><li>P-tuning 이 manual prompt 보다 훨씬 우수한 prompt 검색 및 few-shot task 성능 크게 향상함을 입증</li></ul></li><li>CB, WiC, RTE 및 WSC 등의 task 에서 P-tuning 은 데이터 증강, 앙상블 및 distillation 등 보조 기술로 PET/iPET 보다 우수한 성능</li></ul><p>위 결과는 P-tuning 이 few-shot NLU task 의 이점 입증</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="423-finetuning-vs-mp-finetuning-vs-p-tuning">4.2.3 Finetuning v.s. MP Finetuning v.s. P-tuning<a href="#423-finetuning-vs-mp-finetuning-vs-p-tuning" class="hash-link" aria-label="Direct link to 4.2.3 Finetuning v.s. MP Finetuning v.s. P-tuning" title="Direct link to 4.2.3 Finetuning v.s. MP Finetuning v.s. P-tuning">​</a></h3><p>Table 3, 4 는 NLU 성능 향상을 위해 세 가지 tuning-based paradigm 제시</p><p>P-tuning 은 BERT-based model 에서 평균적으로 약 2 point, GPT-based model 에선 5 points 이상 우수한 성능</p><p>구체적으로, P-tuning 은 대부분 task 에서 best results 를 달성하였지만, WiC 에선 cloze questions 로 정식화하기 어려워, FT 가 우수한 성능 달성</p><p>P-tuning 과 MP+FT 를 비교하면 P-tuning 이 평균적으로 MP+FT 보다 큰 이점을 보여주며, 이는 MP+FT 가 좋은 manual prompt 찾기엔 어렵기 때문이다.</p><p>반면 P-tuning 은 자동으로 더 나은 prompt 를 검색 가능</p><p>P-tuning 은 fine-tuned model 의 parameter 를 tuning 하면서 광범위한 prompt space 탐색 가능하여 새로운 tuning paradigm 으로, fine-tuning 이 어려운 LLM 을 유도하는 데 경쟁력 있는 잠재력 입증</p><h1>5. Related Work</h1><h1>6. Conclusion</h1><p>본 연구에서 <strong><em>P-tuning</em></strong> 제안</p><ul><li>continuous space 에서 더 나은 prompt 를 자동으로 탐색하여 pre-trained model 의 NLU 능력 강화</li><li>큰 검증셋에 덜 의존적이며, adversarial prompt 로부터의 피해를 덜 입고, overfitting 완화</li><li>test 동안 추가 text 를 제공하지 않고도 LLM 의 세계 지식의 64% (P@1) 복구</li><li>SuperGLUE 에서 GPT 스타일 모델에게 NLU 능력을 BERT 와 comparable 한 성능 부여 (과거엔 불가능하다 여김)</li><li>bidirectional model 에 도움되며, SuperGLUE 에서 SOTA 성능 발휘</li><li>위 결과는 LM 이 pre-training 중 생각보다 더 많은 세계 지식을 습득한 것을 입증</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/peft">PEFT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/p-tuning">p-tuning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/gpt">GPT</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/NLP/PEFT/Soft Prompt/2021-03-P-tuning.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Prefix-Tuning: Optimizing Continuous Prompts for Generation</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">The Power of Scale for Parameter-Efficient Prompt Tuning</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#31-architecture" class="table-of-contents__link toc-highlight">3.1 Architecture</a></li><li><a href="#32-optimization" class="table-of-contents__link toc-highlight">3.2 Optimization</a></li><li><a href="#41-knowledge-probing" class="table-of-contents__link toc-highlight">4.1 Knowledge Probing</a><ul><li><a href="#411-datasets-and-formulation" class="table-of-contents__link toc-highlight">4.1.1 Datasets And Formulation</a></li><li><a href="#412-results" class="table-of-contents__link toc-highlight">4.1.2 Results</a></li></ul></li><li><a href="#42-superglue" class="table-of-contents__link toc-highlight">4.2 SuperGLUE</a><ul><li><a href="#421-fully-supervised-learning" class="table-of-contents__link toc-highlight">4.2.1 Fully-Supervised Learning</a></li><li><a href="#422-few-shot-learning" class="table-of-contents__link toc-highlight">4.2.2 Few-Shot Learning</a></li><li><a href="#423-finetuning-vs-mp-finetuning-vs-p-tuning" class="table-of-contents__link toc-highlight">4.2.3 Finetuning v.s. MP Finetuning v.s. P-tuning</a></li></ul></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.130f03bb.js"></script>
<script src="/assets/js/main.78c0c0af.js"></script>
</body>
</html>