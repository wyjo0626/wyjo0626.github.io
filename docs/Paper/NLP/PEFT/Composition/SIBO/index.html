<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/NLP/PEFT/Composition/2024-02-SIBO">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning | WYJLab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Composition/SIBO"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning | WYJLab"><meta data-rh="true" name="description" content="논문 및 이미지 출처 :"><meta data-rh="true" property="og:description" content="논문 및 이미지 출처 :"><link data-rh="true" rel="icon" href="/img/WYJLab.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Composition/SIBO"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Composition/SIBO" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/PEFT/Composition/SIBO" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="WYJLab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="WYJLab Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.9ed678b7.css">
<link rel="preload" href="/assets/js/runtime~main.fba06b0c.js" as="script">
<link rel="preload" href="/assets/js/main.97da4e69.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Multi-Modal/PEFT/Composition/Moka">Multi-Modal</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">Analysis</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Attacking/universal-adversarial-prompt">Attacking</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Augmentation/PromptDA">Augmentation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Generalization/NoisyTune">Generalization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Model/Transformer">Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Multi-Task/Flan-T5">Multi-Task</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">PEFT</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">Composition</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">LoRA: Low-Rank Adaptation of Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoHa">FedPara: Low-Rank Hadamard Product For Communication-Efficient Federated Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/BitFit">BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/IA³">Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/DyLoRA">DyLoRA: Parameter Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoKr">KronA: Parameter Efficient Tuning with Kronecker Adapter</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/AdaLoRA">Adaptive Budget Allocation For Parameter-Efficient Fine-Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/ReLoRA">ReLoRA: High-Rank Training Through Low-Rank Updates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/IncreLoRA">IncreLoRA: Incremental Parameter Allocation Method for Parameter-Efficient Fine-tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/Delta-LoRA">Delta-LoRA: Fine-Tuning High-Rank Parameters with the Delta of Low-Rank Matrices</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LongLoRA">LongLoRA: Efficient Fine-Tuning of LongContext Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/SaLoRA">Structure-Aware Low-Rank Adaptation for Parameter-Efficient Fine-Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/VeRA">VeRA: Vector-Based Random Matrix Adaptation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/SoRA">Sparse Low-rank Adaptation of Pre-trained Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/COLA">Chain of LoRA: Efficient Fine-tuning of Language Models via Residual Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/ApiQ">ApiQ: Finetuning of 2-Bit Quantized Large Language Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/ApiQ">ApiQ: Finetuning of 2-Bit Quantized Large Language Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/DoRA">DoRA: Weight-Decomposed Low-Rank Adaptation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/FLoRA">FLoRA: Low-Rank Adapters Are Secretly Gradient Compressors</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA+">LoRA+: Efficient Low Rank Adaptation of Large Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/MeLoRA">MELoRA: Mini-Ensemble Low-Rank Adapters for Parameter-Efficient Fine-Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/ResLoRA">ResLoRA: Identity Residual Mapping in Low-Rank Adaption</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/SIBO">SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/ALoRA">ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/AutoLoRA">AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/BiLoRA">BiLoRA: A Bi-level Optimization Framework for Overfitting-Resilient Low-Rank Adaptation of Large Pre-trained Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/HiddenKey">LoRA Meets Dropout under a Unified Framework</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA-Dropout">LoRA Dropout as a Sparsity Regularizer for Overfitting Control</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/PISSA">PISSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/DoRA2">DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/ETHER">ETHER: Efficient Finetuning of Large-Scale Models with Hyperplane Reflections</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/MoRA">MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/MiLoRA">MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/MoSLoRA">Mixture-of-Subspaces in Low-Rank Adaptation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/OLoRA">OLoRA: Orthonormal Low-Rank Adaptation of Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/RoseLoRA">RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/SinkLoRA">SinkLoRA: Enhanced Efficiency and Chat Capabilities for Long-Context Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/RandLoRA">RandLoRA: Full-Rank Parameter-Efficient Fine-Tuning of Large Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/DeLoRA">DeLoRA: Decoupling Angles and Strength in Low-Rank Adaptation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/DenseLoRA">DenseLoRA: Dense Low-Rank Adaptation of Large Language Models</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Generalization/Flat-LoRA">Generalization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Mixture/UF">Mixture</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Module/Adapter">Module</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Pruning/SMP">Pruning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Quantization/Fine-Tuning/AlphaTuning">Quantization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Selective/AdapterDrop">Selective</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning">Soft Prompt</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Engineering/ICL/Chain-of-Thought">Prompt Engineering</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Tuning/PTR">Prompt Tuning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Reinforcement Learning/Reflexion">Reinforcement Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Text Generation/InstructGPT">Text Generation</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Reinforce Learning/DPO/RLHF/Self-RLM">Reinforce Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Composition/CLIP-LoRA">Vision-Language</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">NLP</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">PEFT</span><meta itemprop="position" content="3"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Composition</span><meta itemprop="position" content="4"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning</span><meta itemprop="position" content="5"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning</h1></header><p>논문 및 이미지 출처 : <a href="https://arxiv.org/pdf/2402.11896" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2402.11896</a></p><h1>Abstract</h1><p>대규모 언어 모델(LLMs)의 모든 파라미터를 미세 조정(fine-tuning)하려면 상당한 계산 능력과 긴 시간이 필요하다. Adapter tuning 및 LoRA 와 같은 최신 parameter-efficient fine-tuning (PEFT) 기술의 발전은 이러한 LLM 의 파라미터 중 일부만 조정할 수 있도록 한다. </p><p>동시에, over-smoothing 문제는 이러한 Transformer-based LLM 의 효과를 감소시켜 downstream tasks 에서 성능이 최적화되지 못하는 결과를 초래한다는 점이 지적되어 왔다. </p><p>본 논문에서는 initial residual 을 주입하여 PEFT 를 강화하는 <strong>SIBO</strong> (SImple BOoster) 를 제안한다. </p><ul><li>SIBO 는 간단하고 최신 PEFT 기술에 쉽게 확장 가능하며, over-smoothing 을 완화하고 성능을 향상시킨다. </li><li>22 benchmark dataset 에서의 광범위한 실험은 SIBO 가 다양한 강력한 baseline 의 성능을 크게 향상시킴을 보여주었으며, 기존 PEFT 방법에 비해 산술 추론 및 상식 추론 과제에서 각각 최대 15.7% 및 23.5% 의 성능 향상을 달성했다.</li></ul><h1>1. Introduction</h1><p>많은 Transformer-based large language models (LLMs) 은 상당한 깊이를 가지고 있다. </p><p>예를 들어, BERT-large 는 24 layer 를 가지고 있으며, LLaMA-7B 는 32 layer, LLaMA-65B 는 80 layer 를 가지고 있다. 그러나 이러한 깊이는 도전 과제를 제시한다: Deep Transformers 는 over-smoothing 문제에 직면하는 경향이 있다. </p><p>Brunner et al. (2019) 에서 자세히 설명된 바와 같이, 이 문제는 Transformers 의 deeper layer 에서 나타나며, token representation 이 점점 더 균일성으로 수렴하게 된다. </p><p>Over-smoothness 는 Transformer training 의 확장성, 특히 depth 측면에서 방해가 될 뿐만 아니라, model size 를 확장하는 효과를 제한한다. 그 결과, 모델을 확장하면 종종 성능 향상이 미미하거나, 경우에 따라 정확도가 감소하기도 한다.</p><p>한편, LLMs 의 full-model fine-tuning 의 주요 단점은 original model 의 모든 파라미터를 업데이트해야 한다는 점이다. 이는 BERT-large 나 RoBERTa-large 와 같은 모델에서는 비교적 작은 제한 사항이지만, billions 의 trainable parameters 를 포함하는 LLaMA 와 같은 larger model 에서는 주요 장애물로 발전한다. </p><p>많은 접근법들이 이 문제를 해결하기 위해 파라미터의 일부만 업데이트하거나 new tasks 에 맞춘 lightweight external modules 를 추가하는 방법을 탐구해왔다. </p><p>이러한 전략들은 각 task 마다 pre-trained model 과 함께 상대적으로 적은 수의 task 별 파라미터를 저장하고 로드해야 한다. full-model fine-tuning 에 대한 이러한 매력적인 대안들은 parameter-efficient fine-tuning (PEFT) 이라고 불리며 (Houlsby et al., 2019), LLMs 배포의 실현 가능성을 크게 향상시킨다.</p><p>몇몇 접근법들이 over-smoothing 문제를 다루기 위해 제안되었지만, 예를 들어 &quot;uniform tokens&quot; 을 피하기 위해 특별히 설계된 regularization 을 추가하거나, all layers 의 reprensetation 을 융합하는 방법 등이 있지만, PEFT 방법을 통해 over-smoothing 문제를 완화하려는 방법은 아직 제안되지 않았다. </p><p>대부분의 사용 사례에서 모델에 대한 내부 수정이 불가능한 LLMs 시대에, PEFT 기술을 통해 over-smoothing 문제를 해결하는 것은 매우 중요하다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="challenge-and-present-work">Challenge and present work.<a href="#challenge-and-present-work" class="hash-link" aria-label="Direct link to Challenge and present work." title="Direct link to Challenge and present work.">​</a></h4><p>over-smoothing 에 대한 기존의 해결책은 model architecture 의 변경을 포함하며, 따라서 parameter-efficient 하지 않기 때문에, PEFT 기술을 효과적으로 해결할 수 있는 방법은 무엇일까? </p><p>over-smoothing 문제에 기여할 수 있는 두 가지 주요 요인은 다음과 같다: 1) model encoding layer 내의 redundancy, 2) deeper layer 의 효과적인 최적화를 방해하는 suboptimal training process. </p><p>첫 번째 문제를 해결하기 위한 직관적이고 논리적인 해결책은 encoder 의 layer 수를 줄이는 것이다. 그러나 이 접근법은 성능 저하를 초래할 수 있다. </p><p>두 번째 문제를 해결하기 위해, 이전의 접근법들 (Gong et al., 2021; Zhou et al., 2021; Shi et al., 2022) 은 parameter-efficient 하지 않아서 LLMs 에의 적용이 제한적이었다.</p><p>기존의 PEFT 기술과 함께 over-smoothing 을 완화하기 위한 유연하면서도 간단한 plug-and-play framework 를 고안하기 위해, 저자의 아이디어는 PEFT input 에 initial residual 을 주입하는 것이다. </p><p>이 initial residual connection 은 각 token 의 final reprensetation 이 최소한의 input layer 의 feature 를 유지하도록 보장하여, final token representation 의 균일성을 줄이는 것을 목표로 한다. </p><p>저자는 이 새로운 프레임워크를 SIBO, 즉 _SI_mple _BO_oster 라고 명명했으며, 이는 특히 Adapter 와 LoRA 에 설계된 PEFT 기술을 향상시키기 위한 것이다. </p><p>실증적으로, 산술 추론 과제에서 SIBO 는 Adapter 와 LoRA 를 각각 최대 15.7% 와 13.6% 향상시켰다. 상식 추론 과제에서는 Adapter 대비 최대 7.6%, LoRA 대비 23.5% 향상을 보였다.</p><h1>2. Preliminaries</h1><p>다음에서는 두 가지 인기 있는 PEFT 기술의 요약을 제시한다: adapters 와 reparametrization-based methods.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="adapters">Adapters.<a href="#adapters" class="hash-link" aria-label="Direct link to Adapters." title="Direct link to Adapters.">​</a></h4><p>Adapters 는 parallel adapters 와 serial adapters 라는 두 가지 뚜렷한 범주로 나뉜다. </p><p>Parallel adapters 는 core model 의 다양한 layer 옆에 additional learnable module 을 통합한다. </p><p>반대로, serial adapters 는 Transformer model 의 특정 layer 사이에 이러한 module 을 순차적으로 삽입한다. </p><p>예를 들어, Transformer model 의 attention 및 feed forward layers 후에 fully connected networks 을 추가하는 것이다. 본 연구에서는 다음과 같은 일반적인 형식을 가진 고전적인 serial adapter 에 초점을 맞춘다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>h</mi><mo>←</mo><mi>h</mi><mo>+</mo><mi>f</mi><mo stretchy="false">(</mo><mi>h</mi><msub><mi>W</mi><mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mrow><mi>u</mi><mi>p</mi></mrow></msub><mo separator="true">,</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} h \leftarrow h + f(hW_{down})W_{up}, \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-2.85em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></div><p>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1</mn><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">h \in \mathbb{R}^{1 \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span> 는 adapter 이 삽입되기 전의 앞선 layer 의 output 을 나타낸다. 따라서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span> 는 adapter 의 input 으로 사용된다. </p><p>이는 먼저 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi></mrow></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi>r</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W_{down} \in \mathbb{R}^{d \times r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span></span></span></span></span></span></span></span></span></span></span></span></span> 을 통해 lower dimension <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span></span></span> 로 down-projection 된 후, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>u</mi><mi>p</mi></mrow></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>r</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W_{up} \in \mathbb{R}^{r \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span> 을 통해 original dimension <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span></span> 로 up-projection 된다. </p><p>function <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\cdot)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span> 는 non-linear function 을 나타낸다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="reparameterization-based-methods">Reparameterization-based methods.<a href="#reparameterization-based-methods" class="hash-link" aria-label="Direct link to Reparameterization-based methods." title="Direct link to Reparameterization-based methods.">​</a></h4><p>이러한 방법들은 low-rank 전략을 통해 network weights 를 수정하도록 설계되었다. </p><p>이 기술은 성능을 저해하지 않으면서 tunable parameters 의 수를 효과적으로 줄인다. 예를 들어, Low-Rank Adaptation (LoRA) 은 pre-trained weight matrix <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W \in \mathbb{R}^{d \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span> 에 대한 update <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">\Delta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span></span> 를 low-rank decomposition 을 통해 근사한다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>h</mi><mo>←</mo><mi>h</mi><mo stretchy="false">(</mo><mi>W</mi><mo>+</mo><mi>s</mi><mo>⋅</mo><msub><mi>W</mi><mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi></mrow></msub><msub><mi>W</mi><mrow><mi>u</mi><mi>p</mi></mrow></msub><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} h \leftarrow h(W + s \cdot W_{down}W_{up}), \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em"><span style="top:-2.85em"><span class="pstrut" style="height:2.84em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em"><span></span></span></span></span></span></span></span></span></div><p>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">h \in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span> 는 앞선 layer 의 output 이며, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W \in \mathbb{R}^{d \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span> 는 MLP 또는 attention layers 에 해당하는 pre-trained weight matrix 이다. </p><p>matrices <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi></mrow></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi>r</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W_{down} \in \mathbb{R}^{d \times r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span></span></span></span></span></span></span></span></span></span></span></span></span> 및 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>u</mi><mi>p</mi></mrow></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>r</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W_{up} \in \mathbb{R}^{r \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span> 는 업데이트를 근사하기 위한 low rank matrices 이며, 즉 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi><mo>≈</mo><msub><mi>W</mi><mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi></mrow></msub><msub><mi>W</mi><mrow><mi>u</mi><mi>p</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\Delta W \approx W_{down}W_{up}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> 이다. </p><p>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>≪</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">r \ll d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≪</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span></span> 는 LoRA 에 중요한 hyperparameter 이며, scalar <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>≥</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">s \geq 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719em;vertical-align:-0.136em"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span> 는 adjustable hyperparameter 이다.</p><h1>3. Methodology</h1><p>이 섹션에서는 먼저 PEFT 기술에서의 over-smoothing 문제를 분석하고, 그 다음으로 제안된 프레임워크인 SIBO 를 제시한다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="31-over-smoothing-in-peft">3.1 Over-smoothing in PEFT<a href="#31-over-smoothing-in-peft" class="hash-link" aria-label="Direct link to 3.1 Over-smoothing in PEFT" title="Direct link to 3.1 Over-smoothing in PEFT">​</a></h2><p>graph neural networks 에서 유래된 <em>over-smoothing</em> 용어는 반복적인 aggregation layers 에서 동일한 adjacency matrix 를 사용하는 것에서 비롯된 node reprensetation 의 homogeneity 증가로 인한 성능 저하를 의미한다. </p><p>Shi et al. (2022) 는 language model 에서도 over-smoothing 현상이 나타남을 확인했는데, 이는 input sentence 의 different tokens 가 more layers 가 쌓일수록 점점 더 유사한 reprensetation 을 가지게 되어, deep Transformer model 의 효과를 감소시킨다.</p><p>몇몇 전략들이 over-smoothing 을 완화하기 위해 제안되었지만, 이들은 PEFT 기술을 위해 설계되지 않아 LLMs 에의 적용이 덜 실용적이다. </p><p>특히, 저자는 adapters 와 LoRA 를 포함한 널리 채택된 PEFT 기술에서도, 특히 deeper layer 에서 over-smoothing 을 관찰했다. </p><p>저자의 분석에서, over-smoothing 은 같은 문장 내 tokens 간의 유사성을 평가하는 token-wise cosine similarity 를 통해 감지할 수 있다. <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span></span></span></span></span> tokens 로 구성된 sentence <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>h</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>h</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>h</mi><mi>m</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(h_1, h_2, \dots, h_m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 에 대해, token-wise cosine similarity 는 다음과 같이 계산된다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo stretchy="false">(</mo><mi>m</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mi>j</mi></mrow></munder><mfrac><mrow><msubsup><mi>h</mi><mi>i</mi><mi mathvariant="normal">⊤</mi></msubsup><msub><mi>h</mi><mi>j</mi></msub></mrow><mrow><mi mathvariant="normal">∥</mi><msub><mi>h</mi><mi>i</mi></msub><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub><mi mathvariant="normal">∥</mi><msub><mi>h</mi><mi>j</mi></msub><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow></mfrac><mo separator="true">,</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \frac{1}{m(m - 1)} \sum_{i \neq j} \frac{h_i^\top h_j}{\|h_i\|_2 \|h_j\|_2}, \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.9643em;vertical-align:-1.2322em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7322em"><span style="top:-3.7322em"><span class="pstrut" style="height:3.5261em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord">1</span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8479em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5261em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">∥</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∥</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9721em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2322em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7322em"><span style="top:-3.7322em"><span class="pstrut" style="height:3.5261em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2322em"><span></span></span></span></span></span></span></span></span></div><p>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∥</mi><mo>⋅</mo><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\|\cdot\|_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">∥</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 Euclidean norm 이다. </p><p><img loading="lazy" alt="Figure 1, 2" src="/assets/images/image-314-1efa4f00789fbdeafbb468822ff32a58.png" width="611" height="849" class="img_ev3q"></p><p>Fig. 1 과 Fig. 2 에서 볼 수 있듯이, adapters 와 LoRA 모두에서 backbone language model 의 layer depth 가 증가함에 따라 token-wise similarity 가 꾸준히 증가한다. </p><p>따라서, over-smoothing 문제는 PEFT 기술을 통해 adaptation 된 pre-trained language models 에서도 지속된다. 따라서 PEFT methods 의 over-smoothing 을 완화하면서도 효율성을 유지하는 일반적인 프레임워크를 고안하는 것이 필수적이다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="32-initial-residual-integration">3.2 Initial residual integration<a href="#32-initial-residual-integration" class="hash-link" aria-label="Direct link to 3.2 Initial residual integration" title="Direct link to 3.2 Initial residual integration">​</a></h2><p>PEFT 을 위한 범용 plug-and-play 향상을 달성하기 위해, 저자는 PEFT module 의 입력부터 시작하여 pre-trained model 의 각 layer input 에 initial residual 을 주입한다.</p><p>pre-trained model 의 입력으로 작용하는 initial token reprensetation 을 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">h_0 \in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span> 로 나타낸다. </p><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 에서 initial residual 을 통합함으로써, 각 token 의 final reprensetation 이 input layer 의 information 중 적어도 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 부분을 보존하도록 보장한다. </p><p>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>λ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 &lt; \lambda &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6835em;vertical-align:-0.0391em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span> 은 여러 레이어가 관여할 때 중요한 요소이다. </p><p>실질적으로, 저자는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 를 hyperparameter 로 취급하며, 0.2 와 같은 합리적인 값으로 설정함으로써, final token reprensetation 이 input token feature 의 상당 부분을 통합하여 layer 전반에 걸쳐 over-smoothness 를 줄이도록 한다. </p><p>Appendix A 에서 이론적 분석을 제시한다. 다음으로, 저자가 제안한 프레임워크인 SIBO 가 Adapter 와 LoRA, 두 가지 가장 인기 있는 PEFT 기술에 어떻게 적용될 수 있는지를 설명한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="adapter-sibo">Adapter-SIBO.<a href="#adapter-sibo" class="hash-link" aria-label="Direct link to Adapter-SIBO." title="Direct link to Adapter-SIBO.">​</a></h4><p>Adapter 에 initial residual 주입을 구현하는 것은 간단하다. </p><p><img loading="lazy" alt="Figure 3" src="/assets/images/image-315-f29974097668e998fea3f65fe8f882f9.png" width="762" height="494" class="img_ev3q"></p><p>Fig. 3(a) 에서와 같이, SIBO 는 Transformer layer 내의 adapter 의 입구 지점 (즉, 앞선 layer 의 output 과 adapter 의 input) 에 initial token reprensetation <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 를 hidden state <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span> 에 추가한다. </p><p>이 과정은 다음과 같은 기본적인 vector addition 연산을 통해 실행된다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>h</mi><mo>←</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mover accent="true"><mi>h</mi><mo>~</mo></mover><mo>+</mo><mi>f</mi><mo stretchy="false">(</mo><mover accent="true"><mi>h</mi><mo>~</mo></mover><msub><mi>W</mi><mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mrow><mi>u</mi><mi>p</mi></mrow></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>s.t. </mtext><mover accent="true"><mi>h</mi><mo>~</mo></mover><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy="false">)</mo><mi>h</mi><mo>+</mo><mi>λ</mi><msub><mi>h</mi><mn>0</mn></msub><mo separator="true">,</mo></mrow></mstyle></mtd></mtr></mtable></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \begin{aligned} h \leftarrow &amp;\tilde{h} + f(\tilde{h} W_{down})W_{up} \\ &amp;\text{s.t. } \tilde{h} = (1 - \lambda)h + \lambda h_0, \end{aligned} \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.1826em;vertical-align:-1.3413em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8413em"><span style="top:-3.8413em"><span class="pstrut" style="height:3.8413em"></span><span class="mord"><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8413em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span></span></span><span style="top:-2.3187em"><span class="pstrut" style="height:3em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3413em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8413em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">h</span></span><span style="top:-3.6134em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">~</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">h</span></span><span style="top:-3.6134em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">~</span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span><span style="top:-2.3187em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">s.t. </span></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">h</span></span><span style="top:-3.6134em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">~</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">λ</span><span class="mclose">)</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3413em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3413em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8413em"><span style="top:-3.8413em"><span class="pstrut" style="height:3.8413em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3413em"><span></span></span></span></span></span></span></span></span></div><p>여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>λ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 &lt; \lambda &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6835em;vertical-align:-0.0391em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span> 은 initial residual 의 강도를 조절하는 hyperparameter 이다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="lora-sibo">LoRA-SIBO.<a href="#lora-sibo" class="hash-link" aria-label="Direct link to LoRA-SIBO." title="Direct link to LoRA-SIBO.">​</a></h4><p>각 Transformer layer 의 각 LoRA module 에서, update <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">\Delta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span></span> 의 input 은 앞선 layer 의 hidden state <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span> 만을 사용하며, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">\Delta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span></span> 는 low-rank matrices 으로 근사된다. </p><p>LoRA-SIBO 에서는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">\Delta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span></span> 의 input 에 대한 수정을 도입하여, 이는 다음과 같이 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span> 와 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 의 조합이 된다:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>h</mi><mo>←</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>h</mi><mi>W</mi><mo>+</mo><mi>s</mi><mo>⋅</mo><mover accent="true"><mi>h</mi><mo>~</mo></mover><msub><mi>W</mi><mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi></mrow></msub><msub><mi>W</mi><mrow><mi>u</mi><mi>p</mi></mrow></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>s.t. </mtext><mover accent="true"><mi>h</mi><mo>~</mo></mover><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy="false">)</mo><mi>h</mi><mo>+</mo><mi>λ</mi><msub><mi>h</mi><mn>0</mn></msub><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation} \begin{aligned} h \leftarrow &amp;hW + s \cdot \tilde{h} W_{down}W_{up} \\ &amp;\text{s.t. } \tilde{h} = (1 - \lambda)h + \lambda h_0. \end{aligned} \end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.1826em;vertical-align:-1.3413em"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8413em"><span style="top:-3.8413em"><span class="pstrut" style="height:3.8413em"></span><span class="mord"><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8413em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span></span></span><span style="top:-2.3187em"><span class="pstrut" style="height:3em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3413em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8413em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:0.13889em">hW</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">h</span></span><span style="top:-3.6134em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">~</span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span><span style="top:-2.3187em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">s.t. </span></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">h</span></span><span style="top:-3.6134em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">~</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">λ</span><span class="mclose">)</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3413em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3413em"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8413em"><span style="top:-3.8413em"><span class="pstrut" style="height:3.8413em"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3413em"><span></span></span></span></span></span></span></span></span></div><h1>4. Experiments</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="41-datasets">4.1 Datasets<a href="#41-datasets" class="hash-link" aria-label="Direct link to 4.1 Datasets" title="Direct link to 4.1 Datasets">​</a></h2><p>저자의 연구는 다음과 같이 세 가지 구별된 문제 영역으로 분류된 22 benchmark dataset 에 대한 철저한 실증적 검사를 포함한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="arithmetic-reasoning">Arithmetic reasoning.<a href="#arithmetic-reasoning" class="hash-link" aria-label="Direct link to Arithmetic reasoning." title="Direct link to Arithmetic reasoning.">​</a></h4><ol><li>GSM8K: 숙련된 문제 작성자가 만든 언어적으로 다양한 초등학교 수학 단어 문제.</li><li>AQuA: 자연어 설명이 포함된 대수 단어 문제.</li><li>MAWPS: 다양한 복잡성을 가진 산술 및 대수 단어 문제.</li><li>SVAMP: 기존 문제 세트를 약간 수정하여 만든 4학년까지의 학생을 대상으로 한 산술 단어 문제.</li></ol><p>PEFT 기술은 supervised fine-tuning (SFT) 설정을 채택하며, 여기서 감독은 GSM8K, AQuA, MAWPS 의 training sets 를 포함하는 Math10K 에서 파생된다. pre-trained model 은 Math10K 의 예제를 통해 그들의 스타일과 특성을 복제하도록 fine-tuning 된다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="commonsense-reasoning">Commonsense reasoning.<a href="#commonsense-reasoning" class="hash-link" aria-label="Direct link to Commonsense reasoning." title="Direct link to Commonsense reasoning.">​</a></h4><ol><li>BoolQ: 자연스럽고 제한되지 않은 환경에서 유래한 Yes/No 질문.</li><li>PIQA: 두 가지 가능한 해답을 해결하기 위해 물리적 상식이 필요한 질문.</li><li>SIQA: 인간 행동의 사회적 함의를 이해하는 데 중점을 둔 질문.</li><li>HellaSwag: 주어진 맥락을 완성하기 위한 다양한 결말을 가진 상식적 자연어 추론 질문.</li><li>WinoGrande: 적절한 옵션을 선택하기 위해 상식적 추론이 필요한 이진 선택형 빈칸 채우기 과제.</li><li>ARC-c 및 ARC-e: 다중 선택 형식의 실제 초등학교 수준 과학 질문을 포함하는 ARC 데이터셋의 Challenge 및 Easy 세트.</li><li>OBQA: 다단계 추론, 추가적인 상식 및 일반 상식 지식, 그리고 포괄적인 텍스트 이해를 필요로 하는 질문.</li></ol><p>SFT 를 수행하기 위해, 저자는 상식적 추론 능력을 향상시키기 위해 맞춤화된 Commonsense170K 라는 training sets 를 사용한다. 이는 위의 여덟 상식적 추론 데이터셋의 training sets 를 포함한다. </p><p>산술 및 상식적 추론에 대한 데이터셋 요약은 Tab. 1 에 제시되어 있다.</p><p><img loading="lazy" alt="Table 1" src="/assets/images/image-316-97ab87eeea9e320d0850767b3fd5c40c.png" width="895" height="709" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="glue">GLUE.<a href="#glue" class="hash-link" aria-label="Direct link to GLUE." title="Direct link to GLUE.">​</a></h4><p>General Language Understanding Evaluation Benchmark 는 다양한 natural language understanding tasks 를 위한 8 corpus 를 포함한다: CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, 그리고 RTE.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="42-implementations">4.2 Implementations<a href="#42-implementations" class="hash-link" aria-label="Direct link to 4.2 Implementations" title="Direct link to 4.2 Implementations">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="arithmetic-and-commonsense-reasoning">Arithmetic and commonsense reasoning.<a href="#arithmetic-and-commonsense-reasoning" class="hash-link" aria-label="Direct link to Arithmetic and commonsense reasoning." title="Direct link to Arithmetic and commonsense reasoning.">​</a></h4><p>저자는 natural language generation tasks 를 위해 설계된 foundational models 로 LLaMA (7B, 13B) 와 GPT-J (6B) 를 사용한다. </p><p>저자는 baselines 로 Adapter 와 LoRA 를 선택하고, experimental setup 과 hyperparameters 에 대해서는 이전 연구 (Hu et al., 2023) 를 따랐다. </p><p>특히, Adapter 에 대해서는 bottleneck size 가 256 인 feed-forward layers 에 통합하였고; LoRA 에 대해서는 multi-head attention 과 feedforward layers 에 rank 32 로 통합하였다. </p><p>Adapter-SIBO 와 LoRA-SIBO 에 대해서는, initial residual 을 feed-forward layers 의 modules 에만 주입하고, vanilla Adapter 와 LoRA 에서 다른 설정을 유지하면서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>0.1</mn><mo separator="true">,</mo><mn>0.2</mn><mo separator="true">,</mo><mn>0.3</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\lambda \in \{0.1, 0.2, 0.3\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">0.1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.3</span><span class="mclose">}</span></span></span></span></span> 을 경험적으로 선택하였다. experimental setup 에 대한 더 자세한 내용은 Appendix D 에서 확인할 수 있다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="glue-1">GLUE.<a href="#glue-1" class="hash-link" aria-label="Direct link to GLUE." title="Direct link to GLUE.">​</a></h4><p>저자는 backbone 으로 BERT-large 를 사용한다. 최근에 더 큰 모델들이 GLUE benchmark 에서 BERT 를 능가했지만, BERT 는 그 효율성 때문에 계속 선호되고 있다. </p><p>더욱이, BERT 에 대한 full-model finetuning (FT) 은 비교적 용이하여, FT 와 PEFT 기술 간의 직접적인 비교가 가능하다. </p><p>Adapter 에 대해서는, multi-head attention 과 feed-forward layers 후에 adapter layers 를 추가하는 typical setting 을 적용하였고; LoRA 에 대해서는, 이전 연구를 따르며, weights <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">W_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> 와 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">W_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 에 rank 8 로 적용하였다. </p><p>Adapter-SIBO 에 대해서는, self-attention layers 후의 adapter modules 에 initial residual 을 주입하였고; LoRA-SIBO 에 대해서는, 모든 LoRA modules 에 initial residual 을 주입하였다. </p><p>두 SIBO 접근법 모두에 대해서는, 다른 hyperparameters 를 설정하기 위해 이전 연구를 따르면서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>0.1</mn><mo separator="true">,</mo><mn>0.2</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mn>0.7</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\lambda \in \{0.1, 0.2, \dots, 0.7\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">0.1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.7</span><span class="mclose">}</span></span></span></span></span> 을 경험적으로 선택하였다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="43-performance-comparison">4.3 Performance comparison<a href="#43-performance-comparison" class="hash-link" aria-label="Direct link to 4.3 Performance comparison" title="Direct link to 4.3 Performance comparison">​</a></h2><p>저자는 세 가지 문제 영역에서 baselines 와 비교하여 SIBO 의 성능을 평가한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="arithmetic-reasoning-1">Arithmetic reasoning.<a href="#arithmetic-reasoning-1" class="hash-link" aria-label="Direct link to Arithmetic reasoning." title="Direct link to Arithmetic reasoning.">​</a></h4><p>저자는 pre-trained LLaMA 와 GPT-J model 에 PEFT 를 Math10K dataset 을 사용하여 수행함으로써, SIBO 를 사용한 Adapter 와 LoRA 의 성능을 SIBO 없이 수행한 경우와 비교한다. 그 후, fine-tuned model 을 네 가지 수학 추론 데이터셋의 테스트 세트에 대해 테스트한다. </p><p>표준 참조로 GPT-3.5 모델과도 비교하는데, 이 모델은 zero-shot Chain of Thought (CoT)를 사용한다.</p><p>Tab. 2 에서 보고된 바와 같이, 175B-parameter GPT-3.5 model 은 다른 LLMs 보다 우수한 정확도를 보여준다.</p><p><img loading="lazy" alt="Table 2" src="/assets/images/image-317-df58a5c50d265e6a1cbc391839ba0769.png" width="1685" height="722" class="img_ev3q"></p><ul><li>그럼에도 불구하고, LLaMA (13B)에 LoRA-SIBO 를 적용한 경우, GPT-3.5 와 유사한 성능 수준에 도달했으며, 그 차이는 작다. </li><li>SIBO 없이 수행한 경우와 비교할 때, SIBO 는 LLaMA (13B) 에서 2.3%–2.7%, LLaMA (7B) 에서 1.1%–1.3% 의 유의미한 성능 향상을 달성했다. </li><li>7B model 에서의 작은 향상은 layer 수가 적은 small model 에서 over-smoothing 문제가 덜 두드러지기 때문으로, deeper model 에서 over-smoothing 문제를 해결할 필요성을 간접적으로 강조한다. </li><li>한편, SIBO 는 상대적으로 약한 GPT-J 에서 최대 15.7%의 향상을 달성하여, LLaMA (7B)와의 격차를 크게 줄였다.</li><li>더욱이, 저자는 SIBO 가 in-distribution 과 out-of-distribution 시나리오 모두에서 향상을 이루는 것을 관찰했다. </li><li>fine-tuning 에 사용된 데이터셋인 Math10K 는 GSM8K, AQuA, MAWPS 의 훈련 세트를 포함하며, SVAMP 는 제외한다. </li><li>SIBO 는 in-distribution 설정에서 처음 세 데이터셋에 대한 PEFT 방법의 성능을 향상시킬 뿐만 아니라, out-of-distribution 시나리오인 SVAMP 에도 향상을 확장하여, 저자의 방법론의 강건성과 일반화 가능성을 입증한다는 것을 관찰할 수 있다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="commonsense-reasoning-1">Commonsense reasoning.<a href="#commonsense-reasoning-1" class="hash-link" aria-label="Direct link to Commonsense reasoning." title="Direct link to Commonsense reasoning.">​</a></h4><p>다음으로, 저자는 상식적 추론 task 에서 SIBO 의 성능을 조사한다. Tab. 3 은 GPT-J (6B)에 적용된 PEFT 방법들의 비교 분석을 제시한다. </p><p><img loading="lazy" alt="Table 3" src="/assets/images/image-318-a2e4382cf3a2132efc4a4117408b3c3a.png" width="1685" height="364" class="img_ev3q"></p><p>SIBO 는 Adapter 와 LoRA 의 성능을 여덟 개의 다양한 corpus/task 에서 일관되게 그리고 유의미하게 향상시켰으며, 평균 향상 범위는 7.6% 에서 23.5% 사이이다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="glue-2">GLUE.<a href="#glue-2" class="hash-link" aria-label="Direct link to GLUE." title="Direct link to GLUE.">​</a></h4><p>마지막으로, 저자는 backbone model 로 BERT-large 를 사용하여 Tab. 4 에 GLUE 벤치마크 결과를 제시한다. </p><p><img loading="lazy" alt="Table 4" src="/assets/images/image-319-e76c9e700c337dc658496ceb59682a7e.png" width="1685" height="436" class="img_ev3q"></p><p>SIBO 는 여덟 개의 다양한 dataset/task 에서 vanilla PEFT 방법을 지속적으로 능가한다. </p><p>특히, Adapter-SIBO 의 효과는 full-model finetuning (FT)과도 맞먹는다. </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="43-performance-comparison-1">4.3 Performance comparison<a href="#43-performance-comparison-1" class="hash-link" aria-label="Direct link to 4.3 Performance comparison" title="Direct link to 4.3 Performance comparison">​</a></h2><p>저자는 세 가지 문제 영역에서 baselines 와 비교하여 SIBO 의 성능을 평가한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="arithmetic-reasoning-2">Arithmetic reasoning.<a href="#arithmetic-reasoning-2" class="hash-link" aria-label="Direct link to Arithmetic reasoning." title="Direct link to Arithmetic reasoning.">​</a></h4><p>저자는 pre-trained LLaMA 와 GPT-J 모델에 PEFT 를 Math10K dataset 을 사용하여 수행함으로써, SIBO 를 사용한 Adapter 와 LoRA 의 성능을 SIBO 없이 수행한 경우와 비교한다. </p><p>그 후, fine-tuned model  네 가지 수학 추론 데이터셋의 test set 에 대해 테스트한다. 표준 참조로 GPT-3.5 model (text-Davinci-003 버전)과도 비교하는데, 이 모델은 zero-shot Chain of Thought(CoT)를 사용한다.</p><ul><li>Tab. 2에서 보고된 바와 같이, 175B-parameter GPT-3.5 모델은 다른 LLMs 보다 우수한 정확도를 보여준다. </li><li>그럼에도 불구하고, LLaMA (13B)에 LoRA-SIBO 를 적용한 경우, GPT-3.5와 유사한 성능 수준에 도달했으며, 그 차이는 작다. </li><li>SIBO 없이 수행한 경우와 비교할 때, SIBO 는 LLaMA (13B)에서 2.3%–2.7%, LLaMA (7B)에서 1.1%–1.3%의 유의미한 성능 향상을 달성했다. </li><li>7B 모델에서의 작은 향상은 레이어 수가 적은 작은 모델에서 over-smoothing 문제가 덜 두드러지기 때문으로, deeper model 에서 over-smoothing 문제를 해결할 필요성을 간접적으로 강조한다. </li><li>한편, SIBO 는 상대적으로 약한 GPT-J 에서 최대 15.7%의 향상을 달성하여, LLaMA (7B)와의 격차를 크게 줄였다.</li></ul><hr><ul><li>더욱이, 저자는 SIBO 가 in-distribution 과 out-of-distribution 시나리오 모두에서 향상을 이루는 것을 관찰했다. fine-tuning 에 사용된 데이터셋인 Math10K 는 GSM8K, AQuA, MAWPS 의 훈련 세트를 포함하며, SVAMP 는 제외한다. </li><li>SIBO 는 in-distribution 설정에서 처음 세 데이터셋에 대한 PEFT 방법의 성능을 향상시킬 뿐만 아니라, out-of-distribution 시나리오인 SVAMP 에도 향상을 확장하여, 저자의 방법론의 강건성과 일반화 가능성을 입증한다는 것을 관찰할 수 있다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="commonsense-reasoning-2">Commonsense reasoning.<a href="#commonsense-reasoning-2" class="hash-link" aria-label="Direct link to Commonsense reasoning." title="Direct link to Commonsense reasoning.">​</a></h4><p>다음으로, 저자는 상식적 추론 task 에서 SIBO 의 성능을 조사한다. </p><p>Tab. 3은 GPT-J (6B)에 적용된 PEFT 방법들의 비교 분석을 제시한다. </p><p>SIBO 는 Adapter 와 LoRA 의 성능을 여덟 개의 다양한 corpus/task 에서 일관되게 그리고 유의미하게 향상시켰으며, 평균 향상 범위는 7.6% 에서 23.5% 사이이다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="glue-3">GLUE.<a href="#glue-3" class="hash-link" aria-label="Direct link to GLUE." title="Direct link to GLUE.">​</a></h4><p>마지막으로, backbone model 로 BERT-large 를 사용하여 Tab. 4 에 GLUE 벤치마크 결과를 제시한다. </p><p>SIBO 는 여덟 개의 다양한 dataset/task 에서 vanilla PEFT 방법을 지속적으로 능가한다. </p><p>특히, Adapter-SIBO 의 효과는 full-model finetuning (FT)과도 맞먹는다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="44-analyses">4.4 Analyses<a href="#44-analyses" class="hash-link" aria-label="Direct link to 4.4 Analyses" title="Direct link to 4.4 Analyses">​</a></h2><p>이 섹션에서는 먼저 Adapter 와 LoRA 를 위한 initial residual 의 최적 배치를 분석한다. </p><p>그 다음, 저자가 도입한 유일한 hyperparameter 인 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 의 영향을 검토한다. </p><p>이어서, SIBO 로 인한 overhead 를 탐구한다.</p><p>마지막으로, initial residual 이 over-smoothing 문제를 완화하는 역할을 시각화하고, 사례 연구를 제시한다. </p><p>이 연구들에서는 BERT-large 를 backbone 으로 사용하여 CoLA 와 STS-B dataset 을 활용한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="placement">Placement.<a href="#placement" class="hash-link" aria-label="Direct link to Placement." title="Direct link to Placement.">​</a></h4><p>이 섹션에서는 PEFT module 을 위한 initial residual 의 배치를 조사한다. </p><p>Adapter 의 경우, 각 Transformer layer 는 attention layer (ATT)와 feed-forward layer (FFN) 후에 각각 two adapter modules 를 사용한다. </p><p>initial residual 을 주입하기에 더 적합한 위치는 어디일까? </p><p><img loading="lazy" alt="Table 5" src="/assets/images/image-320-2f65ba25d0cd4188a81b5789af951b9d.png" width="1042" height="378" class="img_ev3q"></p><ul><li>Tab. 5 에 나타난 바와 같이, initial residual 을 ATT 위치에만 주입하는 경우 FFN 위치에 주입하는 경우와 거의 동일한 성능을 달성한다. </li><li>그러나 ATT 와 FFN 모두에 initial residual 을 주입하면 성능이 약간 저하된다. </li><li>이는 Transformer layer 당 한 번의 initial residual 주입이 충분하며, 과도한 주입은 노이즈를 유발할 수 있음을 시사한다.</li></ul><p>LoRA 의 경우, 각 module 은 두 가지 유형의 파라미터로 구성된다: frozen pre-trained weights 와 learnable low-rank matrices. </p><p>저자는 initial residual 을 두 가지 모두에 주입해야 하는지, 아니면 learnable low-rank matrices 에만 주입해야 하는지를 탐구했다. </p><p>Tab. 6 은 initial residual 을 learnable low-rank matrices 에만 주입하는 것이 더 나은 결과를 가져옴을 보여준다. </p><p><img loading="lazy" alt="Table 6" src="/assets/images/image-321-010b16396d487b5f091b4964872fbf88.png" width="1181" height="326" class="img_ev3q"></p><p>가능한 이유는 frozen weights 가 layer 의 hidden state 와 initial residual 과 잘 통합되지 않기 때문이다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="impact-of-lambda">Impact of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span>.<a href="#impact-of-lambda" class="hash-link" aria-label="Direct link to impact-of-lambda" title="Direct link to impact-of-lambda">​</a></h4><p>SIBO 는 hidden state 와 initial residual 간의 trade-off 를 균형 있게 조절하는 하나의 새로운 hyperparameter 인 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 만 도입한다. </p><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 의 선택은 final token representation 에서 input features 의 최소 부분을 보존함으로써 over-smoothing 문제를 직접적으로 완화한다. 따라서 저자는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 의 optimal value 를 0.1 에서 0.7 사이로 변동시키며 조사했다. </p><p><img loading="lazy" alt="Figure 4" src="/assets/images/image-322-800ddbdad934152494550475f765f031.png" width="1096" height="529" class="img_ev3q"></p><ul><li>Fig. 4 에 나타난 바와 같이, Adapter 의 경우 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 값이 낮은 0.2 가 일반적으로 더 효과적이다. </li><li>여러 개의 stacked layers 에 걸쳐 각 token 의 final representation 이 input layer 의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 만큼의 부분을 유지하도록 보장하는 것이 중요하지만, 이 비율이 너무 크면 Adapter 의 학습 능력이 저해될 수 있다. </li><li>LoRA 의 경우, hidden state 가 pre-trained weights 와 low-rank matrices 모두에 입력되므로 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 비율의 효과가 자연스럽게 &quot;절반으로 줄어든다&quot;. </li><li>다시 말해, LoRA 의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 값 0.6은 Adapter 의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 값 0.3과 대략적으로 동일하다.</li><li>따라서 LoRA 에서의 최적 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 값은 Adapter 보다 크며, 약 0.6–0.7 근처에서 발생한다.</li></ul><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 를 선택하는 노력에도 불구하고, 저자의 접근법은 실용적이고 자원 절약적이다. BERT 와 같은 small model 의 경우, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 의 다양한 값을 광범위하게 튜닝하는 것이 가능하다. </p><p>반면, LLaMA (13B)와 같은 larger model 의 경우, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>0.1</mn><mo separator="true">,</mo><mn>0.2</mn><mo separator="true">,</mo><mn>0.3</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\lambda \in \{0.1, 0.2, 0.3\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord">0.1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.3</span><span class="mclose">}</span></span></span></span></span> 의 더 작은 범위를 고려하여 튜닝했으며, 이는 Tab. 7 과 Tab. 8 에 나타난 바와 같이 다양한 task 에서 여전히 유의미한 향상을 가져왔다. </p><p><img loading="lazy" alt="Table 7" src="/assets/images/image-323-accbfba7ac00a539bc428e30b0dc829d.png" width="1146" height="470" class="img_ev3q"></p><p><img loading="lazy" alt="Table 8" src="/assets/images/image-324-21955fec4b50293154e1754893e625c5.png" width="1153" height="468" class="img_ev3q"></p><p>특히, 많은 non-optimal value <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 들도 여전히 유의미한 성능 향상을 가져올 수 있어, 광범위한 hyperparameter tuning 없이도 SIBO 의 효능과 강건성을 강조한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="complexity">Complexity.<a href="#complexity" class="hash-link" aria-label="Direct link to Complexity." title="Direct link to Complexity.">​</a></h4><p>SIBO 는 매우 효율적이며, extra parameter 를 도입하지 않고 각 Transformer layer 에서 initial residual vector 와의 합산 연산만 추가한다. </p><p>그 효율성을 입증하기 위해, 저자는 fine-tuning 및 testing 시 floating point operations (FLOPs)와 wall-clock time 을 비교했다. </p><p><img loading="lazy" alt="Table 9" src="/assets/images/image-325-fa7eefd85e03bd226811c3ebd7922ea1.png" width="1206" height="522" class="img_ev3q"></p><p>Tab. 9에 나타난 바와 같이, initial residual vectors 를 합산하는 overhead 는 FLOPs 를 거의 증가시키지 않는다. </p><p>또한, wall-clock time 은 initial residual 을 포함하지 않는 vanilla PEFT 방법과 거의 동일하여, SIBO 의 단순성과 효율성을 강조한다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="visualizations-of-over-smoothing">Visualizations of over-smoothing.<a href="#visualizations-of-over-smoothing" class="hash-link" aria-label="Direct link to Visualizations of over-smoothing." title="Direct link to Visualizations of over-smoothing.">​</a></h4><p>본 연구의 주장은 initial residual 을 사용하여 over-smoothing 을 완화하는 것이다. </p><p>SIBO 가 over-smoothing 을 효과적으로 줄이는지 확인하기 위해, 저자는 SIBO 와 함께 또는 없이 PEFT 방법을 적용한 후 language model 의 last 5 layers 에서 정의된 Eq. 3 의 token-wise cosine similarity 를 비교하는 실험을 수행했다. </p><p><img loading="lazy" alt="Figure 5" src="/assets/images/image-326-0392359a53ec45393b663a8c71b01306.png" width="1248" height="741" class="img_ev3q"></p><p><img loading="lazy" alt="Figure 6" src="/assets/images/image-327-498acb4e280c0334a889a26abc867539.png" width="953" height="734" class="img_ev3q"></p><p>Figs. 5와 6 에서 관찰된 바와 같이, SIBO 가 Adapter 와 LoRA 와 함께 적용될 때 token-wise similarity 가 일반적으로 감소한다. </p><p>본질적으로, SIBO 는 oversmoothing 의 정도를 줄여 better task performance 를 이끌어냈다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="qualitative-case-study">Qualitative case study.<a href="#qualitative-case-study" class="hash-link" aria-label="Direct link to Qualitative case study." title="Direct link to Qualitative case study.">​</a></h4><p>마지막으로, 저자는 사례 연구에서 정량적 발견을 정성적 분석으로 보완한다. </p><p>Tab. 10 은 SVAMP 에서 샘플링된 질문을 제시하며, ChatGPT 3.5 와 다양한 PEFT 방법을 사용한 LLaMA (13B)의 응답을 보여준다.</p><p><img loading="lazy" alt="Table 10" src="/assets/images/image-328-735eb01722238b7c59726d534e3f7a40.png" width="1445" height="1093" class="img_ev3q"></p><ul><li>ChatGPT 는 일반적으로 강건하지만, 이번 경우에는 올바르지 않은 답변을 제공했다. </li><li>유사하게, Adapter 와 LoRA 로 생성된 답변도 주로 <code>cracker</code> 와 <code>snack</code> 의 관련 개념을 초기 단계에서 혼동하여 오류가 발견되었다. </li><li>반면, LoRA-SIBO 는 reasoning 의 초기 단계에서 두 개념을 올바르게 구분함으로써 향상을 보였다. </li><li>Adapter-SIBO 는 두 개념에 대한 명확성을 유지하여 모든 방법보다 우수한 성능을 보였으며, 올바른 답변을 이끌어냈다. </li><li>이러한 향상은 over-smoothness 를 해결함으로써 단어 구별 능력을 향상시키고, <code>cracker</code> 와 <code>snack</code> 과 같이 밀접하게 관련된 개념 간의 명확한 구분을 제공하여 전반적인 성능을 향상시키는 이점을 강조한다. </li><li>더욱이, Adapter-SIBO 와 LoRA-SIBO 의 응답은 vanilla Adapter 와 LoRA 의 응답보다 더 상세하고 높은 품질을 보인다.</li></ul><h1>5. Related work</h1><p>저자는 pre-trained language model 의 parameter-efficient fine-tuning (PEFT)에 대한 논의에 집중한다. 현재 세 가지 주요 범주의 방법이 존재하는데, 이는 prompt-based learning, adapters, reparametrization methods 를 포함한다. 그러나 기존의 어떤 접근법도 over-smoothing 문제를 완화하도록 설계되지 않았다.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-based-learning">Prompt-based learning.<a href="#prompt-based-learning" class="hash-link" aria-label="Direct link to Prompt-based learning." title="Direct link to Prompt-based learning.">​</a></h4><p>Prompt-based learning 은 이상적인 discrete (hard) prompt 의 식별을 continuous (soft) prompt 의 최적화로 확장한다. </p><ul><li>Lester et al. (2021)은 prompt tuning 의 개념을 도입했는데, 이는 trainable tensor 를 input embeddings 의 prefix 로 부착하는 것을 포함한다. </li><li>유사하게, Li 와 Liang (2021)은 all layers 에 걸쳐 soft prompts 를 hidden states 에 통합하는 prefix tuning 이라는 독립적인 방법을 개발했다. </li><li>또 다른 기법인 Intrinsic Prompt Tuning 은 soft prompt 를 압축 및 해제하기 위해 autoencoder 를 활용하지만, 이는 sequence length 를 제한하는 대가를 치른다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="adapters-1">Adapters.<a href="#adapters-1" class="hash-link" aria-label="Direct link to Adapters." title="Direct link to Adapters.">​</a></h4><p>Adapters 는 parallel adapters 와 serial adapters 의 두 가지 형태로 존재한다. </p><ul><li>Parallel adapters (He et al., 2021)는 core model 의 다양한 layer 옆에 agdditional learnable module 을 통합한다. </li><li>다른 전략인 Ladder Side-Tuning (Sung et al., 2022)은 ladder 와 유사한 간소화된 auxiliary network 를 개발하는 데 중점을 둔다. </li><li>이 auxiliary network 는 direct shortcut pathways, 즉 ladder 를 통해 main network 로부터 intermediate activations 을 수신한다. </li><li>반대로, serial adapters 는 특정 layer 사이에 이러한 module 을 순차적으로 삽입한다. </li><li>Houlsby et al. (2019)은 Transformer model 의 attention 과 feed-forward layers 후에 fully connected networks 을 추가했다. </li><li>Pfeiffer et al. (2020)은 self-attention layer 후에 adapter 를 삽입하는 것이 transformer block 당 two adapters 를 사용하는 것과 유사한 성능을 낼 수 있음을 입증했으며, </li><li>AdaMix Wang et al. (2022)은 mixture-of-experts 접근법에서 여러 serial adapters 를 사용한다. </li><li>Compacter (Karimi Mahabadi et al., 2021)는 Kronecker product, low-rank matrices, layer 간 parameter sharing 을 활용하여 adapter weight 생성을 통해 계산 복잡성을 줄이면서도 성능을 유지한다.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="reparametrization-based-methods">Reparametrization-based methods.<a href="#reparametrization-based-methods" class="hash-link" aria-label="Direct link to Reparametrization-based methods." title="Direct link to Reparametrization-based methods.">​</a></h4><p>Reparametrization-based methods 는 low-rank approximation 을 통해 network weights 를 수정하도록 설계되었다. </p><p>이 기술은 high-dimensional matrices 의 reprensetation 능력을 저해하지 않으면서 trainable parameters 의 수를 효과적으로 최소화한다. </p><ul><li>Intrinsic SAID 의 연구는 low-rank framework 내에서 fine-tuning 의 필수 차원성을 조사한다. 반면, LoRA 는 low-rank decomposition 을 통해 pre-trained weight matrix 에 대한 업데이트를 모델링한다. </li><li>이에 기반하여, Edalati et al. (2022)은 그들의 방법에 Kronecker product 를 통합하여 LoRA 의 matrix decomposition 기능을 향상시켰다.</li></ul><h1>6. Conclusion</h1><p>저자는 large pre-trained language models 를 위한 parameter-efficient fine-tuning (PEFT) 기술을 향상시키기 위한 새로운 프레임워크인 SIBO, 즉 _SI_mple _BO_oster 를 제시한다. </p><p>저자의 핵심 아이디어는 over-smoothing 문제를 완화하는 데 중점을 두고 있으며, 이는 pre-trained model 의 특정 위치에 다양한 PEFT module 에 initial residual 을 주입함으로써 달성된다. </p><p>SIBO 는 간단하고 Adapter 와 LoRA 를 포함한 다양한 state-of-the-art PEFT 방법에 쉽게 확장 가능하다. </p><p>세 가지 문제 영역에 걸친 22 benchmark dataset 에 대한 광범위한 실험은 SIBO 가 over-smoothing 을 효과적으로 완화하고 기존 PEFT 기술의 성능을 크게 향상시킨다는 것을 입증한다.</p><h1>7. Limitations</h1><p>저자의 방법은 간단하고 효과적이지만, 하나의 한계가 있다: hyperparameter <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 의 최적 값을 선택하는 데 시간과 계산 자원이 필요하다. </p><p>이 비용은 특히 medium-sized models 에 대해 새로운 hyperparameter 하나만 도입했기 때문에 관리 가능하다. 그러나 매우 큰 모델의 경우, 이는 금지될 수 있다. </p><p>실행 가능한 해결책은 이 hyperparameter 를 continuous learnable parameters 로 변환하여, 모델이 initial residual 의 최적 가중치를 자율적으로 결정할 수 있도록 하는 것이다.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/sibo">SIBO</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/lo-ra">LoRA</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/peft">PEFT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/low-rank">Low-Rank</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/over-smoothing">over-smoothing</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/initial-residual">initial residual</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/NLP/PEFT/Composition/2024-02-SIBO.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/NLP/PEFT/Composition/ResLoRA"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">ResLoRA: Identity Residual Mapping in Low-Rank Adaption</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/NLP/PEFT/Composition/ALoRA"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#31-over-smoothing-in-peft" class="table-of-contents__link toc-highlight">3.1 Over-smoothing in PEFT</a></li><li><a href="#32-initial-residual-integration" class="table-of-contents__link toc-highlight">3.2 Initial residual integration</a></li><li><a href="#41-datasets" class="table-of-contents__link toc-highlight">4.1 Datasets</a></li><li><a href="#42-implementations" class="table-of-contents__link toc-highlight">4.2 Implementations</a></li><li><a href="#43-performance-comparison" class="table-of-contents__link toc-highlight">4.3 Performance comparison</a></li><li><a href="#43-performance-comparison-1" class="table-of-contents__link toc-highlight">4.3 Performance comparison</a></li><li><a href="#44-analyses" class="table-of-contents__link toc-highlight">4.4 Analyses</a></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.fba06b0c.js"></script>
<script src="/assets/js/main.97da4e69.js"></script>
</body>
</html>