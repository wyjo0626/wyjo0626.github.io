<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Paper/NLP/Generalization/2022-02-NoisyTune">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">NoisyTune: A Little Noise Can Help You Finetune Pretrained Language Models Better | WYJLab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wyjo0626.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wyjo0626.github.io/docs/Paper/NLP/Generalization/NoisyTune"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="NoisyTune: A Little Noise Can Help You Finetune Pretrained Language Models Better | WYJLab"><meta data-rh="true" name="description" content="논문 및 이미지 출처 :"><meta data-rh="true" property="og:description" content="논문 및 이미지 출처 :"><link data-rh="true" rel="icon" href="/img/WYJLab.ico"><link data-rh="true" rel="canonical" href="https://wyjo0626.github.io/docs/Paper/NLP/Generalization/NoisyTune"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/Generalization/NoisyTune" hreflang="en"><link data-rh="true" rel="alternate" href="https://wyjo0626.github.io/docs/Paper/NLP/Generalization/NoisyTune" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="WYJLab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="WYJLab Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.9ed678b7.css">
<link rel="preload" href="/assets/js/runtime~main.dc82af9c.js" as="script">
<link rel="preload" href="/assets/js/main.07c26eea.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/WYJLab.svg" alt="WYJLab Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">WYJLab</b></a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Tutorial Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---basics">Tutorial - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/tutorial---extras">Tutorial - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorial - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Paper</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Computer Vision/Adversarial Attack/AR">Computer Vision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Machine Learning/Regularization/Dropout/Dropout">Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Multi-Modal/PEFT/Composition/Moka">Multi-Modal</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">NLP</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Analysis/Contextualized Representation">Analysis</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Attacking/universal-adversarial-prompt">Attacking</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Augmentation/PromptDA">Augmentation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Paper/NLP/Generalization/NoisyTune">Generalization</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Paper/NLP/Generalization/NoisyTune">NoisyTune: A Little Noise Can Help You Finetune Pretrained Language Models Better</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/Generalization/NEFTune">NEFTune: Noisy Embeddings Improve Instruction FineTuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Paper/NLP/Generalization/SymNoise">SymNoise: Advancing Language Model Fine-tuning with Symmetric Noise</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Model/Transformer">Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Multi-Task/Flan-T5">Multi-Task</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/PEFT/Composition/LoRA">PEFT</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Engineering/CoT/Chain-of-Thought">Prompt Engineering</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Prompt Tuning/PTR">Prompt Tuning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Reinforcement Learning/Reflexion">Reinforcement Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/NLP/Text Generation/InstructGPT">Text Generation</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Survey/Prompting">Survey</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/Paper/Vision-Language/CLIP/Few-shot/Composition/CLIP-LoRA">Vision-Language</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Programming/Algorithm/">Programming</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Paper</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">NLP</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Generalization</span><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">NoisyTune: A Little Noise Can Help You Finetune Pretrained Language Models Better</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>NoisyTune: A Little Noise Can Help You Finetune Pretrained Language Models Better</h1></header><p>논문 및 이미지 출처 : <a href="https://arxiv.org/pdf/2202.12024" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2202.12024</a></p><h1>Abstract</h1><p>Pretrained language models (PLMs) 의 효과적인 finetuning 은 downstream task 의 성공에 매우 중요하다. 그러나 PLM 은 pretraining task 와 data 에 overfitting 될 위험이 있으며, 이는 보통 target downstream task 와 간극을 가진다. 이러한 간극은 기존의 PLM finetuning 방법으로는 극복하기 어렵고 최적 이하의 성능으로 이어질 수 있다. </p><p>본 논문에서는 PLM 을 downstream task 에 더 잘 finetuning 할 수 있도록 finetuning 전에 PLM 의 parameter 에 노이즈를 추가하는 간단하지만 효과적인 방법인 <strong><em>NoisyTune</em></strong> 을 제안한다. </p><ul><li>구체적으로, 저자는 matrix-wise perturbation 방법을 제안하며, 이는 parameter matrix 별 표준편차에 기반해 서로 다른 uniform noise 를 추가한다. </li><li>이를 통해 PLM 내 다양한 유형의 parameter 가 가지는 상이한 특성을 고려할 수 있다. </li></ul><p>GLUE English benchmark 와 XTREME multilingual benchmark 모두에서 광범위한 실험을 수행한 결과, <em>NoisyTune</em> 은 다양한 PLM 과 downstream task 에서 일관되게 finetuning 성능을 향상시킬 수 있음을 보여준다.</p><h1>1 Introduction</h1><p>최근 몇 년 동안 pretrained language models (PLMs) 은 NLP 에서 큰 성공을 거두었다. BERT, RoBERTa, UniLM 과 같은 많은 PLM 은 large-scale unlabeled corpus 로부터 self-supervised 방식으로 pretraining 되어, reading comprehension, machine translation, text classification, dialog, recommendation 과 같은 다양한 downstream task 에서 finetuning 을 통해 성능을 크게 향상시켰다.</p><p>PLM 을 효과적으로 finetuning 하여 downstream task 를 더 잘 지원하는 것은 중요한 연구 문제이다. 기존의 많은 NLP 방법들은 일반적으로 downstream task 의 labeled data 로 PLM 을 직접 finetuning 한다. 소수의 연구만이 더 효과적이고 robust PLM finetuning 방법을 탐구하였다. </p><ul><li>예를 들어, Chen et al 은 RecAdam 을 제안하였는데, 이는 finetuned model 과 pretrained model 간의 L2 distance 를 최소화하는 penalty term 을 추가하며, penalty 강도는 finetuning 동안 시간에 따라 변한다. </li><li>Lee et al 은 Mixout 을 제안하였는데, 이는 finetuned model 의 일부 parameter 를 PLM 의 original weight 로 무작위 교체하는 방법이다. </li><li>이러한 PLM finetuning 방법들은 주로 downstream task 의 제한된 labeled data 에 대한 overfitting 을 방지하는 데 초점을 맞추었다.</li></ul><p>그러나 downstream task data 의 overfitting 외에도 거의 연구되지 않은 또 다른 문제는, PLM 이 보통 pretraining task 와 data 에 overfitting 된다는 점이다. 이는 downstream task 및 data 와 큰 간극을 가질 수 있으며, 기존의 PLM finetuning 방법으로는 이러한 간극을 극복하기 어렵다. 이는 특히 downstream task 의 labeled data 가 부족할 때 최적 이하의 성능으로 이어질 수 있다.</p><p><img loading="lazy" alt="Figure 1" src="/assets/images/image-21-e5664ea490d6e56786ce640ff8d2e637.png" width="1742" height="1220" class="img_ev3q"></p><p>이 문제를 다루기 위해, 본 논문에서는 downstream task 에 대해 PLM 을 더 잘 finetuning 할 수 있도록 돕는 간단하면서도 효과적인 방법인 <strong><em>NoisyTune</em></strong> 을 제안한다. </p><ul><li>기존의 finetuning 패러다임 (Fig. 1 (a)) 은 downstream task data 에 대해 PLM 을 직접 finetuning 하는 반면, <em>NoisyTune</em> 의 핵심 아이디어는 finetuning 전에 PLM 의 parameter 를 작은 양의 noise 로 perturbation 하는 것이다 (Fig. 1 (b)). <ul><li>이는 PLM 이 pretraining 단계의 task 와 data 에 overfitting 되는 것을 방지하고, pretraining 과 downstream task 사이의 간극을 줄이는 데 도움이 된다.</li></ul></li><li>또한 PLM 은 다양한 특성을 가진 여러 유형의 parameter 를 포함하고 있으므로, <em>NoisyTune</em> 에서는 각 parameter matrix 의 표준편차에 따라 서로 다른 강도의 uniform noise 를 추가하는 matrix-wise perturbation 방법을 사용하여 더 나은 적응을 도모한다. </li></ul><p>저자는 영어 언어 이해를 위한 GLUE benchmark 와 다국어 언어 이해를 위한 XTREME benchmark 라는 두 가지 널리 사용되는 NLP benchmark 에 대해 광범위한 실험을 수행하였다. 그 결과, <em>NoisyTune</em> 은 다양한 PLM 과 여러 downstream NLP task 의 finetuning 을 일관되게 강화하여 더 나은 성능을 달성할 수 있음을 보였다.</p><p>추가적으로, 결과는 <em>NoisyTune</em> 이 기존의 다양한 PLM finetuning 방법과 쉽게 결합할 수 있으며, 이들의 성능을 더욱 향상시킬 수 있음을 보여준다.</p><h1>2 <em>NoisyTune</em></h1><p><em>NoisyTune</em> 의 목표는 PLM 을 downstream task 에 대해 더 효과적으로 finetuning 하는 것이다. <em>NoisyTune</em> 의 동기는 PLM 이 일부 unlabeled corpus 에 대해 self-supervision task 로 pretraining 되어 있으며, 이러한 pretraining data 와 task 에 overfitting 될 수 있다는 점에 있다. 이는 보통 downstream task 와 data 와 간극을 가지며, 특히 downstream task 의 labeled data 가 제한적인 경우 PLM 이 효과적으로 downstream task 에 적응하기 어렵게 만든다.</p><p>이 문제에서 착안하여, dueling bandits mechanism 이 exploration 을 위해 model 에 randomness 를 추가하는 것처럼, 저자는 downstream task 에 대해 finetuning 하기 전에 PLM 의 parameter 에 일부 noise 를 추가하여 parameter space 에서 일종의 &quot;exploration&quot; 을 수행하고 pretraining task 와 data 에 대한 overfitting risk 를 줄이는 방법을 제안한다 (Fig. 1).</p><p>PLM 은 보통 query, key, value, feed-forward network matrix 와 같은 다양한 종류의 parameter matrix 를 가진다. PLM 의 서로 다른 parameter matrix 는 일반적으로 서로 다른 특성과 scale 을 가진다. 예를 들어, 일부 연구에서는 Transformer 에서 self-attention parameter 와 feed-forward network parameter 가 rank 와 density 와 같은 매우 다른 속성을 가진다는 것을 발견하였다. 따라서 PLM 의 모든 parameter matrix 에 동일한 noise 를 추가하는 것은 model utility 를 유지하는 데 최적이 아닐 수 있다.</p><p>이 문제를 해결하기 위해, 저자는 각 parameter matrix 의 variance 에 따라 서로 다른 강도의 noise 를 추가하는 matrix-wise perturbation 방법을 제안한다. PLM 내의 parameter matrix (or scalar/vector) 를 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>W</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>W</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>W</mi><mi>N</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[W_1, W_2, ..., W_N]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> 이라 하자. 여기서 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span></span></span> 은 parameter matrix 의 개수이다. Parameter matrix <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">W_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 의 perturbation 버전 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>W</mi><mo>~</mo></mover><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{W}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0702em;vertical-align:-0.15em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span><span style="top:-3.6023em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 는 다음과 같이 계산된다.</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msub><mover accent="true"><mi>W</mi><mo>~</mo></mover><mi>i</mi></msub><mo>=</mo><msub><mi>W</mi><mi>i</mi></msub><mo>+</mo><mi>U</mi><mrow><mo fence="true">(</mo><mo>−</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo separator="true">,</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo fence="true">)</mo></mrow><mo>∗</mo><mtext>std</mtext><mo stretchy="false">(</mo><msub><mi>W</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(1)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\tilde{W}_i = W_i + U\left(-\frac{\lambda}{2}, \frac{\lambda}{2}\right) \ast \text{std}(W_i), \tag{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0702em;vertical-align:-0.15em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span><span style="top:-3.6023em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em"></span><span class="mord mathnormal" style="margin-right:0.10903em">U</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">(</span></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">std</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span></span><span class="tag"><span class="strut" style="height:2.4em;vertical-align:-0.95em"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></div><ul><li>여기서 std 는 standard deviation 을 의미한다. </li><li>function <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">U(a, b)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10903em">U</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span></span></span> 는 구간 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a, b]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">b</span><span class="mclose">]</span></span></span></span></span> 에서 uniform distribution noise 를 나타내며, </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 는 relative noise intensity 를 제어하는 hyperparameter 이다. </li><li>따라서 <em>NoisyTune</em> 은 variance 가 큰 parameter 일수록 stronger noise 가 추가된다.</li></ul><p>또한 일부 PLM 에는 RoBERTa 의 token type embedding 과 같이 constant matrix 가 존재한다. 이들은 standard deviation 이 0 이므로 perturbation 되지 않으며, 이를 통해 이러한 constant matrix 가 noise 로 인해 우발적으로 활성화되는 것을 방지할 수 있다.</p><p><em>NoisyTune</em> 은 간단하고 범용적인 plug-and-play 기법으로, 어떤 PLM 의 어떤 task finetuning 에도 적용될 수 있다. 단순히 finetuning 전에 다음과 같은 PyTorch-style 코드를 삽입하면 된다.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> name</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> para </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">named_parameters</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">state_dict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">name</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+=</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">rand</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">para</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">size</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.5</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> noise_lambda </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">std</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">para</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h1>3 Experiments</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="31-datasets-and-experimental-settings">3.1 Datasets and Experimental Settings<a href="#31-datasets-and-experimental-settings" class="hash-link" aria-label="Direct link to 3.1 Datasets and Experimental Settings" title="Direct link to 3.1 Datasets and Experimental Settings">​</a></h2><p>저자는 PLM 평가를 위해 널리 사용되는 두 개의 benchmark 에 대해 광범위한 실험을 수행하였다. </p><ul><li>첫 번째는 GLUE 로, 이는 English language understanding benchmark 이며, natural language inference, sentiment analysis, sentence similarity evaluation 과 같은 다양한 task 를 포함한다. </li><li>두 번째는 XTREME 으로, multilingual language understanding benchmark 이다. 이는 40 개 언어를 다루며 sentence classification, structured prediction, sentence retrieval, question answering 의 네 가지 task 그룹을 포함한다.</li></ul><p>이 benchmark 들에 대한 세부 사항은 원 논문과 공식 웹사이트를 참조할 수 있다. GLUE 의 test label 은 공개되지 않았으므로, 저자는 기존 연구를 따라 GLUE 의 dev set 결과를 보고하였다. XTREME 의 경우 test set 에 대해 평가하였다. Hyperparameter <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 는 GLUE 에서는 0.15, XTREME 에서는 0.1 로 설정하였다. Hyperparameter 탐색 범위는 Tab. 1 에 제시된다.</p><p><img loading="lazy" alt="Table 1" src="/assets/images/image-22-6e3eeb64ca1453609378d31311f8cb65.png" width="1742" height="786" class="img_ev3q"></p><p>Sentence retrieval task 의 경우, 기존 연구를 따라 XNLI dataset 에서 model 을 먼저 학습시키고, 가장 좋은 성능을 보이는 hidden layer 가 생성한 token representation 의 평균을 사용하였다. 서로 다른 언어 간 token embedding alignment 를 해치지 않기 위해, multilingual PLM 의 token embedding 에는 noise 를 추가하지 않았다. 실험은 서로 다른 random seed 로 5 회 반복하였으며 평균 점수를 보고하였다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="32-performance-evaluation">3.2 Performance Evaluation<a href="#32-performance-evaluation" class="hash-link" aria-label="Direct link to 3.2 Performance Evaluation" title="Direct link to 3.2 Performance Evaluation">​</a></h2><p>GLUE benchmark 에서는 BERT, XLNET, RoBERTa, ELECTRA 의 base version 을 직접 finetuning 한 결과와, <em>NoisyTune</em> 을 적용한 후 finetuning 한 결과를 비교하였다. XTREME benchmark 에서는 XLM-R 의 base 및 large version 을 직접 finetuning 한 결과와, <em>NoisyTune</em> 을 적용한 변형된 결과를 비교하였다. 두 benchmark 의 결과는 각각 Tab. 2 와 Tab. 3 에 제시된다. XTREME dataset 에 대해서는 두 가지 유형의 결과를 보고하였다. 첫 번째는 English 에서 다른 언어로의 zero-shot cross-lingual transfer 이며, 두 번째는 English 와 번역된 data 모두에서 학습된 model 결과이다.</p><p><img loading="lazy" alt="Table 2" src="/assets/images/image-23-68f70a1472c6383beb9de20bacdf415b.png" width="3523" height="1189" class="img_ev3q"></p><p><img loading="lazy" alt="Table 3" src="/assets/images/image-24-2bbd1dfc3a5ab8360b3580674960c6b8.png" width="3523" height="1213" class="img_ev3q"></p><ul><li>이 결과에 따르면, <em>NoisyTune</em> 은 English 및 multilingual setting 모두에서 다양한 PLM 의 성능을 일관되게 향상시킬 수 있었다. </li><li>또한 <em>NoisyTune</em> 에 의한 성능 향상은 상대적으로 작은 dataset (e.g., RTE, CoLA, WNLI) 에서 더 크게 나타났다. <ul><li>이는 downstream task 의 labeled data 가 부족할 때, 보통 pretraining task 와 data 에 overfitting 된 original parameter 로부터 효과적으로 PLM 을 finetuning 하기 어렵다는 것을 보여준다.</li></ul></li><li>실험 결과는 <em>NoisyTune</em> 이 PLM 에 소량의 noise 를 적절히 추가하여 서로 다른 parameter space 를 탐색하고 overfitting 문제를 줄임으로써, PLM 이 downstream task 에 더 쉽게 적응할 수 있도록 한다는 것을 검증하였다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="33-which-noise-to-use-and-how">3.3 Which Noise to Use and How?<a href="#33-which-noise-to-use-and-how" class="hash-link" aria-label="Direct link to 3.3 Which Noise to Use and How?" title="Direct link to 3.3 Which Noise to Use and How?">​</a></h2><p>이 절에서는 <em>NoisyTune</em> 에 어떤 종류의 noise 가 더 적합한지 연구한다. 또한, 저자가 제안한 matrix-wise perturbation 방법이 PLM 의 모든 parameter 에 대해 동일한 global noise 를 사용하는 것보다 더 좋은지 탐구한다. 저자는 다섯 가지 방법을 비교하였다.</p><ol><li>noise 를 사용하지 않는 <em>NoisyTune</em></li><li>global Gaussian noise 를 사용하는 <em>NoisyTune</em></li><li>global uniform noise 를 사용하는 <em>NoisyTune</em></li><li>matrix-wise Gaussian noise 를 사용하는 <em>NoisyTune</em></li><li>matrix-wise uniform noise 를 사용하는 <em>NoisyTune</em></li></ol><p>GLUE 의 결과는 Fig. 2 에 제시되어 있으며, XTREME 의 결과도 유사한 패턴을 보인다. 분석 결과, 모든 PLM parameter 에 동일한 분포의 global noise 를 추가하면 model 성능이 저하됨을 확인하였다. 이는 PLM 내 서로 다른 parameter matrix 가 매우 다른 분포와 특성을 가지기 때문이다. 단순히 모든 parameter matrix 에 동일한 global noise 를 추가하는 것은 최적이 아니다.</p><p><img loading="lazy" alt="Figure 2" src="/assets/images/image-25-deb3863467e9882a89f7a4f42a6152e7.png" width="1767" height="1347" class="img_ev3q"></p><ul><li>실험 결과, matrix-wise noise 가 훨씬 더 나은 선택임을 보여주었으며, 이는 서로 다른 parameter matrix 의 특성을 고려할 수 있기 때문이다. </li><li>또한 uniform noise 가 Gaussian noise 보다 더 효과적임을 발견하였다. 이는 Gaussian noise 가 더 넓은 범위를 가지며, 일부 extreme value 가 model 성능에 영향을 미칠 수 있기 때문일 수 있다. 따라서 <em>NoisyTune</em> 에서는 matrix-wise uniform noise 를 사용한다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="34-combination-with-existing-plm-finetuning-methods">3.4 Combination with Existing PLM Finetuning Methods<a href="#34-combination-with-existing-plm-finetuning-methods" class="hash-link" aria-label="Direct link to 3.4 Combination with Existing PLM Finetuning Methods" title="Direct link to 3.4 Combination with Existing PLM Finetuning Methods">​</a></h2><p>Fig. 1 에서 볼 수 있듯이, <em>NoisyTune</em> 은 특정 PLM finetuning 방법과 무관하다. 이는 downstream task-specific data 에 대해 finetuning 하기 전에 적용되므로, 기존의 어떤 PLM finetuning 방법과도 쉽게 결합될 수 있다.</p><p>이 절에서는 <em>NoisyTune</em> 이 기존의 PLM finetuning 기법을 보완하여 더 나은 성능을 달성할 수 있는지를 탐구한다. 여기서 저자는 두 가지 잘 알려진 PLM finetuning 기법을 선택하여 실험하였다: RecAdam 과 Mixout.</p><p><img loading="lazy" alt="Figure 3" src="/assets/images/image-26-99be95e00499ed7c44811fcbfd5651b0.png" width="1767" height="1347" class="img_ev3q"></p><p>실험 결과는 Fig. 3 에 요약되어 있다. </p><ul><li><em>NoisyTune</em> 과 기존 PLM finetuning 기법을 결합하면 성능이 더욱 향상됨을 확인하였다. <ul><li>이는 <em>NoisyTune</em> 은 pretraining signal 의 overfitting 을 다루는 데 목적이 있으며, </li></ul></li><li>반면 기존 기법들은 downstream task 의 overfitting 을 방지하는 데 초점을 맞추기 때문이다. 따라서 <em>NoisyTune</em> 과 기존 PLM finetuning 방법은 상호 보완적이며, <em>NoisyTune</em> 을 통해 강화될 수 있다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="35-empirical-analysis-of-noisytune">3.5 Empirical Analysis of <em>NoisyTune</em><a href="#35-empirical-analysis-of-noisytune" class="hash-link" aria-label="Direct link to 35-empirical-analysis-of-noisytune" title="Direct link to 35-empirical-analysis-of-noisytune">​</a></h2><p>다음으로, <em>NoisyTune</em> 이 왜 PLM finetuning 에 도움이 되는지를 경험적으로 분석한다. 저자는 MRPC dataset 에 대해 BERT 를 <em>NoisyTune</em> 적용 여부 및 서로 다른 학습 데이터 비율에서 finetuning 한 정확도를 비교하였다. 결과는 Fig. 4 에 제시되어 있다.</p><p><img loading="lazy" alt="Figure 4" src="/assets/images/image-27-9af60fd9d31f098b782a0e03e2cddaed.png" width="1767" height="1291" class="img_ev3q"></p><ul><li>실험에서 <em>NoisyTune</em> 은 데이터 양이 달라져도 일관되게 PLM 성능을 향상시켰으며, 특히 학습 데이터가 적을 때 더 큰 효과를 보였다. </li><li>이는 perturbation 된 PLM 이 pretraining task 에 overfitting 될 위험이 낮고, 더 나은 generalization 능력을 가지기 때문이며, 이는 데이터가 제한된 downstream task finetuning 에 특히 유리하다.</li></ul><p>추가적으로, <em>NoisyTune</em> 이 PLM finetuning 에 미치는 영향을 더 자세히 살펴보기 위해, 저자는 MRPC dataset 에 대해 BERT finetuning 동안 다양한 종류의 parameter 의 L1-norm 변화량을 비교하였다 (Fig. 5).</p><p><img loading="lazy" alt="Figure 5" src="/assets/images/image-28-721e05dd0bb3ae1da8e7ab25a33bfcd0.png" width="1767" height="1787" class="img_ev3q"></p><ul><li><em>NoisyTune</em> 에 추가된 noise 는 zero-mean uniform noise 이므로, 절대적 parameter L1-norm 은 크게 변하지 않는다. 그러나 <em>NoisyTune</em> 을 적용하면 L1-norm 의 상대적 변화가 더 작아지는 것을 확인할 수 있다. <ul><li>이는 PLM 이 downstream task 에 적합한 (sub)optimal parameter 를 더 쉽게 찾을 수 있음을 의미한다. </li></ul></li><li>결과적으로, 기존의 direct finetuning 은 downstream task 에 적응하기 위해 더 많은 update 가 필요하지만, 이는 pretraining task 의 overfitting 때문이며, <em>NoisyTune</em> 은 이 문제를 단순하게 완화하고 PLM 의 효과적인 finetuning 을 돕는 방법을 제공한다.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="36-hyperparameter-analysis">3.6 Hyperparameter Analysis<a href="#36-hyperparameter-analysis" class="hash-link" aria-label="Direct link to 3.6 Hyperparameter Analysis" title="Direct link to 3.6 Hyperparameter Analysis">​</a></h2><p>저자는 <em>NoisyTune</em> 의 가장 중요한 hyperparameter 인 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> (relative noise intensity) 의 영향을 분석하였다. 다양한 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 값에 따른 GLUE 평균 점수는 Fig. 6 에 제시되어 있다.</p><p><img loading="lazy" alt="Figure 6" src="/assets/images/image-29-20adc1a03f7af3de8405c5478ae0826b.png" width="1648" height="1306" class="img_ev3q"></p><ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 가 너무 작거나 너무 크면 성능이 최적이 아님을 확인하였다. </li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 가 너무 작은 경우, PLM 이 parameter space exploration 을 수행하기 어렵고 overfitting 문제를 극복하기 힘들다. </li><li>반면 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span> 가 너무 큰 경우, PLM 의 유용한 pretrained knowledge 가 random noise 에 의해 압도될 수 있다. </li><li>GLUE dataset 에서는 0.1 <!-- -->~<!-- --> 0.15 사이의 값이 <em>NoisyTune</em> 에 더 적합하다.</li></ul><h1>4 Conclusion</h1><p>본 논문에서는 PLM 을 downstream task 에 더 효과적으로 finetuning 할 수 있도록, finetuning 전에 소량의 noise 를 추가하는 간단하지만 효과적인 방법인 <strong><em>NoisyTune</em></strong> 을 제안하였다. <em>NoisyTune</em> 은 PLM 의 각 parameter matrix 의 분산에 따라 서로 다른 강도의 noise 를 추가하는 matrix-wise perturbation 방법을 사용한다.</p><p><em>NoisyTune</em> 은 매우 일반적인 방법으로, PLM model 에 독립적이고, downstream task 에 독립적이며, finetuning 방법에도 독립적이다.</p><p>Monolingual benchmark 인 GLUE 와 multilingual benchmark 인 XTREME 에 대한 광범위한 실험 결과, <em>NoisyTune</em> 은 다양한 PLM 과 downstream task 의 finetuning 을 일관되게 강화하여 더 나은 성능을 달성할 수 있음을 입증하였다.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/noisy-tune">NoisyTune</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/noisy-embedding">noisy embedding</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/l-la-ma">LLaMA</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/uniform-distribution">Uniform Distribution</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/NLP/Generalization/2022-02-NoisyTune.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Paper/NLP/Augmentation/PromptDA"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">PromptDA : Label-guided Data Augmentation for Prompt-based Few Shot Learners</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Paper/NLP/Generalization/NEFTune"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">NEFTune: Noisy Embeddings Improve Instruction FineTuning</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#31-datasets-and-experimental-settings" class="table-of-contents__link toc-highlight">3.1 Datasets and Experimental Settings</a></li><li><a href="#32-performance-evaluation" class="table-of-contents__link toc-highlight">3.2 Performance Evaluation</a></li><li><a href="#33-which-noise-to-use-and-how" class="table-of-contents__link toc-highlight">3.3 Which Noise to Use and How?</a></li><li><a href="#34-combination-with-existing-plm-finetuning-methods" class="table-of-contents__link toc-highlight">3.4 Combination with Existing PLM Finetuning Methods</a></li><li><a href="#35-empirical-analysis-of-noisytune" class="table-of-contents__link toc-highlight">3.5 Empirical Analysis of <em>NoisyTune</em></a></li><li><a href="#36-hyperparameter-analysis" class="table-of-contents__link toc-highlight">3.6 Hyperparameter Analysis</a></li></ul></div></div></div><div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/wyjo0626/wyjo0626.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Won-Yong Jo, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.dc82af9c.js"></script>
<script src="/assets/js/main.07c26eea.js"></script>
</body>
</html>