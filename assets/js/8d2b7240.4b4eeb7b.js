"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[26547],{3905:(e,a,t)=>{t.d(a,{Zo:()=>o,kt:()=>c});var n=t(67294);function i(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function l(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function s(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?l(Object(t),!0).forEach((function(a){i(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function r(e,a){if(null==e)return{};var t,n,i=function(e,a){if(null==e)return{};var t,n,i={},l=Object.keys(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||(i[t]=e[t]);return i}(e,a);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var m=n.createContext({}),p=function(e){var a=n.useContext(m),t=a;return e&&(t="function"==typeof e?e(a):s(s({},a),e)),t},o=function(e){var a=p(e.components);return n.createElement(m.Provider,{value:a},e.children)},u="mdxType",k={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},N=n.forwardRef((function(e,a){var t=e.components,i=e.mdxType,l=e.originalType,m=e.parentName,o=r(e,["components","mdxType","originalType","parentName"]),u=p(t),N=i,c=u["".concat(m,".").concat(N)]||u[N]||k[N]||l;return t?n.createElement(c,s(s({ref:a},o),{},{components:t})):n.createElement(c,s({ref:a},o))}));function c(e,a){var t=arguments,i=a&&a.mdxType;if("string"==typeof e||i){var l=t.length,s=new Array(l);s[0]=N;var r={};for(var m in a)hasOwnProperty.call(a,m)&&(r[m]=a[m]);r.originalType=e,r[u]="string"==typeof e?e:i,s[1]=r;for(var p=2;p<l;p++)s[p]=t[p];return n.createElement.apply(null,s)}return n.createElement.apply(null,t)}N.displayName="MDXCreateElement"},6336:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>m,contentTitle:()=>s,default:()=>k,frontMatter:()=>l,metadata:()=>r,toc:()=>p});var n=t(87462),i=(t(67294),t(3905));const l={slug:"CLIP",title:"Learning Transferable Visual Models From Natural Language Supervision",tags:["Vision-Language","CLIP","contrastive learning","zero-shot transfer"]},s=void 0,r={unversionedId:"Paper/Vision-Language/Foundation/Contrastive Learning/2021-03-CLIP",id:"Paper/Vision-Language/Foundation/Contrastive Learning/2021-03-CLIP",title:"Learning Transferable Visual Models From Natural Language Supervision",description:"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :",source:"@site/docs/Paper/Vision-Language/Foundation/Contrastive Learning/2021-03-CLIP.md",sourceDirName:"Paper/Vision-Language/Foundation/Contrastive Learning",slug:"/Paper/Vision-Language/Foundation/Contrastive Learning/CLIP",permalink:"/docs/Paper/Vision-Language/Foundation/Contrastive Learning/CLIP",draft:!1,editUrl:"https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/Vision-Language/Foundation/Contrastive Learning/2021-03-CLIP.md",tags:[{label:"Vision-Language",permalink:"/docs/tags/vision-language"},{label:"CLIP",permalink:"/docs/tags/clip"},{label:"contrastive learning",permalink:"/docs/tags/contrastive-learning"},{label:"zero-shot transfer",permalink:"/docs/tags/zero-shot-transfer"}],version:"current",frontMatter:{slug:"CLIP",title:"Learning Transferable Visual Models From Natural Language Supervision",tags:["Vision-Language","CLIP","contrastive learning","zero-shot transfer"]},sidebar:"tutorialSidebar",previous:{title:"Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision",permalink:"/docs/Paper/Vision-Language/Foundation/Contrastive Learning/ALIGN"},next:{title:"VL-BERT: Pre-Training Of Generic Visual-Linguistic Representations",permalink:"/docs/Paper/Vision-Language/Foundation/Single-Stream/VLBERT"}},m={},p=[{value:"2.1 Natural Language Supervision",id:"21-natural-language-supervision",level:2},{value:"2.2 Creating a Sufficiently Large Dataset",id:"22-creating-a-sufficiently-large-dataset",level:2},{value:"2.3 Selecting an Efficient Pre-Training Method",id:"23-selecting-an-efficient-pre-training-method",level:2},{value:"2.4 Choosing and Scaling a Model",id:"24-choosing-and-scaling-a-model",level:2},{value:"2.5 Training",id:"25-training",level:2},{value:"3.1 Zero-Shot Transfer",id:"31-zero-shot-transfer",level:2},{value:"3.1.1 Motivation",id:"311-motivation",level:3},{value:"3.1.2 Using CLIP For Zero-Shot Transfer",id:"312-using-clip-for-zero-shot-transfer",level:3},{value:"3.1.3 Initial Comparison to Visual N-Grams",id:"313-initial-comparison-to-visual-n-grams",level:3},{value:"3.1.4 Prompt Engineering And Ensembling",id:"314-prompt-engineering-and-ensembling",level:3},{value:"3.1.5 Analysis of Zero-Shot CLIP Performance",id:"315-analysis-of-zero-shot-clip-performance",level:3},{value:"3.2 Representation Learning",id:"32-representation-learning",level:2},{value:"3.3 Robustness to Natural Distribution Shift",id:"33-robustness-to-natural-distribution-shift",level:2},{value:"7.1 Bias",id:"71-bias",level:2},{value:"7.2 Surveillance",id:"72-surveillance",level:2},{value:"7.3 Future Work",id:"73-future-work",level:2}],o={toc:p},u="wrapper";function k(e){let{components:a,...l}=e;return(0,i.kt)(u,(0,n.Z)({},o,l,{components:a,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 : ",(0,i.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/2103.00020.pdf"},"https://arxiv.org/pdf/2103.00020.pdf")),(0,i.kt)("h1",{id:"abstract"},"Abstract"),(0,i.kt)("p",null,"SOTA vision system \uc740 fixed predetermined object categories set \uc744 \uc608\uce21\ud558\ub3c4\ub85d \ud6c8\ub828\ub41c\ub2e4. \uc774\ub294 label \ud655\uc7a5\uc774 \ud544\uc694\ud558\uc5ec \uc77c\ubc18\uc131\uacfc \uc0ac\uc6a9\uc131\uc774 \uc81c\ud55c\ub41c\ub2e4."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uc800\uc790\ub294 simple pre-training task \uc778 caption \uacfc image \uc758 \uad00\ub828\uc131\uc744 \uc608\uce21\ud558\ub294 \uac83\uc774 400M dataset (image, text) \uc5d0\uc11c SOTA image representation \uc744 \ud6a8\uacfc\uc801\uc774\uace0 \ud655\uc7a5 \uac00\ub2a5\ud55c \ubc29\uc2dd\uc73c\ub85c scratch learning \ud568\uc744 \ubcf4\uc5ec\uc90c"),(0,i.kt)("li",{parentName:"ul"},"pre-training \ud6c4 natural language \ub85c learned visual concepts (or describtion new one) \uc744 \ucc38\uc870\ud558\uac70\ub098 model \uc744 downstream task \ub85c zero-shot transfer"),(0,i.kt)("li",{parentName:"ul"},"\uc774 \ubc29\ubc95\uc73c\ub85c OCR, action recognition video, geo-localization \ubc0f \uc5ec\ub7ec \uc720\ud615\uc758 fine-grained object classification \ub4f1 30\uac1c \uc774\uc0c1\uc758 vision dataset \uc5d0 \uc5f0\uad6c"),(0,i.kt)("li",{parentName:"ul"},"\ube44\uad50\uc801 \ub300\ubd80\ubd84\uc758 task \uc5d0 \uc27d\uac8c transfer \ub418\uba70, \ud2b9\uc815 dataset \uc740 \ud6c8\ub828 \uc5c6\uc774 fully supervised baseline \uacfc \uacbd\uc7c1\ub825 \uc788\ub2e4.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc608\ub85c, ImageNet zero-shot \uc5d0\uc11c \uae30\uc874 ResNet-50 \uc758 accuracy \uc640 \uc77c\uce58\ud558\uc9c0\ub9cc, ResNet-50 \uc774 \ud6c8\ub828\ud55c 1.28M training example \uc774 \ud544\uc694\uac00 \uc5c6\uc74c")))),(0,i.kt)("h1",{id:"1-introduction-and-motivating-work"},"1. Introduction and Motivating Work"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"BERT, GPT \ub4f1\uc774 NLP \uc5d0\uc11c raw text \ub97c \uc9c1\uc811 \ud559\uc2b5\ud558\ub294 pre-training \uc73c\ub85c \uc131\uacfc\ub97c \uc774\ub8e8\uc5c8\ub2e4. "),(0,i.kt)("li",{parentName:"ul"},"auto-regressive \ubc0f masked language modeling \uac19\uc740 task-agnostic objective \ub294 \ubaa8\ub378 \ubc0f \ub370\uc774\ud130\uc5d0 \uc5ec\ub7ec \ub2e8\uacc4\ub85c \ud655\uc7a5\ud558\uc5ec \uafb8\uc900\ud788 \ud5a5\uc0c1\uc2dc\ucf30\ub2e4."),(0,i.kt)("li",{parentName:"ul"},"T5, GPT \ub294 input-output interface \uac1c\ubc1c\ub85c task-agnostic architecture \uac00 downstream task \uc5d0 zero-shot transfer"),(0,i.kt)("li",{parentName:"ul"},"GPT-3 \ub294 specific training data \ud544\uc694 \uc5c6\uc774\ub3c4 \uacbd\uc7c1\ub825\uc744 \uac00\uc9d0")),(0,i.kt)("p",null,"\uc774\ub294 web-scale \uc758 pre-training \uc774 \uc81c\uacf5\ud558\ub294 aggregate supervision \uc774 \uace0\ud488\uc9c8\uc758 crowd-labeled NLP dataset \ubcf4\ub2e4 \ub6f0\uc5b4\ub0a8\uc744 \uc2dc\uc0ac. \ud558\uc9c0\ub9cc vision \ubd84\uc57c\ub294 ImageNet \uac19\uc740 crowd-labeled dataset \uc774 \ud45c\uc900\uc801\uc774\uba70, web-scale \uc5d0\uc11c \uc9c1\uc811 \ud559\uc2b5\ud558\ub294 \ud655\uc7a5 \uac00\ub2a5\ud55c pre-training \uc774 vision \uc5d0\uc11c\ub3c4 \uac00\uc838\uc62c\uc9c0 \uc758\ubb38."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Mori et al. (1999) : image-text pair \uc758 document \uc5d0\uc11c \uba85\uc0ac\uc640 \ud615\uc6a9\uc0ac\ub97c \uc608\uce21\ud558\uc5ec \ucee8\ud150\uce20 \uae30\ubc18 \uc774\ubbf8\uc9c0 \uac80\uc0c9\uc744 \uac1c\uc120"),(0,i.kt)("li",{parentName:"ul"},"Quattoni et al. (2007) : image caption \uc5d0\uc11c \ub2e8\uc5b4\ub97c \uc608\uce21\ud558\ub294 classifier \uc758 weight space \uc5d0\uc11c manifold learning \uc744 \ud1b5\ud574 \ub354 \ud6a8\uc728\uc801\uc778 data representation \uc744 \ud559\uc2b5\ud560 \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \uc785\uc99d "),(0,i.kt)("li",{parentName:"ul"},"Srivastava & Salakhutdinov (2012) : low-level image \ubc0f text tag \uae30\ub2a5 \uc704\uc5d0 multimodal Deep Boltzmann \uc744 \ud6c8\ub828\uc2dc\ud0b4\uc73c\ub85c\uc368 deep representation learning \ud0d0\uad6c"),(0,i.kt)("li",{parentName:"ul"},"Joulin et al. (2016) : \uc774\ub7ec\ud55c \uc5f0\uad6c\ub97c \ud604\ub300\ud654\ud558\uace0 image caption \uc5d0\uc11c \ub2e8\uc5b4\ub97c \uc608\uce21\ud558\ub294 \ub370 \ud6c8\ub828\ub41c CNN \uc774 \uc720\uc6a9\ud55c image representation \uc744 \ud559\uc2b5 ",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"YFCC100M dataset(Thomee et al., 2016)\uc758 \uc774\ubbf8\uc9c0 \uc81c\ubaa9, \uc124\uba85 \ubc0f \ud574\uc2dc\ud0dc\uadf8 \uba54\ud0c0\ub370\uc774\ud130\ub97c bag-of-word multi-label classification task \ub85c \ubcc0\ud658"))),(0,i.kt)("li",{parentName:"ul"},"AlexNet : \uc774\ub7ec\ud55c label \uc744 \uc608\uce21\ud558\ub3c4\ub85d pre-training \ud558\uc5ec \uc774\ub7ec\ud55c label \ub85c \ud45c\ud604\ub41c \uac83\uc774 ImageNet-based pre-training on trasfer tasks"),(0,i.kt)("li",{parentName:"ul"},"Li et al. (2017) : \uc774 \uc811\uadfc \ubc29\uc2dd\uc744 \ud655\uc7a5\ud558\uc5ec \uac1c\ubcc4 \ub2e8\uc5b4 \uc678\uc5d0 \uad6c\ubb38 n-gram \ub3c4 \uc608\uce21\ud558\uace0 visual n-grams \ubc0f highest score \ud558\ub098\ub97c \uc608\uce21\ud558\ub294 \uac83\uc73c\ub85c \ub2e4\ub978 image classification dataset \uc73c\ub85c\uc758 zero-shot system \uc758 \ub2a5\ub825\uc744 \uc785\uc99d")),(0,i.kt)("p",null,"VirTex, ICMLM \ubc0f ConVIRT \uac19\uc740 \ucd5c\uc2e0 architecture \ubc0f pre-training approach \ub97c \ucc44\ud0dd\ud558\uc5ec, language modeling, masked language modeling \ubc0f contrastive objective \ub97c \uc0ac\uc6a9\ud574 text \ub85c\ubd80\ud130 image representation \uc744 \uc7a0\uc7ac\ub825\uc744 \uc2dc\uc5f0"),(0,i.kt)("p",null,"\uc774\ub7f0 image prepresentation learning \uc744 \uc704\ud574 natural supervision \uc0ac\uc6a9\uc774 \ub4dc\ubb38\ub370, \uc131\ub2a5\uc774 \ub300\uc548\ubc95\ubcf4\ub2e4 \ud6e8\uc52c \ub0ae\uae30 \ub54c\ubb38"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Li et al (2017) : zero-shot setting \uc5d0\uc11c ImageNet \uc815\ud655\ub3c4\uac00 11.5% \uc5d0 \ubd88\uacfc",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 88.4% \uc815\ud655\ub3c4 (\ub2f9\uc2dc SOTA)\ubcf4\ub2e4 \ud6e8\uc52c \ub0ae\uc74c"),(0,i.kt)("li",{parentName:"ul"},"\uace0\uc804\uc801\uc778 \uc811\uadfc\ubc95\uc758 50% \ubcf4\ub2e4\ub3c4 \ub0ae\uc74c"),(0,i.kt)("li",{parentName:"ul"},"\ub300\uc2e0, \ubc94\uc704\ub97c \uc881\uac8c \uc124\uc815\ud558\uc9c0\ub9cc well-targeted weak supervision \uc0ac\uc6a9\uc774 \uc131\ub2a5\uc744 \ud5a5\uc0c1 "))),(0,i.kt)("li",{parentName:"ul"},"Mahajan et al (2018) : Instagram image \uc5d0\uc11c ImageNet \uad00\ub828 hashtag \uc608\uce21\uc774 \ud6a8\uacfc\uc801\uc778 pre-training task \uc784\uc744 \ubcf4\uc5ec\uc90c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"pre-training model \uc774 ImageNet \uc5d0 \ub9de\uac8c \uc870\uc815\uba74 \uc815\ud655\ub3c4\uac00 5% \uc774\uc0c1 \ud5a5\uc0c1"))),(0,i.kt)("li",{parentName:"ul"},"Kolesnikov et al (2019), Dosovitskiy et al (2020) : noisy \uac00 \uc788\ub294 JFT-300M dataset \uc758 class \uc608\uce21\ud558\uae30 \uc704\ud574 \ubaa8\ub378\uc744 pre-training \ud558\uc5ec \ubcf4\ub2e4 \ub113\uc740 \ubc94\uc704\uc758 transfer benchmark \uc5d0\uc11c \ud070 \uc774\ub4dd")),(0,i.kt)("p",null,'\uc774\ub7f0 \uc5f0\uad6c\ub294 \uc81c\ud55c\ub41c \uc591\uc758 supervision "gold-labels" \ub85c \ud559\uc2b5\ud558\ub294 \uac83\uacfc \uc2e4\uc81c\ub85c \uc81c\ud55c\ub418\uc9c0 \uc54a\uc740 raw text \ub85c\ubd80\ud130 \ud559\uc2b5\ud558\ub294 \uac83 \uc0ac\uc774\uc758 \uc911\uac04 \uc9c0\uc810\uc774\uc9c0\ub9cc, \ud0c0\ud611\ub418\uc9c0 \uc54a\uc74c'),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\ub450 \ubc29\uc2dd \ubaa8\ub450 supervision \uc744 1000 \ubc0f 18291 class \ub85c \uac01\uac01 \uc124\uacc4\ud558\uace0 \uc81c\ud55c"),(0,i.kt)("li",{parentName:"ul"},"natural language \ub294 \uc77c\ubc18\uc131\uc744 \ud1b5\ud574 \ud6e8\uc52c \ub113\uc740 visual concepts \ub97c \ud45c\ud604\ud558\uace0, \ub530\ub77c\uc11c supervise \uac00\ub2a5"),(0,i.kt)("li",{parentName:"ul"},"\ub450 \ubc29\uc2dd \ubaa8\ub450 static softmax classifier \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc608\uce21\ud558\uba70, dynamic output mechanism \uc774 \uc5c6\uc74c"),(0,i.kt)("li",{parentName:"ul"},'\uc774\ub294 \uadf8\ub4e4\uc758 \uc720\uc5f0\uc131\uc744 \uc2ec\uac01\ud558\uac8c \uc81c\ud55c\ud558\uace0 "zero-shot" \uae30\ub2a5\uc744 \uc81c\ud55c')),(0,i.kt)("p",null,"\uc774\ub7ec\ud55c weakly supervised models \uacfc \ucd5c\uadfc\uc758 \uc790\uc5f0\uc5b4\uc5d0\uc11c image representation \uc744 \ud559\uc2b5\ud558\ub294 \ud0d0\uad6c\uc758 \uc8fc\uc694 \ucc28\uc774\uc810\uc740 \uaddc\ubaa8\ub2e4. "),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Mahajan \ub4f1 (2018), Kolesnikov \ub4f1 (2019) : 1M \uc5d0\uc11c 1B images \uc5d0 \ub300\ud574 accelerator years \ub3d9\uc548 \ubaa8\ub378\uc744 \ud6c8\ub828\uc2dc\ucf30\uc9c0\ub9cc, VirTex, ICMLM \ubc0f ConVIRT \ub294 accelerator days \uc5d0 \ud574\ub2f9\ud558\ub294 \uc2dc\uac04\uc5d0 1 ~ 200K images \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud574 \ud6c8\ub828"),(0,i.kt)("li",{parentName:"ul"},"\uc774 \uc5f0\uad6c\ub294 large-scale natural language spervision \ud558\uc5d0 \ud6c8\ub828\ub41c image classifier \uc758 \ud589\ub3d9\uc744 \uc5f0\uad6c\ud558\uc5ec \uc774 \ucc28\uc774\ub97c \ud574\uc18c")),(0,i.kt)("p",null,"web \uc758 public large-scale dataset \uc73c\ub85c  \uc6b0\ub9ac\ub294 400M dataset (image, text) \uc744 \uc0dd\uc131\ud558\uace0, \uc774\ub97c ",(0,i.kt)("strong",{parentName:"p"},"CLIP")," (",(0,i.kt)("strong",{parentName:"p"},"C"),"ontrastive ",(0,i.kt)("strong",{parentName:"p"},"L"),"anguage-",(0,i.kt)("strong",{parentName:"p"},"I"),"mage ",(0,i.kt)("strong",{parentName:"p"},"P"),"re-training)\ub77c\ub294 ConVIRT \uc758 \ub2e8\uc21c\ud654\ub41c \ubc84\uc804\uc744 scratch learning \ud558\uc5ec natural supervision \uc73c\ub85c \ud559\uc2b5\ud558\ub294 \ud6a8\uc728\uc801\uc778 \ubc29\ubc95\uc784\uc744 \uc785\uc99d"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"CLIP \uc758 \ud655\uc7a5 \uac00\ub2a5\uc131\uc744 \uc5f0\uad6c\ud558\uace0 transfer \uc131\ub2a5\uc774 \uacc4\uc0b0\ub7c9\uc758 smoothly predicable function \uc784\uc744 \uad00\ucc30"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc774 GPT \uc640 \uc720\uc0ac\ud558\uac8c pre-training \uc911 OCR, geo-localization, action recognition \ub4f1 \ub9ce\uc740 task \ub97c \uc218\ud589\ud558\ub294 \uac83 \ubc1c\uacac"),(0,i.kt)("li",{parentName:"ul"},"30 dataset \uc5d0 \ub300\ud55c zero-shot transfer \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uc5ec \uc774\uc804 \uc5f0\uad6c\uc778 task-specific supervised models \uc640 \uacbd\uc7c1\ub825\uc774 \uc788\uc74c\uc744 \ud655\uc778"),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c linear-probe representation \ubd84\uc11d\uc73c\ub85c \uacb0\uacfc\ub97c \ud655\uc778\ud558\uace0, CLIP \uc774 ImageNet \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uba74\uc11c\ub3c4 \uacc4\uc0b0\uc801\uc73c\ub85c \ud6a8\uc728\uc801\uc784\uc744 \ubcf4\uc5ec\uc90c"),(0,i.kt)("li",{parentName:"ul"},"zero-shot CLIP \uc774 \ub3d9\ub4f1\ud55c \uc815\ud655\ub3c4\uc758 supervision ImageNet \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \ud6e8\uc52c \ub354 robust \ud568\uc744 \ubc1c\uacac\ud558\uba70, \uc774\ub294 task-agnostic model \uc758 zero-shot \ud3c9\uac00\uac00 \ubaa8\ub378\uc758 \ub2a5\ub825\uc744 \ud6e8\uc52c \ub354 \uc798 \ub300\ud45c\ud55c\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac")),(0,i.kt)("h1",{id:"2-approach"},"2. Approach"),(0,i.kt)("h2",{id:"21-natural-language-supervision"},"2.1 Natural Language Supervision"),(0,i.kt)("p",null,"\uc811\uadfc\ubc95\uc758 \ud575\uc2ec\uc740 ",(0,i.kt)("em",{parentName:"p"},"natural language supervision")," \uc73c\ub85c perception learning \uc774\ub2e4."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uc0c8\ub85c\uc6b4 \uc544\uc774\ub514\uc5b4\ub294 \uc544\ub2c8\uba70, Zhang et al (2020), Gomez et al (2017), Joulin et al (2016) \ubc0f Desai & Johnson (2020) \ub294 image \uc640 text \uc5d0\uc11c visual representation \uc744 \ud559\uc2b5\ud558\ub294 \ubc95\uc744 \uc18c\uac1c\ud558\uba70, \uac01\uac01 \uc774\ub4e4 \ubc29\ubc95\uc744 unsupervision, self-supervision, weakly supervised \ubc0f supervised \ub77c \uc124\uba85"),(0,i.kt)("li",{parentName:"ul"},"natural language \ub97c training signals \ub85c \uc778\uc2dd\ud558\ub294 \uac83\uc774 \uc704 \uc5f0\uad6c \ub77c\uc778\uc758 \uacf5\ud1b5\uc810\uc774\ub77c\ub294 \uc810\uc744 \uac15\uc870"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 \ubc29\uc2dd\uc740 natural language supervision \uc73c\ub85c\ubd80\ud130 \ud559\uc2b5\ud558\uba70, \uc774\ub294 \ub2e4\ub978 \ubc29\ubc95\uc5d0 \ube44\ud574 \uc5ec\ub7ec \uc7a5\uc810 \uc874\uc7ac",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},'image classification \uc744 \uc704\ud55c crowd-labeled \ubcf4\ub2e4 \ud6e8\uc52c \uc26c\uc6b4\ub370, "gold-label" \uc774 \ud544\uc694\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38'),(0,i.kt)("li",{parentName:"ul"},"web \uc758 large-scale text \uc5d0 \ud3ec\ud568\ub41c supervision \uc744 \uc218\ub3d9\uc73c\ub85c \ud559\uc2b5"),(0,i.kt)("li",{parentName:"ul"},"unsupervised \ub610\ub294 self-supervised learning \uacfc \ube44\uad50\ud558\uc5ec \uc7a5\uc810\uc774 \uc788\ub294\ub370, \ub2e8\ud6c8\ud788 representation learning \uc774 \uc544\ub2c8\ub77c representation \uc744 language \uc5d0 \uc5f0\uacb0\ud558\uc5ec \uc720\uc5f0\ud55c zero-shot learning \uac00\ub2a5")))),(0,i.kt)("h2",{id:"22-creating-a-sufficiently-large-dataset"},"2.2 Creating a Sufficiently Large Dataset"),(0,i.kt)("p",null,"\uae30\uc874 \uc5f0\uad6c\ub294 3 dataset: MS-COCO, Visual Genome \ubc0f YFCC100M \ub97c \uc0ac\uc6a9"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"MS-COCO \ubc0f Visual Genome \uc740 \ud604\ub300 \uae30\uc900\uc5d0 \ube44\ud574 \uc791\uc73c\uba70 \uac01\uac01 \uc57d 100,000 training image \uc874\uc7ac"),(0,i.kt)("li",{parentName:"ul"},"\ub2e4\ub978 vision system \uc740 \ucd5c\ub300 3.5B \uc778\uc2a4\ud0c0\uadf8\ub7a8 \uc0ac\uc9c4\uc5d0\uc11c \ud6c8\ub828(Mahajan et al, 2018)"),(0,i.kt)("li",{parentName:"ul"},"YFCC100M \uc740 100M images \ub85c \ub300\uc548\uc774 \ub420 \uc218 \uc788\uc9c0\ub9cc, \uac01 image \uc758 metadata \ub294 \ud76c\uc18c\ud558\uba70 \ud488\uc9c8\uc774 \ub2e4\ub984")),(0,i.kt)("hr",null),(0,i.kt)("p",null,"natural language supervision \ub3d9\uae30 \uc911 \ud558\ub098\ub294 web large-scale dataset \uc774 \uacf5\uac1c \uc0ac\uc6a9 \uac00\ub2a5\ud558\ub2e4\ub294 \uac83."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uae30\uc874 dataset \uc740 \uc774\ub7ec\ud55c \uac00\ub2a5\uc131\uc744 \ubc18\uc601\ud558\uc9c0 \uc54a\uc544 \uc7a0\uc7ac\ub825\uc744 \uacfc\uc18c \ud3c9\uac00\ud560 \uc218 \uc788\uc74c. \uc774\uc5d0 \ub300\uc751\ud574 web public large-scale source 400M pairs (image, text) dataset \uc744 \uad6c\ucd95"),(0,i.kt)("li",{parentName:"ul"},"visual concepts \ud3ec\uad04\uc744 \uc704\ud574 500,000 queries \uc911 \ud558\ub098\ub97c \ud3ec\ud568\ud558\ub294 pairs (image, text)\ub97c \uad6c\uc131\ud558\ub294 \uac83\uc774 \ubaa9\ud45c"),(0,i.kt)("li",{parentName:"ul"},"query \ub2f9 20,000 pairs (image, text) \uc744 \ud3ec\ud568\ud558\uc5ec \ub300\ub7b5\uc801\uc73c\ub85c class balance \ub9de\ucda4"),(0,i.kt)("li",{parentName:"ul"},"GPT-2 \ud6c8\ub828\uc5d0 \uc0ac\uc6a9\ub41c WebText dataset \uacfc \uc720\uc0ac\ud55c total word count")),(0,i.kt)("h2",{id:"23-selecting-an-efficient-pre-training-method"},"2.3 Selecting an Efficient Pre-Training Method"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 1",src:t(74318).Z,width:"2472",height:"1159"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 2",src:t(52316).Z,width:"1431",height:"1490"})),(0,i.kt)("p",null,"natural language \uc5d0\uc11c visual concepts learning \uc740 \uc5b4\ub824\uc6b8 \uc218 \uc788\uc9c0\ub9cc, \uc800\uc790\ub294 training efficiency \uc774 natural language supervision \uc758 \uc131\uacf5\uc801\uc778 \ud655\uc7a5\uc5d0 \ud544\uc218\uc801\uc784\uc744 \ubc1c\uacac\ud558\uc5ec, \uc774 metric \uc744 final pre-training method \ub85c \uc120\ud0dd"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\ucd08\uae30 \ubc29\uc2dd\uc740 VirText \uc640 \uc720\uc0ac\ud558\uac8c image CNN \uacfc text transformer \ub97c \ud568\uaed8 scratch training \ud558\uc5ec image caption \uc744 \uc608\uce21\ud558\ub294 \uac83",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \ud655\uc7a5\ud558\ub294\ub370 \uc5b4\ub824\uc6c0\uc774 \uc788\uc74c"),(0,i.kt)("li",{parentName:"ul"},"Fig. 2 \ucc98\ub7fc ResNet-50 image encoder \uc758 2\ubc30 \uacc4\uc0b0\uc744 \uc0ac\uc6a9\ud558\ub294 63M parameter transformer language model \uc744 \uc0ac\uc6a9\ud558\uc5ec, ImageNet class \uc778\uc2dd\uc5d0 simpler baseline \uc778 bag-of-words encodings \ubcf4\ub2e4 3\ubc30 \ub290\ub9ac\uac8c \ud559\uc2b5")))),(0,i.kt)("hr",null),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"image \uc5d0 \ub300\ud55c contrastive representation learning \ucd5c\uc2e0 \uc5f0\uad6c\uc5d0\uc11c contrastive objectives \uac00 \ub3d9\uc77c\ud55c predictive objective \ub4e4\ubcf4\ub2e4 representations \uc744 \ub354 \uc798 \ud559\uc2b5\ud568\uc744 \ubc1c\uacac"),(0,i.kt)("li",{parentName:"ul"},"\ub2e4\ub978 \uc5f0\uad6c\uc5d0\uc120 image generative model \uc774 high quality image representation \uc744 \ud559\uc2b5\ud560 \uc21c \uc788\uc9c0\ub9cc \ub3d9\uc77c\ud55c \uc131\ub2a5\uc744 \ub0b4\ub824\uba74 contrastive model \ubcf4\ub2e4 \ub354 \ub9ce\uc740 \uacc4\uc0b0\uc774 \ud544\uc694\ud568\uc744 \ubc1c\uacac")),(0,i.kt)("p",null,"\uc774\ub97c \uace0\ub824\ud574, text \uc758 exact word \ub97c \uc608\uce21\ud558\ub294 \ub300\uc2e0, \uc5b4\ub290 text \uac00 \uc5b4\ub290 image \uc640 pair \ub97c \uc774\ub8e8\ub294\uc9c0\ub9cc \uc608\uce21\ud558\ub294 \ub354\uc6b1 \uc26c\uc6b4 proxy task \ub97c \ud574\uacb0\ud558\ub294 \uc2dc\uc2a4\ud15c\uc73c\ub85c \ud6c8\ub828\ud558\ub294 \uac83\uc744 \uc5f0\uad6c."),(0,i.kt)("p",null,"Fig. 2 \uac19\uc774 baseline \uc744 \uc2dc\uc791\uc73c\ub85c contrastive object \ub85c predictive object \ub97c \ubc14\uafb8\uace0, ImageNet \uc73c\ub85c\uc758 zero-shot trasnfer rate \uc5d0\uc11c 4x efficiency \ud5a5\uc0c1\uc744 \uad00\ucc30"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 3",src:t(59346).Z,width:"1431",height:"1490"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("mi",{parentName:"mrow"},"N")),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"N")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N")))))," (image, text) pair batch \uac00 \uc8fc\uc5b4\uc9c0\uba74, batch \uc804\uc5ed\uc5d0\uc11c \ubc1c\uc0dd\ud55c ",(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("mi",{parentName:"mrow"},"N"),(0,i.kt)("mo",{parentName:"mrow"},"\xd7"),(0,i.kt)("mi",{parentName:"mrow"},"N")),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"N \\times N")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7667em",verticalAlign:"-0.0833em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N"),(0,i.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,i.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N")))))," possible (image, text) pair \uc911 \uc5b4\ub5a4 \uac83\uc778\uc9c0 \uc608\uce21\ud558\ub3c4\ub85d \ud6c8\ub828"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub97c \uc704\ud574, batch \ub0b4\uc758 ",(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("mi",{parentName:"mrow"},"N")),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"N")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N")))))," real pairs \uc758 image \ubc0f text embeddings \uc758 cosine similarity \ub97c maximizing \ud558\uace0 ",(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("msup",{parentName:"mrow"},(0,i.kt)("mi",{parentName:"msup"},"N"),(0,i.kt)("mn",{parentName:"msup"},"2")),(0,i.kt)("mo",{parentName:"mrow"},"\u2212"),(0,i.kt)("mi",{parentName:"mrow"},"N")),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"N^2 - N")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8974em",verticalAlign:"-0.0833em"}}),(0,i.kt)("span",{parentName:"span",className:"mord"},(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N"),(0,i.kt)("span",{parentName:"span",className:"msupsub"},(0,i.kt)("span",{parentName:"span",className:"vlist-t"},(0,i.kt)("span",{parentName:"span",className:"vlist-r"},(0,i.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,i.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,i.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,i.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,i.kt)("span",{parentName:"span",className:"mord mtight"},"2")))))))),(0,i.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.kt)("span",{parentName:"span",className:"mbin"},"\u2212"),(0,i.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N")))))," incorrect pairs \uc758 embeddings \uc758 cosine similarity \ub294 minimizing \ud558\uc5ec multi-modal embedding space \ub97c \ud559\uc2b5"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7ec\ud55c similarity scores \uc5d0 \ub300\ud574 symmetric cross entropy loss \ub97c optimizing"),(0,i.kt)("li",{parentName:"ul"},"Fig. 3 \uc740 CLIP \uc758 \ud575\uc2ec \uad6c\ud604\uc758 \uc758\uc0ac \ucf54\ub4dc\ub97c \ud3ec\ud568"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7ec\ud55c batch construction \ubc0f objective \ub294 ",(0,i.kt)("em",{parentName:"li"},"multi-class ",(0,i.kt)("span",{parentName:"em",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("mi",{parentName:"mrow"},"N")),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"N")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N"))))),"-pair loss")," \uac19\uc740 deep metric learning Sohn (2016) \uc5d0\uc11c \ub3c4\uc785"),(0,i.kt)("li",{parentName:"ul"},"Oord et al (2018)\uc5d0 \uc758\ud574 contrastive representation learning \uc774 \uc778\uae30\ub97c \uc5bb\uc5c8\uc73c\uba70, \ucd5c\uadfc\uc5d0\ub294 Zhang et al (2020)\uc758 medical imaging domain \uc5d0\uc11c contrastive (text, image) representation learning \uc73c\ub85c \uc801\uc6a9")),(0,i.kt)("hr",null),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"pre-training dataset \uc774 \ub9e4\uc6b0 \ucee4\uc11c overfitting \uc740 \uace0\ub824\uc0ac\ud56d\uc774 \uc544\ub2c8\uba70, training \uc138\ubd80 \uc0ac\ud56d\uc740 Zhang et al (2020)\uc758 \uad6c\ud604\uacfc \ube44\uad50\ud558\uc5ec \ub2e8\uc21c\ud654"),(0,i.kt)("li",{parentName:"ul"},"\uc800\uc790\ub294 image encoder \ub97c ImageNet weight \ub85c \ucd08\uae30\ud654\ud558\uac70\ub098 text encoder \ub97c pre-trained weight \ub85c \ucd08\uae30\ud654\ud558\uc9c0 \uc54a\uace0 CLIP \uc744 scratch training"),(0,i.kt)("li",{parentName:"ul"},"representation \uacfc contrastive embedding space \uac04\uc758 non-linear projections \uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 Bachman et al (2019)\uc5d0 \uc758\ud574 \ub3c4\uc785\ub418\uc5c8\uace0 Chen et al (2020b)\uc5d0 \uc758\ud574 \ubcf4\uae09"),(0,i.kt)("li",{parentName:"ul"},"\uc800\uc790\ub294 \uac01 encoder \uc758 representation \uc744 multi-modal embedding space \ub85c mapping \ud558\uae30 \uc704\ud574 linear projection \ub9cc \uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"\ub450 \ubc84\uc804 \uac04\uc5d0 training efficiency \ucc28\uc774\ub97c \uad00\ucc30\ud558\uc9c0 \ubabb\ud588\uc73c\uba70 non-linear projection \uc774 self-supervised representation learning \uc5d0\uc11c \ud604\uc7ac \uc774\ubbf8\uc9c0\uc758 \uc138\ubd80 \uc0ac\ud56d\uacfc \ud568\uaed8 \uc0c1\ud638 \uc801\uc751\ub420 \uc218 \uc788\uc74c\uc744 \ucd94\uce21"))),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c \ub9ce\uc740 (image, text) pair \uac00 CLIP \uc758 pre-training dataset \uc5d0\uc11c single sentence \uc77c \ub54c ",(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("msub",{parentName:"mrow"},(0,i.kt)("mi",{parentName:"msub"},"t"),(0,i.kt)("mi",{parentName:"msub"},"v"))),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"t_v")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7651em",verticalAlign:"-0.15em"}}),(0,i.kt)("span",{parentName:"span",className:"mord"},(0,i.kt)("span",{parentName:"span",className:"mord mathnormal"},"t"),(0,i.kt)("span",{parentName:"span",className:"msupsub"},(0,i.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,i.kt)("span",{parentName:"span",className:"vlist-r"},(0,i.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.1514em"}},(0,i.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,i.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,i.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,i.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.03588em"}},"v")))),(0,i.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,i.kt)("span",{parentName:"span",className:"vlist-r"},(0,i.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,i.kt)("span",{parentName:"span"}))))))))))," \uac00 \uc0d8\ud50c\ub9c1\ud558\ub294 \ud14d\uc2a4\ud2b8\uc5d0\uc11c \uade0\uc77c\ud558\uac8c single sentence \ub97c \uc0ac\uc6a9\ud558\ubbc0\ub85c Zhang et al (2020)\uc758 \ud14d\uc2a4\ud2b8 \ubcc0\ud615 \uae30\ub2a5\uc744 \uc81c\uac70"),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c image transformation function ",(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("msub",{parentName:"mrow"},(0,i.kt)("mi",{parentName:"msub"},"t"),(0,i.kt)("mi",{parentName:"msub"},"v"))),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"t_v")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7651em",verticalAlign:"-0.15em"}}),(0,i.kt)("span",{parentName:"span",className:"mord"},(0,i.kt)("span",{parentName:"span",className:"mord mathnormal"},"t"),(0,i.kt)("span",{parentName:"span",className:"msupsub"},(0,i.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,i.kt)("span",{parentName:"span",className:"vlist-r"},(0,i.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.1514em"}},(0,i.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,i.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,i.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,i.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.03588em"}},"v")))),(0,i.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,i.kt)("span",{parentName:"span",className:"vlist-r"},(0,i.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,i.kt)("span",{parentName:"span"}))))))))))," \ub97c \ub2e8\uc21c\ud654"),(0,i.kt)("li",{parentName:"ul"},"\uc870\uc815\ub41c \uc774\ubbf8\uc9c0\uc758 random square crop \uc774 training \uc911\uc5d0 \uc0ac\uc6a9\ub418\ub294 \uc720\uc77c\ud55c data augmentation"),(0,i.kt)("li",{parentName:"ul"},"\ub9c8\uc9c0\ub9c9\uc73c\ub85c, softmax \uc758 logits \ubc94\uc704\ub97c \uc81c\uc5b4\ud558\ub294 temperature parameter ",(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("mi",{parentName:"mrow"},"\u03c4")),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\tau")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.4306em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.1132em"}},"\u03c4")))))," \ub294 hyper-parameter \ub85c\uc11c \ubcc0\ud658\ub418\uc9c0 \uc54a\ub3c4\ub85d \uc9c1\uc811 training \uc911\uc5d0 optimizing")),(0,i.kt)("h2",{id:"24-choosing-and-scaling-a-model"},"2.4 Choosing and Scaling a Model"),(0,i.kt)("p",null,"image encoder \ub294 \ub450 architecture \ub97c \uace0\ub824"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"ResNet-50",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"He et al (2019) \uc758 ResNetD \uac1c\uc120\uacfc Zhang (2019) \uc758 antialiased rect-2 blur pooling \uc73c\ub85c, \uae30\uc874 \ubc84\uc804\uc744 \uc5ec\ub7ec \uac00\uc9c0 \uc218\uc815"),(0,i.kt)("li",{parentName:"ul"},"global average pooling layer \ub97c attention pooling mechanism \uc73c\ub85c \ub300\uccb4"),(0,i.kt)("li",{parentName:"ul"},"attention pooling \uc740 image \uc758 global average-pooled representation \uc5d0 conditioning \ub418\ub294 query \ub85c \uad6c\ud604"))),(0,i.kt)("li",{parentName:"ol"},"Vision Transformer (ViT)",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc870\uae08 \ub2e4\ub978 \ucd08\uae30\ud654\ub97c \uc0ac\uc6a9\ud558\uc5ec combined patch \ubc0f position embeddings \uc774\uc804\uc5d0 \ucd94\uac00\uc801\uc778 layer normalization \uc744 \uc81c\uc678\ud558\uace0 \uc774\ub4e4\uc758 \uad6c\ud604\uc744 \ub530\ub984"),(0,i.kt)("li",{parentName:"ul"})))),(0,i.kt)("p",null,"text encoder \ub294 GPT \uac19\uc774 \uc218\uc815\ub41c Transformer"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"63M parameter 12-layer 512-wide model with 8 attention heads \uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"Transformer \ub294 text \uc758 byte pair encoding (BPE) representation \uc5d0\uc11c \uc791\ub3d9\ud558\uba70 49,152 vocab size \uac00\uc9d0"),(0,i.kt)("li",{parentName:"ul"},"computational efficiency \ub97c \uc704\ud574 max sequence length 76 \uc73c\ub85c \uc81c\ud55c"),(0,i.kt)("li",{parentName:"ul"},"text sequence \ub294 ","[SOS]"," \ubc0f ","[EOS]"," token \uc73c\ub85c \ud45c\uc2dc\ub418\uba70, transformer \uc758 highest layer \uc758 activation \uc740 ","[EOS]"," token \uc5d0\uc11c text representation \uc73c\ub85c \ucde8\uae09\ub418\uba70, layer normalizaing \ub418\uace0, \uc774\ud6c4 multi-modal embedding space \ub85c linear projection"),(0,i.kt)("li",{parentName:"ul"},"text encoder \uc5d0\uc120 masked self-attention \uc744 \uc0ac\uc6a9\ud558\uc5ec pre-trained language model \uc744 \ucd08\uae30\ud654\ud558\uac70\ub098 language modeling \uc744 auxiliary objective \ub85c \ucd94\uac00\ud560 \uc218 \uc788\ub3c4\ub85d \ubcf4\uc874")),(0,i.kt)("hr",null),(0,i.kt)("p",null,"\uc774\uc804 vision \uc5f0\uad6c\uc5d0\uc11c model width or depth \ub9cc \uc99d\uac00 \uc2dc\ud0a4\uc9c0\ub9cc, ResNet image encoder \uc758 \uacbd\uc6b0 Tan & Le (2019) \uc758 \ubc29\uc2dd \ucc44\ud0dd"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 model width, depth \ubc0f resolusion \ubaa8\ub450\uc5d0 \ucd94\uac00 \uacc4\uc0b0\uc744 \ud560\ub2f9\ud558\ub294 \uac83\uc774 model dimension \uc911 \ud558\ub098\uc5d0\ub9cc \ud560\ub2f9\ud558\ub294 \uac83\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uac83\uc744 \ubc1c\uacac"),(0,i.kt)("li",{parentName:"ul"},"Tan & Le (2019) : EfficientNet \uc744 \uc704\ud574 \uac01 \ucc28\uc6d0\uc5d0 \ud560\ub2f9\ub41c \uacc4\uc0b0 \ube44\uc728\uc744 \uc870\uc815"),(0,i.kt)("li",{parentName:"ul"},"\uc800\uc790\ub294 \ucd94\uac00 \uacc4\uc0b0\uc744 model width, depth \ubc0f resolusion \ubaa8\ub450 \uc99d\uac00\uc2dc\ud0a8 \uac83\ub9cc baseline \uc73c\ub85c \uc0ac\uc6a9")),(0,i.kt)("p",null,"text encoder \uc758 \uacbd\uc6b0, text encoder \uc758 \uc6a9\ub7c9\uc5d0 \ub300\ud55c CLIP \uc758 \uc131\ub2a5\uc774 \ub35c \ubbfc\uac10\ud55c \uac83\uc744 \ubc1c\uacac\ud558\uc5ec model width \ub9cc \uc99d\uac00\uc2dc\ud0a4\uace0 depth \ub294 \uc804\ud600 \uc99d\uac00\uc2dc\ud0a4\uc9c0 \uc54a\uc74c"),(0,i.kt)("h2",{id:"25-training"},"2.5 Training"),(0,i.kt)("p",null,"5 ResNet \ubc0f 3 ViT \ud6c8\ub828"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"ResNet \uc758 \uacbd\uc6b0, ResNet-50, ResNet-101 \uc744 \ud6c8\ub828\ud558\uace0 EfficientNet \uc2a4\ud0c0\uc77c\uc758 model scaling \uc744 \ub530\ub974\ub294 3 \uac1c\uc758 model \ucd94\uac00 \ud6c8\ub828"),(0,i.kt)("li",{parentName:"ul"},"\uac01\uac01 ResNet-50\uc758 \uc57d 4x, 16x, 64x \uacc4\uc0b0 \uc0ac\uc6a9",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub4e4 \uac01\uac01 RN50x4, RN50x16, RN50x64 \ub85c \ud45c\uc2dc"))),(0,i.kt)("li",{parentName:"ul"},"Vision Transformer \uc758 \uacbd\uc6b0 ViT-B/32, ViT-B/16, ViT-L/14 \ub97c \ud6c8\ub828"),(0,i.kt)("li",{parentName:"ul"},"\ubaa8\ub4e0 \ubaa8\ub378\uc744 32 epoch \ub3d9\uc548 \ud6c8\ub828"),(0,i.kt)("li",{parentName:"ul"},"Adam optimizer \ub97c \uc0ac\uc6a9\ud558\uace0 \ubaa8\ub4e0 \uac00\uc911\uce58\uc5d0 \ub300\ud574 \uc801\uc6a9\ub418\ub294 decoupled weight decay regularization \ub97c \uc0ac\uc6a9\ud558\uc5ec learning rate \ub97c cosine schedule \uc5d0 \ub530\ub77c \uac10\uc18c"),(0,i.kt)("li",{parentName:"ul"},"initial hyper-parameter \ub294 ResNet50 \ubaa8\ub378\uc744 1 epoch \ub3d9\uc548 \ud6c8\ub828\ud560 \ub54c greedy search, random search \ubc0f manual tuning  \uc758 \uc870\ud569\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc124\uc815"),(0,i.kt)("li",{parentName:"ul"},"\uacc4\uc0b0 \uc81c\uc57d\uc73c\ub85c \uc778\ud574 hyper-parameter \ub294 \uc774\ud6c4 \ub354 \ud070 \ubaa8\ub378\uc5d0 \ub300\ud574 \ud734\ub9ac\uc2a4\ud2f1\ud558\uac8c \uc870\uc815"),(0,i.kt)("li",{parentName:"ul"},"learnable temperature parameter ",(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("mi",{parentName:"mrow"},"\u03c4")),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\tau")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.4306em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.1132em"}},"\u03c4")))))," \ub294 Wu et al, 2018 \uc640 \ub3d9\ub4f1\ud55c \uac12\uc778 0.07 \ub85c \ucd08\uae30\ud654"),(0,i.kt)("li",{parentName:"ul"},"training instability \ubc29\uc9c0\ub97c \uc704\ud574, logits 100\ubc30 \uc774\uc0c1 \ud655\uc7a5\ud558\uc9c0 \uc54a\ub3c4\ub85d clipping"),(0,i.kt)("li",{parentName:"ul"},"very large minibatch size 32,768 \uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"Mixed-precision \ub97c \uc0ac\uc6a9\ud558\uc5ec training \uc744 \uac00\uc18d\ud654\ud558\uace0 \uba54\ubaa8\ub9ac \uc808\uc57d"),(0,i.kt)("li",{parentName:"ul"},"\ucd94\uac00 \uba54\ubaa8\ub9ac \uc808\uc57d\uc744 \uc704\ud574, gradient checkpointing, half-precision Adam statistics \ubc0f half-precision stochastically rounded text encoder weights \uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"embedding similarity \uacc4\uc0b0\uc740 \uac01 GPU \uac00 local batch \uc5d0 \ud544\uc694\ud55c pairwise similarities subset \ub9cc\uc744 \uacc4\uc0b0\ud558\ub3c4\ub85d sharding"),(0,i.kt)("li",{parentName:"ul"},"largest ResNet RN50x64 \ub294 592 V100 GPU \uc5d0\uc11c 18 days training, largest Vision Transformer \ub294 256 V100 GPU \uc5d0\uc11c 12 days training"),(0,i.kt)("li",{parentName:"ul"},"ViT-L/14 \uc758 \uacbd\uc6b0 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uc704\ud574, \ucd94\uac00\ub85c 336 pixel resolution \uc5d0\uc11c \ud55c epoch \ub3d9\uc548 pre-training",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774 \ubaa8\ub378\uc744 ViT-L/14@336px \ub85c \ud45c\uc2dc"))),(0,i.kt)("li",{parentName:"ul"},'\uadf8 \uc678\uc758 \uacbd\uc6b0 "CLIP" \uc73c\ub85c \ubcf4\uace0\ub41c \ubaa8\ub4e0 \uacb0\uacfc\ub294 \uac00\uc7a5 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc900 \uc774 \ubaa8\ub378\uc744 \uc0ac\uc6a9')),(0,i.kt)("h1",{id:"3-experiments"},"3. Experiments"),(0,i.kt)("h2",{id:"31-zero-shot-transfer"},"3.1 Zero-Shot Transfer"),(0,i.kt)("h3",{id:"311-motivation"},"3.1.1 Motivation"),(0,i.kt)("p",null,"vision \uc5d0\uc11c\uc758 zero-shot learning \uc740 unseen object \uc5d0 \ub300\ud55c generalizing \uc5f0\uad6c\ub97c \uc758\ubbf8."),(0,i.kt)("p",null,"\uc800\uc790\ub294 \ub354 \ub113\uc740 \uc758\ubbf8\ub85c unseen dataset \uc73c\ub85c\uc758 generalizing \uc5f0\uad6c\ub97c \ud55c\ub2e4."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Larochelle et al. (2008) \uc758 zero-data learning \ub17c\ubb38\uc5d0\uc11c \ucd94\uad6c\ud558\ub294 \uac83\ucc98\ub7fc unseen task \uc218\ud589\uc744 \uc704\ud55c \ub300\ub9ac\ub85c\uc368\uc758 \uc5ed\ud560"),(0,i.kt)("li",{parentName:"ul"},"unsupervised learning \uc758 \ub9ce\uc740 \uc5f0\uad6c\ub294 ",(0,i.kt)("em",{parentName:"li"},"representation learning")," \ub2a5\ub825\uc5d0 \uc911\uc810\uc744 \ub450\uc9c0\ub9cc, \uc800\uc790\ub294 zero-shot transfer \uc744 \uc5f0\uad6c\ud568\uc73c\ub85c\uc368 ",(0,i.kt)("em",{parentName:"li"},"task-learning")," \ub2a5\ub825\uc744 \uce21\uc815\ud558\ub294 \uac83\uc744 \ub3d9\uae30\ubd80\uc5ec"),(0,i.kt)("li",{parentName:"ul"},"\uc774 \uad00\uc810\uc5d0\uc11c dataset \uc740 specific distribution \uc758 \uc131\ub2a5\uc744 \ud3c9\uac00",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ud558\uc9c0\ub9cc \ub9ce\uc740 vision dataset \uc740 image classification \uc744 \uc9c0\uc6d0\ud558\uae30 \uc704\ud574 \uc5f0\uad6c \uacf5\ub3d9\uccb4\uc5d0 \uc758\ud574 \uc8fc\ub85c \ub9cc\ub4e4\uc5b4\uc84c\uc74c"),(0,i.kt)("li",{parentName:"ul"},"SVHN : Google Street View \uc0ac\uc9c4\uc758 \ubd84\ud3ec\uc5d0\uc11c street number task \ub97c \uce21\uc815"),(0,i.kt)("li",{parentName:"ul"},'CIFAR-10 :\uc5b4\ub5a4 "real" task \ub97c \uce21\uc815\ud558\ub294\uc9c0\ub294 \uba85\ud655\ud558\uc9c0 \uc54a\uc9c0\ub9cc, \ucd94\ucd9c\ub41c \ubd84\ud3ec\ub294 \uba85\ud655 - TinyImages'))),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 dataset \uc5d0\uc11c zero-shot transfer \uc740 CLIP \uc758 distribution shift \ubc0f domain generalization \uc5d0 \ub300\ud55c robustness \ud3c9\uac00\uac00 task generalization \ubcf4\ub2e4 \ub354 \uc911\uc694")),(0,i.kt)("p",null,"\uc800\uc790\ub294 zero-shot transfer \uc744 NLP \uc758 task learning \uc5d0 \uc601\uac10\uc744 \ubc1b\uc74c"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},'language model \ub85c wikipedia document \ub97c \uc0dd\uc131\ud558\ub294 \ud559\uc2b5\uc744 \uc9c4\ud589\ud560 \ub54c \uc774\ub984\uc744 \ub2e4\ub978 \uc5b8\uc5b4\ub85c \ubc88\uc5ed\ud558\ub294 \ub2a5\ub825\uc744 \uac16\ucd94\uac8c \ub418\ub294 "unexpected side-effect" \uc73c\ub85c task learning \uc744 \ucc98\uc74c \uc2dd\ubcc4'),(0,i.kt)("li",{parentName:"ul"},"GPT-1 \uc740 supervised fine-tuning \uac1c\uc120\uc744 \uc704\ud55c transfer learning \uc744 \uc9d1\uc911\ud588\uc9c0\ub9cc, \uc544\ubb34\ub7f0 supervised adaption \uc5c6\uc774\ub3c4 \ub124 \uac00\uc9c0 heuristic zer-shot transfer methods \uc758 \uc131\ub2a5\uc774 \uc9c0\uc18d\uc801\uc73c\ub85c \ud5a5\uc0c1\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5f0\uad6c\ub97c \ud3ec\ud568\ud55c \uc2e4\ud5d8\uc744 \uc218\ud589"),(0,i.kt)("li",{parentName:"ul"},"\uc774 \ubd84\uc11d\uc740 task learning \uc744 \uc804\uc801\uc73c\ub85c \uc5f0\uad6c\ud558\ub294 \ub370 \ucd08\uc810\uc744 \ub9de\ucd98 GPT-2 \uc758 \uae30\ucd08")),(0,i.kt)("h3",{id:"312-using-clip-for-zero-shot-transfer"},"3.1.2 Using CLIP For Zero-Shot Transfer"),(0,i.kt)("p",null,"CLIP \uc740 dataset \uc5d0\uc11c image \uc640 text snippet \uc774 \ud568\uaed8 \uc5f0\uacb0\ub418\uc5b4 \uc788\ub294\uc9c0 \uc608\uce21\ud558\ub3c4\ub85d pre-training"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"zero-shot classification \uc218\ud589\uc744 \uc704\ud574, \uc704 \ub2a5\ub825\uc744 \uc7ac\uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},'\uac01 dataset \uc758 \ubaa8\ub4e0 class name \uc744 potential text pair set \uc73c\ub85c \uc0ac\uc6a9\ud558\uace0 CLIP \uc5d0 \ub530\ub77c most probable (image, text) pair \ub97c \uc608\uce21 (e.g. "A photo of a {class}.")',(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uba3c\uc800 \uac01 image \uc640 possible texts \uc758 feature embedding \uc744 \ud574\ub2f9 encoder \ub85c \uacc4\uc0b0"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7ec\ud55c embedding \uc758 cosine similarity \ub294 temperature parameter ",(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("mi",{parentName:"mrow"},"\u03c4")),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\tau")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.4306em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.1132em"}},"\u03c4")))))," \ub85c scaling \ub418\uace0 softmax \ub97c \ud1b5\ud574 probability distribution \uc73c\ub85c normalizing"),(0,i.kt)("li",{parentName:"ul"},"\uc774 prediction layer \ub294 L2-normalized inputs, L2-normalized weight, no bias \ubc0f temperature scaling \uc778 logistic regression  classifier"))),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub807\uac8c \ud574\uc11d\ud558\uba74 image encoder \ub294 image \uc758 feature representation \uc744 \uacc4\uc0b0\ud558\ub294 vision backbone \uc774\uace0, text encoder \ub294 class \uac00 \ub098\ud0c0\ub0b4\ub294 visual concepts \ub97c \uc9c0\uc815\ud558\ub294 text \uc5d0 \uae30\ubc18\ud55c linear classifier \uc758 weight \ub97c \uc0dd\uc131\ud558\ub294 hypernetwork"),(0,i.kt)("li",{parentName:"ul"},"\uc774 \ud574\uc11d\uc744 \uacc4\uc18d \uc801\uc6a9\ud558\uba74 CLIP pre-training \uc758 \ubaa8\ub4e0 \ub2e8\uacc4\ub97c \ud3ec\ud568\ud558\uc5ec \ubb34\uc791\uc704\ub85c \uc0dd\uc131\ub41c proxy \uc758 \uc131\ub2a5\uc744 \ucd5c\uc801\ud654\ud558\uace0 \ud55c \uc608\uc81c\ub2f9 \ud074\ub798\uc2a4\ub97c \ud3ec\ud568\ud558\uace0 natural language descriptions \uc744 \ud1b5\ud574 \uc815\uc758\ub41c \ucd1d 32,768 total classes \ub97c \ud3ec\ud568\ud558\ub294 vision dataset \uc5d0 \ub300\ud55c CLIP \uc758 \uc131\ub2a5\uc744 \ubcfc \uc218 \uc788\uc74c"),(0,i.kt)("li",{parentName:"ul"},"zero-shot \ud3c9\uac00\ub294 text-encoder \uc5d0 \uc758\ud574 \uacc4\uc0b0\ub41c zero-shot classifier \ub97c \uce90\uc2f1\ud558\uace0 \uc774\ub97c dataset \uc758 \ubaa8\ub4e0 subsequent predictions \uc5d0 \uc7ac\uc0ac\uc6a9\ud569. \uc774\ub97c \ud1b5\ud574 \uc0dd\uc131 \ube44\uc6a9\uc744 dataset \uc758 \ubaa8\ub4e0 \uc608\uce21\uc5d0 \uac78\uccd0 \ubd84\ud560 \uac00\ub2a5")),(0,i.kt)("h3",{id:"313-initial-comparison-to-visual-n-grams"},"3.1.3 Initial Comparison to Visual N-Grams"),(0,i.kt)("p",null,"Tab. 1 \uc5d0\uc11c Visual N-Grams \uc640 CLIP \ube44\uad50"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Table 1",src:t(66666).Z,width:"1360",height:"704"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"best CLIP \uc740 ImageNet \uc758 proof concept \uc758 11.5% to 76.2% \ub85c accuracy \ud5a5\uc0c1",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"1.28M crowd-labeled training examples \ub97c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc74c\uc5d0\ub3c4 original ResNet-50 \uc758 \uc131\ub2a5\uacfc \uc77c\uce58"))),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc758 top-5 accuracy \ub294 top-1 accuracy \ubcf4\ub2e4 \ub69c\ub837\ud558\uac8c \ub192\uc73c\uba70, 95% top-5 accuracy \ub97c \uac00\uc9c0\uba70 Inception-V4 \uc640 \uc77c\uce58",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uac15\ub825\ud55c fully supervised baselines \uc744 zero-shot setting \uc5d0\uc11c \uc77c\uce58\uc2dc\ud0a4\ub294 \ub2a5\ub825\uc740 CLIP \uac00 \uc720\uc5f0\ud558\uace0 \uc2e4\uc6a9\uc801\uc778 zero-shot vision classifier \ub85c\uc758 \uc911\uc694\ud55c \ubc1c\uc804\uc784\uc744 \uc2dc\uc0ac"))),(0,i.kt)("li",{parentName:"ul"},"Visual N-Grams \uc640\uc758 \ube44\uad50\ub294 CLIP \uc758 contextualizing \ud558\uae30 \uc704\ud55c \uac83\uc774\uba70, CLIP \uc640 Visual N-Grams \uc0ac\uc774\uc758 \uc9c1\uc811\uc801\uc778 \ube44\uad50\ub85c \ud574\uc11d\ub418\uc5b4\uc11c\ub294 \uc548\ub428",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774 \ub450 \uc2dc\uc2a4\ud15c \uc0ac\uc774\uc758 \ub9ce\uc740 \uc131\ub2a5 \uad00\ub828 \ucc28\uc774\uc810\uc774 \uc81c\uc5b4\ub418\uc9c0 \uc54a\uc558\uae30 \ub54c\ubb38"),(0,i.kt)("li",{parentName:"ul"},"\uc608\ub85c, \uc800\uc790\ub294 10x larger dataset \uc5d0\uc11c \ud6c8\ub828\ud558\uace0, \uc608\uce21 \ub2f9 \uac70\uc758 100x computing \ud544\uc694\ub85c\ud558\ub294 vision model \uc744 \uc0ac\uc6a9\ud588\uc73c\uba70, \uc544\ub3c4 training computing \ub7c9\uc740 Visual N-Grams \uc758 1000x \uc774\uc0c1\uc77c \uac83"),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub9ac\uace0 Visual N-Grams \uac00 \ubc1c\ud45c\ub420 \ub54c\ub294 \uc874\uc7ac\ud558\uc9c0 \uc54a\uc558\ub358 Transformer \uae30\ubc18 \ubaa8\ub378\uc744 \uc0ac\uc6a9"))),(0,i.kt)("li",{parentName:"ul"},"\uac00\uae4c\uc6b4 \ube44\uad50\ub85c, Visual N-Grams \uac00 \ud6c8\ub828\ub41c YFCC100M dataset \uc5d0\uc11c CLIP ResNet-50 \uc744 \ud6c8\ub828\uc2dc\ud0a4\uace0 \uc774 \ubaa8\ub378\uc774 \ubcf4\uace0\ub41c ImageNet \uc131\ub2a5\uacfc \uc77c\uce58\ud558\ub294 \uac83\uc744 \ubc1c\uacac",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774 \uae30\uc900 \uc131\ub2a5\uc740 Visual N-Grams \ucc98\ub7fc pre-trained ImageNet weight \ub85c \ucd08\uae30\ud654\ub41c \uac83\uc774 \uc544\ub2c8\ub77c scratch training"))),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc740 \ub2e4\ub978 2 reported dataset \uc5d0\uc11c\ub3c4 Visual N-Grams \ub97c \ub2a5\uac00",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Yahoo \uc5d0\uc11c CLIP \ub294 error number \ub97c 95% \uc904\uc774\uace0, SUN \uc5d0\uc120 Visual N-Grams \uc758 accuracy \ub450 \ubc30 \uc774\uc0c1 \ub298\ub9bc"))),(0,i.kt)("li",{parentName:"ul"},"\ub354 \ud3ec\uad04\uc801\uc778 \ubd84\uc11d\uacfc \uc2a4\ud2b8\ub808\uc2a4 \ud14c\uc2a4\ud2b8\ub97c \uc218\ud589\uc744 \uc704\ud574, 30 dataset \uc744 \ud3ec\ud568\ud558\uace0, 50 vision systems \uc640 \ube44\uad50")),(0,i.kt)("h3",{id:"314-prompt-engineering-and-ensembling"},"3.1.4 Prompt Engineering And Ensembling"),(0,i.kt)("p",null,"\ub300\ubd80\ubd84\uc758 standard image classification dataset \uc740 natural language based zero-shot transfer \uc744 \uac00\ub2a5\ucf00\ud558\ub294 class name \uc744 \uc9c0\uc815\ud558\uac70\ub098 \uc124\uba85\ud558\ub294 \uc815\ubcf4\ub97c \ud6c4\uc18d\ucc98\ub9ac\ud55c\ub2e4."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\ub300\ubd80\ubd84 image \ub97c numeric id \ub9cc\uc73c\ub85c annotation \ucc98\ub9ac\ud558\uace0 \uc774 id \ub97c english name \uc73c\ub85c \ub2e4\uc2dc \ub9e4\ud551\ud558\ub294 \ud30c\uc77c \ud3ec\ud568",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Flowers102 \uc640 GTSRB \ub4f1\uc740 zero-shot transfer \uc744 \uc644\uc804\ud788 \ubc29\uc9c0\ud558\uc5ec \uc774\ub7f0 \ub9e4\ud551\uc774 \uc5c6\ub2e4."),(0,i.kt)("li",{parentName:"ul"},"\ub9ce\uc740 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc774\ub7ec\ud55c label \uc740 \ub2e4\uc18c \ubb34\uc791\uc704\ub85c \uc120\ud0dd\ub418\uc5b4 zero-shot transfer \uacfc \uad00\ub828\ub41c \ubb38\uc81c\ub97c \uc608\uc0c1\ud558\uc9c0 \uc54a\uc74c")))),(0,i.kt)("hr",null),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Table 2",src:t(59782).Z,width:"883",height:"633"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uc77c\ubc18\uc801\uc778 \ubb38\uc81c\ub294 \ub2e4\uc758\uc131 (polysemy) \uc774\ub2e4. class name \uc774 CLIP \uc758 text encoder \uc5d0 \uc81c\uacf5\ub41c \uc720\uc77c\ud55c \uc815\ubcf4\uc77c \ub54c, context \ubd80\uc7ac\ub85c \uc5b4\ub5a4 \ub2e8\uc5b4 \uc758\ubbf8\ub97c \uc9c0\uce6d\ud558\ub294\uc9c0 \uad6c\ubd84\ud560 \uc218 \uc5c6\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uacbd\uc6b0\uc5d0 \ub530\ub77c \ub3d9\uc77c\ud55c \ub2e8\uc5b4\uc758 \uc5ec\ub7ec \uc758\ubbf8\uac00 \ub3d9\uc77c\ud55c \ub370\uc774\ud130\uc14b\uc758 \uc11c\ub85c \ub2e4\ub978 \ud074\ub798\uc2a4\ub85c \ud3ec\ud568\ub420 \uc218 \uc788\uc74c"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uac74\uc124 \ud06c\ub808\uc778\uacfc \ube44\ud589\ud558\ub294 \ud06c\ub808\uc778\uc744 \ubaa8\ub450 \ud3ec\ud568\ud558\ub294 ImageNet \uc5d0\uc11c \ubc1c\uc0dd"),(0,i.kt)("li",{parentName:"ul"},"\ub2e4\ub978 \uc608\ub85c\ub294 Oxford-IIIT Pet \uc758 \ud074\ub798\uc2a4. \ubb38\ub9e5\uc5d0\uc11c \uba85\ubc31\ud558\uac8c \uac1c\uc885\uc758 \ud488\uc885\uc744 \uc9c0\uce6d\ud558\uc9c0\ub9cc, \ubb38\ub9e5\uc774 \uc5c6\ub294 text encoder \uc5d0\uac8c\ub294 \uac1c\uc885\uc774\ub77c\ub294 \ub2e8\uc5b4\uac00 \uadf8\ub0e5 \uc885\ub958\uc758 \uc2a4\ud3ec\uce20 \uc120\uc218\uc77c \uc218\ub3c4 \uc788\uc74c"))),(0,i.kt)("li",{parentName:"ul"},"\ub2e4\ub978 \ubb38\uc81c\ub294 pre-training dataset \uc5d0\uc11c image \uc640 \ud568\uaed8 \uc5f0\uacb0\ub41c text \uac00 \uc77c\ubc18\uc801\uc73c\ub85c single word \uac00 \uc544\ub2c8\ub77c\ub294 \uac83",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},'\uc77c\ubc18\uc801\uc73c\ub85c, text \ub294 \uc5b4\ub5a4 \ubc29\uc2dd\uc73c\ub85c\ub4e0 \uc774\ubbf8\uc9c0\ub97c \uc124\uba85\ud558\ub294 \uc804\uccb4 \ubb38\uc7a5. \uc774 distribution gap \uc744 \uc904\uc774\uae30 \uc704\ud574 "A photo of a {label}" \uac19\uc740 prompt template \ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uc774\ubbf8\uc9c0\uc758 \ub0b4\uc6a9\uc5d0 \ub300\ud55c text \uc784\uc744 \uba85\uc2dc\ud558\ub294 good default \uc784\uc744 \ubc1c\uacac'),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub807\uac8c \ud558\uba74 label text \ub9cc \uc0ac\uc6a9\ud558\ub294 baseline \ubcf4\ub2e4 ImageNet \uc758 \uc815\ud655\ub3c4\uac00 1.3% \ud5a5\uc0c1"))),(0,i.kt)("li",{parentName:"ul"},'"prompt engineering" \uc5d0 \ub300\ud574\uc11c\ub294 GPT3 \ucc98\ub7fc \uac01 task \uc5d0 \ub300\ud55c prompt text \ub97c \uc0ac\uc6a9\uc790 \uc815\uc758\ud558\uc5ec zero-shot \uc131\ub2a5\uc744 \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \ubc1c\uacac',(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"image classification dataset \uc5d0\uc11c \uce74\ud14c\uace0\ub9ac \uc9c0\uc815\uc774 \ub3c4\uc6c0\uc774 \ub428",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},'\uc608\ub85c, Oxford-IIIT Pets \uc5d0\uc11c "A photo of a {label}, a type of pet." \uc744 \uc0ac\uc6a9\ud558\uc5ec context \ub97c \uc81c\uacf5\ud558\ub294 \uac83\uc774 \uc798 \uc791\ub3d9'),(0,i.kt)("li",{parentName:"ul"},"Food101 \uc5d0\uc120 \uc74c\uc2dd \uc720\ud615\uc744 \uc9c0\uc815\ud558\uace0, FGVC Aircraft \uc5d0\uc120 \ud56d\uacf5\uae30 \uc720\ud615\uc744 \uc9c0\uc815\ud558\ub294 \uac83\uc774 \ub3c4\uc6c0"),(0,i.kt)("li",{parentName:"ul"},"OCR \uc5d0\uc120 \ud14d\uc2a4\ud2b8\ub098 \uc22b\uc790 \uc8fc\uc704\uc5d0 \ub530\uc634\ud45c\ub97c \ub123\ub294 \uac83\uc774 \uc131\ub2a5\uc744 \ud5a5\uc0c1"),(0,i.kt)("li",{parentName:"ul"},'\ub9c8\uc9c0\ub9c9\uc73c\ub85c, \uc704\uc131 \uc774\ubbf8\uc9c0 \ubd84\ub958 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc774\ubbf8\uc9c0\uac00 \uc774\ub7ec\ud55c \ud615\uc2dd\uc758 \uac83\uc784\uc744 \uba85\uc2dc\ud558\ub294 \uac83\uc774 \ub3c4\uc6c0\uc774 \ub418\uc5c8\uc73c\uba70 "a satellite photo of a {label}" \uc758 \ubcc0\ud615\uc744 \uc0ac\uc6a9'))))),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub2e4\ub978 \ubc29\ubc95\uc73c\ub85c \uc5ec\ub7ec zero-shot classifier \ub97c ensemble \uc744 \uc2dc\ub3c4",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},'\uc774\ub7ec\ud55c classfier \ub294 "A photo of a big {label}" \uacfc "A photo of a small {label}" \uac19\uc740 \ub2e4\ub978 context prompt \ub97c \uc0ac\uc6a9\ud558\uc5ec \uacc4\uc0b0'),(0,i.kt)("li",{parentName:"ul"},"probability space \uac00 \uc544\ub2cc embedding space \uc5d0\uc11c ensemble \uad6c\uc131",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub97c \ud1b5\ud574 computing cost \ub97c \ub9ce\uc740 \uc608\uce21\uc5d0 \uac78\uccd0 \ubd84\ud560\ud560 \ub54c \uc559\uc0c1\ube14\uc758 \uacc4\uc0b0 \ube44\uc6a9\uc774 single classifier \uc0ac\uc6a9\ud558\ub294 \uac83\uacfc \ub3d9\uc77c\ud574\uc9d0"))),(0,i.kt)("li",{parentName:"ul"},"\uc800\uc790\ub294 many generated zero-shot classifier \ub97c \uac70\uce5c \uc559\uc0c1\ube14\uc744 \ud1b5\ud574 \uc2e0\ub8b0\ud560 \uc218 \uc788\ub294 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uad00\ucc30\ud588\uc73c\uba70 \ub300\ubd80\ubd84\uc758 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 \uc774\ub97c \uc0ac\uc6a9",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"ImageNet \uc5d0\uc120 80 different context prompts \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc559\uc0c1\ube14\uc744 \uad6c\uc131\ud558\uba70, \uc704 \uc124\uba85\uc778 single default prompt \ubcf4\ub2e4 3.5% \ucd94\uac00 \uc131\ub2a5 \ud5a5\uc0c1"))),(0,i.kt)("li",{parentName:"ul"},"\uc885\ud569\uc801\uc73c\ub85c, \ud504\ub86c\ud504\ud2b8 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1\uacfc \uc559\uc0c1\ube14\ub9c1\uc740 ImageNet \uc758 \uc815\ud655\ub3c4\ub97c \uac70\uc758 5% \ud5a5\uc0c1"),(0,i.kt)("li",{parentName:"ul"},"Fig. 4 \uc5d0\uc11c \ud504\ub86c\ud504\ud2b8 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1\uacfc \uc559\uc0c1\ube14\ub9c1\uc774 \ucee8\ud14d\uc2a4\ud2b8 \uc5c6\ub294 baseline \uc5d0 \ube44\ud574 CLIP \ubaa8\ub378\uc758 \uc77c\ub828\uc758 \uc131\ub2a5\uc744 \uc5b4\ub5bb\uac8c \ubcc0\ud654\uc2dc\ud0a4\ub294\uc9c0\ub97c \uc2dc\uac01\ud654")))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 4",src:t(82646).Z,width:"1407",height:"1781"})),(0,i.kt)("h3",{id:"315-analysis-of-zero-shot-clip-performance"},"3.1.5 Analysis of Zero-Shot CLIP Performance"),(0,i.kt)("p",null,"CLIP zero-shot classifier \uc758 \uc5ec\ub7ec \ud2b9\uc131\uc744 \uc5f0\uad6c"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 5",src:t(78707).Z,width:"1407",height:"1781"})),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"zero-shot classifier \uc758 \uc131\ub2a5\uc744 \uc0b4\ud3b4\ubd04",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"simple off-the-shelf baseline: ResNet-50 \uc758 feature \uc5d0 fitting fully supervised, regularized, logistic regression classifier \uc5d0 \uad50\ucc28 \uac80\uc99d"),(0,i.kt)("li",{parentName:"ul"},"Fig. 5 \uc5d0\uc11c 27 dataset \uc5d0\uc11c \ube44\uad50"),(0,i.kt)("li",{parentName:"ul"},"Zero-shot CLIP \uc774 baseline \ubcf4\ub2e4 \ub354 \uc790\uc8fc \uc131\ub2a5\uc774 \uc6b0\uc218. 16 dataset \uc5d0\uc11c \uc6b0\uc2b9"),(0,i.kt)("li",{parentName:"ul"},"individual datasets \ub97c \uc0b4\ud3b4\ubcf4\uba74 \uba87 \uac00\uc9c0 \ud765\ubbf8\ub85c\uc6b4 \ub3d9\uc791\uc774 \uad00\ucc30",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"fine-grained classification tasks \uc5d0\uc11c \uc131\ub2a5\uc5d0 \ud070 \ucc28\uc774\uac00 \uc788\uc74c\uc744 \uc54c \uc218 \uc788\uc74c"),(0,i.kt)("li",{parentName:"ul"},"Stanford Cars \ubc0f Food101 \uc5d0\uc11c zero-shot CLIP \uc740 ResNet-50 \ud2b9\uc131\uc758 logisitc regression \ubcf4\ub2e4 20% \uc774\uc0c1 \uc6b0\uc218\ud55c \ubc18\uba74, \ub2e4\ub978 2 dataset \uc778 Flowers102 \ubc0f FGVCAircraft \uc5d0\uc120 10% \uc774\uc0c1 \uc131\ub2a5\uc774 \ub5a8\uc5b4\uc9d0"),(0,i.kt)("li",{parentName:"ul"},"OxfordPets \ubc0f Birdsnap \uc5d0\uc120 \uc131\ub2a5\uc740 \ud6e8\uc52c \ube44\uc2b7"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 \ucc28\uc774\ub294 WIT \uc640 ImageNet \uac04\uc758 \ub2e4\uc591\ud55c \uc218\uc900\uc758 task supervision \uc774 \uc8fc\ub41c \uc774\uc720\ub85c \ucd94\uce21"),(0,i.kt)("li",{parentName:"ul"},'"general" opbject classification dataset \uc778 ImageNet, CIFAR10/100, STL10 \ubc0f PascalVOC2007 \uc758 \uc131\ub2a5\uc740 \ubaa8\ub450 \ube44\uad50\uc801 \uc720\uc0ac\ud558\uba70 \ubaa8\ub4e0 \uacbd\uc6b0\uc5d0\uc11c zero-shot CLIP \uc5d0 \uc57d\uac04\uc758 \uc774\uc810\uc774 \uc788\uc74c'))),(0,i.kt)("li",{parentName:"ul"},"STL10 \uc5d0\uc120 CLIP \uc740 \uc804\uccb4\uc801\uc73c\ub85c 99.3% \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud558\uc5ec \ud6c8\ub828 \uc608\uc81c\ub97c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc740 SOTA \uc218\uc900\uc778 \uac83\uc73c\ub85c \ubcf4\uc784"),(0,i.kt)("li",{parentName:"ul"},"zero-shot CLIP \ub294 \ube44\ub514\uc624\uc5d0\uc11c \ud589\ub3d9 \uc778\uc2dd\uc744 \uce21\uc815\ud558\ub294 2 dataset \uc5d0\uc11c ResNet-50 \ubcf4\ub2e4 \ub192\uc740 \uc131\ub2a5\uc744 \ubcf4\uc784"),(0,i.kt)("li",{parentName:"ul"},"Kinetics700 \uc5d0\uc11c CLIP \ub294 ResNet-50 \ubcf4\ub2e4 14.5% \uc6b0\uc218\ud55c \uc131\ub2a5, UCF101 \uc5d0\uc11c ResNet-50 \ubcf4\ub2e4 7.7% \uc6b0\uc218\ud55c \uc131\ub2a5",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uba85\uc0ac \uc911\uc2ec\uc758 object supervision \uacfc \ube44\uad50\ud558\uc5ec \ub3d9\uc0ac\ub97c \ud3ec\ud568\ud558\ub294 visual concept \uc790\uc5f0\uc5b4\uac00 \ub113\uc740 supervision \uc744 \uc81c\uacf5\ud558\ubbc0\ub85c \ucd94\uc815"))),(0,i.kt)("li",{parentName:"ul"},"zero-shot CLIP \uac00 \ub69c\ub837\ud558\uac8c \uc131\ub2a5\uc774 \ub5a8\uc5b4\uc9c0\ub294 \uc601\uc5ed\uc744 \uc0b4\ud3b4\ubcf4\uc790",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"zero-shot CLIP \uac00 \uc704\uc131 \uc774\ubbf8\uc9c0 \ubd84\ub958 (EuroSAT \ubc0f RESISC45), \ub9bc\ud504 \uacb0\uc808 \uc885\uc591 \uac10\uc9c0 (PatchCamelyon), \ud569\uc131 \uc7a5\uba74\uc5d0\uc11c \ubb3c\uccb4 \uc218 \uacc4\uc0b0 (CLEVRCounts), \uc790\uc728 \uc8fc\ud589 \uad00\ub828 \uc791\uc5c5 (GTSRB), \uac00\uc7a5 \uac00\uae4c\uc6b4 \uc790\ub3d9\ucc28\uae4c\uc9c0\uc758 \uac70\ub9ac \uc778\uc2dd (KITTI Distance)\uacfc \uac19\uc774 \ud2b9\ud654\ub41c, \ubcf5\uc7a1\ud55c \ub610\ub294 \ucd94\uc0c1\uc801\uc778 task \uc5d0 \uc0c1\ub2f9\ud788 \uc57d\ud568"),(0,i.kt)("li",{parentName:"ul"},"\uc774 \uacb0\uacfc\ub294 \ub354 \ubcf5\uc7a1\ud55c \uc791\uc5c5\uc5d0 \ub300\ud55c zero-shot CLIP \uc758 \ub2a5\ub825\uc774 \ubd80\uc871\ud568\uc744 \uac15\uc870"),(0,i.kt)("li",{parentName:"ul"},"\ub300\uc870\uc801\uc73c\ub85c, non-expert humans \ub294 \uba87 \uac00\uc9c0 \uc791\uc5c5, \uc608\ub97c \ub4e4\uc5b4 \uacc4\uc0b0, \uc704\uc131 \uc774\ubbf8\uc9c0 \ubd84\ub958 \ubc0f \uad50\ud1b5 \uc2e0\ud638 \uc778\uc2dd\uacfc \uac19\uc740 \uc791\uc5c5\uc744 \uac15\ub825\ud558\uac8c \uc218\ud589\ud560 \uc218 \uc788\uc73c\ubbc0\ub85c \ud5a5\ud6c4 \uac1c\uc120\uc758 \ub9ce\uc740 \uc5ec\uc9c0\uac00 \uc788\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac"),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 \uc6b0\ub9ac\ub294 \uac70\uc758 \ubaa8\ub4e0 \uc778\uac04 (\ubc0f \uac00\ub2a5\uc131 \uc788\ub294 CLIP)\uc5d0\uac8c \uc0ac\uc804 \uacbd\ud5d8\uc774 \uc5c6\ub294 \ub9bc\ud504 \uacb0\uc808 \uc885\uc591 \ubd84\ub958\uc640 \uac19\uc740 \uc5b4\ub824\uc6b4 task \uc5d0 \ub300\ud55c zero-shot transfer \uc744 \uce21\uc815\ud558\ub294 \uac83\uc774 \uc758\ubbf8\uac00 \uc788\ub294\uc9c0 \uc5ec\ubd80\ub294 \uba85\ud655\ud558\uc9c0 \uc54a\uc74c")))))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 6",src:t(36762).Z,width:"1407",height:"1851"})),(0,i.kt)("ol",{start:2},(0,i.kt)("li",{parentName:"ol"},"1 \uc5d0\uc11c zero-shot \uc744 fully supervised model \uacfc \ube44\uad50\ud558\ub294 \ud55c\ud3b8, 2 \uc5d0\uc120 few-shot \ube44\uad50",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fig. 6 \uc5d0\uc11c zero-shot CLIP \uac00 best ImageNet model, self-supervised learning \ubc0f CLIP \uc790\uccb4\ub97c \ud3ec\ud568\ud55c \uc5ec\ub7ec image model \uc758 feature \uc5d0 \ub300\ud55c few-shot logistic regression \uacfc \ube44\uad50\ud55c \uacb0\uacfc\ub97c \uc2dc\uac01\ud654"),(0,i.kt)("li",{parentName:"ul"},"zero-shot \uc774 1-shot \ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub5a8\uc5b4\uc9c8 \uac83\uc73c\ub85c \uc9c1\uad00\uc801\uc73c\ub85c \uae30\ub300\ub418\uc9c0\ub9cc, \uc2e4\uc81c\ub85c 4-shot logistic regression \uc131\ub2a5\uacfc \uc77c\uce58"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 zero-shot \uacfc few-shot \ubc29\uc2dd \uc0ac\uc774\uc758 \uc8fc\uc694 \ucc28\uc774 \ub54c\ubb38",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uba3c\uc800, CLIP \uc758 zero-shot classifier \ub294 visual concepts \ub97c \uc9c1\uc811 \uc9c0\uc815\ud560 \uc218 \uc788\ub294(\u201c\u201ccommunicated\u201d\u201d) natural language \ub97c \ud1b5\ud574 \uc0dd\uc131"),(0,i.kt)("li",{parentName:"ul"},'\ubc18\uba74, "normal" supervised learning \uc740 training example \uc5d0\uc11c visual concepts \ub97c \uac04\uc811\uc801\uc73c\ub85c \ucd94\ub860\ud574\uc57c \ud568'),(0,i.kt)("li",{parentName:"ul"},"context-less example-based learning \uc740 \ub9ce\uc740 \ub2e4\ub978 \uac00\uc124\uc774 \ub370\uc774\ud130\uc640 \uc77c\uad00\ub420 \uc218 \uc788\uc73c\uba70, \ud2b9\ud788 1-shot \uc758 \uacbd\uc6b0\ub294 \ub354 \uadf8\ub7fc"),(0,i.kt)("li",{parentName:"ul"},"single image \ub294 \uc885\uc885 \ub9ce\uc740 \ub2e4\ub978 visual concept \ub97c \ud3ec\ud568"),(0,i.kt)("li",{parentName:"ul"},"capable learner \ub294 visual cues \uc640 heuristics \ub97c \ud65c\uc6a9\ud560 \uc218 \uc788\uc9c0\ub9cc, \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc2dc\uc5f0\ub418\ub294 \uac1c\ub150\uc774 \uc8fc\uc694 \uac1d\uccb4\uc784\uc744 \uac00\uc815\ud558\ub294 \ub4f1\uc758 \ubcf4\uc7a5\uc740 \uc5c6\uc74c"))),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 zero-shot \uacfc few-shot \uc131\ub2a5\uc758 \ucc28\uc774\ub97c \ud574\uc18c\ud558\ub294 \uc7a0\uc7ac\uc801\uc778 \ubc29\ubc95\uc740 few-shot classifier \uc758 weights \uc5d0 \ub300\ud55c CLIP \uc758 zero-shot classifier \ub97c \uc0ac\uc804 \uc815\ubcf4\ub85c \uc0ac\uc6a9\ud558\ub294 \uac83",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc9c1\uc811\uc801\uc778 \uad6c\ud604\uc73c\ub85c\ub294 \uc0dd\uc131\ub41c \uac00\uc911\uce58\uc5d0 \ub300\ud55c L2 penalty \ub97c \ucd94\uac00\ud558\ub294 \uac83\uc774\uc9c0\ub9cc, \uc774 regularizer \uac12\uc774 \ub108\ubb34 \ud070 \uacbd\uc6b0 few-shot classifier \ub294 zero-shot classifier \uac00 \ub420 \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \ubc1c\uacac"),(0,i.kt)("li",{parentName:"ul"},"\ub2e4\ub978 \ubaa8\ub378\uc758 \ud2b9\uc131\uc5d0\uc11c zero-shot CLIP \uacfc few-shot logistic regression \uc744 \ube44\uad50\ud560 \ub54c, CLIP \ub294 \ucd5c\uace0\uc758 \uc131\ub2a5\uc744 \ubc1c\ud718\ud558\ub294 16-shot classifier \uc640 \uac70\uc758 \uac19\uc740 \uc131\ub2a5\uc744 \ubcf4\uc784")))))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 7",src:t(36562).Z,width:"1407",height:"1783"})),(0,i.kt)("ol",{start:3},(0,i.kt)("li",{parentName:"ol"},"\uac1c\ubcc4 \ub370\uc774\ud130\uc14b\uc5d0\uc11c\uc758 \uc131\ub2a5\ub3c4 \uc870\uc0ac",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fig. 7 \uc5d0\uc11c zero-shot CLIP \uc131\ub2a5\uc744 \ub9de\ucd94\uae30 \uc704\ud574 \ub3d9\uc77c\ud55c feature space \uc5d0\uc11c logistic regression classifier \uac00 \ud544\uc694\ub85c\ud558\ub294 \ud074\ub798\uc2a4 \ub2f9 labeled example \uc218\uc758 \ucd94\uc815\uce58\ub97c \ubcf4\uc5ec\uc90c"),(0,i.kt)("li",{parentName:"ul"},"zero-shot CLIP \ub3c4 linear classifier \uc774\ubbc0\ub85c, \uc774\ub7f0 setting \uc5d0\uc11c zero-shot transfer \uc758 \ud6a8\uc728\uc131\uc744 \ucd94\uc815",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc218\ucc9c \uac1c\uc758 linear classifier training \uc744 \ud53c\ud558\uae30 \uc704\ud574 1, 2, 4, 8, 16-shot, \uadf8\ub9ac\uace0 \uac01 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud6c8\ub828\ub41c fully supervised linear classifier \uc758 \uc131\ub2a5\uc744 log-linear interpolation \uae30\ubc18\uc73c\ub85c \ucd94\uc815"),(0,i.kt)("li",{parentName:"ul"},"zero-shot transfer \ub294 dataset \ub9c8\ub2e4 \ub9e4\uc6b0 \ub2e4\uc591\ud55c \ud6a8\uc728\uc131\uc744 \ub098\ud0c0\ub0bc \uc218 \uc788\uc73c\uba70, class \ub2f9 1 labeled example \ubd80\ud130 184 \uae4c\uc9c0 \ubc94\uc704\uac00 \uc788\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Flowers102 \ubc0f EuroSAT \uc740 1-shot model \uc744 \ubcf4\ub2e4 \ub4a4\uccd0\uc9d0"),(0,i.kt)("li",{parentName:"ul"},"dataset \uc808\ubc18\uc740 class \ub2f9 less 5 example \uc774 \ud544\uc694\ud558\uba70, \ud3c9\uade0\uc740 5.4"),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 mean estimated data efficiency \ub294 class \ub2f9 \ud3c9\uade0 20.8 example"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 supervised classifier \uac00 \ub9ce\uc740 labeled example \uc744 \ud544\uc694\ub85c\ud558\ub294 \ub370\uc774\ud130\uc14b\uc758 20% \ub54c\ubb38"))),(0,i.kt)("li",{parentName:"ul"},"ImageNet \uc5d0\uc120 zero-shot CLIP \uac00 16-shot linear classifier trained on same feature space \uc640 \uc77c\uce58")))))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 8",src:t(27978).Z,width:"1472",height:"1779"})),(0,i.kt)("ol",{start:4},(0,i.kt)("li",{parentName:"ol"},"evaluate dataset \uc774 linear classifier parameter \ub85c \uc798 \ucd94\uc815\ub41c\ub2e4 \uac00\uc815\ud558\uba74, CLIP \uc758 zero-shot classifier \ub3c4 linear classifier \uc131\ub2a5\uc73c\ub85c setting \ud558\uace0 \uc788\uc73c\ubbc0\ub85c, fully supervised classifier \uc131\ub2a5\uc740 zero-shot transfer \uc774 \ub2ec\uc131 \uac00\ub2a5\ud55c \uc0c1\ud55c\uc744 \ub300\ub7b5 \uc124\uc815\ud55c\ub2e4.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\uc5d0 Fig. 8 \uc5d0\uc11c CLIP \uc758 zero-shot \uc131\ub2a5\uc744 dataset \ubcc4\ub85c fully supervised linear classifier \uc640 \ube44\uad50"),(0,i.kt)("li",{parentName:"ul"},"dosh line ",(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("mi",{parentName:"mrow"},"y"),(0,i.kt)("mo",{parentName:"mrow"},"="),(0,i.kt)("mi",{parentName:"mrow"},"x")),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"y = x")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.625em",verticalAlign:"-0.1944em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.03588em"}},"y"),(0,i.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.kt)("span",{parentName:"span",className:"mrel"},"="),(0,i.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.4306em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"))))),' \uc740 "optimial" zero-shot classifier \uc744 \ub098\ud0c0\ub0c4'),(0,i.kt)("li",{parentName:"ul"},"\ub300\ubd80\ubd84\uc758 dataset \uc5d0\uc11c zero-shot classifier \uc758 \uc131\ub2a5\uc740 \uc5ec\uc804\ud788 fully supervised classifier \ubcf4\ub2e4 10% ~ 25% \uc815\ub3c4 \ub5a8\uc5b4\uc9c0\ubbc0\ub85c, CLIP \uc758 task-learning \ubc0f zero-shot transfer \ub2a5\ub825\uc744 \uac1c\uc120\ud560 \uc5ec\uc9c0\uac00 \ub9ce\uc774 \ub0a8\uc544 \uc788\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac"),(0,i.kt)("li",{parentName:"ul"},"zero-shot \uc131\ub2a5\uacfc fully supervised \uc131\ub2a5 \uc0ac\uc774\uc5d0\ub294 0.82 \uc758 positive correlation \uc774 \uc788\uc73c\uba70 (p-value < ",(0,i.kt)("span",{parentName:"li",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("mn",{parentName:"mrow"},"1"),(0,i.kt)("msup",{parentName:"mrow"},(0,i.kt)("mn",{parentName:"msup"},"0"),(0,i.kt)("mrow",{parentName:"msup"},(0,i.kt)("mo",{parentName:"mrow"},"\u2212"),(0,i.kt)("mn",{parentName:"mrow"},"6")))),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"10^{-6}")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8141em"}}),(0,i.kt)("span",{parentName:"span",className:"mord"},"1"),(0,i.kt)("span",{parentName:"span",className:"mord"},(0,i.kt)("span",{parentName:"span",className:"mord"},"0"),(0,i.kt)("span",{parentName:"span",className:"msupsub"},(0,i.kt)("span",{parentName:"span",className:"vlist-t"},(0,i.kt)("span",{parentName:"span",className:"vlist-r"},(0,i.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,i.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,i.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,i.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,i.kt)("span",{parentName:"span",className:"mord mtight"},(0,i.kt)("span",{parentName:"span",className:"mord mtight"},"\u2212"),(0,i.kt)("span",{parentName:"span",className:"mord mtight"},"6"))))))))))))),"), \uc774\ub294 CLIP \uac00 underlying representation \uacfc task-learning \uc744 zero-shot transfer \uc5d0 \uc0c1\ub300\uc801\uc73c\ub85c \uc77c\uad00\ub418\uac8c \uc5f0\uacb0\ud558\ub294 \uacbd\ud5a5\uc774 \uc788\uc74c\uc744 \uc2dc\uc0ac"),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 zero-shot CLIP \uc740 5 dataset \uc5d0\uc11c\ub9cc fully supervised \uc131\ub2a5\uc5d0 \uc811\uadfc: STL10, CIFAR10, Food101, OxfordPets \ubc0f Caltech101",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774 dataset \uc5d0\uc11c zero-shot accuracy \uc640 fully supervised accuracy \ubaa8\ub450 90% \uc774\uc0c1"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 CLIP \uac00 underlying representation \uc774 high quality task \uc5d0 \ub300\ud574 zero-shot transfer \uc774 \ub354 \ud6a8\uacfc\uc801\uc77c \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac"),(0,i.kt)("li",{parentName:"ul"},"zero-shot \uc131\ub2a5\uc758 \uc99d\uac00\uc5d0 \ub300\ud55c linear regression model \uc758 slope \uc744 \uacc4\uc0b0\ud558\uba74, fully supervised \uc131\ub2a5\uc744 \uae30\uc900\uc73c\ub85c zero-shot \uc131\ub2a5\uc774 1.28% \uac1c\uc120"),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 95th-percentile confidence intervals \ub294 1 \ubbf8\ub9cc\uc758 \uac12\ub3c4 \ud3ec\ud568(0.93-1.79)")))))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 9",src:t(51528).Z,width:"1514",height:"1561"})),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"\uba87 \ub144\uac04 dataset \ud06c\uae30\uc640 \uc591\uc5d0 \ub300\ud55c \uc131\ub2a5 \uc608\uce21\uc774 \uac00\ub2a5. GPT \uacc4\uc5f4 \ubaa8\ub378\uc740 \uc9c0\uae08\uae4c\uc9c0 training computing cost 1000x \uc99d\uac00\uc5d0 \ub530\ub77c zero-shot \uc131\ub2a5\uc774 \uc77c\uad00\ub418\uac8c \ud5a5\uc0c1",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fig. 9 \uc5d0\uc11c CLIP \uc758 zero-shot \uc131\ub2a5\uc774 \ube44\uc2b7\ud55c \ube44\uc728\ub85c \uc99d\uac00\ud558\ub294\uc9c0 \ud655\uc778"),(0,i.kt)("li",{parentName:"ul"},"39 evaluation \uc744 \uac78\uccd0 36 dataset \uc5d0\uc11c 5\uac1c\uc758 ResNet CLIP \ubaa8\ub378\uc758 average error rate \ub97c plot \ud558\uace0, CLIP \uc774 44x \uc99d\uac00\ud558\ub294 model computing \uc5d0 \ub300\ud574 \ube44\uc2b7\ud55c log-log linear scaling \uacbd\ud5a5\uc774 \uc720\uc9c0\ub418\ub294 \uac83\uc744 \ubc1c\uacac"),(0,i.kt)("li",{parentName:"ul"},"\uc804\ubc18\uc801\uc778 \uacbd\ud5a5\uc740 \ubd80\ub4dc\ub7fd\uc9c0\ub9cc, \uac1c\ubcc4 \ud3c9\uac00\uc758 \uc131\ub2a5\uc740 \ud6e8\uc52c \ub354 \ubd88\uc548\uc815",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 individual training runs on sub-tasks \uac04\uc758 high variance \uc5d0 \uc758\ud55c \uac83\uc778\uc9c0 \uafb8\uc900\ud788 \ud5a5\uc0c1\ub418\ub294 \uacbd\ud5a5\uc744 \uac00\ub824\uc8fc\ub294 \uac83\uc778\uc9c0 \ub610\ub294 \uc131\ub2a5\uc774 \uc2e4\uc81c\ub85c \uc77c\ubd80 task \uc5d0\uc11c computing function \uc73c\ub85c\uc11c non-monotonic \uc77c \uc218 \uc788\uc74c")))))),(0,i.kt)("h2",{id:"32-representation-learning"},"3.2 Representation Learning"),(0,i.kt)("p",null,"zero-shot \ubd84\uc11d\uc744 \ud588\uc9c0\ub9cc representation \ub2a5\ub825 \uc5f0\uad6c\uac00 \ub354 \uc77c\ubc18\uc801\uc774\ub2e4."),(0,i.kt)("p",null,'"ideal" representation \uc774 \uac00\uc838\uc57c \ud560 \uc18d\uc131\uc5d0 \ub300\ud55c \uc758\uacac\uc774 \ub2e4\ub974\uba70, representation \uc758 quality \ub97c \ud3c9\uac00\ud558\ub294 \ub9ce\uc740 \ubc29\ubc95\uc774 \uc874\uc7ac'),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"representation \uc744 linear classification \uc5d0 fitting \ud558\uace0 \ub2e4\uc591\ud55c dataset \uc5d0 \uc131\ub2a5\uc744 \uce21\uc815\ud558\ub294 \uac83\uc774 \uc77c\ubc18\uc801\uc778 \uc811\uadfc"),(0,i.kt)("li",{parentName:"ul"},"\ub300\uc548\uc73c\ub85c \ubaa8\ub378\uc758 end-to-end fine-tuning \uc131\ub2a5\uc744 \uce21\uc815",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uc720\uc5f0\uc131\uc744 \ub192\uc774\uba70, \uc774\uc804 \uc5f0\uad6c\uc5d0\uc11c fine-tuning \uc774 \ub300\ubd80\ubd84\uc758 image classification dataset \uc5d0\uc11c linear classification \ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90c")))),(0,i.kt)("p",null,"fine-tuning \uc758 \ub192\uc740 \uc131\ub2a5\uc740 \uc2e4\uc6a9\uc801\uc774\uc9c0\ub9cc, \uc800\uc790\ub294 linear classifier \uae30\ubc18 \ud3c9\uac00."),(0,i.kt)("p",null,"\uc800\uc790\ub294 high-performing task \ubc0f dataset \uc5d0 \uc911\ub9bd\uc801\uc778 pre-trainng \ubc29\uc2dd\uc5d0 \uc911\uc810\uc744 \ub454\ub2e4."),(0,i.kt)("p",null,"fine-tuning \uc740 \uac01 dataset \uc5d0 representation \uc744 \uc801\uc751\uc2dc\ucf1c \uc77c\ubc18\uc801\uc774\uace0 \uacac\uace0\ud55c prepresentation \uc744 \ud559\uc2b5\uc5d0 \uc2e4\ud328\ud560 \uc218 \uc788\ub294 \ud55c\ud3b8, linear classifier \ub294 \uc720\uc5f0\uc131\uc774 \uc81c\ud55c\ub418\uc5b4 \uc774\ub7f0 \uc2e4\ud328\ub97c \uac1c\ubc1c \uc911\uc5d0 \ud53c\ub4dc\ubc31 \uac00\ub2a5"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"CLIP \uc758 \uacbd\uc6b0 supervised linear classifier training \uc774 zero-shot classifier \uc5d0 \uc0ac\uc6a9\ub41c \ubc29\ubc95\uacfc \ub9e4\uc6b0 \uc720\uc0ac\ud558\uae30 \ub54c\ubb38\uc5d0 \uad11\ubc94\uc704\ud55c \ube44\uad50\uc640 \ubd84\uc11d \uac00\ub2a5"),(0,i.kt)("li",{parentName:"ul"},"\ub9c8\uc9c0\ub9c9\uc73c\ub85c, \ub9ce\uc740 task \uc5d0 \uac78\uccd0 CLIP \ub97c \ub2e4\uc591\ud55c baseline model \uacfc \ube44\uad50\ud558\uae30\ub97c \ubaa9\ud45c"),(0,i.kt)("li",{parentName:"ul"},"27 dataset \uc5d0\uc11c 66 models \ub97c \uc5f0\uad6c\ud558\ub294 \uac83\uc740 1782\uac00\uc9c0 \ub2e4\ub978 \ud3c9\uac00\ub97c \uc870\uc728\ud558\ub294 \uac83\uc744 \uc694\uad6c"),(0,i.kt)("li",{parentName:"ul"},"fine-tuning \uc758 largeer design \ubc0f hyperparameter \ub85c\uc11c \uacf5\uc815\ud55c \ud3c9\uac00\uac00 \uc5b4\ub824\uc6b4 \ubc18\uba74, linear classifier \ub294 \ucd5c\uc18c\ud55c\uc758 hyperparameter tuning \ub9cc \ud544\uc694\ud558\uc5ec \ud45c\uc900\ud654\ub41c \uad6c\ud604\uacfc \ud3c9\uac00\uac00 \uc788\uc74c")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 10",src:t(8840).Z,width:"2044",height:"1590"})),(0,i.kt)("p",null,"Fig. 10 \uc740 \uc800\uc790\uc758 \ubc1c\uacac\uc774\uba70, confirmation \ub610\ub294 reporting bias \uc758 \uc6b0\ub824\ub97c \ucd5c\uc18c\ud654\ud558\uae30 \uc704\ud574 12 dataset \uc5d0\uc11c \uc131\ub2a5 \uc5f0\uad6c"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"ResNet-50 \ubc0f ResNet-101 \uac19\uc740 small CLIP \uc740 \ub2e4\ub978 ResNet (BiT-S \ubc0f original) trained on ImageNet-1K \ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubc1c\ud718\ud558\uc9c0\ub9cc, ResNet (BiT-S) trained on ImageNet-21K (BiT-M) \ubcf4\ub2e4\ub294 \uc131\ub2a5\uc774 \ub0ae\ub2e4",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 small CLIP \uc740 \uc720\uc0ac\ud55c \uacc4\uc0b0 \uc694\uad6c \uc0ac\ud56d\uc744 \uac16\ub294 EfficientNet family \ubcf4\ub2e4\ub3c4 \uc131\ub2a5\uc774 \ub0ae\ub2e4"),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 CLIP \ub85c \ud6c8\ub828\ub41c \ubaa8\ub378\uc740 \ub9e4\uc6b0 \uc798 \ud655\uc7a5\ub418\uba70, \uc6b0\ub9ac\uac00 \ud6c8\ub828\ud55c \uac00\uc7a5 \ud070 \ubaa8\ub378 (ResNet-50x64)\uc740 \ucd1d \uc810\uc218 \ubc0f \ucef4\ud4e8\ud305 \ud6a8\uc728\uc131 \uce21\uba74\uc5d0\uc11c \ucd5c\uc0c1\uc758 \uae30\uc874 \ubaa8\ub378 (Noisy Student EfficientNet-L2)\uc744 \uc57d\uac04 \ub2a5\uac00"),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c, CLIP vision transformer \ub294 CLIP ResNet \ubcf4\ub2e4 \uc57d 3\ubc30 \ub354 \ucef4\ud4e8\ud305 \ud6a8\uc728\uc801\uc774\uba70, \uc774\ub294 \uc6b0\ub9ac\uc758 \ucef4\ud4e8\ud305 \uc608\uc0b0 \ub0b4\uc5d0\uc11c \ub354 \ub192\uc740 \uc804\ubc18\uc801\uc778 \uc131\ub2a5\uc744 \ub2ec\uc131"),(0,i.kt)("li",{parentName:"ul"},"best model \uc740 1 additional epoch \ub3d9\uc548 dataset \uc744 336 pixels fine-tuned ViT-L/14 \uc774\ub2e4. "),(0,i.kt)("li",{parentName:"ul"},"\uc774 \ubaa8\ub378\uc740 \uc774 evaluation suite \uc804\ubc18\uc5d0 \uac78\uccd0 \uae30\uc874 \ubaa8\ub378\uc758 \ud3c9\uade0\uc801\uc778 \uc131\ub2a5\uc744 2.6% \ud5a5\uc0c1"))),(0,i.kt)("li",{parentName:"ul"},"Fig. 21 \uc5d0\uc11c \ud488\uc9c8\uc801\uc73c\ub85c \ubcf4\uba74, CLIP \uc740 \uc774\uc804\uc5d0 random initialization \uc5d0\uc11c end-to-end trained single vision model \uc5d0\uc11c \ubcf4\uc5ec\uc9c4 \uac83\ubcf4\ub2e4 \ub354 \ub113\uc740 task set \uc744 \ud559\uc2b5",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 task \uc5d0\ub294 \uc9c0\ub9ac\uc801 \uc704\uce58, \uad11\ud559 \ubb38\uc790 \uc778\uc2dd, \uc5bc\uad74 \uac10\uc815 \uc778\uc2dd, \ub3d9\uc791 \uc778\uc2dd\uc774 \ud3ec\ud568",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 Kornblith et al. (2019)\uc758 \uc5f0\uad6c\uac00 ImageNet \uacfc \uacb9\uce58\ub294 task \uc73c\ub85c \ud3b8\ud5a5\ub418\uc5c8\ub2e4\uace0 \uc8fc\uc7a5\ud558\uc5ec, \uc774\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574 \uc6b0\ub9ac\ub294 \ub354 \ub113\uc740 27 dataset evaluation suite \uc5d0\uc11c \uc131\ub2a5 \uce21\uc815"))),(0,i.kt)("li",{parentName:"ul"},"\ub113\uc740 evaluation suite \uc5d0\uc11c CLIP \uc758 \uc7a5\uc810\uc774 \ub354\uc6b1 \uba85\ud655",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uaddc\ubaa8\uc5d0 \uad00\uacc4\uc5c6\uc774 \ubaa8\ub4e0 CLIP \uc740 \ucef4\ud4e8\ud305 \ud6a8\uc728\uc131 \uce21\uba74\uc5d0\uc11c \ubaa8\ub4e0 \ud3c9\uac00\ub97c \ub2a5\uac00"),(0,i.kt)("li",{parentName:"ul"},"best model \uc758 \ud3c9\uade0 \uc810\uc218 \ud5a5\uc0c1\uc740 \uc774\uc804 \uc2dc\uc2a4\ud15c\ubcf4\ub2e4 2.6% \uc5d0\uc11c 5% \ub85c \uc99d\uac00"),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c, self-supervised system \uc774 \uc800\uc790\uc758 evaluation suite \uc5d0\uc11c \ub69c\ub837\ud558\uac8c \ub354 \uc798 \uc218\ud589",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc608\ub97c \ub4e4\uc5b4, Kornblith et al. (2019)\uc758 12 dataset \uc5d0\uc11c \uc5ec\uc804\ud788 SimCLRv2 \uac00 \ud3c9\uade0\uc801\uc73c\ub85c BiT-M \ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub0ae\uc9c0\ub9cc, SimCLRv2 \ub294 \uc800\uc790\uc758 27 dataset evaluation suite \uc5d0\uc11c BiT-M \uc744 \ub2a5\uac00"),(0,i.kt)("li",{parentName:"ul"},'\uc774\ub7ec\ud55c \uacb0\uacfc\ub294 "general" \uc131\ub2a5\uc744 \ub354 \uc798 \uc774\ud574\ud558\uae30 \uc704\ud574 task \ub2e4\uc591\uc131\uacfc \ubc94\uc704\ub97c \uacc4\uc18d \ud655\ub300\ud558\ub294 \uac83\uc774 \uc720\uc6a9\ud560 \uac83\uc73c\ub85c \ubcf4\uc784'),(0,i.kt)("li",{parentName:"ul"},"\uc800\uc790\ub294 VTAB \uc640 \uc720\uc0ac\ud55c \ucd94\uac00\uc801\uc778 \ud3c9\uac00 \ub178\ub825\uc774 \uac00\uce58 \uc788\ub2e4\uace0 \uc758\uc2ec")))))))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 11",src:t(29421).Z,width:"1276",height:"1672"})),(0,i.kt)("p",null,"Fig. 11 \uc5d0\uc11c 27 dataset evaluation suite \uc5d0\uc11c\uc758 CLIP \uacfc best model \uac04\uc758 \ucc28\uc774 \uc2dc\uac01\ud654"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"CLIP \uc740 27 dataset \uc911 21 \uc5d0\uc11c Noisy Student EfficientNet-L2 \ub97c \ub2a5\uac00"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc740 OCR(SST2 \ubc0f HatefulMemes), \uc9c0\ub9ac\uc801 \uc704\uce58 \ubc0f \uc7a5\uba74 \uc778\uc2dd(Country211, SUN397) \ubc0f \ube44\ub514\uc624\uc5d0\uc11c\uc758 \ud65c\ub3d9 \uc778\uc2dd(Kinetics700 \ubc0f UCF101)\uacfc \uac19\uc740 task \uc5d0\uc11c \uac00\uc7a5 \ud06c\uac8c \uc131\ub2a5\uc744 \uac1c\uc120"),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c, CLIP \uc740 Stanford Cars \ubc0f GTSRB \uc5d0\uc11c \uc138\ubc00\ud55c \uc790\ub3d9\ucc28 \ubc0f \uad50\ud1b5 \ud45c\uc9c0\ud310 \uc778\uc2dd\uc5d0\uc11c \ud6e8\uc52c \ub354 \uc798 \uc218\ud589",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 ImageNet \uc5d0\uc11c narrow supervision \ubb38\uc81c\uc77c \uc218 \uc788\uc74c"))),(0,i.kt)("li",{parentName:"ul"},"GTSRB \uc5d0\uc11c\uc758 14.7% \ud5a5\uc0c1\uacfc \uac19\uc740 \uacb0\uacfc\ub294 \ubaa8\ub4e0 \uad50\ud1b5 \ubc0f \ub3c4\ub85c \ud45c\uc9c0\ud310\uc5d0 \ub300\ud574 single label \ub9cc \uc788\ub294 ImageNet-1K \uc758 \ubb38\uc81c\ub97c \ub098\ud0c0\ub0bc \uc218 \uc788\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 supervised representation \uc774 class \ub0b4 \uc138\ubd80 \uc0ac\ud56d\uc744 \ucd95\uc18c\ud558\uace0 fine-grained downstream task \uc5d0\uc11c \uc815\ud655\ub3c4\ub97c \uc800\ud574\ud560 \uc218 \uc788\uc74c"))),(0,i.kt)("li",{parentName:"ul"},"\uc5b8\uae09\ud588\ub4ef, CLIP \uc740 \uc5ec\uc804\ud788 \uba87\uba87 dataset \uc5d0\uc11c EfficientNet \ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub0ae\uc74c"),(0,i.kt)("li",{parentName:"ul"},"\ub180\ub78d\uac8c\ub3c4, EfficientNet \uc774 CLIP \uc5d0 \ube44\ud574 \uac00\uc7a5 \uc798 \uc218\ud589\ud558\ub294 dataset \uc740 \ud6c8\ub828\ub41c \ub370\uc774\ud130\uc14b\uc778 ImageNet"),(0,i.kt)("li",{parentName:"ul"},"EfficientNet \uc740 CIFAR10 \ubc0f CIFAR100 \uacfc \uac19\uc740 \ub0ae\uc740 \ud574\uc0c1\ub3c4 \ub370\uc774\ud130\uc14b\uc5d0\uc11c\ub3c4 CLIP \ubcf4\ub2e4 \uc57d\uac04 \ub354 \uc798 \uc218\ud589",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 CLIP \uc5d0 \uaddc\ubaa8\ubcc4 \ub370\uc774\ud130 \uc99d\uac15\uc774 \ubd80\uc871\ud55c \uac83\uc774 \uc77c\ubd80 \uc6d0\uc778\uc77c \uac83"))),(0,i.kt)("li",{parentName:"ul"},"EfficientNet \uc740 PatchCamelyon \ubc0f CLEVRCounts \uc5d0\uc11c\ub3c4 \uc57d\uac04 \ub354 \uc798 \uc218\ud589\ud558\ub294\ub370, \uc774\ub294 \ub450 \uc811\uadfc \ubc29\uc2dd \ubaa8\ub450\uc5d0\uc11c \uc804\ubc18\uc801\uc778 \uc131\ub2a5\uc774 \uc5ec\uc804\ud788 \ub0ae\uae30 \ub54c\ubb38")),(0,i.kt)("h2",{id:"33-robustness-to-natural-distribution-shift"},"3.3 Robustness to Natural Distribution Shift"),(0,i.kt)("p",null,"2015\ub144, ImageNet \uc5d0\uc11c \uc778\uac04\uc744 \ub2a5\uac00\ud558\uc9c0\ub9cc, \uc5ec\uc804\ud788 \ub2e8\uc21c\ud55c \uc2e4\uc218\ub97c \ud55c\ub2e4. \uc774\ub7ec\ud55c \ubd88\uc77c\uce58\uc5d0 \ub300\ud55c \uc5ec\ub7ec \uc544\uc774\ub514\uc5b4\uac00 \uc81c\uc548\ub418\uace0 \uc788\ub2e4."),(0,i.kt)("p",null,"\uacf5\ud1b5 \uc8fc\uc81c\ub294 \ub525 \ub7ec\ub2dd\uc774 training dataset \uc5d0 \uc720\uc9c0\ub418\ub294 correlation \ubc0f pattern \ubc1c\uacac\uc5d0 \ub6f0\uc5b4\ub098\uba70, in-distribution \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4. \uadf8\ub7ec\ub098 \uc774\ub7ec\ud55c correlation \uacfc pattern \uc911 \ub9ce\uc740 \uac83\ub4e4\uc774 \uc2e4\uc81c\ub85c \uc758\ubbf8 \uc5c6\uc73c\uba70, \ub2e4\ub978 distribution \uc5d0\uc11c \uc720\uc9c0\ub418\uc9c0 \uc54a\uc544 \ub2e4\ub978 dataset \uc5d0\uc11c \uc131\ub2a5\uc774 \ud06c\uac8c \uc800\ud558\ub41c\ub2e4."),(0,i.kt)("p",null,"\uc774\ub7f0 \uc5f0\uad6c\ub294 ImageNet \uc5d0\uc11c \ud55c\uc815\uc801\uc73c\ub85c \ud3c9\uac00\ud588\ub2e4. \uc774\ub294 \uc77c\ubc18\ud654 \uc2e4\uc218\uac00 \uc788\uc744 \uc218 \uc788\uc73c\uba70, \uc774\ub7f0 \uc2e4\ud328\uac00 \ub525\ub7ec\ub2dd\uacfc ImageNet \uc758 \uacb0\ud569\uc774 \uc5b4\ub290 \uc815\ub3c4\uc77c\uae4c? very large dataset \uc5d0\uc11c\uc758 natural language supervision \uc744 \ud1b5\ud574 \ud6c8\ub828\ub418\uace0 high zero-shot \uc131\ub2a5\uc744 \ubc1c\ud718\ud560 \uc218 \uc788\ub294 CLIP \ubaa8\ub378\uc740 \uc774\ub7ec\ud55c \uc815\ub3c4\ub97c \uc870\uc0ac\ud55c\ub2e4."),(0,i.kt)("p",null,"Taori et al. (2020) \ub294 ImageNet model \uc758 \uc774\ub7f0 \ud589\ub3d9\uc744 \uc591\uc801\uc73c\ub85c \uc774\ud574\ud558\uae30 \uc704\ud574 \ub098\uc544\uac00\ub294 \ud3ec\uad04\uc801\uc778 \uc5f0\uad6c\uc774\uba70 \uc131\ub2a5\uc774 ",(0,i.kt)("em",{parentName:"p"},"natural distribution shifts")," \ub97c \ud3c9\uac00\ud560 \ub54c \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \uc5f0\uad6c"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub4e4\uc740 7 distribution shifts set \uc131\ub2a5\uc744 \uce21\uc815 : ImageNetV2, ImageNet Sketch, Youtube-BB \ubc0f ImageNet-Vid, ObjectNet, ImageNet Adversarial \ubc0f ImageNet Rendition"),(0,i.kt)("li",{parentName:"ul"},"dataset \uc744 \uc0c8\ub85c\uc6b4 image \ub85c \uad6c\uc131\ud558\uc5ec \ub2e4\uc591\ud55c \uc18c\uc2a4\uc5d0\uc11c \uc218\uc9d1"),(0,i.kt)("li",{parentName:"ul"},"ImageNet-C, Stylized ImageNet \ub610\ub294 \uc874\uc7ac\ud558\ub294 \uc774\ubbf8\uc9c0\ub97c \ub2e4\uc591\ud55c \ubc29\ubc95\uc73c\ub85c \uc65c\uace1\ud558\uc5ec \ub9cc\ub4e0 adversarial attacks \uacfc \uac19\uc740 synthetic distribution shifts"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub97c \uc81c\uc548\ud55c \uc774\uc720 \uc911 \ud558\ub098\ub294 \uc5ec\ub7ec \uae30\ubc95\uc774 synthetic distribution shifts \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uac83\uc774 \uc99d\uba85\ub418\uc5c8\uc9c0\ub9cc, \uc774\ub7ec\ud55c \uae30\ubc95\ub4e4\uc774 natural distribution \uc5d0\uc11c \uc77c\uad00\ub41c \uac1c\uc120\uc744 \uac00\uc838\uc624\uc9c0 \ubabb\ud558\ub294 \uacbd\uc6b0\uac00 \ub9ce\ub2e4\uace0 \ubc1c\uacac\ud558\uae30 \ub54c\ubb38")),(0,i.kt)("hr",null),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 12",src:t(44959).Z,width:"1935",height:"1392"})),(0,i.kt)("p",null,"\uc218\uc9d1\ub41c \ub370\uc774\ud130\uc14b \uc804\uc5ed\uc5d0\uc11c, ImageNet model \uc758 \uc815\ud655\ub3c4\ub294 ImageNet validation set \uc5d0 \uae30\ub300\uce58 \uc774\ud558\ub85c \ub5a8\uc5b4\uc9c4\ub2e4. "),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"all 7 natural distribution shift datasets \uc758 \ud3c9\uade0 \uc815\ud655\ub3c4\uc640 ImageNet class subset \uc5d0\uc11c\uc758 \ud3c9\uade0 \uc815\ud655\ub3c4\ub97c \ubcf4\uace0\ud558\uba70, \ud2b9\ubcc4\ud788 \uba85\uc2dc\ub418\uc9c0 \uc54a\uc740 \uacbd\uc6b0\uc5d0\ub294 ImageNet \uacfc \uad00\ub828\ub41c class subset \uc744 \uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c Youtube-BB \ubc0f ImageNet-Vid \uc758 \uacbd\uc6b0 \ub450 \uac00\uc9c0 \ub2e4\ub978 \ud3c9\uac00 \uc124\uc815\uc774 \uc788\uc73c\ubbc0\ub85c pm-0 \ubc0f pm-10 \uc815\ud655\ub3c4\uc758 \ud3c9\uade0\uc744 \uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"ResNet-101 \uc740 \uc774\ub7ec\ud55c natural distribution shift \uc5d0\uc11c \ud3c9\uac00\ub420 \ub54c ImageNet validation set \uacfc \ube44\uad50\ud558\uc5ec 5\ubc30 \ub9ce\uc740 \uc2e4\uc218\ub97c \uc800\uc9c0\ub978\ub2e4."),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 Taori et al. (2020)\ub294 distribution shift \ud558\uc5d0\uc11c\uc758 \uc815\ud655\ub3c4\uac00 ImageNet \uc815\ud655\ub3c4\uc640 \uc608\uce21 \uac00\ub2a5\ud558\uac8c \uc99d\uac00\ud558\uace0, logit-transformed \uc815\ud655\ub3c4\uc758 \ub85c\uadf8\uc5d0 \ub300\ud55c linear function \uc73c\ub85c \uc798 \ubaa8\ub378\ub9c1\ub428\uc744 \ubc1c\uacac"),(0,i.kt)("li",{parentName:"ul"},"Taori et al. (2020)\ub294 \uc774 \uacb0\uacfc\ub97c \uc0ac\uc6a9\ud558\uc5ec \uacac\uace0\uc131 \ubd84\uc11d\uc774 effective \ubc0f relative robustness \ub97c \uad6c\ubcc4\ud574\uc57c \ud55c\ub2e4\uace0 \uc81c\uc548",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ud6a8\uacfc\uc801\uc778 \uacac\uace0\uc131\uc740 distribution shift \ud558\uc5d0\uc11c\uc758 \uc815\ud655\ub3c4\uac00 in-distribution \uacfc out-of-distribution \uc815\ud655\ub3c4 \uc0ac\uc774\uc758 \ubb38\uc11c\ud654\ub41c \uad00\uacc4\ub97c \uc608\uce21\ud558\ub294 \uac83\ubcf4\ub2e4 \uac1c\uc120\ub418\ub294 \uc815\ub3c4\ub97c \uce21\uc815"),(0,i.kt)("li",{parentName:"ul"},"relative robustness \ub294 out-of-distribution \uc815\ud655\ub3c4\uc758 \uac1c\uc120\uc744 \ud3ec\ucc29"),(0,i.kt)("li",{parentName:"ul"},"Taori et al. (2020)\ub294 \uacac\uace0\uc131 \uae30\ubc95\uc774 ",(0,i.kt)("em",{parentName:"li"},"effective")," \ubc0f ",(0,i.kt)("em",{parentName:"li"},"relative")," robustness \ub97c \ubaa8\ub450 \ud5a5\uc0c1\uc2dc\ud0a4\ub3c4\ub85d \ubaa9\ud45c\ub85c \ud574\uc57c \ud55c\ub2e4\uace0 \uc8fc\uc7a5")))),(0,i.kt)("hr",null),(0,i.kt)("p",null,"Taori et al. (2020)\uc5d0\uc11c \uc5f0\uad6c\ub41c \uac70\uc758 \ubaa8\ub4e0 \ubaa8\ub378\uc740 ImageNet \uc5d0\uc11c training \ub418\uac70\ub098 fine-tuning \ud55c\ub2e4."),(0,i.kt)("p",null,"ImageNet dataset distribution \uc5d0 \ub300\ud55c training \ub610\ub294 adapting \uc774 observsed robustness gap \uc6d0\uc778\uc77c\uae4c?"),(0,i.kt)("p",null,"\uc9c1\uad00\uc801\uc73c\ub85c, zero-shot model \uc740 \ud574\ub2f9 distribution \uc5d0\uc11c\ub9cc \uc720\uc9c0\ub418\ub294 \ud2b9\uc815 correlation \uc774\ub098 pattern \uc744 \ud65c\uc6a9\ud560 \uc218 \uc5c6\uc5b4\uc57c \ud55c\ub2e4. \ub530\ub77c\uc11c zero-shot model \uc774 higher effective robustness \uc744 \uac00\uc9c0\uace0 \uc788\uc744 \uac83\uc73c\ub85c \uae30\ub300\ud558\ub294 \uac83\uc740 \ud569\ub9ac\uc801\uc774\ub2e4. "),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 13",src:t(50087).Z,width:"1935",height:"1047"})),(0,i.kt)("p",null,"Fig. 13 \uc5d0\uc11c natural distribution shift \uc5d0\uc11c zero-shot CLIP \uc758 \uc131\ub2a5\uc744 \uae30\uc874 ImageNet \ubaa8\ub378\uacfc \ube44\uad50"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\ubaa8\ub4e0 zero-shot CLIP \uc740 effective robustness \ub97c \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0a4\uace0, ImageNet \uc815\ud655\ub3c4\uc640 distribution shift \ud558\uc5d0\uc11c\uc758 \uc815\ud655\ub3c4 \uac04\uc758 \uaca9\ucc28\ub97c \ucd5c\ub300 75% \uae4c\uc9c0 \uc904\uc784"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 \uacb0\uacfc\ub294 zero-shot model \uc774 \ud6e8\uc52c \ub354 \uacac\uace0\ud560 \uc218 \uc788\uc9c0\ub9cc, supervised learning on ImageNet \uc774 robustness gap \uc744 \uc77c\uc73c\ud0a4\ub294 \uac83\uc740 \uc544\ub2d8\uc744 \ubc18\ub4dc\uc2dc \uc758\ubbf8\ud558\uc9c0\ub294 \uc54a\ub294\ub2e4"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc758 \ub2e4\ub978 \uc138\ubd80 \uc0ac\ud56d, \uc608\ub85c large \ubc0f diverse pre-training dataset \ub610\ub294 natural language supervision \uc0ac\uc6a9\uc740 image feature \ub97c \ud6e8\uc52c \ub354 \uacac\uace0\ud558\uac8c \ub9cc\ub4e4 \uc218 \uc788\ub2e4"),(0,i.kt)("li",{parentName:"ul"},"zero-shot \ub610\ub294 fine-tuning \uc5d0 \uad00\uacc4\uc5c6\uc774, \uc774\ub97c \uc881\ud788\uae30 \uc704\ud55c \ucd08\uae30 \uc2e4\ud5d8\uc73c\ub85c, ImageNet distribution \uc5d0 \uc801\uc751\ud558\uae30 \uc704\ud574 CLIP \ubaa8\ub378\uc758 feature \uc5d0 L2 regularized logistic regression classifier \ub97c adapting \ud6c4 CLIP \uc758 \uc131\ub2a5\uc774 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \uce21\uc815")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 14",src:t(54440).Z,width:"1935",height:"1302"})),(0,i.kt)("p",null,"\uc6b0\ub9ac\ub294 Fig. 14 \uc5d0\uc11c zero-shot classifier \uc5d0\uc11c\uc758 \uc131\ub2a5 \ubcc0\ud654\ub97c \uc2dc\uac01\ud654"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"CLIP \uc744 ImageNet distribution \uc5d0 adapting \ud558\ub824\uba74 \uc804\ubc18\uc801\uc73c\ub85c ImageNet \uc815\ud655\ub3c4\uac00 9.2% \uc99d\uac00\ud558\uc5ec 85.4% \ub85c, \uc774\ub294 Mahajan et al. (2018)\uc758 2018\ub144 SOTA \uc640 \uc815\ud655\ub3c4\uac00 \ub3d9\uc77c. \uadf8\ub7ec\ub098 distribution shift \ud558\uc5d0\uc11c\uc758 \ud3c9\uade0 \uc815\ud655\ub3c4\ub294 \uc57d\uac04 \uac10\uc18c"),(0,i.kt)("li",{parentName:"ul"},"ImageNet dataset \uc5d0\uc11c \uc815\ud655\ub3c4\uac00 9.2% \uc99d\uac00\ud558\ub294 \uac83\uc740 distribution shift \ud558\uc5d0\uc11c\uc758 \uc131\ub2a5\uc5d0\ub294 \uac70\uc758\ub098 \uc804\ud600 \uc601\ud5a5\uc744 \uc8fc\uc9c0 \uc54a\uc73c\uba74\uc11c\ub3c4 \uc758\ubbf8\uc801\uc73c\ub85c \uc911\uc694",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},'\uc774\ub7ec\ud55c \uc774\ub4dd\uc740 \uc8fc\ub85c "exploiting spurious correlations" \uc5d0\uc11c \uc624\ub294 \uac83\uc77c\uac00? \uc774 \ud589\ub3d9\uc774 CLIP, ImageNet \ubc0f distribution shifts studied \ub610\ub294 general phenomena \uc778\uc9c0, \uadf8\ub9ac\uace0 linear classifier \uac19\uc740 end-to-end fine-tuning \uac19\uc740 \uacbd\uc6b0\ub3c4 \ub9c8\ucc2c\uac00\uc9c0\uc778\uc9c0 \uc54c \uc218 \uc5c6\uc74c'))),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c flexible zero-shot natural-language-based image classifiers \ub85c \uac00\ub2a5\ud55c \ub610 \ub2e4\ub978 robustness \uac1c\uc785\uc744 \uc870\uc0ac",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"7 transfer dataset \uac04\uc758 target class \uac00 \ud56d\uc0c1 ImageNet \uc758 \uac83\uacfc \uc644\ubcbd\ud558\uac8c \uc77c\uce58\ud558\uc9c0\ub294 \uc54a\uc74c"),(0,i.kt)("li",{parentName:"ul"},"Youtube-BB \uc640 ImageNet-Vid \ub450 dataset \uc740 ImageNet \uc758 super-class \ub85c \uad6c\uc131"),(0,i.kt)("li",{parentName:"ul"},"ImageNet model \uc758 fixed 1000-way classifier \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc608\uce21\ud558\ub824\uace0 \ud560 \ub54c \ubb38\uc81c\uac00 \ubc1c\uc0dd"),(0,i.kt)("li",{parentName:"ul"},"Taori et al. (2020)\uc740 ImageNet class \uacc4\uce35 \uad6c\uc870\uc5d0 \ub530\ub77c \ubaa8\ub4e0 sub-classes \uc5d0 \ub300\ud574 \uc608\uce21\uc744 \ucd5c\ub300\ud654\ud568\uc73c\ub85c\uc368 \uc774\ub97c \ucc98\ub9ac. \ub54c\ub85c\ub294 \uc774 \ub9e4\ud551\uc774 \uc644\ubcbd \uc774\ud558\uc77c \uc218 \uc788\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Youtube-BB \uc758 person \uc758 \uacbd\uc6b0, \uc608\uce21\uc740 \uc57c\uad6c \uc120\uc218, \uc2e0\ubd80, \uc2a4\ucfe0\ubc84 \ub2e4\uc774\ubc84\uc758 ImageNet class \ub97c pooling \ud558\ub294 \uac83"))),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc744 \uc0ac\uc6a9\ud558\uba74 \uac01 dataset \uc5d0 \ub300\ud55c class name \uc744 \uae30\ubc18\uc73c\ub85c custom zero-shot classifier \ub97c \uc9c1\uc811 \uc0dd\uc131 \uac00\ub2a5"))),(0,i.kt)("li",{parentName:"ul"},"Fig. 14 \uc5d0\uc120 \uc774\uac83\uc774 \ud3c9\uade0 effective robustness \ub97c 5% \ud5a5\uc0c1\uc2dc\ud0a4\uc9c0\ub9cc \ud070 \uac1c\uc120\uc774 \uba87\uba87 dataset \uc5d0\ub9cc \uc9d1\uc911\ub418\uc5b4 \uc788\uc74c\uc744 \ubcfc \uc218 \uc788\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ud765\ubbf8\ub86d\uac8c\ub3c4, ObjectNet\uc758 \uc815\ud655\ub3c4\ub3c4 2.3% \uc99d\uac00"),(0,i.kt)("li",{parentName:"ul"},"\uc774 dataset \uc740 ImageNet class \uc640 \uadfc\uc811\ud558\uac8c \uacb9\uce58\ub3c4\ub85d \uc124\uacc4\ub418\uc5c8\uc9c0\ub9cc, ObjectNet \uc758 \uac01 class name \uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\uc740 \ud544\uc694\ud55c \uacbd\uc6b0 ImageNet class name \uc744 \uc0ac\uc6a9\ud558\uace0 \uc608\uce21\uc744 pooling \ud558\ub294 \uac83\ubcf4\ub2e4 \uc57d\uac04 \ub3c4\uc6c0\uc774 \ub428")))),(0,i.kt)("p",null,"zero-shot CLIP \uc740 effective robustness \ub97c \ud5a5\uc0c1\uc2dc\ud0a4\uc9c0\ub9cc, Fig. 14 \ucc98\ub7fc \uc774 \ud61c\ud0dd\uc740 fully supervised setting \uc5d0\uc120 \uac70\uc758 \uc0ac\ub77c\uc9c4\ub2e4. zero-shot \uc5d0\uc11c fully supervised \uae4c\uc9c0\uc758 \uc5f0\uc18d\uc5d0\uc11c effective robustness \uac00 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \uc870\uc0ac."),(0,i.kt)("p",null,"Fig. 15 \uc5d0\uc11c best CLIP \uc758 feature \uc5d0 \ub300\ud55c zero-shot, 1-shot, 2-shot, 4-shot, ..., 128-shot \ubc0f fully supervised logistic regression classifier \uc758 \uc131\ub2a5\uc744 \uc2dc\uac01\ud654"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 15",src:t(5686).Z,width:"975",height:"1257"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uc801\uc740 \uc591\uc758 \ub370\uc774\ud130\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\ub3c4 baseline model \ubcf4\ub2e4 higher effective robustness \ub97c \ubcf4\uc774\uc9c0\ub9cc, \uc774 \ud61c\ud0dd\uc740 in-distribution \uc131\ub2a5\uc774 \ub354 \ub9ce\uc740 training data \uc640 \ud568\uaed8 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc0ac\ub77c\uc9c0\uace0 \ub300\ubd80\ubd84\uc758 \uacbd\uc6b0\uc5d0\ub294 \uc644\uc804\ud788 \uc5c6\uc5b4\uc9c4\ub2e4")),(0,i.kt)("p",null,"\uc774\ub7ec\ud55c \uacb0\uacfc\ub97c \uc885\ud569\ud558\uba74, large-scale task \ubc0f dataset agnostic pre-training \uacfc broad evaluation suites \uc5d0 \ub300\ud55c zero-shot \ubc0f few-shot \ubca4\uce58\ub9c8\ud0b9\uc73c\ub85c\uc758 reorientation towards \uac00 \ub354 \uacac\uace0\ud55c \uc2dc\uc2a4\ud15c\uc758 \uac1c\ubc1c\uc744 \ucd09\uc9c4\ud558\uace0 \uc131\ub2a5\uc744 \ubcf4\ub2e4 \uc815\ud655\ud558\uac8c \ud3c9\uac00\ud55c\ub2e4. "),(0,i.kt)("h1",{id:"4-comparison-to-human-performance"},"4. Comparison to Human Performance"),(0,i.kt)("p",null,"CLIP \uacfc \uc778\uac04 \uc131\ub2a5 \ubc0f \uc778\uac04 \ud559\uc2b5 \ube44\uad50\ub97c \uc704\ud574 CLIP \uc758 evaluation setting \uacfc \uc720\uc0ac\ud558\uac8c \uc778\uac04\ub4e4 \ud3c9\uac00"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"\uc774\ub294 \uc778\uac04\uc774 \uc5bc\ub9c8\ub098 \uac15\ub825\ud55c zero-shot \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uc9c0, \uc131\ub2a5\uc774 \ud55c \ub450\uac1c\uc758 image sample \uc744 \ubcf4\uc5ec\uc904 \ub54c \uc5bc\ub9c8\ub098 \ud5a5\uc0c1\ub418\ub294\uc9c0 \uc54c\uc544\ubcf4\uace0\uc790 \ud568")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"\uc774\ub97c \ud1b5\ud574 \uc778\uac04\uacfc CLIP \uac04\uc758 task \ub09c\uc774\ub3c4\ub97c \ube44\uad50\ud558\uace0, \uc774\ub4e4\uac04\uc758 correlation \uacfc difference \ud30c\uc545"),(0,i.kt)("p",{parentName:"li"},"Oxford IIT Pets dataset \uc758 test set 3669 images \ub97c \uac01\uac01 5\uba85\uc5d0\uac8c \uc81c\uacf5\ud558\uace0 \ube44\uc2b7\ud55c 37 cat \ubc0f dog \ub97c \uc120\ud0dd\ud558\ub3c4\ub85d \ud568.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"zero-shot \uc0c1\ud669\uc5d0\uc11c \uc778\uac04\uc740 \uac01 \ud488\uc885 \uc608\uc2dc\ub97c \ubc1b\uc9c0 \uc54a\uc740\ucc44 \uc774\ubbf8\uc9c0\ub97c \ub77c\ubca8\ub9c1\ud558\ub3c4\ub85d \uc694\uccad.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"1-shot \uc5d0\uc11c\ub294 \uac01 \ud488\uc885\uc758 \ud55c\uc7a5 \uc0d8\ud50c \uc774\ubbf8\uc9c0\ub97c \ubc1b\uace0, 2-shot \uc5d0\uc11c\ub294 \ub450 \uc7a5\uc758 \uc0d8\ud50c \uc774\ubbf8\uc9c0\ub97c \ubc1b\uc74c"))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 16",src:t(93470).Z,width:"1440",height:"1546"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uc778\uac04\uc740 class \ub2f9 1 training example \uc758 \ud3c9\uade0 \uc131\ub2a5\uc774 54% to 76% \ub85c \ud5a5\uc0c1",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ucd94\uac00 \ud6c8\ub828 \uc608\uc81c\uc5d0 \ub300\ud55c \ud55c\uacc4\uc801\uc778 \uc774\ub4dd\uc740 \uac70\uc758 \uc5c6\uc74c"))),(0,i.kt)("li",{parentName:"ul"},"zero-shot to 1-shot \uc758 \uacfc\uc815\uc5d0\uc11c \uc778\uac04\uc740 \ubd88\ud655\uc2e4\ud55c \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\uac00 \ud5a5\uc0c1"),(0,i.kt)("li",{parentName:"ul"},"\ud558\ub098\uc758 \uc608\uc81c\ub97c \ud1b5\ud574 \ubd88\ud655\uc2e4\ud55c \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \ud655\ub960\uc744 \uc5c5\ub370\uc774\ud2b8\uac00 \uac00\ub2a5\ud568\uc744 \uc2dc\uc0ac"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub97c \uace0\ub824\ud574, CLIP \uc740 zero-shot \uc131\ub2a5\uc744 \uc704\ud55c \uc720\ub9dd\ud55c training \uc804\ub7b5\uc774\uc9c0\ub9cc, few-shot \uacfc \ucc28\uc774\uac00 \ud06c\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc74c")),(0,i.kt)("p",null,"\uc774 \uacb0\uacfc\ub294 \uc544\uc9c1 \uae30\uacc4\uacfc \uc778\uac04\uc758 \uc0d8\ud50c \ud6a8\uc728\uc131 \uac04\uc758 \uaca9\ucc28\ub97c \uc904\uc774\uae30 \uc704\ud55c \uc54c\uace0\ub9ac\uc998 \uac1c\uc120\uc774 \uc5ec\uc804\ud788 \ud544\uc694\ud558\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"few-shot \ud3c9\uac00\uc5d0\uc11c CLIP \uc740 \uc0ac\uc804 \uc9c0\uc2dd\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ud65c\uc6a9\ud558\uc9c0 \uc54a\uc73c\uba70, \uc778\uac04\uc740 \uadf8\ub807\uae30 \ub54c\ubb38\uc5d0 \uc6b0\ub9ac\ub294 \uc0ac\uc804 \uc9c0\uc2dd\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ud4e8\uc0f7 \ud559\uc2b5\uc5d0 \ud1b5\ud569\ud558\ub294 \ubc29\ubc95\uc744 \ucc3e\ub294 \uac83\uc774 CLIP\uc758 \uc54c\uace0\ub9ac\uc998 \uac1c\uc120\uc5d0 \uc911\uc694\ud55c \ub2e8\uacc4\ub77c\uace0 \ucd94\uce21"),(0,i.kt)("li",{parentName:"ul"},"\uc6b0\ub9ac\uc758 \uc9c0\uc2dd\uc5d0 \ub530\ub974\uba74, \uace0\ud488\uc9c8 \uc0ac\uc804 \ud6c8\ub828 \ubaa8\ub378\uc758 \ud2b9\uc131 \uc704\uc5d0 linear classifier \uc0ac\uc6a9\uc774 few-shot learning \uc5d0 \ub300\ud55c \uac70\uc758 \ucd5c\uc2e0 \uae30\uc220 \uc218\uc900",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \ucd5c\uace0\uc758 few-shot learning \ubc29\ubc95\uacfc \uc778\uac04\uc758 few-shot learning \uc0ac\uc774\uc5d0 \uaca9\ucc28\uac00 \uc788\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac"))),(0,i.kt)("li",{parentName:"ul"},"\ub9cc\uc57d \uc778\uac04 \uc815\ud655\ub3c4 \ub300 CLIP \uc758 zero-shot \uc815\ud655\ub3c4\ub97c \uadf8\ub798\ud504\ub85c \uadf8\ub824\ubcf4\uba74 (Fig. 16), CLIP \uc5d0 \ub300\ud55c \uac00\uc7a5 \uc5b4\ub824\uc6b4 \ubb38\uc81c\uac00 \uc778\uac04\uc5d0\uac8c\ub3c4 \uc5b4\ub824\uc6b4 \uac83\uc784\uc744 \ud655\uc778. ",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc624\ucc28\uac00 \uc77c\uad00\ub418\ub294 \ud55c, \uc800\uc790\uc758 \uac00\uc124\uc740 dataset noisy (\uc798\ubabb \ub77c\ubca8\ub9c1\ub41c \uc774\ubbf8\uc9c0 \ud3ec\ud568) \ubc0f \uc778\uac04\uacfc \ubaa8\ub378 \ubaa8\ub450\uc5d0\uac8c \ub09c\uc81c\uc778 \ubd84\ud3ec \ubc16 \uc774\ubbf8\uc9c0 \ub54c\ubb38\uc77c \uac83\uc774\ub77c\uace0 \uc0dd\uac01")))),(0,i.kt)("h1",{id:"5-data-overlap-analysis"},"5. Data Overlap Analysis"),(0,i.kt)("p",null,"pre-training on large internet dataset \uc758 \uc6b0\ub824 \uc0ac\ud56d\uc740 downstream evals \uc640 \uc758\ub3c4\ud558\uc9c0 \uc54a\uc740 overlap \uc774\ub2e4."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\ucd5c\uc545\uc758 \uacbd\uc6b0, evaluation dataset \uc758 complete copy \uac00 pre-training dataset \uc73c\ub85c \uc720\ucd9c\ub418\uc5b4 \uc77c\ubc18\ud654\uc758 \uc758\ubbf8 \uc788\ub294 \ud14c\uc2a4\ud2b8\ub85c\uc11c\uc758 \ud3c9\uac00\ub97c \ubb34\ud6a8\ud654\ud560 \uc218 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc870\uc0ac\ud558\ub294 \uac83\uc774 \uc911\uc694"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub97c \ubc29\uc9c0\ud558\uae30 \uc704\ud55c \ud55c \uac00\uc9c0 \uc635\uc158\uc740 \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\uae30 \uc804\uc5d0 \ubaa8\ub4e0 \uc911\ubcf5\uc744 \uc2dd\ubcc4\ud558\uace0 \uc81c\uac70\ud558\ub294 \uac83",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uc9c4\uc815\ud55c hold-out \uc131\ub2a5\uc744 \ubcf4\uace0\ud558\uae30\ub294 \ubcf4\uc7a5\ud558\uc9c0\ub9cc, \ubaa8\ub378\uc774 \uc0ac\uc804\uc5d0 \ud3c9\uac00\ub420 \uc218 \uc788\ub294 \ubaa8\ub4e0 \uac00\ub2a5\ud55c \ub370\uc774\ud130\ub97c \ubbf8\ub9ac \uc54c\uc544\uc57c \ud55c\ub2e4\ub294 \uac83\uc744 \uc694\uad6c"),(0,i.kt)("li",{parentName:"ul"},"\uc774\uac83\uc740 \ubca4\uce58\ub9c8\ud0b9\uacfc \ubd84\uc11d\uc758 \ubc94\uc704\ub97c \uc81c\ud55c\ud558\ub294 \ub2e8\uc810 \uc874\uc7ac"),(0,i.kt)("li",{parentName:"ul"},"\uc0c8\ub85c\uc6b4 \ud3c9\uac00\ub97c \ucd94\uac00\ud558\uae30 \uc704\ud574\uc11c\ub294 \ube44\uc6a9\uc774 \ub9ce\uc774 \ub4dc\ub294 re-training \uc774 \ud544\uc694\ud558\uac70\ub098 \uc911\ucca9\uc73c\ub85c \uc778\ud55c \ubbf8\uc815\ub7c9\uc801 \uc774\uc810\uc744 \ubcf4\uace0\ud560 \uc704\ud5d8\uc774 \uc788\ub2e4")))),(0,i.kt)("p",null,"\ub300\uc2e0, \uc800\uc790\ub294 \uc911\ucca9\uc774 \uc5bc\ub9c8\ub098 \ubc1c\uc0dd\ud558\ub294\uc9c0\uc640 \uc774\ub7ec\ud55c \uc911\ucca9\uc73c\ub85c \uc778\ud574 \uc131\ub2a5\uc774 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \ubb38\uc11c\ud654. \uc774\ub97c \uc704\ud574 \ub2e4\uc74c \uc808\ucc28\ub97c \uc0ac\uc6a9\ud55c\ub2e4."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"\uac01 evaluation dataset \uc5d0 \ub300\ud574, \uadf8 \uc608\uc81c\uc5d0 \ub300\ud55c duplicate detector \uc2e4\ud589.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ud6c4 \uc218\ub3d9\uc73c\ub85c \ucc3e\uc740 nearest neighbors \ub97c \uac80\uc0ac\ud558\uace0 \ub192\uc740 \uc815\ubc00\ub3c4\ub97c \uc720\uc9c0\ud558\uba74\uc11c \uc7ac\ud604\uc728\uc744 \uadf9\ub300\ud654\ud558\uae30 \uc704\ud55c dataset \ub2f9 threshold \uc124\uc815"),(0,i.kt)("li",{parentName:"ul"},"\uc774 \uc784\uacc4\uac12\uc744 \uc0ac\uc6a9\ud558\uc5ec Overlap\uacfc Clean \ub450 \uac1c\uc758 \uc0c8\ub85c\uc6b4 subset \uc0dd\uc131"),(0,i.kt)("li",{parentName:"ul"},"Overlap \uc5d0\ub294 \uc784\uacc4\uac12 \uc774\uc0c1\uc758 \uc720\uc0ac\uc131\uc744 \uac00\uc9c4 \ubaa8\ub4e0 \uc608\uc81c\uac00 \ud3ec\ud568\ub418\uace0, Clean \uc5d0\ub294 \uc774 \uc784\uacc4\uac12 \uc774\ud558\uc758 \ubaa8\ub4e0 \uc608\uc81c\uac00 \ud3ec\ud568"),(0,i.kt)("li",{parentName:"ul"},"\ubcc0\uacbd\ub418\uc9c0 \uc54a\uc740 \uc804\uccb4 \ub370\uc774\ud130\uc14b\uc740 All\ub85c \ud45c\uae30"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub97c \ud1b5\ud574 \ub370\uc774\ud130 \uc624\uc5fc \uc815\ub3c4\ub97c \ubaa8\ub4e0 \uc608\uc81c \uc911 Overlap \uc758 \uc218\uc640 All \uc758 \ud06c\uae30\uc758 \ube44\uc728\ub85c \uae30\ub85d"))),(0,i.kt)("li",{parentName:"ol"},"\uc774\ud6c4 CLIP RN50x64 \uc758 zero-shot \uc815\ud655\ub3c4\ub97c \uacc4\uc0b0\ud558\uace0 \uc138 \ubd84\ud560\uc5d0 \ub300\ud55c All - Clean \uc744 \uc8fc\uc694 \uc9c0\ud45c\ub85c \ubcf4\uace0",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uc624\uc5fc\uc73c\ub85c \uc778\ud55c \uc815\ud655\ub3c4 \ubcc0\ud654"),(0,i.kt)("li",{parentName:"ul"},"\uc774 \uac12\uc774 \uc591\uc218\uc774\uba74 overlapping data \ub85c \uc778\ud574 \uc804\uccb4\uc801\uc73c\ub85c \ubcf4\uace0\ub41c \uc815\ud655\ub3c4\uac00 \uc5bc\ub9c8\ub098 over-fitting \ub418\uc5c8\ub294\uc9c0\uc5d0 \ub300\ud55c \ucd94\uc815\uac12"))),(0,i.kt)("li",{parentName:"ol"},"overlap \ub7c9\uc740 \uc885\uc885 \uc791\uae30 \ub54c\ubb38\uc5d0 Overlap \ud558\uc704 \uc9d1\ud569\uc758 \uc77c\ud3c9\uade0 (\ub354 \ud070) p-value \uc744 \uacc4\uc0b0\ud558\uace0 \uc77c\ubcc0\ub7c9 \uc720\uc758\uc131 \uac80\uc815\uc744 \uc2e4\ud589",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c 99.5% \uc758 Clopper-Pearson confidenec intervals \ub97c Dirty \uc5d0 \ub300\ud574 \uacc4\uc0b0\ud558\uc5ec \ub610 \ub2e4\ub978 \ud655\uc778\uc744 \uc9c4\ud589")))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Figure 17",src:t(21894).Z,width:"2039",height:"1070"})),(0,i.kt)("p",null,"\uc774 \ubd84\uc11d\uc758 \uc694\uc57d\uc740 Fig. 17 \uc5d0 \uc81c\uc2dc."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"35 dataset \uc911 9 dataset \uc5d0\ub294 \uc911\ubcf5\ub514 \uac10\uc9c0\ub418\uc9c0 \uc54a\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc77c\ubd80\ub294 \ud569\uc131 \ub610\ub294 \uc804\ubb38\ud654\ub41c dataset \uc774\ub77c \uc778\ud130\ub137\uc5d0 \uac8c\uc2dc\ub420 \uac00\ub2a5\uc131 \uc801\uc74c (e.g. MNIST, CLEVR \ubc0f GTSRB)"),(0,i.kt)("li",{parentName:"ul"},"\ub610\ub294 \uc800\uc790\uc758 dataset \uc5d0\ub294 \uc0dd\uc131\ub41c \ud6c4 \ub9cc\ub4e4\uc5b4\uc9c4 novel data \ub97c \ud3ec\ud568\ud558\uc5ec \uc911\ubcf5\uc774 \uc5c6\uc74c\uc744 \ubcf4\uc7a5 (ObjectNet \ubc0f Hateful Memes)"))),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uc800\uc790\uc758 detector \uac00 low-false positive rate \ub97c \uac00\uc9d0\uc744 \ubcf4\uc5ec\uc90c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"false positive \ub294 \ubd84\uc11d\uc5d0\uc11c \uc624\uc5fc \ud6a8\uacfc\ub97c under-estimate \ud560 \uc218 \uc788\uc5b4\uc11c \uc911\uc694\ud568"))),(0,i.kt)("li",{parentName:"ul"},"median overlap 2.2%, average oberlap 3.2%",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc18c\ub7c9\uc758 \uc911\ubcf5\uc774 \uc804\uccb4\uc801\uc778 \uc815\ud655\ub3c4\uac00 0.1% \uc774\uc0c1\uc73c\ub85c \ubcc0\uacbd\ub418\ub294 \uacbd\uc6b0\ub294 \ub4dc\ubb3c\ub2e4."),(0,i.kt)("li",{parentName:"ul"},"\uc774 \uc911 \uc784\uacc4\uac12\uc744 \ucd08\uacfc\ud558\ub294 7 dataset \ub9cc \uc788\ub2e4."),(0,i.kt)("li",{parentName:"ul"},"\uc774 \uc911 2\uac1c\ub9cc \ubcf4\uc815\ub41c Bonferroni \uc218\uc815 \ud6c4\uc5d0 \ud1b5\uacc4\uc801\uc73c\ub85c \uc720\uc758\ud568"),(0,i.kt)("li",{parentName:"ul"},"\ucd5c\ub300 \uac10\uc9c0\ub41c \uac1c\uc120\uc740 overlap rate \uac00 12.1% \uc778 Birdsnap \uc5d0\uc11c 0.6% \ub9cc\ud07c\uc774\ub2e4."),(0,i.kt)("li",{parentName:"ul"},"largest overlap \uc740 21.5% \uc778 Country211 \uc5d0\uc11c \ubc1c\uc0dd",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uc800\uc790\uc758 pre-training dataset \uc774 filtered sub-set \uc744 \ud3ec\ud568\ud558\uace0 \uc788\ub294 YFCC100M \uc5d0\uc11c \uad6c\uc131\ub418\uc5c8\uae30 \ub54c\ubb38"),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 \uc774\ub7ec\ud55c \ud070 \uc911\ubcf5\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0 Country211 \uc758 \uc815\ud655\ub3c4\ub294 0.2% \ub9cc \uc99d\uac00"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uc911\ubcf5\ub418\ub294 \uc608\uc81c\uc758 training text \uac00 downstream eval measure \uac00 specific task \uc640 \uad00\ub828\uc774 \uc5c6\ub294 \uacbd\uc6b0\uac00 \ub9ce\uae30 \ub54c\ubb38\uc77c \uc218 \uc788\uc74c"))),(0,i.kt)("li",{parentName:"ul"},"Country211 \uc740 \uc9c0\ub9ac\uc801 \uc704\uce58 \ud30c\uc545 \ub2a5\ub825\uc744 \uce21\uc815\ud558\uc9c0\ub9cc, \uc774\ub7ec\ud55c \uc911\ubcf5\uc5d0 \ub300\ud55c training text \ub97c \uac80\uc0ac\ud558\uba74 \uc774\ubbf8\uc9c0\uc758 \uc704\uce58\ub97c \uc5b8\uae09\ud558\uc9c0 \uc54a\ub294 \uac83\uc73c\ub85c \ub098\ud0c0\ub0a8")))),(0,i.kt)("hr",null),(0,i.kt)("p",null,"\uc800\uc790\uc758 \ubd84\uc11d\uc5d4 two potential concerns \ub97c \uc778\uc2dd."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"detector \ub294 \uc644\ubcbd\ud558\uc9c0 \uc54a\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"detector \ub294 proxy training task \uc5d0 \uac70\uc758 100% \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud558\uace0, \uc218\ub3d9 \uac80\uc0ac \ubc0f threshold tuning \uc744 \ud1b5\ud574 \ubc1c\uacac\ub41c nearest-neighbors \uc0ac\uc774\uc5d0 \ub192\uc740 \uc815\ubc00\ub3c4\uc640 \uc7ac\ud604\uc728\uc744 \uac00\uc9d0"),(0,i.kt)("li",{parentName:"ul"},"\ud558\uc9c0\ub9cc 400M examples \ub97c \ud1b5\ud55c \uc7ac\ud604\uc728\uc744 \ucd94\uc801\uc801\uc73c\ub85c \ud655\uc778\uc740 \ubd88\uac00\ub2a5"))),(0,i.kt)("li",{parentName:"ol"},"Overlap \uacfc Clean subset \uac04\uc758 data distribution \uc774 \ubcc0\ud560 \uc218 \uc788\ub2e4\ub294 \uc810",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},'Kinetics-700 \uc5d0\uc11c \ub9ce\uc740 "overlap" \uc774 \uc2e4\uc81c\ub85c \ubaa8\ub450 black transition frames',(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\uac83\uc774 Kinetics-700 \uc774 Overlap \uc5d0\uc11c 20% \uc758 \uc815\ud655\ub3c4 \ud558\ub77d\uc744 \ubcf4\uc774\ub294 \uc774\uc720",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ubcf4\ub2e4 subtle distribution shifts \uac00 \uc788\uc744 \uc218 \uc788\ub2e4\uace0 \uc758\uc2ec"))),(0,i.kt)("li",{parentName:"ul"},"CIFAR-100 \uc758 \uacbd\uc6b0, \ud574\uc0c1\ub3c4\uac00 \ub9e4\uc6b0 \ub0ae\uae30 \ub54c\ubb38\uc5d0 \ub9ce\uc740 \uc911\ubcf5\uc774 \uc0c8\uc758 \uc0c8\ub098 \ube44\ud589\uae30\uc640 \uac19\uc740 \uc791\uc740 \uac1d\uccb4\uc758 false positives \ub85c \ub098\ud0c0\ub0a8"),(0,i.kt)("li",{parentName:"ul"},"\uc815\ud655\ub3c4\uc758 \ubcc0\ud654\ub294 overlap class distribution \uc774\ub098 difficulty \ubcc0\ud654 \ub54c\ubb38\uc77c \uc218 \uc788\uc74c"),(0,i.kt)("li",{parentName:"ul"},"\ubd88\ud589\ud788\ub3c4, \uc774\ub7f0 distribution \ubc0f difficulty \ubcc0\ud654\ub294 over-fitting \ud6a8\uacfc\ub97c \uac00\ub9ac\uae30\ub3c4 \ud568")))))),(0,i.kt)("p",null,"\uadf8\ub7ec\ub098 \uc704 \uacb0\uacfc\ub294 large scale pre-training \uc5d0 \uad00\ud55c \uc774\uc804 \uc5f0\uad6c\uc5d0\uc11c\uc758 \uc720\uc0ac\ud55c duplicate analysis \uacb0\uacfc\ub97c \ub530\ub978\ub2e4."),(0,i.kt)("p",null,"Mahajan et al. (2018) \ubc0f Kolesnikov et al. (2019)\ub294 \uc720\uc0ac\ud55c overlap rate \ub97c \uac80\ucd9c\ud558\uace0 \uc804\ubc18\uc801\uc778 \uc131\ub2a5\uc5d0\ub294 \ucd5c\uc18c\ud55c\uc758 \ubcc0\ud654\ub9cc \uc788\uc5c8\ub2e4. \uc911\uc694\ud55c \uc810\uc740 Kolesnikov et al. (2019)\uac00 \ub17c\ubb38 introduction \uc5d0\uc11c \ub17c\uc758\ud55c alternative de-duplication \uc804\ub7b5\uacfc \uc6b0\ub9ac\uac00 \uacb0\uc815\ud55c \uc811\uadfc \ubc29\uc2dd \uc0ac\uc774\uc758 \ucc28\uc774\uac00 \uac70\uc758 \uc5c6\uc5c8\ub2e4\ub294 \uac83"),(0,i.kt)("h1",{id:"6-limitations"},"6. Limitations"),(0,i.kt)("p",null,"CLIP \uc5d0\ub294 \ub9ce\uc740 \uc81c\ud55c \uc874\uc7ac."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"training splits \uc744 \ud3ec\ud568\ud55c dataset \uc758 \uacbd\uc6b0, zero-shot CLIP \uc131\ub2a5\uc740 \ud3c9\uade0\uc801\uc73c\ub85c ResNet-50 features \uc758 top \uc5d0 linear classifier \uc758 simple supervised baseline \uacfc \uacbd\uc7c1\ub825 \uc788\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 dataset \ub300\ubd80\ubd84\uc5d0\uc11c, \uc774 baseline \uc758 \uc131\ub2a5\uc740 \uc804\ubc18\uc801\uc778 SOTA \ubcf4\ub2e4 \ud6e8\uc52c \ub0ae\uc74c"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc758 task learning \ubc0f transfer \ub2a5\ub825 \uac1c\uc120\uc744 \uc704\ud574 \ub9ce\uc740 \uc5f0\uad6c\uac00 \ud544\uc694"),(0,i.kt)("li",{parentName:"ul"},"scaling \uc740 \uc131\ub2a5\uc744 \uafb8\uc900\ud788 \ud5a5\uc0c1\uc2dc\ud0a4\uba70, \uacc4\uc18d\ud574\uc11c \uac1c\uc120\ud560 \uc218 \uc788\ub294 \uacbd\ub85c\uc784\uc744 \uc81c\uc2dc"),(0,i.kt)("li",{parentName:"ul"},"\ud558\uc9c0\ub9cc zero-shot CLIP \uc774 SOTA \ub2ec\uc131\uc744 \uc704\ud574\uc120 computing \ub7c9\uc744 1000x  \uc99d\uac00\ud574\uc57c \ud55c\ub2e4\uace0 \ucd94\uc815"))),(0,i.kt)("li",{parentName:"ul"},"CLIP zero-shot \uc131\ub2a5\uc740 \uc5ec\ub7ec task \uc5d0\uc120 \uc5ec\uc804\ud788 \uc57d\ud568",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"task-specific model \uacfc \ube44\uad50\ud558\uc5ec, \uc790\ub3d9\ucc28 \ubaa8\ub378, \uaf43 \uc885\ub958 \ubc0f \ud56d\uacf5\uae30 \ub4f1 \uc138\ubd80 \ubd84\ub958 \uc720\ud615\uc5d0\uc11c \uc57d\ud568"),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c \uc774\ubbf8\uc9c0 \uac1d\uccb4 \uc218\ub97c \uc138\ub294 \uac83 \uac19\uc740 \ucd94\uc0c1\uc801\uc774\uace0 \uccb4\uacc4\uc801\uc778 task \ub3c4 \uc5b4\ub824\uc6c0"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc758 pre-training dataset \uc5d0 \ud3ec\ud568\ub418\uc9c0 \uc54a\uc740, \uc0dd\ub7b5\ub41c novel task \uc5d0 \ub300\ud574\uc120 CLIP \uc758 \uc131\ub2a5\uc774 \uac70\uc758 \ubb34\uc791\uc704\uc5d0 \uac00\uae4c\uc6c0"))),(0,i.kt)("li",{parentName:"ul"},"zero-shot CLIP \uc740 \ub9ce\uc740 natural image distribution \uc5d0 generalizing \ud558\uc9c0\ub9cc, out-of-distribution \uc5d0\ub294 \uc5ec\uc804\ud788 generalizing \ud558\uc9c0 \ubabb\ud568",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 OCR task \uc5d0\uc11c \uba85\ud655\ud788 \ub098\ud0c0\ub0a8"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc740 MNIST \uc190\uae00\uc528 \uc22b\uc790\uc5d0\uc120 88% \uc815\ud655\ub3c4\ub9cc \ub2ec\uc131"),(0,i.kt)("li",{parentName:"ul"},"raw pixel \uc5d0 \ub300\ud55c logistic regression \uc758 simple baseline \uc774 zero-shot CLIP \ubcf4\ub2e4 \ub6f0\uc5b4\ub0a8"),(0,i.kt)("li",{parentName:"ul"},"\uc758\ubbf8\ub860\uc801 \ubc0f near-duplicate nearest-neighbor retrival \uacb0\uacfc, MNIST \ub294 pre-training dataset \uc5d0 \uc5c6\uc74c\uc744 \ud655\uc778\ud588\uc73c\uba70, \uc774\ub294 CLIP \uc774 \ucde8\uc57d\ud55c \uc77c\ubc18\ud654 \ud574\uacb0\uc5d0\ub294 \uac70\uc758 \uae30\uc5ec\ud558\uc9c0 \uc54a\uc74c\uc744 \uc2dc\uc0ac"),(0,i.kt)("li",{parentName:"ul"},"\ub300\uc2e0 \uc774\ub97c \uc6b0\ud68c\ud558\ub824\uace0 \ud558\uba74, large scale \uc774\uace0 diverse dataset \uc73c\ub85c \ud6c8\ub828\ud558\uc5ec effectively in-distribution \uc73c\ub85c \ud3ec\ud568\ub420 \uac83\uc73c\ub85c \uae30\ub300"))),(0,i.kt)("li",{parentName:"ul"},"\ub113\uace0 \ub2e4\uc591\ud55c task \ubc0f dataset \uc5d0 flexible zero-shot classifier \ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc9c0\ub9cc, \uc8fc\uc5b4\uc9c4 zero-shot classifier \uc758 concept \uc911\uc5d0\uc11c\ub9cc \uc120\ud0dd \uac00\ub2a5",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"novel output \uc744 \uc0dd\uc131\ud558\ub294 image captioning \uac19\uc740 flexible approach \uc640 \ube44\uad50\ud558\uba74 \uc0c1\ub2f9\ud788 \uc81c\ud55c\uc801"),(0,i.kt)("li",{parentName:"ul"},"image caption baseline \uc758 \uacc4\uc0b0 \ud6a8\uc728\uc131\uc740 CLIP \ubcf4\ub2e4 \ud6e8\uc52c \ub0ae\uc74c. \uc774\ub294 CLIP \uc758 \ud6a8\uc728\uc131\uc744 \uacb0\ud569\ud55c \uc811\uadfc \ubc29\uc2dd\uc744 \uc2dc\ub3c4\ud560 \uac00\uce58\uac00 \uc788\uc74c. \ub300\uc548\uc73c\ub85c inference \uc2dc natural language explanations \uc758 \ub9ce\uc740 retrieval \uc218\ud589\uc744 \ud560 \uc218 \uc788\uc74c"))),(0,i.kt)("li",{parentName:"ul"},"deep learning \uc758 data efficiency \ud574\uacb0\ud558\uc9c0 \uc54a\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ub300\uc2e0, 400M training examples \ub85c \ud655\uc7a5\ud560 \uc218 \uc788\ub294 supervision \uc744 \uc0ac\uc6a9\ud558\uc5ec \ubcf4\uc0c1"),(0,i.kt)("li",{parentName:"ul"},"training \uc911\uc5d0 \ubcf8 image \uac00 \ucd08\ub2f9 \ud558\ub098\uc529 \uc81c\uc2dc\ub418\uba74, 32 epochs \ub3d9\uc548 12.8B \uc758 image \ub97c \ubc18\ubcf5\ud558\ub294\ub370 405\ub144 \uac78\ub9b4 \uac83"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc744 self-supervision \ubc0f self-training \uacfc \uacb0\ud569\ud558\ub294 \uac83\uc740 standard supervision learning \ubcf4\ub2e4 data efficiency \ub97c \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\uc5b4 \uc720\ub9dd\ud558\ub2e4"))),(0,i.kt)("li",{parentName:"ul"},"\uc800\uc790\uc758 \ucd08\uc810\uc740 zero-shot transfer \uc784\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0, \ubc18\ubcf5\uc801\uc778 CLIP \uac1c\ubc1c \uc548\ub0b4\ub97c \uc704\ud574 full validation set \uc131\ub2a5\uc744 \ucffc\ub9ac",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"validation set \uc5d0\ub294 \uc218\ucc9c\uac1c \uc608\uc81c\uac00 \uc788\uc5b4, \uc2e4\uc81c\ub85c\ub294 zero-shot \uc5d0\ub294 \ud604\uc2e4\uc801\uc774\uc9c0 \uc54a\uc74c"))),(0,i.kt)("li",{parentName:"ul"},"\uc7a0\uc7ac\uc801\uc778 \ubb38\uc81c\ub294 validation set \uc120\ud0dd",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"12 dataset set \uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uace0\ud558\uba70, \ubb34\uc791\uc704\uc758 27 dataset set \uc744 \uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"\uc774 set \uc740 \uba85\ubc31\ud788 CLIP \uac1c\ubc1c \ubc0f \uae30\ub2a5\uacfc \ud568\uaed8 \uc801\uc751\ub41c \uac83\uc73c\ub85c, \uad11\ubc94\uc704\ud55c zero-shot \ud3c9\uac00\ub97c \uc704\ud574 \uba85\uc2dc\uc801\uc73c\ub85c \uc124\uacc4\ub41c \uc791\uc5c5\uc758 \uc0c8\ub85c\uc6b4 \ubca4\uce58\ub9c8\ud06c\ub97c \ub9cc\ub4dc\ub294 \uac83\uc774 \uc774\ub7ec\ud55c \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub420 \uac83"))),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc740 \uc778\ud130\ub137\uc5d0\uc11c image \uc640 text \ub97c \uacb0\ud569\ud558\uc5ec \ud6c8\ub828",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7ec\ud55c image-text \uc30d\uc740 \ud544\ud130\ub9c1\ub418\uc9c0 \uc54a\uace0 \uc120\ubcc4\ub418\uc9c0 \uc54a\uc558\uc73c\uba70, CLIP \uc774 \ub9ce\uc740 \uc0ac\ud68c\uc801 \ud3b8\ud5a5\uc744 \ud559\uc2b5\ud558\uac8c \ub41c\ub2e4."),(0,i.kt)("li",{parentName:"ul"},"image caption model \uc5d0 \ub300\ud574 \uc774\uc804\uc5d0 \uc99d\uba85"))),(0,i.kt)("li",{parentName:"ul"},"\uc774 \uc5f0\uad6c\uc5d0\uc11c image classification \uc744 natural language \ub97c \ud1b5\ud574 \uba85\uc2dc\ud558\ub294 \uac83\uc774 \uc720\uc5f0\ud558\uace0 \uc77c\ubc18\uc801\uc778 \uc778\ud130\ud398\uc774\uc2a4\uc784\uc744 \uac15\uc870\ud588\uc9c0\ub9cc, \uc774\uac83\uc5d0\ub294 \uc81c\ud55c \uc0ac\ud56d \uc874\uc7ac",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ub9ce\uc740 complex task \uc640 visual concepts \ub294 text \ub9cc\uc73c\ub85c \uc9c0\uc815\ud558\uae30\uac00 \uc5b4\ub824\uc6b8 \uc218 \uc788\uc74c"),(0,i.kt)("li",{parentName:"ul"},"\uc2e4\uc81c training examples \ub294 \uba85\ubc31\ud558\uac8c \uc720\uc6a9\ud558\uc9c0\ub9cc, CLIP \ub294 few-shot \uc131\ub2a5\uc744 \uc9c1\uc811 \ucd5c\uc801\ud654\ud558\uc9c0\ub294 \uc54a\uc74c"))),(0,i.kt)("li",{parentName:"ul"},"\uc800\uc790\uc758 \uc5f0\uad6c\uc5d0\uc120 CLIP \uc758 feature top \uc5d0 linear classifier \ub97c \ub9de\ucd94\uac8c \ub428",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 zero-shot setting \uc5d0\uc11c few-shot setting \uc73c\ub85c \uc804\ud658\ud560 \ub54c \uc131\ub2a5\uc774 \ubc18\ub300\ub85c \uac10\uc18c\ud558\ub294 \uc774\uc0c1\ud55c \ud604\uc0c1\uc744 \ucd08\ub798"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uc778\uac04\uc758 \uc131\ub2a5\uacfc\ub294 \ud06c\uac8c \ub2e4\ub974\ub2e4",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc778\uac04\uc758 \uc131\ub2a5\uc740 zero-shot setting \uc5d0\uc11c 1-shot setting \uc73c\ub85c \uc804\ud658\ud568\uc73c\ub85c\uc368 \ud06c\uac8c \uc99d\uac00")))))),(0,i.kt)("h1",{id:"7-broader-impacts"},"7. Broader Impacts"),(0,i.kt)("p",null,"CLIP \uc758 \uc131\ub2a5\uacfc \ubaa9\uc801\uc5d0 \ub300\ud55c \ud3c9\uac00\uac00 \ud544\uc694\ud558\uba70, \uc774\ub97c \uc704\ud55c \ub354 \ub113\uc740 \uc601\ud5a5\uc744 \ubd84\uc11d"),(0,i.kt)("p",null,"\ub610\ud55c CLIP \uc740 \ucd94\uac00 re-training \uc5c6\uc774 \uc790\uc2e0\ub9cc\uc758 classifier \ub97c \ub9cc\ub4e4 \uc218 \uc788\ub294 \ub2a5\ub825 \uc18c\uac1c"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uc774 \ub2a5\ub825\uc740 GPT-3 \uc640 \uc720\uc0ac\ud55c large-scale generative models \uc758 \ud2b9\uc131\uc744 \ubcf5\ud569\ud558\uba70, \uc774\ub7ec\ud55c \ubaa8\ub378\uc740 \ube44\uad50\uc801 non-trivial zero-shot(\ub610\ub294 few-shot) generalization \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc11c \ub2e4\uc591\ud55c \ub2a5\ub825\uc744 \uac00\uc9c8 \uc218 \uc788\ub2e4."),(0,i.kt)("li",{parentName:"ul"},"\uc800\uc790\uc758 zero-shot setting \uc5d0\uc11c\uc758 CLIP \uc5f0\uad6c\ub294 image retrieval or search \uac19\uc740 widely-applicable tasks \uc5d0 \ub300\ud55c \uc720\ub9dd\uc131\uc744 \ubcf4\uc5ec\uc90c"),(0,i.kt)("li",{parentName:"ul"},"\uc774\uc804 30 dataset \uc5d0 \ucd94\uac00\ud558\uc5ec FairFace \uc5d0\uc11c \ud3c9\uac00\ud558\uace0 bias probes \uc2e4\uc2dc"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ud6c4, downstream task surveillance \uc5d0\uc11c \ube44\uad50 \ubd84\uc11d"),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c model \uc758 social biases \ub97c \ud2b9\uc131\ud654\ud558\uae30 \uc704\ud574 \ub178\ub825",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"bias test \ub294 \ub2e4\uc591\ud55c \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c\uc758 \ubc18\uc751\uc744 \uc870\uc0ac\ud558\ub294 \ucd08\uae30 \ub178\ub825\uc774\uba70, \ubc94\uc704\ub294 \ud55c\uc815")))),(0,i.kt)("h2",{id:"71-bias"},"7.1 Bias"),(0,i.kt)("p",null,"Buolamwini & Gebru (2018) \ubc0f Karkkainen & Joo (2019)\uc5d0\uc11c \uc81c\uc2dc\ub41c bias probes \uc5d0 \uc601\uac10\uc744 \ubc1b\uc544 CLIP \uc758 \uc77c\ubd80 bias \ub97c \uc608\ube44\uc801\uc73c\ub85c \ubd84\uc11d\ud558\uace0, Solaiman et al. (2019)\uac00 \uc2e4\uc2dc\ud55c \uac83\uacfc \uc720\uc0ac\ud55c specific bias examples \ub97c \ucc3e\uae30 \uc704\ud55c \ud0d0\uc0c9\uc801 bias search \uc218\ud589"),(0,i.kt)("p",null,"FairFace dataset \uc5d0\uc11c zero-shot CLIP \uc758 \uc131\ub2a5\uc744 \ubd84\uc11d\ud558\uc5ec initial bias probes \ub85c \uc2dc\uc791\ud558\uace0, class design \uc744 \ud3ec\ud568\ud55c additional biases \ubc0f biases sources \ub97c \ub354 \ud0d0\uad6c"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Table 3",src:t(20953).Z,width:"886",height:"411"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Table 4",src:t(73714).Z,width:"884",height:"503"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Table 5",src:t(62058).Z,width:"1485",height:"681"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"FairFace dataset \uc5d0\uc11c \ub450 \ubc84\uc804\uc758 CLIP \ud3c9\uac00",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"zero-shot CLIP (ZS CLIP) \uacfc CLIP featre \uc758 top \uc744 FairFace \uc5d0 fitting \ud55c logistic regression classifier (LR CLIP)",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"LR CLIP \uc774 classification test \uc5d0\uc11c ResNext-101 32x48d Instagram (Linear Probe Instagram) \ubc0f FairFace \uc790\uccb4 \ubaa8\ub378\ubcf4\ub2e4 \ub192\uc740 \uc815\ud655\ub3c4 \ub2ec\uc131"),(0,i.kt)("li",{parentName:"ul"},"ZS CLIP \uc131\ub2a5\uc740 \uce74\ud14c\uace0\ub9ac\ubcc4\ub85c \ub2e4\ub974\uba70 \uc77c\ubd80 \uce74\ud14c\uace0\ub9ac\uc5d0 \ub300\ud574 FairFace \ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub098\ube60\uc9c0\uace0 \ub2e4\ub978 \uce74\ud14c\uace0\ub9ac\ub294 \ub098\uc740 \uacb0\uacfc\ub97c \ubcf4\uc784 (Tab. 3, Tab. 4)"))),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c intersectional race \ubc0f gener \ub97c \uae30\uc900\uc73c\ub85c LR \ubc0f ZS CLIP \ud14c\uc2a4\ud2b8",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ubaa8\ub4e0 race \uc5d0 \ub300\ud574 gender \uc131\ub2a5\uc774 95% \uc774\uc0c1\uc784\uc744 \ubc1c\uacac (Tab. 5)"))))),(0,i.kt)("li",{parentName:"ul"},"LR CLIP \uc774 gener, race \ubc0f age \uc5d0 \ub530\ub978 classification \uc758 \uc815\ud655\ub3c4\uac00 Linear Probe Instagram \ubcf4\ub2e4 \ub192\uc740 \uc131\ub2a5\uc744 \ub2ec\uc131\ud588\uc9c0\ub9cc, bias \uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub294 real world \uc5d0\uc11c\uc758 \uacf5\uc815\uc131\uc5d0 \ub300\ud55c \uc758\ubbf8\uc788\ub294 \ucc99\ub3c4\ub85c\uc11c\ub294 \uc885\uc885 \uc2e4\ud328",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"sub-groups \uc5d0\uc11c \uc131\ub2a5 \ucc28\uc774\uac00 \ub0ae\uace0 \uc815\ud655\ub3c4\uac00 \ub192\uc544\uc9c4\ub2e4 \ud574\ub3c4, \uc774\ub294 bias \uac00 \ub0ae\uc544\uc9c8 \uac83\uc774\ub77c\ub294 \uac83\uc744 \uc758\ubbf8\ud558\uc9c4 \uc54a\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc608\ub85c, underrepresented groups \uc758 \ub192\uc740 \uc131\ub2a5\uc740 \ud68c\uc0ac\uac00 \uc5bc\uad74 \uc778\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc5ec group \uac04\uc5d0 \ube44\ub840\ud558\uc9c0 \uc54a\ub294 \ubc29\uc2dd\uc73c\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc73c\uba70, \uacb0\uacfc\uc801\uc73c\ub85c race, age \ubc0f gener \uc5d0 \ub530\ub978 \uc601\ud5a5\uc774 \ub2e4\ub974\uac8c \ubc1c\uc0dd\ud560 \uc218 \uc788\uc74c"),(0,i.kt)("li",{parentName:"ul"},"facial classification \uc0ac\uc6a9\uc740 \ubb38\uc81c \uc5c6\ub294 task \ub77c\ub294 \uac83\uc744 \uc2dc\uc0ac\ud558\uac70\ub098 \ubc30\ud3ec\ub41c \ub9e5\ub77d\uc5d0\uc11c race, age \ub610\ub294 gener classification \uc758 \uc0ac\uc6a9\uc744 \uc9c0\uc9c0\ud558\ub294 \uac83\uc774 \uc544\ub2d8\uc744 \uc758\ubbf8")))))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Table 6",src:t(6328).Z,width:"1772",height:"381"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Table 7",src:t(32359).Z,width:"1783",height:"403"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c Crawford (2017)\uc5d0\uc11c \uc124\uba85\ud55c \ud45c\ud604\uc801 \ud53c\ud574\ub97c \uc720\ubc1c\ud560 \uac00\ub2a5\uc131\uc774 \ub192\uc740 classification tmers \ub97c \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub378\uc744 \uac80\uc0ac",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"ZS CLIP \uc774 FairFace \uc758 10,000 images \ub97c \ubd84\ub958\ud558\ub3c4\ub85d \uc694\uad6c\ud558\ub294 \uc2e4\ud5d8\uc744 \uc9c4\ud589"),(0,i.kt)("li",{parentName:"ul"},"FairFace classes \uc678\uc5d0\ub3c4 'animal', 'gorilla', 'chimpanzee', 'orangutan', 'thief', 'criminal', 'suspicius person' \ucd94\uac00"),(0,i.kt)("li",{parentName:"ul"},"\uc774 \uc2e4\ud5d8\uc758 \ubaa9\ud45c\ub294 \ubaa8\ub378\uc774 \uc5b4\ub5a4 demographic subgroups \uc5d0 \ub300\ud574 \ud3b8\uacac\uc774\ub098 \ud53c\ud574\ub97c \ub354 \ub9ce\uc774 \uc904 \uc218 \uc788\ub294\uc9c0 \ud655\uc778\ud558\ub294 \uac83"))),(0,i.kt)("li",{parentName:"ul"},"\uc774\ubbf8\uc9c0\uc758 4.9% (confidence intervals \ub294 4.6% ~ 5.4% \uc0ac\uc774)\uac00 \uc800\uc790\uc758 probes \uc5d0\uc11c \uc0ac\uc6a9\ud55c non-human classes('animal', 'chimpanzee', 'gorilla', 'orangutan') \uc911 \ud558\ub098\ub85c \uc798\ubabb \ubd84\ub958\ub418\uc5c8\uc74c\uc744 \ubc1c\uacac",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774 \uc911 'Black' image \uc758 misclassification rate \uac00 \uac00\uc7a5 \ub192\uc558\uc73c\uba70(\uc57d 14%; confidence intervals \ub294 ","[12.6% ~ 16.4%]","), \ub2e4\ub978 \ubaa8\ub4e0 race \ub294 8% \ubbf8\ub9cc\uc758 misclassification rate \ub97c \ubcf4\uc784"),(0,i.kt)("li",{parentName:"ul"},"0-20\uc138\uc758 \uc0ac\ub78c\ub4e4 \uc911 14% \uac00 \uc774 \uce74\ud14c\uace0\ub9ac\uc5d0 \ubd84\ub958"))),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c, \ub0a8\uc131 \uc774\ubbf8\uc9c0\uc758 16.5% \uac00 \ubc94\uc8c4\uc640 \uad00\ub828\ub41c class('thief', 'suspicious person', 'criminal')\ub85c missclassify \ub418\uc5c8\uc73c\uba70, \uc5ec\uc131 \uc774\ubbf8\uc9c0\uc758 9.8% \uac00 \uc774\uc5d0 \ud574\ub2f9",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ud765\ubbf8\ub86d\uac8c, 0-20\uc138 \uc0ac\ub78c\ub4e4\uc740 \ubc94\uc8c4 \uad00\ub828 \ud074\ub798\uc2a4\uc5d0 \uc18d\ud560 \ud655\ub960\uc774 \ub2e4\ub978 \uc5f0\ub839\ub300 \uc774\ubbf8\uc9c0\ubcf4\ub2e4 \ub192\uc558\uc74c(\uc57d 18%)"),(0,i.kt)("li",{parentName:"ul"},"race \uac04\uc5d0 \ubc94\uc8c4 \uad00\ub828 \uc6a9\uc5b4\uc5d0 \ub300\ud55c \ubd84\ub958\uc758 \ucc28\uc774\uac00 \uc788\uc5c8\uc74c (Tab. 6)"))),(0,i.kt)("li",{parentName:"ul"},"20\uc138 \ubbf8\ub9cc\uc778 \uc0ac\ub78c\ub4e4\uc774 \ubc94\uc8c4 \uad00\ub828 \ubc0f non-human animal \uce74\ud14c\uace0\ub9ac\uc5d0 \uac00\uc7a5 \uc790\uc8fc \ubd84\ub958\ub418\uc5c8\uc74c\uc744 \uad00\ucc30\ud588\uae30 \ub54c\ubb38\uc5d0, \ub3d9\uc77c\ud55c \ud074\ub798\uc2a4\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub3d9\uc77c\ud55c \uce74\ud14c\uace0\ub9ac\ub85c \uc774\ubbf8\uc9c0\ub97c \ubd84\ub958\ud558\ub294 \uc2e4\ud5d8\uc744 \uc9c4\ud589",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ubaa9\ud45c\ub294 \uc774\ub7ec\ud55c classification \uc758 age \uc5d0 \ub530\ub978 \ud53c\ud574\uc758 \ubd84\ud3ec\uac00 \uc5b4\ub5bb\uac8c \ubcc0\uacbd\ub418\ub294\uc9c0 \ud655\uc778\ud558\ub294 \uac83"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub85c \uc778\ud574 20\uc138 \ubbf8\ub9cc \uc0ac\ub78c\ub4e4\uc758 \uc218\uac00 \ubc94\uc8c4 \uad00\ub828 \uce74\ud14c\uace0\ub9ac\ub098 non-human animal \uce74\ud14c\uace0\ub9ac\uc5d0 \ubd84\ub958\ub41c \uc774\ubbf8\uc9c0 \uc218\uac00 \ud06c\uac8c \uc904\uc5b4\ub4e0 \uac83\uc744 \ubc1c\uacac (Tab. 7)"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 class design \uc774 \ubaa8\ub378\uc758 \uc131\ub2a5\ubfd0 \uc544\ub2c8\ub77c \ubaa8\ub378\uc774 \ud45c\ud604\ud558\ub294 \uc6d0\uce58 \uc54a\ub294 bias \uc774\ub098 behavior \ub97c \uacb0\uc815\ud558\ub294 \uc8fc\uc694 \uc694\uc778\uc774 \ub420 \uc218 \uc788\uc74c\uc744 \ub098\ud0c0\ub0c4")))),(0,i.kt)("p",null,"\uc774\ub7ec\ud55c probe results \ub294 \ud3ec\ud568\ub418\ub294 \ud074\ub798\uc2a4 \uce74\ud14c\uace0\ub9ac\uc640 \uac01 \ud074\ub798\uc2a4\ub97c \uc124\uba85\ud558\ub294 \ud2b9\uc815 \uc5b8\uc5b4\uc5d0 \ub530\ub77c \ubcc0\uacbd\ub420 \uc218 \uc788\ub2e4. Poor class design \uc740 \uc2e4\uc81c \uc131\ub2a5\uc774 \ub098\ube60\uc9c8 \uc218 \uc788\uc73c\uba70, \uc774\ub7ec\ud55c \uc6b0\ub824\ub294 \ud2b9\ud788 CLIP \uac19\uc740 \ubaa8\ub378\uc5d0\uac8c \uc911\uc694\ud558\ub2e4. \uac1c\ubc1c\uc790\uac00 \uc790\uc2e0\uc758 \ud074\ub798\uc2a4\ub97c \uc27d\uac8c \ub514\uc790\uc778\ud560 \uc218 \uc788\uae30 \ub54c\ubb38\uc774\ub2e4."),(0,i.kt)("p",null,"Schwemmer et al. (2020)\uc5d0\uc11c \uc81c\uc2dc\ud55c \uac83\uacfc \uc720\uc0ac\ud55c \uc2e4\ud5d8\uc744 \uc218\ud589\ud558\uc5ec Members of Congress images \ub97c \uc0ac\uc6a9\ud558\uc5ec CLIP \uc774 \ub0a8\uc131\uacfc \uc5ec\uc131 \uc774\ubbf8\uc9c0\ub97c \ub2e4\ub974\uac8c \ucc98\ub9ac\ud558\ub294 \ubc29\uc2dd\uc744 \ud14c\uc2a4\ud2b8."),(0,i.kt)("p",null,"\uc800\uc790\ub294 \uc138 \uac00\uc9c0\ub97c \ud14c\uc2a4\ud2b8 \ud55c\ub2e4. gener classification \uc758 \uc815\ud655\ub3c4\uc640 two different label sets \uac04\uc5d0 \uc5b4\ub5bb\uac8c \ubd84\uc0b0\ub418\ub294\uc9c0 \ud14c\uc2a4\ud2b8\ud558\ub294\ub370, first label set \uc740 300 label set \uc744 \uc0ac\uc6a9\ud558\uc600\uc73c\uba70, second label set \uc740 Google Cloud Vision, Amazon Rekognition \ubc0f Microsoft Azure Computer Vision \uc774 \ubaa8\ub4e0 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud574 \ubc18\ud658\ud55c \ub808\uc774\ube14\uc744 \uacb0\ud569\ud55c \uac83."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Members of Congress images \ub97c \uc0ac\uc6a9\ud574 \ubaa8\ub378\uc758 gender prediction \uc131\ub2a5\uc744 \uc0b4\ud3b4\ubd04",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"official setting/position of power \uc5d0 \uc788\ub294 \uc0ac\ub78c\uc758 image \ub97c \ubcf4\uace0 gener \ub97c \uc62c\ubc14\ub974\uac8c \uc778\uc2dd\ud558\ub294\uc9c0 \ud655\uc778\ud558\uae30 \uc704\ud568"),(0,i.kt)("li",{parentName:"ul"},"\ubaa8\ub378\uc774 100% \uc815\ud655\ub3c4\ub97c \ub2ec\uc131"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 FairFace dataset \uc131\ub2a5\uc774 \uc6b0\uc218\ud55c \uac83\uc73c\ub85c \ub098\ud0c0\ub098\uba70, Members of Congress dataset \uc758 \ubaa8\ub4e0 \uc774\ubbf8\uc9c0\uac00 FairFace \uc640\ub294 \ub2e4\ub974\uac8c high-quality \uc774\uace0 clear \ud558\uac8c \uc911\uc559 \uc815\ub82c\ub418\uc5b4 \uc788\uae30 \ub54c\ubb38\uc73c\ub85c \ucd94\uce21."))),(0,i.kt)("li",{parentName:"ol"},"label probability \uc5d0 \ub300\ud55c threshold \ub97c \uc124\uc815\ud558\uc5ec \ubc18\ud658\ub41c label \uc758 bias \uac00 \uc5b4\ub5bb\uac8c \ub2ec\ub77c\uc9c0\ub294\uc9c0 \uc2e4\ud5d8",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"threshold 0.5% \ubc0f 4.0% \ub85c \uc124\uc815\ud558\uc5ec \uc2e4\ud5d8"),(0,i.kt)("li",{parentName:"ul"},"lower threshold \uac00 lower quality \uc758 label \uc744 \uc720\ub3c4\ud558\ub294 \uacbd\ud5a5\uc744 \ubc1c\uacac",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 threshold \ud558\uc5d0 label distribution \uc758 \ucc28\uc774\ub3c4 bias signal \uc744 \uac16\uc744 \uc218 \uc788\ub2e4."),(0,i.kt)("li",{parentName:"ul"},'\uc608\ub85c, 0.5% threshold \ud558\uc5d0\uc120 "nanny" \ub098 "housekeeper" \uac19\uc740 label \uc740 \uc5ec\uc131\uc5d0\uac8c, "prisoner" \ubc0f "mobster" \uac19\uc740 label \uc740 \ub0a8\uc131\uc5d0\uac8c \ub098\ud0c0\ub098\ub294 \uac83\uc744 \ubc1c\uacac')))))),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},'higher 4% threshold \uc5d0\uc120 both gender \uc5d0\uc11c highest probabiliy \ub97c \uac00\uc9c4 label \uc5d0\ub294 "lowmaker", "legislator" \ubc0f "congressman" \uc774 \ud3ec\ud568',(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},'\uc774\ub7f0 bias \ub294 lower probability labels \uc5d0\uc11c\ub3c4 \ub098\ud0c0\ub098\uba74\uc11c "sufficiently" safe behavior \uc774 \ubb34\uc5c7\uc778\uc9c0 \uc81c\uae30')))),(0,i.kt)("ol",{start:3},(0,i.kt)("li",{parentName:"ol"},"Google Cloud Vision (GCV), Amazon Rekognition \ubc0f Microsoft \uac00 \ubc18\ud658\ud55c label \uc758 \uacb0\ud569\uc14b\uc744 \uc0ac\uc6a9\ud560 \ub54c, GCV system \uc5d0\uc11c \ubc1c\uacac\ub41c bias \uac00 \uc800\uc790\uc758 \uc2dc\uc2a4\ud15c\uc5d0\ub3c4 \uc720\uc0ac\ud558\uac8c \ub098\ud0c0\ub0a8",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc5ec\uc131\uc5d0\uac8c \ub354 \ub9ce\uc774 'brown hair', 'blonde' \ubc0f 'blond' \uac19\uc740 label \uc774 \ubd80\uc5ec\ub418\ub294 \uacbd\ud5a5\uc774 \uc788\uc74c",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uac8c\ub2e4\uac00 CLIP \ub294 'executive' \ub098 'doctor' \uac19\uc740 \uace0\uc704 \uc9c1\ucc45\uc744 \ub0a8\uc131\uc5d0\uac8c \ubd88\uade0\ud615\ud558\uac8c \uc790\uc8fc \ubd80\uc5ec"),(0,i.kt)("li",{parentName:"ul"},"\uc5ec\uc131\uc5d0\uac8c \ub354 \uc790\uc8fc \ubd80\uc5ec\ub41c \ub124 \uac00\uc9c0 \uc9c1\uc5c5 \uac00\uc6b4\ub370 \uc138 \uac00\uc9c0\ub294 'newscaster', 'television presenter', 'newsreader' \uc774\uace0 \ub124 \ubc88\uc9f8\ub294 'Judge' \uc600\uc74c"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 GCV \uc5d0\uc11c \ubc1c\uacac\ub41c \ud3b8\ud5a5\uacfc \uc720\uc0ac\ud558\uba70, \uc5ed\uc0ac\uc801\uc778 \uc131\ubcc4 \ucc28\ubcc4\uc744 \ubcf4\uc5ec\uc90c"))),(0,i.kt)("li",{parentName:"ul"},"label set \uc5d0 threshold 0.5% \ub85c \ub0ae\ucd94\uc5c8\uc744 \ub54c, \ub0a8\uc131\uc744 \ub354 \uc790\uc138\ud788 \ubb18\uc0ac\ud558\ub294 label \ub3c4 'suit', 'tie' \ubc0f 'necktie' \uac19\uc740 \uc678\ubaa8 \uc9c0\ud5a5\uc801\uc778 \ub2e8\uc5b4\ub85c \uc774\ub3d9\ud558\ub294 \uac83\uc744 \ubc1c\uacac"),(0,i.kt)("li",{parentName:"ul"},"\uc5ec\uc131 \uc774\ubbf8\uc9c0\uc5d0 \uc0ac\uc6a9\ub418\uc9c0 \uc54a\uc740 \uc9c1\uc5c5 \uc9c0\ud5a5 \ub2e8\uc5b4\uac00 \ub0a8\uc131\uacfc \uc5ec\uc131 \ubaa8\ub450\uc5d0\uac8c \uc0ac\uc6a9\ub418\uc5c8\uc74c")))),(0,i.kt)("p",null,"\uc774\ub7ec\ud55c \uc2e4\ud5d8\uc740 Design decision \uc774 \uc5b4\ub5bb\uac8c biases \uac00 \ub098\ud0c0\ub098\ub294\uc9c0\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\uba70, \ud2b9\ud788 CLIP \uc758 \uc720\uc5f0\uc131\uc744 \uace0\ub824\ud560 \ub54c \uc911\uc694\ud558\ub2e4."),(0,i.kt)("p",null,"training data \uc640 model architecture \ubfd0\ub9cc \uc544\ub2c8\ub77c class design \ubc0f threshold \uac19\uc740 \uc694\uc18c\uc5d0 \ub300\ud55c \uacb0\uc815\uc740 \ubaa8\ub378\uc774 \ucd9c\ub825\ud558\ub294 label \uc744 \ubcc0\uacbd\uc2dc\ud0ac \uc218 \uc788\uc73c\uba70, \uacb0\uacfc\uc801\uc73c\ub85c Crawford(2017)\uc5d0 \uc124\uba85\ub41c \ud2b9\uc815 \uc720\ud615\uc758 \ud53c\ud574\ub97c \ub192\uc774\uac70\ub098 \ub0ae\ucd9c \uc218 \uc788\uc2b5\ub2c8\ub2e4. "),(0,i.kt)("h2",{id:"72-surveillance"},"7.2 Surveillance"),(0,i.kt)("p",null,"\uc800\uc790\ub294 \uc0ac\ud68c\uc801\uc73c\ub85c \ubbfc\uac10\ud55c downstream task : surveillance \uc640 \uad00\ub828\ud558\uc5ec \ubaa8\ub378\uc744 \ud2b9\uc815\ud55c\ub2e4."),(0,i.kt)("p",null,"\uc800\uc790\uc758 \ubd84\uc11d \ubaa9\ud45c\ub294 characterization approach \ub97c \ub354 \uc798 \ubc18\uc601\ud558\uace0 \uaddc\ubc94\uacfc \uc810\uac80\uc744 \uc9c0\uc6d0\ud558\ub294 \uac83\uc744 \ubaa9\ud45c\ub85c \ud55c\ub2e4."),(0,i.kt)("p",null,"surveillance \ud3ec\ud568\uc740 \uc774 domain \uc5d0 \ub300\ud55c \uad00\uc2ec\uc774 \uc544\ub2c8\uba70, surveillance \uac00 \uc0ac\ud68c\uc801 \uc601\ud5a5\uc744 \uace0\ub824\ud560 \ub54c \uc2dc\ub3c4\ud574\uc57c\ud560 \uc911\uc694\ud55c domain \uc774\ub77c \uc0dd\uac01"),(0,i.kt)("p",null,"\uc800\uc790\ub294 model \uc131\ub2a5\uc744 CCTV camera image \uc758 classification \uce21\uc815 \ubc0f zero-shot celebrity identification \uc9c4\ud589"),(0,i.kt)("p",null,"\uba3c\uc800, low-resolusion images captured from  surveillance cameras (e.g. CCTV) \uc5d0\uc11c test \uc9c4\ud589"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"VIRAT dataset \uacfc Varadarajan & Odobez (2009) dataset \uc744 \uc0ac\uc6a9\ud588\ub294\ub370, \uc774\ub4e4\uc740 \ubaa8\ub450 real world outdoor scenes \uc640 non-actors \ud3ec\ud568",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"CLIP \uc758 \uc720\uc5f0\ud55c \ud074\ub798\uc2a4 \uad6c\uc131\uc744 \uace0\ub824\ud574 12 different video sequences \uc5d0\uc11c \ucea1\ucc98\ud55c 515 surveillance images \ub97c \ub300\uc0c1\uc73c\ub85c self-constructed general class \ub97c \ub300\uc0c1\uc73c\ub85c \uc138\ubc00\ud558\uace0 \uc815\uad50\ud55c \ubd84\ub958\ub97c \ud14c\uc2a4\ud2b8 \uc9c4\ud589"),(0,i.kt)("li",{parentName:"ul"},"Coarse classification \uc5d0\uc120 \ubaa8\ub378\uc774 \uc774\ubbf8\uc9c0\uc758 \uc8fc\uc694 \ub300\uc0c1\uc744 \uc62c\ubc14\ub974\uac8c \uc2dd\ubcc4\ud574\uc57c \ud568 (i.g., \ube48 \uc8fc\ucc28\uc7a5, \ud559\uad50 \ucea0\ud37c\uc2a4 \ub4f1\uc758 \uc0ac\uc9c4\uc778\uc9c0 \uc5ec\ubd80\ub97c \uacb0\uc815)",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ubbf8\uc9c0 \ub0b4\uc6a9\uc744 \uc790\uccb4\uc801\uc73c\ub85c caption \uc73c\ub85c \uc9c0\uc5b4\uc11c class \ub97c \uad6c\uc131\ud588\uc73c\uba70, \ubaa8\ub378\uc774 \uc120\ud0dd\ud560 \uc218 \uc788\ub294 \uc635\uc158\uc774 \ud56d\uc0c1  least 6 options \uc774\uc0c1\uc774\ub2e4"),(0,i.kt)("li",{parentName:"ul"},"\uac8c\ub2e4\uac00, 'stress test' \ub97c \uc2e4\uc2dc\ud588\ub294\ub370, \uc774\ub54c class set \uc5d0 \uc774\ubbf8\uc9c0\uc640 '\uac00\uae4c\uc6b4' \ud56d\ubaa9\uc744 \uc124\uba85\ud558\ub294 caption \uc911 \ud558\ub098 \uc774\uc0c1\uc774 \ud3ec\ud568 (\uc608: '\ud770\uc0c9 \ucc28\uac00 \uc788\ub294 \uc8fc\ucc28\uc7a5' \ub300 '\ube68\uac04\uc0c9 \ucc28\uac00 \uc788\ub294 \uc8fc\ucc28\uc7a5'). \uc6b0\ub9ac\ub294 \ucd08\uae30 \ud3c9\uac00\uc5d0\uc11c CCTV \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \ubaa8\ub378\uc758 \uc0c1\uc704 1\uc704 \uc815\ud655\ub3c4\uac00 91.8%\uc600\uc74c\uc744 \ubc1c\uacac\ud588\uc2b5\ub2c8\ub2e4. \ub450 \ubc88\uc9f8 \ud3c9\uac00\uc5d0\uc11c \uc815\ud655\ub3c4\ub294 \ud06c\uac8c 51.1%\ub85c \ub5a8\uc5b4\uc84c\uc73c\uba70, \ubaa8\ub378\uc740 '\uac00\uae4c\uc6b4' \ub2f5\ubcc0\uc744 40.7%\uc758 \ube44\uc728\ub85c \uc798\ubabb \uc120\ud0dd\ud588\uc2b5\ub2c8\ub2e4."))),(0,i.kt)("li",{parentName:"ul"},"Fine-grained classification \uc5d0\uc120 \ubaa8\ub378\uc774 \uc774\ubbf8\uc9c0\uc758 \uc791\uc740 \ud2b9\uc9d5 (e.g. \uad6c\uc11d\uc5d0 \uc11c \uc788\ub294 \uc0ac\ub78c)\uc758 \uc874\uc7ac \ub610\ub294 \ubd80\uc7ac\ub97c \ud310\ub2e8\ud558\uae30 \uc704\ud574 \uad6c\uc131\ub41c \ub450 \uac00\uc9c0 \uc635\uc158 \uc911\uc5d0\uc11c \uc120\ud0dd\ud574\uc57c \ud568",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc138\ubc00\ud55c \uac10\uc9c0\uc5d0\uc11c\ub294 \uc81c\ub85c\uc0f7 \ubaa8\ub378\uc774 \uc131\ub2a5\uc774 \ub0ae\uc558\uc73c\uba70, \uacb0\uacfc\uac00 \uac70\uc758 \ubb34\uc791\uc704\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4. \uc720\uc758\ud560 \uc810\uc740 \uc774 \uc2e4\ud5d8\uc774 \uc774\ubbf8\uc9c0 \uc2dc\ud000\uc2a4\uc5d0\uc11c \uc791\uc740 \uac1d\uccb4\uc758 \uc874\uc7ac \ub610\ub294 \ubd80\uc7ac\ub97c \uac10\uc9c0\ud558\uae30 \uc704\ud574\uc11c\ub9cc \ub300\uc0c1\uc73c\ub85c \ud588\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4.")))))),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Table 8",src:t(47246).Z,width:"899",height:"378"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c CelebA dataset \uc744 \uc0ac\uc6a9\ud558\uc5ec 'in the wild' \uc758 \uc2e0\uc6d0 \uac10\uc9c0\uc5d0 \ub300\ud55c CLIP zero-shot \uc744 \ud14c\uc2a4\ud2b8",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub97c \ud1b5\ud574 \ubaa8\ub378\uc774 pre-training \ub41c public data \ub9cc \uc0ac\uc6a9\ud558\uc5ec \uc2e0\uc6d0 \uac10\uc9c0\uc758 \uc131\ub2a5\uc744 \uc5bc\ub9c8\ub098 \uc798 \ud558\ub294\uc9c0\ub97c \ud3c9\uac00"),(0,i.kt)("li",{parentName:"ul"},"celebrity images dataset \uc5d0\uc11c \uc774\ub97c \ud14c\uc2a4\ud2b8\ud588\uc9c0\ub9cc, \ubaa8\ub378\uc774 \uc774\ub984\uacfc \uc5bc\uad74\uc744 \uc5f0\uacb0\ud558\uae30 \uc704\ud574 \ud544\uc694\ud55c pre-training data \uc591\uc774 \uacc4\uc18d \uac10\uc18c\ud560 \uac83\uc73c\ub85c \uac00\uc815 (Tab. 8)"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uc911\uc694\ud55c \uc0ac\ud68c\uc801 \uc601\ud5a5\uc744 \ubbf8\uce5c\ub2e4. \ucd5c\uadfc NLP \ubd84\uc57c\uc758 \ucd5c\uadfc \ubc1c\uc804\uacfc \uc720\uc0ac\ud558\uba70, \uc774\ub7ec\ud55c LLM \uc740 \uc778\ud130\ub137 \ub370\uc774\ud130\ub97c \uae30\ubc18\uc73c\ub85c \uaf64 \uc791\uc740 \uacf5\uac1c \uc778\ubb3c\uc5d0 \uad00\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\ub294 \ub180\ub77c\uc6b4 \ub2a5\ub825\uc744 \uac00\uc9c0\uace0 \uc788\ub2e4"))),(0,i.kt)("li",{parentName:"ul"},"\uc800\uc790\ub294 'in the wild' 8k celebrity images \uc5d0 \ub300\ud574 100 possible classes \uc911 59.2% top-1 accuracy \ub97c \uac16\ub294 \ubaa8\ub378\uc744 \ubc1c\uacac.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 \uc774 \uc131\ub2a5\uc740 class size \ub97c 1k celebrity names \ub85c \ud655\uc7a5\ud588\uc744 \ub54c 43.3% \ub85c \ub5a8\uc5b4\uc9d0",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774 \uc131\ub2a5\uc740 Google \uc758 Celebrity Recognition \uacfc \uac19\uc740 \uc0dd\uc0b0 \uc218\uc900\uc758 \ubaa8\ub378\uacfc \ube44\uad50\ud558\uba74 \uacbd\uc7c1\ub825\uc774 \uc5c6\ub2e4"),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 \uc774\ub7ec\ud55c \uacb0\uacfc\ub97c \uc8fc\ubaa9\ud560 \ub9cc\ud55c \uc810\uc740 \uc774 \ubd84\uc11d\uc774 pre-training data \uc5d0\uc11c \ucd94\ub860\ub41c names \ub97c \uae30\ubc18\uc73c\ub85c \ud55c zero-shot identification \ub2a5\ub825\ub9cc\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc218\ud589\ub418\uc5c8\ub2e4\ub294 \uac83 - additional task-specific dataset \uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc558\uc73c\ubbc0\ub85c (\uc0c1\ub300\uc801\uc73c\ub85c) \uac15\ub825\ud55c \uacb0\uacfc\ub294 \uc774\ub7ec\ud55c \uc2dc\uc2a4\ud15c\uc744 \uc8fc\uc5b4\uc9c4 \ubb38\ub9e5\uacfc \ub3c4\uba54\uc778\uc5d0\uc11c \uc870\uc2ec\uc2a4\ub7fd\uac8c \uc5f0\uad6c\ud574\uc57c \ud560 \ud544\uc694\uc131\uc744 \ub354\uc6b1 \uac15\uc870"))))),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc740 \uc81c\ub85c\uc0f7 \ub2a5\ub825\uc744 \uac00\uc9c0\uace0 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc0c1\ub300\uc801\uc73c\ub85c \uc801\uc740 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\ub294 task \uc5d0 \ub300\ud574 \uc0c1\ub2f9\ud55c \uc774\uc810\uc744 \uc81c\uacf5",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 \ub9ce\uc740 \uc218\uc694\uac00 \uc788\ub294 surveillance task \uc5d0 \ub300\ud574 large datasets \uacfc \uace0\uc131\ub2a5 supervised model \uc774 \uc774\ubbf8 \uc874\uc7ac\ud558\uae30 \ub54c\ubb38\uc5d0, CLIP \uc758 \uc774\ub7ec\ud55c \uc6a9\ub3c4\uc5d0 \ub300\ud55c \ube44\uad50\uc801 \ub9e4\ub825\uc740 \ub0ae\ub2e4"),(0,i.kt)("li",{parentName:"ul"},"\uac8c\ub2e4\uac00, CLIP \ub294 object detection \uacfc semantic segmentation \uac19\uc740 \uc77c\ubc18\uc801\uc778 surveillance-relevant tasks \uc5d0 \ub300\ud574 \uc124\uacc4\ub418\uc9c0 \uc54a\uc558\ub2e4",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 \uc774\ub7ec\ud55c \uc6a9\ub3c4\ub85c \uc124\uacc4\ub41c \ubaa8\ub378\uc778 Detectron2 \uac19\uc740 \ubaa8\ub378\uc774 \ub110\ub9ac \uc0ac\uc6a9 \uac00\ub2a5\ud55c \uacbd\uc6b0\uc5d0\ub294 \ud2b9\uc815 surveillance tasks \uc5d0 \ub300\ud574 \uc81c\ud55c\uc801\uc73c\ub85c \uc0ac\uc6a9\ub418\ub294 \uac83\uc744 \uc758\ubbf8"))))),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 CLIP \uc740 training data \uac00 \ud544\uc694\ud558\uc9c0 \uc54a\uc740 \uce21\uba74\uc758 \uc0ac\uc6a9\uc131\uc744 \uc81c\uacf5\ud558\uae30 \ub54c\ubb38\uc5d0 \ud2b9\uc815 \uc0ac\uc6a9\uc790 \uc815\uc758 \ubc0f \ud2b9\uc218\ud55c surveillance case \ub97c \uac00\ub2a5\ucf00 \ud568",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ub530\ub77c\uc11c CLIP \ubc0f \uc720\uc0ac\ud55c \ubaa8\ub378\uc740 \ud2b9\ubcc4\ud788 \ub9de\ucda4\ud654\ub41c \ubaa8\ub378\uc774\ub098 \ub370\uc774\ud130\uc14b\uc774 \uc5c6\ub294 \uc791\uc740 \uc218\uc694 \uac10\uc2dc \uc0ac\uc6a9 \uc0ac\ub840\ub97c \uac00\ub2a5\ud558\uac8c \ud560 \uc218 \uc788\uc73c\uba70, \uc774\ub294 \uc774\ub7ec\ud55c \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \uad6c\ucd95\ud558\ub294 \ub370 \ud544\uc694\ud55c \uae30\uc220 \uc694\uad6c \uc0ac\ud56d\uc744 \ub0ae\ucd9c \uc218 \uc788\ub2e4. ")))),(0,i.kt)("h2",{id:"73-future-work"},"7.3 Future Work"),(0,i.kt)("p",null,"\ucd08\uae30 \ubd84\uc11d\uc740 \uc77c\ubc18\uc801\uc778 vision model \uc758 \ub3c4\uc804\uacfc bias \uc601\ud5a5\uc744 \ubcf4\uc558\uace0, \ub2e8\uc810 \ubc0f bias \ub97c \ud2b9\uc131\ud654\ud558\ub294 \ubbf8\ub798 \uc5f0\uad6c\ub97c \ucd09\uc9c4"),(0,i.kt)("p",null,"CLIP \uc758 \ud2b9\uc131\ud654\ud558\uace0, \uc720\ub9dd\ud55c \uc131\ub2a5\uc744 \ubc1c\ud718\ud558\ub294 \uac83\uc774 \uc911\uc694."),(0,i.kt)("p",null,"\uc800\uc790\ub294 \ub2e4\uc74c\uc758 \uc774\uc720\ub85c \uc720\uc775\ud560 \uac00\ub2a5\uc131\uc774 \ub192\ub2e4\uace0 \ubcf8\ub2e4."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uc5f0\uad6c \uacfc\uc815 \ucd08\uae30\uc5d0 \ubaa8\ub378\uc758 \uc7a0\uc7ac\uc801\uc73c\ub85c \uc720\uc775\ud55c downstream task \uc0ac\uc6a9\uc744 \uc2dd\ubcc4\ud568\uc73c\ub85c\uc368 \uc751\uc6a9 \ubd84\uc57c\ub97c \uace0\ub824"),(0,i.kt)("li",{parentName:"ul"},"\uc0ac\ud68c\uc801 \uc774\ud574\uad00\uacc4\uc790\uc758 \ub9ce\uc740 \uc9d1\ud569\uacfc \uc911\uc694\ud55c \ubbfc\uac10\uc131\uc744 \uac00\uc9c4 \uc791\uc5c5\uc744 \ubd80\uac01\uc2dc\ud0b4\uc73c\ub85c\uc368, \uc815\ucc45 \uacb0\uc815\uc790\uc758 \uac1c\uc785\uc744 \uc694\uad6c\ud560 \uc218 \uc788\ub294 \uc791\uc5c5\uc744 \ub3c4\ucd9c"),(0,i.kt)("li",{parentName:"ul"},"\ubaa8\ub378\uc758 bias \uc744 \ub354 \uc798 \ud2b9\uc131\ud654\ud558\uc5ec \uc6b0\ub824\ub418\ub294 \uc601\uc5ed\uacfc \uac1c\uc785\uc774 \ud544\uc694\ud55c \uc601\uc5ed\uc744 \uc54c\ub9bc"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uac19\uc740 \uc2dc\uc2a4\ud15c\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud55c test suite \uc744 \uc0dd\uc131\ud568\uc73c\ub85c\uc368, \uac1c\ubc1c \uc8fc\uae30 \ucd08\uae30\uc5d0 \ubaa8\ub378 \ub2a5\ub825\uc744 \ub354 \uc798 \ud2b9\uc131\ud654\ud568"),(0,i.kt)("li",{parentName:"ul"},"\uc7a0\uc7ac\uc801\uc778 \uc2e4\ud328 \ubaa8\ub4dc\uc640 \ucd94\uac00 \uc791\uc5c5 \uc601\uc5ed\uc744 \uc2dd\ubcc4\ud568")),(0,i.kt)("h1",{id:"8-related-work"},"8. Related Work"),(0,i.kt)("p",null,"\uc77c\ubc18\uc801\uc73c\ub85c human language \ub97c training signal \ub85c \ud65c\uc6a9\ud558\ub294 \uacbd\uc6b0, supervision \uc744 \uc0ac\uc6a9\ud55c\ub2e4."),(0,i.kt)("p",null,"NLP task \uc5d0\uc11c description, feedback, instruction \ubc0f device \uac19\uc740 \ud615\ud0dc\uc758 natural language supervision \uc744 \ud65c\uc6a9\ud558\uc5ec \ucc3d\uc758\uc801\uc774\uace0 \uace0\uae09\uc2a4\ub7ec\uc6b4 \ubc29\ubc95\uc73c\ub85c \ud0d0\uad6c\ub41c\ub2e4"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"CLIP \uc740 language \uc678\uc758 domain \uc5d0\uc11c training signal \ub85c natural language \ub97c \uc0ac\uc6a9",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774\ub294 natural language supervision \uc774 video event understanding task \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uc704\ud574 natural language description \uc744 supervision source \ub85c \uc0ac\uc6a9 \uac00\ub2a5\ud568\uc744 \ubcf4\uc5ec\uc900 Ramanathan et al (2013)\uc758 task \uc774\ub2e4"),(0,i.kt)("li",{parentName:"ul"},"\ub2e4\ub978 \ucd08\uae30 \uc5f0\uad6c\ub294 image \uc640 related tag (not natural language)\ub97c \uc0ac\uc6a9\ud558\uc5ec semantic segmentation task \uc5d0 \ud65c\uc6a9\ud588\ub2e4."),(0,i.kt)("li",{parentName:"ul"},"\ub354 \ucd5c\uadfc\uc5d0\ub294 natural language description \uc744 fine-grained visual classification birds \uac1c\uc120\uc5d0 \uc0ac\uc6a9\ub418\uac70\ub098 visual representation \ubc0f classifier \uac1c\uc120\uc5d0 \uc5f0\uad6c\ub97c \ud558\uae30\ub3c4 \ud55c\ub2e4"),(0,i.kt)("li",{parentName:"ul"},"\ub9c8\uc9c0\ub9c9\uc73c\ub85c, natural language \ub97c supervision \uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \uae30\uc220\uacfc \ubcf4\uac15 \ud559\uc2b5 \ud658\uacbd\uc744 \uacb0\ud569\ud558\ub294 \uae30\uc220\ub3c4 \uc788\ub2e4."))),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc758 pre-training task \ub294 text-image retrieval \uc744 \ucd5c\uc801\ud654"),(0,i.kt)("li",{parentName:"ul"},"natural language supervision \uc744 image \uc678\uc758 domain \uc5d0 \ud65c\uc6a9\ud558\ub294 \ub2e4\ub978 \uc5f0\uad6c\ub3c4 \uc874\uc7ac",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Stroud et al (2020)\uc740 image \ub300\uc2e0 video \uc5d0 description text \ub97c \uacb0\ud569\ud558\uc5ec large scale representation learning \ud0d0\uad6c"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7ec\ud55c \uc5f0\uad6c\ub4e4\uc740 large-scale natural language supervision \uc744 \uc5ec\ub7ec domain \uc5d0 \ub300\ud55c high-quality recognition system learning \uc5d0 \ub300\ud55c \uc720\ub9dd\ud55c \ubc29\ubc95\uc784\uc744 \uc2dc\uc0ac"),(0,i.kt)("li",{parentName:"ul"},"Alayrac et al (2020)\uc740 \uc774\ub7ec\ud55c \uc5f0\uad6c\ub97c \uc74c\uc6d0 \uc624\ub514\uc624\ub97c \ucd94\uac00\uc801\uc778 supervision source \ub85c \ucd94\uac00\ud568\uc73c\ub85c\uc368 \uc774 \ub77c\uc778\uc758 \uc5f0\uad6c\uc744 \ud655\uc7a5"))),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc5f0\uad6c\uc758 \uc77c\ud658\uc73c\ub85c \uc6b0\ub9ac\ub294 \uc0c8\ub85c\uc6b4 image-text pair dataset \uad6c\ucd95",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\ud604\ub300\uc758 image-text retrieval task \ub294 Pascal1K, Flickr8K \ubc0f Flickr30K \uac19\uc740 crowd-based sentence-level image caption evaluation dataset \uc5d0 \uc758\uc874"),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 \uc774\ub7ec\ud55c dataset \uc740 \uc5ec\uc804\ud788 \ube44\uad50\uc801 \uc791\uace0 \uc2e4\ud604 \uac00\ub2a5\ud55c \uc131\ub2a5\uc744 \uc81c\ud55c"),(0,i.kt)("li",{parentName:"ul"},"Mithun et al (2018)\uc740 \uc778\ud130\ub137\uc5d0\uc11c \uc218\uc9d1\ud55c (image, text) pair \uc758 \ucd94\uac00 \uc9d1\ud569\uc774 \uac80\uc0c9 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90c"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 dataset \uc740 \uc5ec\uc804\ud788 \ud070 filtering \uc744 \uc0ac\uc6a9\ud558\uac70\ub098 OCR \uac19\uc740 task-specific \uc744 \uc704\ud574 \uc124\uacc4\ub418\uc5b4, WIT \uac19\uc740 very large dataset \ubcf4\ub2e4 \ud6e8\uc52c \uc791\ub2e4"))),(0,i.kt)("li",{parentName:"ul"},"CLIP\uc640 \uad00\ub828\ub41c \uc544\uc774\ub514\uc5b4 \uc911 \ud558\ub098\ub294 Webly supervised learning",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774 \uc5f0\uad6c \ub77c\uc778\uc740 image retrieval \ub97c query \ud558\uc5ec \uc6a9\uc5b4\uc5d0 \ub300\ud55c image dataset \uc744 \uad6c\ucd95\ud558\uace0 query \ub97c \ubc18\ud658\ub41c image label \ub85c \uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7ec\ud55c \ubc29\uc2dd\uc73c\ub85c \ud6c8\ub828\ub41c classifier \ub294 smaller carefully labeled dataset \uc5d0 \ud6c8\ub828\ub41c classifier \uc640 \uacbd\uc7c1"),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7ec\ud55c image-query pair \ub294 \uc885\uc885 additional training data \ub85c \uc0ac\uc6a9\ub418\uc5b4 standard dataset \uc758 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30\ub3c4 \ud568"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc740 dataset \uc0dd\uc131 \uacfc\uc815\uc758 \uc77c\ud658\uc73c\ub85c retrieval query \ub97c \uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"\uadf8\ub7ec\ub098 CLIP \uc740 single word \ub098 short n-gram \uc778 \uacbd\uc6b0\uac00 \ub9ce\uc740 query \uac00 \uc544\ub2cc image \uc640 \ud568\uaed8 \ubc1c\uc0dd\ud558\ub294 \uc804\uccb4 text sequence \ub97c supervision \uc73c\ub85c \uc0ac\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"\ub610\ud55c CLIP \uc5d0\uc120 \uc774 \ub2e8\uacc4\ub97c \ubb38\uc790\uc5f4 \uc77c\uce58\ub97c query \ud558\ub294 text \ub9cc\uc73c\ub85c \uc81c\ud55c"),(0,i.kt)("li",{parentName:"ul"},'\ub300\ubd80\ubd84\uc758 Webly supervised learning \uc5f0\uad6c\ub294 \ubcf5\uc7a1\ud55c \uac80\uc0c9 \ubc0f \ud544\ud130\ub9c1 \ud30c\uc774\ud504\ub77c\uc778\uc744 \uc0ac\uc6a9\ud55c\ub2e4. \uc774\ub7ec\ud55c \ub77c\uc778\uc758 \uc5f0\uad6c \uc911\uc5d0\uc11c\ub3c4 "Learning Everything about Anything: Webly-Supervised Visual Concept Learning" \ub294 CLIP \uacfc \uc720\uc0ac\ud55c \ubaa9\ud45c\uac00 \uc788\uc74c'))),(0,i.kt)("li",{parentName:"ul"},"\ub9c8\uc9c0\ub9c9\uc73c\ub85c, CLIP \uc740 \ucd5c\uadfc\uc5d0 \ud65c\ubc1c\ud55c \ud65c\ub3d9\uacfc \uad00\ub828",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\uc774 \uc5f0\uad6c \ub77c\uc778\uc740 vidual question answering, visual commonsense reasoning \ub610\ub294 multimodal entailment \uac19\uc740 complex downstream task \ud574\uacb0\uc744 \uc704\ud574 vision-language \uc758 jointly model \uc744 \ud559\uc2b5\ud558\ub294 \ub370 \uc911\uc810\uc744 \ub454\ub2e4."),(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7ec\ud55c \uc2dc\uc2a4\ud15c\uc740 image-text pair \uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c training objective \ub97c \ud1b5\ud569\uc801\uc73c\ub85c tuning \ud558\uace0 \uc774\uc804\uc5d0 \uc5b8\uae09\ub41c \uc5f0\uad6c\ub4e4\uc5d0 \uc801\uc6a9\ud558\uc5ec \uc778\uc0c1\uc801\uc778 \uacb0\uacfc\ub97c \ub2ec\uc131"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc740 \ub300\uc2e0, natural language supervision \uc744 \ud1b5\ud574 visual model \uc744 scratch training \ud558\ub294 \ub370 \uc911\uc810\uc744 \ub450\uba70 image \uc640 text domain \uc744 densely connection \ud558\uc9c0 \uc54a\uc74c"),(0,i.kt)("li",{parentName:"ul"},"CLIP \ubaa8\ub378\uc5d0\uc11c image \uc640 text domain \uac04\uc758 \uc720\uc77c\ud55c \uc0c1\ud638 \uc791\uc6a9\uc740 learned joint embedding space \uc5d0\uc11c\uc758 single dot product \uc774\ub2e4")))),(0,i.kt)("h1",{id:"9-conclusion"},"9. Conclusion"),(0,i.kt)("p",null,"\uc800\uc790\ub294 NLP \uc758 task-agnostic web-scale pre-training \uc744 \ub2e4\ub978 domain \uc73c\ub85c transfer \uc774 \uac00\ub2a5\ud55c\uc9c0 \uc870\uc0ac"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\uc774\ub7f0 \uacf5\uc2dd\uc744 \ucc44\ud0dd\ud558\uba74 vision \ubd84\uc57c\uc5d0\uc11c \uc720\uc0ac\ud55c \ud589\ub3d9\uc774 \ub098\ud0c0\ub098\uba70, \uc774 \uc5f0\uad6c \ub77c\uc778\uc758 \uc0ac\ud68c\uc801 \ud568\uc758\uc5d0 \ub300\ud574 \ub17c\uc758"),(0,i.kt)("li",{parentName:"ul"},"CLIP \uc740 pre-training \uacfc\uc815\uc5d0 \ub2e4\uc591\ud55c task \ub97c \uc218\ud589\ud558\ub294 \uac83\uc744 \ubc30\uc6b0\uae30 \ub54c\ubb38\uc5d0 training objective \ub97c optimizing \ud5c8\uae30 \uc704\ud574 natural prompting \uc744 \ud1b5\ud574 \uc774\ub7ec\ud55c task learning \uc744 \ud65c\uc6a9"),(0,i.kt)("li",{parentName:"ul"},"\ucda9\ubd84\ud55c \uaddc\ubaa8\ub85c \uc774\ub7ec\ud55c \uc811\uadfc \ubc29\uc2dd\uc758 \uc131\ub2a5\uc740 task-specific supervised models \uc640 \uacbd\uc7c1\ub825\uc744 \uac16\uc744 \uc218 \uc788\uc73c\ub098, \uc5ec\uc804\ud788 \ub9ce\uc740 \uac1c\uc120 \uc5ec\uc9c0\uac00 \uc788\uc74c")))}k.isMDXComponent=!0},52316:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-1-9aa315ca64ac315d667d1ca9d4235f94.png"},8840:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-10-86bc480e4e24a1fb0ceb861a15e237c3.png"},29421:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-11-8d28fbb60c1575f127ec3b07f99f9a5b.png"},44959:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-12-482cecce99b9f1e82f1f4829919fc1ef.png"},50087:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-13-0adac16a7492aeef41b31a375d819b7c.png"},54440:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-14-2de28ac7ffe3ae4aab52b3222b0ca570.png"},5686:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-15-61451f90a6a8b66efa45719e37a57e34.png"},93470:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-16-b08144cece35076f50475d99ad5cc139.png"},21894:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-17-9e63be3355195fc414ceefff16f4660c.png"},20953:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-18-b4fc5cfd89ff7cf0e82b5ea66d9c83dc.png"},59782:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-19-e79ec4abf991b3e6eaad32870661873a.png"},59346:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-2-0cba2524b21bb91781d4e525b7c0857b.png"},73714:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-20-8d2913b0d32543e1dcf39e5254277080.png"},62058:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-21-9af0671dcc471b3b6c88b4a7425753a1.png"},6328:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-22-cd3e38bc2fc3e217ec7e42d2ac2abfb4.png"},32359:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-23-c52576ccbc7257f1ea5486de622e4e03.png"},47246:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-24-5fa1bafc736c27089669555cbf1b2b39.png"},66666:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-3-8473fb72de6bb23de7f70746ec422475.png"},82646:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-4-3ffd600ad134bd9a4eec40d45b8dbe12.png"},78707:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-5-df879b2b006e48fa9bbb4c87976fbf86.png"},36762:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-6-ec4fda5046c5b294c24f168e3e3889b3.png"},36562:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-7-89c736b73d7ee9043c143cec86c68c6c.png"},27978:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-8-038af04854a718622cc353b9958293dd.png"},51528:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-9-1c44db1086557d2fa26cec83c21ce558.png"},74318:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/image-c5d2bfb5cec159dfdb40fe20931f1a06.png"}}]);