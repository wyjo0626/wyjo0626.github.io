"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[64214],{63361:e=>{e.exports=JSON.parse('{"label":"RL","permalink":"/docs/tags/rl","allTagsPath":"/docs/tags","count":4,"items":[{"id":"Paper/Reinforce Learning/PPO/RLAIF/2023-05-ALMoST","title":"Aligning Large Language Models through Synthetic Feedback","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Reinforce Learning/PPO/RLAIF/ALMoST"},{"id":"Paper/Reinforce Learning/PPO/RLAIF/2022-12-ConstitutionalAI","title":"Constitutional AI: Harmlessness from AI Feedback","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Reinforce Learning/PPO/RLAIF/Constitutional AI"},{"id":"Paper/Reinforce Learning/PPO/RLAIF/2023-09-d-RLAIF","title":"RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Reinforce Learning/PPO/RLAIF/d-RLAIF"},{"id":"Paper/Reinforce Learning/PPO/RLAIF/2023-10-UltraFeedback","title":"UltraFeedback: Boosting Language Models with Scaled AI Feedback","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Reinforce Learning/PPO/RLAIF/UltraFeedback"}]}')}}]);