"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[1407],{2074:o=>{o.exports=JSON.parse('{"label":"Quantized LLMs","permalink":"/docs/tags/quantized-ll-ms","allTagsPath":"/docs/tags","count":3,"items":[{"id":"Paper/NLP/PEFT/Composition/2023-10-LoftQ","title":"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Composition/LoftQ"},{"id":"Paper/NLP/PEFT/Composition/2023-09-QA-LoRA","title":"QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Composition/QA-LoRA"},{"id":"Paper/NLP/PEFT/Composition/2023-05-QLoRA","title":"QLORA: Efficient Finetuning of Quantized LLMs","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Composition/QLoRA"}]}')}}]);