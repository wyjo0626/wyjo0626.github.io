"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[34672],{5132:e=>{e.exports=JSON.parse('{"label":"Zero-shot Learning","permalink":"/docs/tags/zero-shot-learning","allTagsPath":"/docs/tags","count":9,"items":[{"id":"Paper/Vision-Language/VQA-IC/Zero-shot/2023-03-DeCap","title":"DeCap: Decoding CLIP Latents for Zer-Shot Captioning via Text-Only Training","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/VQA-IC/Zero-shot/DeCap"},{"id":"Paper/Vision-Language/VQA-IC/Zero-shot/2024-09-IFCap","title":"IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/VQA-IC/Zero-shot/IFCap"},{"id":"Paper/Vision-Language/VQA-IC/Zero-shot/2022-05-MAGIC","title":"Language Models Can See: Plugging Visual Controls in Text Generation","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/VQA-IC/Zero-shot/MAGIC"},{"id":"Paper/Vision-Language/VQA-IC/Zero-shot/2024-03-MeaCap","title":"MeaCap: Memory-Augmented Zero-shot Image Captioning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/VQA-IC/Zero-shot/MeaCap"},{"id":"Paper/Vision-Language/VQA-IC/Zero-shot/2022-11-CapDec","title":"Text-Only Training for Image Captioning using Noise-Injected CLIP","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/VQA-IC/Zero-shot/CapDec"},{"id":"Paper/Vision-Language/VQA-IC/Zero-shot/2023-07-ViECap","title":"Transferable Decoding with Visual Entities for Zero-Shot Image Captioning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/VQA-IC/Zero-shot/ViECap"},{"id":"Paper/Vision-Language/VQA-IC/Zero-shot/2025-04-11-MERCap","title":"Zero-Shot Image Captioning with Multi-type Entity Representations","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/VQA-IC/Zero-shot/MERCap"},{"id":"Paper/Vision-Language/VQA-IC/Zero-shot/2021-11-ZeroCap","title":"ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/VQA-IC/Zero-shot/ZeroCap"},{"id":"Paper/Vision-Language/VQA-IC/Zero-shot/2023-06-ZeroGen","title":"ZeroGen: Zero-shot Multimodal Controllable Text Generation with Multiple Oracles","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/VQA-IC/Zero-shot/ZeroGen"}]}')}}]);