"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[96303],{43845:a=>{a.exports=JSON.parse('{"label":"4-bit quantization","permalink":"/docs/tags/4-bit-quantization","allTagsPath":"/docs/tags","count":1,"items":[{"id":"Paper/NLP/PEFT/Quantization/Fine-Tuning/2022-10-AlphaTuning","title":"AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of Large-Scale Pre-Trained Language Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Quantization/Fine-Tuning/AlphaTuning"}]}')}}]);