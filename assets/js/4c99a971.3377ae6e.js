"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[81580],{79623:e=>{e.exports=JSON.parse('{"label":"Pixel-Level","permalink":"/docs/tags/pixel-level","allTagsPath":"/docs/tags","count":15,"items":[{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2023-11-A2XP","title":"A2XP: Towards Private Domain Generalization","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/A2XP"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2024-03-ADAVIPRO","title":"AdaViPro: Region-Based Adaptive Visual Prompt For Large-Scale Models Adapting","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/AdaViPro"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2023-10-AutoVP","title":"AutoVP: An Automated Visual Prompting Framework and Benchmark","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/AutoVP"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2021-02-CMAR","title":"Cross-modal Adversarial Reprogramming","description":"\uc774\ubbf8\uc9c0 \ubc0f \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/CMAR"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2023-03-DAM-VP","title":"Diversity-Aware Meta Visual Prompting","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/DAM-VP"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2023-03-EVP-L","title":"Explicit Visual Prompting for Low-Level Structure Segmentations","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/EVP-L"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2024-04-TVP","title":"Exploring the Transferability of Visual Prompting for Multimodal Large Language Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/TVP"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2022-03-VP","title":"Exploring Visual Prompts for Adapting Large-Scale Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/VP"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2023-04-HintAug","title":"Hint-Aug: Drawing Hints from Foundation Vision Transformers towards Boosted Few-shot Parameter-Efficient Tuning","description":"\ub17c\ubb38 \ubc0f image \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/HinTAug"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2023-11-InMeMo","title":"Instruct Me More! Random Prompting for Visual In-Context Learning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/InMeMo"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2023-12-LaViP","title":"LaViP: Language-Grounded Visual Prompts","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/LaViP"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2024-06-SMM","title":"Sample-specific Masks for Visual Reprogramming-based Prompting","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/SMM"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2022-11-ILM-VP","title":"Understanding and Improving Visual Prompting: A Label-Mapping Perspective","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/ILM-VP"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2022-12-EVP","title":"Unleashing the Power of Visual Prompting At the Pixel Level","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/EVP"},{"id":"Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/2022-10-Watermarking","title":"Watermarking for Out-of-distribution Detection","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/CLIP/Few-shot/Prompting/Pixel-Level/Watermarking"}]}')}}]);