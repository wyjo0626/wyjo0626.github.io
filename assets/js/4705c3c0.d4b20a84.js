"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[19432],{73461:e=>{e.exports=JSON.parse('{"label":"APLe","permalink":"/docs/tags/ap-le","allTagsPath":"/docs/tags","count":1,"items":[{"id":"Paper/Vision-Language/PEFT/Multi-Modality/2024-01-APLe","title":"APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning","description":"Pre-trained vision-language (V-L) model \uc740 downstream task \ub85c\uc758 generalization \uae30\uc900\uc744 \uc124\uc815\ud558\ub294 \uc8fc\ubaa9\ud560 \ub9cc\ud55c \ud6c4\ubcf4 \uc911 \ud558\ub098\uc774\ub2e4. \uae30\uc874 \uc5f0\uad6c\uc5d0\uc11c\ub294 V-L model \uc758 \ub2e4\uc591\ud55c \ud2b9\uc131, \uc608\ub97c \ub4e4\uc5b4 text input \uc5d0 \ub300\ud55c \ubbfc\uac10\uc131\uacfc multimodal prompt \uc804\ubc18\uc5d0 \uac78\uce5c tuning \uacfc\uc815\uc758 \uc5b4\ub824\uc6c0 \ub4f1\uc774 \ud0d0\uad6c\ub418\uc5c8\ub2e4. CLIP \uacfc \uac19\uc740 V-L model \uc758 \uace0\uae09 \ud65c\uc6a9\uc5d0\uc11c, \ucd5c\uadfc \uc811\uadfc \ubc29\uc2dd\ub4e4\uc740 hand-craft prompt \ub300\uc2e0 \ud559\uc2b5 \uac00\ub2a5\ud55c prompt \ub97c \ubc30\uce58\ud558\uc5ec generalization \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uace0 \uc55e\uc11c \uc5b8\uae09\ud55c \ubb38\uc81c\ub97c \ud574\uacb0\ud55c\ub2e4. Image fusion \uc5d0\uc11c \ub110\ub9ac \uc0ac\uc6a9\ub418\ub294 layer-wise training \uc5d0\uc11c \uc601\uac10\uc744 \ubc1b\uc544, CLIP \uc758 \uc11c\ub85c \ub2e4\ub978 modality branch \ub97c sequential training \uacfc\uc815\uc73c\ub85c \uc801\uc751\uc2dc\ud0a4\ub294 \uac83\uc774 generalization \ud5a5\uc0c1\uc5d0 \ud6a8\uacfc\uc801\uc784\uc744 \ud655\uc778\ud558\uc600\ub2e4.","permalink":"/docs/Paper/Vision-Language/PEFT/Multi-Modality/APLe"}]}')}}]);