"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[36837],{15120:i=>{i.exports=JSON.parse('{"label":"Computer Vision","permalink":"/docs/tags/computer-vision","allTagsPath":"/docs/tags","count":4,"items":[{"id":"Paper/Computer Vision/Image Classification/2020-10-ViT","title":"An Image Is Worth 16X16 Words: Transformers for image recognition at sacle","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Computer Vision/Image Classification/ViT"},{"id":"Paper/Computer Vision/Image Classification/2021-04-EfficientNetV2","title":"EfficientNetV2: Smaller Models and Faster Training","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2"},{"id":"Paper/Computer Vision/Few-shot/2024-01-AMT","title":"Mixture of Adversarial LoRAs: Boosting Robust Generalization in Meta-Tuning","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Computer Vision/Few-shot/AMT"},{"id":"Paper/NLP/Text Generation/2022-03-InstructGPT","title":"Training language models to follow instructions with human feedback (+ ChatGPT)","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/Text Generation/InstructGPT"}]}')}}]);