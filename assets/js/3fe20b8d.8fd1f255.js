"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[46897],{62599:e=>{e.exports=JSON.parse('{"label":"multi-task","permalink":"/docs/tags/multi-task","allTagsPath":"/docs/tags","count":6,"items":[{"id":"Paper/Computer Vision/Multi-task/2022-06-Unified Interface","title":"A Unified Sequence Interface for Vision Tasks","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Computer Vision/Multi-task/Unified Interface"},{"id":"Paper/NLP/PEFT/Soft Prompt/2022-05-ATTEMPT","title":"ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT"},{"id":"Paper/NLP/Multi-Task/2023-05-CodeT5p","title":"CodeT5+: Open Code Large Language Models for Code Understanding and Generation","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/Multi-Task/CodeT5+"},{"id":"Paper/NLP/Multi-Task/2022-10-Flan-T5","title":"Scaling Instruction-Finetuned Language Models","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/Multi-Task/Flan-T5"},{"id":"Paper/NLP/PEFT/Soft Prompt/2022-05-SPoT","title":"SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT"},{"id":"Paper/Computer Vision/Multi-task/2023-03-UNINEXT","title":"UNINEXT: Universal Instance Perception as Object Discovery and Retrieval","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Computer Vision/Multi-task/UNINEXT"}]}')}}]);