"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[91836],{74907:e=>{e.exports=JSON.parse('{"label":"RLAIF","permalink":"/docs/tags/rlaif","allTagsPath":"/docs/tags","count":3,"items":[{"id":"Paper/Reinforce Learning/PPO/RLAIF/2023-05-ALMoST","title":"Aligning Large Language Models through Synthetic Feedback","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Reinforce Learning/PPO/RLAIF/ALMoST"},{"id":"Paper/Reinforce Learning/PPO/RLAIF/2022-12-ConstitutionalAI","title":"Constitutional AI: Harmlessness from AI Feedback","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Reinforce Learning/PPO/RLAIF/Constitutional AI"},{"id":"Paper/Reinforce Learning/PPO/RLAIF/2023-09d-RLAIF","title":"RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Reinforce Learning/PPO/RLAIF/d-RLAIF"}]}')}}]);