"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[45369],{62761:n=>{n.exports=JSON.parse('{"label":"FP4","permalink":"/docs/tags/fp-4","allTagsPath":"/docs/tags","count":2,"items":[{"id":"Paper/NLP/PEFT/Quantization/Fine-Tuning/2024-10-LLM-FP4","title":"LLM-FP4: 4-Bit Floating-Point Quantized Transformers","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Quantization/Fine-Tuning/LLM-FP4"},{"id":"Paper/NLP/PEFT/Quantization/Fine-Tuning/2025-01-fp4","title":"Optimizing Large Language Model Training Using FP4 Quantization","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/NLP/PEFT/Quantization/Fine-Tuning/fp4"}]}')}}]);