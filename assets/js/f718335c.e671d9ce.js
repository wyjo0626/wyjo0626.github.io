"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[58935],{77042:e=>{e.exports=JSON.parse('{"label":"CLIP-Adapter","permalink":"/docs/tags/clip-adapter","allTagsPath":"/docs/tags","count":2,"items":[{"id":"Paper/Vision-Language/PEFT/Module/2021-10-CLIP-Adapter","title":"CLIP-Adapter: Better Vision-Language Models with Feature Adapters","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Module/CLIP-Adapter"},{"id":"Paper/Vision-Language/PEFT/Module/2021-11-Tip-Adapter","title":"Tip-Adapter: Training-Free Adaption of CLIP for Few-Shot Classification","description":"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :","permalink":"/docs/Paper/Vision-Language/PEFT/Module/Tip-Adapter"}]}')}}]);