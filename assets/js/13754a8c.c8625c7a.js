"use strict";(self.webpackChunkWon_Yong_Jo=self.webpackChunkWon_Yong_Jo||[]).push([[77731],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>k});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var d=a.createContext({}),s=function(e){var t=a.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=s(e.components);return a.createElement(d.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,d=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),c=s(n),m=o,k=c["".concat(d,".").concat(m)]||c[m]||u[m]||r;return n?a.createElement(k,i(i({ref:t},p),{},{components:n})):a.createElement(k,i({ref:t},p))}));function k(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=m;var l={};for(var d in t)hasOwnProperty.call(t,d)&&(l[d]=t[d]);l.originalType=e,l[c]="string"==typeof e?e:o,i[1]=l;for(var s=2;s<r;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},37679:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>l,toc:()=>s});var a=n(87462),o=(n(67294),n(3905));const r={slug:"CodeT5+",title:"CodeT5+: Open Code Large Language Models for Code Understanding and Generation",tags:["CodeT5p","CodeT5+","CodeT5","NLP","Code Understanding","Code Generation","Multi-Task","Paper"]},i=void 0,l={unversionedId:"Paper/NLP/Multi-Task/2023-05-CodeT5p",id:"Paper/NLP/Multi-Task/2023-05-CodeT5p",title:"CodeT5+: Open Code Large Language Models for Code Understanding and Generation",description:"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 :",source:"@site/docs/Paper/NLP/Multi-Task/2023-05-CodeT5p.md",sourceDirName:"Paper/NLP/Multi-Task",slug:"/Paper/NLP/Multi-Task/CodeT5+",permalink:"/docs/Paper/NLP/Multi-Task/CodeT5+",draft:!1,editUrl:"https://github.com/wyjo0626/wyjo0626.github.io/tree/master/docs/docs/Paper/NLP/Multi-Task/2023-05-CodeT5p.md",tags:[{label:"CodeT5p",permalink:"/docs/tags/code-t-5-p"},{label:"CodeT5+",permalink:"/docs/tags/code-t-5"},{label:"NLP",permalink:"/docs/tags/nlp"},{label:"Code Understanding",permalink:"/docs/tags/code-understanding"},{label:"Code Generation",permalink:"/docs/tags/code-generation"},{label:"Multi-Task",permalink:"/docs/tags/multi-task"},{label:"Paper",permalink:"/docs/tags/paper"}],version:"current",frontMatter:{slug:"CodeT5+",title:"CodeT5+: Open Code Large Language Models for Code Understanding and Generation",tags:["CodeT5p","CodeT5+","CodeT5","NLP","Code Understanding","Code Generation","Multi-Task","Paper"]},sidebar:"tutorialSidebar",previous:{title:"Scaling Instruction-Finetuned Language Models",permalink:"/docs/Paper/NLP/Multi-Task/Flan-T5"},next:{title:"LoRA: Low-Rank Adaptation of Large Language Models",permalink:"/docs/Paper/NLP/PEFT/Composition/LoRA"}},d={},s=[{value:"3.1. Unimodal Pretraining on Code Data",id:"31-unimodal-pretraining-on-code-data",level:2},{value:"Span Denoising",id:"span-denoising",level:3},{value:"Causal Language Modeling (CLM)",id:"causal-language-modeling-clm",level:3},{value:"3.2. Bimodal Pretraining on Text-code Data",id:"32-bimodal-pretraining-on-text-code-data",level:2},{value:"Text-Code Contrastive Learning",id:"text-code-contrastive-learning",level:3},{value:"Text-Code Matching",id:"text-code-matching",level:3},{value:"Text-Code Causal LM",id:"text-code-causal-lm",level:3},{value:"3.3. Compute-efficient Pretraining with Frozen Off-the-shelf LLMs",id:"33-compute-efficient-pretraining-with-frozen-off-the-shelf-llms",level:2},{value:"3.4. Adaptation to Downstream Understanding and Generation Tasks",id:"34-adaptation-to-downstream-understanding-and-generation-tasks",level:2},{value:"Seq2Seq Generation Tasks",id:"seq2seq-generation-tasks",level:3},{value:"Decoder-only Tasks",id:"decoder-only-tasks",level:3},{value:"Understanding Tasks",id:"understanding-tasks",level:3},{value:"4.1. Pretraining Dataset",id:"41-pretraining-dataset",level:2},{value:"4.2. Pretraining Setup",id:"42-pretraining-setup",level:2}],p={toc:s},c="wrapper";function u(e){let{components:t,...r}=e;return(0,o.kt)(c,(0,a.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"\ub17c\ubb38 \ubc0f \uc774\ubbf8\uc9c0 \ucd9c\ucc98 : ",(0,o.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/2305.07922v2.pdf"},"https://arxiv.org/pdf/2305.07922v2.pdf")),(0,o.kt)("h1",{id:"abstract"},"Abstract"),(0,o.kt)("p",null,"\ud604\uc7ac code LLMs \ub294 \ub450 \uac00\uc9c0 \uc8fc\uc694 \ud55c\uacc4\uc810 \uc874\uc7ac"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"specific architecture (encoder-only, decoder-only) \ub610\ub294 encoder-decoder network \uc5d0 \uc758\uc874",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"\uc804\uc790\ub294 \uc751\uc6a9\ud558\ub294\ub370 \uc788\uc5b4 inflexibility"),(0,o.kt)("li",{parentName:"ul"},"\ud6c4\uc790\ub294 \ubaa8\ub4e0 task \uc5d0 \ub300\ud55c single system \uc744 \ub2e4\ub8e8\uc5b4 subset \uc5d0 \ub300\ud574 suboptimal \uc131\ub2a5\uc744 \ubcf4\uc784"))),(0,o.kt)("li",{parentName:"ol"},"\uad00\ub828\uc5c6\ub294 downstream task \ub85c pretraining limited set \uc744 \uc0ac\uc6a9")),(0,o.kt)("p",null,"\uc774\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574, component modules \ub97c \uc720\uc5f0\ud558\uac8c \uacb0\ud569\ud558\uc5ec \ub113\uc740 \ubc94\uc704\uc758 downstream code task \uc5d0 \uc801\ud569\ud55c encoder-decoder LLMs \uc758 ",(0,o.kt)("strong",{parentName:"p"},"CodeT5+")," \ub97c \uc81c\uc548"),(0,o.kt)("p",null,"\uc774\ub7ec\ud55c \uc720\uc5f0\uc131\uc740 pretrain-finetune \ubd88\uc77c\uce58\uc131\uc744 \uc644\ud654\ud558\uae30 \uc704\ud574 ",(0,o.kt)("strong",{parentName:"p"},"pretraining objectives \uc758 mixture"),"\uc744 \uc81c\uc548"),(0,o.kt)("p",null,"\uc774 objectives \ub294 \ub2e8\uc77c \ub610\ub294 \uc774\uc911\uc758 code \ub9d0\ubb49\uce58\uc5d0\uc11c span denoising, contrasive learning, text-code matching \ubc0f causal LM pretraining tasks \uc218\ud589 \uac00\ub2a5"),(0,o.kt)("p",null,"\ub610\ud55c \ubaa8\ub378\uc744 \ud6a8\uc728\uc801\uc73c\ub85c scale up \ud558\uae30 \uc704\ud574 CodeT5+ \ub97c \ucc98\uc74c\ubd80\ud130 \ud6c8\ub828\ud558\uc9c0 \uc54a\uace0 frozen off-the-shelf LLMs \uc73c\ub85c \ucd08\uae30\ud654\ud558\ub294 \ubc29\ubc95"),(0,o.kt)("p",null,"\uadf8\ub9ac\uace0 instruction-tuning \uc744 \ud0d0\uad6c"),(0,o.kt)("p",null,"\uc800\uc790\ub294 CodeT5+ \ub97c 20\uac1c\uc758 code-related benchmarks \uc5d0 \uad11\ubc94\uc704\ud558\uac8c \ud3c9\uac00\ub97c \ud588\uc73c\uba70, zero-shot, finetuning, instruction-tuning \uc744 \ud3ec\ud568\ud55c\ub2e4."),(0,o.kt)("p",null,"code generation/completion, math programming \ubc0f text-to-code retrieval task \uac19\uc740 \ub2e4\uc591\ud55c code-related task \uc5d0\uc11c SOTA \ub97c \ub2ec\uc131"),(0,o.kt)("h1",{id:"1-introduction"},"1. Introduction"),(0,o.kt)("p",null,"LLMs \ub294 \ub300\uaddc\ubaa8 \ucf54\ub4dc \uae30\ubc18 \ub370\uc774\ud130 (\uc608; GitHub \uacf5\uac1c \ub370\uc774\ud130)\ub85c pretrain \ud558\uc5ec \ub2e4\uc591\ud55c \ucf54\ub4dc \uad00\ub828 downstream task \ub85c transfer \ud560 \uc218 \uc788\ub2e4."),(0,o.kt)("p",null,"\ud558\uc9c0\ub9cc \uae30\uc874\uc758 \ub9ce\uc740 \ubaa8\ub378\uc774 \ud2b9\uc815 downstream task \ub9cc \uc798 \uc218\ud589\ub418\ub3c4\ub85d \uc124\uacc4\uac00 \ub418\uc5b4 \uc788\ub2e4. \uc774\ub294 \uc8fc\ub85c \uc544\ud0a4\ud14d\ucc98\uc640 pretraining task \uc218\ud589 \uacfc\uc81c\uc5d0 \ub300\ud55c \ub450 \uc81c\ud55c\uc73c\ub85c \uc778\ud55c \uac83\uc73c\ub85c \uc8fc\uc7a5\ud55c\ub2e4."),(0,o.kt)("hr",null),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Architecture")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Figure 1",src:n(10954).Z,width:"690",height:"381"})),(0,o.kt)("p",null,"\uae30\uc874\uc758 code LLM \uc740 understanding / generation task \uc5d0\ub9cc \uc798 \uc218\ud589\ub418\ub294 encoder-only / decoder-only \ubaa8\ub378\uc744 \ucc44\ud0dd\ud55c\ub2e4."),(0,o.kt)("p",null,"\ud2b9\ud788, text-to-code retrieval \uac19\uc740 understading task \uc6a9\uc774\ud55c encoder model,\ncode generation \uac19\uc740 generation task \uc5d0 \ub300\ud55c decoder model \uc774 \uac15\ub825\ud55c \uc131\ub2a5\uc744 \ubcf4\uc778\ub2e4."),(0,o.kt)("p",null,"\uadf8\ub7ec\ub098 \ub514\ucf54\ub354 \ubaa8\ub378\uc740 \uc778\ucf54\ub354 \ubaa8\ub378\uc5d0 \ube44\ud574 \uac80\uc0c9 \ubc0f \uac10\uc9c0 \uc791\uc5c5\uac19\uc740 understading task \uc5d0 \uc774\uc0c1\uc801\uc774\uc9c0 \uc54a\uc73c\uba70, \ucd5c\uadfc encoder-decoder architecture \ub97c \ub9ce\uc774 \ucc44\ud0dd\ud55c\ub2e4."),(0,o.kt)("p",null,"understanding \uacfc generation \ubaa8\ub450\ub97c \uc9c0\uc6d0\ud558\uc9c0\ub9cc, \uc5ec\uc804\ud788 \ucd5c\uc801\uc758 \uc131\ub2a5\uc744 \ub0b4\uc9c0 \ubabb\ud55c\ub2e4."),(0,o.kt)("p",null,"Unixcoder \ub294 encoder-decoder \ubaa8\ub378\uc774 \uac80\uc0c9 \ubc0f \ucf54\ub4dc \uc644\uc131 \uc791\uc5c5\uc5d0\uc11c SOTA \uc778 encoder \ubc0f decoder-only \ubaa8\ub378\uc744 \ub2a5\uac00\ud558\uc9c0 \ubabb\ud558\ub294 \uac83\uc744 \ubc1c\uacac\ud588\ub2e4."),(0,o.kt)("p",null,"\uc774 \uacb0\ud568\uc740 \uc8fc\ub85c \ubaa8\ub4e0 \uc791\uc5c5\uc5d0 \uc801\uc751\ub418\ub294 \ub2e8\uc77c \ubaa8\ub4c8 \uc544\ud0a4\ud14d\ucc98\uc758 \ud55c\uacc4\ub2e4. \uc694\uc57d\ud558\uc790\uba74, \uae30\uc874 \uc811\uadfc\ubc29\uc2dd\uc740 \uac1c\ubcc4 \uad6c\uc131 \uc694\uc18c\uac00 \ub2e4\ub978 downstream task \uc5d0 \ub354 \ud65c\uc131\ud654\ub420 \uc218 \uc788\ub3c4\ub85d \uc124\uacc4\ub418\uc9c0 \uc54a\uc558\ub2e4."),(0,o.kt)("hr",null),(0,o.kt)("p",null,"\ud604\uc7ac \uc81c\ud55c\ub41c \ud6c8\ub828\uc14b\uc73c\ub85c \uc0ac\uc6a9\ud558\uc5ec, pretrain, transfer \uc0ac\uc774\uc758 \ubd88\uc77c\uce58\ub85c \uc778\ud55c downstream task \uc758 \uc131\ub2a5 \ud558\ub77d\uc744 \uc57c\uae30\ud568."),(0,o.kt)("p",null,"\uc608\ub85c T5 \uae30\ubc18 \ubaa8\ub378\uc740 \uc885\uc885 span denoising \ubaa9\uc801\uc73c\ub85c \ud6c8\ub828\ub41c\ub2e4. \uadf8\ub7ec\ub098 \ucf54\ub4dc \uc0dd\uc131 \uac19\uc740 downstream task \uc758 \ub300\ubd80\ubd84 SOTA \ubaa8\ub378\uc740 \ud504\ub85c\uadf8\ub7a8 \ud1a0\ud070\uc744 \ud558\ub098\uc529 auto-regressively predict \ud558\uc5ec \ub2e4\uc74c \ud1a0\ud070\uc744 \uc608\uce21\ud558\ub294 \ubaa9\uc801\uc73c\ub85c pretrain \ud55c\ub2e4."),(0,o.kt)("p",null,"\ucd5c\uadfc \uc2dc\ub3c4\ub294 \uc704 \ubb38\uc81c \uc644\ud654\ub97c \uc704\ud574 contrastive learning \uc744 \ub3c4\uc785\ud558\uc9c0\ub9cc, text \uc640 code representation \uc0ac\uc774\uc758 alignment \ub97c \ubb34\uc2dc\ud55c\ub2e4."),(0,o.kt)("hr",null),(0,o.kt)("p",null,"\uc800\uc790\ub294 CodeT5+ \uc758 \ubaa8\ub378 \ud06c\uae30\ub97c \ud655\uc7a5\ud558\uae30 \uc704\ud574 \uacc4\uc0b0 \ud6a8\uc728\uc801\uc778 pretrain \uc804\ub7b5\uc744 \uc0ac\uc6a9\ud558\uc5ec CodeT5+ \uc758 \uad6c\uc131 \uc694\uc18c\ub97c \ucd08\uae30\ud654\ud558\ub294\ub370 \uc874\uc7ac\ud558\ub294 code LLMs \ub97c \ud65c\uc6a9\ud55c\ub2e4."),(0,o.kt)("p",null,'pretrained checkpoint \ub85c encoder, decoder \ub97c \ucd08\uae30\ud654\ud558\uace0 cross attention layer \ub85c \uc5f0\uacb0\ud558\ub294 "shallow encoder, deep decoder" architecture \ub97c \ucc44\ud0dd\ud55c\ub2e4.'),(0,o.kt)("p",null,"deep decoder LLM \uc740 \uace0\uc815\ud558\uba70, shallow encoder \uc640 cross attention layer \ub9cc \ud6c8\ub828\ud558\uc5ec \ud6a8\uc728\uc801\uc778 \uc870\uc815\uc744 \uc704\ud574 \ud6c8\ub828 \uac00\ub2a5\ud55c \ub9e4\uac1c \ubcc0\uc218\uc758 \uc218\ub97c \ud06c\uac8c \uc904\uc778\ub2e4."),(0,o.kt)("p",null,"\ub9c8\uc9c0\ub9c9\uc73c\ub85c, NLP \ubd84\uc57c\uc758 \ucd5c\uadfc \uc5f0\uad6c\uc778\ub85c Instruction tuning \uc73c\ub85c \ud0d0\uad6c\ud55c\ub2e4."),(0,o.kt)("hr",null),(0,o.kt)("p",null,"20\uac1c \uc774\uc0c1\uc758 code \uad00\ub828 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c CodeT5+ \ub97c \uad11\ubc94\uc704\ud558\uac8c \ud3c9\uac00\ud588\ub2e4."),(0,o.kt)("p",null,"zero-shot, finetuning \ubc0f instruction tuning \uc744 \ud3ec\ud568\ud55c\ub2e4."),(0,o.kt)("p",null,"\uacb0\uacfc\ub294 CodeT+ \uac00 \ub9ce\uc740 downstream \uc791\uc5c5\uc5d0\uc11c SOTA baseline \uc5d0 \ube44\ud574 \uc0c1\ub2f9\ud55c \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc900\ub2e4."),(0,o.kt)("h1",{id:"2-related-work"},"2. Related Work"),(0,o.kt)("h1",{id:"3-codet5-open-code-large-language-models"},"3. CodeT5+: Open Code Large Language Models"),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://velog.velcdn.com/images/whdnjsdyd111/post/05132274-f16b-4877-8d32-6083f1b509ea/image.png",alt:null})),(0,o.kt)("p",null,"code understanding \ubc0f generation task \ub97c \uc704\ud55c \uc0c8\ub85c\uc6b4 open code LLMs \uc778 CodeT5+ \ub97c \uac1c\ubc1c."),(0,o.kt)("p",null,"encoder-decoder \ub97c \uae30\ubc18\uc73c\ub85c\ud55c CodeT5+ \ub294 unimodal \ubc0f bimodal \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c pretrain objectives \ub97c \ud1b5\ud574 \ub2e4\uc591\ud55c \ubaa8\ub4dc\uc5d0\uc11c \uc791\ub3d9 \uac00\ub2a5\ud55c \uc720\uc5f0\uc131\uc744 \uac16\ucd94\uace0 \uc788\ub2e4."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"unimodal pretraining \uccab \ub2e8\uacc4\ub85c, \uacc4\uc0b0 \ud6a8\uc728\uc801\uc778 \ubaa9\uc801\uc73c\ub85c \ub300\uaddc\ubaa8 \ucf54\ub4dc \ub370\uc774\ud130\ub85c pretrain"),(0,o.kt)("li",{parentName:"ol"},"bimodal pretraining \ub450 \ubc88\uc9f8 \ub2e8\uacc4\ub85c, cross-modal \ud559\uc2b5 \ubaa9\uc801\uc73c\ub85c code-text data \uc758 smaller set\uc73c\ub85c \ubaa8\ub378\uc744 \uacc4\uc18d pretrain"),(0,o.kt)("li",{parentName:"ol"},"\uac01 \ub2e8\uacc4\uc5d0\uc11c \uc5ec\ub7ec pretrain objective \ub97c \ub3d9\uc77c\ud55c \uac00\uc911\uce58\ub85c \uacf5\ud1b5 \ucd5c\uc801\ud654")),(0,o.kt)("p",null,"\uc704 \uc811\uadfc \ubc29\uc2dd\uc774 \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc5d0 \ub178\ucd9c\ub418\uc5b4 \ud48d\ubd80\ud55c context representation \uc744 \ud559\uc2b5\ud558\ub294 \ub370 \ud6a8\uc728\uc801\uc774\ub780 \uac83\uc744 \ubc1c\uacac"),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://velog.velcdn.com/images/whdnjsdyd111/post/0855f084-7dc0-4ab4-8ec3-8069254a01fc/image.png",alt:null})),(0,o.kt)("h2",{id:"31-unimodal-pretraining-on-code-data"},"3.1. Unimodal Pretraining on Code Data"),(0,o.kt)("p",null,"\uba3c\uc800, CodeT+ \ub97c \ub300\uaddc\ubaa8 \ucf54\ub4dc unimodal data \ub85c \uc0ac\uc804\ud559\uc2b5. GitHub \uc758 \uc624\ud508 \uc18c\uc2a4\ub85c, \ucf54\ub4dc \ubc0f \uc8fc\uc11d\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc74c."),(0,o.kt)("p",null,"\ub450 \ubc88\uc9f8\ub85c, code-text \uc30d\uc758 \ub370\uc774\ud130\ub85c, Span Denoising \ubc0f CLM task \ub97c \uc0ac\uc804\ud559\uc2b5\ud55c\ub2e4. \uc774 \uc791\uc5c5\uc740 \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ubc94\uc704\uc758 code context \ub97c \ubcf5\uad6c\ud558\ub294 \ubc29\ubc95\uc744 \ud559\uc2b5\ud560 \uc218 \uc788\ub3c4\ub85d \ud55c\ub2e4."),(0,o.kt)("h3",{id:"span-denoising"},"Span Denoising"),(0,o.kt)("p",null,"encoder input \uc5d0 15% \ud1a0\ud070\uc744 \ubb34\uc791\uc704 mask \ub85c \ub300\uccb4\ud558\uace0, decoder \uac00 \ubcf5\uad6c\ud558\ub3c4\ub85d \ud55c\ub2e4."),(0,o.kt)("h3",{id:"causal-language-modeling-clm"},"Causal Language Modeling (CLM)"),(0,o.kt)("p",null,"\ub450 \uac00\uc9c0 \ubcc0\ud615\uc73c\ub85c auto-regressive generation \uc744 \uc704\ud574 \ucd5c\uc801\ud654."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"\uc784\uc758\ub85c \ud53c\ubc97 \uc704\uce58\ub97c \uc120\ud0dd\ud558\uc5ec, \uadf8 \uc774\uc804\uc758 context \ub97c source sequence \ub85c, \uc774 \ud6c4\uc758 \uc2dc\ud000\uc2a4\ub97c target output \uc73c\ub85c \uac04\uc8fc.\n\uc774\ub97c seq2seq \uc640 \uc5b8\uc5b4 \ubaa8\ub378\ub9c1 \ubaa9\uc801\uc73c\ub85c \ud45c\uae30\n\ud53c\ubc97 \uc704\uce58\ub294 \uc804\uccb4 sequence \uc758 10% - 90% \uc0ac\uc774\uc5d0\uc11c \uade0\ub4f1\ud558\uac8c \uc0d8\ud50c\ub9c1\ub418\ub3c4\ub85d \uc81c\ud55c\ud558\uace0 source sequence \uc5d0 \ud2b9\uc218 \ud1a0\ud070 ","[CLM]"," \uc744 \ucd94\uac00"),(0,o.kt)("li",{parentName:"ol"},"decoder \uc804\uc6a9 generation task \ub85c, \uccab \ubc88\uc9f8 \ubcc0\ud615\uc758 \uadf9\ub2e8\uc801\uc778 \uacbd\uc6b0.\n","[CLM]"," \ud1a0\ud070\uc744 encoder \uc5d0 \uc785\ub825\uc73c\ub85c \uc804\ub2ec\ud558\uace0, decoder \uc5d0\uac8c \uc804\uccb4 \ucf54\ub4dc \uc2dc\ud000\uc2a4\ub97c \uc0dd\uc131\ud558\ub3c4\ub85d \uc694\uad6c.")),(0,o.kt)("h2",{id:"32-bimodal-pretraining-on-text-code-data"},"3.2. Bimodal Pretraining on Text-code Data"),(0,o.kt)("p",null,"\ub450 \ubc88\uc9f8 \ub2e8\uacc4\ub85c, \uc800\uc790\ub294 text-code bimodal data \ub85c pretrain \ud558\uc600\ub2e4."),(0,o.kt)("p",null,"\uc5ec\uae30\uc11c \uac01 text-code \uc30d\uc740 code function \uacfc \ub300\uc751\ud558\ub294 docstring describing \uc744 \ud3ec\ud568\ud55c\ub2e4."),(0,o.kt)("p",null,"\uc774\ub7f0 bimodal data \ub294 \ubaa8\ub378 \ud6c8\ub828\uc774 cross-modal understanding \uacfc generation \uc5d0 \uc6a9\uc774\ud558\ub3c4\ub85d \ud55c\ub2e4."),(0,o.kt)("p",null,"bimodal tasks \ub294 cross-modal contrastive learning, matching \ubc0f causal LM task \ub97c \ud3ec\ud568\ud55c\ub2e4."),(0,o.kt)("h3",{id:"text-code-contrastive-learning"},"Text-Code Contrastive Learning"),(0,o.kt)("p",null,"\uc774 tasks \ub294 text \ubc0f code representations \uc758 feature space \ub97c \uc815\ub82c\ud558\uae30 \uc704\ud574 positive text-code paris \ub294 \ubaa8\uc73c\uace0 negative text-code pairs \ub97c \ubd84\ub9ac\ud558\ub294 \uac83\uc744 \ubaa9\ud45c\ub85c \ud55c\ub2e4."),(0,o.kt)("p",null,"Guo et al. ","[2022]"," \ub294 code understanding task \uc5d0\uc11c \uc774\uc810\uc744 \uc785\uc99d\ud588\ub2e4. \uc774 task \ub294 encoder \uc5d0\uc11c\ub9cc \ud65c\uc131\ud654\ud558\uba70, text \ub098 code snippet \uc744 bidirectional self-attention \uc744 \ud1b5\ud574 continuous representation \uc73c\ub85c \uc778\ucf54\ub529\ud55c\ub2e4."),(0,o.kt)("p",null,"BERT \uc640 \uc720\uc0ac\ud558\uac8c, \uc800\uc790\ub294 input \uc55e\uc5d0 special token ","[CLS]"," \uc744 \ubd99\uc774\uace0, \ucd5c\uc885 Transformer layer \uc758 output embeddings \ub97c \ud574\ub2f9 input text \ub098 input code \uc758 representations \uc73c\ub85c \uac04\uc8fc\ud55c\ub2e4."),(0,o.kt)("p",null,"\ub610\ud55c, linear layer \ub97c \ucd94\uac00\ud558\uace0 L2 normalization \uc744 \uc0ac\uc6a9\ud558\uc5ec \ucd9c\ub825\uc744 256-dimensional embeddings \ub85c \ub9e4\ud551\ud55c\ub2e4."),(0,o.kt)("p",null,"negative samples \ub97c \ubcf4\uac15\ud558\uae30 \uc704\ud574, momentum encoder \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc774\uc804 mini-batches \uc758 \uc784\ubca0\ub529\uc744 \uc800\uc7a5\ud55c\ub2e4."),(0,o.kt)("p",null,"\uad6c\uccb4\uc801\uc73c\ub85c, momentum encoder \ub294 \ud604\uc7ac mini-batch \uc758 \uc0d8\ud50c\uc744 enqueue \ud558\uace0 \uac00\uc7a5 \uc624\ub798\ub41c mini-batch \ub294 dequeue \ud558\uc5ec queuing \uc2dc\uc2a4\ud15c\uc744 \uc720\uc9c0\ud55c\ub2e4."),(0,o.kt)("p",null,"\uae30\uc874\uc758 encoder \uc640 momentum encoder \uc758 linear interpolation \uc744 \ud1b5\ud574 momentum encoder \ub97c \uc5c5\ub370\uc774\ud2b8\ud558\uc5ec training step \uac04\uc758 representation \uc77c\uad00\uc131\uc744 \ubcf4\uc7a5\ud55c\ub2e4."),(0,o.kt)("h3",{id:"text-code-matching"},"Text-Code Matching"),(0,o.kt)("p",null,"\uc774 task \ub294 decoder \ub97c \ud65c\uc131\ud654\uc2dc\ud0a4\uace0 text \uc640 code snippet \uc774 \ub3d9\uc77c\uc548 \uc758\ubbf8\ub97c \uac00\uc9c0\ub294\uc9c0 \uc608\uce21\ud558\ub294 \uac83\uc744 \ubaa9\ud45c\ub85c \ud568."),(0,o.kt)("p",null,"\uc774\ub294 text \uc640 code modalities \uac04\uc758 fine-grained alignment \ub97c \ud3ec\ucc29\ud558\ub294 \ub354 \ub098\uc740 bimodal representations \ub97c \ud559\uc2b5 \ud558\ub294\ub370 \ub3c4\uc6c0\uc774 \ub41c\ub2e4."),(0,o.kt)("p",null,"code sample \uc774 \uc8fc\uc5b4\uc9c0\uba74 decoder \ub294 embedding layer \ubc0f causal self-attention layer \ub97c \ud1b5\uacfc\uc2dc\ud0a8 \ud6c4, self-attention representation \uc740 cross attention layer \ub85c \uc804\ub2ec\ub418\uc5b4 encoder \ub85c\ubd80\ud130 \ubc1b\uc740 text representation \uc640 \uad00\ub828\ud55c signal \uc744 query \ud55c\ub2e4."),(0,o.kt)("p",null,"task-specific ","[Match]"," token \uc740 code input sequence \uc758 \ub9e8 \uc55e\uc5d0 \ucd94\uac00\ub418\uc5b4 decoder \uc5d0 text-code matching functionality \ub97c \uc81c\uacf5\ud574\uc8fc\uba70, ","[EOS]"," token \uc740 code input \ub05d\uc5d0 \ucd94\uac00\ub41c\ub2e4."),(0,o.kt)("p",null,"decoder \ub294 causal self-attention mask \ub97c \uc0ac\uc6a9\ud558\uba70 last decoder token \ub9cc \uc804\uccb4 context \uc5d0 \ucc38\uc5ec\ud560 \uc218 \uc788\uc5b4, ","[EOS]"," \uc758 output embedding \uc744 text-code cross-modal \uc758 alignment representation \uc73c\ub85c \ub2e4\ub8ec\ub2e4."),(0,o.kt)("p",null,"\ub9c8\uc9c0\ub9c9\uc73c\ub85c, binary matching task \ub97c \uc704\ud574 decoder \uc758 output embedding \uc704\uc5d0 linear layer \ub97c \uc0ac\uc6a9\ud558\uc5ec text-code pair \uac00 positive (match) \uc778\uc9c0 negative (unmatched) \uc778\uc9c0\ub97c \uc608\uce21\ud55c\ub2e4."),(0,o.kt)("hr",null),(0,o.kt)("p",null,"\uc815\ubcf4\uac00 \ub9ce\uc740 negative \ub97c \ucc3e\uae30 \uc704\ud574, \uc800\uc790\ub294 hard negative mining \uc804\ub7b5\uc744 \uc0ac\uc6a9\ud55c\ub2e4."),(0,o.kt)("p",null,"\ud2b9\ud788, \ud604\uc7ac \uc0d8\ud50c\uacfc momentum encoder \uac00 \uc720\uc9c0\ud558\ub294 queue \ub0b4\uc758 \uc774\uc804 \uc0d8\ud50c \uac04\uc758 contrastive-based similarity score \uc5d0 \ub530\ub77c hard negative \ub97c \uc0d8\ud50c\ub9c1\ud55c\ub2e4."),(0,o.kt)("p",null,"\uc774\ub807\uac8c \ud558\uba74 harder negative \uac00 \uc120\ud0dd\ub420 \uac00\ub2a5\uc131\uc774 \ub192\uc544\uc9c4\ub2e4."),(0,o.kt)("p",null,"positive pairs \uc758 batch \uc758 \uacbd\uc6b0, code/text query \ub97c \uc0ac\uc6a9\ud558\uc5ec text/code queue \uc5d0\uc11c negative \ub97c mining \ud558\uc5ec negative pairs \uc758 \ub450 batch \ub97c \uad6c\uc131\ud55c\ub2e4."),(0,o.kt)("h3",{id:"text-code-causal-lm"},"Text-Code Causal LM"),(0,o.kt)("p",null,"\uc774 task \ub294 encoder \ubc0f decoder \ubaa8\ub450 \ud65c\uc131\ud654\uc2dc\ud0a4\uba70, text-to-code \ubc0f code-to-text \uc0dd\uc131\uc73c\ub85c dual multimodal conversion \uc744 \ud1b5\ud55c cross-modal generative \ubaa9\ud45c\uc5d0 \ucd08\uc810\uc744 \ub454\ub2e4."),(0,o.kt)("p",null,"\uad6c\uccb4\uc801\uc73c\ub85c, text sample \uc774 input \uc77c \uacbd\uc6b0, decoder \uc758 input sequence \uc5d0 ","[CDec]"," token \uc744 \uc55e\uc5d0 \ucd94\uac00\ud55c\ub2e4. "),(0,o.kt)("p",null,"\uc774 \uacbd\uc6b0, decoder \ub294 code generation funtionality \ub85c \uc791\ub3d9\ud55c\ub2e4. "),(0,o.kt)("p",null,"\ubc18\ub300\ub85c, input \uc774 code sample \uc778 \uacbd\uc6b0\uc5d4 decoder \uc758 input sequence dp ","[TDec]"," token \ub9e8 \uc55e\uc5d0 \ucd94\uac00\ud558\uc5ec, deocder \ub294 text generation functionality \ub85c \uc791\ub3d9\ud55c\ub2e4."),(0,o.kt)("p",null,"\uc774\ub7f0 \uc720\ud615\uc758 Causal LM \uc740 code summarization \uac19\uc740 multimodal generative downstream tasks \uc5d0\uc11c pretrain-finetune gap \uc744 \uc904\uc774\uae30 \uc704\ud55c \ud6a8\uacfc\uc801\uc778 learning objective \ub85c \uc785\uc99d\ub418\uc5c8\ub2e4."),(0,o.kt)("h2",{id:"33-compute-efficient-pretraining-with-frozen-off-the-shelf-llms"},"3.3. Compute-efficient Pretraining with Frozen Off-the-shelf LLMs"),(0,o.kt)("p",null,"\ubaa8\ub378\uc744 \ucca8\ubd80\ud130 pretraining \ud558\uc9c0 \uc54a\uace0 \ud6a8\uc728\uc801\uc73c\ub85c \ud655\uc7a5\ud558\uae30 \uc704\ud574, \uc800\uc790\ub294 CodeT5+ \uc758 component (encoder, decoder)\ub97c off-the-shelf pretrained LLM \ub85c \ucd08\uae30\ud654\ud558\ub294 compute-efficient pretraining \uc804\ub7b5\uc744 \uc81c\uc548\ud55c\ub2e4. (Fig 2. \uc624\ub978\ucabd)"),(0,o.kt)("p",null,"\uc774 \ud655\uc7a5\uc744 \uc704\ud574, ","[Li et al., 2022b]",' \uc758 \uc601\uac10\uc744 \ubc1b\uc544, \uae30\uc874 T5 \ubaa8\ub378\uacfc \ub3d9\uc77c\ud55c \ud06c\uae30\uc758 encoder \uc640 decoder \ub300\uc2e0 "shallow encoder and deep decoder" architecture \ub97c \uc0ac\uc6a9\ud55c\ub2e4.'),(0,o.kt)("p",null,"[Li et al., 2022b]"," \uc5d0 \ub530\ub974\uba74, T5-based model \uc758 decoder \ub294 \uc885\uc885 \uc0dd\uc131 \uc791\uc5c5\uc5d0\uc11c \ub354 \ub192\uc740 \ubcf5\uc7a1\uc131\uc744 \ucc98\ub9ac\ud574\uc57c \ud558\ubbc0\ub85c, \ub354 \ub9ce\uc740 neural parameters \ub85c \uac15\ud654\ud574\uc57c \ud55c\ub2e4."),(0,o.kt)("p",null,"\ubd84\ub9ac\ub418\uc5b4 pretrain \ub41c encoder \uc640 decoder \ub97c \uc5f0\uacb0\ud558\uae30 \uc704\ud574, \uc800\uc790\ub294 self-attention layer \uc774\ud6c4 decoder block \uc5d0 \ubb34\uc791\uc704\ub85c \ucd08\uae30\ud654\ub41c cross-attention layer \ub97c \uc0bd\uc785\ud55c\ub2e4."),(0,o.kt)("p",null,"efficient tuning \uc744 \uc704\ud574, cross-attention layer \ub294 top-",(0,o.kt)("span",{parentName:"p",className:"math math-inline"},(0,o.kt)("span",{parentName:"span",className:"katex"},(0,o.kt)("span",{parentName:"span",className:"katex-mathml"},(0,o.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,o.kt)("semantics",{parentName:"math"},(0,o.kt)("mrow",{parentName:"semantics"},(0,o.kt)("mi",{parentName:"mrow"},"L")),(0,o.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"L")))),(0,o.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,o.kt)("span",{parentName:"span",className:"base"},(0,o.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,o.kt)("span",{parentName:"span",className:"mord mathnormal"},"L")))))," decoder layer (\ubcf8 \uc2e4\ud5d8\uc740",(0,o.kt)("span",{parentName:"p",className:"math math-inline"},(0,o.kt)("span",{parentName:"span",className:"katex"},(0,o.kt)("span",{parentName:"span",className:"katex-mathml"},(0,o.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,o.kt)("semantics",{parentName:"math"},(0,o.kt)("mrow",{parentName:"semantics"},(0,o.kt)("mi",{parentName:"mrow"},"L")),(0,o.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"L")))),(0,o.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,o.kt)("span",{parentName:"span",className:"base"},(0,o.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,o.kt)("span",{parentName:"span",className:"mord mathnormal"},"L"))))),"=1)\uc5d0\ub9cc \uc0bd\uc785\ud55c\ub2e4."),(0,o.kt)("p",null,"small encoder \uc640 cross-attention layer \ub9cc trainable \ud558\ub3c4\ub85d \uc720\uc9c0\ud558\uba74\uc11c, \ub300\ubd80\ubd84\uc758 decoder parameter \ub294 \uace0\uc815\ud55c\ub2e4. \ub610\ud55c, training stability \ud5a5\uc0c1\uc744 \uc704\ud574 gating function \uc744 \ucd94\uac00\ud558\uac70\ub098 \ud2b9\uc815 frequency \ub85c multiple cross-attention layer \ub97c \uc0bd\uc785\ud558\ub294 \ub4f1\uc758 \uc124\uacc4\ub3c4 \ud0d0\uad6c\ud55c\ub2e4."),(0,o.kt)("p",null,"\ud558\uc9c0\ub9cc, \uc0c1\ub2f9\ud55c \uc131\ub2a5 \ud5a5\uc0c1\uc740 \uad00\ucc30\ub418\uc9c0 \uc54a\uc558\uc73c\uba70, \ub354 \uc88b\uc9c0 \uc54a\uc740 \uacb0\uacfc\ub85c\ub294 \uc774\ub7f0 \uc124\uacc4 \uc120\ud0dd\uc740 \uacc4\uc0b0 \ube44\uc6a9\uc774 \ub108\ubb34 \ub9ce\uc774 \ub4e4\uac8c \ub41c\ub2e4."),(0,o.kt)("h2",{id:"34-adaptation-to-downstream-understanding-and-generation-tasks"},"3.4. Adaptation to Downstream Understanding and Generation Tasks"),(0,o.kt)("p",null,"pretraining \uc758 \ub450 \ub2e8\uacc4 \ud6c4, CodeT5+ \ub294 \ub2e4\uc591\ud55c \ubaa8\ub4dc\uc5d0 \uc720\uc5f0\ud558\uac8c \uc791\ub3d9\ud558\uc5ec Seq2Seq generation task, decoder-only tasks \ubc0f understanding-based tasks \ub97c \ud3ec\ud568\ud55c \ub2e4\uc591\ud55c task \ub97c \uc9c0\uc6d0\ud560 \uc218 \uc788\ub2e4."),(0,o.kt)("h3",{id:"seq2seq-generation-tasks"},"Seq2Seq Generation Tasks"),(0,o.kt)("p",null,"encoder-decoder model \uc778 CodeT5+ \ub294 code generation \ubc0f summarization \uac19\uc740 Seq2Seq generation task \uc5d0 \uc790\uc5f0\uc2a4\ub7fd\uac8c \uc801\uc751\ud560 \uc218 \uc788\ub2e4."),(0,o.kt)("p",null,"\ub610\ud55c, encoder \ub97c \uc0ac\uc6a9\ud558\uc5ec code snippets \ub97c \uac80\uc0c9\ud558\uace0, \uc774\ub97c code generation \uc744 \uc704\ud574 encoder \ubc0f decoder \ubaa8\ub450 \uc0ac\uc6a9\ud558\ub294 retrieval-agumented generation model \ub85c \uc801\uc6a9\ud560 \uc218 \uc788\ub2e4."),(0,o.kt)("h3",{id:"decoder-only-tasks"},"Decoder-only Tasks"),(0,o.kt)("p",null,"\uc774 \uc124\uc815\uc5d0\uc120, encoder input \uc5d0 \ud56d\uc0c1 ","[CLM]"," \ud1a0\ud070\uc744 \uc8fc\uc785\ud558\uace0, source sequence \ub97c prefix context \ub85c decoder \uc5d0 \uc804\ub2ec\ud55c\ub2e4."),(0,o.kt)("p",null,"encoder \uc640 decoder \uc758 cross-attention layers \uc758 weight \ub97c \uace0\uc815\ud55c\ub2e4."),(0,o.kt)("p",null,"\uc774 \uc804\ub7b5\uc740 decoder \ud30c\ud2b8\ub9cc \ud65c\uc131\ud654\ud558\uba70 \uae30\uc220\uc801\uc73c\ub85c \uc804\uccb4 model parameter \uc758 \uc57d \uc808\ubc18\uc744 \uc904\uc778\ub2e4."),(0,o.kt)("p",null,"\uc800\uc790\ub294 next-line code completion task \ub97c \uc0ac\uc6a9\ud558\uc5ec CodeT5+ \uc758 decoder \uc804\uc6a9 generation \ub2a5\ub825\uc744 \ud3c9\uac00\ud55c\ub2e4."),(0,o.kt)("h3",{id:"understanding-tasks"},"Understanding Tasks"),(0,o.kt)("p",null,"CodeT5+ \ub294 understanding tasks \ub97c \ub450 \uac00\uc9c0 \ubc29\uc2dd\uc73c\ub85c \uc9c0\uc6d0\ud560 \uc218 \uc788\ub2e4"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"encoder \ub97c \uc0ac\uc6a9\ud558\uc5ec text/code embedding \uc744 \uc5bb\uc5b4 \uc774\ub97c detection task \ub098 retrieval task \ub97c \uc704\ud574 binary classifier \uc5d0 \uc804\ub2ec\ud560 \uc218 \uc788\ub2e4."),(0,o.kt)("li",{parentName:"ol"},"encoder \ub97c decoder \uc640 \uacb0\ud569\ud558\uc5ec text-to-code retrieval task \uc5d0 \ub300\ud55c text-code matching score \ub97c \uc608\uce21\ud560 \uc218 \uc788\ub2e4.")),(0,o.kt)("h1",{id:"4-pretraining-and-instruction-tuning"},"4. Pretraining and Instruction Tuning"),(0,o.kt)("h2",{id:"41-pretraining-dataset"},"4.1. Pretraining Dataset"),(0,o.kt)("p",null,"\ucd5c\uadfc \ucd9c\uc2dc\ub41c GitHub Code \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec CodeSearchNet \uc758 pretraining dataset \uc744 \ud655\uc7a5\ud588\ub2e4."),(0,o.kt)("p",null,"9 \uac1c\uc758 PLs (Python, Java, Ruby, JavaScript, GO, PHP, C, C++, C#)\ub97c \uc120\ud0dd\ud558\uc600\uace0, \ud5c8\uc6a9 \ub77c\uc774\uc120\uc2a4\ub97c \uac00\uc9c4 \ucf54\ub4dc\uc640 50 ~ 2000 tokens \uc744 \uac00\uc9c4 \ud30c\uc77c\ub4e4\ub9cc \ud544\ud130\ub9c1 \ud558\uc600\ub2e4."),(0,o.kt)("p",null,"\ub610\ud55c, GitHub repository name \uc744 \ud655\uc778\ud558\uc5ec CodeSearchNet \uacfc \ub2e4\ub978 downstream tasks \uc5d0\uc11c \uc911\ubcf5\ub418\ub294 \ubd80\ubd84\uc744 \ud544\ud130\ub9c1\ud588\ub2e4."),(0,o.kt)("p",null,"\uc911\ubcf5 \ub370\uc774\ud130\ub294  exact match \ub97c \uae30\uc900\uc73c\ub85c \ud544\ud130\ub9c1\ub418\uc5b4 \uc911\ubcf5\ub418\ub294 \ubd80\ubd84\uc774 \uc788\uc744 \uc218 \uc788\uc9c0\ub9cc, \uc774 \uc911\ubcf5\uc740 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ud070 \uc601\ud5a5\uc744 \ubbf8\uce58\uc9c0 \uc54a\uc744 \uac83\uc73c\ub85c \uc608\uc0c1\ub41c\ub2e4."),(0,o.kt)("p",null,"\uc800\uc790\ub294 CodeT5 tokenizer \ub97c \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uad6d\uc5b4 \ub370\uc774\ud130\uc14b\uc744 \ud1a0\ud070\ud654\ud588\uc73c\uba70, \uc774\ub85c \uc778\ud574 5150\uc5b5 \uac1c\uc758 \ud1a0\ud070\uc774 \uc0dd\uc131\ub418\uc5c8\ub2e4. \uc774\ub294 CodeSearchNet \ubcf4\ub2e4 \uc57d 50\ubc30 \ud070 \ud06c\uae30\uc774\ub2e4."),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://velog.velcdn.com/images/whdnjsdyd111/post/0ae8a69d-13f6-417f-b2b0-fa999be692cc/image.png",alt:null})),(0,o.kt)("p",null,"Table 1 \uc5d0\ub294 unimodal code \ubc0f bimodal text-code pretrained dataset \uc758 \ud1b5\uacc4\uc774\ub2e4."),(0,o.kt)("p",null,"\ud45c\uc5d0\uc11c \ubcf4\uc774\ub4ef, GitHub \ucf54\ub4dc\ub85c\ubd80\ud130 \uc815\ub9ac\ub41c \ub370\uc774\ud130\uc14b\uc740 CodeSearchNet bimodal data \uc758 function level \ubcf4\ub2e4 \ud6e8\uc52c \ud070 \ub370\uc774\ud130 \ud06c\uae30\ub97c \uac00\uc9c0\uace0 \uc788\uc5b4, \ubaa8\ub378\uc774 pretrain \uc758 \uccab \ub2e8\uacc4\uc5d0\uc11c \ud48d\ubd80\ud55c representation \uc744 \ud559\uc2b5\ud560 \uc218 \uc788\uac8c \ud574\uc900\ub2e4."),(0,o.kt)("p",null,"CodeT5 \uc640 \ub2ec\ub9ac \uc800\uc790\ub294 CodeSearchNet \uc758 bimodal \ub370\uc774\ud130\ub9cc\uc744 CodeT5+ \uc758 \ub450 \ubc88\uc9f8 \ub2e8\uacc4 pretrain \uc5d0 \uc0ac\uc6a9\ud55c\ub2e4."),(0,o.kt)("p",null,"\uc774 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uc8fc\ub85c text-code \uad00\ub828 task \uc778 text-to-code retrieval \ubc0f generation \uc5d0 \ubaa8\ub378\uc744 \uc801\uc751\uc2dc\ud0a8\ub2e4."),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://velog.velcdn.com/images/whdnjsdyd111/post/02324785-4135-4a1f-84aa-b405f15475df/image.png",alt:null})),(0,o.kt)("h2",{id:"42-pretraining-setup"},"4.2. Pretraining Setup"),(0,o.kt)("p",null,"\uc800\uc790\ub294 CodeT5+ models \uc744 \ub450 \uadf8\ub8f9\uc73c\ub85c pretrain \ud55c\ub2e4."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"CodeT5+ 220M \ubc0f 770M \uc740 T5 \uc758 \uc544\ud0a4\ud14d\ucc98\uc5d0 \ub530\ub77c \ucc98\uc74c\ubd80\ud130 train \ub41c\ub2e4."),(0,o.kt)("li",{parentName:"ol"},"CodeT5+ 2B, 6B, 16B \ub294 decoder \ub97c CodeGen-mono 2B, 6B, 16B model \uc5d0\uc11c \ucd08\uae30\ud654\ud558\uace0 encoder \ub97c CodeGen-mono 350M \uc5d0\uc11c \ucd08\uae30\ud654\ud55c\ub2e4.")),(0,o.kt)("p",null,"scaing \uc804\ub7b5\uc744 \uc8fc\ubaa9\ud558\uc790, "),(0,o.kt)("p",null,"\uc6d0\ub798\uc758 CodeGen \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec \ud6c4\uc790\uc758 CodeT5+ \ubaa8\ub378 \uadf8\ub8f9\uc740 \ubb34\uc2dc\ud560 \ub9cc\ud55c \ud559\uc2b5 \uac00\ub2a5\ud55c \ub9e4\uac1c\ubcc0\uc218\ub97c \ub3c4\uc785\ud569\ub2c8\ub2e4(2B, 6B, 16B \ubaa8\ub378\uc5d0 \ub300\ud574 350M \uc778\ucf54\ub354\uc640 36M, 67M, 151M\uc758 \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4 \ud558\ub098). \uc774 \ub450 \uadf8\ub8f9\uc758 \ubaa8\ub378\uc5d0\ub294 \uac01\uac01 CodeT5 \ud1a0\ud06c\ub098\uc774\uc800\uc640 CodeGen \ud1a0\ud06c\ub098\uc774\uc800\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc0ac\uc804\ud559\uc2b5\uc5d0\uc11c\ub294 16\uac1c\uc758 A100-40G GPU\uac00 \uc7a5\ucc29\ub41c Google Cloud Platform\uc758 \ud074\ub7ec\uc2a4\ud130\uc5d0\uc11c CodeT5+\ub97c \ub300\uaddc\ubaa8\uc758 \ub2e8\ubaa8\ub2ec \ub370\uc774\ud130\uc14b\uacfc \uc774\ud6c4 \uc791\uc740 \uc774\uc911\ubaa8\ub2ec \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 \ub2e8\uacc4\uc801\uc778 \uc804\ub7b5\uc73c\ub85c \uc0ac\uc804\ud559\uc2b5\ud569\ub2c8\ub2e4."),(0,o.kt)("p",null,"\uccab \ubc88\uc9f8 \ub2e8\uacc4\uc5d0\uc11c\ub294 10,000\ubc88\uc758 \ud559\uc2b5 \ub2e8\uacc4 \ub3d9\uc548 \ubaa8\ub378\uc744 \uc2a4\ud32c \ub178\uc774\uc988 \uc81c\uac70 \uc791\uc5c5\uc73c\ub85c \uc608\uc5f4\ud55c \ud6c4, \ub450 \uac1c\uc758 CLM \uc791\uc5c5\uacfc \uac19\uc740 \uac00\uc911\uce58\ub85c \ud569\ub3d9 \ud6c8\ub828\uc744 100,000\ubc88\uc758 \ub2e8\uacc4 \ub3d9\uc548 \uc9c4\ud589\ud569\ub2c8\ub2e4. \uc2a4\ud32c \ub178\uc774\uc988 \uc81c\uac70 \uc791\uc5c5\uc5d0 \ub300\ud574 \uc120\ud615 \uac10\uc1e0 \ud559\uc2b5\ub960(LR) \uc2a4\ucf00\uc904\ub7ec\ub97c \uc0ac\uc6a9\ud558\uba70, \ucd5c\ub300 \ud559\uc2b5\ub960\uc740 2e-4\uc774\uace0 \ubc30\uce58 \ud06c\uae30\ub294 \ub178\uc774\uc988 \uc81c\uac70\uc5d0\ub294 2048, CLM\uc5d0\ub294 512\ub85c \uc124\uc815\ud569\ub2c8\ub2e4. \uc785\ub825 \ubc0f \ucd9c\ub825 \ub370\uc774\ud130\ub97c \uc900\ube44\ud558\uae30 \uc704\ud574 \uc2a4\ud32c \ub178\uc774\uc988 \uc81c\uac70 \uc791\uc5c5\uc758 \ucd5c\ub300 \uae38\uc774\ub97c 512\ub85c \uc124\uc815\ud558\uace0, \ucf54\ub4dc \uc644\uc131 CLM\uc758 \uc18c\uc2a4 \ubc0f \ud0c0\uac9f \uc2dc\ud000\uc2a4\uc758 \ucd5c\ub300 \uae38\uc774\ub97c \uac01\uac01 768\uacfc 600\uc73c\ub85c, \ub514\ucf54\ub354\ub9cc\uc744 \uc0ac\uc6a9\ud55c \uc0dd\uc131 CLM\uc758 \ucd5c\ub300 \uae38\uc774\ub97c 1\uacfc 1024\ub85c \uc124\uc815\ud569\ub2c8\ub2e4."),(0,o.kt)("p",null,"\ub450 \ubc88\uc9f8 \ub2e8\uacc4\uc5d0\uc11c\ub294 \ub300\uc870 \ud559\uc2b5, \ub9e4\uce6d \ubc0f \ub450 \uac1c\uc758 CLM \uc190\uc2e4\uc744 \ub3d9\uc77c\ud55c \uac00\uc911\uce58\ub85c 10 \uc5d0\ud3ed \ub3d9\uc548 \ud569\ub3d9\uc73c\ub85c \ucd5c\uc801\ud654\ud569\ub2c8\ub2e4. \ubc30\uce58 \ud06c\uae30\ub294 256\uc774\uace0 \ucd5c\ub300 \uc2dc\ud000\uc2a4 \uae38\uc774\ub294 \ucf54\ub4dc\uc640 \ud14d\uc2a4\ud2b8 \uc2dc\ud000\uc2a4 \uac01\uac01 420\uacfc 128\ub85c \uc124\uc815\ud569\ub2c8\ub2e4."),(0,o.kt)("p",null,"\ubaa8\ub4e0 \uc2e4\ud5d8\uc5d0\uc11c\ub294 0.1 \uac00\uc911\uce58 \uac10\uc1e0\ub97c \uac00\uc9c4 AdamW \uc635\ud2f0\ub9c8\uc774\uc800 ","[Loshchilov and Hutter, 2019]","\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ub610\ud55c DeepSpeed\uc758 ZeRO Stage 2 ","[Rasley et al., 2020]","\uc640 FP16\uc758 \ud63c\ud569 \uc815\ubc00\ub3c4 \ud6c8\ub828\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud6c8\ub828 \uac00\uc18d\ud654\ub97c \uc218\ud589\ud569\ub2c8\ub2e4. CodeT5+ 2B, 6B \ubc0f 16B\uc758 \ud6c8\ub828\uc5d0\ub294 FP16\ub85c \uace0\uc815\ub41c \ub514\ucf54\ub354 \uac00\uc911\uce58\ub97c \uc0ac\uc6a9\ud558\uace0 \ub2e4\ub978 \ud559\uc2b5 \uac00\ub2a5\ud55c \uac00\uc911\uce58\ub294 FP32\ub85c \uc720\uc9c0\ud569\ub2c8\ub2e4. CodeT5+ 6B \ubc0f 16B \ubaa8\ub378\uc5d0 \ub300\ud574\uc11c\ub294 DeepSpeed ZeRO Stage 3\uc758 \ub9e4\uac1c\ubcc0\uc218 \ubd84\ud560\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4."))}u.isMDXComponent=!0},10954:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/image-8e1ada16915a7783d6b61a8bf2815fb1.png"}}]);