[{"documents":[{"i":1,"t":"","u":"/blog/archive","b":["Blog"]},{"i":2,"t":"Long Blog Post","u":"/blog/long-blog-post","b":["Blog"]},{"i":4,"t":"First Blog Post","u":"/blog/first-blog-post","b":["Blog"]},{"i":6,"t":"Welcome","u":"/blog/welcome","b":["Blog"]},{"i":8,"t":"MDX Blog Post","u":"/blog/mdx-blog-post","b":["Blog"]},{"i":10,"t":"Tutorial Intro","u":"/docs/intro","b":["Docs"]},{"i":20,"t":"EfficientNetV2: Smaller Models and Faster Training","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","b":["Docs","Paper","Computer Vision","Image Classification"]},{"i":81,"t":"An Image Is Worth 16X16 Words: Transformers for image recognition at sacle","u":"/docs/Paper/Computer Vision/Image Classification/ViT","b":["Docs","Paper","Computer Vision","Image Classification"]},{"i":121,"t":"A Unified Sequence Interface for Vision Tasks","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","b":["Docs","Paper","Computer Vision","Multi-task"]},{"i":160,"t":"UNINEXT: Universal Instance Perception as Object Discovery and Retrieval","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","b":["Docs","Paper","Computer Vision","Multi-task"]},{"i":210,"t":"PromptDA : Label-guided Data Augmentation for Prompt-based Few Shot Learners","u":"/docs/Paper/NLP/Augmentation/PromptDA","b":["Docs","Paper","NLP","Augmentation"]},{"i":216,"t":"Prismer: A Vision-Language Model with An Esemble of Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","b":["Docs","Paper","Computer Vision","Vision-Language"]},{"i":280,"t":"Attention Is All You Need","u":"/docs/Paper/NLP/Model/Transformer","b":["Docs","Paper","NLP","Model"]},{"i":331,"t":"Unsupervised Prompt Learning for Vision-Language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","b":["Docs","Paper","Computer Vision","Vision-Language"]},{"i":379,"t":"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","b":["Docs","Paper","NLP","Multi-Task"]},{"i":431,"t":"From Images to Textual Prompts: Zero-shot Visual Question Answering with Frozen Large Language Models","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","b":["Docs","Paper","Computer Vision","Vision-Language"]},{"i":480,"t":"CodeT5+: Open Code Large Language Models for Code Understanding and Generation","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","b":["Docs","Paper","NLP","Multi-Task"]},{"i":518,"t":"BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","b":["Docs","Paper","NLP","PEFT","Composition"]},{"i":534,"t":"Scaling Instruction-Finetuned Language Models","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","b":["Docs","Paper","NLP","Multi-Task"]},{"i":584,"t":"Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning","u":"/docs/Paper/NLP/PEFT/Composition/IA³","b":["Docs","Paper","NLP","PEFT","Composition"]},{"i":623,"t":"Parameter-efficient Tuning for Large Language Model without Calculating Its Gradients","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","b":["Docs","Paper","NLP","PEFT","Mixture"]},{"i":653,"t":"Parameter-Efficient Transfer Learning for NLP","u":"/docs/Paper/NLP/PEFT/Module/Adapter","b":["Docs","Paper","NLP","PEFT","Module"]},{"i":678,"t":"APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":714,"t":"LoRA: Low-Rank Adaptation of Large Language Models","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","b":["Docs","Paper","NLP","PEFT","Composition"]},{"i":781,"t":"Adaptive Budget Allocation For Parameter-Efficient Fine-Tuning","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","b":["Docs","Paper","NLP","PEFT","Composition"]},{"i":844,"t":"Pruning Pre-trained Language Models Without Fine-Tuning","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","b":["Docs","Paper","NLP","PEFT","Pruning"]},{"i":882,"t":"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":929,"t":"LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":974,"t":"ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1009,"t":"P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1057,"t":"DEPT: Decomposed Prompt Tuning For Parameter-Efficient Fine Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1088,"t":"GPT Understands, Too","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1121,"t":"The Power of Scale for Parameter-Efficient Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1154,"t":"Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1222,"t":"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1286,"t":"Prefix-Tuning: Optimizing Continuous Prompts for Generation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1342,"t":"SMoP: Towards Efficient and Effective Prompt Tuning with Sparse Mixture-of-Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1374,"t":"UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","b":["Docs","Paper","NLP","PEFT","Mixture"]},{"i":1404,"t":"SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1437,"t":"Reflexion: Language Agents with Verbal Reinforcement Learning","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","b":["Docs","Paper","NLP","Reinforcement Learning"]},{"i":1463,"t":"XPrompt: Exploring the Extreme of Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","b":["Docs","Paper","NLP","PEFT","Soft Prompt"]},{"i":1528,"t":"What is the Algorithm?","u":"/docs/Programming/Algorithm/","b":["Docs","Programming","What is the Algorithm?"]},{"i":1541,"t":"Training language models to follow instructions with human feedback (+ ChatGPT)","u":"/docs/Paper/NLP/Text Generation/InstructGPT","b":["Docs","Paper","NLP","Text Generation"]},{"i":1580,"t":"Congratulations!","u":"/docs/tutorial-basics/congratulations","b":["Docs","Tutorial - Basics"]},{"i":1584,"t":"Create a Blog Post","u":"/docs/tutorial-basics/create-a-blog-post","b":["Docs","Tutorial - Basics"]},{"i":1588,"t":"BackJoon","u":"/docs/Programming/Algorithm/Problems","b":["Docs","Programming","What is the Algorithm?"]},{"i":1590,"t":"Create a Document","u":"/docs/tutorial-basics/create-a-document","b":["Docs","Tutorial - Basics"]},{"i":1596,"t":"Deploy your site","u":"/docs/tutorial-basics/deploy-your-site","b":["Docs","Tutorial - Basics"]},{"i":1601,"t":"Manage Docs Versions","u":"/docs/tutorial-extras/manage-docs-versions","b":["Docs","Tutorial - Extras"]},{"i":1609,"t":"Create a Page","u":"/docs/tutorial-basics/create-a-page","b":["Docs","Tutorial - Basics"]},{"i":1615,"t":"Markdown Features","u":"/docs/tutorial-basics/markdown-features","b":["Docs","Tutorial - Basics"]},{"i":1629,"t":"Translate your site","u":"/docs/tutorial-extras/translate-your-site","b":["Docs","Tutorial - Extras"]},{"i":1641,"t":"PTR: Prompt Tuning with Rules for Text Classification","u":"/docs/Paper/NLP/Prompt Tuning/PTR","b":["Docs","Paper","NLP","Prompt Tuning"]},{"i":1690,"t":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing","u":"/docs/Paper/NLP/Survey/Prompting","b":["Docs","Paper","NLP","Survey"]}],"index":{"version":"2.3.9","fields":["t"],"fieldVectors":[["t/1",[]],["t/2",[0,4.524,1,3.144,2,3.144]],["t/4",[1,3.144,2,3.144,3,4.524]],["t/6",[4,5.463]],["t/8",[1,3.144,2,3.144,5,4.524]],["t/10",[6,4.95,7,4.95]],["t/20",[8,3.861,9,3.861,10,1.228,11,3.861,12,2.468]],["t/81",[13,3.882,14,3.165,15,3.165,16,3.165,17,2.716,18,3.165,19,3.165]],["t/121",[20,3.313,21,3.861,22,3.861,23,2.953,24,2.953]],["t/160",[25,3.367,26,2.89,27,3.367,28,3.367,29,3.367,30,3.367,31,3.367]],["t/210",[32,2.681,33,2.301,34,2.681,35,2.681,36,2.681,37,2.681,38,0.853,39,2.301,40,2.301,41,2.051,42,2.681]],["t/216",[10,1.144,23,2.751,43,3.597,44,1.202,45,3.597,46,3.597]],["t/280",[47,3.44,48,4.95]],["t/331",[10,1.144,23,2.751,38,1.144,44,1.202,49,3.597,50,2.3]],["t/379",[10,1.006,38,1.006,44,1.058,51,3.165,52,3.165,53,3.165,54,3.165,55,2.023]],["t/431",[10,0.811,13,2.19,38,0.811,41,1.951,44,0.853,55,1.631,56,2.552,57,2.19,58,2.19,59,2.552,60,2.552,61,2.19]],["t/480",[10,0.949,44,0.998,55,1.909,62,2.986,63,2.986,64,4.337,65,2.562,66,2.562]],["t/518",[10,0.853,17,2.301,39,2.301,44,0.896,67,2.681,68,2.681,69,1.165,70,0.993,71,1.483,72,0.811,73,2.681]],["t/534",[10,1.228,44,1.291,74,2.953,75,2.953,76,3.861]],["t/584",[40,2.425,41,2.161,50,1.806,69,1.228,70,1.046,71,1.563,72,0.855,77,2.425,78,2.825,79,2.825]],["t/623",[10,0.949,44,0.998,55,1.909,69,1.297,70,1.105,72,0.903,80,2.562,81,2.986,82,2.986]],["t/653",[50,2.468,69,1.678,70,1.429,83,2.953,84,3.861]],["t/678",[10,0.898,12,1.806,38,0.898,44,0.944,47,1.964,70,1.046,72,0.855,85,2.825,86,1.675,87,2.161]],["t/714",[10,1.071,44,1.126,55,2.153,86,1.996,88,3.367,89,3.367,90,3.367]],["t/781",[69,1.463,70,1.246,71,1.863,72,1.019,86,1.996,91,3.367,92,3.367]],["t/844",[10,1.006,12,2.023,44,1.058,71,1.751,72,0.957,80,2.716,87,2.42,93,3.165]],["t/882",[10,0.898,44,0.944,47,1.964,57,2.425,70,1.046,71,1.563,72,0.855,86,1.675,94,2.425,95,2.825]],["t/929",[10,1.006,58,2.716,69,1.375,70,1.171,75,2.42,86,1.876,94,2.716,96,2.716]],["t/974",[24,2.051,38,0.853,47,1.864,69,1.165,70,0.993,72,0.811,97,2.681,98,2.681,99,2.681,100,2.301,101,2.301]],["t/1009",[24,2.051,26,2.301,38,0.853,71,1.483,72,1.451,74,2.051,96,2.301,102,2.681,103,2.681]],["t/1057",[38,1.006,69,1.375,70,1.171,71,1.751,72,1.368,104,3.165,105,3.165]],["t/1088",[65,4.248,106,4.95]],["t/1121",[38,1.144,69,1.563,70,1.331,72,1.088,74,2.751,107,3.597]],["t/1154",[38,1.438,72,1.368,108,4.523,109,3.165,110,3.165]],["t/1222",[38,1.006,50,2.023,69,1.375,70,1.171,72,0.957,83,2.42,111,3.165,112,3.165]],["t/1286",[38,1.144,66,3.087,72,1.088,113,3.597,114,3.597,115,3.597]],["t/1342",[38,1.379,70,1.105,72,0.903,100,2.562,116,2.986,117,2.986,118,2.986,119,2.986]],["t/1374",[10,1.006,20,2.716,44,1.058,69,1.375,70,1.171,72,0.957,120,3.165,121,3.165]],["t/1404",[10,0.949,38,0.949,61,2.562,77,2.562,83,2.283,86,1.77,101,2.562,122,2.986,123,2.986]],["t/1437",[44,1.202,50,2.3,124,3.597,125,3.597,126,3.597,127,3.597]],["t/1463",[38,1.228,72,1.168,128,3.861,129,3.861,130,3.861]],["t/1528",[131,5.463]],["t/1541",[10,0.949,12,1.909,33,2.562,44,0.998,75,2.283,132,2.986,133,2.986,134,2.986,135,2.986]],["t/1580",[136,5.463]],["t/1584",[1,3.144,2,3.144,137,3.46]],["t/1588",[138,5.463]],["t/1590",[137,3.785,139,4.95]],["t/1596",[140,4.95,141,4.248]],["t/1601",[142,4.524,143,4.524,144,4.524]],["t/1609",[137,3.785,145,4.95]],["t/1615",[146,4.95,147,4.95]],["t/1629",[141,4.248,148,4.95]],["t/1641",[38,1.144,72,1.088,149,3.597,150,3.597,151,3.597,152,3.597]],["t/1690",[12,1.714,38,1.274,44,0.896,87,2.051,153,2.681,154,2.681,155,2.681,156,2.681,157,2.681,158,2.681]]],"invertedIndex":[["",{"_index":33,"t":{"210":{"position":[[9,1]]},"1541":{"position":[[68,2]]}}}],["16x16",{"_index":15,"t":{"81":{"position":[[18,5]]}}}],["adapt",{"_index":86,"t":{"678":{"position":[[47,10]]},"714":{"position":[[15,10]]},"781":{"position":[[0,8]]},"882":{"position":[[6,8]]},"929":{"position":[[6,7]]},"1404":{"position":[[26,10]]}}}],["agent",{"_index":125,"t":{"1437":{"position":[[20,6]]}}}],["algorithm",{"_index":131,"t":{"1528":{"position":[[12,10]]}}}],["alloc",{"_index":92,"t":{"781":{"position":[[16,10]]}}}],["answer",{"_index":60,"t":{"431":{"position":[[58,9]]}}}],["aprompt",{"_index":85,"t":{"678":{"position":[[0,8]]}}}],["attempt",{"_index":97,"t":{"974":{"position":[[0,8]]}}}],["attent",{"_index":47,"t":{"280":{"position":[[0,9]]},"678":{"position":[[9,9]]},"882":{"position":[[71,9]]},"974":{"position":[[51,11]]}}}],["augment",{"_index":37,"t":{"210":{"position":[[29,12]]}}}],["backjoon",{"_index":138,"t":{"1588":{"position":[[0,8]]}}}],["base",{"_index":39,"t":{"210":{"position":[[53,5]]},"518":{"position":[[63,5]]}}}],["better",{"_index":77,"t":{"584":{"position":[[44,6]]},"1404":{"position":[[6,6]]}}}],["bitfit",{"_index":67,"t":{"518":{"position":[[0,7]]}}}],["blog",{"_index":1,"t":{"2":{"position":[[5,4]]},"4":{"position":[[6,4]]},"8":{"position":[[4,4]]},"1584":{"position":[[9,4]]}}}],["budget",{"_index":91,"t":{"781":{"position":[[9,6]]}}}],["calcul",{"_index":81,"t":{"623":{"position":[[60,11]]}}}],["chain",{"_index":51,"t":{"379":{"position":[[0,5]]}}}],["chatgpt",{"_index":135,"t":{"1541":{"position":[[71,8]]}}}],["cheaper",{"_index":78,"t":{"584":{"position":[[55,7]]}}}],["classif",{"_index":152,"t":{"1641":{"position":[[39,14]]}}}],["code",{"_index":64,"t":{"480":{"position":[[14,4],[45,4]]}}}],["codet5",{"_index":62,"t":{"480":{"position":[[0,8]]}}}],["compar",{"_index":103,"t":{"1009":{"position":[[34,10]]}}}],["congratul",{"_index":136,"t":{"1580":{"position":[[0,16]]}}}],["context",{"_index":79,"t":{"584":{"position":[[71,7]]}}}],["continu",{"_index":115,"t":{"1286":{"position":[[26,10]]}}}],["creat",{"_index":137,"t":{"1584":{"position":[[0,6]]},"1590":{"position":[[0,6]]},"1609":{"position":[[0,6]]}}}],["data",{"_index":36,"t":{"210":{"position":[[24,4]]}}}],["decompos",{"_index":105,"t":{"1057":{"position":[[6,10]]}}}],["deploy",{"_index":140,"t":{"1596":{"position":[[0,6]]}}}],["dept",{"_index":104,"t":{"1057":{"position":[[0,5]]}}}],["discoveri",{"_index":30,"t":{"160":{"position":[[49,9]]}}}],["doc",{"_index":143,"t":{"1601":{"position":[[7,4]]}}}],["document",{"_index":139,"t":{"1590":{"position":[[9,8]]}}}],["effect",{"_index":118,"t":{"1342":{"position":[[28,9]]}}}],["effici",{"_index":70,"t":{"518":{"position":[[25,9]]},"584":{"position":[[19,9]]},"623":{"position":[[10,9]]},"653":{"position":[[10,9]]},"678":{"position":[[37,9]]},"781":{"position":[[41,9]]},"882":{"position":[[15,9]]},"929":{"position":[[28,9]]},"974":{"position":[[19,9]]},"1057":{"position":[[45,9]]},"1121":{"position":[[33,9]]},"1222":{"position":[[42,9]]},"1342":{"position":[[14,9]]},"1374":{"position":[[43,9]]}}}],["efficientnetv2",{"_index":8,"t":{"20":{"position":[[0,15]]}}}],["elicit",{"_index":53,"t":{"379":{"position":[[27,7]]}}}],["enabl",{"_index":112,"t":{"1222":{"position":[[24,7]]}}}],["esembl",{"_index":45,"t":{"216":{"position":[[41,7]]}}}],["expert",{"_index":46,"t":{"216":{"position":[[52,7]]}}}],["explor",{"_index":129,"t":{"1463":{"position":[[9,9]]}}}],["extrem",{"_index":130,"t":{"1463":{"position":[[23,7]]}}}],["faster",{"_index":11,"t":{"20":{"position":[[35,6]]}}}],["featur",{"_index":147,"t":{"1615":{"position":[[9,8]]}}}],["feedback",{"_index":134,"t":{"1541":{"position":[[59,8]]}}}],["few",{"_index":40,"t":{"210":{"position":[[59,3]]},"584":{"position":[[0,3]]}}}],["fine",{"_index":71,"t":{"518":{"position":[[35,4]]},"584":{"position":[[29,4]]},"781":{"position":[[51,4]]},"844":{"position":[[44,4]]},"882":{"position":[[25,4]]},"1009":{"position":[[48,4]]},"1057":{"position":[[55,4]]}}}],["finetun",{"_index":76,"t":{"534":{"position":[[20,9]]}}}],["first",{"_index":3,"t":{"4":{"position":[[0,5]]}}}],["follow",{"_index":132,"t":{"1541":{"position":[[28,6]]}}}],["framework",{"_index":121,"t":{"1374":{"position":[[19,9]]}}}],["frozen",{"_index":61,"t":{"431":{"position":[[73,6]]},"1404":{"position":[[13,6]]}}}],["gener",{"_index":66,"t":{"480":{"position":[[68,10]]},"1286":{"position":[[49,10]]}}}],["gpt",{"_index":106,"t":{"1088":{"position":[[0,3]]}}}],["gradient",{"_index":82,"t":{"623":{"position":[[76,9]]}}}],["guid",{"_index":35,"t":{"210":{"position":[[17,6]]}}}],["human",{"_index":133,"t":{"1541":{"position":[[53,5]]}}}],["imag",{"_index":13,"t":{"81":{"position":[[3,5],[48,5]]},"431":{"position":[[5,6]]}}}],["improv",{"_index":109,"t":{"1154":{"position":[[24,9]]}}}],["init",{"_index":95,"t":{"882":{"position":[[66,4]]}}}],["instanc",{"_index":27,"t":{"160":{"position":[[19,8]]}}}],["instruct",{"_index":75,"t":{"534":{"position":[[8,11]]},"929":{"position":[[45,11]]},"1541":{"position":[[35,12]]}}}],["interfac",{"_index":22,"t":{"121":{"position":[[19,9]]}}}],["intro",{"_index":7,"t":{"10":{"position":[[9,5]]}}}],["label",{"_index":34,"t":{"210":{"position":[[11,5]]}}}],["languag",{"_index":44,"t":{"216":{"position":[[18,8]]},"331":{"position":[[40,8]]},"379":{"position":[[54,8]]},"431":{"position":[[86,8]]},"480":{"position":[[25,8]]},"518":{"position":[[76,8]]},"534":{"position":[[30,8]]},"623":{"position":[[37,8]]},"678":{"position":[[73,8]]},"714":{"position":[[35,8]]},"844":{"position":[[20,8]]},"882":{"position":[[40,8]]},"1374":{"position":[[53,8]]},"1437":{"position":[[11,8]]},"1541":{"position":[[9,8]]},"1690":{"position":[[84,8]]}}}],["larg",{"_index":55,"t":{"379":{"position":[[48,5]]},"431":{"position":[[80,5]]},"480":{"position":[[19,5]]},"623":{"position":[[31,5]]},"714":{"position":[[29,5]]}}}],["learn",{"_index":50,"t":{"331":{"position":[[20,8]]},"584":{"position":[[79,8]]},"653":{"position":[[29,8]]},"1222":{"position":[[61,8]]},"1437":{"position":[[53,8]]}}}],["learner",{"_index":42,"t":{"210":{"position":[[68,8]]}}}],["llama",{"_index":94,"t":{"882":{"position":[[0,5]]},"929":{"position":[[0,5]]}}}],["long",{"_index":0,"t":{"2":{"position":[[0,4]]}}}],["lora",{"_index":88,"t":{"714":{"position":[[0,5]]}}}],["low",{"_index":89,"t":{"714":{"position":[[6,3]]}}}],["manag",{"_index":142,"t":{"1601":{"position":[[0,6]]}}}],["markdown",{"_index":146,"t":{"1615":{"position":[[0,8]]}}}],["mask",{"_index":73,"t":{"518":{"position":[[69,6]]}}}],["mdx",{"_index":5,"t":{"8":{"position":[[0,3]]}}}],["method",{"_index":156,"t":{"1690":{"position":[[65,7]]}}}],["mixtur",{"_index":100,"t":{"974":{"position":[[63,8]]},"1342":{"position":[[64,7]]}}}],["model",{"_index":10,"t":{"20":{"position":[[24,6]]},"216":{"position":[[27,5]]},"331":{"position":[[49,6]]},"379":{"position":[[63,6]]},"431":{"position":[[95,6]]},"480":{"position":[[34,6]]},"518":{"position":[[85,6]]},"534":{"position":[[39,6]]},"623":{"position":[[46,5]]},"678":{"position":[[82,6]]},"714":{"position":[[44,6]]},"844":{"position":[[29,6]]},"882":{"position":[[49,6]]},"929":{"position":[[57,5]]},"1374":{"position":[[62,5]]},"1404":{"position":[[20,5]]},"1541":{"position":[[18,6]]}}}],["multi",{"_index":98,"t":{"974":{"position":[[29,5]]}}}],["multitask",{"_index":111,"t":{"1222":{"position":[[0,9]]}}}],["natur",{"_index":157,"t":{"1690":{"position":[[76,7]]}}}],["need",{"_index":48,"t":{"280":{"position":[[21,4]]}}}],["nlp",{"_index":84,"t":{"653":{"position":[[42,3]]}}}],["object",{"_index":29,"t":{"160":{"position":[[42,6]]}}}],["open",{"_index":63,"t":{"480":{"position":[[9,4]]}}}],["optim",{"_index":114,"t":{"1286":{"position":[[15,10]]}}}],["p",{"_index":102,"t":{"1009":{"position":[[0,1]]}}}],["page",{"_index":145,"t":{"1609":{"position":[[9,4]]}}}],["paramet",{"_index":69,"t":{"518":{"position":[[15,9]]},"584":{"position":[[9,9]]},"623":{"position":[[0,9]]},"653":{"position":[[0,9]]},"781":{"position":[[31,9]]},"929":{"position":[[18,9]]},"974":{"position":[[9,9]]},"1057":{"position":[[35,9]]},"1121":{"position":[[23,9]]},"1222":{"position":[[32,9]]},"1374":{"position":[[33,9]]}}}],["percept",{"_index":28,"t":{"160":{"position":[[28,10]]}}}],["post",{"_index":2,"t":{"2":{"position":[[10,4]]},"4":{"position":[[11,4]]},"8":{"position":[[9,4]]},"1584":{"position":[[14,4]]}}}],["power",{"_index":107,"t":{"1121":{"position":[[4,5]]}}}],["pre",{"_index":87,"t":{"678":{"position":[[61,3]]},"844":{"position":[[8,3]]},"1690":{"position":[[0,3]]}}}],["predict",{"_index":153,"t":{"1690":{"position":[[23,8]]}}}],["prefix",{"_index":113,"t":{"1286":{"position":[[0,6]]}}}],["prismer",{"_index":43,"t":{"216":{"position":[[0,8]]}}}],["process",{"_index":158,"t":{"1690":{"position":[[93,10]]}}}],["prompt",{"_index":38,"t":{"210":{"position":[[46,6]]},"331":{"position":[[13,6]]},"379":{"position":[[17,9]]},"431":{"position":[[23,8]]},"678":{"position":[[19,6]]},"974":{"position":[[80,7]]},"1009":{"position":[[13,6]]},"1057":{"position":[[17,6]]},"1121":{"position":[[43,6]]},"1154":{"position":[[9,6],[34,6]]},"1222":{"position":[[10,6]]},"1286":{"position":[[37,7]]},"1342":{"position":[[38,6],[75,7]]},"1404":{"position":[[50,6]]},"1463":{"position":[[34,6]]},"1641":{"position":[[5,6]]},"1690":{"position":[[11,7],[55,9]]}}}],["promptda",{"_index":32,"t":{"210":{"position":[[0,8]]}}}],["prune",{"_index":93,"t":{"844":{"position":[[0,7]]}}}],["ptr",{"_index":149,"t":{"1641":{"position":[[0,4]]}}}],["question",{"_index":59,"t":{"431":{"position":[[49,8]]}}}],["rank",{"_index":90,"t":{"714":{"position":[[10,4]]}}}],["reason",{"_index":54,"t":{"379":{"position":[[35,9]]}}}],["recognit",{"_index":18,"t":{"81":{"position":[[54,11]]}}}],["reflexion",{"_index":124,"t":{"1437":{"position":[[0,10]]}}}],["reinforc",{"_index":127,"t":{"1437":{"position":[[39,13]]}}}],["reparameter",{"_index":110,"t":{"1154":{"position":[[62,18]]}}}],["residu",{"_index":108,"t":{"1154":{"position":[[0,8],[53,8]]}}}],["retriev",{"_index":31,"t":{"160":{"position":[[63,9]]}}}],["rule",{"_index":150,"t":{"1641":{"position":[[24,5]]}}}],["sacl",{"_index":19,"t":{"81":{"position":[[69,5]]}}}],["scale",{"_index":74,"t":{"534":{"position":[[0,7]]},"1009":{"position":[[79,6]]},"1121":{"position":[[13,5]]}}}],["sequenc",{"_index":21,"t":{"121":{"position":[[10,8]]}}}],["shot",{"_index":41,"t":{"210":{"position":[[63,4]]},"431":{"position":[[37,4]]},"584":{"position":[[4,4]]}}}],["simpl",{"_index":68,"t":{"518":{"position":[[8,6]]}}}],["site",{"_index":141,"t":{"1596":{"position":[[12,4]]},"1629":{"position":[[15,4]]}}}],["smaller",{"_index":9,"t":{"20":{"position":[[16,7]]}}}],["smop",{"_index":116,"t":{"1342":{"position":[[0,5]]}}}],["soft",{"_index":101,"t":{"974":{"position":[[75,4]]},"1404":{"position":[[45,4]]}}}],["spars",{"_index":119,"t":{"1342":{"position":[[57,6]]}}}],["spot",{"_index":122,"t":{"1404":{"position":[[0,5]]}}}],["survey",{"_index":155,"t":{"1690":{"position":[[45,6]]}}}],["systemat",{"_index":154,"t":{"1690":{"position":[[34,10]]}}}],["task",{"_index":24,"t":{"121":{"position":[[40,5]]},"974":{"position":[[35,4]]},"1009":{"position":[[90,5]]}}}],["text",{"_index":151,"t":{"1641":{"position":[[34,4]]}}}],["textual",{"_index":56,"t":{"431":{"position":[[15,7]]}}}],["thought",{"_index":52,"t":{"379":{"position":[[9,7]]}}}],["through",{"_index":123,"t":{"1404":{"position":[[37,7]]}}}],["toward",{"_index":117,"t":{"1342":{"position":[[6,7]]}}}],["train",{"_index":12,"t":{"20":{"position":[[42,8]]},"678":{"position":[[65,7]]},"844":{"position":[[12,7]]},"1541":{"position":[[0,8]]},"1690":{"position":[[4,6]]}}}],["transfer",{"_index":83,"t":{"653":{"position":[[20,8]]},"1222":{"position":[[52,8]]},"1404":{"position":[[57,8]]}}}],["transform",{"_index":17,"t":{"81":{"position":[[31,12]]},"518":{"position":[[51,11]]}}}],["translat",{"_index":148,"t":{"1629":{"position":[[0,9]]}}}],["tune",{"_index":72,"t":{"518":{"position":[[40,6]]},"584":{"position":[[34,6]]},"623":{"position":[[20,6]]},"678":{"position":[[26,6]]},"781":{"position":[[56,6]]},"844":{"position":[[49,6]]},"882":{"position":[[30,6]]},"974":{"position":[[40,6]]},"1009":{"position":[[2,6],[20,6],[53,6]]},"1057":{"position":[[24,6],[60,6]]},"1121":{"position":[[50,6]]},"1154":{"position":[[16,7],[41,6]]},"1222":{"position":[[17,6]]},"1286":{"position":[[7,7]]},"1342":{"position":[[45,6]]},"1374":{"position":[[68,6]]},"1463":{"position":[[41,6]]},"1641":{"position":[[12,6]]}}}],["tutori",{"_index":6,"t":{"10":{"position":[[0,8]]}}}],["understand",{"_index":65,"t":{"480":{"position":[[50,13]]},"1088":{"position":[[4,12]]}}}],["unifi",{"_index":20,"t":{"121":{"position":[[2,7]]},"1374":{"position":[[11,7]]}}}],["uninext",{"_index":25,"t":{"160":{"position":[[0,8]]}}}],["unipelt",{"_index":120,"t":{"1374":{"position":[[0,8]]}}}],["univers",{"_index":26,"t":{"160":{"position":[[9,9]]},"1009":{"position":[[60,11]]}}}],["unsupervis",{"_index":49,"t":{"331":{"position":[[0,12]]}}}],["v2",{"_index":96,"t":{"929":{"position":[[14,3]]},"1009":{"position":[[9,3]]}}}],["verbal",{"_index":126,"t":{"1437":{"position":[[32,6]]}}}],["version",{"_index":144,"t":{"1601":{"position":[[12,8]]}}}],["via",{"_index":99,"t":{"974":{"position":[[47,3]]}}}],["vision",{"_index":23,"t":{"121":{"position":[[33,6]]},"216":{"position":[[11,6]]},"331":{"position":[[33,6]]}}}],["visual",{"_index":58,"t":{"431":{"position":[[42,6]]},"929":{"position":[[38,6]]}}}],["welcom",{"_index":4,"t":{"6":{"position":[[0,7]]}}}],["without",{"_index":80,"t":{"623":{"position":[[52,7]]},"844":{"position":[[36,7]]}}}],["word",{"_index":16,"t":{"81":{"position":[[24,6]]}}}],["worth",{"_index":14,"t":{"81":{"position":[[12,5]]}}}],["xprompt",{"_index":128,"t":{"1463":{"position":[[0,8]]}}}],["zero",{"_index":57,"t":{"431":{"position":[[32,4]]},"882":{"position":[[61,4]]}}}]],"pipeline":["stemmer"]}},{"documents":[{"i":12,"t":"Getting Started","u":"/docs/intro","h":"#getting-started","p":10},{"i":14,"t":"What you'll need","u":"/docs/intro","h":"#what-youll-need","p":10},{"i":16,"t":"Generate a new site","u":"/docs/intro","h":"#generate-a-new-site","p":10},{"i":18,"t":"Start your site","u":"/docs/intro","h":"#start-your-site","p":10},{"i":22,"t":"개요","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":24,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":26,"t":"2. Related Work","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":28,"t":"3. EfficientNetV2 Architecture Design","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":29,"t":"Understanding Training Efficiency","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#understanding-training-efficiency","p":20},{"i":30,"t":"Training with very large image sizes is slow","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#training-with-very-large-image-sizes-is-slow","p":20},{"i":32,"t":"Depthwise convolutions are slow in early layers but effective in later stages","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#depthwise-convolutions-are-slow-in-early-layers-but-effective-in-later-stages","p":20},{"i":34,"t":"Equally scailing up every stage is sub-optimal","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#equally-scailing-up-every-stage-is-sub-optimal","p":20},{"i":36,"t":"Training-Aware NAS and Scailing","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#training-aware-nas-and-scailing","p":20},{"i":37,"t":"NAS Search","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#nas-search","p":20},{"i":39,"t":"EfficientNetV2 Architecture","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#efficientnetv2-architecture","p":20},{"i":41,"t":"EfficientNetV2 Scailing","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#efficientnetv2-scailing","p":20},{"i":43,"t":"Training Speed Comparison","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#training-speed-comparison","p":20},{"i":45,"t":"4. Progressive Learning","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":46,"t":"Motivation","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#motivation","p":20},{"i":48,"t":"Progressive Learning with adaptive Regularization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#progressive-learning-with-adaptive-regularization","p":20},{"i":50,"t":"5. Main Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":51,"t":"ImageNet ILSVRC2012","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#imagenet-ilsvrc2012","p":20},{"i":52,"t":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup","p":20},{"i":54,"t":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results","p":20},{"i":56,"t":"ImageNet21k","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#imagenet21k","p":20},{"i":57,"t":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup-1","p":20},{"i":59,"t":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results-1","p":20},{"i":61,"t":"Transfer Learning Datasets","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#transfer-learning-datasets","p":20},{"i":62,"t":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup-2","p":20},{"i":64,"t":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results-2","p":20},{"i":66,"t":"6. Ablation Studies","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":67,"t":"Comparison to EfficientNet","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#comparison-to-efficientnet","p":20},{"i":69,"t":"Performance with the same training","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#performance-with-the-same-training","p":20},{"i":70,"t":"Scailing Down","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#scailing-down","p":20},{"i":71,"t":"Progressive Learning for Different Networks","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#progressive-learning-for-different-networks","p":20},{"i":73,"t":"Importance of Adaptive Regularization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#importance-of-adaptive-regularization","p":20},{"i":75,"t":"7. Conclusion","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":77,"t":"Summarization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":79,"t":"Experiments","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":83,"t":"Abstract","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":85,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":87,"t":"2. Related Work","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":89,"t":"3. Method","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":90,"t":"3.1 Vision Transformer (ViT)","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#31-vision-transformer-vit","p":81},{"i":92,"t":"Intuctive bias","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#intuctive-bias","p":81},{"i":94,"t":"Hybris Architecture","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#hybris-architecture","p":81},{"i":96,"t":"3.2 fine-tuning and higher resolution","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#32-fine-tuning-and-higher-resolution","p":81},{"i":98,"t":"4. Experiments","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":100,"t":"4.1 Setup","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#41-setup","p":81},{"i":101,"t":"Datasets","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#datasets","p":81},{"i":103,"t":"Model Variants","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#model-variants","p":81},{"i":105,"t":"Training & Fine-tuning","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#training--fine-tuning","p":81},{"i":107,"t":"Metrics","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#metrics","p":81},{"i":109,"t":"4.2 Comparison to State Of The Art","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#42-comparison-to-state-of-the-art","p":81},{"i":111,"t":"4.3 Pre-trained Data Requirements","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#43-pre-trained-data-requirements","p":81},{"i":113,"t":"4.4 Scailing Study","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#44-scailing-study","p":81},{"i":115,"t":"4.5 Inspecting Vision Transformer","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#45-inspecting-vision-transformer","p":81},{"i":117,"t":"4.6 self-supervision","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#46-self-supervision","p":81},{"i":119,"t":"5. Conclusion","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#5-conclusion","p":81},{"i":123,"t":"Abstract","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":125,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":127,"t":"2. Approach","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":129,"t":"2.1 A unified interface with tokenization","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#21-a-unified-interface-with-tokenization","p":121},{"i":131,"t":"2.2 Unified architecture and objective function","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#22-unified-architecture-and-objective-function","p":121},{"i":133,"t":"2.3 Training","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#23-training","p":121},{"i":135,"t":"Data mixing","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#data-mixing","p":121},{"i":137,"t":"Batch mixing","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#batch-mixing","p":121},{"i":139,"t":"2.4 Inference and de-tokenization","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#24-inference-and-de-tokenization","p":121},{"i":141,"t":"3. Experiments","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":142,"t":"3.1 Experimental settings and implementation details","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#31-experimental-settings-and-implementation-details","p":121},{"i":144,"t":"Object detection","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#object-detection","p":121},{"i":146,"t":"Instance segmentation","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#instance-segmentation","p":121},{"i":148,"t":"Keypoint detection","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#keypoint-detection","p":121},{"i":150,"t":"Four-tasks joint training","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#four-tasks-joint-training","p":121},{"i":152,"t":"Baselines","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#baselines","p":121},{"i":154,"t":"3.2 Quantitative results","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#32-quantitative-results","p":121},{"i":156,"t":"3.3 Qualitative results","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#33-qualitative-results","p":121},{"i":158,"t":"5. Conclusion","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":162,"t":"Abstract","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":164,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":166,"t":"2. Related Work","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":167,"t":"3. Approch","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":169,"t":"3.1 Prompt Generation","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#31-prompt-generation","p":160},{"i":171,"t":"3.2 Image-Prompt Feature Fusion","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#32-image-prompt-feature-fusion","p":160},{"i":173,"t":"3.3 Object Discovery and Retrieval","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#33-object-discovery-and-retrieval","p":160},{"i":175,"t":"3.4 Training and Inference","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#34-training-and-inference","p":160},{"i":176,"t":"Training","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#training","p":160},{"i":178,"t":"Inference","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#inference","p":160},{"i":180,"t":"4. Experiments","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":181,"t":"4.1 Implementation Details","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#41-implementation-details","p":160},{"i":183,"t":"4.2 Evaluations on 10 Tasks","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#42-evaluations-on-10-tasks","p":160},{"i":184,"t":"Object Detection and Instance Segmentation","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#object-detection-and-instance-segmentation","p":160},{"i":186,"t":"REC and RES","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#rec-and-res","p":160},{"i":188,"t":"SOT","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#sot","p":160},{"i":190,"t":"VOS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#vos","p":160},{"i":192,"t":"MOT","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#mot","p":160},{"i":194,"t":"MOTS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#mots","p":160},{"i":196,"t":"VIS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#vis","p":160},{"i":198,"t":"R-VOS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#r-vos","p":160},{"i":200,"t":"4.3 Ablations and Other Analysis","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#43-ablations-and-other-analysis","p":160},{"i":202,"t":"Fusion","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#fusion","p":160},{"i":204,"t":"Queries","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#queries","p":160},{"i":206,"t":"Unification","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#unification","p":160},{"i":208,"t":"5. Conclusions","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":212,"t":"Abstract","u":"/docs/Paper/NLP/Augmentation/PromptDA","h":"","p":210},{"i":214,"t":"1. Introduction","u":"/docs/Paper/NLP/Augmentation/PromptDA","h":"","p":210},{"i":218,"t":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":220,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":222,"t":"2. Related Work","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":223,"t":"3. Prismer: Open-ended Reasoning with Multi-modal Knowledge","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":224,"t":"3.1 Model Overview","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#31-model-overview","p":216},{"i":226,"t":"3.2 Pre-trained Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#32-pre-trained-experts","p":216},{"i":228,"t":"3.3 Key Architectural Components","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#33-key-architectural-components","p":216},{"i":229,"t":"Modality-Specific Convolutional Stem","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#modality-specific-convolutional-stem","p":216},{"i":231,"t":"Experts Resampler","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#experts-resampler","p":216},{"i":233,"t":"Lightweight Adaptor","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#lightweight-adaptor","p":216},{"i":235,"t":"3.4 Training Objective","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#34-training-objective","p":216},{"i":237,"t":"4. Experiments","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":238,"t":"4.1 Prismer Model Variants","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#41-prismer-model-variants","p":216},{"i":240,"t":"4.2 Training and Evaluation Details","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#42-training-and-evaluation-details","p":216},{"i":241,"t":"Pre-training Datasets","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#pre-training-datasets","p":216},{"i":243,"t":"Optimisation and Implementation","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#optimisation-and-implementation","p":216},{"i":245,"t":"Evalution Setting","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#evalution-setting","p":216},{"i":247,"t":"4.3 Results on Vision-Language Benchmarks","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#43-results-on-vision-language-benchmarks","p":216},{"i":248,"t":"Fine-tuned Performance COCO Caption, NoCaps and VQAv2","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#fine-tuned-performance-coco-caption-nocaps-and-vqav2","p":216},{"i":250,"t":"Zero-shot Performance on Image Captioning","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#zero-shot-performance-on-image-captioning","p":216},{"i":252,"t":"Few-shot Performance on ImageNet Classification","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#few-shot-performance-on-imagenet-classification","p":216},{"i":254,"t":"5. Additional Analysis","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":256,"t":"5.1 Intriguing Properties of Prismer","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#51-intriguing-properties-of-prismer","p":216},{"i":257,"t":"More Experts, Better Performance","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#more-experts-better-performance","p":216},{"i":259,"t":"Better Experts, Better Performance","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#better-experts-better-performance","p":216},{"i":261,"t":"Robustness to Noisy Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#robustness-to-noisy-experts","p":216},{"i":263,"t":"5.2 Architecture Design and Training Details","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#52-architecture-design-and-training-details","p":216},{"i":264,"t":"Adaptor Design and Size","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#adaptor-design-and-size","p":216},{"i":266,"t":"Resampler Design and Multi-modal Sampling Strategy","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#resampler-design-and-multi-modal-sampling-strategy","p":216},{"i":268,"t":"The Effect of Frozen Backbones","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#the-effect-of-frozen-backbones","p":216},{"i":270,"t":"6. Conclusions, Limitations and Discussion","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":272,"t":"Multi-modal In-context Learning","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#multi-modal-in-context-learning","p":216},{"i":274,"t":"Zero-shot Adaptation on New Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#zero-shot-adaptation-on-new-experts","p":216},{"i":276,"t":"Free-form Inference on Partial Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#free-form-inference-on-partial-experts","p":216},{"i":278,"t":"Representation of Expert Knowledge","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#representation-of-expert-knowledge","p":216},{"i":282,"t":"Abstract","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":284,"t":"1. Introduction","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":286,"t":"2. Background","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":288,"t":"3. Model Architecture","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":290,"t":"3.1 Encoder and Decoder Stacks","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":291,"t":"Encoder","u":"/docs/Paper/NLP/Model/Transformer","h":"#encoder","p":280},{"i":293,"t":"Decoder","u":"/docs/Paper/NLP/Model/Transformer","h":"#decoder","p":280},{"i":295,"t":"3.2 Attention","u":"/docs/Paper/NLP/Model/Transformer","h":"#32-attention","p":280},{"i":297,"t":"3.2.1 Scaled Dot-Product Attention","u":"/docs/Paper/NLP/Model/Transformer","h":"#321-scaled-dot-product-attention","p":280},{"i":299,"t":"3.2.2 Multi-Head Attention","u":"/docs/Paper/NLP/Model/Transformer","h":"#322-multi-head-attention","p":280},{"i":301,"t":"3.2.3 Applications of Attention in our Model","u":"/docs/Paper/NLP/Model/Transformer","h":"#323-applications-of-attention-in-our-model","p":280},{"i":303,"t":"3.3 Position-wise Feed-Forward Networks","u":"/docs/Paper/NLP/Model/Transformer","h":"#33-position-wise-feed-forward-networks","p":280},{"i":305,"t":"3.4 Embedding and Softmax","u":"/docs/Paper/NLP/Model/Transformer","h":"#34-embedding-and-softmax","p":280},{"i":307,"t":"3.5 Positional Encoding","u":"/docs/Paper/NLP/Model/Transformer","h":"#35-positional-encoding","p":280},{"i":309,"t":"4. Why Self-Attention","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":311,"t":"5. Training","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":312,"t":"5.1 Training Data and Batching","u":"/docs/Paper/NLP/Model/Transformer","h":"#51-training-data-and-batching","p":280},{"i":314,"t":"5.2 Hardware and Schedule","u":"/docs/Paper/NLP/Model/Transformer","h":"#52-hardware-and-schedule","p":280},{"i":316,"t":"5.3 Optimizer","u":"/docs/Paper/NLP/Model/Transformer","h":"#53-optimizer","p":280},{"i":318,"t":"5.4 Regularization","u":"/docs/Paper/NLP/Model/Transformer","h":"#54-regularization","p":280},{"i":320,"t":"6. Results","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":321,"t":"6.1 Machine Translation","u":"/docs/Paper/NLP/Model/Transformer","h":"#61-machine-translation","p":280},{"i":323,"t":"6.2 Model Variations","u":"/docs/Paper/NLP/Model/Transformer","h":"#62-model-variations","p":280},{"i":325,"t":"6.3 English Constituency Parsing","u":"/docs/Paper/NLP/Model/Transformer","h":"#63-english-constituency-parsing","p":280},{"i":327,"t":"7. Conclusion","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":329,"t":"Appendix","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":333,"t":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":335,"t":"Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":337,"t":"Related Work","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":338,"t":"Vision-language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#vision-language-models","p":331},{"i":340,"t":"Prompt Learning","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-learning","p":331},{"i":342,"t":"Self-training","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#self-training","p":331},{"i":344,"t":"Method","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":346,"t":"Overview of UPL","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#overview-of-upl","p":331},{"i":348,"t":"Pseudo Label Generation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-generation","p":331},{"i":349,"t":"Inference of CLIP","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#inference-of-clip","p":331},{"i":351,"t":"Pseudo Label Generation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-generation-1","p":331},{"i":353,"t":"Pseudo Label Ensemble","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-ensemble","p":331},{"i":355,"t":"Prompt Representation Optimization","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-representation-optimization","p":331},{"i":357,"t":"Learnable Prompt Representation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#learnable-prompt-representation","p":331},{"i":359,"t":"Inference","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#inference","p":331},{"i":361,"t":"Prompt Representation Ensemble","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-representation-ensemble","p":331},{"i":363,"t":"Experiment","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":364,"t":"Implementation Details","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#implementation-details","p":331},{"i":365,"t":"Vision-language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#vision-language-models-1","p":331},{"i":367,"t":"Pseudo Label Generation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-generation-2","p":331},{"i":369,"t":"Learnable Prompt Representation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#learnable-prompt-representation-1","p":331},{"i":371,"t":"Training Details","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#training-details","p":331},{"i":373,"t":"Dataset","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#dataset","p":331},{"i":375,"t":"Main Results","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":377,"t":"Conclusion","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":381,"t":"Abstract","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":383,"t":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":385,"t":"2. Chain-of-Thought Prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":387,"t":"3. Arithmetic Reasoning","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":389,"t":"3.1. Experimental Steup","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#31-experimental-steup","p":379},{"i":390,"t":"Benchmarks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#benchmarks","p":379},{"i":392,"t":"Standard prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#standard-prompting","p":379},{"i":394,"t":"Chain-of-thought prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#chain-of-thought-prompting","p":379},{"i":396,"t":"Language models","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#language-models","p":379},{"i":398,"t":"3.2. Results","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#32-results","p":379},{"i":400,"t":"3.3. Ablation Study","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#33-ablation-study","p":379},{"i":402,"t":"Equation only","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#equation-only","p":379},{"i":404,"t":"Variable compute only","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#variable-compute-only","p":379},{"i":406,"t":"Chain of thought after answer","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#chain-of-thought-after-answer","p":379},{"i":408,"t":"3.4. Robustness of Chain of Thought","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#34-robustness-of-chain-of-thought","p":379},{"i":410,"t":"4. Commonsense Reasoning","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":411,"t":"Benchmarks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#benchmarks-1","p":379},{"i":413,"t":"Prompts","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#prompts","p":379},{"i":415,"t":"Results","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#results","p":379},{"i":417,"t":"5. Symbolic Reasoning","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":419,"t":"Tasks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#tasks","p":379},{"i":421,"t":"Last letter concatenation","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#last-letter-concatenation","p":379},{"i":423,"t":"Coin flip","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#coin-flip","p":379},{"i":425,"t":"6. Discussion","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":427,"t":"7. Related Work","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":429,"t":"8. Conclusions","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":433,"t":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":435,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":437,"t":"2. Related Work","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":438,"t":"2.1 Recent Advances in VQA Method","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#21-recent-advances-in-vqa-method","p":431},{"i":440,"t":"2.2 LLM for Zero/Few-Shot VQA Tasks","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#22-llm-for-zerofew-shot-vqa-tasks","p":431},{"i":442,"t":"Multi-modal pretraining","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#multi-modal-pretraining","p":431},{"i":444,"t":"Language-mediated VQA","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#language-mediated-vqa","p":431},{"i":446,"t":"3. Method","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":448,"t":"3.1 Answer Extraction","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#31-answer-extraction","p":431},{"i":450,"t":"3.2 Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#32-question-generation","p":431},{"i":452,"t":"Template-based Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#template-based-question-generation","p":431},{"i":454,"t":"Neural Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#neural-question-generation","p":431},{"i":456,"t":"3.3 Question-relevant Caption Prompt","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#33-question-relevant-caption-prompt","p":431},{"i":458,"t":"3.4 Prompt Design","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#34-prompt-design","p":431},{"i":460,"t":"4. Experiment","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":462,"t":"4.1 Enviroment Setup","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#41-enviroment-setup","p":431},{"i":463,"t":"Datasets","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#datasets","p":431},{"i":465,"t":"Implementation details","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#implementation-details","p":431},{"i":467,"t":"Competing methods","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#competing-methods","p":431},{"i":469,"t":"4.2 Main Results","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#42-main-results","p":431},{"i":470,"t":"SOTA results on zero-shot evaluation with plug-in frozen LLMs","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#sota-results-on-zero-shot-evaluation-with-plug-in-frozen-llms","p":431},{"i":472,"t":"Scaling effect of LLMs and their emergent capabilities on VQA","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#scaling-effect-of-llms-and-their-emergent-capabilities-on-vqa","p":431},{"i":474,"t":"Competitive performance with end-to-end pretraining and few-shot methods","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#competitive-performance-with-end-to-end-pretraining-and-few-shot-methods","p":431},{"i":476,"t":"4.3 Experimental Results of Different LLMs","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#43-experimental-results-of-different-llms","p":431},{"i":478,"t":"5. Limitation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":482,"t":"Abstract","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":480},{"i":484,"t":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":480},{"i":486,"t":"2. Related Work","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":480},{"i":487,"t":"3. CodeT5+: Open Code Large Language Models","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":480},{"i":489,"t":"3.1. Unimodal Pretraining on Code Data","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#31-unimodal-pretraining-on-code-data","p":480},{"i":491,"t":"Span Denoising","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#span-denoising","p":480},{"i":493,"t":"Causal Language Modeling (CLM)","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#causal-language-modeling-clm","p":480},{"i":495,"t":"3.2. Bimodal Pretraining on Text-code Data","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#32-bimodal-pretraining-on-text-code-data","p":480},{"i":497,"t":"Text-Code Contrastive Learning","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-contrastive-learning","p":480},{"i":499,"t":"Text-Code Matching","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-matching","p":480},{"i":501,"t":"Text-Code Causal LM","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-causal-lm","p":480},{"i":503,"t":"3.3. Compute-efficient Pretraining with Frozen Off-the-shelf LLMs","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#33-compute-efficient-pretraining-with-frozen-off-the-shelf-llms","p":480},{"i":505,"t":"3.4. Adaptation to Downstream Understanding and Generation Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#34-adaptation-to-downstream-understanding-and-generation-tasks","p":480},{"i":507,"t":"Seq2Seq Generation Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#seq2seq-generation-tasks","p":480},{"i":509,"t":"Decoder-only Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#decoder-only-tasks","p":480},{"i":511,"t":"Understanding Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#understanding-tasks","p":480},{"i":513,"t":"4. Pretraining and Instruction Tuning","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":480},{"i":514,"t":"4.1. Pretraining Dataset","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#41-pretraining-dataset","p":480},{"i":516,"t":"4.2. Pretraining Setup","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#42-pretraining-setup","p":480},{"i":520,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":522,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":524,"t":"2. Background: fine-tuning and parameter-efficient fine-tuning","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":526,"t":"3. Bias-terms Fine-tuning (BitFit)","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":528,"t":"4. Experiments and Results","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":530,"t":"5. Related Work","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":532,"t":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":536,"t":"Abstract","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":538,"t":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":540,"t":"2. Flan Finetuning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":542,"t":"2.1. Finetuning Data","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#21-finetuning-data","p":534},{"i":543,"t":"Task mixtures.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#task-mixtures","p":534},{"i":545,"t":"Chain-of-thought finetuning mixture.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#chain-of-thought-finetuning-mixture","p":534},{"i":547,"t":"Templates and formatting.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#templates-and-formatting","p":534},{"i":549,"t":"2.2. Finetuning procedure","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#22-finetuning-procedure","p":534},{"i":551,"t":"2.3. Evaluation Protocol","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#23-evaluation-protocol","p":534},{"i":552,"t":"Evaluation benchmarks.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#evaluation-benchmarks","p":534},{"i":554,"t":"Evaluation mathods and metrics.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#evaluation-mathods-and-metrics","p":534},{"i":556,"t":"3. Scaling to 540B parameters and 1.8K tasks","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":558,"t":"4. Finetuning with chain-of-thought annotations","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":560,"t":"4.1. Finetuning on chain-of-thought improves reasoning on held-out tasks","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#41-finetuning-on-chain-of-thought-improves-reasoning-on-held-out-tasks","p":534},{"i":562,"t":"4.2. Some chain-of-thought data is needed to maintain reasoning ability","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#42-some-chain-of-thought-data-is-needed-to-maintain-reasoning-ability","p":534},{"i":564,"t":"4.3. Unlocking zero-shot reasoning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#43-unlocking-zero-shot-reasoning","p":534},{"i":566,"t":"5. Putting it all together","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":568,"t":"6. Usability evaluation of open-ended generation","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":570,"t":"7. Discussion","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":572,"t":"Scaling curves for instruction finetuning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#scaling-curves-for-instruction-finetuning","p":534},{"i":574,"t":"CoT finetuning is critical for reasoning abilities","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#cot-finetuning-is-critical-for-reasoning-abilities","p":534},{"i":576,"t":"Instruction finetuning generalizes across models","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-generalizes-across-models","p":534},{"i":578,"t":"Instruction finetuning improves usability and mitigates some potential harms","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-improves-usability-and-mitigates-some-potential-harms","p":534},{"i":580,"t":"Instruction finetuning is relatively compute-efficient","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-is-relatively-compute-efficient","p":534},{"i":582,"t":"9. Conclusions","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":586,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":588,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":590,"t":"2. Background","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":591,"t":"3. Designing the T-Few Recipe","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":593,"t":"3.1 Model and Datasets","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#31-model-and-datasets","p":584},{"i":595,"t":"3.2 Unlikelihood Training and Length Normalization","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#32-unlikelihood-training-and-length-normalization","p":584},{"i":597,"t":"3.3 Parameter-efficient fine-tuning with (IA)3(IA)^3(IA)3","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#33-parameter-efficient-fine-tuning-with-ia3","p":584},{"i":599,"t":"3.4 Pre-training (IA)3(IA)^3(IA)3","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#34-pre-training-ia3","p":584},{"i":601,"t":"3.5 Combining the ingredients","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#35-combining-the-ingredients","p":584},{"i":603,"t":"4. Outperforming ICL with T-Few","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":605,"t":"4.1 Performance on T0 tasks","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#41-performance-on-t0-tasks","p":584},{"i":607,"t":"4.2 Comparing computational costs","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#42-comparing-computational-costs","p":584},{"i":609,"t":"Inference cost","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#inference-cost","p":584},{"i":611,"t":"Training cost","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#training-cost","p":584},{"i":613,"t":"Storage cost","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#storage-cost","p":584},{"i":615,"t":"Memory usage","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#memory-usage","p":584},{"i":617,"t":"4.3 Performance on Real-world Few-shot Tasks (RAFT)","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#43-performance-on-real-world-few-shot-tasks-raft","p":584},{"i":619,"t":"4.4 Ablation experiments","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#44-ablation-experiments","p":584},{"i":621,"t":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":625,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":627,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":629,"t":"2. Method","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":631,"t":"3. Experiments","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":632,"t":"3.1 Experimental Settings","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#31-experimental-settings","p":623},{"i":634,"t":"Prefix tuning Plug-in","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#prefix-tuning-plug-in","p":623},{"i":636,"t":"3.2 Main Results","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#32-main-results","p":623},{"i":637,"t":"3.2.1 Experiments on GPT-2 Series of Models","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#321-experiments-on-gpt-2-series-of-models","p":623},{"i":639,"t":"3.2.2 Experiments on T5 Series of Models","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#322-experiments-on-t5-series-of-models","p":623},{"i":641,"t":"3.2.3 Importance of the Reduction Factor rrr","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#323-importance-of-the-reduction-factor-r","p":623},{"i":643,"t":"3.2.4 Memory Usage","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#324-memory-usage","p":623},{"i":645,"t":"3.3 Utilize Bridge Model Directly?","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#33-utilize-bridge-model-directly","p":623},{"i":647,"t":"4. Related Work","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":649,"t":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":651,"t":"Limitations","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":655,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"","p":653},{"i":657,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"","p":653},{"i":659,"t":"2. Adapter tuning for NLP","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"","p":653},{"i":661,"t":"2.1 Instantiation for Transformer Networks","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#21-instantiation-for-transformer-networks","p":653},{"i":663,"t":"3. Experiments","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"","p":653},{"i":665,"t":"3.1 Experiments Settings","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#31-experiments-settings","p":653},{"i":667,"t":"3.2 GLUE benchmark","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#32-glue-benchmark","p":653},{"i":669,"t":"3.3 Additional Classification Tasks","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#33-additional-classification-tasks","p":653},{"i":671,"t":"3.4 Parameter/Performance trade-off","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#34-parameterperformance-trade-off","p":653},{"i":673,"t":"3.5 SQuAD Extractive Question Answering","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#35-squad-extractive-question-answering","p":653},{"i":675,"t":"3.6 Analysis and Discussion","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#36-analysis-and-discussion","p":653},{"i":677,"t":"4. Related Work","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"","p":653},{"i":680,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":682,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":684,"t":"3. Prompt Tuning Revisit","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":685,"t":"3.1 Preliminary","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#31-preliminary","p":678},{"i":687,"t":"3.2 Connection with Key-Value Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#32-connection-with-key-value-prompts","p":678},{"i":689,"t":"3.3 Empirical Study","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#33-empirical-study","p":678},{"i":691,"t":"4. Attention Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":693,"t":"4.1 Input Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#41-input-prompts","p":678},{"i":695,"t":"4.2 Attention Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#42-attention-prompts","p":678},{"i":697,"t":"4.3 Task-specific Head","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#43-task-specific-head","p":678},{"i":699,"t":"5. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":700,"t":"5.1 Datasets","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#51-datasets","p":678},{"i":702,"t":"5.2 Baselines","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#52-baselines","p":678},{"i":704,"t":"5.3 Implementation Details","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#53-implementation-details","p":678},{"i":706,"t":"5.4 Main Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#54-main-results","p":678},{"i":708,"t":"6. Analysis and Discussion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":710,"t":"7. Conclusions","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":712,"t":"Limitations","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":716,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":718,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":720,"t":"Terminologies and Conventions","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#terminologies-and-conventions","p":714},{"i":722,"t":"2. Problem Statement","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":724,"t":"3. Aren't Existing Solutions Good Enough?","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":726,"t":"Adapter Layer Introduce Inference Latency","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#adapter-layer-introduce-inference-latency","p":714},{"i":728,"t":"Directly Optimizing the Prompt is Hard","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#directly-optimizing-the-prompt-is-hard","p":714},{"i":730,"t":"4. Out Method","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":732,"t":"4.1 Low-Rank-Parameterized Update Matrices","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#41-low-rank-parameterized-update-matrices","p":714},{"i":734,"t":"A Generalization of Full Fine-tuning","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#a-generalization-of-full-fine-tuning","p":714},{"i":736,"t":"No Additional Inference Latency","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#no-additional-inference-latency","p":714},{"i":738,"t":"4.2 Applying LoRA to Transformer","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#42-applying-lora-to-transformer","p":714},{"i":740,"t":"Practical Benefits and Limitations","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#practical-benefits-and-limitations","p":714},{"i":742,"t":"5. Empirical Experiments","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":744,"t":"5.1 Baselines","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#51-baselines","p":714},{"i":746,"t":"Fine-Tuning (FT)","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#fine-tuning-ft","p":714},{"i":748,"t":"Bias-only or BitFit","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#bias-only-or-bitfit","p":714},{"i":750,"t":"Prefix-embedding tuning (PreEmbed)","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#prefix-embedding-tuning-preembed","p":714},{"i":752,"t":"Prefix-layer tuning (PreLayer)","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#prefix-layer-tuning-prelayer","p":714},{"i":754,"t":"Adapter tuning","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#adapter-tuning","p":714},{"i":756,"t":"LoRA","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#lora","p":714},{"i":758,"t":"5.2 RoBERTa Base/Large","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#52-roberta-baselarge","p":714},{"i":760,"t":"5.3 DeBERTa XXL","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#53-deberta-xxl","p":714},{"i":762,"t":"5.4 GPT-2 Medium/Large","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#54-gpt-2-mediumlarge","p":714},{"i":764,"t":"5.5 Scaling up to GPT-3 175B","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#55-scaling-up-to-gpt-3-175b","p":714},{"i":766,"t":"6. Related Works","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":767,"t":"7. Understanding the Low-Rank Updates","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":769,"t":"7.1 Which Weight Matrices in Transformer Should We Apply LoRA To?","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#71-which-weight-matrices-in-transformer-should-we-apply-lora-to","p":714},{"i":771,"t":"7.2 What is the Optimal Rank rrr For LoRA?","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#72-what-is-the-optimal-rank-r-for-lora","p":714},{"i":773,"t":"Subspace similarity between different rrr","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#subspace-similarity-between-different-r","p":714},{"i":775,"t":"Subspace similarity between different random seeds","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#subspace-similarity-between-different-random-seeds","p":714},{"i":777,"t":"7.3 How Does the Adaptation Matrix △W\\triangle W△W Compare To WWW?","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#73-how-does-the-adaptation-matrix-triangle-w-compare-to-w","p":714},{"i":779,"t":"8. Conclusion And Future Work","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":783,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":785,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":787,"t":"2. Background","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":788,"t":"Transformer-based Models","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#transformer-based-models","p":781},{"i":790,"t":"Low Rank Adaptation","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#low-rank-adaptation","p":781},{"i":792,"t":"3. AdaLoRA Method","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":794,"t":"3.1 SVD-Based Adaptation","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#31-svd-based-adaptation","p":781},{"i":796,"t":"3.2 Importance-Aware Rank Allocation","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#32-importance-aware-rank-allocation","p":781},{"i":798,"t":"Magnitude of singular values","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#magnitude-of-singular-values","p":781},{"i":800,"t":"Sensitivity-based importance","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#sensitivity-based-importance","p":781},{"i":802,"t":"3.3 Global Budget Scheduler","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#33-global-budget-scheduler","p":781},{"i":804,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":806,"t":"Implementation Details","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#implementation-details","p":781},{"i":808,"t":"Baselines","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#baselines","p":781},{"i":810,"t":"4.1 Natural Language Understanding","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#41-natural-language-understanding","p":781},{"i":811,"t":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#models-and-datasets","p":781},{"i":813,"t":"Implementation Details","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#implementation-details-1","p":781},{"i":815,"t":"Main results","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#main-results","p":781},{"i":817,"t":"4.2 Question Answering","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#42-question-answering","p":781},{"i":818,"t":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#models-and-datasets-1","p":781},{"i":820,"t":"Implementation Details","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#implementation-details-2","p":781},{"i":822,"t":"Main Results","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#main-results-1","p":781},{"i":824,"t":"4.3 Nautral Language Generation","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#43-nautral-language-generation","p":781},{"i":825,"t":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#models-and-datasets-2","p":781},{"i":827,"t":"Implementation Details","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#implementation-details-3","p":781},{"i":829,"t":"Main Results","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#main-results-2","p":781},{"i":831,"t":"4.4 Analysis","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#44-analysis","p":781},{"i":832,"t":"Different budget levels","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#different-budget-levels","p":781},{"i":834,"t":"Comparison to low-rank parameterization","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#comparison-to-low-rank-parameterization","p":781},{"i":836,"t":"Variants of the importance score","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#variants-of-the-importance-score","p":781},{"i":838,"t":"The role of two components","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#the-role-of-two-components","p":781},{"i":840,"t":"The resulting budget distribution","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#the-resulting-budget-distribution","p":781},{"i":842,"t":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":846,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":848,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":850,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":852,"t":"3. Background","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":854,"t":"4. Static Model Pruning","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":856,"t":"4.1 Masking Function","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#41-masking-function","p":844},{"i":858,"t":"4.2 Task-Specific Head","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#42-task-specific-head","p":844},{"i":860,"t":"4.3 Training Objective","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#43-training-objective","p":844},{"i":862,"t":"5. Experiments","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":863,"t":"5.1 Datasets","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#51-datasets","p":844},{"i":865,"t":"5.2 Experiments Setups","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#52-experiments-setups","p":844},{"i":867,"t":"5.3 Baseline","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#53-baseline","p":844},{"i":869,"t":"5.4 Experiments Results","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#54-experiments-results","p":844},{"i":871,"t":"6. Analysis","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":872,"t":"6.1 Masking Function","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#61-masking-function","p":844},{"i":874,"t":"6.2 Task-Specific Head","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#62-task-specific-head","p":844},{"i":876,"t":"6.3 Training Objective","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#63-training-objective","p":844},{"i":878,"t":"7. Conclusion","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":880,"t":"8. Limitation","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":884,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":886,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":888,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":889,"t":"3. LLaMA-Adapter","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":890,"t":"3.1 Learnable Adaptation Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":892,"t":"3.2 Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#32-zero-initialized-attention","p":882},{"i":894,"t":"3.3 Multi-modal Reasoning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#33-multi-modal-reasoning","p":882},{"i":896,"t":"3.4 Zero-initialized Attention for other Large Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#34-zero-initialized-attention-for-other-large-models","p":882},{"i":898,"t":"Vision Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#vision-models","p":882},{"i":900,"t":"Language Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#language-models","p":882},{"i":902,"t":"4. Experiment","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":903,"t":"4.1 Instruction-following Evaluation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#41-instruction-following-evaluation","p":882},{"i":904,"t":"Settings","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#settings","p":882},{"i":906,"t":"Performance","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#performance","p":882},{"i":908,"t":"Efficiency","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#efficiency","p":882},{"i":910,"t":"4.2 Multi-modal Evaluation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#42-multi-modal-evaluation","p":882},{"i":911,"t":"Settings","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#settings-1","p":882},{"i":913,"t":"Performance","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#performance-1","p":882},{"i":915,"t":"4.3 Ablation Study","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#43-ablation-study","p":882},{"i":916,"t":"Insertion Layers","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#insertion-layers","p":882},{"i":918,"t":"Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#zero-initialized-attention","p":882},{"i":920,"t":"Robustness to Over-fitting","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#robustness-to-over-fitting","p":882},{"i":922,"t":"4.4 Zero-initialized Attention for other Large Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#44-zero-initialized-attention-for-other-large-models","p":882},{"i":923,"t":"Settings","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#settings-2","p":882},{"i":925,"t":"Performance","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#performance-2","p":882},{"i":927,"t":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":931,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":933,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":935,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":936,"t":"3. A Revisit of LLaMA-Adapter","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":937,"t":"Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#zero-initialized-attention","p":929},{"i":939,"t":"Simple Multi-modal Variant","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#simple-multi-modal-variant","p":929},{"i":941,"t":"Open-ended Multi-modal Reasoning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#open-ended-multi-modal-reasoning","p":929},{"i":943,"t":"4. LLaMA-Adapter V2","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":944,"t":"4.1 Bias Tuning of Linear Layers","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#41-bias-tuning-of-linear-layers","p":929},{"i":946,"t":"Discussion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#discussion","p":929},{"i":948,"t":"4.2 Joint Training with Disjoint Parameters","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#42-joint-training-with-disjoint-parameters","p":929},{"i":950,"t":"Discussion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#discussion-1","p":929},{"i":952,"t":"4.3 Early Fusion of Visual Knowledge","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#43-early-fusion-of-visual-knowledge","p":929},{"i":954,"t":"4.4 Integration with Experts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#44-integration-with-experts","p":929},{"i":956,"t":"5. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":957,"t":"5.1 Experimental Setups","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#51-experimental-setups","p":929},{"i":958,"t":"Training Data","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#training-data","p":929},{"i":960,"t":"Implementation Details","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#implementation-details","p":929},{"i":962,"t":"5.2 Stronger Language Instruction Model","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#52-stronger-language-instruction-model","p":929},{"i":964,"t":"5.3 Visual Instruction Model","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#53-visual-instruction-model","p":929},{"i":966,"t":"Image Captioning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#image-captioning","p":929},{"i":968,"t":"Visual Understanding","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#visual-understanding","p":929},{"i":970,"t":"Integration with Experts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#integration-with-experts","p":929},{"i":972,"t":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":976,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":978,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":980,"t":"2. Background and Problem Setup","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":981,"t":"3. Method","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":983,"t":"3.1 Source Prompt Pre-training","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#31-source-prompt-pre-training","p":974},{"i":985,"t":"3.2 Target Prompt Training","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#32-target-prompt-training","p":974},{"i":987,"t":"3.2.1 Input-prompt Attentions","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#321-input-prompt-attentions","p":974},{"i":989,"t":"3.2.2 Prompt Interpolation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#322-prompt-interpolation","p":974},{"i":991,"t":"3.3 Multi-task Training and Inference","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#33-multi-task-training-and-inference","p":974},{"i":993,"t":"3.4  Parameter Efficiency of ATTEMPT","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#34--parameter-efficiency-of-attempt","p":974},{"i":995,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":996,"t":"4.1 Source and Target Tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#41-source-and-target-tasks","p":974},{"i":998,"t":"4.2 Baselines and Implementation Details","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#42-baselines-and-implementation-details","p":974},{"i":1000,"t":"5. Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":1001,"t":"5.1 Main Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#51-main-results","p":974},{"i":1003,"t":"5.2 Few-shot Domain Adaptations","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#52-few-shot-domain-adaptations","p":974},{"i":1005,"t":"5.3 Analyses","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#53-analyses","p":974},{"i":1007,"t":"7. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":1011,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1013,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1015,"t":"2. Preliminaries","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1016,"t":"NLU Tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#nlu-tasks","p":1009},{"i":1018,"t":"Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#prompt-tuning","p":1009},{"i":1020,"t":"3. P-Tuning v2","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1021,"t":"3.1 Lack of Universality","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#31-lack-of-universality","p":1009},{"i":1023,"t":"Lack of universality across scales","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#lack-of-universality-across-scales","p":1009},{"i":1025,"t":"Lack of universality across tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#lack-of-universality-across-tasks","p":1009},{"i":1027,"t":"3.2 Deep Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#32-deep-prompt-tuning","p":1009},{"i":1029,"t":"3.3 Optimization and Implementation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#33-optimization-and-implementation","p":1009},{"i":1030,"t":"Reparameterization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#reparameterization","p":1009},{"i":1032,"t":"Prompt Length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#prompt-length","p":1009},{"i":1034,"t":"Multi-task Learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#multi-task-learning","p":1009},{"i":1036,"t":"Classification Head","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#classification-head","p":1009},{"i":1038,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1040,"t":"NLU Tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#nlu-tasks-1","p":1009},{"i":1042,"t":"Pre-trained Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#pre-trained-models","p":1009},{"i":1044,"t":"Multitask Learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#multitask-learning","p":1009},{"i":1046,"t":"4.1 P-tuning v2: Across Scales","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#41-p-tuning-v2-across-scales","p":1009},{"i":1048,"t":"4.2 P-tuning v2: Across Tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#42-p-tuning-v2-across-tasks","p":1009},{"i":1050,"t":"4.3 Ablation Study","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#43-ablation-study","p":1009},{"i":1051,"t":"Verbalizer with LM head v.s. [CLS] label with linear head","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#verbalizer-with-lm-head-vs-cls-label-with-linear-head","p":1009},{"i":1053,"t":"Prompt depth","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#prompt-depth","p":1009},{"i":1055,"t":"5. Conclusions","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1059,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"","p":1057},{"i":1061,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"","p":1057},{"i":1063,"t":"2. Method","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"","p":1057},{"i":1064,"t":"2.1 Background: Prompt Tuning (PT)","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#21-background-prompt-tuning-pt","p":1057},{"i":1066,"t":"2.2 Our Approach: Decomposed Prompt Tuning (DePT)","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#22-our-approach-decomposed-prompt-tuning-dept","p":1057},{"i":1068,"t":"3. Experiments And Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"","p":1057},{"i":1069,"t":"3.1 Experimental Setup","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#31-experimental-setup","p":1057},{"i":1071,"t":"3.2 Main Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#32-main-results","p":1057},{"i":1072,"t":"3.2.1 Performance on GLUE and SuperGLUE benchmarks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#321-performance-on-glue-and-superglue-benchmarks","p":1057},{"i":1074,"t":"3.2.2 Performance on MRQA 2019 Shared Task and other NLP datasets","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#322-performance-on-mrqa-2019-shared-task-and-other-nlp-datasets","p":1057},{"i":1076,"t":"3.3.3 Performance on Vision-Language tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#333-performance-on-vision-language-tasks","p":1057},{"i":1078,"t":"3.3 Time and Memory Efficiency","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#33-time-and-memory-efficiency","p":1057},{"i":1079,"t":"3.3.1 DePT improves and memory efficiency up to more than 20%","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#331-dept-improves-and-memory-efficiency-up-to-more-than-20","p":1057},{"i":1081,"t":"3.3.2 DePT grows more efficient as the model size increases","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#332-dept-grows-more-efficient-as-the-model-size-increases","p":1057},{"i":1083,"t":"3.4 Further Analysis","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#34-further-analysis","p":1057},{"i":1085,"t":"4. Related Works","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"","p":1057},{"i":1086,"t":"5. Epilogue","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"","p":1057},{"i":1090,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1092,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1094,"t":"2. Motivation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1096,"t":"3. Method: P-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1098,"t":"3.1 Architecture","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#31-architecture","p":1088},{"i":1100,"t":"3.2 Optimization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#32-optimization","p":1088},{"i":1102,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1104,"t":"4.1 Knowledge Probing","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#41-knowledge-probing","p":1088},{"i":1106,"t":"4.1.1 Datasets And Formulation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#411-datasets-and-formulation","p":1088},{"i":1108,"t":"4.1.2 Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#412-results","p":1088},{"i":1110,"t":"4.2 SuperGLUE","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#42-superglue","p":1088},{"i":1112,"t":"4.2.1 Fully-Supervised Learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#421-fully-supervised-learning","p":1088},{"i":1114,"t":"4.2.2 Few-Shot Learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#422-few-shot-learning","p":1088},{"i":1116,"t":"4.2.3 Finetuning v.s. MP Finetuning v.s. P-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#423-finetuning-vs-mp-finetuning-vs-p-tuning","p":1088},{"i":1118,"t":"5. Related Work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1119,"t":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1123,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1125,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1127,"t":"2. Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1129,"t":"2.1 Design Decisions","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#21-design-decisions","p":1121},{"i":1131,"t":"2.2 Unlearning Span Corruption","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#22-unlearning-span-corruption","p":1121},{"i":1133,"t":"3. Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1135,"t":"3.1 Closing the Gap","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#31-closing-the-gap","p":1121},{"i":1137,"t":"3.2 Ablation Study","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#32-ablation-study","p":1121},{"i":1138,"t":"Prompt Length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#prompt-length","p":1121},{"i":1140,"t":"Prompt Initialization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#prompt-initialization","p":1121},{"i":1142,"t":"Pre-training Objective","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#pre-training-objective","p":1121},{"i":1144,"t":"4. Comparison to Similar Approaches","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1146,"t":"5. Resilience to Domain Shift","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1148,"t":"6. Prompt Ensembling","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1150,"t":"7. Interpretability","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1152,"t":"8. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1156,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1158,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1160,"t":"2. Background","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1161,"t":"Fine-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#fine-tuning","p":1154},{"i":1163,"t":"Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#prompt-tuning","p":1154},{"i":1165,"t":"3 Method","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1166,"t":"3.1 RESIDUAL PROMPT TUNING","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#31-residual-prompt-tuning","p":1154},{"i":1168,"t":"3.2 Design choices","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#32-design-choices","p":1154},{"i":1169,"t":"Residual connection","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#residual-connection","p":1154},{"i":1171,"t":"Depth and width of MLP","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#depth-and-width-of-mlp","p":1154},{"i":1173,"t":"Non-linearity and normalization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#non-linearity-and-normalization","p":1154},{"i":1175,"t":"Parameter sharing","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#parameter-sharing","p":1154},{"i":1177,"t":"3.3 Training and Inference","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#33-training-and-inference","p":1154},{"i":1179,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1180,"t":"4.1 Datasets","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#41-datasets","p":1154},{"i":1182,"t":"4.2 Architectures","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#42-architectures","p":1154},{"i":1184,"t":"BERT","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#bert","p":1154},{"i":1186,"t":"T5","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#t5","p":1154},{"i":1188,"t":"4.3 Baselines","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#43-baselines","p":1154},{"i":1190,"t":"4.4 Experimental setup","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#44-experimental-setup","p":1154},{"i":1192,"t":"5. Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1193,"t":"5.1 Main Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#51-main-results","p":1154},{"i":1194,"t":"5.1.1 Comparison with prompt tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#511-comparison-with-prompt-tuning","p":1154},{"i":1196,"t":"5.1.2 Other parameter-efficient methods","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#512-other-parameter-efficient-methods","p":1154},{"i":1198,"t":"5.2 Robustness to the choice of learning rate","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#52-robustness-to-the-choice-of-learning-rate","p":1154},{"i":1200,"t":"5.3 Robustness to the prompt initialization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#53-robustness-to-the-prompt-initialization","p":1154},{"i":1202,"t":"5.4 Prompt tuning in few-shot setting","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#54-prompt-tuning-in-few-shot-setting","p":1154},{"i":1204,"t":"5.5 Performance and prompt length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#55-performance-and-prompt-length","p":1154},{"i":1206,"t":"5.6 Ablation studies","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#56-ablation-studies","p":1154},{"i":1207,"t":"Parameter sharing.","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#parameter-sharing-1","p":1154},{"i":1209,"t":"Overparameterization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#overparameterization","p":1154},{"i":1211,"t":"7. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1213,"t":"Limitations","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#limitations","p":1154},{"i":1215,"t":"Appendix","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1216,"t":"A. Implementation and Training","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#a-implementation-and-training","p":1154},{"i":1217,"t":"A.6 Parameter-efficiency of RESIDUAL PROMPT TUNING","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#a6-parameter-efficiency-of-residual-prompt-tuning","p":1154},{"i":1219,"t":"B. Performance on SuperGLUE","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#b-performance-on-superglue","p":1154},{"i":1220,"t":"B.2. Covergence of different prompt tuning approaches","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#b2-covergence-of-different-prompt-tuning-approaches","p":1154},{"i":1224,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1226,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1228,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1229,"t":"Parameter-efficient transfer learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#parameter-efficient-transfer-learning","p":1222},{"i":1231,"t":"Multitask learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#multitask-learning","p":1222},{"i":1233,"t":"Knowledge distillation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#knowledge-distillation","p":1222},{"i":1235,"t":"3. Approach","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1237,"t":"Prompt tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#prompt-tuning","p":1222},{"i":1239,"t":"3.1 Multitask prompt tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#31-multitask-prompt-tuning","p":1222},{"i":1241,"t":"Prompt decomposition","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#prompt-decomposition","p":1222},{"i":1243,"t":"Prompt distillation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#prompt-distillation","p":1222},{"i":1245,"t":"3.2 Source Training And Target Adaptation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#32-source-training-and-target-adaptation","p":1222},{"i":1247,"t":"Parameter-efficiency","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#parameter-efficiency","p":1222},{"i":1249,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1251,"t":"4.1 Experiemtal Setup","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#41-experiemtal-setup","p":1222},{"i":1252,"t":"Datasets and tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#datasets-and-tasks","p":1222},{"i":1254,"t":"Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#models","p":1222},{"i":1256,"t":"Baseline","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#baseline","p":1222},{"i":1258,"t":"Implementation details","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#implementation-details","p":1222},{"i":1260,"t":"4.2 Results and Analysis","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#42-results-and-analysis","p":1222},{"i":1261,"t":"Full-dataset adaptation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#full-dataset-adaptation","p":1222},{"i":1263,"t":"Few-shot adaptation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#few-shot-adaptation","p":1222},{"i":1265,"t":"Natural language generation tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#natural-language-generation-tasks","p":1222},{"i":1267,"t":"Model scaling","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#model-scaling","p":1222},{"i":1269,"t":"Analyzing prompt metrices","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#analyzing-prompt-metrices","p":1222},{"i":1271,"t":"4.3 Ablation studies","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#43-ablation-studies","p":1222},{"i":1272,"t":"Prompt decomposition and distillation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#prompt-decomposition-and-distillation","p":1222},{"i":1274,"t":"Distillation objective","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#distillation-objective","p":1222},{"i":1276,"t":"Prompt length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#prompt-length","p":1222},{"i":1278,"t":"Target adaptation strategy","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#target-adaptation-strategy","p":1222},{"i":1280,"t":"Stochastic task sampling","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#stochastic-task-sampling","p":1222},{"i":1282,"t":"Number of source tasks for pretraining","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#number-of-source-tasks-for-pretraining","p":1222},{"i":1284,"t":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1288,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1290,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1292,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1293,"t":"3. Problem Statement","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1295,"t":"3.1 Autoregressive LM","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#31-autoregressive-lm","p":1286},{"i":1297,"t":"3.2 Encoder-Decoder Archirecture","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#32-encoder-decoder-archirecture","p":1286},{"i":1299,"t":"3.3 Fine-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#33-fine-tuning","p":1286},{"i":1301,"t":"4. Prefix-Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1302,"t":"4.1 Intuition","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#41-intuition","p":1286},{"i":1304,"t":"4.2 Method","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#42-method","p":1286},{"i":1306,"t":"4.3 Parameterization of PθP_{\\theta}Pθ​","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#43-parameterization-of-p_theta","p":1286},{"i":1308,"t":"5. Experimental Setup","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1309,"t":"5.1 Datasets and Metrics","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#51-datasets-and-metrics","p":1286},{"i":1311,"t":"5.2 Methods","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#52-methods","p":1286},{"i":1313,"t":"5.3 Architectures and Hyperparameters","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#53-architectures-and-hyperparameters","p":1286},{"i":1315,"t":"6. Main Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1316,"t":"6.1 Table-to-text Generation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#61-table-to-text-generation","p":1286},{"i":1318,"t":"6.2 Summarization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#62-summarization","p":1286},{"i":1320,"t":"6.3 Low-data Setting","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#63-low-data-setting","p":1286},{"i":1322,"t":"6.4 Extrapolation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#64-extrapolation","p":1286},{"i":1324,"t":"7. Intrinsic Evaluation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1325,"t":"7.1 Prefix Length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#71-prefix-length","p":1286},{"i":1327,"t":"7.2 Full vs Embedding-only","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#72-full-vs-embedding-only","p":1286},{"i":1329,"t":"7.3 Prefix-tuning vs Infix-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#73-prefix-tuning-vs-infix-tuning","p":1286},{"i":1331,"t":"7.4 Initialization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#74-initialization","p":1286},{"i":1333,"t":"7.5 Data Efficiency","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#75-data-efficiency","p":1286},{"i":1335,"t":"8. Discussion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1336,"t":"Personalization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#personalization","p":1286},{"i":1338,"t":"Batching across users.","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#batching-across-users","p":1286},{"i":1340,"t":"Inductive bias of prefix-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#inductive-bias-of-prefix-tuning","p":1286},{"i":1344,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1346,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1348,"t":"2. Method","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1349,"t":"2.1 Preliminaries","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#21-preliminaries","p":1342},{"i":1351,"t":"2.2 SMoP: Sparse Mixture-of-Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#22-smop-sparse-mixture-of-prompts","p":1342},{"i":1353,"t":"2.3 Router Perturbation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#23-router-perturbation","p":1342},{"i":1355,"t":"3 Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1356,"t":"3.1 Experimental Settings","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#31-experimental-settings","p":1342},{"i":1358,"t":"3.2 Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#32-results","p":1342},{"i":1359,"t":"3.2.1 Main Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#321-main-results","p":1342},{"i":1361,"t":"3.2.2 Length and Number of Soft Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#322-length-and-number-of-soft-prompts","p":1342},{"i":1363,"t":"3.2.3 Routing Methods","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#323-routing-methods","p":1342},{"i":1365,"t":"4. Related Work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1366,"t":"4.1 Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#41-prompt-tuning","p":1342},{"i":1368,"t":"4.2 Mixture-of-Experts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#42-mixture-of-experts","p":1342},{"i":1370,"t":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1372,"t":"Limitations","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1376,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1378,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1380,"t":"2. Preliminaries","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1381,"t":"2.1 PELT Methods without Additional Parameters","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#21-pelt-methods-without-additional-parameters","p":1374},{"i":1383,"t":"2.2 PELT Methods with Additional Parameters","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#22-pelt-methods-with-additional-parameters","p":1374},{"i":1385,"t":"3. Unifying PELT Methods","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1386,"t":"3.1 Task Formulation","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#31-task-formulation","p":1374},{"i":1388,"t":"3.2 Proposed Method","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#32-proposed-method","p":1374},{"i":1390,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1392,"t":"4.1 Experiment Setup","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#41-experiment-setup","p":1374},{"i":1394,"t":"4.2 Analysis of Individual PELT Methods","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#42-analysis-of-individual-pelt-methods","p":1374},{"i":1396,"t":"4.3 Analysis of UniPELT","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#43-analysis-of-unipelt","p":1374},{"i":1398,"t":"4.4 Efficiency of PELT Methods","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#44-efficiency-of-pelt-methods","p":1374},{"i":1400,"t":"5. Related Work","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1402,"t":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1406,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1408,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1410,"t":"2. Improving Prompt Tuning with SPoT","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1412,"t":"2.1 Experimental setup","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#21-experimental-setup","p":1404},{"i":1414,"t":"2.1.1 Baselines","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#211-baselines","p":1404},{"i":1416,"t":"2.1.2 Evaluation datasets","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#212-evaluation-datasets","p":1404},{"i":1418,"t":"2.1.3 Data for source prompt tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#213-data-for-source-prompt-tuning","p":1404},{"i":1420,"t":"2.1.4 Training details","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#214-training-details","p":1404},{"i":1422,"t":"2.2 Effect of SPoT","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#22-effect-of-spot","p":1404},{"i":1424,"t":"3. Predicting task transferability","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1426,"t":"3.1 Measuring transferability","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#31-measuring-transferability","p":1404},{"i":1428,"t":"3.2 Defining task similarity through prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#32-defining-task-similarity-through-prompts","p":1404},{"i":1430,"t":"3.3 Predicting transferability via simiarity","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#33-predicting-transferability-via-simiarity","p":1404},{"i":1432,"t":"4. Related Work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1433,"t":"5. Limitations & Future work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1435,"t":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1439,"t":"Abstract","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1441,"t":"1 Introduction","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1443,"t":"2 Related work","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1444,"t":"3 Reflexion: reinforcement via verbal reflection","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1446,"t":"Actor","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#actor","p":1437},{"i":1448,"t":"Evaluator","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#evaluator","p":1437},{"i":1450,"t":"Self-reflection","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#self-reflection","p":1437},{"i":1452,"t":"Memory","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#memory","p":1437},{"i":1454,"t":"The Reflexion process","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#the-reflexion-process","p":1437},{"i":1456,"t":"4 Experiments","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1457,"t":"4.1 Sequential decision making: ALFWorld","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#41-sequential-decision-making-alfworld","p":1437},{"i":1458,"t":"4.2 Reasoning: HotpotQA","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#42-reasoning-hotpotqa","p":1437},{"i":1459,"t":"4.3 Programming","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#43-programming","p":1437},{"i":1460,"t":"Ablation study","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#ablation-study","p":1437},{"i":1461,"t":"5 Limitations","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1465,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1467,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1469,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1470,"t":"2.1 Pre-trained Language Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#21-pre-trained-language-models","p":1463},{"i":1472,"t":"2.2 Prompt Learning in NLP","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#22-prompt-learning-in-nlp","p":1463},{"i":1474,"t":"2.3 Lottery Ticket Hypothesis","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#23-lottery-ticket-hypothesis","p":1463},{"i":1476,"t":"3. Preliminary","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1478,"t":"4. XPrompt","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1480,"t":"4.1 Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#41-prompt-tuning","p":1463},{"i":1482,"t":"4.2 Hierarchical Structured Pruning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#42-hierarchical-structured-pruning","p":1463},{"i":1484,"t":"4.2.1 Token-level Pruning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#421-token-level-pruning","p":1463},{"i":1486,"t":"4.2.2 Piece-level Pruning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#422-piece-level-pruning","p":1463},{"i":1488,"t":"4.3 Rewinding","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#43-rewinding","p":1463},{"i":1490,"t":"5. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1491,"t":"5.1 Datasets","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#51-datasets","p":1463},{"i":1493,"t":"5.2 Baselines","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#52-baselines","p":1463},{"i":1495,"t":"5.3 Implementation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#53-implementation","p":1463},{"i":1497,"t":"6. Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1498,"t":"6.1 Results on High-resource Scenarios","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#61-results-on-high-resource-scenarios","p":1463},{"i":1500,"t":"6.2 Results on Low-resource Scenarios","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#62-results-on-low-resource-scenarios","p":1463},{"i":1502,"t":"7. Analysis and Discussion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1504,"t":"7.1 Do Positive Prompts and Negative Prompts Exist?","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#71-do-positive-prompts-and-negative-prompts-exist","p":1463},{"i":1506,"t":"7.2 Parameter Efficiency","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#72-parameter-efficiency","p":1463},{"i":1508,"t":"7.3 Granularity of Pruning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#73-granularity-of-pruning","p":1463},{"i":1510,"t":"7.4 Prompt Length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#74-prompt-length","p":1463},{"i":1512,"t":"7.5 Prompt Initialization and Transfer","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#75-prompt-initialization-and-transfer","p":1463},{"i":1514,"t":"8. Conclusions","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1516,"t":"Limitations","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1518,"t":"Appendix","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1519,"t":"A. More Results of P-TuningV2","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#a-more-results-of-p-tuningv2","p":1463},{"i":1520,"t":"B. Token and Piece Importance Score","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#b-token-and-piece-importance-score","p":1463},{"i":1522,"t":"C. XPrompt Transfer","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#c-xprompt-transfer","p":1463},{"i":1524,"t":"D. Importance Scores Visualization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#d-importance-scores-visualization","p":1463},{"i":1526,"t":"E. SuperGLUE Statistics, Metrics and Soft Prompt Templates","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#e-superglue-statistics-metrics-and-soft-prompt-templates","p":1463},{"i":1530,"t":"Time Complexity","u":"/docs/Programming/Algorithm/","h":"","p":1528},{"i":1532,"t":"Space Complexity","u":"/docs/Programming/Algorithm/","h":"","p":1528},{"i":1534,"t":"Algorithm","u":"/docs/Programming/Algorithm/","h":"","p":1528},{"i":1535,"t":"Array & List","u":"/docs/Programming/Algorithm/","h":"#array--list","p":1528},{"i":1537,"t":"구간 합","u":"/docs/Programming/Algorithm/","h":"#구간-합","p":1528},{"i":1539,"t":"투 포인터","u":"/docs/Programming/Algorithm/","h":"#투-포인터","p":1528},{"i":1543,"t":"Abstract","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1545,"t":"1. Introduction","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1547,"t":"2. Related Work","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1548,"t":"3. Methods and experimental details","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1549,"t":"3.1 High-level methodology","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#31-high-level-methodology","p":1541},{"i":1551,"t":"3.2 Dataset","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#32-dataset","p":1541},{"i":1553,"t":"3.3 Task","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#33-task","p":1541},{"i":1555,"t":"3.4 Human data collection","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#34-human-data-collection","p":1541},{"i":1557,"t":"3.5 Models","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#35-models","p":1541},{"i":1559,"t":"3.6 Evaluation","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#36-evaluation","p":1541},{"i":1561,"t":"4. Result","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1562,"t":"4.1 Results on the API distribution","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#41-results-on-the-api-distribution","p":1541},{"i":1564,"t":"4.2 Results on public NLP datasets","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#42-results-on-public-nlp-datasets","p":1541},{"i":1566,"t":"4.3 Qualitative results","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#43-qualitative-results","p":1541},{"i":1568,"t":"5. Discussion","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1569,"t":"5.1 Implications for alignment research","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#51-implications-for-alignment-research","p":1541},{"i":1571,"t":"5.2 Who are we aligning to?","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#52-who-are-we-aligning-to","p":1541},{"i":1572,"t":"5.3 Limitations","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#53-limitations","p":1541},{"i":1574,"t":"ChatGPT","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1576,"t":"Method","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#method","p":1541},{"i":1578,"t":"Limitations","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#limitations","p":1541},{"i":1582,"t":"What's next?","u":"/docs/tutorial-basics/congratulations","h":"#whats-next","p":1580},{"i":1586,"t":"Create your first Post","u":"/docs/tutorial-basics/create-a-blog-post","h":"#create-your-first-post","p":1584},{"i":1592,"t":"Create your first Doc","u":"/docs/tutorial-basics/create-a-document","h":"#create-your-first-doc","p":1590},{"i":1594,"t":"Configure the Sidebar","u":"/docs/tutorial-basics/create-a-document","h":"#configure-the-sidebar","p":1590},{"i":1598,"t":"Build your site","u":"/docs/tutorial-basics/deploy-your-site","h":"#build-your-site","p":1596},{"i":1603,"t":"Create a docs version","u":"/docs/tutorial-extras/manage-docs-versions","h":"#create-a-docs-version","p":1601},{"i":1605,"t":"Add a Version Dropdown","u":"/docs/tutorial-extras/manage-docs-versions","h":"#add-a-version-dropdown","p":1601},{"i":1607,"t":"Update an existing version","u":"/docs/tutorial-extras/manage-docs-versions","h":"#update-an-existing-version","p":1601},{"i":1611,"t":"Create your first React Page","u":"/docs/tutorial-basics/create-a-page","h":"#create-your-first-react-page","p":1609},{"i":1613,"t":"Create your first Markdown Page","u":"/docs/tutorial-basics/create-a-page","h":"#create-your-first-markdown-page","p":1609},{"i":1617,"t":"Front Matter","u":"/docs/tutorial-basics/markdown-features","h":"#front-matter","p":1615},{"i":1619,"t":"Links","u":"/docs/tutorial-basics/markdown-features","h":"#links","p":1615},{"i":1621,"t":"Images","u":"/docs/tutorial-basics/markdown-features","h":"#images","p":1615},{"i":1623,"t":"Code Blocks","u":"/docs/tutorial-basics/markdown-features","h":"#code-blocks","p":1615},{"i":1625,"t":"Admonitions","u":"/docs/tutorial-basics/markdown-features","h":"#admonitions","p":1615},{"i":1627,"t":"MDX and React Components","u":"/docs/tutorial-basics/markdown-features","h":"#mdx-and-react-components","p":1615},{"i":1631,"t":"Configure i18n","u":"/docs/tutorial-extras/translate-your-site","h":"#configure-i18n","p":1629},{"i":1633,"t":"Translate a doc","u":"/docs/tutorial-extras/translate-your-site","h":"#translate-a-doc","p":1629},{"i":1635,"t":"Start your localized site","u":"/docs/tutorial-extras/translate-your-site","h":"#start-your-localized-site","p":1629},{"i":1637,"t":"Add a Locale Dropdown","u":"/docs/tutorial-extras/translate-your-site","h":"#add-a-locale-dropdown","p":1629},{"i":1639,"t":"Build your localized site","u":"/docs/tutorial-extras/translate-your-site","h":"#build-your-localized-site","p":1629},{"i":1643,"t":"Abstract","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1645,"t":"1. Introduction","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1647,"t":"2. Preliminaries","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1648,"t":"3. Prompt tuning with rules (PTR)","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1650,"t":"3.1 Overall framework of PTR","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#31-overall-framework-of-ptr","p":1641},{"i":1652,"t":"3.2 Task decomposition","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#32-task-decomposition","p":1641},{"i":1654,"t":"3.3 Sub-prompts for conditional functions","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#33-sub-prompts-for-conditional-functions","p":1641},{"i":1656,"t":"3.4 Composing sub-prompts for tasks","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#34-composing-sub-prompts-for-tasks","p":1641},{"i":1658,"t":"3.5 Sub-prompts with multiple label words","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#35-sub-prompts-with-multiple-label-words","p":1641},{"i":1660,"t":"4. Experiments","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1661,"t":"4.1 The results on relation classification","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#41-the-results-on-relation-classification","p":1641},{"i":1662,"t":"Datasets","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#datasets","p":1641},{"i":1664,"t":"Baselines and implementation details","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#baselines-and-implementation-details","p":1641},{"i":1666,"t":"Comparison between PTR and fine-tuning","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#comparison-between-ptr-and-fine-tuning","p":1641},{"i":1668,"t":"Comparison between PTR and prompt tuning","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#comparison-between-ptr-and-prompt-tuning","p":1641},{"i":1670,"t":"4.2 The results on entity typing","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#42-the-results-on-entity-typing","p":1641},{"i":1671,"t":"Dataset","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#dataset","p":1641},{"i":1673,"t":"Baselines and implementation details","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#baselines-and-implementation-details-1","p":1641},{"i":1675,"t":"Comparison between PTR and baselines","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#comparison-between-ptr-and-baselines","p":1641},{"i":1677,"t":"4.3 The results on intent classification","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#43-the-results-on-intent-classification","p":1641},{"i":1679,"t":"Dataset","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#dataset-1","p":1641},{"i":1681,"t":"Baselines and implementation details","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#baselines-and-implementation-details-2","p":1641},{"i":1683,"t":"Comparison between PTR and baselines","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#comparison-between-ptr-and-baselines-1","p":1641},{"i":1685,"t":"4.4 The convergence of PTR","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#44-the-convergence-of-ptr","p":1641},{"i":1687,"t":"5. Related work","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1688,"t":"6. Conclusion","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1692,"t":"Abstract","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1694,"t":"1. Two Sea Changes in Natural Language Processing","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1696,"t":"2 A Formal Description of Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1697,"t":"2.1 Supervised Learning in NLP","u":"/docs/Paper/NLP/Survey/Prompting","h":"#21-supervised-learning-in-nlp","p":1690},{"i":1699,"t":"2.2 Prompting Basics","u":"/docs/Paper/NLP/Survey/Prompting","h":"#22-prompting-basics","p":1690},{"i":1701,"t":"2.2.1 Prompt Addition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#221-prompt-addition","p":1690},{"i":1703,"t":"2.2.2 Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#222-answer-search","p":1690},{"i":1705,"t":"2.2.3 Answer Mapping","u":"/docs/Paper/NLP/Survey/Prompting","h":"#223-answer-mapping","p":1690},{"i":1707,"t":"2.3 Design Considerations for Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#23-design-considerations-for-prompting","p":1690},{"i":1709,"t":"3 Prompt Template Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1711,"t":"3.1 Prompt Shape","u":"/docs/Paper/NLP/Survey/Prompting","h":"#31-prompt-shape","p":1690},{"i":1713,"t":"3.2 Manual Template Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#32-manual-template-engineering","p":1690},{"i":1715,"t":"3.3 Automated Template Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#33-automated-template-learning","p":1690},{"i":1717,"t":"3.3.1 Discrete Prompt","u":"/docs/Paper/NLP/Survey/Prompting","h":"#331-discrete-prompt","p":1690},{"i":1719,"t":"3.3.2 Continuous Prompt","u":"/docs/Paper/NLP/Survey/Prompting","h":"#332-continuous-prompt","p":1690},{"i":1721,"t":"4 Prompt Answer Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1723,"t":"4.1 Answer Shape","u":"/docs/Paper/NLP/Survey/Prompting","h":"#41-answer-shape","p":1690},{"i":1725,"t":"4.2 Answer Space Design Method","u":"/docs/Paper/NLP/Survey/Prompting","h":"#42-answer-space-design-method","p":1690},{"i":1727,"t":"4.2.1 Manual Design","u":"/docs/Paper/NLP/Survey/Prompting","h":"#421-manual-design","p":1690},{"i":1729,"t":"4.2.2 Discrete Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#422-discrete-answer-search","p":1690},{"i":1731,"t":"4.2.3 Continuous Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#423-continuous-answer-search","p":1690},{"i":1733,"t":"5 Multi-Prompt Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1735,"t":"5.1 Prompt Ensembling","u":"/docs/Paper/NLP/Survey/Prompting","h":"#51-prompt-ensembling","p":1690},{"i":1737,"t":"5.2 Prompt Augmentation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#52-prompt-augmentation","p":1690},{"i":1739,"t":"5.3 Prompt Composition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#53-prompt-composition","p":1690},{"i":1741,"t":"5.4 Prompt Decomposition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#54-prompt-decomposition","p":1690},{"i":1743,"t":"6 Training Strategies for Prompting Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1745,"t":"6.1 Training Settings","u":"/docs/Paper/NLP/Survey/Prompting","h":"#61-training-settings","p":1690},{"i":1747,"t":"6.2 Parameter Update Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"#62-parameter-update-methods","p":1690},{"i":1749,"t":"6.2.1 Promptless Fine-tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#621-promptless-fine-tuning","p":1690},{"i":1751,"t":"6.2.2 Tuning-free Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#622-tuning-free-prompting","p":1690},{"i":1753,"t":"6.2.3 Fixed-LM Prompt Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#623-fixed-lm-prompt-tuning","p":1690},{"i":1755,"t":"6.2.4 Fixed-Prompt LM Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#624-fixed-prompt-lm-tuning","p":1690},{"i":1757,"t":"6.2.5 Prompt+LM Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#625-promptlm-tuning","p":1690},{"i":1759,"t":"7 Applications","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1761,"t":"7.1 Knowledge Probing","u":"/docs/Paper/NLP/Survey/Prompting","h":"#71-knowledge-probing","p":1690},{"i":1763,"t":"7.2 Structure Prediction","u":"/docs/Paper/NLP/Survey/Prompting","h":"#72-structure-prediction","p":1690},{"i":1765,"t":"7.3 Classification-based Tasks","u":"/docs/Paper/NLP/Survey/Prompting","h":"#73-classification-based-tasks","p":1690},{"i":1767,"t":"7.4 Information Extraction","u":"/docs/Paper/NLP/Survey/Prompting","h":"#74-information-extraction","p":1690},{"i":1769,"t":"7.5 \"Reasoning\" in NLP","u":"/docs/Paper/NLP/Survey/Prompting","h":"#75-reasoning-in-nlp","p":1690},{"i":1771,"t":"7.6 Question Answering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#76-question-answering","p":1690},{"i":1773,"t":"7.7  Text Generation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#77--text-generation","p":1690},{"i":1775,"t":"7.8 Automatic Evaluation of Text Generation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#78-automatic-evaluation-of-text-generation","p":1690},{"i":1777,"t":"7.9 Meta-Applications","u":"/docs/Paper/NLP/Survey/Prompting","h":"#79-meta-applications","p":1690},{"i":1779,"t":"7.10 Multi-modal Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#710-multi-modal-learning","p":1690},{"i":1781,"t":"8 Prompt-Relevant Topics","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1783,"t":"9 Challenges","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1785,"t":"9.1 Selection of Pre-trained LMs","u":"/docs/Paper/NLP/Survey/Prompting","h":"#91-selection-of-pre-trained-lms","p":1690},{"i":1787,"t":"9.2 Prompt Design","u":"/docs/Paper/NLP/Survey/Prompting","h":"#92-prompt-design","p":1690},{"i":1789,"t":"9.3 Prompt Answer Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#93-prompt-answer-engineering","p":1690},{"i":1791,"t":"9.4 Selection of Tuning Strategy","u":"/docs/Paper/NLP/Survey/Prompting","h":"#94-selection-of-tuning-strategy","p":1690},{"i":1793,"t":"9.5 Multiple Prompt Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#95-multiple-prompt-learning","p":1690},{"i":1795,"t":"9.6 Theoretical and Empirical Analysis of Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#96-theoretical-and-empirical-analysis-of-prompting","p":1690},{"i":1797,"t":"9.7 Transferability of Prompts","u":"/docs/Paper/NLP/Survey/Prompting","h":"#97-transferability-of-prompts","p":1690},{"i":1799,"t":"9.8 Combination of Different Paradigms","u":"/docs/Paper/NLP/Survey/Prompting","h":"#98-combination-of-different-paradigms","p":1690},{"i":1801,"t":"9.9 Calibration of Prompting Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"#99-calibration-of-prompting-methods","p":1690}],"index":{"version":"2.3.9","fields":["t"],"fieldVectors":[["t/12",[0,7.404,1,6.426]],["t/14",[2,7.404,3,6.814]],["t/16",[4,3.886,5,5.88,6,5.095]],["t/18",[1,6.426,6,5.904]],["t/22",[7,6.79]],["t/24",[8,3.687,9,3.687]],["t/26",[10,3.156,11,3.455,12,3.421]],["t/28",[13,2.798,14,4.877,15,3.914,16,3.761]],["t/29",[17,4.928,18,3.105,19,3.941]],["t/30",[18,2.2,20,4.527,21,3.752,22,3.61,23,3.929,24,4.167]],["t/32",[24,3.489,25,3.791,26,3.489,27,3.489,28,3.023,29,3.142,30,3.791,31,3.489]],["t/34",[31,4.167,32,4.527,33,3.61,34,3.929,35,3.752,36,3.391]],["t/36",[18,2.731,33,4.481,37,5.171,38,5.171]],["t/37",[38,6.814,39,6.136]],["t/39",[14,6.426,15,5.157]],["t/41",[14,6.426,33,5.904]],["t/43",[18,3.105,40,6.389,41,4.45]],["t/45",[42,3.237,43,5.545,44,3.784]],["t/46",[45,8.101]],["t/48",[43,4.877,44,3.328,46,3.371,47,4.877]],["t/50",[48,3.265,49,4.2,50,2.989]],["t/51",[51,6.814,52,7.404]],["t/52",[53,5.597]],["t/54",[50,4.118]],["t/56",[54,8.802]],["t/57",[53,5.597]],["t/59",[50,4.118]],["t/61",[44,3.784,55,4.661,56,3.566]],["t/62",[53,5.597]],["t/64",[50,4.118]],["t/66",[57,3.886,58,4.45,59,4.45]],["t/67",[41,5.157,60,7.404]],["t/69",[18,3.105,61,3.941,62,6.389]],["t/70",[33,5.904,63,7.404]],["t/71",[43,4.877,44,3.328,64,4.209,65,4.877]],["t/73",[46,3.834,47,5.545,66,4.786]],["t/75",[67,4.867,68,3.964]],["t/77",[69,8.101]],["t/79",[70,4.498]],["t/83",[71,4.421]],["t/85",[8,3.687,9,3.687]],["t/87",[10,3.156,11,3.455,12,3.421]],["t/89",[13,3.687,72,3.926]],["t/90",[73,3.039,74,4.209,75,4.334,76,5.619]],["t/92",[77,7.404,78,5.904]],["t/94",[15,5.157,79,7.404]],["t/96",[80,2.712,81,3.356,82,2.219,83,5.015,84,5.015]],["t/98",[42,3.751,70,3.784]],["t/100",[53,4.708,85,4.088]],["t/101",[56,4.913]],["t/103",[86,3.818,87,6.136]],["t/105",[7,4.334,18,2.731,81,3.761,82,2.487]],["t/107",[88,7.019]],["t/109",[41,3.914,89,3.103,90,5.619,91,5.619]],["t/111",[18,2.437,92,2.97,93,3.571,94,3.356,95,5.015]],["t/113",[33,5.095,59,4.45,96,4.661]],["t/115",[74,4.209,75,4.334,97,5.619,98,5.619]],["t/117",[99,6.389,100,5.295,101,5.545]],["t/119",[48,3.784,68,3.964]],["t/123",[71,4.421]],["t/125",[8,3.687,9,3.687]],["t/127",[10,3.657,102,5.904]],["t/129",[103,3.834,104,4.877,105,5.619,106,4.656]],["t/131",[15,3.493,104,4.352,107,3.493,108,3.571,109,4.155]],["t/133",[18,3.599,110,5.904]],["t/135",[94,4.956,111,6.814]],["t/137",[111,6.814,112,6.426]],["t/139",[106,4.656,113,5.619,114,3.834,115,5.619]],["t/141",[13,3.687,70,3.784]],["t/142",[73,2.712,116,3.422,117,3.422,118,3.009,119,2.97]],["t/144",[108,5.273,120,6.426]],["t/146",[121,6.814,122,6.814]],["t/148",[120,6.426,123,7.404]],["t/150",[18,2.731,124,5.619,125,2.798,126,5.171]],["t/152",[127,5.597]],["t/154",[50,2.989,80,3.455,128,6.389]],["t/156",[50,2.989,129,3.691,130,5.88]],["t/158",[48,3.784,68,3.964]],["t/162",[71,4.421]],["t/164",[8,3.687,9,3.687]],["t/166",[10,3.156,11,3.455,12,3.421]],["t/167",[13,3.687,131,7.404]],["t/169",[4,3.886,73,3.455,132,2.293]],["t/171",[22,3.998,80,2.712,132,1.8,133,5.015,134,4.352]],["t/173",[108,4.002,129,3.246,135,5.619,136,5.619]],["t/175",[18,3.105,114,4.36,137,4.2]],["t/176",[18,4.278]],["t/178",[114,6.006]],["t/180",[42,3.751,70,3.784]],["t/181",[85,3.528,118,3.834,119,3.784]],["t/183",[89,3.103,125,2.798,138,3.631,139,5.619]],["t/184",[108,4.002,120,4.877,121,5.171,122,5.171]],["t/186",[140,7.404,141,7.404]],["t/188",[142,8.802]],["t/190",[143,8.101]],["t/192",[144,8.101]],["t/194",[144,8.101]],["t/196",[145,8.802]],["t/198",[143,6.814,146,7.404]],["t/200",[58,4.45,92,3.784,147,4.277]],["t/202",[134,7.639]],["t/204",[148,8.802]],["t/206",[149,8.802]],["t/208",[48,3.784,68,3.964]],["t/212",[71,4.421]],["t/214",[8,3.687,9,3.687]],["t/218",[71,4.421]],["t/220",[8,3.687,9,3.687]],["t/222",[10,3.156,11,3.455,12,3.421]],["t/223",[13,1.888,150,3.29,151,3.142,152,3.142,153,2.538,154,2.492,155,2.641,156,2.924]],["t/224",[73,3.455,86,3.294,157,5.88]],["t/226",[18,2.731,80,3.039,93,4.002,158,3.834]],["t/228",[15,3.914,129,3.246,159,5.171,160,4.877]],["t/229",[26,5.171,155,3.914,161,4.656,162,5.619]],["t/231",[158,5.052,163,6.814]],["t/233",[164,7.404,165,6.814]],["t/235",[18,3.105,108,4.55,137,4.2]],["t/237",[42,3.751,70,3.784]],["t/238",[85,3.103,86,2.897,87,4.656,150,4.877]],["t/240",[18,2.731,89,3.103,119,3.328,138,3.631]],["t/241",[18,3.105,56,3.566,93,4.55]],["t/243",[118,4.443,166,7.404]],["t/245",[117,5.052,167,7.404]],["t/247",[50,2.346,74,3.756,92,2.97,168,3.188,169,3.868]],["t/248",[61,2.546,81,2.762,82,1.826,170,4.127,171,3.42,172,4.127,173,4.127]],["t/250",[22,3.998,61,3.093,171,4.155,174,3.571,175,3.356]],["t/252",[51,4.615,61,3.093,175,3.356,176,3.571,177,3.868]],["t/254",[48,3.265,147,4.277,178,4.928]],["t/256",[150,4.877,179,3.761,180,5.619,181,5.619]],["t/257",[61,3.466,158,3.834,182,4.656,183,5.171]],["t/259",[61,3.466,158,3.834,183,7.397]],["t/261",[158,4.36,184,5.095,185,6.389]],["t/263",[15,3.493,16,3.356,18,2.437,119,2.97,186,3.356]],["t/264",[16,4.277,23,5.545,165,5.88]],["t/266",[16,3.03,154,2.976,155,3.154,163,4.167,187,4.167,188,3.752]],["t/268",[29,5.295,189,5.545,190,6.389]],["t/270",[57,3.418,68,3.009,191,3.694,192,3.914]],["t/272",[44,3.328,154,3.694,155,3.914,193,5.619]],["t/274",[5,4.615,46,3.009,158,3.422,174,3.571,175,3.356]],["t/276",[114,3.422,158,3.422,194,4.615,195,5.015,196,5.015]],["t/278",[156,4.928,158,4.36,197,5.095]],["t/282",[71,4.421]],["t/284",[8,3.687,9,3.687]],["t/286",[10,3.657,198,5.401]],["t/288",[13,3.182,15,4.45,86,3.294]],["t/290",[73,3.039,199,4.656,200,4.656,201,5.619]],["t/291",[199,7.294]],["t/293",[200,7.294]],["t/295",[80,4.004,202,4.867]],["t/297",[202,3.296,203,3.998,204,3.658,205,5.015,206,5.015]],["t/299",[154,3.694,202,3.694,207,4.481,208,4.334]],["t/301",[86,2.897,202,3.694,209,4.877,210,4.877]],["t/303",[65,3.929,129,2.615,211,3.929,212,4.527,213,4.527,214,4.527]],["t/305",[137,4.2,215,5.545,216,6.389]],["t/307",[199,5.295,211,5.545,217,5.095]],["t/309",[42,3.237,100,5.295,202,4.2]],["t/311",[18,3.599,48,3.784]],["t/312",[18,2.731,94,3.761,112,4.877,179,3.761]],["t/314",[186,4.277,218,6.389,219,5.88]],["t/316",[36,5.546,220,5.052]],["t/318",[47,6.426,221,5.711]],["t/320",[50,3.464,57,4.503]],["t/321",[222,5.095,223,6.389,224,5.88]],["t/323",[86,3.294,225,5.095,226,6.389]],["t/325",[227,4.877,228,5.619,229,5.619,230,5.619]],["t/327",[67,4.867,68,3.964]],["t/329",[231,7.639]],["t/333",[71,4.421]],["t/335",[9,4.384]],["t/337",[11,4.004,12,3.964]],["t/338",[74,4.786,86,3.294,168,4.062]],["t/340",[44,4.385,132,2.657]],["t/342",[18,3.599,100,6.136]],["t/344",[72,4.667]],["t/346",[157,6.814,232,7.404]],["t/348",[4,3.886,233,5.295,234,4.928]],["t/349",[114,5.052,235,7.404]],["t/351",[4,3.886,233,5.295,234,4.928]],["t/353",[233,5.295,234,4.928,236,5.295]],["t/355",[36,4.786,132,2.293,197,5.095]],["t/357",[132,2.293,197,5.095,237,5.545]],["t/359",[114,6.006]],["t/361",[132,2.293,197,5.095,236,5.295]],["t/363",[70,4.498]],["t/364",[118,4.443,119,4.385]],["t/365",[74,4.786,86,3.294,168,4.062]],["t/367",[4,3.886,233,5.295,234,4.928]],["t/369",[132,2.293,197,5.095,237,5.545]],["t/371",[18,3.599,119,4.385]],["t/373",[56,4.913]],["t/375",[49,4.867,50,3.464]],["t/377",[68,4.713]],["t/381",[71,4.421]],["t/383",[8,3.687,9,3.687]],["t/385",[10,2.775,132,2.017,238,4.099,239,4.099]],["t/387",[13,3.182,153,4.277,240,6.389]],["t/389",[73,3.455,116,4.36,241,6.389]],["t/390",[169,6.79]],["t/392",[132,2.657,242,7.404]],["t/394",[132,2.293,238,4.661,239,4.661]],["t/396",[86,3.818,168,4.708]],["t/398",[50,3.464,80,4.004]],["t/400",[58,4.45,59,4.45,129,3.691]],["t/402",[243,8.802]],["t/404",[244,7.404,245,6.136]],["t/406",[238,4.661,239,4.661,246,4.2]],["t/408",[137,3.694,184,4.481,238,4.099,239,4.099]],["t/410",[42,3.237,153,4.277,247,6.389]],["t/411",[169,6.79]],["t/413",[132,3.159]],["t/415",[50,4.118]],["t/417",[48,3.265,153,4.277,248,6.389]],["t/419",[125,4.384]],["t/421",[249,6.389,250,6.389,251,6.389]],["t/423",[252,7.404,253,7.404]],["t/425",[57,4.503,192,5.157]],["t/427",[11,3.455,12,3.421,67,4.2]],["t/429",[68,3.964,254,5.546]],["t/433",[71,4.421]],["t/435",[8,3.687,9,3.687]],["t/437",[10,3.156,11,3.455,12,3.421]],["t/438",[72,2.659,103,3.422,255,5.015,256,5.015,257,4.155]],["t/440",[107,3.154,125,2.255,175,3.03,257,3.752,258,3.61,259,4.527]],["t/442",[154,4.2,155,4.45,260,4.55]],["t/444",[168,4.062,257,5.295,261,6.389]],["t/446",[13,3.687,72,3.926]],["t/448",[73,3.455,246,4.2,262,5.545]],["t/450",[4,3.886,80,3.455,263,4.786]],["t/452",[4,3.418,263,4.209,264,4.334,265,4.481]],["t/454",[4,3.886,263,4.786,266,6.389]],["t/456",[129,2.897,132,1.8,171,4.155,263,3.756,267,4.615]],["t/458",[16,4.277,132,2.293,137,4.2]],["t/460",[42,3.751,70,3.784]],["t/462",[53,4.062,85,3.528,268,6.389]],["t/463",[56,4.913]],["t/465",[118,4.443,119,4.385]],["t/467",[72,3.926,269,7.404]],["t/469",[49,4.2,50,2.989,89,3.528]],["t/470",[50,1.774,138,2.45,174,2.7,175,2.538,189,3.29,258,3.023,270,3.791,271,3.489]],["t/472",[29,3.752,204,3.303,257,3.752,258,3.61,272,4.527,273,4.527]],["t/474",[61,2.339,72,2.01,152,4.952,175,2.538,176,2.7,260,2.7,274,3.791]],["t/476",[50,2.346,64,3.756,92,2.97,116,3.422,258,3.998]],["t/478",[48,3.784,191,4.867]],["t/482",[71,4.421]],["t/484",[8,3.687,9,3.687]],["t/486",[10,3.156,11,3.455,12,3.421]],["t/487",[13,2.055,21,3.42,86,2.128,151,3.42,168,2.624,275,4.127,276,3.091]],["t/489",[73,2.712,94,3.356,260,3.571,276,3.756,277,5.015]],["t/491",[278,6.814,279,7.404]],["t/493",[86,2.897,168,3.573,280,5.171,281,5.619]],["t/495",[80,2.449,94,3.03,260,3.224,276,3.391,282,4.527,283,3.391]],["t/497",[44,3.328,276,4.209,283,4.209,284,5.619]],["t/499",[276,4.786,283,4.786,285,6.389]],["t/501",[276,4.209,280,5.171,283,4.209,286,4.334]],["t/503",[19,2.546,129,2.384,189,3.581,245,3.42,258,3.29,260,2.939,287,4.127]],["t/505",[4,2.754,17,3.492,46,2.716,125,2.255,137,2.976,288,4.527]],["t/507",[4,3.886,125,3.182,289,6.389]],["t/509",[125,3.687,200,6.136]],["t/511",[17,5.711,125,3.687]],["t/513",[42,2.846,82,2.487,260,4.002,290,4.099]],["t/514",[56,3.566,85,3.528,260,4.55]],["t/516",[53,4.062,89,3.528,260,4.55]],["t/520",[71,4.421]],["t/522",[8,3.687,9,3.687]],["t/524",[10,1.872,19,2.339,81,4,82,2.645,198,2.766,291,2.41]],["t/526",[13,2.255,78,3.61,81,3.03,82,2.004,292,4.527,293,4.167]],["t/528",[42,3.237,50,2.989,70,3.265]],["t/530",[11,3.455,12,3.421,48,3.265]],["t/532",[57,4.503,68,3.964]],["t/536",[71,4.421]],["t/538",[8,3.687,9,3.687]],["t/540",[10,3.156,294,6.389,295,4.277]],["t/542",[94,4.277,103,4.36,295,4.277]],["t/543",[125,3.687,296,6.136]],["t/545",[238,4.099,239,4.099,295,3.761,296,4.656]],["t/547",[264,5.711,297,7.404]],["t/549",[107,4.45,295,4.277,298,6.389]],["t/551",[110,5.095,138,4.129,299,6.389]],["t/552",[138,4.785,169,5.711]],["t/554",[88,5.095,138,4.129,300,6.389]],["t/556",[13,2.255,125,2.255,204,3.303,291,2.879,301,4.527,302,4.527]],["t/558",[42,2.54,238,3.658,239,3.658,295,3.356,303,5.015]],["t/560",[85,1.936,125,1.746,153,2.347,238,2.558,239,2.558,295,2.347,304,2.905,305,3.506,306,3.227]],["t/562",[3,3.489,89,2.093,94,2.538,153,2.538,238,2.766,239,2.766,307,3.791,308,3.489]],["t/564",[92,2.97,153,3.356,174,3.571,175,3.356,309,5.015]],["t/566",[48,3.265,310,6.389,311,6.389]],["t/568",[4,2.754,57,2.754,138,2.926,151,3.752,152,3.752,312,4.167]],["t/570",[67,4.867,192,5.157]],["t/572",[204,4.099,290,4.099,295,3.761,313,5.619]],["t/574",[153,3.356,295,3.356,308,4.615,314,5.015,315,5.015]],["t/576",[4,3.418,86,2.897,290,4.099,295,3.761]],["t/578",[290,3.01,295,2.762,304,3.42,312,3.798,316,4.127,317,4.127,318,4.127]],["t/580",[19,3.093,245,4.155,290,3.658,295,3.356,319,5.015]],["t/582",[68,3.964,320,6.814]],["t/586",[71,4.421]],["t/588",[8,3.687,9,3.687]],["t/590",[10,3.657,198,5.401]],["t/591",[13,2.497,16,3.356,176,3.571,321,4.615,322,5.015]],["t/593",[56,3.566,73,3.455,86,3.294]],["t/595",[18,2.437,80,2.712,323,5.015,324,3.658,325,4.615]],["t/597",[19,2.793,81,3.03,82,2.004,129,2.615,291,2.879,326,4.167]],["t/599",[18,2.731,93,4.002,137,3.694,326,5.171]],["t/601",[217,5.095,327,5.88,328,6.389]],["t/603",[42,2.54,176,3.571,321,4.615,329,5.015,330,5.015]],["t/605",[61,3.466,85,3.103,125,2.798,331,5.619]],["t/607",[89,3.103,245,4.656,332,5.171,333,4.656]],["t/609",[114,5.052,333,6.136]],["t/611",[18,3.599,333,6.136]],["t/613",[333,6.136,334,7.404]],["t/615",[335,5.904,336,6.814]],["t/617",[61,2.339,92,2.245,125,1.888,175,2.538,176,2.7,337,3.791,338,3.791,339,3.791]],["t/619",[58,4.45,70,3.265,96,4.661]],["t/621",[48,3.784,68,3.964]],["t/625",[71,4.421]],["t/627",[8,3.687,9,3.687]],["t/629",[10,3.657,72,3.926]],["t/631",[13,3.687,70,3.784]],["t/632",[73,3.455,116,4.36,117,4.36]],["t/634",[82,2.828,271,5.88,340,4.786]],["t/636",[49,4.2,50,2.989,80,3.455]],["t/637",[10,2.236,70,2.314,86,2.334,203,3.61,341,3.929,342,4.167]],["t/639",[70,2.563,86,2.586,207,3.998,342,4.615,343,4.615]],["t/641",[66,3.756,209,4.352,344,5.015,345,5.015,346,4.352]],["t/643",[335,5.095,336,5.88,347,6.389]],["t/645",[86,2.586,129,2.897,348,5.015,349,5.015,350,4.615]],["t/647",[11,3.455,12,3.421,42,3.237]],["t/649",[48,3.784,68,3.964]],["t/651",[191,5.786]],["t/655",[71,4.421]],["t/657",[8,3.687,9,3.687]],["t/659",[10,2.775,46,3.371,82,2.487,351,4.334]],["t/661",[65,4.877,75,4.334,103,3.834,352,5.619]],["t/663",[13,3.687,70,3.784]],["t/665",[70,3.265,73,3.455,117,4.36]],["t/667",[80,3.455,169,4.928,353,5.88]],["t/669",[125,2.798,129,3.246,177,4.334,178,4.334]],["t/671",[137,4.2,354,6.389,355,6.389]],["t/673",[217,3.998,246,3.296,262,4.352,263,3.756,356,5.015]],["t/675",[147,4.277,192,4.45,357,5.88]],["t/677",[11,3.455,12,3.421,42,3.237]],["t/680",[8,3.687,9,3.687]],["t/682",[10,3.156,11,3.455,12,3.421]],["t/684",[13,2.798,82,2.487,132,2.017,358,5.171]],["t/685",[73,4.004,359,5.711]],["t/687",[80,2.712,132,1.8,159,4.615,360,4.615,361,4.615]],["t/689",[59,4.45,129,3.691,362,5.545]],["t/691",[42,2.846,82,2.487,132,2.017,202,3.694]],["t/693",[85,3.528,132,2.293,363,5.88]],["t/695",[89,3.528,132,2.293,202,4.2]],["t/697",[92,3.328,125,2.798,161,4.656,208,4.334]],["t/699",[48,3.784,70,3.784]],["t/700",[56,4.133,179,4.956]],["t/702",[127,4.708,186,4.956]],["t/704",[118,3.834,119,3.784,220,4.36]],["t/706",[49,4.2,50,2.989,221,4.928]],["t/708",[57,3.886,147,4.277,192,4.45]],["t/710",[67,4.867,68,3.964]],["t/712",[191,5.786]],["t/716",[71,4.421]],["t/718",[8,3.687,9,3.687]],["t/720",[364,7.404,365,7.404]],["t/722",[10,3.156,366,5.545,367,5.88]],["t/724",[13,2.255,368,4.527,369,3.929,370,4.527,371,4.527,372,4.527]],["t/726",[28,3.998,46,3.009,114,3.422,373,5.015,374,4.615]],["t/728",[36,4.209,132,2.017,350,5.171,375,5.619]],["t/730",[42,3.237,72,3.388,306,5.88]],["t/732",[85,2.5,376,3.492,377,3.492,378,3.929,379,3.752,380,4.167]],["t/734",[4,3.418,81,3.761,82,2.487,381,4.877]],["t/736",[114,4.36,178,4.928,374,5.88]],["t/738",[75,4.334,89,3.103,382,5.171,383,4.656]],["t/740",[191,4.2,384,6.389,385,6.389]],["t/742",[48,3.265,70,3.265,362,5.545]],["t/744",[127,4.708,179,4.956]],["t/746",[81,4.277,82,2.828,386,6.389]],["t/748",[78,5.904,293,6.814]],["t/750",[82,2.487,215,4.877,340,4.209,387,5.619]],["t/752",[28,4.481,82,2.487,340,4.209,388,5.619]],["t/754",[46,4.443,82,3.277]],["t/756",[383,7.294]],["t/758",[186,4.277,389,6.389,390,6.389]],["t/760",[220,4.36,391,6.389,392,6.389]],["t/762",[10,2.775,221,4.334,341,4.877,393,5.619]],["t/764",[13,2.255,34,3.929,204,3.303,341,3.929,394,4.167,395,4.527]],["t/766",[11,3.455,12,3.421,57,3.886]],["t/767",[17,3.868,67,3.296,376,3.868,377,3.868,379,4.155]],["t/769",[75,3.492,380,4.167,382,4.167,383,3.752,396,3.752,397,4.527]],["t/771",[36,3.756,346,4.352,377,3.868,383,4.155,398,4.155]],["t/773",[64,3.756,346,4.352,399,4.615,400,4.155,401,3.868]],["t/775",[64,3.391,399,4.167,400,3.752,401,3.492,402,4.527,403,4.527]],["t/777",[46,2.476,332,3.798,404,3.42,405,4.127,406,4.127,407,4.127,408,4.127]],["t/779",[12,3.009,68,3.009,254,4.209,409,5.171]],["t/783",[71,4.421]],["t/785",[8,3.687,9,3.687]],["t/787",[10,3.657,198,5.401]],["t/788",[75,4.928,86,3.294,265,5.095]],["t/790",[46,3.834,376,4.928,377,4.928]],["t/792",[13,3.182,72,3.388,410,6.389]],["t/794",[46,3.371,73,3.039,265,4.481,411,5.619]],["t/796",[37,4.615,66,3.756,80,2.712,377,3.868,412,5.015]],["t/798",[361,5.88,413,6.389,414,6.389]],["t/800",[66,4.786,265,5.095,415,6.389]],["t/802",[129,3.246,219,5.171,416,5.619,417,4.877]],["t/804",[42,3.751,70,3.784]],["t/806",[118,4.443,119,4.385]],["t/808",[127,5.597]],["t/810",[17,4.334,85,3.103,168,3.573,418,4.877]],["t/811",[56,4.133,86,3.818]],["t/813",[118,4.443,119,4.385]],["t/815",[49,4.867,50,3.464]],["t/817",[89,3.528,246,4.2,263,4.786]],["t/818",[56,4.133,86,3.818]],["t/820",[118,4.443,119,4.385]],["t/822",[49,4.867,50,3.464]],["t/824",[4,3.418,92,3.328,168,3.573,419,5.619]],["t/825",[56,4.133,86,3.818]],["t/827",[118,4.443,119,4.385]],["t/829",[49,4.867,50,3.464]],["t/831",[96,5.401,147,4.956]],["t/832",[64,4.786,417,5.545,420,5.295]],["t/834",[41,3.914,376,4.334,377,4.334,378,4.877]],["t/836",[66,4.786,87,5.295,421,5.545]],["t/838",[160,5.545,422,6.389,423,5.88]],["t/840",[50,2.989,417,5.545,424,5.88]],["t/842",[48,3.784,68,3.964]],["t/846",[71,4.421]],["t/848",[8,3.687,9,3.687]],["t/850",[10,3.156,11,3.455,12,3.421]],["t/852",[13,3.687,198,5.401]],["t/854",[42,2.846,86,2.897,425,5.619,426,4.481]],["t/856",[85,3.528,109,5.295,427,5.88]],["t/858",[89,3.103,125,2.798,161,4.656,208,4.334]],["t/860",[18,3.105,92,3.784,108,4.55]],["t/862",[48,3.784,70,3.784]],["t/863",[56,4.133,179,4.956]],["t/865",[53,4.062,70,3.265,186,4.277]],["t/867",[127,4.708,220,5.052]],["t/869",[50,2.989,70,3.265,221,4.928]],["t/871",[57,4.503,147,4.956]],["t/872",[109,5.295,222,5.095,427,5.88]],["t/874",[125,2.798,161,4.656,208,4.334,225,4.481]],["t/876",[18,3.105,108,4.55,227,5.545]],["t/878",[67,4.867,68,3.964]],["t/880",[191,4.867,254,5.546]],["t/884",[71,4.421]],["t/886",[8,3.687,9,3.687]],["t/888",[10,3.156,11,3.455,12,3.421]],["t/889",[13,3.182,46,3.834,428,5.545]],["t/890",[46,3.371,73,3.039,132,2.017,237,4.877]],["t/892",[80,3.039,174,4.002,202,3.694,429,4.002]],["t/894",[129,3.246,153,3.761,154,3.694,155,3.914]],["t/896",[21,3.752,86,2.334,137,2.976,174,3.224,202,2.976,429,3.224]],["t/898",[74,5.546,86,3.818]],["t/900",[86,3.818,168,4.708]],["t/902",[42,3.751,70,3.784]],["t/903",[85,3.103,138,3.631,290,4.099,430,5.619]],["t/904",[117,6.006]],["t/906",[61,5.43]],["t/908",[19,5.43]],["t/910",[89,3.103,138,3.631,154,3.694,155,3.914]],["t/911",[117,6.006]],["t/913",[61,5.43]],["t/915",[58,4.45,59,4.45,92,3.784]],["t/916",[28,5.904,431,7.404]],["t/918",[174,4.55,202,4.2,429,4.55]],["t/920",[184,5.095,432,6.389,433,6.389]],["t/922",[21,3.752,86,2.334,96,3.303,174,3.224,202,2.976,429,3.224]],["t/923",[117,6.006]],["t/925",[61,5.43]],["t/927",[48,3.784,68,3.964]],["t/931",[71,4.421]],["t/933",[8,3.687,9,3.687]],["t/935",[10,3.156,11,3.455,12,3.421]],["t/936",[13,2.798,46,3.371,358,5.171,428,4.877]],["t/937",[174,4.55,202,4.2,429,4.55]],["t/939",[87,4.656,154,3.694,155,3.914,434,5.619]],["t/941",[151,4.155,152,4.155,153,3.356,154,3.296,155,3.493]],["t/943",[42,2.846,46,3.371,428,4.877,435,4.656]],["t/944",[28,3.998,78,3.998,82,2.219,85,2.769,436,4.352]],["t/946",[192,6.131]],["t/948",[18,2.437,89,2.769,126,4.615,291,3.188,437,5.015]],["t/950",[192,6.131]],["t/952",[27,4.615,92,2.97,134,4.352,156,3.868,438,4.155]],["t/954",[96,4.661,158,4.36,439,5.88]],["t/956",[48,3.784,70,3.784]],["t/957",[53,4.062,116,4.36,179,4.277]],["t/958",[18,3.599,94,4.956]],["t/960",[118,4.443,119,4.385]],["t/962",[86,2.586,168,3.188,186,3.356,290,3.658,440,5.015]],["t/964",[86,2.897,220,3.834,290,4.099,438,4.656]],["t/966",[22,5.904,171,6.136]],["t/968",[17,5.711,438,6.136]],["t/970",[158,5.052,439,6.814]],["t/972",[57,4.503,68,3.964]],["t/976",[71,4.421]],["t/978",[8,3.687,9,3.687]],["t/980",[10,2.775,53,3.573,198,4.099,366,4.877]],["t/981",[13,3.687,72,3.926]],["t/983",[18,2.437,73,2.712,93,3.571,132,1.8,441,3.998]],["t/985",[18,2.731,80,3.039,132,2.017,442,4.656]],["t/987",[132,2.017,202,3.694,203,4.481,363,5.171]],["t/989",[132,2.293,207,5.095,443,6.389]],["t/991",[18,2.437,114,3.422,125,2.497,129,2.897,154,3.296]],["t/993",[19,3.466,137,3.694,291,3.573,444,5.619]],["t/995",[42,3.751,70,3.784]],["t/996",[85,3.103,125,2.798,441,4.481,442,4.656]],["t/998",[89,3.103,118,3.371,119,3.328,127,3.573]],["t/1000",[48,3.784,50,3.464]],["t/1001",[49,4.2,50,2.989,179,4.277]],["t/1003",[46,3.009,175,3.356,176,3.571,186,3.356,445,4.615]],["t/1005",[220,5.052,446,7.404]],["t/1007",[67,4.867,68,3.964]],["t/1011",[71,4.421]],["t/1013",[8,3.687,9,3.687]],["t/1015",[10,3.657,359,5.711]],["t/1016",[125,3.687,447,6.814]],["t/1018",[82,3.277,132,2.657]],["t/1020",[13,2.798,82,2.487,435,4.656,448,4.334]],["t/1021",[73,3.455,449,5.545,450,5.545]],["t/1023",[204,4.661,449,5.545,450,5.545]],["t/1025",[125,3.182,449,5.545,450,5.545]],["t/1027",[80,3.039,82,2.487,132,2.017,451,5.619]],["t/1029",[36,4.786,118,3.834,129,3.691]],["t/1030",[452,8.802]],["t/1032",[132,2.657,324,5.401]],["t/1034",[44,3.784,125,3.182,154,4.2]],["t/1036",[177,5.711,208,5.711]],["t/1038",[42,3.751,70,3.784]],["t/1040",[125,3.687,447,6.814]],["t/1042",[18,3.105,86,3.294,93,4.55]],["t/1044",[44,4.385,453,6.426]],["t/1046",[82,2.219,85,2.769,204,3.658,435,4.155,448,3.868]],["t/1048",[82,2.219,89,2.769,125,2.497,435,4.155,448,3.868]],["t/1050",[58,4.45,59,4.45,92,3.784]],["t/1051",[208,4.61,234,2.924,286,2.924,436,3.29,454,3.489,455,3.489,456,3.791]],["t/1053",[132,2.657,457,6.814]],["t/1055",[48,3.784,68,3.964]],["t/1059",[71,4.421]],["t/1061",[8,3.687,9,3.687]],["t/1063",[10,3.657,72,3.926]],["t/1064",[82,2.219,103,3.422,132,1.8,198,3.658,458,5.015]],["t/1066",[82,2.004,102,3.61,107,3.154,132,1.625,459,4.527,460,3.929]],["t/1068",[13,3.182,50,2.989,70,3.265]],["t/1069",[53,4.062,73,3.455,116,4.36]],["t/1071",[49,4.2,50,2.989,80,3.455]],["t/1072",[61,3.093,169,3.868,203,3.998,353,4.615,461,4.155]],["t/1074",[56,2.116,61,2.339,125,1.888,207,3.023,351,2.924,462,3.791,463,3.791,464,3.29]],["t/1076",[61,3.093,74,3.756,125,2.497,168,3.188,465,5.015]],["t/1078",[19,3.466,129,3.246,335,4.481,466,5.171]],["t/1079",[19,2.339,34,3.29,182,3.142,304,3.142,335,3.023,460,3.29,467,3.489,468,3.791]],["t/1081",[19,2.339,23,3.29,86,1.955,182,3.142,460,3.29,469,3.489,470,3.791,471,3.791]],["t/1083",[137,4.2,147,4.277,472,6.389]],["t/1085",[11,3.455,12,3.421,42,3.237]],["t/1086",[48,3.784,473,7.404]],["t/1090",[71,4.421]],["t/1092",[8,3.687,9,3.687]],["t/1094",[10,3.657,45,6.814]],["t/1096",[13,2.798,72,2.979,82,2.487,448,4.334]],["t/1098",[15,5.157,73,4.004]],["t/1100",[36,5.546,80,4.004]],["t/1102",[42,3.751,70,3.784]],["t/1104",[85,3.528,156,4.928,474,5.88]],["t/1106",[56,3.566,475,6.389,476,5.88]],["t/1108",[50,3.464,477,7.404]],["t/1110",[89,4.088,461,6.136]],["t/1112",[44,3.328,101,4.877,478,4.877,479,5.619]],["t/1114",[44,3.328,175,3.761,176,4.002,480,4.877]],["t/1116",[82,1.678,295,4,448,2.924,455,5.5,481,3.489,482,3.791]],["t/1118",[11,3.455,12,3.421,48,3.265]],["t/1119",[57,4.503,68,3.964]],["t/1123",[71,4.421]],["t/1125",[8,3.687,9,3.687]],["t/1127",[10,3.156,82,2.828,132,2.293]],["t/1129",[16,4.277,103,4.36,483,5.88]],["t/1131",[107,3.914,278,5.171,484,5.619,485,5.619]],["t/1133",[13,3.687,50,3.464]],["t/1135",[73,3.455,486,6.389,487,6.389]],["t/1137",[58,4.45,59,4.45,80,3.455]],["t/1138",[132,2.657,324,5.401]],["t/1140",[132,2.657,429,5.273]],["t/1142",[18,3.105,93,4.55,108,4.55]],["t/1144",[41,3.914,42,2.846,102,4.481,400,4.656]],["t/1146",[48,2.871,445,5.171,488,5.619,489,5.619]],["t/1148",[57,3.886,132,2.293,236,5.295]],["t/1150",[67,4.867,490,7.404]],["t/1152",[68,3.964,254,5.546]],["t/1156",[71,4.421]],["t/1158",[8,3.687,9,3.687]],["t/1160",[10,3.657,198,5.401]],["t/1161",[81,4.956,82,3.277]],["t/1163",[82,3.277,132,2.657]],["t/1165",[13,3.687,72,3.926]],["t/1166",[73,3.039,82,2.487,132,2.017,491,4.877]],["t/1168",[16,4.277,80,3.455,492,5.88]],["t/1169",[360,6.814,491,6.426]],["t/1171",[457,5.88,493,6.389,494,6.389]],["t/1173",[325,5.88,436,5.545,495,6.389]],["t/1175",[291,4.708,464,6.426]],["t/1177",[18,3.105,114,4.36,129,3.691]],["t/1179",[42,3.751,70,3.784]],["t/1180",[56,4.133,85,4.088]],["t/1182",[15,5.157,89,4.088]],["t/1184",[496,8.802]],["t/1186",[343,8.101]],["t/1188",[92,4.385,127,4.708]],["t/1190",[53,4.062,96,4.661,116,4.36]],["t/1192",[48,3.784,50,3.464]],["t/1193",[49,4.2,50,2.989,179,4.277]],["t/1194",[41,3.914,82,2.487,132,2.017,497,5.619]],["t/1196",[19,3.466,72,2.979,291,3.573,498,5.619]],["t/1198",[44,2.97,184,3.998,186,3.356,492,4.615,499,5.015]],["t/1200",[132,2.017,184,4.481,220,3.834,429,4.002]],["t/1202",[82,2.004,117,3.089,132,1.625,175,3.03,176,3.224,221,3.492]],["t/1204",[61,3.466,132,2.017,324,4.099,394,5.171]],["t/1206",[58,4.45,59,4.45,500,6.389]],["t/1207",[291,4.708,464,6.426]],["t/1209",[501,8.802]],["t/1211",[67,4.867,68,3.964]],["t/1213",[191,5.786]],["t/1215",[231,7.639]],["t/1216",[18,3.599,118,4.443]],["t/1217",[19,2.793,82,2.004,132,1.625,291,2.879,491,3.929,502,4.527]],["t/1219",[61,3.941,461,5.295,503,5.88]],["t/1220",[64,3.391,82,2.004,102,3.61,132,1.625,504,4.527,505,4.527]],["t/1224",[71,4.421]],["t/1226",[8,3.687,9,3.687]],["t/1228",[10,3.156,11,3.455,12,3.421]],["t/1229",[19,3.466,44,3.328,55,4.099,291,3.573]],["t/1231",[44,4.385,453,6.426]],["t/1233",[156,5.711,506,6.136]],["t/1235",[13,3.687,102,5.904]],["t/1237",[82,3.277,132,2.657]],["t/1239",[73,3.039,82,2.487,132,2.017,453,4.877]],["t/1241",[132,2.657,507,6.136]],["t/1243",[132,2.657,506,6.136]],["t/1245",[18,2.437,46,3.009,80,2.712,441,3.998,442,4.155]],["t/1247",[19,4.567,291,4.708]],["t/1249",[42,3.751,70,3.784]],["t/1251",[53,4.062,85,3.528,508,6.389]],["t/1252",[56,4.133,125,3.687]],["t/1254",[86,4.539]],["t/1256",[127,5.597]],["t/1258",[118,4.443,119,4.385]],["t/1260",[50,2.989,89,3.528,147,4.277]],["t/1261",[46,3.834,56,3.566,381,5.545]],["t/1263",[46,3.834,175,4.277,176,4.55]],["t/1265",[4,3.418,125,2.798,168,3.573,418,4.877]],["t/1267",[86,3.818,204,5.401]],["t/1269",[88,5.095,132,2.293,509,6.389]],["t/1271",[58,4.45,59,4.45,92,3.784]],["t/1272",[132,2.293,506,5.295,507,5.295]],["t/1274",[108,5.273,506,6.136]],["t/1276",[132,2.657,324,5.401]],["t/1278",[46,3.834,188,5.295,442,5.295]],["t/1280",[125,3.182,187,5.88,510,6.389]],["t/1282",[125,2.798,260,4.002,441,4.481,511,5.171]],["t/1284",[48,3.784,68,3.964]],["t/1288",[71,4.421]],["t/1290",[8,3.687,9,3.687]],["t/1292",[10,3.156,11,3.455,12,3.421]],["t/1293",[13,3.182,366,5.545,367,5.88]],["t/1295",[73,3.455,286,4.928,512,6.389]],["t/1297",[80,3.039,199,4.656,200,4.656,513,5.619]],["t/1299",[81,4.277,82,2.828,129,3.691]],["t/1301",[42,3.237,82,2.828,340,4.786]],["t/1302",[85,4.088,514,7.404]],["t/1304",[72,3.926,89,4.088]],["t/1306",[92,3.784,378,5.545,515,6.389]],["t/1308",[48,3.265,53,4.062,116,4.36]],["t/1309",[56,3.566,88,5.095,179,4.277]],["t/1311",[72,3.926,186,4.956]],["t/1313",[15,4.45,220,4.36,516,6.389]],["t/1315",[49,4.2,50,2.989,57,3.886]],["t/1316",[4,3.418,222,4.481,283,4.209,517,5.619]],["t/1318",[69,6.814,225,5.904]],["t/1320",[94,3.761,117,3.834,227,4.877,376,4.334]],["t/1322",[518,7.404,519,7.404]],["t/1324",[67,4.2,138,4.129,520,6.389]],["t/1325",[324,4.661,340,4.786,396,5.295]],["t/1327",[215,4.877,381,4.877,398,4.656,521,5.171]],["t/1329",[82,3.034,340,3.391,404,3.752,521,4.167,522,4.527]],["t/1331",[429,5.273,523,6.426]],["t/1333",[19,3.941,94,4.277,524,5.545]],["t/1335",[192,5.157,254,5.546]],["t/1336",[525,8.802]],["t/1338",[112,6.426,526,7.404]],["t/1340",[78,4.481,82,2.487,340,4.209,527,5.619]],["t/1344",[71,4.421]],["t/1346",[8,3.687,9,3.687]],["t/1348",[10,3.657,72,3.926]],["t/1349",[103,5.052,359,5.711]],["t/1351",[107,3.493,132,1.8,296,4.155,528,5.015,529,5.015]],["t/1353",[110,5.095,530,6.389,531,6.389]],["t/1355",[13,3.687,70,3.784]],["t/1356",[73,3.455,116,4.36,117,4.36]],["t/1358",[50,3.464,80,4.004]],["t/1359",[49,4.2,50,2.989,203,5.095]],["t/1361",[132,1.8,207,3.998,324,3.658,511,4.615,532,4.615]],["t/1363",[72,3.388,209,5.545,533,6.389]],["t/1365",[11,3.455,12,3.421,42,3.237]],["t/1366",[82,2.828,85,3.528,132,2.293]],["t/1368",[89,3.528,158,4.36,296,5.295]],["t/1370",[48,3.784,68,3.964]],["t/1372",[191,5.786]],["t/1376",[71,4.421]],["t/1378",[8,3.687,9,3.687]],["t/1380",[10,3.657,359,5.711]],["t/1381",[72,2.401,103,3.089,178,3.492,291,2.879,534,3.61,535,4.527]],["t/1383",[72,2.659,107,3.493,178,3.868,291,3.188,534,3.998]],["t/1385",[13,2.798,72,2.979,104,4.877,534,4.481]],["t/1386",[73,3.455,125,3.182,476,5.88]],["t/1388",[72,3.388,80,3.455,536,6.389]],["t/1390",[42,3.751,70,3.784]],["t/1392",[53,4.062,70,3.265,85,3.528]],["t/1394",[72,2.659,89,2.769,147,3.356,534,3.998,537,5.015]],["t/1396",[92,3.784,147,4.277,538,6.389]],["t/1398",[19,3.466,72,2.979,96,4.099,534,4.481]],["t/1400",[11,3.455,12,3.421,48,3.265]],["t/1402",[57,4.503,68,3.964]],["t/1406",[71,4.421]],["t/1408",[8,3.687,9,3.687]],["t/1410",[10,2.477,82,2.219,132,1.8,304,4.155,539,4.615]],["t/1412",[53,4.062,103,4.36,116,4.36]],["t/1414",[127,4.708,540,7.404]],["t/1416",[56,3.566,138,4.129,541,6.389]],["t/1418",[82,2.219,94,3.356,132,1.8,441,3.998,542,5.015]],["t/1420",[18,3.105,119,3.784,543,6.389]],["t/1422",[29,5.295,107,4.45,539,5.88]],["t/1424",[13,2.798,55,4.099,125,2.798,544,4.877]],["t/1426",[55,4.661,73,3.455,545,6.389]],["t/1428",[80,2.449,125,2.255,132,1.625,400,3.752,546,4.527,547,4.527]],["t/1430",[55,3.658,129,2.897,544,4.352,548,4.615,549,5.015]],["t/1432",[11,3.455,12,3.421,42,3.237]],["t/1433",[7,3.868,12,2.685,48,2.563,191,3.296,409,4.615]],["t/1435",[57,4.503,68,3.964]],["t/1439",[71,4.421]],["t/1441",[8,3.687,9,3.687]],["t/1443",[10,3.156,11,3.455,12,3.421]],["t/1444",[13,2.255,454,4.167,548,4.167,550,4.167,551,4.527,552,4.167]],["t/1446",[553,8.802]],["t/1448",[138,5.688]],["t/1450",[100,6.136,552,6.814]],["t/1452",[335,7.019]],["t/1454",[550,6.814,554,6.814]],["t/1456",[42,3.751,70,3.784]],["t/1457",[85,2.769,483,4.615,555,5.015,556,5.015,557,5.015]],["t/1458",[89,3.528,153,4.277,558,6.389]],["t/1459",[92,4.385,559,7.404]],["t/1460",[58,5.157,59,5.157]],["t/1461",[48,3.784,191,4.867]],["t/1465",[71,4.421]],["t/1467",[8,3.687,9,3.687]],["t/1469",[10,3.156,11,3.455,12,3.421]],["t/1470",[18,2.437,86,2.586,93,3.571,103,3.422,168,3.188]],["t/1472",[44,3.328,107,3.914,132,2.017,351,4.334]],["t/1474",[110,4.481,560,5.619,561,5.619,562,5.619]],["t/1476",[13,3.687,359,5.711]],["t/1478",[42,3.751,563,6.814]],["t/1480",[82,2.828,85,3.528,132,2.293]],["t/1482",[89,3.103,426,4.481,564,5.619,565,5.171]],["t/1484",[106,4.656,420,4.656,426,4.481,478,4.877]],["t/1486",[420,4.656,426,4.481,480,4.877,566,5.171]],["t/1488",[92,4.385,567,7.404]],["t/1490",[48,3.784,70,3.784]],["t/1491",[56,4.133,179,4.956]],["t/1493",[127,4.708,186,4.956]],["t/1495",[118,4.443,220,5.052]],["t/1497",[50,3.464,57,4.503]],["t/1498",[50,2.346,222,3.998,568,4.615,569,4.615,570,4.615]],["t/1500",[50,2.346,225,3.998,376,3.868,569,4.615,570,4.615]],["t/1502",[67,4.2,147,4.277,192,4.45]],["t/1504",[132,2.46,211,3.929,369,3.929,396,3.752,571,4.527]],["t/1506",[19,3.941,291,4.062,398,5.295]],["t/1508",[404,5.295,426,5.095,572,6.389]],["t/1510",[132,2.293,324,4.661,523,5.545]],["t/1512",[55,4.099,132,2.017,429,4.002,524,4.877]],["t/1514",[68,3.964,254,5.546]],["t/1516",[191,5.786]],["t/1518",[231,7.639]],["t/1519",[50,2.629,182,4.656,448,4.334,573,5.619]],["t/1520",[66,3.756,106,4.155,421,4.352,503,4.615,566,4.615]],["t/1522",[55,4.661,563,5.88,574,6.389]],["t/1524",[66,4.209,421,4.877,438,4.656,575,5.619]],["t/1526",[88,3.29,132,1.481,264,3.183,461,3.42,532,3.798,576,4.127,577,4.127]],["t/1530",[466,6.814,578,6.814]],["t/1532",[578,6.814,579,6.814]],["t/1534",[580,8.802]],["t/1535",[7,4.928,581,6.389,582,6.389]],["t/1537",[7,7.491]],["t/1539",[7,7.491]],["t/1543",[71,4.421]],["t/1545",[8,3.687,9,3.687]],["t/1547",[10,3.156,11,3.455,12,3.421]],["t/1548",[13,2.798,72,2.979,116,3.834,119,3.328]],["t/1549",[73,3.039,420,4.656,568,5.171,583,5.619]],["t/1551",[56,4.133,80,4.004]],["t/1553",[125,3.687,129,4.277]],["t/1555",[94,3.761,137,3.694,584,5.619,585,5.619]],["t/1557",[86,3.818,217,5.904]],["t/1559",[138,4.785,357,6.814]],["t/1561",[42,3.751,50,3.464]],["t/1562",[50,2.629,85,3.103,424,5.171,586,5.619]],["t/1564",[50,2.346,56,2.799,89,2.769,351,3.868,587,5.015]],["t/1566",[50,2.989,92,3.784,130,5.88]],["t/1568",[48,3.784,192,5.157]],["t/1569",[179,3.761,588,5.619,589,5.171,590,5.619]],["t/1571",[186,4.956,589,6.814]],["t/1572",[191,4.867,220,5.052]],["t/1574",[591,8.802]],["t/1576",[72,4.667]],["t/1578",[191,5.786]],["t/1582",[592,7.404,593,7.404]],["t/1586",[594,5.095,595,5.295,596,6.389]],["t/1592",[594,5.095,595,5.295,597,5.545]],["t/1594",[598,6.814,599,7.404]],["t/1598",[6,5.904,600,6.814]],["t/1603",[594,5.095,597,5.545,601,5.545]],["t/1605",[601,5.545,602,5.88,603,5.88]],["t/1607",[369,5.545,379,5.295,601,5.545]],["t/1611",[594,4.481,595,4.656,604,5.171,605,5.171]],["t/1613",[594,4.481,595,4.656,605,5.171,606,5.619]],["t/1617",[607,7.404,608,7.404]],["t/1619",[609,8.802]],["t/1621",[22,7.019]],["t/1623",[276,5.546,610,7.404]],["t/1625",[611,8.802]],["t/1627",[160,5.545,604,5.88,612,6.389]],["t/1631",[598,6.814,613,7.404]],["t/1633",[224,6.814,597,6.426]],["t/1635",[1,5.545,6,5.095,614,5.545]],["t/1637",[602,5.88,603,5.88,614,5.545]],["t/1639",[6,5.095,600,5.88,614,5.545]],["t/1643",[71,4.421]],["t/1645",[8,3.687,9,3.687]],["t/1647",[10,3.657,359,5.711]],["t/1648",[13,2.497,82,2.219,132,1.8,615,5.015,616,3.756]],["t/1650",[73,3.039,616,4.209,617,5.619,618,5.619]],["t/1652",[80,3.455,125,3.182,507,5.295]],["t/1654",[35,4.155,109,4.155,129,2.897,132,1.8,619,5.015]],["t/1656",[35,4.155,125,2.497,132,1.8,137,3.296,620,5.015]],["t/1658",[35,3.752,132,1.625,217,3.61,234,3.492,621,4.167,622,4.527]],["t/1660",[42,3.751,70,3.784]],["t/1661",[11,3.039,50,2.629,85,3.103,177,4.334]],["t/1662",[56,4.913]],["t/1664",[118,3.834,119,3.784,127,4.062]],["t/1666",[41,3.493,81,3.356,82,2.219,401,3.868,616,3.756]],["t/1668",[41,3.493,82,2.219,132,1.8,401,3.868,616,3.756]],["t/1670",[50,2.629,89,3.103,623,5.619,624,5.619]],["t/1671",[56,4.913]],["t/1673",[118,3.834,119,3.784,127,4.062]],["t/1675",[41,3.914,127,3.573,401,4.334,616,4.209]],["t/1677",[50,2.629,92,3.328,177,4.334,625,5.619]],["t/1679",[56,4.913]],["t/1681",[118,3.834,119,3.784,127,4.062]],["t/1683",[41,3.914,127,3.573,401,4.334,616,4.209]],["t/1685",[96,4.661,616,4.786,626,6.389]],["t/1687",[11,3.455,12,3.421,48,3.265]],["t/1688",[57,4.503,68,3.964]],["t/1692",[71,4.421]],["t/1694",[8,2.055,168,2.624,418,3.581,423,3.798,554,3.798,627,4.127,628,4.127]],["t/1696",[10,2.775,132,2.017,629,5.619,630,5.619]],["t/1697",[44,3.328,101,4.877,103,3.834,351,4.334]],["t/1699",[107,4.45,132,2.293,631,6.389]],["t/1701",[132,2.293,178,4.928,632,6.389]],["t/1703",[39,5.295,246,4.2,633,6.389]],["t/1705",[246,4.2,634,6.389,635,6.389]],["t/1707",[16,3.761,110,4.481,132,2.017,636,5.619]],["t/1709",[13,2.798,132,2.017,264,4.334,637,4.656]],["t/1711",[73,3.455,132,2.293,638,5.88]],["t/1713",[80,3.039,264,4.334,637,4.656,639,5.171]],["t/1715",[44,3.328,129,3.246,264,4.334,640,5.619]],["t/1717",[132,2.293,467,5.88,641,5.88]],["t/1719",[132,2.293,469,5.88,642,5.88]],["t/1721",[42,2.846,132,2.017,246,3.694,637,4.656]],["t/1723",[85,3.528,246,4.2,638,5.88]],["t/1725",[16,3.356,72,2.659,89,2.769,246,3.296,579,4.615]],["t/1727",[16,4.277,478,5.545,639,5.88]],["t/1729",[39,4.656,246,3.694,480,4.877,641,5.171]],["t/1731",[39,4.656,246,3.694,481,5.171,642,5.171]],["t/1733",[44,3.328,48,2.871,132,2.017,154,3.694]],["t/1735",[132,2.293,179,4.277,236,5.295]],["t/1737",[132,2.293,186,4.277,643,6.389]],["t/1739",[132,2.293,220,4.36,644,6.389]],["t/1741",[132,2.293,221,4.928,507,5.295]],["t/1743",[18,2.437,57,3.05,72,2.659,132,1.8,188,4.155]],["t/1745",[18,3.105,117,4.36,222,5.095]],["t/1747",[72,2.979,225,4.481,291,3.573,379,4.656]],["t/1749",[81,3.761,82,2.487,645,5.619,646,5.619]],["t/1751",[82,2.487,132,2.017,194,5.171,647,5.619]],["t/1753",[82,2.219,132,1.8,286,3.868,648,5.015,649,4.615]],["t/1755",[82,2.219,132,1.8,286,3.868,649,4.615,650,5.015]],["t/1757",[82,2.828,651,6.389,652,6.389]],["t/1759",[67,4.867,210,6.426]],["t/1761",[156,4.928,396,5.295,474,5.88]],["t/1763",[398,5.295,544,5.545,565,5.88]],["t/1765",[125,2.798,177,4.334,265,4.481,404,4.656]],["t/1767",[262,5.545,523,5.545,653,6.389]],["t/1769",[153,4.277,351,4.928,524,5.545]],["t/1771",[246,4.2,263,4.786,654,6.389]],["t/1773",[4,3.886,283,4.786,655,6.389]],["t/1775",[4,3.05,138,3.24,283,3.756,656,5.015,657,5.015]],["t/1777",[210,5.545,658,6.389,659,6.389]],["t/1779",[44,3.328,154,3.694,155,3.914,660,5.619]],["t/1781",[132,2.017,254,4.209,267,5.171,661,5.619]],["t/1783",[320,6.814,662,7.404]],["t/1785",[18,2.437,93,3.571,286,3.868,663,5.015,664,4.615]],["t/1787",[16,4.277,132,2.293,665,6.389]],["t/1789",[132,2.017,246,3.694,637,4.656,666,5.619]],["t/1791",[82,2.487,188,4.656,664,5.171,667,5.619]],["t/1793",[44,3.328,132,2.017,621,5.171,668,5.619]],["t/1795",[132,1.8,147,3.356,362,4.352,669,5.015,670,5.015]],["t/1797",[55,4.661,132,2.293,671,6.389]],["t/1799",[64,4.209,327,5.171,672,5.619,673,5.619]],["t/1801",[72,2.979,132,2.017,674,5.619,675,5.619]]],"invertedIndex":[["",{"_index":7,"t":{"22":{"position":[[0,2]]},"105":{"position":[[9,1]]},"1433":{"position":[[15,1]]},"1535":{"position":[[6,1]]},"1537":{"position":[[0,2],[3,1]]},"1539":{"position":[[0,1],[2,3]]}}}],["1",{"_index":8,"t":{"24":{"position":[[0,2]]},"85":{"position":[[0,2]]},"125":{"position":[[0,2]]},"164":{"position":[[0,2]]},"214":{"position":[[0,2]]},"220":{"position":[[0,2]]},"284":{"position":[[0,2]]},"383":{"position":[[0,2]]},"435":{"position":[[0,2]]},"484":{"position":[[0,2]]},"522":{"position":[[0,2]]},"538":{"position":[[0,2]]},"588":{"position":[[0,2]]},"627":{"position":[[0,2]]},"657":{"position":[[0,2]]},"680":{"position":[[0,2]]},"718":{"position":[[0,2]]},"785":{"position":[[0,2]]},"848":{"position":[[0,2]]},"886":{"position":[[0,2]]},"933":{"position":[[0,2]]},"978":{"position":[[0,2]]},"1013":{"position":[[0,2]]},"1061":{"position":[[0,2]]},"1092":{"position":[[0,2]]},"1125":{"position":[[0,2]]},"1158":{"position":[[0,2]]},"1226":{"position":[[0,2]]},"1290":{"position":[[0,2]]},"1346":{"position":[[0,2]]},"1378":{"position":[[0,2]]},"1408":{"position":[[0,2]]},"1441":{"position":[[0,1]]},"1467":{"position":[[0,2]]},"1545":{"position":[[0,2]]},"1645":{"position":[[0,2]]},"1694":{"position":[[0,2]]}}}],["1.8k",{"_index":302,"t":{"556":{"position":[[34,4]]}}}],["10",{"_index":139,"t":{"183":{"position":[[19,2]]}}}],["175b",{"_index":395,"t":{"764":{"position":[[24,4]]}}}],["2",{"_index":10,"t":{"26":{"position":[[0,2]]},"87":{"position":[[0,2]]},"127":{"position":[[0,2]]},"166":{"position":[[0,2]]},"222":{"position":[[0,2]]},"286":{"position":[[0,2]]},"385":{"position":[[0,2]]},"437":{"position":[[0,2]]},"486":{"position":[[0,2]]},"524":{"position":[[0,2]]},"540":{"position":[[0,2]]},"590":{"position":[[0,2]]},"629":{"position":[[0,2]]},"637":{"position":[[25,1]]},"659":{"position":[[0,2]]},"682":{"position":[[0,2]]},"722":{"position":[[0,2]]},"762":{"position":[[8,1]]},"787":{"position":[[0,2]]},"850":{"position":[[0,2]]},"888":{"position":[[0,2]]},"935":{"position":[[0,2]]},"980":{"position":[[0,2]]},"1015":{"position":[[0,2]]},"1063":{"position":[[0,2]]},"1094":{"position":[[0,2]]},"1127":{"position":[[0,2]]},"1160":{"position":[[0,2]]},"1228":{"position":[[0,2]]},"1292":{"position":[[0,2]]},"1348":{"position":[[0,2]]},"1380":{"position":[[0,2]]},"1410":{"position":[[0,2]]},"1443":{"position":[[0,1]]},"1469":{"position":[[0,2]]},"1547":{"position":[[0,2]]},"1647":{"position":[[0,2]]},"1696":{"position":[[0,1]]}}}],["2.1",{"_index":103,"t":{"129":{"position":[[0,3]]},"438":{"position":[[0,3]]},"542":{"position":[[0,4]]},"661":{"position":[[0,3]]},"1064":{"position":[[0,3]]},"1129":{"position":[[0,3]]},"1349":{"position":[[0,3]]},"1381":{"position":[[0,3]]},"1412":{"position":[[0,3]]},"1470":{"position":[[0,3]]},"1697":{"position":[[0,3]]}}}],["2.1.1",{"_index":540,"t":{"1414":{"position":[[0,5]]}}}],["2.1.2",{"_index":541,"t":{"1416":{"position":[[0,5]]}}}],["2.1.3",{"_index":542,"t":{"1418":{"position":[[0,5]]}}}],["2.1.4",{"_index":543,"t":{"1420":{"position":[[0,5]]}}}],["2.2",{"_index":107,"t":{"131":{"position":[[0,3]]},"440":{"position":[[0,3]]},"549":{"position":[[0,4]]},"1066":{"position":[[0,3]]},"1131":{"position":[[0,3]]},"1351":{"position":[[0,3]]},"1383":{"position":[[0,3]]},"1422":{"position":[[0,3]]},"1472":{"position":[[0,3]]},"1699":{"position":[[0,3]]}}}],["2.2.1",{"_index":632,"t":{"1701":{"position":[[0,5]]}}}],["2.2.2",{"_index":633,"t":{"1703":{"position":[[0,5]]}}}],["2.2.3",{"_index":634,"t":{"1705":{"position":[[0,5]]}}}],["2.3",{"_index":110,"t":{"133":{"position":[[0,3]]},"551":{"position":[[0,4]]},"1353":{"position":[[0,3]]},"1474":{"position":[[0,3]]},"1707":{"position":[[0,3]]}}}],["2.4",{"_index":113,"t":{"139":{"position":[[0,3]]}}}],["20",{"_index":468,"t":{"1079":{"position":[[58,3]]}}}],["2019",{"_index":463,"t":{"1074":{"position":[[26,4]]}}}],["3",{"_index":13,"t":{"28":{"position":[[0,2]]},"89":{"position":[[0,2]]},"141":{"position":[[0,2]]},"167":{"position":[[0,2]]},"223":{"position":[[0,2]]},"288":{"position":[[0,2]]},"387":{"position":[[0,2]]},"446":{"position":[[0,2]]},"487":{"position":[[0,2]]},"526":{"position":[[0,2]]},"556":{"position":[[0,2]]},"591":{"position":[[0,2]]},"631":{"position":[[0,2]]},"663":{"position":[[0,2]]},"684":{"position":[[0,2]]},"724":{"position":[[0,2]]},"764":{"position":[[22,1]]},"792":{"position":[[0,2]]},"852":{"position":[[0,2]]},"889":{"position":[[0,2]]},"936":{"position":[[0,2]]},"981":{"position":[[0,2]]},"1020":{"position":[[0,2]]},"1068":{"position":[[0,2]]},"1096":{"position":[[0,2]]},"1133":{"position":[[0,2]]},"1165":{"position":[[0,1]]},"1235":{"position":[[0,2]]},"1293":{"position":[[0,2]]},"1355":{"position":[[0,1]]},"1385":{"position":[[0,2]]},"1424":{"position":[[0,2]]},"1444":{"position":[[0,1]]},"1476":{"position":[[0,2]]},"1548":{"position":[[0,2]]},"1648":{"position":[[0,2]]},"1709":{"position":[[0,1]]}}}],["3.1",{"_index":73,"t":{"90":{"position":[[0,3]]},"142":{"position":[[0,3]]},"169":{"position":[[0,3]]},"224":{"position":[[0,3]]},"290":{"position":[[0,3]]},"389":{"position":[[0,4]]},"448":{"position":[[0,3]]},"489":{"position":[[0,4]]},"593":{"position":[[0,3]]},"632":{"position":[[0,3]]},"665":{"position":[[0,3]]},"685":{"position":[[0,3]]},"794":{"position":[[0,3]]},"890":{"position":[[0,3]]},"983":{"position":[[0,3]]},"1021":{"position":[[0,3]]},"1069":{"position":[[0,3]]},"1098":{"position":[[0,3]]},"1135":{"position":[[0,3]]},"1166":{"position":[[0,3]]},"1239":{"position":[[0,3]]},"1295":{"position":[[0,3]]},"1356":{"position":[[0,3]]},"1386":{"position":[[0,3]]},"1426":{"position":[[0,3]]},"1549":{"position":[[0,3]]},"1650":{"position":[[0,3]]},"1711":{"position":[[0,3]]}}}],["3.2",{"_index":80,"t":{"96":{"position":[[0,3]]},"154":{"position":[[0,3]]},"171":{"position":[[0,3]]},"226":{"position":[[0,3]]},"295":{"position":[[0,3]]},"398":{"position":[[0,4]]},"450":{"position":[[0,3]]},"495":{"position":[[0,4]]},"595":{"position":[[0,3]]},"636":{"position":[[0,3]]},"667":{"position":[[0,3]]},"687":{"position":[[0,3]]},"796":{"position":[[0,3]]},"892":{"position":[[0,3]]},"985":{"position":[[0,3]]},"1027":{"position":[[0,3]]},"1071":{"position":[[0,3]]},"1100":{"position":[[0,3]]},"1137":{"position":[[0,3]]},"1168":{"position":[[0,3]]},"1245":{"position":[[0,3]]},"1297":{"position":[[0,3]]},"1358":{"position":[[0,3]]},"1388":{"position":[[0,3]]},"1428":{"position":[[0,3]]},"1551":{"position":[[0,3]]},"1652":{"position":[[0,3]]},"1713":{"position":[[0,3]]}}}],["3.2.1",{"_index":203,"t":{"297":{"position":[[0,5]]},"637":{"position":[[0,5]]},"987":{"position":[[0,5]]},"1072":{"position":[[0,5]]},"1359":{"position":[[0,5]]}}}],["3.2.2",{"_index":207,"t":{"299":{"position":[[0,5]]},"639":{"position":[[0,5]]},"989":{"position":[[0,5]]},"1074":{"position":[[0,5]]},"1361":{"position":[[0,5]]}}}],["3.2.3",{"_index":209,"t":{"301":{"position":[[0,5]]},"641":{"position":[[0,5]]},"1363":{"position":[[0,5]]}}}],["3.2.4",{"_index":347,"t":{"643":{"position":[[0,5]]}}}],["3.3",{"_index":129,"t":{"156":{"position":[[0,3]]},"173":{"position":[[0,3]]},"228":{"position":[[0,3]]},"303":{"position":[[0,3]]},"400":{"position":[[0,4]]},"456":{"position":[[0,3]]},"503":{"position":[[0,4]]},"597":{"position":[[0,3]]},"645":{"position":[[0,3]]},"669":{"position":[[0,3]]},"689":{"position":[[0,3]]},"802":{"position":[[0,3]]},"894":{"position":[[0,3]]},"991":{"position":[[0,3]]},"1029":{"position":[[0,3]]},"1078":{"position":[[0,3]]},"1177":{"position":[[0,3]]},"1299":{"position":[[0,3]]},"1430":{"position":[[0,3]]},"1553":{"position":[[0,3]]},"1654":{"position":[[0,3]]},"1715":{"position":[[0,3]]}}}],["3.3.1",{"_index":467,"t":{"1079":{"position":[[0,5]]},"1717":{"position":[[0,5]]}}}],["3.3.2",{"_index":469,"t":{"1081":{"position":[[0,5]]},"1719":{"position":[[0,5]]}}}],["3.3.3",{"_index":465,"t":{"1076":{"position":[[0,5]]}}}],["3.4",{"_index":137,"t":{"175":{"position":[[0,3]]},"235":{"position":[[0,3]]},"305":{"position":[[0,3]]},"408":{"position":[[0,4]]},"458":{"position":[[0,3]]},"505":{"position":[[0,4]]},"599":{"position":[[0,3]]},"671":{"position":[[0,3]]},"896":{"position":[[0,3]]},"993":{"position":[[0,3]]},"1083":{"position":[[0,3]]},"1555":{"position":[[0,3]]},"1656":{"position":[[0,3]]}}}],["3.5",{"_index":217,"t":{"307":{"position":[[0,3]]},"601":{"position":[[0,3]]},"673":{"position":[[0,3]]},"1557":{"position":[[0,3]]},"1658":{"position":[[0,3]]}}}],["3.6",{"_index":357,"t":{"675":{"position":[[0,3]]},"1559":{"position":[[0,3]]}}}],["4",{"_index":42,"t":{"45":{"position":[[0,2]]},"98":{"position":[[0,2]]},"180":{"position":[[0,2]]},"237":{"position":[[0,2]]},"309":{"position":[[0,2]]},"410":{"position":[[0,2]]},"460":{"position":[[0,2]]},"513":{"position":[[0,2]]},"528":{"position":[[0,2]]},"558":{"position":[[0,2]]},"603":{"position":[[0,2]]},"647":{"position":[[0,2]]},"677":{"position":[[0,2]]},"691":{"position":[[0,2]]},"730":{"position":[[0,2]]},"804":{"position":[[0,2]]},"854":{"position":[[0,2]]},"902":{"position":[[0,2]]},"943":{"position":[[0,2]]},"995":{"position":[[0,2]]},"1038":{"position":[[0,2]]},"1085":{"position":[[0,2]]},"1102":{"position":[[0,2]]},"1144":{"position":[[0,2]]},"1179":{"position":[[0,2]]},"1249":{"position":[[0,2]]},"1301":{"position":[[0,2]]},"1365":{"position":[[0,2]]},"1390":{"position":[[0,2]]},"1432":{"position":[[0,2]]},"1456":{"position":[[0,1]]},"1478":{"position":[[0,2]]},"1561":{"position":[[0,2]]},"1660":{"position":[[0,2]]},"1721":{"position":[[0,1]]}}}],["4.1",{"_index":85,"t":{"100":{"position":[[0,3]]},"181":{"position":[[0,3]]},"238":{"position":[[0,3]]},"462":{"position":[[0,3]]},"514":{"position":[[0,4]]},"560":{"position":[[0,4]]},"605":{"position":[[0,3]]},"693":{"position":[[0,3]]},"732":{"position":[[0,3]]},"810":{"position":[[0,3]]},"856":{"position":[[0,3]]},"903":{"position":[[0,3]]},"944":{"position":[[0,3]]},"996":{"position":[[0,3]]},"1046":{"position":[[0,3]]},"1104":{"position":[[0,3]]},"1180":{"position":[[0,3]]},"1251":{"position":[[0,3]]},"1302":{"position":[[0,3]]},"1366":{"position":[[0,3]]},"1392":{"position":[[0,3]]},"1457":{"position":[[0,3]]},"1480":{"position":[[0,3]]},"1562":{"position":[[0,3]]},"1661":{"position":[[0,3]]},"1723":{"position":[[0,3]]}}}],["4.1.1",{"_index":475,"t":{"1106":{"position":[[0,5]]}}}],["4.1.2",{"_index":477,"t":{"1108":{"position":[[0,5]]}}}],["4.2",{"_index":89,"t":{"109":{"position":[[0,3]]},"183":{"position":[[0,3]]},"240":{"position":[[0,3]]},"469":{"position":[[0,3]]},"516":{"position":[[0,4]]},"562":{"position":[[0,4]]},"607":{"position":[[0,3]]},"695":{"position":[[0,3]]},"738":{"position":[[0,3]]},"817":{"position":[[0,3]]},"858":{"position":[[0,3]]},"910":{"position":[[0,3]]},"948":{"position":[[0,3]]},"998":{"position":[[0,3]]},"1048":{"position":[[0,3]]},"1110":{"position":[[0,3]]},"1182":{"position":[[0,3]]},"1260":{"position":[[0,3]]},"1304":{"position":[[0,3]]},"1368":{"position":[[0,3]]},"1394":{"position":[[0,3]]},"1458":{"position":[[0,3]]},"1482":{"position":[[0,3]]},"1564":{"position":[[0,3]]},"1670":{"position":[[0,3]]},"1725":{"position":[[0,3]]}}}],["4.2.1",{"_index":478,"t":{"1112":{"position":[[0,5]]},"1484":{"position":[[0,5]]},"1727":{"position":[[0,5]]}}}],["4.2.2",{"_index":480,"t":{"1114":{"position":[[0,5]]},"1486":{"position":[[0,5]]},"1729":{"position":[[0,5]]}}}],["4.2.3",{"_index":481,"t":{"1116":{"position":[[0,5]]},"1731":{"position":[[0,5]]}}}],["4.3",{"_index":92,"t":{"111":{"position":[[0,3]]},"200":{"position":[[0,3]]},"247":{"position":[[0,3]]},"476":{"position":[[0,3]]},"564":{"position":[[0,4]]},"617":{"position":[[0,3]]},"697":{"position":[[0,3]]},"824":{"position":[[0,3]]},"860":{"position":[[0,3]]},"915":{"position":[[0,3]]},"952":{"position":[[0,3]]},"1050":{"position":[[0,3]]},"1188":{"position":[[0,3]]},"1271":{"position":[[0,3]]},"1306":{"position":[[0,3]]},"1396":{"position":[[0,3]]},"1459":{"position":[[0,3]]},"1488":{"position":[[0,3]]},"1566":{"position":[[0,3]]},"1677":{"position":[[0,3]]}}}],["4.4",{"_index":96,"t":{"113":{"position":[[0,3]]},"619":{"position":[[0,3]]},"831":{"position":[[0,3]]},"922":{"position":[[0,3]]},"954":{"position":[[0,3]]},"1190":{"position":[[0,3]]},"1398":{"position":[[0,3]]},"1685":{"position":[[0,3]]}}}],["4.5",{"_index":97,"t":{"115":{"position":[[0,3]]}}}],["4.6",{"_index":99,"t":{"117":{"position":[[0,3]]}}}],["5",{"_index":48,"t":{"50":{"position":[[0,2]]},"119":{"position":[[0,2]]},"158":{"position":[[0,2]]},"208":{"position":[[0,2]]},"254":{"position":[[0,2]]},"311":{"position":[[0,2]]},"417":{"position":[[0,2]]},"478":{"position":[[0,2]]},"530":{"position":[[0,2]]},"566":{"position":[[0,2]]},"621":{"position":[[0,2]]},"649":{"position":[[0,2]]},"699":{"position":[[0,2]]},"742":{"position":[[0,2]]},"842":{"position":[[0,2]]},"862":{"position":[[0,2]]},"927":{"position":[[0,2]]},"956":{"position":[[0,2]]},"1000":{"position":[[0,2]]},"1055":{"position":[[0,2]]},"1086":{"position":[[0,2]]},"1118":{"position":[[0,2]]},"1146":{"position":[[0,2]]},"1192":{"position":[[0,2]]},"1284":{"position":[[0,2]]},"1308":{"position":[[0,2]]},"1370":{"position":[[0,2]]},"1400":{"position":[[0,2]]},"1433":{"position":[[0,2]]},"1461":{"position":[[0,1]]},"1490":{"position":[[0,2]]},"1568":{"position":[[0,2]]},"1687":{"position":[[0,2]]},"1733":{"position":[[0,1]]}}}],["5.1",{"_index":179,"t":{"256":{"position":[[0,3]]},"312":{"position":[[0,3]]},"700":{"position":[[0,3]]},"744":{"position":[[0,3]]},"863":{"position":[[0,3]]},"957":{"position":[[0,3]]},"1001":{"position":[[0,3]]},"1193":{"position":[[0,3]]},"1309":{"position":[[0,3]]},"1491":{"position":[[0,3]]},"1569":{"position":[[0,3]]},"1735":{"position":[[0,3]]}}}],["5.1.1",{"_index":497,"t":{"1194":{"position":[[0,5]]}}}],["5.1.2",{"_index":498,"t":{"1196":{"position":[[0,5]]}}}],["5.2",{"_index":186,"t":{"263":{"position":[[0,3]]},"314":{"position":[[0,3]]},"702":{"position":[[0,3]]},"758":{"position":[[0,3]]},"865":{"position":[[0,3]]},"962":{"position":[[0,3]]},"1003":{"position":[[0,3]]},"1198":{"position":[[0,3]]},"1311":{"position":[[0,3]]},"1493":{"position":[[0,3]]},"1571":{"position":[[0,3]]},"1737":{"position":[[0,3]]}}}],["5.3",{"_index":220,"t":{"316":{"position":[[0,3]]},"704":{"position":[[0,3]]},"760":{"position":[[0,3]]},"867":{"position":[[0,3]]},"964":{"position":[[0,3]]},"1005":{"position":[[0,3]]},"1200":{"position":[[0,3]]},"1313":{"position":[[0,3]]},"1495":{"position":[[0,3]]},"1572":{"position":[[0,3]]},"1739":{"position":[[0,3]]}}}],["5.4",{"_index":221,"t":{"318":{"position":[[0,3]]},"706":{"position":[[0,3]]},"762":{"position":[[0,3]]},"869":{"position":[[0,3]]},"1202":{"position":[[0,3]]},"1741":{"position":[[0,3]]}}}],["5.5",{"_index":394,"t":{"764":{"position":[[0,3]]},"1204":{"position":[[0,3]]}}}],["5.6",{"_index":500,"t":{"1206":{"position":[[0,3]]}}}],["540b",{"_index":301,"t":{"556":{"position":[[14,4]]}}}],["6",{"_index":57,"t":{"66":{"position":[[0,2]]},"270":{"position":[[0,2]]},"320":{"position":[[0,2]]},"425":{"position":[[0,2]]},"532":{"position":[[0,2]]},"568":{"position":[[0,2]]},"708":{"position":[[0,2]]},"766":{"position":[[0,2]]},"871":{"position":[[0,2]]},"972":{"position":[[0,2]]},"1119":{"position":[[0,2]]},"1148":{"position":[[0,2]]},"1315":{"position":[[0,2]]},"1402":{"position":[[0,2]]},"1435":{"position":[[0,2]]},"1497":{"position":[[0,2]]},"1688":{"position":[[0,2]]},"1743":{"position":[[0,1]]}}}],["6.1",{"_index":222,"t":{"321":{"position":[[0,3]]},"872":{"position":[[0,3]]},"1316":{"position":[[0,3]]},"1498":{"position":[[0,3]]},"1745":{"position":[[0,3]]}}}],["6.2",{"_index":225,"t":{"323":{"position":[[0,3]]},"874":{"position":[[0,3]]},"1318":{"position":[[0,3]]},"1500":{"position":[[0,3]]},"1747":{"position":[[0,3]]}}}],["6.2.1",{"_index":645,"t":{"1749":{"position":[[0,5]]}}}],["6.2.2",{"_index":647,"t":{"1751":{"position":[[0,5]]}}}],["6.2.3",{"_index":648,"t":{"1753":{"position":[[0,5]]}}}],["6.2.4",{"_index":650,"t":{"1755":{"position":[[0,5]]}}}],["6.2.5",{"_index":651,"t":{"1757":{"position":[[0,5]]}}}],["6.3",{"_index":227,"t":{"325":{"position":[[0,3]]},"876":{"position":[[0,3]]},"1320":{"position":[[0,3]]}}}],["6.4",{"_index":518,"t":{"1322":{"position":[[0,3]]}}}],["7",{"_index":67,"t":{"75":{"position":[[0,2]]},"327":{"position":[[0,2]]},"427":{"position":[[0,2]]},"570":{"position":[[0,2]]},"710":{"position":[[0,2]]},"767":{"position":[[0,2]]},"878":{"position":[[0,2]]},"1007":{"position":[[0,2]]},"1150":{"position":[[0,2]]},"1211":{"position":[[0,2]]},"1324":{"position":[[0,2]]},"1502":{"position":[[0,2]]},"1759":{"position":[[0,1]]}}}],["7.1",{"_index":396,"t":{"769":{"position":[[0,3]]},"1325":{"position":[[0,3]]},"1504":{"position":[[0,3]]},"1761":{"position":[[0,3]]}}}],["7.10",{"_index":660,"t":{"1779":{"position":[[0,4]]}}}],["7.2",{"_index":398,"t":{"771":{"position":[[0,3]]},"1327":{"position":[[0,3]]},"1506":{"position":[[0,3]]},"1763":{"position":[[0,3]]}}}],["7.3",{"_index":404,"t":{"777":{"position":[[0,3]]},"1329":{"position":[[0,3]]},"1508":{"position":[[0,3]]},"1765":{"position":[[0,3]]}}}],["7.4",{"_index":523,"t":{"1331":{"position":[[0,3]]},"1510":{"position":[[0,3]]},"1767":{"position":[[0,3]]}}}],["7.5",{"_index":524,"t":{"1333":{"position":[[0,3]]},"1512":{"position":[[0,3]]},"1769":{"position":[[0,3]]}}}],["7.6",{"_index":654,"t":{"1771":{"position":[[0,3]]}}}],["7.7",{"_index":655,"t":{"1773":{"position":[[0,3]]}}}],["7.8",{"_index":656,"t":{"1775":{"position":[[0,3]]}}}],["7.9",{"_index":658,"t":{"1777":{"position":[[0,3]]}}}],["8",{"_index":254,"t":{"429":{"position":[[0,2]]},"779":{"position":[[0,2]]},"880":{"position":[[0,2]]},"1152":{"position":[[0,2]]},"1335":{"position":[[0,2]]},"1514":{"position":[[0,2]]},"1781":{"position":[[0,1]]}}}],["9",{"_index":320,"t":{"582":{"position":[[0,2]]},"1783":{"position":[[0,1]]}}}],["9.1",{"_index":663,"t":{"1785":{"position":[[0,3]]}}}],["9.2",{"_index":665,"t":{"1787":{"position":[[0,3]]}}}],["9.3",{"_index":666,"t":{"1789":{"position":[[0,3]]}}}],["9.4",{"_index":667,"t":{"1791":{"position":[[0,3]]}}}],["9.5",{"_index":668,"t":{"1793":{"position":[[0,3]]}}}],["9.6",{"_index":669,"t":{"1795":{"position":[[0,3]]}}}],["9.7",{"_index":671,"t":{"1797":{"position":[[0,3]]}}}],["9.8",{"_index":672,"t":{"1799":{"position":[[0,3]]}}}],["9.9",{"_index":674,"t":{"1801":{"position":[[0,3]]}}}],["a.6",{"_index":502,"t":{"1217":{"position":[[0,3]]}}}],["abil",{"_index":308,"t":{"562":{"position":[[64,7]]},"574":{"position":[[41,9]]}}}],["ablat",{"_index":58,"t":{"66":{"position":[[3,8]]},"200":{"position":[[4,9]]},"400":{"position":[[5,8]]},"619":{"position":[[4,8]]},"915":{"position":[[4,8]]},"1050":{"position":[[4,8]]},"1137":{"position":[[4,8]]},"1206":{"position":[[4,8]]},"1271":{"position":[[4,8]]},"1460":{"position":[[0,8]]}}}],["abstract",{"_index":71,"t":{"83":{"position":[[0,8]]},"123":{"position":[[0,8]]},"162":{"position":[[0,8]]},"212":{"position":[[0,8]]},"218":{"position":[[0,8]]},"282":{"position":[[0,8]]},"333":{"position":[[0,8]]},"381":{"position":[[0,8]]},"433":{"position":[[0,8]]},"482":{"position":[[0,8]]},"520":{"position":[[0,8]]},"536":{"position":[[0,8]]},"586":{"position":[[0,8]]},"625":{"position":[[0,8]]},"655":{"position":[[0,8]]},"716":{"position":[[0,8]]},"783":{"position":[[0,8]]},"846":{"position":[[0,8]]},"884":{"position":[[0,8]]},"931":{"position":[[0,8]]},"976":{"position":[[0,8]]},"1011":{"position":[[0,8]]},"1059":{"position":[[0,8]]},"1090":{"position":[[0,8]]},"1123":{"position":[[0,8]]},"1156":{"position":[[0,8]]},"1224":{"position":[[0,8]]},"1288":{"position":[[0,8]]},"1344":{"position":[[0,8]]},"1376":{"position":[[0,8]]},"1406":{"position":[[0,8]]},"1439":{"position":[[0,8]]},"1465":{"position":[[0,8]]},"1543":{"position":[[0,8]]},"1643":{"position":[[0,8]]},"1692":{"position":[[0,8]]}}}],["actor",{"_index":553,"t":{"1446":{"position":[[0,5]]}}}],["adalora",{"_index":410,"t":{"792":{"position":[[3,7]]}}}],["adapt",{"_index":46,"t":{"48":{"position":[[26,8]]},"73":{"position":[[14,8]]},"274":{"position":[[10,10]]},"505":{"position":[[5,10]]},"659":{"position":[[3,7]]},"726":{"position":[[0,7]]},"754":{"position":[[0,7]]},"777":{"position":[[17,10]]},"790":{"position":[[9,10]]},"794":{"position":[[14,10]]},"889":{"position":[[9,7]]},"890":{"position":[[14,10]]},"936":{"position":[[22,7]]},"943":{"position":[[9,7]]},"1003":{"position":[[20,11]]},"1245":{"position":[[31,10]]},"1261":{"position":[[13,10]]},"1263":{"position":[[9,10]]},"1278":{"position":[[7,10]]}}}],["adaptor",{"_index":165,"t":{"233":{"position":[[12,7]]},"264":{"position":[[0,7]]}}}],["add",{"_index":602,"t":{"1605":{"position":[[0,3]]},"1637":{"position":[[0,3]]}}}],["addit",{"_index":178,"t":{"254":{"position":[[3,10]]},"669":{"position":[[4,10]]},"736":{"position":[[3,10]]},"1381":{"position":[[25,10]]},"1383":{"position":[[22,10]]},"1701":{"position":[[13,8]]}}}],["admonit",{"_index":611,"t":{"1625":{"position":[[0,11]]}}}],["advanc",{"_index":256,"t":{"438":{"position":[[11,8]]}}}],["alfworld",{"_index":557,"t":{"1457":{"position":[[32,8]]}}}],["algorithm",{"_index":580,"t":{"1534":{"position":[[0,9]]}}}],["align",{"_index":589,"t":{"1569":{"position":[[21,9]]},"1571":{"position":[[15,8]]}}}],["alloc",{"_index":412,"t":{"796":{"position":[[26,10]]}}}],["analys",{"_index":446,"t":{"1005":{"position":[[4,8]]}}}],["analysi",{"_index":147,"t":{"200":{"position":[[24,8]]},"254":{"position":[[14,8]]},"675":{"position":[[4,8]]},"708":{"position":[[3,8]]},"831":{"position":[[4,8]]},"871":{"position":[[3,8]]},"1083":{"position":[[12,8]]},"1260":{"position":[[16,8]]},"1394":{"position":[[4,8]]},"1396":{"position":[[4,8]]},"1502":{"position":[[3,8]]},"1795":{"position":[[30,8]]}}}],["analyz",{"_index":509,"t":{"1269":{"position":[[0,9]]}}}],["annot",{"_index":303,"t":{"558":{"position":[[36,11]]}}}],["answer",{"_index":246,"t":{"406":{"position":[[23,6]]},"448":{"position":[[4,6]]},"673":{"position":[[30,9]]},"817":{"position":[[13,9]]},"1703":{"position":[[6,6]]},"1705":{"position":[[6,6]]},"1721":{"position":[[9,6]]},"1723":{"position":[[4,6]]},"1725":{"position":[[4,6]]},"1729":{"position":[[15,6]]},"1731":{"position":[[17,6]]},"1771":{"position":[[13,9]]},"1789":{"position":[[11,6]]}}}],["api",{"_index":586,"t":{"1562":{"position":[[19,3]]}}}],["appendix",{"_index":231,"t":{"329":{"position":[[0,8]]},"1215":{"position":[[0,8]]},"1518":{"position":[[0,8]]}}}],["appli",{"_index":382,"t":{"738":{"position":[[4,8]]},"769":{"position":[[51,5]]}}}],["applic",{"_index":210,"t":{"301":{"position":[[6,12]]},"1759":{"position":[[2,12]]},"1777":{"position":[[9,12]]}}}],["approach",{"_index":102,"t":{"127":{"position":[[3,8]]},"1066":{"position":[[8,9]]},"1144":{"position":[[25,10]]},"1220":{"position":[[43,10]]},"1235":{"position":[[3,8]]}}}],["approch",{"_index":131,"t":{"167":{"position":[[3,7]]}}}],["archirectur",{"_index":513,"t":{"1297":{"position":[[20,12]]}}}],["architectur",{"_index":15,"t":{"28":{"position":[[18,12]]},"39":{"position":[[15,12]]},"94":{"position":[[7,12]]},"131":{"position":[[12,12]]},"228":{"position":[[8,13]]},"263":{"position":[[4,12]]},"288":{"position":[[9,12]]},"1098":{"position":[[4,12]]},"1182":{"position":[[4,13]]},"1313":{"position":[[4,13]]}}}],["aren't",{"_index":368,"t":{"724":{"position":[[3,6]]}}}],["arithmet",{"_index":240,"t":{"387":{"position":[[3,10]]}}}],["array",{"_index":581,"t":{"1535":{"position":[[0,5]]}}}],["art",{"_index":91,"t":{"109":{"position":[[31,3]]}}}],["attempt",{"_index":444,"t":{"993":{"position":[[29,7]]}}}],["attent",{"_index":202,"t":{"295":{"position":[[4,9]]},"297":{"position":[[25,9]]},"299":{"position":[[17,9]]},"301":{"position":[[22,9]]},"309":{"position":[[12,9]]},"691":{"position":[[3,9]]},"695":{"position":[[4,9]]},"892":{"position":[[21,9]]},"896":{"position":[[21,9]]},"918":{"position":[[17,9]]},"922":{"position":[[21,9]]},"937":{"position":[[17,9]]},"987":{"position":[[19,10]]}}}],["augment",{"_index":643,"t":{"1737":{"position":[[11,12]]}}}],["autom",{"_index":640,"t":{"1715":{"position":[[4,9]]}}}],["automat",{"_index":657,"t":{"1775":{"position":[[4,9]]}}}],["autoregress",{"_index":512,"t":{"1295":{"position":[[4,14]]}}}],["awar",{"_index":37,"t":{"36":{"position":[[9,5]]},"796":{"position":[[15,5]]}}}],["b",{"_index":503,"t":{"1219":{"position":[[0,2]]},"1520":{"position":[[0,2]]}}}],["b.2",{"_index":504,"t":{"1220":{"position":[[0,4]]}}}],["backbon",{"_index":190,"t":{"268":{"position":[[21,9]]}}}],["background",{"_index":198,"t":{"286":{"position":[[3,10]]},"524":{"position":[[3,11]]},"590":{"position":[[3,10]]},"787":{"position":[[3,10]]},"852":{"position":[[3,10]]},"980":{"position":[[3,10]]},"1064":{"position":[[4,11]]},"1160":{"position":[[3,10]]}}}],["base",{"_index":265,"t":{"452":{"position":[[9,5]]},"788":{"position":[[12,5]]},"794":{"position":[[8,5]]},"800":{"position":[[12,5]]},"1765":{"position":[[19,5]]}}}],["base/larg",{"_index":390,"t":{"758":{"position":[[12,10]]}}}],["baselin",{"_index":127,"t":{"152":{"position":[[0,9]]},"702":{"position":[[4,9]]},"744":{"position":[[4,9]]},"808":{"position":[[0,9]]},"867":{"position":[[4,8]]},"998":{"position":[[4,9]]},"1188":{"position":[[4,9]]},"1256":{"position":[[0,8]]},"1414":{"position":[[6,9]]},"1493":{"position":[[4,9]]},"1664":{"position":[[0,9]]},"1673":{"position":[[0,9]]},"1675":{"position":[[27,9]]},"1681":{"position":[[0,9]]},"1683":{"position":[[27,9]]}}}],["basic",{"_index":631,"t":{"1699":{"position":[[14,6]]}}}],["batch",{"_index":112,"t":{"137":{"position":[[0,5]]},"312":{"position":[[22,8]]},"1338":{"position":[[0,8]]}}}],["benchmark",{"_index":169,"t":{"247":{"position":[[31,10]]},"390":{"position":[[0,10]]},"411":{"position":[[0,10]]},"552":{"position":[[11,11]]},"667":{"position":[[9,9]]},"1072":{"position":[[40,10]]}}}],["benefit",{"_index":385,"t":{"740":{"position":[[10,8]]}}}],["bert",{"_index":496,"t":{"1184":{"position":[[0,4]]}}}],["better",{"_index":183,"t":{"257":{"position":[[14,6]]},"259":{"position":[[0,6],[16,6]]}}}],["between",{"_index":401,"t":{"773":{"position":[[20,7]]},"775":{"position":[[20,7]]},"1666":{"position":[[11,7]]},"1668":{"position":[[11,7]]},"1675":{"position":[[11,7]]},"1683":{"position":[[11,7]]}}}],["bia",{"_index":78,"t":{"92":{"position":[[10,4]]},"526":{"position":[[3,4]]},"748":{"position":[[0,4]]},"944":{"position":[[4,4]]},"1340":{"position":[[10,4]]}}}],["bimod",{"_index":282,"t":{"495":{"position":[[5,7]]}}}],["bitfit",{"_index":293,"t":{"526":{"position":[[26,8]]},"748":{"position":[[13,6]]}}}],["block",{"_index":610,"t":{"1623":{"position":[[5,6]]}}}],["bridg",{"_index":349,"t":{"645":{"position":[[12,6]]}}}],["budget",{"_index":417,"t":{"802":{"position":[[11,6]]},"832":{"position":[[10,6]]},"840":{"position":[[14,6]]}}}],["build",{"_index":600,"t":{"1598":{"position":[[0,5]]},"1639":{"position":[[0,5]]}}}],["c",{"_index":574,"t":{"1522":{"position":[[0,2]]}}}],["calibr",{"_index":675,"t":{"1801":{"position":[[4,11]]}}}],["capabl",{"_index":273,"t":{"472":{"position":[[42,12]]}}}],["caption",{"_index":171,"t":{"248":{"position":[[28,8]]},"250":{"position":[[31,10]]},"456":{"position":[[22,7]]},"966":{"position":[[6,10]]}}}],["causal",{"_index":280,"t":{"493":{"position":[[0,6]]},"501":{"position":[[10,6]]}}}],["chain",{"_index":238,"t":{"385":{"position":[[3,5]]},"394":{"position":[[0,5]]},"406":{"position":[[0,5]]},"408":{"position":[[19,5]]},"545":{"position":[[0,5]]},"558":{"position":[[19,5]]},"560":{"position":[[19,5]]},"562":{"position":[[10,5]]}}}],["challeng",{"_index":662,"t":{"1783":{"position":[[2,10]]}}}],["chang",{"_index":628,"t":{"1694":{"position":[[11,7]]}}}],["chatgpt",{"_index":591,"t":{"1574":{"position":[[0,7]]}}}],["choic",{"_index":492,"t":{"1168":{"position":[[11,7]]},"1198":{"position":[[22,6]]}}}],["cl",{"_index":456,"t":{"1051":{"position":[[29,5]]}}}],["classif",{"_index":177,"t":{"252":{"position":[[33,14]]},"669":{"position":[[15,14]]},"1036":{"position":[[0,14]]},"1661":{"position":[[28,14]]},"1677":{"position":[[26,14]]},"1765":{"position":[[4,14]]}}}],["clip",{"_index":235,"t":{"349":{"position":[[13,4]]}}}],["clm",{"_index":281,"t":{"493":{"position":[[25,5]]}}}],["close",{"_index":486,"t":{"1135":{"position":[[4,7]]}}}],["coco",{"_index":170,"t":{"248":{"position":[[23,4]]}}}],["code",{"_index":276,"t":{"487":{"position":[[17,4]]},"489":{"position":[[29,4]]},"495":{"position":[[33,4]]},"497":{"position":[[5,4]]},"499":{"position":[[5,4]]},"501":{"position":[[5,4]]},"1623":{"position":[[0,4]]}}}],["codet5",{"_index":275,"t":{"487":{"position":[[3,8]]}}}],["coin",{"_index":252,"t":{"423":{"position":[[0,4]]}}}],["collect",{"_index":585,"t":{"1555":{"position":[[15,10]]}}}],["combin",{"_index":327,"t":{"601":{"position":[[4,9]]},"1799":{"position":[[4,11]]}}}],["commonsens",{"_index":247,"t":{"410":{"position":[[3,11]]}}}],["compar",{"_index":332,"t":{"607":{"position":[[4,9]]},"777":{"position":[[51,7]]}}}],["comparison",{"_index":41,"t":{"43":{"position":[[15,10]]},"67":{"position":[[0,10]]},"109":{"position":[[4,10]]},"834":{"position":[[0,10]]},"1144":{"position":[[3,10]]},"1194":{"position":[[6,10]]},"1666":{"position":[[0,10]]},"1668":{"position":[[0,10]]},"1675":{"position":[[0,10]]},"1683":{"position":[[0,10]]}}}],["compet",{"_index":269,"t":{"467":{"position":[[0,9]]}}}],["competit",{"_index":274,"t":{"474":{"position":[[0,11]]}}}],["complex",{"_index":578,"t":{"1530":{"position":[[5,10]]},"1532":{"position":[[6,10]]}}}],["compon",{"_index":160,"t":{"228":{"position":[[22,10]]},"838":{"position":[[16,10]]},"1627":{"position":[[14,10]]}}}],["compos",{"_index":620,"t":{"1656":{"position":[[4,9]]}}}],["composit",{"_index":644,"t":{"1739":{"position":[[11,11]]}}}],["comput",{"_index":245,"t":{"404":{"position":[[9,7]]},"503":{"position":[[5,7]]},"580":{"position":[[37,7]]},"607":{"position":[[14,13]]}}}],["concaten",{"_index":251,"t":{"421":{"position":[[12,13]]}}}],["conclus",{"_index":68,"t":{"75":{"position":[[3,10]]},"119":{"position":[[3,10]]},"158":{"position":[[3,10]]},"208":{"position":[[3,11]]},"270":{"position":[[3,12]]},"327":{"position":[[3,10]]},"377":{"position":[[0,10]]},"429":{"position":[[3,11]]},"532":{"position":[[3,10]]},"582":{"position":[[3,11]]},"621":{"position":[[3,10]]},"649":{"position":[[3,10]]},"710":{"position":[[3,11]]},"779":{"position":[[3,10]]},"842":{"position":[[3,10]]},"878":{"position":[[3,10]]},"927":{"position":[[3,10]]},"972":{"position":[[3,10]]},"1007":{"position":[[3,10]]},"1055":{"position":[[3,11]]},"1119":{"position":[[3,10]]},"1152":{"position":[[3,10]]},"1211":{"position":[[3,10]]},"1284":{"position":[[3,10]]},"1370":{"position":[[3,10]]},"1402":{"position":[[3,10]]},"1435":{"position":[[3,10]]},"1514":{"position":[[3,11]]},"1688":{"position":[[3,10]]}}}],["condit",{"_index":619,"t":{"1654":{"position":[[20,11]]}}}],["configur",{"_index":598,"t":{"1594":{"position":[[0,9]]},"1631":{"position":[[0,9]]}}}],["connect",{"_index":360,"t":{"687":{"position":[[4,10]]},"1169":{"position":[[9,10]]}}}],["consider",{"_index":636,"t":{"1707":{"position":[[11,14]]}}}],["constitu",{"_index":229,"t":{"325":{"position":[[12,12]]}}}],["context",{"_index":193,"t":{"272":{"position":[[15,7]]}}}],["continu",{"_index":642,"t":{"1719":{"position":[[6,10]]},"1731":{"position":[[6,10]]}}}],["contrast",{"_index":284,"t":{"497":{"position":[[10,11]]}}}],["convent",{"_index":365,"t":{"720":{"position":[[18,11]]}}}],["converg",{"_index":626,"t":{"1685":{"position":[[8,11]]}}}],["convolut",{"_index":26,"t":{"32":{"position":[[10,12]]},"229":{"position":[[18,13]]}}}],["corrupt",{"_index":485,"t":{"1131":{"position":[[20,10]]}}}],["cost",{"_index":333,"t":{"607":{"position":[[28,5]]},"609":{"position":[[10,4]]},"611":{"position":[[9,4]]},"613":{"position":[[8,4]]}}}],["cot",{"_index":314,"t":{"574":{"position":[[0,3]]}}}],["coverg",{"_index":505,"t":{"1220":{"position":[[5,10]]}}}],["creat",{"_index":594,"t":{"1586":{"position":[[0,6]]},"1592":{"position":[[0,6]]},"1603":{"position":[[0,6]]},"1611":{"position":[[0,6]]},"1613":{"position":[[0,6]]}}}],["critic",{"_index":315,"t":{"574":{"position":[[18,8]]}}}],["curv",{"_index":313,"t":{"572":{"position":[[8,6]]}}}],["d",{"_index":575,"t":{"1524":{"position":[[0,2]]}}}],["data",{"_index":94,"t":{"111":{"position":[[16,4]]},"135":{"position":[[0,4]]},"312":{"position":[[13,4]]},"489":{"position":[[34,4]]},"495":{"position":[[38,4]]},"542":{"position":[[16,4]]},"562":{"position":[[27,4]]},"958":{"position":[[9,4]]},"1320":{"position":[[8,4]]},"1333":{"position":[[4,4]]},"1418":{"position":[[6,4]]},"1555":{"position":[[10,4]]}}}],["dataset",{"_index":56,"t":{"61":{"position":[[18,8]]},"101":{"position":[[0,8]]},"241":{"position":[[13,8]]},"373":{"position":[[0,7]]},"463":{"position":[[0,8]]},"514":{"position":[[17,7]]},"593":{"position":[[14,8]]},"700":{"position":[[4,8]]},"811":{"position":[[11,8]]},"818":{"position":[[11,8]]},"825":{"position":[[11,8]]},"863":{"position":[[4,8]]},"1074":{"position":[[57,8]]},"1106":{"position":[[6,8]]},"1180":{"position":[[4,8]]},"1252":{"position":[[0,8]]},"1261":{"position":[[5,7]]},"1309":{"position":[[4,8]]},"1416":{"position":[[17,8]]},"1491":{"position":[[4,8]]},"1551":{"position":[[4,7]]},"1564":{"position":[[26,8]]},"1662":{"position":[[0,8]]},"1671":{"position":[[0,7]]},"1679":{"position":[[0,7]]}}}],["de",{"_index":115,"t":{"139":{"position":[[18,2]]}}}],["deberta",{"_index":391,"t":{"760":{"position":[[4,7]]}}}],["decis",{"_index":483,"t":{"1129":{"position":[[11,9]]},"1457":{"position":[[15,8]]}}}],["decod",{"_index":200,"t":{"290":{"position":[[16,7]]},"293":{"position":[[0,7]]},"509":{"position":[[0,7]]},"1297":{"position":[[12,7]]}}}],["decompos",{"_index":459,"t":{"1066":{"position":[[18,10]]}}}],["decomposit",{"_index":507,"t":{"1241":{"position":[[7,13]]},"1272":{"position":[[7,13]]},"1652":{"position":[[9,13]]},"1741":{"position":[[11,13]]}}}],["deep",{"_index":451,"t":{"1027":{"position":[[4,4]]}}}],["defin",{"_index":546,"t":{"1428":{"position":[[4,8]]}}}],["denois",{"_index":279,"t":{"491":{"position":[[5,9]]}}}],["dept",{"_index":460,"t":{"1066":{"position":[[43,6]]},"1079":{"position":[[6,4]]},"1081":{"position":[[6,4]]}}}],["depth",{"_index":457,"t":{"1053":{"position":[[7,5]]},"1171":{"position":[[0,5]]}}}],["depthwis",{"_index":25,"t":{"32":{"position":[[0,9]]}}}],["descript",{"_index":630,"t":{"1696":{"position":[[11,11]]}}}],["design",{"_index":16,"t":{"28":{"position":[[31,6]]},"263":{"position":[[17,6]]},"264":{"position":[[8,6]]},"266":{"position":[[10,6]]},"458":{"position":[[11,6]]},"591":{"position":[[3,9]]},"1129":{"position":[[4,6]]},"1168":{"position":[[4,6]]},"1707":{"position":[[4,6]]},"1725":{"position":[[17,6]]},"1727":{"position":[[13,6]]},"1787":{"position":[[11,6]]}}}],["detail",{"_index":119,"t":{"142":{"position":[[45,7]]},"181":{"position":[[19,7]]},"240":{"position":[[28,7]]},"263":{"position":[[37,7]]},"364":{"position":[[15,7]]},"371":{"position":[[9,7]]},"465":{"position":[[15,7]]},"704":{"position":[[19,7]]},"806":{"position":[[15,7]]},"813":{"position":[[15,7]]},"820":{"position":[[15,7]]},"827":{"position":[[15,7]]},"960":{"position":[[15,7]]},"998":{"position":[[33,7]]},"1258":{"position":[[15,7]]},"1420":{"position":[[15,7]]},"1548":{"position":[[28,7]]},"1664":{"position":[[29,7]]},"1673":{"position":[[29,7]]},"1681":{"position":[[29,7]]}}}],["detect",{"_index":120,"t":{"144":{"position":[[7,9]]},"148":{"position":[[9,9]]},"184":{"position":[[7,9]]}}}],["differ",{"_index":64,"t":{"71":{"position":[[25,9]]},"476":{"position":[[28,9]]},"773":{"position":[[28,9]]},"775":{"position":[[28,9]]},"832":{"position":[[0,9]]},"1220":{"position":[[19,9]]},"1799":{"position":[[19,9]]}}}],["directli",{"_index":350,"t":{"645":{"position":[[25,9]]},"728":{"position":[[0,8]]}}}],["discoveri",{"_index":135,"t":{"173":{"position":[[11,9]]}}}],["discret",{"_index":641,"t":{"1717":{"position":[[6,8]]},"1729":{"position":[[6,8]]}}}],["discuss",{"_index":192,"t":{"270":{"position":[[32,10]]},"425":{"position":[[3,10]]},"570":{"position":[[3,10]]},"675":{"position":[[17,10]]},"708":{"position":[[16,10]]},"946":{"position":[[0,10]]},"950":{"position":[[0,10]]},"1335":{"position":[[3,10]]},"1502":{"position":[[16,10]]},"1568":{"position":[[3,10]]}}}],["disjoint",{"_index":437,"t":{"948":{"position":[[24,8]]}}}],["distil",{"_index":506,"t":{"1233":{"position":[[10,12]]},"1243":{"position":[[7,12]]},"1272":{"position":[[25,12]]},"1274":{"position":[[0,12]]}}}],["distribut",{"_index":424,"t":{"840":{"position":[[21,12]]},"1562":{"position":[[23,12]]}}}],["doc",{"_index":597,"t":{"1592":{"position":[[18,3]]},"1603":{"position":[[9,4]]},"1633":{"position":[[12,3]]}}}],["domain",{"_index":445,"t":{"1003":{"position":[[13,6]]},"1146":{"position":[[17,6]]}}}],["dot",{"_index":205,"t":{"297":{"position":[[13,3]]}}}],["down",{"_index":63,"t":{"70":{"position":[[9,4]]}}}],["downstream",{"_index":288,"t":{"505":{"position":[[19,10]]}}}],["dropdown",{"_index":603,"t":{"1605":{"position":[[14,8]]},"1637":{"position":[[13,8]]}}}],["e",{"_index":576,"t":{"1526":{"position":[[0,2]]}}}],["earli",{"_index":27,"t":{"32":{"position":[[35,5]]},"952":{"position":[[4,5]]}}}],["effect",{"_index":29,"t":{"32":{"position":[[52,9]]},"268":{"position":[[4,6]]},"472":{"position":[[8,6]]},"1422":{"position":[[4,6]]}}}],["effici",{"_index":19,"t":{"29":{"position":[[23,10]]},"503":{"position":[[13,9]]},"524":{"position":[[41,9]]},"580":{"position":[[45,9]]},"597":{"position":[[14,9]]},"908":{"position":[[0,10]]},"993":{"position":[[15,10]]},"1078":{"position":[[20,10]]},"1079":{"position":[[31,10]]},"1081":{"position":[[22,9]]},"1196":{"position":[[22,9]]},"1217":{"position":[[14,10]]},"1229":{"position":[[10,9]]},"1247":{"position":[[10,10]]},"1333":{"position":[[9,10]]},"1398":{"position":[[4,10]]},"1506":{"position":[[14,10]]}}}],["efficientnet",{"_index":60,"t":{"67":{"position":[[14,12]]}}}],["efficientnetv2",{"_index":14,"t":{"28":{"position":[[3,14]]},"39":{"position":[[0,14]]},"41":{"position":[[0,14]]}}}],["embed",{"_index":215,"t":{"305":{"position":[[4,9]]},"750":{"position":[[7,9]]},"1327":{"position":[[12,9]]}}}],["emerg",{"_index":272,"t":{"472":{"position":[[33,8]]}}}],["empir",{"_index":362,"t":{"689":{"position":[[4,9]]},"742":{"position":[[3,9]]},"1795":{"position":[[20,9]]}}}],["encod",{"_index":199,"t":{"290":{"position":[[4,7]]},"291":{"position":[[0,7]]},"307":{"position":[[15,8]]},"1297":{"position":[[4,7]]}}}],["end",{"_index":152,"t":{"223":{"position":[[17,5]]},"474":{"position":[[29,3],[36,3]]},"568":{"position":[[32,5]]},"941":{"position":[[5,5]]}}}],["engin",{"_index":637,"t":{"1709":{"position":[[18,11]]},"1713":{"position":[[20,11]]},"1721":{"position":[[16,11]]},"1789":{"position":[[18,11]]}}}],["english",{"_index":228,"t":{"325":{"position":[[4,7]]}}}],["enough",{"_index":372,"t":{"724":{"position":[[34,7]]}}}],["ensembl",{"_index":236,"t":{"353":{"position":[[13,8]]},"361":{"position":[[22,8]]},"1148":{"position":[[10,10]]},"1735":{"position":[[11,10]]}}}],["entiti",{"_index":623,"t":{"1670":{"position":[[19,6]]}}}],["enviro",{"_index":268,"t":{"462":{"position":[[4,10]]}}}],["epilogu",{"_index":473,"t":{"1086":{"position":[[3,8]]}}}],["equal",{"_index":32,"t":{"34":{"position":[[0,7]]}}}],["equat",{"_index":243,"t":{"402":{"position":[[0,8]]}}}],["evalu",{"_index":138,"t":{"183":{"position":[[4,11]]},"240":{"position":[[17,10]]},"470":{"position":[[26,10]]},"551":{"position":[[5,10]]},"552":{"position":[[0,10]]},"554":{"position":[[0,10]]},"568":{"position":[[13,10]]},"903":{"position":[[26,10]]},"910":{"position":[[16,10]]},"1324":{"position":[[13,10]]},"1416":{"position":[[6,10]]},"1448":{"position":[[0,9]]},"1559":{"position":[[4,10]]},"1775":{"position":[[14,10]]}}}],["evalut",{"_index":167,"t":{"245":{"position":[[0,9]]}}}],["exist",{"_index":369,"t":{"724":{"position":[[10,8]]},"1504":{"position":[[45,6]]},"1607":{"position":[[10,8]]}}}],["experi",{"_index":70,"t":{"79":{"position":[[0,11]]},"98":{"position":[[3,11]]},"141":{"position":[[3,11]]},"180":{"position":[[3,11]]},"237":{"position":[[3,11]]},"363":{"position":[[0,10]]},"460":{"position":[[3,10]]},"528":{"position":[[3,11]]},"619":{"position":[[13,11]]},"631":{"position":[[3,11]]},"637":{"position":[[6,11]]},"639":{"position":[[6,11]]},"663":{"position":[[3,11]]},"665":{"position":[[4,11]]},"699":{"position":[[3,11]]},"742":{"position":[[13,11]]},"804":{"position":[[3,11]]},"862":{"position":[[3,11]]},"865":{"position":[[4,11]]},"869":{"position":[[4,11]]},"902":{"position":[[3,10]]},"956":{"position":[[3,11]]},"995":{"position":[[3,11]]},"1038":{"position":[[3,11]]},"1068":{"position":[[3,11]]},"1102":{"position":[[3,11]]},"1179":{"position":[[3,11]]},"1249":{"position":[[3,11]]},"1355":{"position":[[2,11]]},"1390":{"position":[[3,11]]},"1392":{"position":[[4,10]]},"1456":{"position":[[2,11]]},"1490":{"position":[[3,11]]},"1660":{"position":[[3,11]]}}}],["experiemt",{"_index":508,"t":{"1251":{"position":[[4,11]]}}}],["experiment",{"_index":116,"t":{"142":{"position":[[4,12]]},"389":{"position":[[5,12]]},"476":{"position":[[4,12]]},"632":{"position":[[4,12]]},"957":{"position":[[4,12]]},"1069":{"position":[[4,12]]},"1190":{"position":[[4,12]]},"1308":{"position":[[3,12]]},"1356":{"position":[[4,12]]},"1412":{"position":[[4,12]]},"1548":{"position":[[15,12]]}}}],["expert",{"_index":158,"t":{"226":{"position":[[16,7]]},"231":{"position":[[0,7]]},"257":{"position":[[5,8]]},"259":{"position":[[7,8]]},"261":{"position":[[20,7]]},"274":{"position":[[28,7]]},"276":{"position":[[31,7]]},"278":{"position":[[18,6]]},"954":{"position":[[21,7]]},"970":{"position":[[17,7]]},"1368":{"position":[[15,7]]}}}],["extract",{"_index":262,"t":{"448":{"position":[[11,10]]},"673":{"position":[[10,10]]},"1767":{"position":[[16,10]]}}}],["extrapol",{"_index":519,"t":{"1322":{"position":[[4,13]]}}}],["factor",{"_index":345,"t":{"641":{"position":[[34,6]]}}}],["featur",{"_index":133,"t":{"171":{"position":[[17,7]]}}}],["feed",{"_index":213,"t":{"303":{"position":[[18,4]]}}}],["few",{"_index":176,"t":{"252":{"position":[[0,3]]},"474":{"position":[[56,3]]},"591":{"position":[[19,3]]},"603":{"position":[[28,3]]},"617":{"position":[[30,3]]},"1003":{"position":[[4,3]]},"1114":{"position":[[6,3]]},"1202":{"position":[[21,3]]},"1263":{"position":[[0,3]]}}}],["fine",{"_index":81,"t":{"96":{"position":[[4,4]]},"105":{"position":[[11,4]]},"248":{"position":[[0,4]]},"524":{"position":[[15,4],[51,4]]},"526":{"position":[[14,4]]},"597":{"position":[[24,4]]},"734":{"position":[[25,4]]},"746":{"position":[[0,4]]},"1161":{"position":[[0,4]]},"1299":{"position":[[4,4]]},"1666":{"position":[[27,4]]},"1749":{"position":[[17,4]]}}}],["finetun",{"_index":295,"t":{"540":{"position":[[8,10]]},"542":{"position":[[5,10]]},"545":{"position":[[17,10]]},"549":{"position":[[5,10]]},"558":{"position":[[3,10]]},"560":{"position":[[5,10]]},"572":{"position":[[31,10]]},"574":{"position":[[4,10]]},"576":{"position":[[12,10]]},"578":{"position":[[12,10]]},"580":{"position":[[12,10]]},"1116":{"position":[[6,10],[25,10]]}}}],["first",{"_index":595,"t":{"1586":{"position":[[12,5]]},"1592":{"position":[[12,5]]},"1611":{"position":[[12,5]]},"1613":{"position":[[12,5]]}}}],["fit",{"_index":433,"t":{"920":{"position":[[19,7]]}}}],["fix",{"_index":649,"t":{"1753":{"position":[[6,5]]},"1755":{"position":[[6,5]]}}}],["flan",{"_index":294,"t":{"540":{"position":[[3,4]]}}}],["flip",{"_index":253,"t":{"423":{"position":[[5,4]]}}}],["follow",{"_index":430,"t":{"903":{"position":[[16,9]]}}}],["form",{"_index":195,"t":{"276":{"position":[[5,4]]}}}],["formal",{"_index":629,"t":{"1696":{"position":[[4,6]]}}}],["format",{"_index":297,"t":{"547":{"position":[[14,11]]}}}],["formul",{"_index":476,"t":{"1106":{"position":[[19,11]]},"1386":{"position":[[9,11]]}}}],["forward",{"_index":214,"t":{"303":{"position":[[23,7]]}}}],["four",{"_index":124,"t":{"150":{"position":[[0,4]]}}}],["framework",{"_index":618,"t":{"1650":{"position":[[12,9]]}}}],["free",{"_index":194,"t":{"276":{"position":[[0,4]]},"1751":{"position":[[13,4]]}}}],["front",{"_index":607,"t":{"1617":{"position":[[0,5]]}}}],["frozen",{"_index":189,"t":{"268":{"position":[[14,6]]},"470":{"position":[[50,6]]},"503":{"position":[[40,6]]}}}],["ft",{"_index":386,"t":{"746":{"position":[[12,4]]}}}],["full",{"_index":381,"t":{"734":{"position":[[20,4]]},"1261":{"position":[[0,4]]},"1327":{"position":[[4,4]]}}}],["fulli",{"_index":479,"t":{"1112":{"position":[[6,5]]}}}],["function",{"_index":109,"t":{"131":{"position":[[39,8]]},"856":{"position":[[12,8]]},"872":{"position":[[12,8]]},"1654":{"position":[[32,9]]}}}],["further",{"_index":472,"t":{"1083":{"position":[[4,7]]}}}],["fusion",{"_index":134,"t":{"171":{"position":[[25,6]]},"202":{"position":[[0,6]]},"952":{"position":[[10,6]]}}}],["futur",{"_index":409,"t":{"779":{"position":[[18,6]]},"1433":{"position":[[17,6]]}}}],["gap",{"_index":487,"t":{"1135":{"position":[[16,3]]}}}],["gener",{"_index":4,"t":{"16":{"position":[[0,8]]},"169":{"position":[[11,10]]},"348":{"position":[[13,10]]},"351":{"position":[[13,10]]},"367":{"position":[[13,10]]},"450":{"position":[[13,10]]},"452":{"position":[[24,10]]},"454":{"position":[[16,10]]},"505":{"position":[[48,10]]},"507":{"position":[[8,10]]},"568":{"position":[[38,10]]},"576":{"position":[[23,11]]},"734":{"position":[[2,14]]},"824":{"position":[[21,10]]},"1265":{"position":[[17,10]]},"1316":{"position":[[18,10]]},"1773":{"position":[[10,10]]},"1775":{"position":[[33,10]]}}}],["get",{"_index":0,"t":{"12":{"position":[[0,7]]}}}],["global",{"_index":416,"t":{"802":{"position":[[4,6]]}}}],["glue",{"_index":353,"t":{"667":{"position":[[4,4]]},"1072":{"position":[[21,4]]}}}],["good",{"_index":371,"t":{"724":{"position":[[29,4]]}}}],["gpt",{"_index":341,"t":{"637":{"position":[[21,3]]},"762":{"position":[[4,3]]},"764":{"position":[[18,3]]}}}],["granular",{"_index":572,"t":{"1508":{"position":[[4,11]]}}}],["grow",{"_index":470,"t":{"1081":{"position":[[11,5]]}}}],["hard",{"_index":375,"t":{"728":{"position":[[34,4]]}}}],["hardwar",{"_index":218,"t":{"314":{"position":[[4,8]]}}}],["harm",{"_index":318,"t":{"578":{"position":[[71,5]]}}}],["head",{"_index":208,"t":{"299":{"position":[[12,4]]},"697":{"position":[[18,4]]},"858":{"position":[[18,4]]},"874":{"position":[[18,4]]},"1036":{"position":[[15,4]]},"1051":{"position":[[19,4],[53,4]]}}}],["held",{"_index":305,"t":{"560":{"position":[[58,4]]}}}],["hierarch",{"_index":564,"t":{"1482":{"position":[[4,12]]}}}],["high",{"_index":568,"t":{"1498":{"position":[[15,4]]},"1549":{"position":[[4,4]]}}}],["higher",{"_index":83,"t":{"96":{"position":[[20,6]]}}}],["hotpotqa",{"_index":558,"t":{"1458":{"position":[[15,8]]}}}],["human",{"_index":584,"t":{"1555":{"position":[[4,5]]}}}],["hybri",{"_index":79,"t":{"94":{"position":[[0,6]]}}}],["hyperparamet",{"_index":516,"t":{"1313":{"position":[[22,15]]}}}],["hypothesi",{"_index":562,"t":{"1474":{"position":[[19,10]]}}}],["i18n",{"_index":613,"t":{"1631":{"position":[[10,4]]}}}],["ia)3(ia)^3(ia)3",{"_index":326,"t":{"597":{"position":[[41,16]]},"599":{"position":[[17,16]]}}}],["icl",{"_index":330,"t":{"603":{"position":[[17,3]]}}}],["ilsvrc2012",{"_index":52,"t":{"51":{"position":[[9,10]]}}}],["imag",{"_index":22,"t":{"30":{"position":[[25,5]]},"171":{"position":[[4,5]]},"250":{"position":[[25,5]]},"966":{"position":[[0,5]]},"1621":{"position":[[0,6]]}}}],["imagenet",{"_index":51,"t":{"51":{"position":[[0,8]]},"252":{"position":[[24,8]]}}}],["imagenet21k",{"_index":54,"t":{"56":{"position":[[0,11]]}}}],["implement",{"_index":118,"t":{"142":{"position":[[30,14]]},"181":{"position":[[4,14]]},"243":{"position":[[17,14]]},"364":{"position":[[0,14]]},"465":{"position":[[0,14]]},"704":{"position":[[4,14]]},"806":{"position":[[0,14]]},"813":{"position":[[0,14]]},"820":{"position":[[0,14]]},"827":{"position":[[0,14]]},"960":{"position":[[0,14]]},"998":{"position":[[18,14]]},"1029":{"position":[[21,14]]},"1216":{"position":[[3,14]]},"1258":{"position":[[0,14]]},"1495":{"position":[[4,14]]},"1664":{"position":[[14,14]]},"1673":{"position":[[14,14]]},"1681":{"position":[[14,14]]}}}],["implic",{"_index":588,"t":{"1569":{"position":[[4,12]]}}}],["import",{"_index":66,"t":{"73":{"position":[[0,10]]},"641":{"position":[[6,10]]},"796":{"position":[[4,10]]},"800":{"position":[[18,10]]},"836":{"position":[[16,10]]},"1520":{"position":[[19,10]]},"1524":{"position":[[3,10]]}}}],["improv",{"_index":304,"t":{"560":{"position":[[36,8]]},"578":{"position":[[23,8]]},"1079":{"position":[[11,8]]},"1410":{"position":[[3,9]]}}}],["increas",{"_index":471,"t":{"1081":{"position":[[50,9]]}}}],["individu",{"_index":537,"t":{"1394":{"position":[[16,10]]}}}],["induct",{"_index":527,"t":{"1340":{"position":[[0,9]]}}}],["infer",{"_index":114,"t":{"139":{"position":[[4,9]]},"175":{"position":[[17,9]]},"178":{"position":[[0,9]]},"276":{"position":[[10,9]]},"349":{"position":[[0,9]]},"359":{"position":[[0,9]]},"609":{"position":[[0,9]]},"726":{"position":[[24,9]]},"736":{"position":[[14,9]]},"991":{"position":[[28,9]]},"1177":{"position":[[17,9]]}}}],["infix",{"_index":522,"t":{"1329":{"position":[[21,5]]}}}],["inform",{"_index":653,"t":{"1767":{"position":[[4,11]]}}}],["ingredi",{"_index":328,"t":{"601":{"position":[[18,11]]}}}],["initi",{"_index":429,"t":{"892":{"position":[[9,11]]},"896":{"position":[[9,11]]},"918":{"position":[[5,11]]},"922":{"position":[[9,11]]},"937":{"position":[[5,11]]},"1140":{"position":[[7,14]]},"1200":{"position":[[29,14]]},"1331":{"position":[[4,14]]},"1512":{"position":[[11,14]]}}}],["input",{"_index":363,"t":{"693":{"position":[[4,5]]},"987":{"position":[[6,5]]}}}],["insert",{"_index":431,"t":{"916":{"position":[[0,9]]}}}],["inspect",{"_index":98,"t":{"115":{"position":[[4,10]]}}}],["instanc",{"_index":121,"t":{"146":{"position":[[0,8]]},"184":{"position":[[21,8]]}}}],["instanti",{"_index":352,"t":{"661":{"position":[[4,13]]}}}],["instruct",{"_index":290,"t":{"513":{"position":[[19,11]]},"572":{"position":[[19,11]]},"576":{"position":[[0,11]]},"578":{"position":[[0,11]]},"580":{"position":[[0,11]]},"903":{"position":[[4,11]]},"962":{"position":[[22,11]]},"964":{"position":[[11,11]]}}}],["integr",{"_index":439,"t":{"954":{"position":[[4,11]]},"970":{"position":[[0,11]]}}}],["intent",{"_index":625,"t":{"1677":{"position":[[19,6]]}}}],["interfac",{"_index":105,"t":{"129":{"position":[[14,9]]}}}],["interpol",{"_index":443,"t":{"989":{"position":[[13,13]]}}}],["interpret",{"_index":490,"t":{"1150":{"position":[[3,16]]}}}],["intrigu",{"_index":180,"t":{"256":{"position":[[4,10]]}}}],["intrins",{"_index":520,"t":{"1324":{"position":[[3,9]]}}}],["introduc",{"_index":373,"t":{"726":{"position":[[14,9]]}}}],["introduct",{"_index":9,"t":{"24":{"position":[[3,12]]},"85":{"position":[[3,12]]},"125":{"position":[[3,12]]},"164":{"position":[[3,12]]},"214":{"position":[[3,12]]},"220":{"position":[[3,12]]},"284":{"position":[[3,12]]},"335":{"position":[[0,12]]},"383":{"position":[[3,12]]},"435":{"position":[[3,12]]},"484":{"position":[[3,12]]},"522":{"position":[[3,12]]},"538":{"position":[[3,12]]},"588":{"position":[[3,12]]},"627":{"position":[[3,12]]},"657":{"position":[[3,12]]},"680":{"position":[[3,12]]},"718":{"position":[[3,12]]},"785":{"position":[[3,12]]},"848":{"position":[[3,12]]},"886":{"position":[[3,12]]},"933":{"position":[[3,12]]},"978":{"position":[[3,12]]},"1013":{"position":[[3,12]]},"1061":{"position":[[3,12]]},"1092":{"position":[[3,12]]},"1125":{"position":[[3,12]]},"1158":{"position":[[3,12]]},"1226":{"position":[[3,12]]},"1290":{"position":[[3,12]]},"1346":{"position":[[3,12]]},"1378":{"position":[[3,12]]},"1408":{"position":[[3,12]]},"1441":{"position":[[2,12]]},"1467":{"position":[[3,12]]},"1545":{"position":[[3,12]]},"1645":{"position":[[3,12]]}}}],["intuct",{"_index":77,"t":{"92":{"position":[[0,9]]}}}],["intuit",{"_index":514,"t":{"1302":{"position":[[4,9]]}}}],["joint",{"_index":126,"t":{"150":{"position":[[11,5]]},"948":{"position":[[4,5]]}}}],["key",{"_index":159,"t":{"228":{"position":[[4,3]]},"687":{"position":[[20,3]]}}}],["keypoint",{"_index":123,"t":{"148":{"position":[[0,8]]}}}],["knowledg",{"_index":156,"t":{"223":{"position":[[50,9]]},"278":{"position":[[25,9]]},"952":{"position":[[27,9]]},"1104":{"position":[[4,9]]},"1233":{"position":[[0,9]]},"1761":{"position":[[4,9]]}}}],["label",{"_index":234,"t":{"348":{"position":[[7,5]]},"351":{"position":[[7,5]]},"353":{"position":[[7,5]]},"367":{"position":[[7,5]]},"1051":{"position":[[35,5]]},"1658":{"position":[[30,5]]}}}],["lack",{"_index":449,"t":{"1021":{"position":[[4,4]]},"1023":{"position":[[0,4]]},"1025":{"position":[[0,4]]}}}],["languag",{"_index":168,"t":{"247":{"position":[[22,8]]},"338":{"position":[[7,8]]},"365":{"position":[[7,8]]},"396":{"position":[[0,8]]},"444":{"position":[[0,8]]},"487":{"position":[[28,8]]},"493":{"position":[[7,8]]},"810":{"position":[[12,8]]},"824":{"position":[[12,8]]},"900":{"position":[[0,8]]},"962":{"position":[[13,8]]},"1076":{"position":[[28,8]]},"1265":{"position":[[8,8]]},"1470":{"position":[[16,8]]},"1694":{"position":[[30,8]]}}}],["larg",{"_index":21,"t":{"30":{"position":[[19,5]]},"487":{"position":[[22,5]]},"896":{"position":[[41,5]]},"922":{"position":[[41,5]]}}}],["last",{"_index":249,"t":{"421":{"position":[[0,4]]}}}],["latenc",{"_index":374,"t":{"726":{"position":[[34,7]]},"736":{"position":[[24,7]]}}}],["later",{"_index":30,"t":{"32":{"position":[[65,5]]}}}],["layer",{"_index":28,"t":{"32":{"position":[[41,6]]},"726":{"position":[[8,5]]},"752":{"position":[[7,5]]},"916":{"position":[[10,6]]},"944":{"position":[[26,6]]}}}],["learn",{"_index":44,"t":{"45":{"position":[[15,8]]},"48":{"position":[[12,8]]},"61":{"position":[[9,8]]},"71":{"position":[[12,8]]},"272":{"position":[[23,8]]},"340":{"position":[[7,8]]},"497":{"position":[[22,8]]},"1034":{"position":[[11,8]]},"1044":{"position":[[10,8]]},"1112":{"position":[[23,8]]},"1114":{"position":[[15,8]]},"1198":{"position":[[32,8]]},"1229":{"position":[[29,8]]},"1231":{"position":[[10,8]]},"1472":{"position":[[11,8]]},"1697":{"position":[[15,8]]},"1715":{"position":[[23,8]]},"1733":{"position":[[15,8]]},"1779":{"position":[[17,8]]},"1793":{"position":[[20,8]]}}}],["learnabl",{"_index":237,"t":{"357":{"position":[[0,9]]},"369":{"position":[[0,9]]},"890":{"position":[[4,9]]}}}],["length",{"_index":324,"t":{"595":{"position":[[30,6]]},"1032":{"position":[[7,6]]},"1138":{"position":[[7,6]]},"1204":{"position":[[27,6]]},"1276":{"position":[[7,6]]},"1325":{"position":[[11,6]]},"1361":{"position":[[6,6]]},"1510":{"position":[[11,6]]}}}],["letter",{"_index":250,"t":{"421":{"position":[[5,6]]}}}],["level",{"_index":420,"t":{"832":{"position":[[17,6]]},"1484":{"position":[[12,5]]},"1486":{"position":[[12,5]]},"1549":{"position":[[9,5]]}}}],["lightweight",{"_index":164,"t":{"233":{"position":[[0,11]]}}}],["limit",{"_index":191,"t":{"270":{"position":[[16,11]]},"478":{"position":[[3,10]]},"651":{"position":[[0,11]]},"712":{"position":[[0,11]]},"740":{"position":[[23,11]]},"880":{"position":[[3,10]]},"1213":{"position":[[0,11]]},"1372":{"position":[[0,11]]},"1433":{"position":[[3,11]]},"1461":{"position":[[2,11]]},"1516":{"position":[[0,11]]},"1572":{"position":[[4,11]]},"1578":{"position":[[0,11]]}}}],["linear",{"_index":436,"t":{"944":{"position":[[19,6]]},"1051":{"position":[[46,6]]},"1173":{"position":[[4,9]]}}}],["link",{"_index":609,"t":{"1619":{"position":[[0,5]]}}}],["list",{"_index":582,"t":{"1535":{"position":[[8,4]]}}}],["llama",{"_index":428,"t":{"889":{"position":[[3,5]]},"936":{"position":[[16,5]]},"943":{"position":[[3,5]]}}}],["llm",{"_index":258,"t":{"440":{"position":[[4,3]]},"470":{"position":[[57,4]]},"472":{"position":[[18,4]]},"476":{"position":[[38,4]]},"503":{"position":[[61,4]]}}}],["lm",{"_index":286,"t":{"501":{"position":[[17,2]]},"1051":{"position":[[16,2]]},"1295":{"position":[[19,2]]},"1753":{"position":[[12,2]]},"1755":{"position":[[19,2]]},"1785":{"position":[[29,3]]}}}],["local",{"_index":614,"t":{"1635":{"position":[[11,9]]},"1637":{"position":[[6,6]]},"1639":{"position":[[11,9]]}}}],["lora",{"_index":383,"t":{"738":{"position":[[13,4]]},"756":{"position":[[0,4]]},"769":{"position":[[57,4]]},"771":{"position":[[37,5]]}}}],["lotteri",{"_index":560,"t":{"1474":{"position":[[4,7]]}}}],["low",{"_index":376,"t":{"732":{"position":[[4,3]]},"767":{"position":[[21,3]]},"790":{"position":[[0,3]]},"834":{"position":[[14,3]]},"1320":{"position":[[4,3]]},"1500":{"position":[[15,3]]}}}],["machin",{"_index":223,"t":{"321":{"position":[[4,7]]}}}],["magnitud",{"_index":413,"t":{"798":{"position":[[0,9]]}}}],["main",{"_index":49,"t":{"50":{"position":[[3,4]]},"375":{"position":[[0,4]]},"469":{"position":[[4,4]]},"636":{"position":[[4,4]]},"706":{"position":[[4,4]]},"815":{"position":[[0,4]]},"822":{"position":[[0,4]]},"829":{"position":[[0,4]]},"1001":{"position":[[4,4]]},"1071":{"position":[[4,4]]},"1193":{"position":[[4,4]]},"1315":{"position":[[3,4]]},"1359":{"position":[[6,4]]}}}],["maintain",{"_index":307,"t":{"562":{"position":[[45,8]]}}}],["make",{"_index":556,"t":{"1457":{"position":[[24,7]]}}}],["manual",{"_index":639,"t":{"1713":{"position":[[4,6]]},"1727":{"position":[[6,6]]}}}],["map",{"_index":635,"t":{"1705":{"position":[[13,7]]}}}],["markdown",{"_index":606,"t":{"1613":{"position":[[18,8]]}}}],["mask",{"_index":427,"t":{"856":{"position":[[4,7]]},"872":{"position":[[4,7]]}}}],["match",{"_index":285,"t":{"499":{"position":[[10,8]]}}}],["mathod",{"_index":300,"t":{"554":{"position":[[11,7]]}}}],["matric",{"_index":380,"t":{"732":{"position":[[34,8]]},"769":{"position":[[17,8]]}}}],["matrix",{"_index":405,"t":{"777":{"position":[[28,6]]}}}],["matter",{"_index":608,"t":{"1617":{"position":[[6,6]]}}}],["mdx",{"_index":612,"t":{"1627":{"position":[[0,3]]}}}],["measur",{"_index":545,"t":{"1426":{"position":[[4,9]]}}}],["mediat",{"_index":261,"t":{"444":{"position":[[9,8]]}}}],["medium/larg",{"_index":393,"t":{"762":{"position":[[10,12]]}}}],["memori",{"_index":335,"t":{"615":{"position":[[0,6]]},"643":{"position":[[6,6]]},"1078":{"position":[[13,6]]},"1079":{"position":[[24,6]]},"1452":{"position":[[0,6]]}}}],["meta",{"_index":659,"t":{"1777":{"position":[[4,4]]}}}],["method",{"_index":72,"t":{"89":{"position":[[3,6]]},"344":{"position":[[0,6]]},"438":{"position":[[27,6]]},"446":{"position":[[3,6]]},"467":{"position":[[10,7]]},"474":{"position":[[65,7]]},"629":{"position":[[3,6]]},"730":{"position":[[7,6]]},"792":{"position":[[11,6]]},"981":{"position":[[3,6]]},"1063":{"position":[[3,6]]},"1096":{"position":[[3,7]]},"1165":{"position":[[2,6]]},"1196":{"position":[[32,7]]},"1304":{"position":[[4,6]]},"1311":{"position":[[4,7]]},"1348":{"position":[[3,6]]},"1363":{"position":[[14,7]]},"1381":{"position":[[9,7]]},"1383":{"position":[[9,7]]},"1385":{"position":[[17,7]]},"1388":{"position":[[13,6]]},"1394":{"position":[[32,7]]},"1398":{"position":[[23,7]]},"1548":{"position":[[3,7]]},"1576":{"position":[[0,6]]},"1725":{"position":[[24,6]]},"1743":{"position":[[36,7]]},"1747":{"position":[[21,7]]},"1801":{"position":[[29,7]]}}}],["methodolog",{"_index":583,"t":{"1549":{"position":[[15,11]]}}}],["metric",{"_index":88,"t":{"107":{"position":[[0,7]]},"554":{"position":[[23,8]]},"1269":{"position":[[17,8]]},"1309":{"position":[[17,7]]},"1526":{"position":[[25,7]]}}}],["mitig",{"_index":316,"t":{"578":{"position":[[46,9]]}}}],["mix",{"_index":111,"t":{"135":{"position":[[5,6]]},"137":{"position":[[6,6]]}}}],["mixtur",{"_index":296,"t":{"543":{"position":[[5,9]]},"545":{"position":[[28,8]]},"1351":{"position":[[17,7]]},"1368":{"position":[[4,7]]}}}],["mlp",{"_index":494,"t":{"1171":{"position":[[19,3]]}}}],["modal",{"_index":155,"t":{"223":{"position":[[44,5]]},"229":{"position":[[0,8]]},"266":{"position":[[27,5]]},"272":{"position":[[6,5]]},"442":{"position":[[6,5]]},"894":{"position":[[10,5]]},"910":{"position":[[10,5]]},"939":{"position":[[13,5]]},"941":{"position":[[17,5]]},"1779":{"position":[[11,5]]}}}],["model",{"_index":86,"t":{"103":{"position":[[0,5]]},"224":{"position":[[4,5]]},"238":{"position":[[12,5]]},"288":{"position":[[3,5]]},"301":{"position":[[39,5]]},"323":{"position":[[4,5]]},"338":{"position":[[16,6]]},"365":{"position":[[16,6]]},"396":{"position":[[9,6]]},"487":{"position":[[37,6]]},"493":{"position":[[16,8]]},"576":{"position":[[42,6]]},"593":{"position":[[4,5]]},"637":{"position":[[37,6]]},"639":{"position":[[34,6]]},"645":{"position":[[19,5]]},"788":{"position":[[18,6]]},"811":{"position":[[0,6]]},"818":{"position":[[0,6]]},"825":{"position":[[0,6]]},"854":{"position":[[10,5]]},"896":{"position":[[47,6]]},"898":{"position":[[7,6]]},"900":{"position":[[9,6]]},"922":{"position":[[47,6]]},"962":{"position":[[34,5]]},"964":{"position":[[23,5]]},"1042":{"position":[[12,6]]},"1081":{"position":[[39,5]]},"1254":{"position":[[0,6]]},"1267":{"position":[[0,5]]},"1470":{"position":[[25,6]]},"1557":{"position":[[4,6]]}}}],["more",{"_index":182,"t":{"257":{"position":[[0,4]]},"1079":{"position":[[48,4]]},"1081":{"position":[[17,4]]},"1519":{"position":[[3,4]]}}}],["mot",{"_index":144,"t":{"192":{"position":[[0,3]]},"194":{"position":[[0,4]]}}}],["motiv",{"_index":45,"t":{"46":{"position":[[0,10]]},"1094":{"position":[[3,10]]}}}],["mp",{"_index":482,"t":{"1116":{"position":[[22,2]]}}}],["mrqa",{"_index":462,"t":{"1074":{"position":[[21,4]]}}}],["multi",{"_index":154,"t":{"223":{"position":[[38,5]]},"266":{"position":[[21,5]]},"272":{"position":[[0,5]]},"299":{"position":[[6,5]]},"442":{"position":[[0,5]]},"894":{"position":[[4,5]]},"910":{"position":[[4,5]]},"939":{"position":[[7,5]]},"941":{"position":[[11,5]]},"991":{"position":[[4,5]]},"1034":{"position":[[0,5]]},"1733":{"position":[[2,5]]},"1779":{"position":[[5,5]]}}}],["multipl",{"_index":621,"t":{"1658":{"position":[[21,8]]},"1793":{"position":[[4,8]]}}}],["multitask",{"_index":453,"t":{"1044":{"position":[[0,9]]},"1231":{"position":[[0,9]]},"1239":{"position":[[4,9]]}}}],["na",{"_index":38,"t":{"36":{"position":[[15,3]]},"37":{"position":[[0,3]]}}}],["natur",{"_index":418,"t":{"810":{"position":[[4,7]]},"1265":{"position":[[0,7]]},"1694":{"position":[[22,7]]}}}],["nautral",{"_index":419,"t":{"824":{"position":[[4,7]]}}}],["need",{"_index":3,"t":{"14":{"position":[[12,4]]},"562":{"position":[[35,6]]}}}],["neg",{"_index":571,"t":{"1504":{"position":[[28,8]]}}}],["network",{"_index":65,"t":{"71":{"position":[[35,8]]},"303":{"position":[[31,8]]},"661":{"position":[[34,8]]}}}],["neural",{"_index":266,"t":{"454":{"position":[[0,6]]}}}],["new",{"_index":5,"t":{"16":{"position":[[11,3]]},"274":{"position":[[24,3]]}}}],["next",{"_index":593,"t":{"1582":{"position":[[7,5]]}}}],["nlp",{"_index":351,"t":{"659":{"position":[[22,3]]},"1074":{"position":[[53,3]]},"1472":{"position":[[23,3]]},"1564":{"position":[[22,3]]},"1697":{"position":[[27,3]]},"1769":{"position":[[19,3]]}}}],["nlu",{"_index":447,"t":{"1016":{"position":[[0,3]]},"1040":{"position":[[0,3]]}}}],["nocap",{"_index":172,"t":{"248":{"position":[[37,6]]}}}],["noisi",{"_index":185,"t":{"261":{"position":[[14,5]]}}}],["non",{"_index":495,"t":{"1173":{"position":[[0,3]]}}}],["normal",{"_index":325,"t":{"595":{"position":[[37,13]]},"1173":{"position":[[18,13]]}}}],["number",{"_index":511,"t":{"1282":{"position":[[0,6]]},"1361":{"position":[[17,6]]}}}],["object",{"_index":108,"t":{"131":{"position":[[29,9]]},"144":{"position":[[0,6]]},"173":{"position":[[4,6]]},"184":{"position":[[0,6]]},"235":{"position":[[13,9]]},"860":{"position":[[13,9]]},"876":{"position":[[13,9]]},"1142":{"position":[[13,9]]},"1274":{"position":[[13,9]]}}}],["open",{"_index":151,"t":{"223":{"position":[[12,4]]},"487":{"position":[[12,4]]},"568":{"position":[[27,4]]},"941":{"position":[[0,4]]}}}],["optim",{"_index":36,"t":{"34":{"position":[[39,7]]},"316":{"position":[[4,9]]},"355":{"position":[[22,12]]},"728":{"position":[[9,10]]},"771":{"position":[[16,7]]},"1029":{"position":[[4,12]]},"1100":{"position":[[4,12]]}}}],["optimis",{"_index":166,"t":{"243":{"position":[[0,12]]}}}],["out",{"_index":306,"t":{"560":{"position":[[63,3]]},"730":{"position":[[3,3]]}}}],["outperform",{"_index":329,"t":{"603":{"position":[[3,13]]}}}],["over",{"_index":432,"t":{"920":{"position":[[14,4]]}}}],["overal",{"_index":617,"t":{"1650":{"position":[[4,7]]}}}],["overparameter",{"_index":501,"t":{"1209":{"position":[[0,20]]}}}],["overview",{"_index":157,"t":{"224":{"position":[[10,8]]},"346":{"position":[[0,8]]}}}],["p",{"_index":448,"t":{"1020":{"position":[[3,1]]},"1046":{"position":[[4,1]]},"1048":{"position":[[4,1]]},"1096":{"position":[[11,1]]},"1116":{"position":[[41,1]]},"1519":{"position":[[19,1]]}}}],["page",{"_index":605,"t":{"1611":{"position":[[24,4]]},"1613":{"position":[[27,4]]}}}],["paradigm",{"_index":673,"t":{"1799":{"position":[[29,9]]}}}],["paramet",{"_index":291,"t":{"524":{"position":[[31,9]]},"556":{"position":[[19,10]]},"597":{"position":[[4,9]]},"948":{"position":[[33,10]]},"993":{"position":[[5,9]]},"1175":{"position":[[0,9]]},"1196":{"position":[[12,9]]},"1207":{"position":[[0,9]]},"1217":{"position":[[4,9]]},"1229":{"position":[[0,9]]},"1247":{"position":[[0,9]]},"1381":{"position":[[36,10]]},"1383":{"position":[[33,10]]},"1506":{"position":[[4,9]]},"1747":{"position":[[4,9]]}}}],["parameter",{"_index":378,"t":{"732":{"position":[[13,13]]},"834":{"position":[[23,16]]},"1306":{"position":[[4,16]]}}}],["parameter/perform",{"_index":354,"t":{"671":{"position":[[4,21]]}}}],["pars",{"_index":230,"t":{"325":{"position":[[25,7]]}}}],["partial",{"_index":196,"t":{"276":{"position":[[23,7]]}}}],["pelt",{"_index":534,"t":{"1381":{"position":[[4,4]]},"1383":{"position":[[4,4]]},"1385":{"position":[[12,4]]},"1394":{"position":[[27,4]]},"1398":{"position":[[18,4]]}}}],["perform",{"_index":61,"t":{"69":{"position":[[0,11]]},"248":{"position":[[11,11]]},"250":{"position":[[10,11]]},"252":{"position":[[9,11]]},"257":{"position":[[21,11]]},"259":{"position":[[23,11]]},"474":{"position":[[12,11]]},"605":{"position":[[4,11]]},"617":{"position":[[4,11]]},"906":{"position":[[0,11]]},"913":{"position":[[0,11]]},"925":{"position":[[0,11]]},"1072":{"position":[[6,11]]},"1074":{"position":[[6,11]]},"1076":{"position":[[6,11]]},"1204":{"position":[[4,11]]},"1219":{"position":[[3,11]]}}}],["person",{"_index":525,"t":{"1336":{"position":[[0,15]]}}}],["perturb",{"_index":531,"t":{"1353":{"position":[[11,12]]}}}],["piec",{"_index":566,"t":{"1486":{"position":[[6,5]]},"1520":{"position":[[13,5]]}}}],["plug",{"_index":271,"t":{"470":{"position":[[42,4]]},"634":{"position":[[14,4]]}}}],["posit",{"_index":211,"t":{"303":{"position":[[4,8]]},"307":{"position":[[4,10]]},"1504":{"position":[[7,8]]}}}],["post",{"_index":596,"t":{"1586":{"position":[[18,4]]}}}],["potenti",{"_index":317,"t":{"578":{"position":[[61,9]]}}}],["practic",{"_index":384,"t":{"740":{"position":[[0,9]]}}}],["pre",{"_index":93,"t":{"111":{"position":[[4,3]]},"226":{"position":[[4,3]]},"241":{"position":[[0,3]]},"599":{"position":[[4,3]]},"983":{"position":[[18,3]]},"1042":{"position":[[0,3]]},"1142":{"position":[[0,3]]},"1470":{"position":[[4,3]]},"1785":{"position":[[17,3]]}}}],["predict",{"_index":544,"t":{"1424":{"position":[[3,10]]},"1430":{"position":[[4,10]]},"1763":{"position":[[14,10]]}}}],["preemb",{"_index":387,"t":{"750":{"position":[[24,10]]}}}],["prefix",{"_index":340,"t":{"634":{"position":[[0,6]]},"750":{"position":[[0,6]]},"752":{"position":[[0,6]]},"1301":{"position":[[3,6]]},"1325":{"position":[[4,6]]},"1329":{"position":[[4,6]]},"1340":{"position":[[18,6]]}}}],["prelay",{"_index":388,"t":{"752":{"position":[[20,10]]}}}],["preliminari",{"_index":359,"t":{"685":{"position":[[4,11]]},"1015":{"position":[[3,13]]},"1349":{"position":[[4,13]]},"1380":{"position":[[3,13]]},"1476":{"position":[[3,11]]},"1647":{"position":[[3,13]]}}}],["pretrain",{"_index":260,"t":{"442":{"position":[[12,11]]},"474":{"position":[[40,11]]},"489":{"position":[[14,11]]},"495":{"position":[[13,11]]},"503":{"position":[[23,11]]},"513":{"position":[[3,11]]},"514":{"position":[[5,11]]},"516":{"position":[[5,11]]},"1282":{"position":[[27,11]]}}}],["prismer",{"_index":150,"t":{"223":{"position":[[3,8]]},"238":{"position":[[4,7]]},"256":{"position":[[29,7]]}}}],["probe",{"_index":474,"t":{"1104":{"position":[[14,7]]},"1761":{"position":[[14,7]]}}}],["problem",{"_index":366,"t":{"722":{"position":[[3,7]]},"980":{"position":[[18,7]]},"1293":{"position":[[3,7]]}}}],["procedur",{"_index":298,"t":{"549":{"position":[[16,9]]}}}],["process",{"_index":554,"t":{"1454":{"position":[[14,7]]},"1694":{"position":[[39,10]]}}}],["product",{"_index":206,"t":{"297":{"position":[[17,7]]}}}],["program",{"_index":559,"t":{"1459":{"position":[[4,11]]}}}],["progress",{"_index":43,"t":{"45":{"position":[[3,11]]},"48":{"position":[[0,11]]},"71":{"position":[[0,11]]}}}],["prompt",{"_index":132,"t":{"169":{"position":[[4,6]]},"171":{"position":[[10,6]]},"340":{"position":[[0,6]]},"355":{"position":[[0,6]]},"357":{"position":[[10,6]]},"361":{"position":[[0,6]]},"369":{"position":[[10,6]]},"385":{"position":[[20,9]]},"392":{"position":[[9,9]]},"394":{"position":[[17,9]]},"413":{"position":[[0,7]]},"456":{"position":[[30,6]]},"458":{"position":[[4,6]]},"684":{"position":[[3,6]]},"687":{"position":[[30,7]]},"691":{"position":[[13,6]]},"693":{"position":[[10,7]]},"695":{"position":[[14,7]]},"728":{"position":[[24,6]]},"890":{"position":[[25,7]]},"983":{"position":[[11,6]]},"985":{"position":[[11,6]]},"987":{"position":[[12,6]]},"989":{"position":[[6,6]]},"1018":{"position":[[0,6]]},"1027":{"position":[[9,6]]},"1032":{"position":[[0,6]]},"1053":{"position":[[0,6]]},"1064":{"position":[[16,6]]},"1066":{"position":[[29,6]]},"1127":{"position":[[3,6]]},"1138":{"position":[[0,6]]},"1140":{"position":[[0,6]]},"1148":{"position":[[3,6]]},"1163":{"position":[[0,6]]},"1166":{"position":[[13,6]]},"1194":{"position":[[22,6]]},"1200":{"position":[[22,6]]},"1202":{"position":[[4,6]]},"1204":{"position":[[20,6]]},"1217":{"position":[[37,6]]},"1220":{"position":[[29,6]]},"1237":{"position":[[0,6]]},"1239":{"position":[[14,6]]},"1241":{"position":[[0,6]]},"1243":{"position":[[0,6]]},"1269":{"position":[[10,6]]},"1272":{"position":[[0,6]]},"1276":{"position":[[0,6]]},"1351":{"position":[[28,7]]},"1361":{"position":[[32,7]]},"1366":{"position":[[4,6]]},"1410":{"position":[[13,6]]},"1418":{"position":[[22,6]]},"1428":{"position":[[37,7]]},"1472":{"position":[[4,6]]},"1480":{"position":[[4,6]]},"1504":{"position":[[16,7],[37,7]]},"1510":{"position":[[4,6]]},"1512":{"position":[[4,6]]},"1526":{"position":[[42,6]]},"1648":{"position":[[3,6]]},"1654":{"position":[[8,7]]},"1656":{"position":[[18,7]]},"1658":{"position":[[8,7]]},"1668":{"position":[[27,6]]},"1696":{"position":[[26,9]]},"1699":{"position":[[4,9]]},"1701":{"position":[[6,6]]},"1707":{"position":[[30,9]]},"1709":{"position":[[2,6]]},"1711":{"position":[[4,6]]},"1717":{"position":[[15,6]]},"1719":{"position":[[17,6]]},"1721":{"position":[[2,6]]},"1733":{"position":[[8,6]]},"1735":{"position":[[4,6]]},"1737":{"position":[[4,6]]},"1739":{"position":[[4,6]]},"1741":{"position":[[4,6]]},"1743":{"position":[[26,9]]},"1751":{"position":[[18,9]]},"1753":{"position":[[15,6]]},"1755":{"position":[[12,6]]},"1781":{"position":[[2,6]]},"1787":{"position":[[4,6]]},"1789":{"position":[[4,6]]},"1793":{"position":[[13,6]]},"1795":{"position":[[42,9]]},"1797":{"position":[[23,7]]},"1801":{"position":[[19,9]]}}}],["prompt+lm",{"_index":652,"t":{"1757":{"position":[[6,9]]}}}],["promptless",{"_index":646,"t":{"1749":{"position":[[6,10]]}}}],["properti",{"_index":181,"t":{"256":{"position":[[15,10]]}}}],["propos",{"_index":536,"t":{"1388":{"position":[[4,8]]}}}],["protocol",{"_index":299,"t":{"551":{"position":[[16,8]]}}}],["prune",{"_index":426,"t":{"854":{"position":[[16,7]]},"1482":{"position":[[28,7]]},"1484":{"position":[[18,7]]},"1486":{"position":[[18,7]]},"1508":{"position":[[19,7]]}}}],["pseudo",{"_index":233,"t":{"348":{"position":[[0,6]]},"351":{"position":[[0,6]]},"353":{"position":[[0,6]]},"367":{"position":[[0,6]]}}}],["pt",{"_index":458,"t":{"1064":{"position":[[30,4]]}}}],["ptr",{"_index":616,"t":{"1648":{"position":[[28,5]]},"1650":{"position":[[25,3]]},"1666":{"position":[[19,3]]},"1668":{"position":[[19,3]]},"1675":{"position":[[19,3]]},"1683":{"position":[[19,3]]},"1685":{"position":[[23,3]]}}}],["public",{"_index":587,"t":{"1564":{"position":[[15,6]]}}}],["put",{"_index":310,"t":{"566":{"position":[[3,7]]}}}],["pθp_{\\theta}p",{"_index":515,"t":{"1306":{"position":[[24,15]]}}}],["qualit",{"_index":130,"t":{"156":{"position":[[4,11]]},"1566":{"position":[[4,11]]}}}],["quantit",{"_index":128,"t":{"154":{"position":[[4,12]]}}}],["queri",{"_index":148,"t":{"204":{"position":[[0,7]]}}}],["question",{"_index":263,"t":{"450":{"position":[[4,8]]},"452":{"position":[[15,8]]},"454":{"position":[[7,8]]},"456":{"position":[[4,8]]},"673":{"position":[[21,8]]},"817":{"position":[[4,8]]},"1771":{"position":[[4,8]]}}}],["r",{"_index":146,"t":{"198":{"position":[[0,1]]}}}],["raft",{"_index":339,"t":{"617":{"position":[[45,6]]}}}],["random",{"_index":402,"t":{"775":{"position":[[38,6]]}}}],["rank",{"_index":377,"t":{"732":{"position":[[8,4]]},"767":{"position":[[25,4]]},"771":{"position":[[24,4]]},"790":{"position":[[4,4]]},"796":{"position":[[21,4]]},"834":{"position":[[18,4]]}}}],["rate",{"_index":499,"t":{"1198":{"position":[[41,4]]}}}],["re",{"_index":141,"t":{"186":{"position":[[8,3]]}}}],["react",{"_index":604,"t":{"1611":{"position":[[18,5]]},"1627":{"position":[[8,5]]}}}],["real",{"_index":337,"t":{"617":{"position":[[19,4]]}}}],["reason",{"_index":153,"t":{"223":{"position":[[23,9]]},"387":{"position":[[14,9]]},"410":{"position":[[15,9]]},"417":{"position":[[12,9]]},"560":{"position":[[45,9]]},"562":{"position":[[54,9]]},"564":{"position":[[25,9]]},"574":{"position":[[31,9]]},"894":{"position":[[16,9]]},"941":{"position":[[23,9]]},"1458":{"position":[[4,10]]},"1769":{"position":[[4,11]]}}}],["rec",{"_index":140,"t":{"186":{"position":[[0,3]]}}}],["recent",{"_index":255,"t":{"438":{"position":[[4,6]]}}}],["recip",{"_index":322,"t":{"591":{"position":[[23,6]]}}}],["reduct",{"_index":344,"t":{"641":{"position":[[24,9]]}}}],["reflect",{"_index":552,"t":{"1444":{"position":[[38,10]]},"1450":{"position":[[5,10]]}}}],["reflexion",{"_index":550,"t":{"1444":{"position":[[2,10]]},"1454":{"position":[[4,9]]}}}],["regular",{"_index":47,"t":{"48":{"position":[[35,14]]},"73":{"position":[[23,14]]},"318":{"position":[[4,14]]}}}],["reinforc",{"_index":551,"t":{"1444":{"position":[[13,13]]}}}],["rel",{"_index":319,"t":{"580":{"position":[[26,10]]}}}],["relat",{"_index":11,"t":{"26":{"position":[[3,7]]},"87":{"position":[[3,7]]},"166":{"position":[[3,7]]},"222":{"position":[[3,7]]},"337":{"position":[[0,7]]},"427":{"position":[[3,7]]},"437":{"position":[[3,7]]},"486":{"position":[[3,7]]},"530":{"position":[[3,7]]},"647":{"position":[[3,7]]},"677":{"position":[[3,7]]},"682":{"position":[[3,7]]},"766":{"position":[[3,7]]},"850":{"position":[[3,7]]},"888":{"position":[[3,7]]},"935":{"position":[[3,7]]},"1085":{"position":[[3,7]]},"1118":{"position":[[3,7]]},"1228":{"position":[[3,7]]},"1292":{"position":[[3,7]]},"1365":{"position":[[3,7]]},"1400":{"position":[[3,7]]},"1432":{"position":[[3,7]]},"1443":{"position":[[2,7]]},"1469":{"position":[[3,7]]},"1547":{"position":[[3,7]]},"1661":{"position":[[19,8]]},"1687":{"position":[[3,7]]}}}],["relev",{"_index":267,"t":{"456":{"position":[[13,8]]},"1781":{"position":[[9,8]]}}}],["reparameter",{"_index":452,"t":{"1030":{"position":[[0,18]]}}}],["represent",{"_index":197,"t":{"278":{"position":[[0,14]]},"355":{"position":[[7,14]]},"357":{"position":[[17,14]]},"361":{"position":[[7,14]]},"369":{"position":[[17,14]]}}}],["requir",{"_index":95,"t":{"111":{"position":[[21,12]]}}}],["resampl",{"_index":163,"t":{"231":{"position":[[8,9]]},"266":{"position":[[0,9]]}}}],["research",{"_index":590,"t":{"1569":{"position":[[31,8]]}}}],["residu",{"_index":491,"t":{"1166":{"position":[[4,8]]},"1169":{"position":[[0,8]]},"1217":{"position":[[28,8]]}}}],["resili",{"_index":488,"t":{"1146":{"position":[[3,10]]}}}],["resolut",{"_index":84,"t":{"96":{"position":[[27,10]]}}}],["resourc",{"_index":569,"t":{"1498":{"position":[[20,8]]},"1500":{"position":[[19,8]]}}}],["result",{"_index":50,"t":{"50":{"position":[[8,7]]},"54":{"position":[[0,7]]},"59":{"position":[[0,7]]},"64":{"position":[[0,7]]},"154":{"position":[[17,7]]},"156":{"position":[[16,7]]},"247":{"position":[[4,7]]},"320":{"position":[[3,7]]},"375":{"position":[[5,7]]},"398":{"position":[[5,7]]},"415":{"position":[[0,7]]},"469":{"position":[[9,7]]},"470":{"position":[[5,7]]},"476":{"position":[[17,7]]},"528":{"position":[[19,7]]},"636":{"position":[[9,7]]},"706":{"position":[[9,7]]},"815":{"position":[[5,7]]},"822":{"position":[[5,7]]},"829":{"position":[[5,7]]},"840":{"position":[[4,9]]},"869":{"position":[[16,7]]},"1000":{"position":[[3,7]]},"1001":{"position":[[9,7]]},"1068":{"position":[[19,7]]},"1071":{"position":[[9,7]]},"1108":{"position":[[6,7]]},"1133":{"position":[[3,7]]},"1192":{"position":[[3,7]]},"1193":{"position":[[9,7]]},"1260":{"position":[[4,7]]},"1315":{"position":[[8,7]]},"1358":{"position":[[4,7]]},"1359":{"position":[[11,7]]},"1497":{"position":[[3,7]]},"1498":{"position":[[4,7]]},"1500":{"position":[[4,7]]},"1519":{"position":[[8,7]]},"1561":{"position":[[3,6]]},"1562":{"position":[[4,7]]},"1564":{"position":[[4,7]]},"1566":{"position":[[16,7]]},"1661":{"position":[[8,7]]},"1670":{"position":[[8,7]]},"1677":{"position":[[8,7]]}}}],["retriev",{"_index":136,"t":{"173":{"position":[[25,9]]}}}],["revisit",{"_index":358,"t":{"684":{"position":[[17,7]]},"936":{"position":[[5,7]]}}}],["rewind",{"_index":567,"t":{"1488":{"position":[[4,9]]}}}],["roberta",{"_index":389,"t":{"758":{"position":[[4,7]]}}}],["robust",{"_index":184,"t":{"261":{"position":[[0,10]]},"408":{"position":[[5,10]]},"920":{"position":[[0,10]]},"1198":{"position":[[4,10]]},"1200":{"position":[[4,10]]}}}],["role",{"_index":422,"t":{"838":{"position":[[4,4]]}}}],["rout",{"_index":533,"t":{"1363":{"position":[[6,7]]}}}],["router",{"_index":530,"t":{"1353":{"position":[[4,6]]}}}],["rrr",{"_index":346,"t":{"641":{"position":[[41,3]]},"771":{"position":[[29,3]]},"773":{"position":[[38,3]]}}}],["rule",{"_index":615,"t":{"1648":{"position":[[22,5]]}}}],["same",{"_index":62,"t":{"69":{"position":[[21,4]]}}}],["sampl",{"_index":187,"t":{"266":{"position":[[33,8]]},"1280":{"position":[[16,8]]}}}],["scail",{"_index":33,"t":{"34":{"position":[[8,8]]},"36":{"position":[[23,8]]},"41":{"position":[[15,8]]},"70":{"position":[[0,8]]},"113":{"position":[[4,8]]}}}],["scale",{"_index":204,"t":{"297":{"position":[[6,6]]},"472":{"position":[[0,7]]},"556":{"position":[[3,7]]},"572":{"position":[[0,7]]},"764":{"position":[[4,7]]},"1023":{"position":[[28,6]]},"1046":{"position":[[24,6]]},"1267":{"position":[[6,7]]}}}],["scenario",{"_index":570,"t":{"1498":{"position":[[29,9]]},"1500":{"position":[[28,9]]}}}],["schedul",{"_index":219,"t":{"314":{"position":[[17,8]]},"802":{"position":[[18,9]]}}}],["score",{"_index":421,"t":{"836":{"position":[[27,5]]},"1520":{"position":[[30,5]]},"1524":{"position":[[14,6]]}}}],["sea",{"_index":627,"t":{"1694":{"position":[[7,3]]}}}],["search",{"_index":39,"t":{"37":{"position":[[4,6]]},"1703":{"position":[[13,6]]},"1729":{"position":[[22,6]]},"1731":{"position":[[24,6]]}}}],["seed",{"_index":403,"t":{"775":{"position":[[45,5]]}}}],["segment",{"_index":122,"t":{"146":{"position":[[9,12]]},"184":{"position":[[30,12]]}}}],["select",{"_index":664,"t":{"1785":{"position":[[4,9]]},"1791":{"position":[[4,9]]}}}],["self",{"_index":100,"t":{"117":{"position":[[4,4]]},"309":{"position":[[7,4]]},"342":{"position":[[0,4]]},"1450":{"position":[[0,4]]}}}],["sensit",{"_index":415,"t":{"800":{"position":[[0,11]]}}}],["seq2seq",{"_index":289,"t":{"507":{"position":[[0,7]]}}}],["sequenti",{"_index":555,"t":{"1457":{"position":[[4,10]]}}}],["seri",{"_index":342,"t":{"637":{"position":[[27,6]]},"639":{"position":[[24,6]]}}}],["set",{"_index":117,"t":{"142":{"position":[[17,8]]},"245":{"position":[[10,7]]},"632":{"position":[[17,8]]},"665":{"position":[[16,8]]},"904":{"position":[[0,8]]},"911":{"position":[[0,8]]},"923":{"position":[[0,8]]},"1202":{"position":[[30,7]]},"1320":{"position":[[13,7]]},"1356":{"position":[[17,8]]},"1745":{"position":[[13,8]]}}}],["setup",{"_index":53,"t":{"52":{"position":[[0,5]]},"57":{"position":[[0,5]]},"62":{"position":[[0,5]]},"100":{"position":[[4,5]]},"462":{"position":[[15,5]]},"516":{"position":[[17,5]]},"865":{"position":[[16,6]]},"957":{"position":[[17,6]]},"980":{"position":[[26,5]]},"1069":{"position":[[17,5]]},"1190":{"position":[[17,5]]},"1251":{"position":[[16,5]]},"1308":{"position":[[16,5]]},"1392":{"position":[[15,5]]},"1412":{"position":[[17,5]]}}}],["shape",{"_index":638,"t":{"1711":{"position":[[11,5]]},"1723":{"position":[[11,5]]}}}],["share",{"_index":464,"t":{"1074":{"position":[[31,6]]},"1175":{"position":[[10,7]]},"1207":{"position":[[10,8]]}}}],["shelf",{"_index":287,"t":{"503":{"position":[[55,5]]}}}],["shift",{"_index":489,"t":{"1146":{"position":[[24,5]]}}}],["shot",{"_index":175,"t":{"250":{"position":[[5,4]]},"252":{"position":[[4,4]]},"274":{"position":[[5,4]]},"440":{"position":[[21,4]]},"470":{"position":[[21,4]]},"474":{"position":[[60,4]]},"564":{"position":[[20,4]]},"617":{"position":[[34,4]]},"1003":{"position":[[8,4]]},"1114":{"position":[[10,4]]},"1202":{"position":[[25,4]]},"1263":{"position":[[4,4]]}}}],["sidebar",{"_index":599,"t":{"1594":{"position":[[14,7]]}}}],["simiar",{"_index":549,"t":{"1430":{"position":[[35,9]]}}}],["similar",{"_index":400,"t":{"773":{"position":[[9,10]]},"775":{"position":[[9,10]]},"1144":{"position":[[17,7]]},"1428":{"position":[[18,10]]}}}],["simpl",{"_index":434,"t":{"939":{"position":[[0,6]]}}}],["singular",{"_index":414,"t":{"798":{"position":[[13,8]]}}}],["site",{"_index":6,"t":{"16":{"position":[[15,4]]},"18":{"position":[[11,4]]},"1598":{"position":[[11,4]]},"1635":{"position":[[21,4]]},"1639":{"position":[[21,4]]}}}],["size",{"_index":23,"t":{"30":{"position":[[31,5]]},"264":{"position":[[19,4]]},"1081":{"position":[[45,4]]}}}],["slow",{"_index":24,"t":{"30":{"position":[[40,4]]},"32":{"position":[[27,4]]}}}],["smop",{"_index":528,"t":{"1351":{"position":[[4,5]]}}}],["soft",{"_index":532,"t":{"1361":{"position":[[27,4]]},"1526":{"position":[[37,4]]}}}],["softmax",{"_index":216,"t":{"305":{"position":[[18,7]]}}}],["solut",{"_index":370,"t":{"724":{"position":[[19,9]]}}}],["sot",{"_index":142,"t":{"188":{"position":[[0,3]]}}}],["sota",{"_index":270,"t":{"470":{"position":[[0,4]]}}}],["sourc",{"_index":441,"t":{"983":{"position":[[4,6]]},"996":{"position":[[4,6]]},"1245":{"position":[[4,6]]},"1282":{"position":[[10,6]]},"1418":{"position":[[15,6]]}}}],["space",{"_index":579,"t":{"1532":{"position":[[0,5]]},"1725":{"position":[[11,5]]}}}],["span",{"_index":278,"t":{"491":{"position":[[0,4]]},"1131":{"position":[[15,4]]}}}],["spars",{"_index":529,"t":{"1351":{"position":[[10,6]]}}}],["specif",{"_index":161,"t":{"229":{"position":[[9,8]]},"697":{"position":[[9,8]]},"858":{"position":[[9,8]]},"874":{"position":[[9,8]]}}}],["speed",{"_index":40,"t":{"43":{"position":[[9,5]]}}}],["spot",{"_index":539,"t":{"1410":{"position":[[32,4]]},"1422":{"position":[[14,4]]}}}],["squad",{"_index":356,"t":{"673":{"position":[[4,5]]}}}],["stack",{"_index":201,"t":{"290":{"position":[[24,6]]}}}],["stage",{"_index":31,"t":{"32":{"position":[[71,6]]},"34":{"position":[[26,5]]}}}],["standard",{"_index":242,"t":{"392":{"position":[[0,8]]}}}],["start",{"_index":1,"t":{"12":{"position":[[8,7]]},"18":{"position":[[0,5]]},"1635":{"position":[[0,5]]}}}],["state",{"_index":90,"t":{"109":{"position":[[18,5]]}}}],["statement",{"_index":367,"t":{"722":{"position":[[11,9]]},"1293":{"position":[[11,9]]}}}],["static",{"_index":425,"t":{"854":{"position":[[3,6]]}}}],["statist",{"_index":577,"t":{"1526":{"position":[[13,11]]}}}],["stem",{"_index":162,"t":{"229":{"position":[[32,4]]}}}],["steup",{"_index":241,"t":{"389":{"position":[[18,5]]}}}],["stochast",{"_index":510,"t":{"1280":{"position":[[0,10]]}}}],["storag",{"_index":334,"t":{"613":{"position":[[0,7]]}}}],["strategi",{"_index":188,"t":{"266":{"position":[[42,8]]},"1278":{"position":[[18,8]]},"1743":{"position":[[11,10]]},"1791":{"position":[[24,8]]}}}],["stronger",{"_index":440,"t":{"962":{"position":[[4,8]]}}}],["structur",{"_index":565,"t":{"1482":{"position":[[17,10]]},"1763":{"position":[[4,9]]}}}],["studi",{"_index":59,"t":{"66":{"position":[[12,7]]},"113":{"position":[[13,5]]},"400":{"position":[[14,5]]},"689":{"position":[[14,5]]},"915":{"position":[[13,5]]},"1050":{"position":[[13,5]]},"1137":{"position":[[13,5]]},"1206":{"position":[[13,7]]},"1271":{"position":[[13,7]]},"1460":{"position":[[9,5]]}}}],["sub",{"_index":35,"t":{"34":{"position":[[35,3]]},"1654":{"position":[[4,3]]},"1656":{"position":[[14,3]]},"1658":{"position":[[4,3]]}}}],["subspac",{"_index":399,"t":{"773":{"position":[[0,8]]},"775":{"position":[[0,8]]}}}],["summar",{"_index":69,"t":{"77":{"position":[[0,13]]},"1318":{"position":[[4,13]]}}}],["superglu",{"_index":461,"t":{"1072":{"position":[[30,9]]},"1110":{"position":[[4,9]]},"1219":{"position":[[18,9]]},"1526":{"position":[[3,9]]}}}],["supervis",{"_index":101,"t":{"117":{"position":[[9,11]]},"1112":{"position":[[12,10]]},"1697":{"position":[[4,10]]}}}],["svd",{"_index":411,"t":{"794":{"position":[[4,3]]}}}],["symbol",{"_index":248,"t":{"417":{"position":[[3,8]]}}}],["t",{"_index":321,"t":{"591":{"position":[[17,1]]},"603":{"position":[[26,1]]}}}],["t0",{"_index":331,"t":{"605":{"position":[[19,2]]}}}],["t5",{"_index":343,"t":{"639":{"position":[[21,2]]},"1186":{"position":[[0,2]]}}}],["tabl",{"_index":517,"t":{"1316":{"position":[[4,5]]}}}],["target",{"_index":442,"t":{"985":{"position":[[4,6]]},"996":{"position":[[15,6]]},"1245":{"position":[[24,6]]},"1278":{"position":[[0,6]]}}}],["task",{"_index":125,"t":{"150":{"position":[[5,5]]},"183":{"position":[[22,5]]},"419":{"position":[[0,5]]},"440":{"position":[[30,5]]},"505":{"position":[[59,5]]},"507":{"position":[[19,5]]},"509":{"position":[[13,5]]},"511":{"position":[[14,5]]},"543":{"position":[[0,4]]},"556":{"position":[[39,5]]},"560":{"position":[[67,5]]},"605":{"position":[[22,5]]},"617":{"position":[[39,5]]},"669":{"position":[[30,5]]},"697":{"position":[[4,4]]},"858":{"position":[[4,4]]},"874":{"position":[[4,4]]},"991":{"position":[[10,4]]},"996":{"position":[[22,5]]},"1016":{"position":[[4,5]]},"1025":{"position":[[28,5]]},"1034":{"position":[[6,4]]},"1040":{"position":[[4,5]]},"1048":{"position":[[24,5]]},"1074":{"position":[[38,4]]},"1076":{"position":[[37,5]]},"1252":{"position":[[13,5]]},"1265":{"position":[[28,5]]},"1280":{"position":[[11,4]]},"1282":{"position":[[17,5]]},"1386":{"position":[[4,4]]},"1424":{"position":[[14,4]]},"1428":{"position":[[13,4]]},"1553":{"position":[[4,4]]},"1652":{"position":[[4,4]]},"1656":{"position":[[30,5]]},"1765":{"position":[[25,5]]}}}],["templat",{"_index":264,"t":{"452":{"position":[[0,8]]},"547":{"position":[[0,9]]},"1526":{"position":[[49,9]]},"1709":{"position":[[9,8]]},"1713":{"position":[[11,8]]},"1715":{"position":[[14,8]]}}}],["term",{"_index":292,"t":{"526":{"position":[[8,5]]}}}],["terminolog",{"_index":364,"t":{"720":{"position":[[0,13]]}}}],["text",{"_index":283,"t":{"495":{"position":[[28,4]]},"497":{"position":[[0,4]]},"499":{"position":[[0,4]]},"501":{"position":[[0,4]]},"1316":{"position":[[13,4]]},"1773":{"position":[[5,4]]},"1775":{"position":[[28,4]]}}}],["theoret",{"_index":670,"t":{"1795":{"position":[[4,11]]}}}],["thought",{"_index":239,"t":{"385":{"position":[[12,7]]},"394":{"position":[[9,7]]},"406":{"position":[[9,7]]},"408":{"position":[[28,7]]},"545":{"position":[[9,7]]},"558":{"position":[[28,7]]},"560":{"position":[[28,7]]},"562":{"position":[[19,7]]}}}],["through",{"_index":547,"t":{"1428":{"position":[[29,7]]}}}],["ticket",{"_index":561,"t":{"1474":{"position":[[12,6]]}}}],["time",{"_index":466,"t":{"1078":{"position":[[4,4]]},"1530":{"position":[[0,4]]}}}],["togeth",{"_index":311,"t":{"566":{"position":[[18,8]]}}}],["token",{"_index":106,"t":{"129":{"position":[[29,12]]},"139":{"position":[[21,12]]},"1484":{"position":[[6,5]]},"1520":{"position":[[3,5]]}}}],["topic",{"_index":661,"t":{"1781":{"position":[[18,6]]}}}],["trade",{"_index":355,"t":{"671":{"position":[[26,5]]}}}],["train",{"_index":18,"t":{"29":{"position":[[14,8]]},"30":{"position":[[0,8]]},"36":{"position":[[0,8]]},"43":{"position":[[0,8]]},"69":{"position":[[26,8]]},"105":{"position":[[0,8]]},"111":{"position":[[8,7]]},"133":{"position":[[4,8]]},"150":{"position":[[17,8]]},"175":{"position":[[4,8]]},"176":{"position":[[0,8]]},"226":{"position":[[8,7]]},"235":{"position":[[4,8]]},"240":{"position":[[4,8]]},"241":{"position":[[4,8]]},"263":{"position":[[28,8]]},"311":{"position":[[3,8]]},"312":{"position":[[4,8]]},"342":{"position":[[5,8]]},"371":{"position":[[0,8]]},"595":{"position":[[17,8]]},"599":{"position":[[8,8]]},"611":{"position":[[0,8]]},"860":{"position":[[4,8]]},"876":{"position":[[4,8]]},"948":{"position":[[10,8]]},"958":{"position":[[0,8]]},"983":{"position":[[22,8]]},"985":{"position":[[18,8]]},"991":{"position":[[15,8]]},"1042":{"position":[[4,7]]},"1142":{"position":[[4,8]]},"1177":{"position":[[4,8]]},"1216":{"position":[[22,8]]},"1245":{"position":[[11,8]]},"1420":{"position":[[6,8]]},"1470":{"position":[[8,7]]},"1743":{"position":[[2,8]]},"1745":{"position":[[4,8]]},"1785":{"position":[[21,7]]}}}],["transfer",{"_index":55,"t":{"61":{"position":[[0,8]]},"1229":{"position":[[20,8]]},"1424":{"position":[[19,15]]},"1426":{"position":[[14,15]]},"1430":{"position":[[15,15]]},"1512":{"position":[[30,8]]},"1522":{"position":[[11,8]]},"1797":{"position":[[4,15]]}}}],["transform",{"_index":75,"t":{"90":{"position":[[11,11]]},"115":{"position":[[22,11]]},"661":{"position":[[22,11]]},"738":{"position":[[21,11]]},"769":{"position":[[29,11]]},"788":{"position":[[0,11]]}}}],["translat",{"_index":224,"t":{"321":{"position":[[12,11]]},"1633":{"position":[[0,9]]}}}],["tune",{"_index":82,"t":{"96":{"position":[[9,6]]},"105":{"position":[[16,6]]},"248":{"position":[[5,5]]},"513":{"position":[[31,6]]},"524":{"position":[[20,6],[56,6]]},"526":{"position":[[19,6]]},"597":{"position":[[29,6]]},"634":{"position":[[7,6]]},"659":{"position":[[11,6]]},"684":{"position":[[10,6]]},"691":{"position":[[20,6]]},"734":{"position":[[30,6]]},"746":{"position":[[5,6]]},"750":{"position":[[17,6]]},"752":{"position":[[13,6]]},"754":{"position":[[8,6]]},"944":{"position":[[9,6]]},"1018":{"position":[[7,6]]},"1020":{"position":[[5,6]]},"1027":{"position":[[16,6]]},"1046":{"position":[[6,6]]},"1048":{"position":[[6,6]]},"1064":{"position":[[23,6]]},"1066":{"position":[[36,6]]},"1096":{"position":[[13,6]]},"1116":{"position":[[43,6]]},"1127":{"position":[[10,6]]},"1161":{"position":[[5,6]]},"1163":{"position":[[7,6]]},"1166":{"position":[[20,6]]},"1194":{"position":[[29,6]]},"1202":{"position":[[11,6]]},"1217":{"position":[[44,6]]},"1220":{"position":[[36,6]]},"1237":{"position":[[7,6]]},"1239":{"position":[[21,6]]},"1299":{"position":[[9,6]]},"1301":{"position":[[10,6]]},"1329":{"position":[[11,6],[27,6]]},"1340":{"position":[[25,6]]},"1366":{"position":[[11,6]]},"1410":{"position":[[20,6]]},"1418":{"position":[[29,6]]},"1480":{"position":[[11,6]]},"1648":{"position":[[10,6]]},"1666":{"position":[[32,6]]},"1668":{"position":[[34,6]]},"1749":{"position":[[22,6]]},"1751":{"position":[[6,6]]},"1753":{"position":[[22,6]]},"1755":{"position":[[22,6]]},"1757":{"position":[[16,6]]},"1791":{"position":[[17,6]]}}}],["tuningv2",{"_index":573,"t":{"1519":{"position":[[21,8]]}}}],["two",{"_index":423,"t":{"838":{"position":[[12,3]]},"1694":{"position":[[3,3]]}}}],["type",{"_index":624,"t":{"1670":{"position":[[26,6]]}}}],["understand",{"_index":17,"t":{"29":{"position":[[0,13]]},"505":{"position":[[30,13]]},"511":{"position":[[0,13]]},"767":{"position":[[3,13]]},"810":{"position":[[21,13]]},"968":{"position":[[7,13]]}}}],["unif",{"_index":149,"t":{"206":{"position":[[0,11]]}}}],["unifi",{"_index":104,"t":{"129":{"position":[[6,7]]},"131":{"position":[[4,7]]},"1385":{"position":[[3,8]]}}}],["unimod",{"_index":277,"t":{"489":{"position":[[5,8]]}}}],["unipelt",{"_index":538,"t":{"1396":{"position":[[16,7]]}}}],["univers",{"_index":450,"t":{"1021":{"position":[[12,12]]},"1023":{"position":[[8,12]]},"1025":{"position":[[8,12]]}}}],["unlearn",{"_index":484,"t":{"1131":{"position":[[4,10]]}}}],["unlikelihood",{"_index":323,"t":{"595":{"position":[[4,12]]}}}],["unlock",{"_index":309,"t":{"564":{"position":[[5,9]]}}}],["up",{"_index":34,"t":{"34":{"position":[[17,2]]},"764":{"position":[[12,2]]},"1079":{"position":[[42,2]]}}}],["updat",{"_index":379,"t":{"732":{"position":[[27,6]]},"767":{"position":[[30,7]]},"1607":{"position":[[0,6]]},"1747":{"position":[[14,6]]}}}],["upl",{"_index":232,"t":{"346":{"position":[[12,3]]}}}],["usabl",{"_index":312,"t":{"568":{"position":[[3,9]]},"578":{"position":[[32,9]]}}}],["usag",{"_index":336,"t":{"615":{"position":[[7,5]]},"643":{"position":[[13,5]]}}}],["user",{"_index":526,"t":{"1338":{"position":[[16,6]]}}}],["util",{"_index":348,"t":{"645":{"position":[[4,7]]}}}],["v.",{"_index":455,"t":{"1051":{"position":[[24,4]]},"1116":{"position":[[17,4],[36,4]]}}}],["v2",{"_index":435,"t":{"943":{"position":[[17,2]]},"1020":{"position":[[12,2]]},"1046":{"position":[[13,3]]},"1048":{"position":[[13,3]]}}}],["valu",{"_index":361,"t":{"687":{"position":[[24,5]]},"798":{"position":[[22,6]]}}}],["variabl",{"_index":244,"t":{"404":{"position":[[0,8]]}}}],["variant",{"_index":87,"t":{"103":{"position":[[6,8]]},"238":{"position":[[18,8]]},"836":{"position":[[0,8]]},"939":{"position":[[19,7]]}}}],["variat",{"_index":226,"t":{"323":{"position":[[10,10]]}}}],["verbal",{"_index":454,"t":{"1051":{"position":[[0,10]]},"1444":{"position":[[31,6]]}}}],["veri",{"_index":20,"t":{"30":{"position":[[14,4]]}}}],["version",{"_index":601,"t":{"1603":{"position":[[14,7]]},"1605":{"position":[[6,7]]},"1607":{"position":[[19,7]]}}}],["vi",{"_index":145,"t":{"196":{"position":[[0,3]]}}}],["via",{"_index":548,"t":{"1430":{"position":[[31,3]]},"1444":{"position":[[27,3]]}}}],["vision",{"_index":74,"t":{"90":{"position":[[4,6]]},"115":{"position":[[15,6]]},"247":{"position":[[15,6]]},"338":{"position":[[0,6]]},"365":{"position":[[0,6]]},"898":{"position":[[0,6]]},"1076":{"position":[[21,6]]}}}],["visual",{"_index":438,"t":{"952":{"position":[[20,6]]},"964":{"position":[[4,6]]},"968":{"position":[[0,6]]},"1524":{"position":[[21,13]]}}}],["vit",{"_index":76,"t":{"90":{"position":[[23,5]]}}}],["vo",{"_index":143,"t":{"190":{"position":[[0,3]]},"198":{"position":[[2,3]]}}}],["vqa",{"_index":257,"t":{"438":{"position":[[23,3]]},"440":{"position":[[26,3]]},"444":{"position":[[18,3]]},"472":{"position":[[58,3]]}}}],["vqav2",{"_index":173,"t":{"248":{"position":[[48,5]]}}}],["vs",{"_index":521,"t":{"1327":{"position":[[9,2]]},"1329":{"position":[[18,2]]}}}],["w\\triangl",{"_index":406,"t":{"777":{"position":[[35,11]]}}}],["weight",{"_index":397,"t":{"769":{"position":[[10,6]]}}}],["what'",{"_index":592,"t":{"1582":{"position":[[0,6]]}}}],["width",{"_index":493,"t":{"1171":{"position":[[10,5]]}}}],["wise",{"_index":212,"t":{"303":{"position":[[13,4]]}}}],["without",{"_index":535,"t":{"1381":{"position":[[17,7]]}}}],["word",{"_index":622,"t":{"1658":{"position":[[36,5]]}}}],["work",{"_index":12,"t":{"26":{"position":[[11,4]]},"87":{"position":[[11,4]]},"166":{"position":[[11,4]]},"222":{"position":[[11,4]]},"337":{"position":[[8,4]]},"427":{"position":[[11,4]]},"437":{"position":[[11,4]]},"486":{"position":[[11,4]]},"530":{"position":[[11,4]]},"647":{"position":[[11,4]]},"677":{"position":[[11,4]]},"682":{"position":[[11,4]]},"766":{"position":[[11,5]]},"779":{"position":[[25,4]]},"850":{"position":[[11,4]]},"888":{"position":[[11,4]]},"935":{"position":[[11,4]]},"1085":{"position":[[11,5]]},"1118":{"position":[[11,4]]},"1228":{"position":[[11,4]]},"1292":{"position":[[11,4]]},"1365":{"position":[[11,4]]},"1400":{"position":[[11,4]]},"1432":{"position":[[11,4]]},"1433":{"position":[[24,4]]},"1443":{"position":[[10,4]]},"1469":{"position":[[11,4]]},"1547":{"position":[[11,4]]},"1687":{"position":[[11,4]]}}}],["world",{"_index":338,"t":{"617":{"position":[[24,5]]}}}],["www",{"_index":408,"t":{"777":{"position":[[62,4]]}}}],["w△w",{"_index":407,"t":{"777":{"position":[[47,3]]}}}],["xprompt",{"_index":563,"t":{"1478":{"position":[[3,7]]},"1522":{"position":[[3,7]]}}}],["xxl",{"_index":392,"t":{"760":{"position":[[12,3]]}}}],["you'll",{"_index":2,"t":{"14":{"position":[[5,6]]}}}],["zero",{"_index":174,"t":{"250":{"position":[[0,4]]},"274":{"position":[[0,4]]},"470":{"position":[[16,4]]},"564":{"position":[[15,4]]},"892":{"position":[[4,4]]},"896":{"position":[[4,4]]},"918":{"position":[[0,4]]},"922":{"position":[[4,4]]},"937":{"position":[[0,4]]}}}],["zero/few",{"_index":259,"t":{"440":{"position":[[12,8]]}}}]],"pipeline":["stemmer"]}},{"documents":[{"i":3,"t":"This is the summary of a very long blog post, Use a <!-- truncate --> comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","s":"Long Blog Post","u":"/blog/long-blog-post","h":"","p":2},{"i":5,"t":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","s":"First Blog Post","u":"/blog/first-blog-post","h":"","p":4},{"i":7,"t":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md 2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","s":"Welcome","u":"/blog/welcome","h":"","p":6},{"i":9,"t":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. <button onClick={() => alert('button clicked!')}>Click me!</button> Click me!","s":"MDX Blog Post","u":"/blog/mdx-blog-post","h":"","p":8},{"i":11,"t":"Let's discover Docusaurus in less than 5 minutes.","s":"Tutorial Intro","u":"/docs/intro","h":"","p":10},{"i":13,"t":"Get started by creating a new site. Or try Docusaurus immediately with docusaurus.new.","s":"Getting Started","u":"/docs/intro","h":"#getting-started","p":10},{"i":15,"t":"Node.js version 16.14 or above: When installing Node.js, you are recommended to check all checkboxes related to dependencies.","s":"What you'll need","u":"/docs/intro","h":"#what-youll-need","p":10},{"i":17,"t":"Generate a new Docusaurus site using the classic template. The classic template will automatically be added to your project after you run the command: npm init docusaurus@latest my-website classic You can type this command into Command Prompt, Powershell, Terminal, or any other integrated terminal of your code editor. The command also installs all necessary dependencies you need to run Docusaurus.","s":"Generate a new site","u":"/docs/intro","h":"#generate-a-new-site","p":10},{"i":19,"t":"Run the development server: cd my-website npm run start The cd command changes the directory you're working with. In order to work with your newly created Docusaurus site, you'll need to navigate the terminal there. The npm run start command builds your website locally and serves it through a development server, ready for you to view at http://localhost:3000/. Open docs/intro.md (this page) and edit some lines: the site reloads automatically and displays your changes.","s":"Start your site","u":"/docs/intro","h":"#start-your-site","p":10},{"i":21,"t":"논문 및 이미지 출처 : https://arxiv.org/abs/2104.00298","s":"EfficientNetV2: Smaller Models and Faster Training","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":23,"t":"EfficientNetV2는 neural architecture speed (NAS) 와 scailing을 통해 이전 모델들 보다 더 빠르고 적은 파라미터 가지는 Convolution Network 특히 SOTA 모델보다 더 빠르면서 6.8배 작다 빠른 속도를 위해 progressive learning 을 도입하지만 이는 정확도를 떨어뜨려, 개선된 method인 adaptively adjust regularization 을 도입","s":"개요","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":25,"t":"GPT3-3 처럼 엄청 큰 모델과 데이터셋을 통한 훈련은 좋은 성능을 보여주지만, 수 천개의 GPU와 주 단위 학습으로, 재훈련 및 개선이 어려움 따라서 훈련 효율성이 최근 관심도가 높아지고 있다. model aim NFNets expensive batch normalization 제거 ConNets attention layer 추가로 훈련 속도 개선 VIT Transformer 블록으로 큰 데이터셋에 훈련 효율성 개선 이전 연구인 EfficientNet 에선 다음 문제점이 존재했다. 매우 큰 사이즈 이미지에는 훈련이 느림 depthwise convolution 이 초기 레이어에선 느림 매 단계마다 하는 동일한 scailing up은 차선책이었음 이를 Fused-MBConv 로 설계하고, NAS 와 scailing 으로 정확도, 속도, 파라미터 사이즈를 최적화한다. (파라미터는 6.8배 작아지고 속도는 4배 빨라짐) 이전 progressive learning 연구(FixRes, Mix&Match)는 모든 이미지 사이즈를 같은 정규화를 하지만, 이는 이상적이지 못하므로 개선된 progressive learning 제안 초기 epoch에 작은 이미지와 약한 정규화로, 서서히 이미지 사이즈를 증가시켜 큰 이미지엔 강한 정규화 학습키는 방법 이 접근법은 정확도를 떨어뜨리지 않으며 속도를 증가시킴 ImageNet 에서 3~9배 빠르고 이전 모델보다 6.8배 작아졌지만 87.7%의 정확도를 보임 이는 ViT-L/16 보다 5~11배 빠르면서 2% 의 높은 정확도를 가졌다.","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":27,"t":"훈련 및 파라미터 효율성 model aim DenseNet, EfficientNet 적은 파라미터로 좋은 정확도를 목표 ResNet, ResNetSt, TResNet, EfficientNet-X inference 속도를 개선 NFNet, BoTNet 훈련 속도 개선 이러한 연구들은 training 이나 inference 속도를 개선했지만 더 많은 파라미터가 생겨났다. Progressive training 관련 연구로 Progressive resizing 과 Mix&Match 가 있지만, 이는 accuracy drop 을 야기한다. curriculum learning 에 영감을 받아, 점점 정규화를 추가함으로써 서서히 학습을 어렵게 한다. Neural architecture search (NAS) image classification, object detection, segmentation 등에선 FLOPs 나 inference 효율 개선으로 주로 연구됐지만, 본 논문에서는 training 및 parameter 효율 개선으로 사용","s":"2. Related Work","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":31,"t":"EfficientNet 에선 큰 이미지에 대한 학습이 느리다고 했다. (모든 메모리가 GPU/TPU 에 고정 & 큰 이미지로 인한 작은 배치를 사용했어야 했서 속도가 느려졌다고 함) 간단한 개선법으로 작은 이미지 사이즈로 FixRes 를 적용하는 것이다. 위 표와 같이 작은 이미지로 배치를 늘려 2.2배 속도가 빨라지고 약간의 높은 정확도를 얻었다. (어떠한 fine-tuning 을 이용하지 않고도)","s":"Training with very large image sizes is slow","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#training-with-very-large-image-sizes-is-slow","p":20},{"i":33,"t":"EfficientNet 에서 사용한 Depthwise convolution 은 regular convolution 보다 적은 파라미터와 FLOPs 를 가지지만 accelerator 를 활용할 수 없게 된다. 그래서 최근에 MBConv 의 depthwise conv3x3 과 Conv1x1 을 single regular conv3x3 으로 교체한 Fused-MBConv 가 제안되었다. 두 블록을 비교하기 위해 MBConv 로 이루어진 EfficientNet-B4 모델에 서서히 Fused-MBConv 로 교체해보았다. 모든 블록을 Fused-MBConv 로 바꾸기 보단, 1-3 초기 단계를 교체하니 Params 와 FLOPs 가 적으면서도 정확도가 높았다.","s":"Depthwise convolutions are slow in early layers but effective in later stages","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#depthwise-convolutions-are-slow-in-early-layers-but-effective-in-later-stages","p":20},{"i":35,"t":"EfficientNet 에서 매 단계 동일하게 scailing up 하는 것은 차선책이었다. 이는 훈련 속도 및 파라미터 효율성에 기여를 하지 못하여, 본 논문에서는 non-uniform scaliling 전략으로 후기 단계에 서서히 추가하는 것을 제안 추가로 EfficientNet 에서 이미지를 scale up 을 하니 큰 메모리 소비와 훈련 속도 저하를 야기했음 이 이슈 해결을 위해서 scailing 규칙을 약간 수정하고, 최대 이미지 크기를 좀 더 작은 값으로 제한함","s":"Equally scailing up every stage is sub-optimal","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#equally-scailing-up-every-stage-is-sub-optimal","p":20},{"i":38,"t":"accelerator 를 사용하여 정확도, 파라미터 그리고 훈련 효율성을 최적화하기 위해 training-aware NAS 를 사용 EfficientNet 을 사용하며 search space 는 stage 기반의 factorized space 로 구성되며, {MBConv, Fused-MBConv} 의 convolution 과 {3x3, 5x5} 의 커널 사이즈, 확장 비율 {1, 4, 6} 을 포함한다. 반면에, 불필요한 작업인 pooling 을 제거 EfficientNet 에서 이미 연구된 채널 크기를 재사용 하여 search space 사이즈를 줄임 A - model accuracy S - nomalized training step time P - parameter size 를 다음과 같이 결합하여 search reward 에 대한 간단한 가중치를 만든다. A · Sw · Pv - weight w = -0.007 v = -0.05","s":"NAS Search","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#nas-search","p":20},{"i":40,"t":"위는 EfficientNetV2-S 의 아키텍처로, 기존 EfficientNet 과의 차이점은 다음과 같다. MBConv 와 초기 단계에 fused-MBConv 사용 MBConv 의 적은 비율을 선호 3x3 kernel 사이즈를 선호 EfficientNet 의 마지막 단계에서 stride-1 을 제거 위 차이점들로 파라미터와 처리시간을 줄임","s":"EfficientNetV2 Architecture","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#efficientnetv2-architecture","p":20},{"i":42,"t":"몇 가지 추가적인 최적화로 EfficientNetV2-S 를 scale up 하여 EfficientNetV2-M/L 을 얻었다. 매우 큰 이미지는 큰 메모리 비용 및 훈련 속도 오버헤드를 야기하므로 최대 480 으로 제한 EfficientNetV2-S 처럼 5-6단계에서 서서히 레이어를 더 추가","s":"EfficientNetV2 Scailing","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#efficientnetv2-scailing","p":20},{"i":44,"t":"모든 모델을 progressive learning 을 하지 않고 고정된 사이즈 이미지로 훈련한 결과, training-aware NAS 와 scailing 을 적용한 EfficientNetV2 가 다른 모델들 보다 매우 빠른 것을 관찰했다.","s":"Training Speed Comparison","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#training-speed-comparison","p":20},{"i":47,"t":"이미지 사이즈는 훈련 효율성에 큰 영향을 준다고 했었다. 다른 연구에서 다이나믹하게 이미지 사이즈를 훈련 중에 바꾸는데 (고정된 regularization 으로), 이는 정확도 저하를 야기했다. 이는 unbalanced regularization 으로 인해 생겨난다고 가설을 세운다. unbalanced regularization 가설을 입증하기 위해 각기 다른 이미지 사이즈와 데이터 augmentation으로, 작은 이미지는 약한 augmentation, 큰 이미지는 강한 augmentation을 사용한 것이 정확도가 좋았다. 따라서 본 논문에서는 작은 이미지에는 약한 regularization 을, 큰 이미지에는 강한 regularization 으로 과적합을 방지하는 것이 중요하다고 주장한다. 위 실험을 통해, progressive learning 을 개선한 method 인 adaptively adjust regularization 을 제안한다.","s":"Motivation","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#motivation","p":20},{"i":49,"t":"위와 같이 훈련 프로세스에 개선된 progressive learning 을 사용한다. 초기 에폭에 작은 이미지와 약한 정규화를 사용하여 학습을 쉽게하고 빠르게 한다. 이미지 크기를 서서히 증가 시키며, 강한 정규화를 추가하여 학습을 어렵게 한다. N - 전체 steps Se - 타깃 이미지 사이즈 Φe - 정규화 magnitude 리스트 = {Φek} k - dropout rate 또는 maxiup rate value 와 같은 정규화 타입 M - 각 훈련을 M stage 로 나눔 각 stage 는 1 <= i <= M 이고, 모델은 Si 사이즈 이미지와 Φi = {Φik} 의 정규화를 훈련한다. 처음엔 S0 와 Φ0 을 초기화하고, 각 단계의 값을 결정하기 위해 linear interpolation 을 사용한다. 알고리즘은 다음과 같다. 본 논문에서는 다음 3 가지의 정규화를 다룬다. Dropout - 무작위로 채널을 dropping 함. magnitude - γ\\gammaγ RandAugment - 각 이미지마다 데이터 증강. magnitude - ϵ\\epsilonϵ Mixup - data augmentation 을 교차시킨다. 라벨이 있는 두 이미지 (xi,yi)(x_i, y_i)(xi​,yi​) 와 (xj,yj)(x_j, y_j)(xj​,yj​) 가 주어졌을 때, λ 비율로 섞어 결합한다. x~i=λxj+(1−λ)xi\\tilde{x}_i = \\lambda{x}_j + (1-\\lambda)x_ix~i​=λxj​+(1−λ)xi​ and y~i=λyj+(1−λ)yi\\tilde{y}_i = \\lambda{y}_j + (1-\\lambda)y_iy~​i​=λyj​+(1−λ)yi​ magnitude - λ\\lambdaλ","s":"Progressive Learning with adaptive Regularization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#progressive-learning-with-adaptive-regularization","p":20},{"i":53,"t":"1.28M 훈련셋과 50,000 검증셋의 1000 클래스가 포함된 ImageNet ILSVRC2012 에는 테스트셋이 없으므로 훈련셋에서 25,000 이미지를 남김 훈련 세팅은 EfficientNet 을 따른다. RMSProp optimizer ( 0.9 decay, 0.9 momentum ) 0.99 batch norm momentum 1e-5 weight decay 350 epoch 0.256 lr, decayed 0.97 every 2.4 epoch exponential moving average (EMA) 0.9999 decay rate Regularization RandAgment Mixup Dropout progressive learning 은 4단계로, 약 87 에폭 당 진행했다고 한다.","s":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup","p":20},{"i":55,"t":"위의 성능표에서 보이듯 같은 computing resource 에서 EfficientNetV2-M 은 EfficientNet-B7 보다 11배 빠르다 한다. ResNetSt 와 비교하면 EfficientNetV2-M 이 2.8배 더 빠르면서도 0.6% 의 정확도가 높았다.","s":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results","p":20},{"i":58,"t":"ImageNet21k 는 21,841 클래스와 13M 훈련셋을 가진다. 테스트와 검증셋이 없으므로 무작위로 100,000개 이미지를 검증셋으로, 나머지는 테스트셋으로 이용한다. ImageNet ILSVRC2012 의 세팅을 사용하면서도 약간 변화를 주었다. 훈련 시간을 줄이기 위해 에폭수를 60 또는 30으로 변경 각 이미지는 multiple labels 를 가지므로, softmax loss 계산 전에 1로 합쳐서 정규화 진행","s":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup-1","p":20},{"i":60,"t":"위 성능표에서 보이듯 EfficientNetN2-L 는 Vit-L 보다 2.5배 더 적은 파라미터와 3.6배 더 적은 FLOPs, 그리고 6~7배 빨라진 학습 속도를 보였다.","s":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results-1","p":20},{"i":63,"t":"ImageNet ILSVRC2012 을 훈련하여 CIFAR-10, CIFAR-100, Flowers, Cars 데이터셋을 fine-tuning 한다. 훈련 세팅은 ImageNet 과 비슷하며, 약간의 수정이 있다. 512 batch size 0.001 lr, cosine decay fixed 10,000 steps disable weigt decay, simple data augmentation","s":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup-2","p":20},{"i":65,"t":"위의 성능표에서 보이듯, CIFAR-100 에서 EfficientNetV2-L 은 이전 모델 GPipe/EfficientNets 보다 0.6%, ViT/DeiT 보다 1.5% 더 좋은 정확도를 보인다.","s":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results-2","p":20},{"i":68,"t":"EfficientNetV2 와 EfficientNets 를 비교해보자.","s":"Comparison to EfficientNet","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#comparison-to-efficientnet","p":20},{"i":72,"t":"progressive learning 을 다른 모델에도 적용하여 비교한다.","s":"Progressive Learning for Different Networks","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#progressive-learning-for-different-networks","p":20},{"i":74,"t":"이미지 크기에 따른 adaptive regularization 접근법을 이용하여 결과를 관찰한다.","s":"Importance of Adaptive Regularization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#importance-of-adaptive-regularization","p":20},{"i":76,"t":"training-aware NAS 와 model scailing 으로 최적화 개선된 progressivel learning 인 adaptively adjust learning 으로 이미지 크기를 서서히 증가시키며 강한 정규화를 사용 기존의 EfficientNet 의 아키텍처 초기 단계에 Fused-MBConv 를 교체 위 사항들을 통해 기존 EfficientNet 모델보다 6.8배 작아졌으며 11배 빨라졌다.","s":"7. Conclusion","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":78,"t":"Problems Solutions Training with very large image size is slow Apply FixRes with small image size Depthwise convolutions are slow in early layers but effective in later stages Gradually replace MBConv with Fused-MBConv Equally scailing up every stage is sub-optimal In early stage, Train small image size with weak regularization and gradually increase image size with stronger regularization Improved method of progressive learning: adaptively adjust regularization In the early epoch, train the network with small image size and weak regularization (e.g., dropout, randaugment, mixup) then gradually increase image size and add stronger regularization Speed up the training without causing accuracy drop use three types of regularization Dropout RandAugment Mixup Defference from EfficientNet Architecture In the early stage (1-3), replace MBConv with Fused-MBConv remove stride-1 in the last stage refer kernel of 3x3 size Training-Aware NAS and Scailing Algorithm","s":"Summarization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":80,"t":"Setup 350 epoch 1e-4 lr, 1e-5 weight decay, 0.9 momentum RMSProp Implemented Network Code https://github.com/whdnjsdyd111/Paper-Experiments/blob/main/Image%20Classification/models/net/efficientnet.py","s":"Experiments","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":82,"t":"논문 및 이미지 출처 : https://arxiv.org/abs/2010.11929v2","s":"An Image Is Worth 16X16 Words: Transformers for image recognition at sacle","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":84,"t":"NLP task 에서 Transformer Architecture 가 사용되어 오고 있다. 본 논문에서는 vision 의 CNN 구조를 유지하면서 Transformer 를 적용해 훌륭한 결과로 SOTA 를 달성하였다. 이를 Vision Transformer (ViT) 로 명명한다.","s":"Abstract","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":86,"t":"비전 분야에서, CNN-like 아키텍처 와 self-attention 을 결합하는 여러 시도가 있었고, 일부에서는 CNN 을 완전 교체 후자 모델은 이론적으로는 효율적이지만 GPU 에서 효과적으로 확장되지 않았음 위 사항들로 여전히 ResNet 과 같은 아키텍처가 여전히 SOTA 를 달성 본 논문은, 이에 가능한 한 적은 수정으로 표준 Transformer 를 직접 이미지에 적용하기 위해 실험을 진행 이미지를 패치 단위로 분할 분할된 패치의 선형 임베딩 시퀀스를 NLP 의 토큰처럼 처리하여 Transformer 에 입력으로 제공 중간 규모 데이터셋(ImageNet)으로 학습했을 때는 ResNet 보다 정확도가 낮은데, Transformer 는 equivariance 와 locality 같은 inductive bias 가 부족하여 일반화가 잘 되지 않기 때문으로 보인다. 큰 규모의 데이터셋(14M-300M 이미지)에서 훈련되면, 위 단점이 보완되어 다른 데이터셋에 transfer learning 을 한 결과 뛰어난 정확도를 보였다. inductive bias inductive bias 란 머신 러닝이 학습할 때, 어떤 가정이나 제한을 통하여 문제 공간을 탐색하는 방식 모델이 데이터로부터 일반화를 하는 데 중요한 역할 딥 러닝에서 inductive bias 의 예로 Layer 의 수, 각 Layer 의 뉴런 수, activation function 등의 구조적 제한이 있다. 적절한 inductive bias 로 일반화 성능을 올릴 수 있지만, 부적절하면 과적합을 발생한다. Trnasformer 에서 이러한 inductive bias 가 부족한 이유는 논문의 방법론 설명에 나온다.","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":88,"t":"Transformer 를 이미지 처리에 적용하려면 각 픽셀이 다른 모든 픽셀에 대한 self-attention 을 적용해야 했기 때문에 실질적으론 힘들다. self-attention 따라서 각 쿼리 픽셀의 지역 이웃에 대해서 self-attention 을 적용하거나, Sparse Transformer, block 크기 가변적 조정 등 다양한 방법으로 self-attention 을 적용하였지만 GPU 에서 효율적이지 못하였다. patch 이어, Cordonnier 모델은 2x2 크기 패치로 self-attention 을 적용하였는데, ViT 와 유사하지만, 패치가 작아 작은 해상도에서만 적용이 가능하나 본 연구는 중간 해상도에도 적용이 가능하다. combination CNN with self-attention Bello 등은 feature map 에 self-attention 을 추가, Hu 등은 CNN 의 출력 결과를 self-attention 으로 추가 처리하며 다양하게 CNN 과 self-attention 을 결합한 연구가 이루어지고 있다. 본 연구에서는 ImageNet 보다 큰 ImageNet-21k 와 JFT-300M 과 같은 대규모 데이터셋에서, 데이터셋 크기에 따른 CNN 성능이 어떻게 변화하는 지 연구하며 Transformer 를 훈련시킨다.","s":"2. Related Work","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":91,"t":"표준 Transformer (NLP) 에서는 token embedding 의 1D sequence 를 받는다. 2D 인 이미지를 다루기 위해, 이미지를 다음과 같이 처리한다. 이미지 입력 Embedding 이미지 x∈RH×W×Cx \\in \\mathbb{R}^{H \\times W \\times C}x∈RH×W×C 를 flattened 2D patch 의 sequence 인 xp∈RN×(P2⋅C)x_p \\in \\mathbb{R}^{N \\times ( P^2 \\cdot C )}xp​∈RN×(P2⋅C) 로 재배치한다. (H,W)(H, W)(H,W) : 원본 이미지 해상도 CCC : 채널 수 (P,P)(P, P)(P,P) : 각 이미지 패치의 해상도 N=HW/P2N = HW/P^2N=HW/P2 : 생성된 패치의 수, Transformer 의 효과적인 input sequence 길이 Transformer 는 모든 레이어에서 일정한 latent vector 사이즈 DDD 를 사용하므로, 패치를 flatten 하고 linear projection (아래의 식 1) 으로 DDD 차원으로 매핑한다. 이 projection 의 출력을 patch embedding 이라 칭한다. latent vector $$ latent vector 는 데이터를 압축하고 잠재적인 특징을 추출하는 데 사용되는 벡터이다. 일반적으로 입력 데이터를 저차원 벡터 공간으로 매핑하여 유용한 정보를 추출하고, 해당 정보를 바탕으로 다양한 테스크를 수행하는 데 사용된다. Token BERT 의 [ class ] token 과 유사하게, embedding patch 에 학습 가능한 embedding ( z00=xclassz_{0}^{0} = x_{\\textup{class}}z00​=xclass​ ) 을 추가 Transformer encoder 의 출력 상태 ( zL0z_{L}^{0}zL0​ ) 는 이미지 표현 yyy 로 사용 (아래의 식 4) pre-training 및 fine-tuning 을 수행할 때 Classification Head 를 zL0z_{L}^{0}zL0​ 에 부착 Classification Head pre-training : 1-hidden layer 인 MLP fine-tuning : 1-linear layer Position embedding position 정보 유지를 위해, Position embedding 을 patch embedding 에 추가 2D-aware position embedding 의 성능 향상은 관찰되지 않음 → 1D position embedding 사용 embedding vector 의 sequence 를 encoder 에 입력 Transformer encoder Multi-Head self-attention 와 MLP Block 을 교차하는 Layer 를 포함 Layernorm (LN) 을 모든 Block 이전에 적용 Residual Connection 을 모든 블록 끝에 적용 MLP 는 GELU non-linearity 가 있는 두 개의 레이어를 포함 (1) zo=[xclass; xp1E; x1=2pE; ...; xpNE]+Epos, E∈RN×(P2⋅C), Epos∈R(N+1)×Dz_o = [x_\\textup{class};\\ x^1_p\\textup{E};\\ x^1=2_p\\textup{E};\\ ...;\\ x^N_p\\textup{E}] + E_{pos},\\ E \\in \\mathbb{R}^{N \\times ( P^2 \\cdot C )},\\ E_{pos} \\in \\mathbb{R}^{(N + 1) \\times D}zo​=[xclass​; xp1​E; x1=2p​E; ...; xpN​E]+Epos​, E∈RN×(P2⋅C), Epos​∈R(N+1)×D 입력에 해당하는 수식으로, patch 로 나눈 각 이미지 시퀀스다. 마지막 EposE_{pos}Epos​ 는 각 시퀀스의 순서를 나타내는 Positional Encoding 이다. (2) zϱ′=MSA(LN(zϱ−1))+zϱ−1, ϱ=1 ... Lz'_\\varrho = \\textup{MSA}(\\textup{LN}(z_{\\varrho-1})) + z_{\\varrho-1},\\ \\varrho = 1 \\ ...\\ Lzϱ′​=MSA(LN(zϱ−1​))+zϱ−1​, ϱ=1 ... L Transformer Encoder 의 수식으로, Layer Normalization (LN) 후, Multi-head Attention (MSA) 을 적용 이후, Residual 로 zϱ−1z_{\\varrho - 1}zϱ−1​ 을 더한다 (3) zϱ=MLP(LN(zϱ′))+zϱ′,ϱ=1 ... Lz_\\varrho = \\textup{MLP}(\\textup{LN}(z'_\\varrho)) + z'_\\varrho,\\qquad \\varrho = 1 \\ ...\\ Lzϱ​=MLP(LN(zϱ′​))+zϱ′​,ϱ=1 ... L MLP head 의 수식으로, 위와 동일하다. (4) y=LN(zL0)y = \\textup{LN}(z^0_L)y=LN(zL0​) 마지막으로, classification 으로 target 값을 찾는다.","s":"3.1 Vision Transformer (ViT)","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#31-vision-transformer-vit","p":81},{"i":93,"t":"CNN 은 locality, 2D 이웃 구조체를 내재 반면, ViT 는 MLP 레이어만 지역성을 가지고, self-attention 레이어는 전역적이기 때문에 CNNs 보다 inductive bias 가 적다. Transformer 에서는 이 2D 이웃 구조체는 극히 드물게 사용한다. 모델 시작 부분에서 이미지를 패치로 자르는 것 fine-tuning 시 이미지의 position embedding 조절 position embedding 은 초기화 시 패치들의 2D position 정보가 없으며, 패치 간의 모든 관계를 처음부터 학습 해야함","s":"Intuctive bias","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#intuctive-bias","p":81},{"i":95,"t":"원시적인 Image patch 대안으로, sequence 는 CNN 의 feature map 으로 구성하는 것이 가능하여 Hybrid model 을 만든다. patch embedding projection EEE (식 1) 은 CNN feature map 으로 추출된 patch 에 적용한다. 특별한 경우, patch 는 1x1 사이즈도 가능 한데, 이는 sequence 가 feature map 의 차원을 flatten 하고 projecting 하여 Transformer 차원으로 얻을 수 있다는 것을 의미한다. CNN feature map 으로 patch 추출 → Flatten → embedding projection EEE (식 1)","s":"Hybris Architecture","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#hybris-architecture","p":81},{"i":97,"t":"일반적으로 ViT 를 큰 데이터셋에 pre-training 하고 downstream task 로 fine-tuning 이를 위해 다음 사항들을 진행한다. prediction head 제거 0 으로 초기화된 D×KD \\times KD×K 를 feedforward layer 에 부착 (여기서 KKK 는 downstream class 수) pre-training 보다 높은 해상도로 fine-tune 하는 것이 이득 높은 해상도로 할 땐, patch size 를 동일하게 해야함 → 더 큰 effective sequence length 가 생성 fine-tune 시, pre-trained 의 position embedding 은 의미가 없음 따라서 pre-trained 의 position embedding 을 2D 보간 (interpolation) 해야 함 위의 해상도 조정 및 패치 추출은 ViT 에 대한 이미지 구조의 inductive bias 를 삽입하는 방법","s":"3.2 fine-tuning and higher resolution","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#32-fine-tuning-and-higher-resolution","p":81},{"i":99,"t":"Resnet, ViT, hybrid 를 각각 평가한다.","s":"4. Experiments","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":102,"t":"train dataset ILSVRC-2012 ImageNet-1k (1.3M images) ImageNet-21k (14M images) JFT-18k (303M high resolution images) transfer dataset transfer learning 평가 ImageNet ImageNet ReaL CIFAR-10/100 Oxford-IIIT Pets/-Flowers102 VTAV 또한 19-task VTAB 분류 평가로 여러 그룹의 작은 데이터셋 transfer 평가 Natural : Pets, CIFAR Specialized : medical, satellite imagery Structured : geometric, localization","s":"Datasets","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#datasets","p":81},{"i":104,"t":"Table 1 의 Base, Large, Huge 는 BERT 를 기반으로한 ViT 의 구성이다. 간단한 표기법으로 모델 사이즈 및 input patch 사이즈를 다음과 같이 나타낸다. ViT-L/16 : 16x16 input patch 및 \"Large\" 모델 sequence length 는 patch 크기 제곱에 반비례 → patch 가 작을수록 계산량 증가 CNN 베이스라인은 ResNet 으로, 다음과 같이 수정을 더하였다. Batch Normalization → Group Normalization & Standardized Convolution 이렇게 수정한 ResNet 을 BiT 라 표시 transfer learning 의 성능 향상 Hybrid 모델의 경우, 중간 feature map 으로 ViT 에 한 픽셀 (1x1) 의 patch 사이를 입력 각기 다른 sequence length 로 실험 ResNet50 - stage 4 ResNet50 - stage 3 (단, Layer 수 유지) → 4배 더 긴 sequence length (stage 3 의 output 이 확장되므로)","s":"Model Variants","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#model-variants","p":81},{"i":106,"t":"train model include ResNet Adam ( β1=0.9\\beta_1 = 0.9β1​=0.9 , β2=0.999\\beta_2 = 0.999β2​=0.999 ) batch size 4096 weight decay 0.1 fine-tune SGD batch size 512 고해상도 변경 : 512 - ViT-L/16, 518 - ViT-H/14","s":"Training & Fine-tuning","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#training--fine-tuning","p":81},{"i":108,"t":"few-shot 정확도는 다음과 같이 얻는다. 고정된 훈련 이미지의 representation 추출 {−1,1}K\\{ -1,1 \\}^K{−1,1}K target vector 로 매핑 위 과정으로 regularized least-squares regression 문제를 해결하여 얻음 주로 fine-tuning 성능에 초점을 두지만, 비용이 많이 들어 linear few-shot 정확도를 빠르게 평가","s":"Metrics","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#metrics","p":81},{"i":110,"t":"ViT-H/14 와 ViT-L/16 를 CNN SOTA 모델들과 비교 한다. BiT Large EfficientNet 으로 semi-supervised 훈련한 Noisy Student 모든 모델은 TPUv3 로 훈련을 진행하였고, 결과는 위 Table 에서 나타난다. 위 그림은 각 VTAB 작업 그룹에 따른 결과 비교이다.","s":"4.2 Comparison to State Of The Art","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#42-comparison-to-state-of-the-art","p":81},{"i":112,"t":"각각 ImageNet, ImageNet-21k, JFT-300M 데이터셋으로 pre-train 한 결과 JFT-300M 이 가장 좋았다. 이는 ResNet 보다 inductive bias 가 적기 때문에 많은 데이터가 있어야 하기 때문이다. 각 pre-train 후 작은 데이터셋에서 성능을 올리기 위해, 세 가지 regularization 을 설정한다. weight decay dropout label smoothing 두 번째로, JFT-300M 의 하위집합으로 9M, 30M, 90M 및 전체를 학습하여 비교한다. 하위 집합에는 추가적인 정규화를 수행하지 않고 모든 하이퍼파라미터를 동일하게 사용한다. 여기서 fine-tuning 정확도 대신 linear few-shot 정확도를 관찰한다. 위 그래프에서 보이듯 작은 데이터셋에는 ResNet 보다 오버피팅 발생한다. 이 결과로 다음을 알 수 있다. transfer learning 시 작은 데이터셋에는 convolution inductive bias 가 유리 transfer learning 시 ViT 는 큰 데이터셋에 유리","s":"4.3 Pre-trained Data Requirements","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#43-pre-trained-data-requirements","p":81},{"i":114,"t":"각 Transformer, BiT, Hybrid 의 크기에 대한 실험 모델은 다음과 같다 ResNets, R50x1, R50x2 R101x1, R152x1, R152x2 pre-train for 14 epochs R152x2, R200x3 pre-train for 14 epochs ViT-B/32, B/16, L/32, L/16 pre-train for 7 epochs L/17, H/14 pre-train for 14 epochs R50+ViT-B/32, B/16, L/32, L/16 pre-train for 7 epochs R50-ViT-L/16 pre-train for 14 epochs 이 실험에서 다음을 관찰할 수 있다. ViT 는 성능/계산 적으로 BiT 보다 뛰어남 적은 비용에선 Hybrid 가 ViT 보다 약간 더 좋음 ViT 는 포화되지 않아, 성능이 더 좋아질 수도 있다.","s":"4.4 Scailing Study","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#44-scailing-study","p":81},{"i":116,"t":"ViT 가 이미지를 처리하는 법을 이해하기 위해 internal representation 을 분석한다. internal representation 이미지 처리 과정에 모델은 입력 이미지의 다양한 특징을 추출하며, 이러한 특징을 모델 내부의 데이터에 맞는 representation 으로 변환한다. Transformer 에서는 이미지 정보를 2D attention 메커니즘으로 1D embedding 으로 변환한다. 이 embedding 이 Transformer 의 internal representation 이다. 왼쪽 : ViT-L/32 로 RGB 의 initial linear embedding 로 Filter 각 Filter 는 저차원의 CNN filter 와 유사 중앙 : ViT-L/32 의 position embedding 유사도 Projection 후 position embedding 이 patch representation 에 추가 즉, 더 가까운 패치 (같은 행/열 등)는 더 유사한 position embedding 을 가짐 → patch 간의 공간정보가 잘 학습 오른쪽 : head 와 network depth 에 따른 attened area 사이즈 self-attention 으로 전체 이미지 정보를 통합 가능한지 조사 attention weight 를 기반으로 image space 간 평균 거리 계산 이 attention distance 는 CNN 의 receptive field 와 유사 낮은 layer 의 self-attention head (낮은 attention distance 지님) 는 CNN 의 초기 convolutional layer 와 유사한 기능을 가짐 → localization 효과 나아가 이미지 분류에 의미있는 영역에 attention 하는 것 발견 receptive field receptive field 는 입력된 이미지의 어떤 부분에서 반응을 보이는지를 나타내는 개념","s":"4.5 Inspecting Vision Transformer","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#45-inspecting-vision-transformer","p":81},{"i":118,"t":"NLP task 에서 self-supervision 을 시도 예로, BERT 에서의 masking ViT 에선 masked patch 를 예측함으로 self-supervision ViT 에서 self-supervision 한 결과 ViT-B/16 모델은 ImageNet 에서 79.9% 정확도 달성 Supervised Learning 보다는 4% 떨어짐","s":"4.6 self-supervision","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#46-self-supervision","p":81},{"i":120,"t":"patch 추출 단계에서 image-specific inductive bias 를 도입하지 않음 대신, 이미지를 sequence 처럼 해석하여 표준 Transformer encoder 로 진행 큰 데이터셋으로 pre-train 하면 잘 작동 (위 실험의 JFT-300M) 남은 과제 detection, segmentation 에서는 ViT 를 어떻게 적용할 것인가 self-supervised 와 큰 규모의 supervised pre-training 간의 갭 ViT 의 scailing 으로 성능 향상 기대","s":"5. Conclusion","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#5-conclusion","p":81},{"i":122,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2206.07669v2.pdf","s":"A Unified Sequence Interface for Vision Tasks","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":124,"t":"NLP 분야는 단일 통합 모델링 프레임워크로 표현할 수 있지만 computer vision 분야에선 아직 없다. 결과로, 서로 다른 vision task 에 대한 아키텍처와 loss function 이 급증하고 있다. 이에 저자는 computer vision 의 다양한 핵심 task 들은 공유된 pixel-to-sequence interface 형태로 나타내면, 통합될 수 있다고 한다. 그리고 bounding box 나 dense mask 와 같은 다양한 타입의 출력을 가진 task 인 object detection, instance segmentation, keypoint detection 및 image captioning 과 같은 네 가지 task 에 초점을 둔다. 각 출력을 통합된 interface 와 discrete token 의 시퀀스로, 특정 task 에 커스터마이징 없이 단일 모델 아키텍처와 모든 task 에 대한 loss function 으로 모델을 학습시킨다. 특정 task 에 풀기 위해, short prompt 를 task description 으로 사용하고 시퀀스 출력을 prompt 에 적응하여 특정 task 의 output 을 생성한다. 이러한 모델로 task 별로 잘 알려진 모델과도 갱쟁력 있는 성능을 보였다.","s":"Abstract","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":126,"t":"다양한 task 를 수행할 수 있는 단일 신경망을 훈련하는 것은 인공 지능의에서 중요한 진전이다. 최근 몇년간, Transformer 을 사용한 큰 언어 모델의 등장으로, 서로 다른 언어 및 관련 task 들이 단일 모델링으로 통합되었다. 이러한 언어 모델은 주어진 task description 으로 해결책을 예측하도록 훈련된다. 이것이 가능한 이유는 이러한 task 들은 동일한 rich language interface 에서 표현할 수 있기 때문이다. 이는 image captioning 이나 visual question answering 처럼 computer vision 쪽으로 확장 가능하나, \"핵심\" computer vision task 에는 자연어로 쉽게 표현할 수 없다는 것이다. object detection : bounding boxes, class label instance segmentation : segmentation mask, image regions keypoint detection : keypoints 이러한 복잡한 tasks 들은 각각 따로 특화된 아키텍처나 loss function 이 개발된다. 서로 다른 vision 을 통합하기 한다는 것은 아키텍처 및 loss function 설계를 간소화하고 task 간의 feature/representation 공유를 촉진하여, task 간의 정교한 output head 를 필요로 하지 않도록 하는 것이다. 또한 기존 모델을 새 task 에 적응시키는 것을 용이하게하고, zero, few 의 새로운 기능을 잠재적으로 열 수 있다. 끝으로, 저자는 네 가지 서로 다른 task 를 단일 pixel-to-sequence interface 로 통합하는 방법을 제시한다. 네 가지 vision task는 object detection, instance segmentation, human keypoint detection, image captioning 이며, 먼저 이 task 들을 single shared interface 로 통합하는 방법을 보여준다. 이후, shared architecture 와 object function 이 있는 뉴럴 네트워크를 훈련한다. 특정 task 에 적용하기 위해선, specific head 사용과, prompt 를 사용하여 task 를 지정하며, sequence output 을 prompt 에 적응시킨다. 이로서, 주어진 task description 으로 특정 task 의 output 을 생성한다.","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":128,"t":"저자는 computer vision task 를 pixel input (task 의 description 과 함께) 을 별개의 tokensequence 로 변환하는 task 중 하나로 캐스팅한다. 저자는 다음 4 가지 task 에 초점을 둔다. object detection instance segmentation keypoint detection image captioning","s":"2. Approach","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":130,"t":"서로 다른 task 는 각각 다음 output 을 가진다. object detection : bounding boxes, class label instance segmentation : segmentation mask, image regions keypoint detection : keypoints image captioning : natural language description, sequence 위와 같이 각각의 task 는 출력 형태가 차이가 있어, 전용 모델 아키텍처와 loss function 이 필요하다. 이를 단일 모델로 해결하기 위해, 저자는 task input 및 output 을 unified interface 로 transformation/tokenization 하는 것을 주장한다. 이 연구에서, sequence interface 를 제안하며, tkas description 및 output 은 다양한 작업의 시퀀스로 표현된다. Object Detection bounding boxes 와 object description 을 연속적인 이미지 좌표를 quantizing 하여 다양한 토큰 의 시퀀스 로 변환 object 는 [ymin⁡,xmin⁡,ymax⁡,xmax⁡,c][y_{\\min}, x_{\\min}, y_{\\max}, x_{\\max}, c][ymin​,xmin​,ymax​,xmax​,c] 와 같은 5 개의 discrete token 의 시퀀스 로 표현 multiple object 는 훈련 이미지를 샘플링할 때마다 주막위로 정렬되어 하나의 시퀀스 로 직렬화 Instance Segmentation 픽셀 단위의 마스크 대신, 해당 instance mask 에 대응하는 polygon 을 개별 객체 인스턴스에 조건화된 이미지 좌표의 시퀀스로 예측하고 또한, polygon 을 시퀀스로 바꾸기 위해, 훈련용 이미지가 샘플링될 때마다 시작 토큰에 대한 시작점을 무작위로 선택 동일한 인스턴스에 여러 polygon 이 있다면, 각 polygon 의 시퀀스를 연결하여 모든 인스턴스에 대해 하나의 대응하는 시퀀스를 얻도록 한다. Keypoint Prediction 주어진 사람 인스턴스에 조건부로 양자화된 이미지 좌표의 시퀀스로 keypoint 를 예측 keypoint 의 시퀀스는 [ykeypoint 1,xkeypoint 1,ykeypoint 2,xkeypoint 2,⋯ ][y_{\\textup{keypoint\\ 1}}, x_{\\textup{keypoint\\ 1}}, y_{\\textup{keypoint\\ 2}}, x_{\\textup{keypoint\\ 2}}, \\cdots][ykeypoint 1​,xkeypoint 1​,ykeypoint 2​,xkeypoint 2​,⋯] 로 인코딩 각 (y,x)(y, x)(y,x) 좌표에 keypoint label (예; 코, 왼쪽 눈, 오른쪽 눈)을 사용할 수 있지만, 간단함을 위해 고정된 순서는 필요하지 않음 일부 keypoint 가 가려져 있는 경우, 좌표 토큰을 특수한 가림 토큰 (occlusion token) 으로 대체 Captioning discrete token 의 시퀀스로 주어진 caption 의 text token 을 직접 예측 네 가지 task 는 모두 동일한 단일 vocabulary 를 가진다.","s":"2.1 A unified interface with tokenization","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#21-a-unified-interface-with-tokenization","p":121},{"i":132,"t":"저자는 복잡한 image input 과 sequence output 을 유연하고 표현력 있는 아키텍처가 필요하다. 따라서 image encoder 와 sequence decoder 가 있는 encoder-decoder 아키텍처를 사용한다. image encoder : 픽셀 인식 및 hidden representation 으로 매핑 여기서 hiden representation 은 ConvNet, Transforer 이나 이들의 조합으로 구현 가능 sequence decoder transformer 기반 디코더는 하나의 토큰을 생성하며, 이전 토큰과 인코딩된 image representation 에 의존한다 이는 여러 vision task 에 대한 현대 뉴럴 네트워크의 아키텍처에 대한 복잡성과 커스터마이징을 제거해준다. 단일 object detection task 에서 디코더가 output token 을 직접적으로 생성하는 것과 달리, 여기선 task prompt 를 조정하여 모델이 관심 task 에 적합한 output 을 생성하도록 한다. 훈련 중엔, prompt 와 원하는 output 을 하나의 시퀀스로 연결하지만, token weighting 체계를 활용하여 디코더가 원하는 output 뿐만 아니라 prompt token 도 예측하도록 훈련된다. 추론 중엔, prompt 가 주어지고 고정되므로, 디코더는 나머지 시퀀스만 생성하면 된다. 훈련 목표는 이미지와 이전 토큰에 조건화된 토근의 likelihood 를 최소화하는 것이다. maximize∑j=1Lwjlog⁡P(yj∣x,y1:j−1),(1)\\textup{maximize} \\sum^L_{j=1}w_j \\log P(y_j|x,y_{1:j-1}), \\tag{1}maximizej=1∑L​wj​logP(yj​∣x,y1:j−1​),(1) xxx 는 input image yyy 는 xxx 와 관련한 시퀀스 길이 LLL, 언급했듯이 시퀀스 yyy 의 초기 부분은 prompt 이다. wjw_jwj​ 를 0 으로 설정하여 loss 에 포함하지 않도록 한다.","s":"2.2 Unified architecture and objective function","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#22-unified-architecture-and-objective-function","p":121},{"i":134,"t":"각 task 는 image-sequence 쌍의 훈련 데이터를 가진다. 두 가지 방법으로 task 를 결합하고 합동으로 훈련을 수행할 수 있다.","s":"2.3 Training","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#23-training","p":121},{"i":136,"t":"서로 다른 task 에서 가져온 mixed image-sequence 쌍으로 dataset 을 만들 수 있으며, 서로 다른 dataset 크기와 task 어려움에 대한 균형을 맞출 수 있다. 이 구성은 개념적으로 매우 간단하지만, image augmentation 은 관련된 시퀀스를 쉽지 않은 방법으로 변경해야할 수 있어 통합하기 어려울 수 있다.","s":"Data mixing","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#data-mixing","p":121},{"i":138,"t":"각 배치에서, 단일 task 에 대한 annotation 을 가진 이미지를 샘플링하고, 이 task 에 적합한 image augmentation 을 수행하고, 증강된 데이터를 image-sequence 쌍으로 변환한다. 이 모델은 각 task 에 대한 loss 와 gradient 를 계산한 수 있고, 특정 task batch 의 gradient 를 적절한 weighting 을 결합할 수 있다. Algorithm 1 과 2 에서 요약 및 전략을 보여준다. 이 연구에선 image augmentation 을 단순하게 처리하기 위해 batch mixing 전략을 사용한다. data mixing 과 batch mixing 은 각 task 에 대한 부분 또는 weightinh 을 지정해야 한다. 이는 경험적인 문제이며, 저자는 한 번에 하나의 task 를 추가하여 greedy 전략을 사용한다. task 추가할 때마다마다, 저자는 기존 task 에 따른 상대적인 weighting 을 유지하면서 new task 의 weighting 을 조절한다. 모든 task 에 걸친 weight 의 합을 하나로 고정한다.","s":"Batch mixing","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#batch-mixing","p":121},{"i":140,"t":"추론할 땐, 시퀀스 시작 시 prompt 가 주어진 모델의 likelihood (예; P(yj∣x,y1:j−1)P(y_j|x,y_{1:j-1})P(yj​∣x,y1:j−1​) ) 로부터 토큰을 샘플링한다. nucleus sampling 을 사용하고 있지만 beam search 와 같은 다른 기술 또한 사용된다. 토큰이 생성되면, 각 task 에 대한 토큰을 디코딩할 수 있다. 서로 다른 task 가 토큰 시퀀스를 생성하기 위해 특정 tokenization scheme 를 필요로 하는 것과 동일하게, 디코딩 (de-tokenization) 프로세스 또한 각 task 에 고유하다. 각 task 의 추론 디코딩에 대한 자세한 설명은 다음과 같다. bounding boxes : 예측된 시퀀스를 5 개 토큰의 tuple 로 분할하여 좌표 토큰과 클래스 토큰을 얻고, 좌표 토큰을 dequantizing 하여 bounding box 를 얻는다. instance segmentation : 각 polygon 에 해당하는 좌표 토큰을 dequantize 한 다음, dense mask 로 변환한다. 모델은 정규화로 훈련되지 않아, output polygonal mask 는 다소 노이즈가 있을 수 있다. 노이즈를 줄이기 위해, multiple sequence 를 샘플링하고 mask 를 평균화한 다음, single binary mask 를 얻기 위해 간단하게 임계값으로 나눈다. keypoint detection : keypoint 의 이미지 좌표 토큰을 직접적으로 dequantizing 한다 captioning : 예측된 discrete token 을 바로 text 로 매핑한다","s":"2.4 Inference and de-tokenization","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#24-inference-and-de-tokenization","p":121},{"i":143,"t":"118k 훈련용 이미지와 5k 검증용 이미지를 포함하는 MS-COCO 2017 dataset 으로 평가를 하며 이 데이터셋으로 4가지 task 를 고려한다. 해당 데이터셋의 이미지는 object bounding box 를 위한 annotation, object instance 를 위한 segmentation mask, person instance 를 위한 keypoint, 그리고 few captions 을 포함한다. 이전 논문 Pix2Seq 을 따라, Vision Transformer (ViT-B) encoder 와 Transformer autoregressive decoder를 사용한다. 이 모델의 총 132M 파라미터를 가지고 있다. 초기화를 위해, Objects365dataset 에서 object detection 을 훈련한 pretrained checkpoint 를 사용했다. COCO 가 상대적으로 작아, task 에 덜 특화된 사전 지식을 가져서 유용 COCO 훈련의 경우 128 이미지 배치 사이즈 1e−41e^{-4}1e−4 의 lr 100 epochs 35k single vocabulary 및 32K text tokens 1K coordinate quantization bins 및 few other class label 최대 시퀀스 길이는 512 백본은 640x640 이미지 사이즈 pretrain 및 finetuning 은 640x640 또는 1024x1024 해상도","s":"3.1 Experimental settings and implementation details","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#31-experimental-settings-and-implementation-details","p":121},{"i":145,"t":"Pix2seq 에 따라 훈련 중 sequence augmentation 을 사용하고, 추론 시 class token 확률을 사용하여 점수를 매긴다. 또한 Pix2seq (가로 세로 비율이 변하지 않고 무작위로 영상 스케일링, 고정된 크기 영역을 무작위로 자른 다음 최대 크기로 패딩) 처럼 scale jittering 을 사용한다.","s":"Object detection","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#object-detection","p":121},{"i":147,"t":"polygon 의 최대 점수를 128 로 설정한다. 모델에게 추론 시 여러 샘플을 생성하도록 요청하고, 생성된 마스크를 평균내는 것이 이득이라는 것을 발견했다. 구체적으로, 각 샘플을 독립적으로 추출하여 이를 prompt 된 객체의 semantic mask 로 변환한다. 그 후, 50% 임계값을 설정하여 마스크를 평균내고, 50% 이상의 픽셀은 해당 인스턴스를 위해 선택된다. 저자는 8개의 샘플이 충분히 좋은 성능을 제공하며 (단일 샘플 사용 시보다 약 6 AP 높음), 12개 이상의 샘플에서는 성능 형상이 보이지 않는 다는 것을 발견했다. 또한 추론 과정에서 prompt 된 object instance 를 포함하는 이미지의 cropped region 에서도 평가를 한다. 이 경우엔, 입력 이미지를 cropped region 만 포함하는 새 이미지로 대체한다. 640x640 크기의 작은 이미지에서는 1.3 AP 로 개선이 이루어졌지만, 1024x1024 크기의 큰 이미지에서는 큰 효과가 없었다.","s":"Instance segmentation","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#instance-segmentation","p":121},{"i":149,"t":"저자는 person instance 을 포함하는 이미지의 copped region 에서 훈련 및 평가한다. 학습 중엔, 이 region 들이 ground-truth annotation 에 의해 제공되며 추론 중엔, 이 region 들은 object detection model 에 의해 제공된다. 이 region 에 제공된 bounding box 의 두 배 크기로 선택한다. 이런 최적의 crop 을 사용하여, 매우 큰 crop (bounding box 크기의 약 20배, 전체 이미지 사용에 근접한 것으로 간주)을 사용하는 것보다 약 9 AP 향상을 얻었다. 또한, quantized sequence 에서 보이지 않는 토큰 좌표를 나타내는 특수 토큰을 사용한다. 학습 시, 이런 토큰에 대한 작은 loss weight 0.1 을 사용한다. 더 큰 가중치를 사용하더라도 AP 에 큰 영향을 미치지 않지만(가중치 1.0 에서 1 낮아짐), 가중치 0.0 을 사용하면 훨씬 나쁜 결과가 나온다 (12 AP 낮음). 추론 시에는 보이지 않는 토큰을 모델이 keypoint 좌표의 최선의 추측값으로 대체한다.","s":"Keypoint detection","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#keypoint-detection","p":121},{"i":151,"t":"object detection, instance segmentation, image captioning 및 keypoint detection 각각 0.1782, 0.7128, 0.099, 0.01 의 mixed weighting 을 사용한다. 이러한 weight 의 셋은 한 번에 하나의 task 를 추가하여 greedy 탐색을 한다.","s":"Four-tasks joint training","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#four-tasks-joint-training","p":121},{"i":153,"t":"object detection 의 경우 strong 2-stage detector 인 Faster R-CNN 및 보다 최신인 Transformer-based detector 인 DETR 와 비교한다. Faster R-CNN 및 DRET 는 모두 Faster R-CNN 의 non-maximum suppression 및 DRET 의 일반화된 IoU 과의 biparite graph matching 같은 설계에서 task 별 사전 설정을 사용한다. 커스터마이징된 아키텍처 및 loss function 때문에, 넓은 범위의 task 로 확장하는 것은 간단하지 않으며 새로운 모델을 설계할 필요가 있다. Mask RCNN 은 Faster R-CNN 을 확장하여 segmentation 및 keypoint 를 통합하는 설계를 지지한다. Mask RCNN 은 네 가지 작업 중 세 가지를 수행할 수 있지만, 여전히 Faster R-CNN 과 동일한 task 기반 세팅이 필요하다. 또한 Transformer 와 유사한 attention 메커니즘을 통합하는 non-local 아키텍처가 있는 Mask R-CNN 의 개선된 버전도 고려한다. 위 방법들은 image captioning 을 할 수 없으므로, task 에 특화된 Transformer 기반의 caption model 을 훈련한다. 이 모델은 caption single task 을 위해 제안된 방법으로 훈련된 것과 유사하지만, 높은 dropout rate 이 있는 사전 훈련된 visual encoder 를 사용하고 있다.","s":"Baselines","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#baselines","p":121},{"i":155,"t":"위 테이블 1 에 결과가 요약 돼있으며, 다음 베이스라인과 두 가지의 모델을 소개 한다. single task 에 대해 훈련된 single task model (여전히 동일한 아키텍처 및 objective function). 따라서 각 task 는 자체의 network weight 를 가진다. sinle network weight 의 셋이 4 가지 task 에 대해 사용된 multi-task model 특정 task 에 대한 아키텍처나 loss function 의 사전 지식 없음에도, 저자의 모델은 여전히 각 개별적인 task 에 대한 결과가 경쟁력 있다고 한다 (심지어 이미지 사이즈가 작을 때도). 모든 task 에 대해 single model 로 훈련했을 때, 모델 사이즈를 동일하게 유지 했음에도 각각의 task 를 해결할 수 있었다. 또한, 이미지 사이즈를 크게 하면 성능 향상도 관찰했다. 한 예외로는 keypoint detection 인데, 감지한 key point 에 대한 cropped interest region 을 이미 사용하여, 이미지 사이즈를 키우는 것이 반드시 유용한 것은 아니며 labeld data 에 제한된 경우 과적합으로 이어질 수 있다. greedy 을 각 task 에 사용하여 적합한 loss weighting 을 선택한 것을 Figure 에서 볼 수 있다. Figure 4a 에서 object detection 과 instance segmentation 간의 weight 비율을 탐색한다. 광범위한 weight 비율의 경우 두 작업의 성능이 모두 피크에 가까워서 두 작업에 대해 2:8 weight 비율을 선택한다. 이후, image captioning task 를 추가하고, captioning task 의 서로 다른 weighting 에서의 성능을 Figure 4b 에서 확인할 수 있으며, 여기서 기존 task 와 image captioning task 에 대한 9:1 weighting 비율이 적절하다는 것을 알 수 있다. 마지막으로, keypoint detection task 를 추가하면, Figure 4c 에서, 이 weight 가 상대적으로 작게 설정될 수 있으며 0.01 을 사용하기로 선택한다.","s":"3.2 Quantitative results","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#32-quantitative-results","p":121},{"i":157,"t":"보다 시각적이고 직관적인 방식으로 모델의 기능과 성능을 입증하기 위해, object detection, instance segmentation, keypoint detection 및 image captioning 과 같은 네 가지 각 task 에 대해 COCO 검증셋으로부터 선택된 이미지에 대한 multi-task 모델의 출력을 보여준다. Figure 5 에서 object detection task 결과를 보여 준다. 이 모델은 어수선한 장면에서도 크기가 다른 물체들을 성공적으로 감지한다. instance segmentation 과 keypoint detection 에 대한 경험적 결과는 Figure 6, 7 에서 보여준다. 두 task 에서 multi-task 모델은 localized 및 정확한 예측을 생성한다. 또한 Table 2 에서 생성된 몇 가지 caption 을 보여준다. 이러한 결과로, 저자는 모델이 대규모 이미지 텍스트 데이터셋을 사용하여 사전 훈련되지 않았다는 것에 주목하며, 이는 모델의 captioning 성능이 크게 향상될 것으로 예상된다.","s":"3.3 Qualitative results","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#33-qualitative-results","p":121},{"i":159,"t":"본 연구에서, task description (prompt) 과 task output 모두 토큰의 discrete sequence 로 표현되는 다양한 \"핵심\" vision task 의 다양한 셋을 해결하기 위한 통합 시퀀스 인터페이스를 탐구한다. 이는 아키텍처 및 loss function 이 task 간에 공유된다는 점에서 multi-task vision model 의 기존 규범에서 크게 벗어난다는 것으로, 이러한 모델이 잘 확립된 task-specific model 에 비해 경쟁력 있는 성능을 달성 할 수 있음을 보여준다. 이 연구에는 제한이 없으며, 기존 접근법에서 크게 벗어났기 때문에 이 아키텍처와 다른 훈련법 모두가 특화된 시스템의 SOTA 에 더 개선됬다고 믿는다. 또한 더 큰 데이터셋(예; image-text pairs) 에 대한 pretraining 또는 더 큰 모델 사이즈를 사용하는 것 모두에서 확장의 이점을 크게 얻을 수 있다고 믿는다. 다른 한계는 접근법이 autoregressive 모델링에 기반하여 특화된 시스템에 비해 추론 속도가 잠재적으로 느릴 수 있다. 효율성을 향상시키는 몇 가지 방법이 있는데, 여기에 non-autoregressive sequence 모델링 사용이 포함된다. 본 연구에서, 모델 추론 속도를 높이기 위해 병렬 쿼리를 활용한다. 예로, 여러 사람의 포즈를 예측하는 것은 독립적인 (모델 자체로 감지되거나 미리 주어진) bounding box 로 모델에 prompt 를 표시하여 독립적으로 수행할 수 있어, 유일한 순차적 예측은 몇 개의 keypoint 를 가진 single person 으로 제한된다. instance segmentation 에도 동일한 전략을 적용할 수 있다. 통합 인터페이스의 최적 구현에는 여전히 더 많은 연구가 필요하고 이 task 에서 탐색된 시퀀스 인터페이스는 잠재적인 구현 중 하나에 불과하지만, 저자는 다양한 task 들이 표현되는 방식의 인터페이스가 향후 범용 인공지능 시스템에서 점점 중요한 역할을 할 것이라 믿고 있다.","s":"5. Conclusion","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":161,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.06674v1.pdf","s":"UNINEXT: Universal Instance Perception as Object Discovery and Retrieval","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":163,"t":"본 논문에서 universal instance perception model 에 대한 next generation 인 UNINEXT 를 제안한다. 기존의 모든 instance perception task 는 category names, language expressionbs, target annotations 와 같은 query 들로 객체를 찾는 것이 목표지만 이들은 모두 독립적인 하위 task 로 분할되어 있는데, 이를 범용적으로 인식할 수 있는 새로운 기술을 제안하는 바이다. 다양한 instance perception task 를 통합된 객체 탐지 및 retrieval paradigm 으로 재구성하고, input prompt 를 단순화하여 객체를 유연하게 인식한다. 이렇게 통합하여 다음 이점을 얻을 수 있다. 서로 다른 tasks 및 label vocabularies 에서 대량의 데이터를 공동으로 훈련하여 일반적인 instance-level 의 표현을 교육하는 데 매우 유용. 특히 훈련 데이터가 부족한 작업에 이점을 제공 통합 모델은 매개 변수 효율적이며, 여러 작업을 동시에 처리할 때 중복 계산을 줄일 수 있음 UNITEXT 는 고전적인 image-level task (object detection, instance segmentation), vision-language task (referring expression comprehension, segmentation) 및 6 개의 video-level object tracking task 를 포함하는 10 개의 instance-level task 로부터 총 20 개의 어려운 벤치마크에 대해 우수한 성능을 보여준다.","s":"Abstract","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":165,"t":"본 논문에서는 위의 정육면체 꼭짓점에 나타낸 10개의 sub-tasks 에 대해 논의한다. 가장 기본적인 task 인 object detection, instance segmentation 은 box 와 mask 로 특정 categories 의 모든 객체를 찾아야 한다. 정적 이미지를 동적 비디오로 입력을 확장할 경우, Multiple Object Tracking (MOT), Multi-Object Tracking and Segmentation (MOTS), Video Instance Segmentation (VIS) 는 비디오에서 특정 category 의 모든 객체 궤적을 찾아야 한다. 위와 같은 category names task 외의 몇몇 task 는 다른 참조 정보를 제공한다. Referring Expression Comprehension (REC), Referring Expression Segmentation (RES), Referring Video Object Segmentation (R-VOS) 는 \"왼쪽에서 네 번째 사람\" 과 같은 language expressions 과 일치하는 객체를 찾아야 한다. Single Object Tracking (SOT), Video Object Segmentation (VOS) 는 첫 번째 프레임에서 제공된 target annotations (box or mask) 을 참조하여 후속 프레임에서 객체의 궤적을 예측해야 한다. 위에서 언급한 모든 tasks 는 특정 속성의 instance 를 인지하려는 것이기 때문에, 이를 instance perception 이라 칭한다. 최근, 대부분의 instance perception 으로 sub-tasks 의 일부분 또는 하나에 대해서만 개발되며, 특정 domain 으로 분리하여 훈련되는데, 이는 다음과 같은 단점을 지닌다. 각 독립적인 설계는 서로 다른 task 및 domain 간의 knowledge 학습을 공유하는 것을 방해하며 중복 매개변수를 초래 서로 다른 task 간의 상호 기여의 가능성이 간과된다. 고정 크기의 classifier 로 제한된 전통적인 object detector 는 다양한 label vocabularies 가 있는 여러 데이터셋을 공동으로 훈련하는 것과 추론 중에 감지할 object categories 를 동적으로 변경하는 것은 어려움 따라서, 본질적으로는 모든 instance perception tasks 는 모든 queries 에 따라 특정 물체를 찾는 것을 목표로 한다. 이에 모든 주요 instance perception tasks 를 한 번에 해결할 수 있는 통합 모델을 설계할 수 있을까? 이 질문에 대한 대답으로 UNINEXT 를 제안 먼저 10 가지의 instance perception 인식 tasks 를 input prompt 에 따라 3 가지 유형으로 재구성 category names 의 prompt (Object Detection, Instance Segmentation, VIS, MOT, MOTS) language expressions 의 prompt (REC, RES, R-VOS) reference annotations 의 prompt (SOT, VOS) 그런 다음, 위 tasks 를 해결하기 위해 통합된 prompt-guieded 객체 발견과 retrieval formulation 를 제안 먼저, prompt 의 가이드 하에 N 개의 object proposals 를 발견 이후, instance-prompt 매칭 점수에 따른 proposals 로부터 최종 instance 를 찾음 위 새로운 formulation 을 기반으로, prompt 를 간단하게 바꿔서 다양한 instance 를 유연하게 찾을 수 있게 된다. 또한 다양한 prompt modalities 를 다루기 위해 다음을 제안 reference text encoder 와 reference visual encoder 로 구성된 prompt generation module 을 채택 early fusion module 을 현재 이미지의 원시 비주얼 특성과 prompt embedding 을 향상 시키기 위해 사용 위 작업으로 깊은 정보 교환이 가능하고 후속 instance 예측 단계에 대해 높은 구별력을 제공한다. 유연한 query-to-instance 방식을 고려하기 위해 다음을 제안 Transformer 기반의 object detector 를 instance decoder 로 선택 특히, 이 decoder 는 먼저 N 개의 instance proposals 를 생성 그후, prompt 를 사용하여 위의 instance proposals 로부터 매칭되는 object 를 찾는다. 이 검색 메커니즘은 전통적으로 사용하는, 고정된 크기의 classifier 를 극복하고 서로 다른 task 와 domain 의 데이터를 공동으로 훈련할 수 있다. 이러한 통합된 모델 아키텍처인 UNINEXT 는 다양한 task 의 대규모 데이터를 강력한 generic representations 를 학습하고 동일한 모델 파라미터로 10 가지의 instance-level perception tasks 를 해결할 수 있다. 실험 결과 20 가지의 벤치마크에서 우수한 결과에 달성했으며 이라한 기여를 다음과 같이 요약한다. universal instance perception 에 대해 통합된 prompt-guided formulation 을 제안하며, 분산된 instance-level 의 sub-tasks 를 하나로 통합 유연한 객체 발견과 검색 파라다임의 이점을 살린 UNINEXT 는 특정 task 헤드가 필요하지 않으므로 서로 다른 tasks 와 domains 를 훈련할 수 있다. 동일한 model parameter 로 10 가지의 instance perception tasks 의 20 가지 벤치마크에 대해 우수한 결과 달성","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":168,"t":"introduction 에서 언급한 것과 같이, instance perception tasks 를 3 가지의 class 로 분류한다. Object detection, instance segmentation, MOT, MOTS 및 VIS 는 category names 를 prompt 로 사용하여 특정 class 의 모든 instance 를 찾는다. REC, RES 및 R-VOS 는 expression 을 prompt 로 이용하여 특정 타깃을 localizing 한다. SOT 와 VOS 는 첫 프레임에 주어진 annotation 을 prompt 로 사용하여 추적하는 타깃의 궤적을 예측한다. 위 tasks 는 prompt 로 특정 객체를 찾는 것을 목표로 한다. 그리고 이 방법은 모든 instance perception tasks 를 prompt-guided 객체 발견과 retrieval problem 으로 재구성하는 동기를 주며 통합 모델 아키텍처와 학습 파라다임으로 해결한다. 다음 그림으로 입증할 수 있다. UNINEXT 는 다음 세 가지의 주요 컴포넌트를 포함한다. prompt generation image-prompt feature fusion object discovery and retrieval","s":"3. Approch","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":170,"t":"먼저, prompt generation modile 은 원본의 다양한 prompt 입력을 통합된 형태로 변환하기 위해 채택됐다. 다음 두 단락에서 각각의 modalities 에 대한 대응 전략을 소개한다. 언어관련 prompt 를 처리하기 위해 language encoder 인 EncL\\textup{Enc}_LEncL​ 를 채택한다. 구체적으로 category-guided tasks 에 대해, 현재 데이터셋에서 나타난 class names 를 언어 표현으로 연결한다. COCO 를 예로, 표현식을 \"person. bicyle, .. , toothbrush\" 와 같이 작성될 수 있다. 이후 category-guided 및 expression-guided tasks 등의 언어 표현식은 EncL\\textup{Enc}_LEncL​ 에 전달되어, 시퀀스 일이 LLL 인 prompt embedding Fp∈RL×dF_p \\in \\mathbb{R}^{L \\times d}Fp​∈RL×d 가 생성된다. annotation-guided tasks 에 대해선, fine-grained visual 특징을 추출하고 target annotations 를 완전히 활용하기 위해, 추가적인 reference visual encoder 인 EncVref\\textup{Enc}_{\\textup{V}}^{\\textup{ref}}EncVref​ 를 도입한다. 구체적으로, 참조하는 프레임에서의 타깃 위치 중심으로 맞춰진 222^222 배의 타깃 박스 영역 템플릿을 자른다. 이후, 이 템플릿을 256×256256 \\times 256256×256 의 고정된 사이즈로 조정한다. 더 정확한 정보를 도입하기 위해, target prior 이라는 추가된 channel 은 템플릿 이미지에 연결되어 4-channel 입력을 형성한다. 자세히 말해, target prior 의 값 target region 에서는 1 이고, 그 외에는 0 이다. 이후, target prior 과 함께한 이 템플릿 이미지는 reference visual encoder EncVref\\textup{Enc}_{\\textup{V}}^{\\textup{ref}}EncVref​ 에 전달되어, {C3,C4,C5,C6}\\{ C_3, C_4, C_5, C_6 \\}{C3​,C4​,C5​,C6​} hierarchical feature pyramid 를 얻는다. 각 구역의 사이즈는 32×3232 \\times 3232×32, 16×1616 \\times 1616×16, 8×88 \\times 88×8, 4×44 \\times 44×4 이다. 타깃 정보를 유지하고 다른 작업과 동일한 형식의 prompt embedding 을 얻기 위해 병합된 모듈이 적용된다. 다시말해, 피처의 모든 level 는 먼저 32×3232 \\times 3232×32 으로 다운샘플링을 한 후에 추가되며, 최종적으로는 Fp∈R1024×dF_p \\in \\mathbb{R}^{1024 \\times d}Fp​∈R1024×d 의 prompt embedding 으로 flatten 된다. Fine-Grained & Coarse-Grained Fine-Grained 하나의 작업을 작은 단위의 프로세스로 나눈 뒤, 다수의 호출을 통해, 작업 결과를 생성해내는 방식 예를 들어, Do() 라는 함수가 있다면 해당 함수를 First_Do(), Second_Do() 로 나누어 작업 결과를 생성해내는 방식 따라서, 다양한 \"Flexible System\" 상에서 유용하게 쓰일 수 있음 Coarse-Grained 하나의 작업을 큰 단위의 프로세스로 나눈 뒤, \"Single Call\" 을 통해, 작업 결과를 생성해내는 방식 예를 들어, Do() 라는 함수가 있다면 단순히, Do() 를 호출해 작업 결과를 생성해내는 방식 따라서, \"Distributed System\" 상에서 유용하게 쓰일 수 있음 위의 prompt 생성 과정은 다음과 같은 공식으로 나타낼 수 있다. Fp={EncLrefexpression-guiededEncLrefcategory-guiededmerge(EncVref[template, prior])annotation-guiededF_p = \\left \\{ \\begin{array}{ll} \\textup{Enc}_L^{\\textup{ref}} & \\textup{expression-guieded} \\\\ \\textup{Enc}_L^{\\textup{ref}} & \\textup{category-guieded} \\\\ \\textup{merge}( \\textup{Enc}_\\textup{V}^{\\textup{ref}}[ \\textup{template, prior} ]) & \\textup{annotation-guieded} \\end{array} \\right.Fp​=⎩⎨⎧​EncLref​EncLref​merge(EncVref​[template, prior])​expression-guiededcategory-guiededannotation-guieded​","s":"3.1 Prompt Generation","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#31-prompt-generation","p":160},{"i":172,"t":"prompt 생성과 병렬로, 현재의 이미지 전체는 다른 visual encoder EncV\\textup{Enc}_{\\textup{V}}EncV​ 로 전달되어, hierarchical visual features FvF_vFv​ 를 얻는다. image contexts 로 원본 prompt embedding 을 강화시키고 원본 visual features 를 prompt-aware 하게 만들기 위해서, early fusion module 를 채택한다. 구체적으로, 다양한 입력의 정보를 찾기위해 bi-directional cross-attention module (Bi-XAtt) 를 사용한다. 이후, retrieved representations 를 원본 features 에 추가한다. 위의 prompt 생성 과정은 다음과 같은 공식으로 나타낼 수 있다. Fp2v,Fv2p=Bi-XAtt(Fv,Fp)Fv′=Fv+Fp2v; Fp′=Fp+Fv2p(1)\\left. \\begin{array}{ll} F_{p2v}, F_{v2p} = \\textup{Bi-XAtt}(F_v, F_p) \\\\ F'_v = F_v + F_{p2v}; \\ F'_p = F_p + F_{v2p} \\\\ \\end{array} \\right. (1)Fp2v​,Fv2p​=Bi-XAtt(Fv​,Fp​)Fv′​=Fv​+Fp2v​; Fp′​=Fp​+Fv2p​​(1) feature 향상을 위해 6 개의 vision-language fusion layer 와 6 개의 추가 BERT layer 를 채택하는 GLIP 과 달리, early fusion module 은 훨씬 더 효율적이다.","s":"3.2 Image-Prompt Feature Fusion","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#32-image-prompt-feature-fusion","p":160},{"i":174,"t":"판별적인 visual 과 prompt representations 과 함께, 다음 중요한 단계는 다양한 인식 tasks 에 대해 input features 를 instance 로 변환하는 것이다. UNINEXT 는 Deformable DETR 에서 제안된 encoder-decoder 아키텍처를 채택하여 유연한 query-instance 형식을 사용한다. Transformer encoder 는 hierarchical prompt-aware viusal feature 를 input 으로 사용한다. 효율적인 Multi-scale Deformable Self-Attention 의 도움으로, 서로 다른 스케일의 타깃 정보를 교환할 수 있으며, 후속 instance decoding 에 대한 강력한 instance feature 를 제공해준다. 또한, Deformable DETR 의 두 단계에서 수행처럼, auxiliary prediction head 는 encoder 의 끝에 추가되어, 가장 높은 점수를 가진 NNN 개의 초기화된 reference points 를 생성하여 decoder 의 input 으로 사용한다. Transformer decoder 는 향상된 multi-scale features 인, encoder 의 N 개의 reference points 와 N 개의 object queries 를 input 으로 사용한다. 이전 연구처럼, object queries 는 instance perception tasks 에서 중요한 역할을 한다. 본 연구는 두 가지의 query 생성 전략을 시도한다. 이미지 또는 프롬프트에 상관없이 변하지 않는 static queries nn.Embedding(N, d) 로 쉽게 구현 가능 프롬프트에 의존적인 dynamic queries 먼저 향상된 prompt features Fv′F'_vFv′​ 를 pooling 하여 global representation 을 얻은 다음, NNN 번 반복하여 수행할 수 있음 위 두 방법으로 정적 쿼리가 동적 쿼리보다더 나은 성능을 발휘 한다는 것을 발견했다. 이유는 정적 쿼리가 동적 쿼리보다 더 많은 정보를 포함하고 더 나은 훈련 안정성을 진행하기 때문이다. deformable attention 의 도움으로, object queries 는 효율적으로 prompt visual features 를 찾으며, 강력한 instance embedding Fins∈RN×dF_{ins} \\in \\mathbb{R}^{N \\times d}Fins​∈RN×d 를 학습할 수 있다. decoder 의 끝 부분에서는 최종적인 instance predictions 을 얻기 위해 prediction heads 그룹을 활용한다. 구체적으로, instance head 는 타깃의 boxes 와 masks 를 생성한다. 또한, embedding head 는 현재 감지된 결과와 MOT, MOTS 및 VIS 의 이전 궤적과 연관시키기 위해 도입된다. 지금까지, 위 그림에서 회색 마스크로 나타낸 NNN 개의 잠재적인 instance proposals 를 채굴했지만, 모든 proposals 는 prompt 가 실제로 참조하는 타깃을 나타내는 것은 아니었다. 따라서, 그림의 오른쪽처럼 prompt embedding 에 따라 이러한 proposals 로부터 실제로 일치되는 타깃을 더 검색해야 한다. 구체적으로, early fusion 후의 prompt embedding Fp′F'_pFp′​ 가 주어지면, category-guided tasks 를 위해 각 category name 의 embedding 을 weight matrix W∈R1×dW \\in \\mathbb{R}^{1 \\times d}W∈R1×d 로 사용한다. 또한, expression-guided 와 annotation-guided tasks 를 위해 weight matrix WWW 는 sequence 차원을 따라 global average pooling (GAP) 를 사용하여 prompt embedding Fp′F'_pFp′​ 를 집계하여 얻는다. W={Fp′[i], i∈{0,1,...,C−1}category1L∑i=0LFp′(i,j)expression/annotationW = \\left \\{ \\begin{array}{ll} F'_p[i], \\ i \\in \\{0, 1, ..., C - 1\\} & \\textup{category} \\\\ \\\\ \\frac{1}{L} \\sum_{i=0}^{L} F'_p (i, j) & \\textup{expression/annotation} \\end{array} \\right.W=⎩⎨⎧​Fp′​[i], i∈{0,1,...,C−1}L1​∑i=0L​Fp′​(i,j)​categoryexpression/annotation​ 마지막으로, instance-prompt 매칭 점수 SSS 는 타깃 features 과 전치된 가중치 행렬의 행렬 곱으로 계산할 수 있으며 식으로 S=FinsWTS = F_{ \\textup{ins}}W^TS=Fins​WT 로 나타낸다. 이전 연구에 따르면, 매칭 스코어는 Focal Loss 로 supervise 될 수 있다. 이전의 고정된 크기의 classifiers 와 달리, proposed retrieval head 는 prompt-instance 매칭 메커니즘으로 객체를 선택한다. 이 유연한 설계는 서로 다른 tasks 의 다양한 label vocabularies 을 가진 거대한 데이터셋을 공동으로 학습하여, UNEXT 를 가능케 한다.","s":"3.3 Object Discovery and Retrieval","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#33-object-discovery-and-retrieval","p":160},{"i":177,"t":"전체 훈련 프로세스는 세 단계를 포함한다. general perception pretraining UNINEXT 를 객체에 대한 범용적인 지식을 학습시키기 위해 object detection 데이터셋인 Object365 로 pretrain Object365 는 mask annotations 가 없기 때문에, mask brach 를 훈련하기 위해, BoxInst 에서 제안한 auxiliary losses 를 도입한다. 이 loss function 은 다음과 같다. Lstage1=Lretrieve+Lbox+Lmaskboxinst(2)L_{\\textup{stage1}} = L_{\\textup{retrieve}} + L_{\\textup{box}} + L_{\\textup{mask}}^{\\textup{boxinst}} \\qquad (2)Lstage1​=Lretrieve​+Lbox​+Lmaskboxinst​(2) image-level joint training 1 단계의 pretrained weight 를 토대로, image datasets 를 공동적으로 UNINEXT 에 finetuning 한다. 주로 COCO 와 RefCOCO, RefCOCO+ 및 RefCOCOg 를 섞은 데이터셋이다. 수동으로 라벨링된 mask annotations 을 사용하면, Dice Loss 및 Focus Loss 와 같은 전통적인 loss function 을 mask 학습에 사용될 수 있다. 이 스텝을 지나면, UNINEXT 는 object detection, instance segmentation, REC 및 RES 에 우수한 성능을 낼 수 있다. Lstage2=Lretrieve+Lbox+Lmask(3)L_{\\textup{stage2}} = L_{\\textup{retrieve}} + L_{\\textup{box}} + L_{\\textup{mask}} \\qquad (3)Lstage2​=Lretrieve​+Lbox​+Lmask​(3) video-level joint training 다양한 downstream object tracking tasks 와 벤치마크를 위해 video-level 데이터셋에 UNINEXT 를 finetuning 한다. 원본 비디오에서 무작위로 선택된 두 프레임을 학습한다. image-level tasks 에서 학습된 지식을 잊는 것을 방지하기 위해, image-level 데이터셋을 가짜 비디오로 변환하여 공동으로 학습 가짜 영상은 COCO, RefCOCO/g/+, SOT&VOS (GOT-10K, LaSOT, TrackingNet 및 Youtube-VOS), MOS&VIS (BDD10K, VIS19, OVIS) 및 R-VOS (Ref-Youtuve-VOS) 를 포함한다 SOT&VOS 에 대한 reference visual encoder 와 연관성에 대한 추가적인 embedding head 도 도입되어 최적화한다. Lstage3=Lretrieve+Lbox+Lmask+Lembed(4)L_{\\textup{stage3}} = L_{\\textup{retrieve}} + L_{\\textup{box}} + L_{\\textup{mask}} + L_{\\textup{embed}} \\qquad (4)Lstage3​=Lretrieve​+Lbox​+Lmask​+Lembed​(4)","s":"Training","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#training","p":160},{"i":179,"t":"category-guided tasks 에 대해, UNINEXT 는 서로다른 categories 의 instance 를 예측하고 이전 궤적과 연관시킨다. 이 연관성 짓는 과정은 온라인 방식으로 이루어지며, 이전 연구처럼 학습된 instance embedding 만을 기반으로 한다. expression-guided 와 annotation-guided 에 대해, 주어진 prompt 와 가장 높은 매칭 점수를 가진 객체를 최종 결과물로 선택한다. 오프라인 방식과 복잡한 후처리 과정에 의해 제한되는 이전 연구와 달리, 이 방법은 간단하고, 온라인 방식이며, 후처리가 필요하지 않다.","s":"Inference","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#inference","p":160},{"i":182,"t":"본 저자는 세 가지의 백본 모델 ResNet-50, ConvNeXt-Large 및 ViT-Huge 를 visual encoder 로 시도한다. 또한 BERT 를 text encoder 로 채택하고 파라미터는 1, 2 번째 훈련 단계에서 훈련되며, 마지막 훈련 단계에서 동결 시킨다. Transformer encoder-decoder 아키텍처는 DETR 연구에 따라 6 encoder layer 와 6 decoder layer 를 사용한다. object queries 수 NNN 은 900 optimizer, AdamW, 0.05 weight decay Object365 pretraining 에 대해 32, 16 A 100 GPUs 사용","s":"4.1 Implementation Details","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#41-implementation-details","p":160},{"i":185,"t":"UNINEXT 를 COCO val2017 (5k images) 및 test-dev split (20k images) 에서 SOTA object detection 과 instance segmentation AP 점수 비교","s":"Object Detection and Instance Segmentation","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#object-detection-and-instance-segmentation","p":160},{"i":187,"t":"REC 및 RES 를 RefCOCO, RefCOCO+ 및 RefCOCOg 로 평가한다. REC 및 RES 평가지표는 Precision@0.5 와 Overall IoU (oIoU) 를 채택했다.","s":"REC and RES","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#rec-and-res","p":160},{"i":189,"t":"네 개의 large-scale 벤치마크: LaSOT, LaSOT-ext, TrackingNet 및 TNL-2K 로 SOTA 와 SOT 를 비교했다. 이 벤치마크들은 success curve (AUC), normalized precision (PNormP_{Norm}PNorm​) 및 precision (P) 로 평가했으며, 각각 280, 150, 511 및 700 개의 테스트 셋 비디오를 포함한다.","s":"SOT","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#sot","p":160},{"i":191,"t":"VOS 는 DAVIS-2017 및 Youtube-VOS 2018 데이터셋으로 평가한다. DAVIS-2017 은 region similarity J\\mathcal{J}J, contour accuracy F\\mathcal{F}F, averaged score J&F\\mathcal{J} \\& \\mathcal{F}J&F 로 나타낸다. Youtube-VOS 2018 은 J\\mathcal{J}J 와 F\\mathcal{F}F 를 seen 및 unseen categories 로, averaged overall score 는 G\\mathcal{G}G 로 나타낸다.","s":"VOS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#vos","p":160},{"i":193,"t":"MOT 에서 자율운전 중 8 개의 class instance 를 추척을 요구하는 BBD100K 에서 SOTA 와 UNINEXT 를 비교한다. 전통적인 평가지표 Multiple-Object Tracking Accuracy (MOTA), Identity F1 Score (IDF1) 및 Identity Switches (IDS) 를 제외하고도, 추가로 도입된 mMOTA 및 mIDF1 로도 성능 평가를 했다.","s":"MOT","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#mot","p":160},{"i":195,"t":"MOT 와 비슷하게, BDD100K MOTS 첼린지에서 mMOTSA, mMOTSP, mIDF1 및 ID Sw 로 multi-class 추적을 평가한다.","s":"MOTS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#mots","p":160},{"i":197,"t":"Youtube-VIS 와 OVIS 검증셋에서 SOTA 와 UNINEXT 를 비교한다. 특히 위 검증셋은 각각 40 및 25 object categories 와 302 및 140 개 비디오 검증셋을 포함한다. 각 벤치마크에 대해 AP 로 평가한다.","s":"VIS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#vis","p":160},{"i":199,"t":"Ref-Youtube-VOS 와 Ref-DAVIS17 은 R-VOS 분야에서 인기 있는 데이터셋으로, object 에 대해 언어표현을 도입한다. VOS 와 비슷하게 region similarity J\\mathcal{J}J, contour accuracy F\\mathcal{F}F, averaged score J&F\\mathcal{J} \\& \\mathcal{F}J&F 를 평가지표로 채택한다.","s":"R-VOS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#r-vos","p":160},{"i":201,"t":"모든 모델에 ResNet-50 백본을 사용하여 다섯 가지 벤치마크 (COCO, RefCOCO, Youtube-VOS, Ref-Youtube-VOS 및 Youtube-VIS 2019) 에 대해 평가를 진행한다.","s":"4.3 Ablations and Other Analysis","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#43-ablations-and-other-analysis","p":160},{"i":203,"t":"visual features 와 prompt embedding 사이의 fusion 에 대한 영향력을 연구하기 위해, early fusion 없이 구현을 해보았다. 실험 결과 Early fusion 없으면 성능 저하가 일어났는데 다음 주요 세 가지 이유가 있다. prompt embedding 의 지도가 없는 네트워크는 나무나 싱크대 같은 희귀한 타깃을 찾기가 힘들다. early fusion 없는 네트워크는 첫 번째 프레임에서 fine mask annotation 을 완전히 활용할 수 없어 mask 품질이 저하된다. 또한 feature fusion 을 제거하니 성능 저하가 일어났다. feature fusion 은 object detection 및 VIS 에 최소한의 영향을 미치는데, prompt 에서 참조하는 특정 타깃 하나를 찾는 것이 아니라 가능한 모든 object 를 찾는 것을 목표로 하기 때문으로 이해할 수 있다.","s":"Fusion","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#fusion","p":160},{"i":205,"t":"본 저자는 두 가지의 query generation 전략을 비교한다. static queries nn.Embedding(N, d) 로 간단히 구현 가능 VIS task 에서 2.8 AP 로 dynamic queries 전략보다 더 좋은 성능을 냄 잠재적인 이유는 N 개의 다른 object queries 가 단순히 N 번의 query 로 pool 된 prompt 를 복사하는 것보다 서로 다른 타깃간의 풍부한 관계로 인코딩할 수 있기 때문 dynamic queries prompt embedding 에 의존 처음의 4 가지 tasks 에 대해선 static queries 보다 성능이 약간 좋았다.","s":"Queries","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#queries","p":160},{"i":207,"t":"모든 tasks (10 tasks) 를 통합한 모델과 5 가지 tasks 를 통합한 mutliple tasks 모델을 비교하였다. 통합 모델은 5 tasks-specific 모델보다 성능이 약간 더 좋았다. 최종적으로는 통합 모델이 많은 파라미터를 아끼고, 파라미터에 더 효율적이었다.","s":"Unification","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#unification","p":160},{"i":209,"t":"UNINEXT 는 prompt-guided 객체 발견과 검색 파라다임으로 10 가지 instance perception tasks 를 통합했다. UNINEXT 는 동일한 모델 파라미터로 단일 모델 만으로 20 가지의 벤치마크에서 우수한 성능에 도달했다.","s":"5. Conclusions","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":160},{"i":211,"t":"논문 및 이미지 출처 : https://aclanthology.org/2023.eacl-main.41.pdf","s":"PromptDA : Label-guided Data Augmentation for Prompt-based Few Shot Learners","u":"/docs/Paper/NLP/Augmentation/PromptDA","h":"","p":210},{"i":213,"t":"본 논문은 low-resource Natural Language Understanding (NLU) task 에 초점을 둠, Prompt-based Data Augmentation model (promptDA) 를 제안 frozen Pre-trained Language Model (PLMs) 에 small-sacle Soft Prompt (예; trainable vector) 만 훈련 사람이 unlabeled in-domain data 을 수집하는 수고를 덜고 생성된 인공 데이터의 질을 유지 PromptDA 는 두 가지 측면으로 인공 데이터 생성하며 NLU 모델로 low-quality data 필터링 네 가지 벤치마크에서 실험하여, unlabeled in-domain data 를 사용하는 SOTA semi-supervised model 를 포함한 baselinbe 보다 PromptDA 로 생성된 인공 데이터가 성능 능가 PromptDA 의 인공 데이터는 unlabeled in-domain data 와도 상호보완적이다. 결과적으로 NLU 모델은 인공 데이터와 결합하여 더욱 향상되었다.","s":"Abstract","u":"/docs/Paper/NLP/Augmentation/PromptDA","h":"","p":210},{"i":215,"t":"Deep neural networks 는 SOTA 성능 달성을 위해선 large-scale high-quality labeled training data 가 필요하지만, 많은 상황에서 labeled data 구성은 어렵다. 본 논문은 sentence classification 및 sequence labelling task 를 포함한 low-resource NLU task 를 연구 이전 연구들은 NLU model 학습을 위해 추가적인 \"labeled data\" 를 보통 생성한다. Wang et al (2021a) : unlabeled in-domain data 로부터 pseudo labelled training data 생성을 위해 self-training Xu et al (2021) : general corpus 로부터 domain-specific unlabeled data 추출 Wei and Zou (2019); Dai and Adel (2020) : 랜덤 동의어 교체 같은 automatic heuristic rules 을 사용하여 small training data 확장 하지만 위 과정은 문법적이나 의미적으로 잘못된 데이터가 생성되어 텍스트를 왜곡할 수 있다. 위 딜레마를 해결하기 위해, low-resource setting 에서 data augmentation 을 위해 LM 및 PLMs 에 의지하는 기존 연구도 있다. labeled data 가 주어지면, 사람의 노력 없이 PLMs 를 fine-tuning 하여 새로운 인공 데이터를 생성할 수 있지만, 저자는 small training data (100 sample 미만)에서 직접 all parameter fine-tuning은 over-fitting 을 일으킬 수 있으며, 단순히 instance 를 기억할 수 있다고 주장. 결과적으로 인공 데이터는 original instance 와 유사할 수 있으며 NLU model 에 new training signal 을 제공할 수 없다. 최근 prompt-tuning 이 제안되어, 전체 모델 대신 soft prompt (즉, PLMs input 에 prepended continuous vectors) 에만 back-propagate 한다. 이는 full model tuning 과 competitive 하면서도 parameter 를 상당히 줄일 수 있다. 따라서, prompt tuning 은 low-resource generative fine-tuning 의 over-fitting 이슈를 피하기에 적합하다. 이에 영감을 받아 저자는 Prompt-based Data Augmentation model (PromptDA) 제안 pmls 전체를 고정한 채, small labeled training data 에 fine-tuning 할 때 추가적인 soft prompts 만 tuning soft prompt initialization 이 fine-tuning 에 상당히 영향을 주는 것을 관찰. 특히 low-resource situation data augmentation task 를 위한 prompt parameter 를 더 잘 초기화하기 위해, PLMs 의 pre-training corpus 데이터 증강 작업을 위해 프롬프트 매개변수를 더 잘 초기화하기 위해, 우리는 PLMs의 사전 훈련 말뭉치에서 프롬프트 매개변수를 직접 사전 훈련하는 작업에 대해 과제 중립적인 동의어 키워드에서 문장 사전 훈련 작업을 제안합니다. 이 작업은 부분 조각 정보(예: 키워드)에서 전체 훈련 샘플을 생성하는 과정을 모방합니다. 이전 연구(Ding et al., 2020; Yang et al., 2020; Anaby-Tavor et al., 2020)와 유사하게, 우리는 출력 태그에 조건을 걸어 완전한 합성 데이터를 생성하도록 PLMs를 세밀 조정할 수 있습니다. 이를 출력 뷰 생성(Output View Generation)이라고 합니다. 생성된 샘플의 다양성을 증가시키기 위해, 우리는 입력 뷰 생성(Input View Generation)이라는 또 다른 세밀 조정 생성 작업을 소개합니다. 이 작업은 샘플에서 추출된 키워드를 입력으로, 샘플을 출력으로 취합니다. 작은 훈련 데이터로부터 훈련된 NLG 모델은 여전히 낮은 품질의 샘플을 생성할 수 있는 가능성이 있으므로, 생성된 샘플을 필터링하기 위해 NLU 일관성 필터링(Anaby-Tavor et al., 2020)을 활용합니다. 우리는 네 가지 벤치마크에서 실험을 실시했습니다: 시퀀스 라벨링 작업 CoNLL03 (Tjong Kim Sang and De Meulder, 2003) 및 Wikiann (Pan et al., 2017), 문장 분류 작업 SST-2 (Socher et al., 2013) 및 RT (Pang and Lee, 2005). 실험 결과, PromDA로부터 합성된 데이터로 훈련된 NLU 모델이 일련의 경쟁력 있는 기준 모델을 일관되게 능가한다는 것을 보여줍니다. 이는 시퀀스 라벨링 작업에서 최첨단 준지도형 NLU 모델 MetaST (Wang et al., 2021a)을 포함합니다. 게다가, PromDA로부터의 합성 데이터가 레이블이 없는 도메인 데이터와도 상호 보완적임을 발견했습니다. 두 가지 데이터를 결합하면 NLU 모델의 성능을 더욱 향상시킬 수 있습니다. 마지막으로, 다양성 분석 및 사례 연구를 실시하여 PromDA로부터의 합성 데이터 품질을 더 확인합니다. 저희의 소스 코드는 https://github.com/GaryYufei/PromDA 에서 확인하실 수 있습니다.","s":"1. Introduction","u":"/docs/Paper/NLP/Augmentation/PromptDA","h":"","p":210},{"i":217,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.02506.pdf","s":"Prismer: A Vision-Language Model with An Esemble of Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":219,"t":"최근 vision-language 모델이 multi-modal 능력을 보이기 위해 거대한 학습이 필요하다. 이에 Prismer 로 데이터 및 파라미터에 효율적인 vision-language 를 소개 Prismer 는 적은 수의 구성요소만 학습하며, 대부분의 가중치는 미리 학습된 domain experts 로부터 상속받아 학습 중 동결 상태를 유지한다. 넓은 범위의 domain experts 를 모아, Prismer 는 효율적으로 expert knowledge 를 수집하고, 다양한 vision-language 추론 작업에 적용할 수 있음을 보여준다. 최대 2배 적은 데이터로도 Prismer 는 SOTA 를 달성한 모델들과 경쟁력 있는 fine-tuning 과 few-shot learning 성능에 도달 했다.","s":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":221,"t":"pretraining 한 대규모 모델은 다양한 작업에 좋은 일반화 능력을 가졌지만 대량의 훈련 데이터 및 계산 비용이 든다. 특히, vision-language 은 image captioning, visual question answering 등과 같은 multi-modal 추론이 필요하므로 recognition, detection, counting, 3D perception 등의 많은 기술이 요구된다. 일반적으로 이들은 대규모 데이터를 학습한 모델로 해결한다. 대신에, 저자들의 접근법으로 experts 라고 하는 서로 분리된 sub-network 로 이러한 스킬들과 domain knowledge 을 학습시키는 것이다. 이 모델은 모든 것을 한번 학습하는 것보다, 여러 스킬과 domain knowledge 를 통합하는데 초점을 둔다. 이 방법은 multi-modal 학습을 축소하는데 효과적인 방법이다. Prismer 의 핵심 설계는 다음 요소를 포함한다. web-scale knowledge 에 대한 강력한 vision, language 백본 모델 auxiliary knowledge 형태의 low-level vision signals (e.g. depth) 과 high-level vision signals (e.g. instance, segmentic label) 로 다양한 형태의 vision 정보를 인코딩한 vision experts 모든 expert model 은 따로 따로 pre-trained 하여 동결하여 전체 network parameter 에 약 20% 에 해당하는 학습가능한 components 로 연결된다. Prismer 는 13M 에도 불구하고 image captioning, image classification, visual question answering 등의 multi-modal 에 좋은 추론 성능을 보인다. 마지막으로, Prismer 의 다음 학습 방식을 분석한다. noisy experts 에 대해 강한 견고함을 보임 학습 성능 또한 experts 양이 증가함에 따라 호의적으로 확장","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":225,"t":"Prismer 는 encoder-decoder 인 transformer model 이다. endoer : vision input : RGB image 와 multi-label labels (e.g. depth, surface normal, segmentation ..) output : RGB 와 multi-modal features 의 sequence decoder : auto-regressive language cross attention 을 통해 multi-modal features 를 조절 output : 텍스트 token 의 sequence 위 Prismer 는 다른 SOTA 만큼의 성능에 도달하는데 필요한 GPU 시간을 줄였다. web-sacle 을 학습한 pretrained vision 과 language 인 top backbone 모델로 만들어 졌다. 또한 multi-modal signals 를 받아들이기 위해 vision encoder 를 확장하였으며, 이는 generated multi-modal auxiliary knowledge 와 capture semantic 을 가능케 했다. 예를 들어, \"text-reading\" 은 OCR detection expert 로 해결 \"object-recognition\" 은 object detection 으로 해결 모든 visual expert labels 은 Prismer 에 포함한다. Prismer 는 생성 모델로, language modeling 이나 prefix language modeling 같은 vision-language 추론 작업을 새로 만들었다.","s":"3.1 Model Overview","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#31-model-overview","p":216},{"i":227,"t":"Prismer 는 두 가지의 pre-trained experts 를 포함한다. Backbone Experts vision 과 language 모델 모두 transformer 아키텍처를 기반으로 한다 학습가능한 components 로 쉽게 연결 모델 parameter 에 encoding 된 domain knowledge 를 보존하기 위해 pretraining 면서 대부분의 weight 를 동결 Modality Experts low-level vision signals: depth, surface, edge; high-level vision signals: object labels, segmentation labels, text labels; 를 인코딩한 6 modality expert 포함 위 mdality experts 는 black-box 예측기 modality experts 의 weight 를 동결하여 어떤 설계도 가능하도록 함 위 predicted labels 에 modality 별로 후 처리 후 RH×W×C\\mathbb{R}^{H \\times W \\times C}RH×W×C tensor 로 transforming 한다 (H, W, C 는 height, width, channel 임. e.g. depth 는 C=1C = 1C=1, surface 는 C=3C = 3C=3). high-level semantic signal 를 인코딩한 모든 experts 에 대해, 각 픽셀을 이에 대응하는 pretrained CLIP model 로 text embedding 과 함께 tiling 한다. 이후 효과적인 훈련을 위해서 PCA 를 적용하여 차원수를 C=64C = 64C=64 으로 down-sampling 한다. 모든 modality experts 에 대한 자세한 사항은 아래 테이블과 같다.","s":"3.2 Pre-trained Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#32-pre-trained-experts","p":216},{"i":230,"t":"모든 experts labels 는 처음에 무작위로 초기화된 convolution layer 를 지난다. 같은 차원수로 매핑하기 위함 5 convolution layers 를 적용 각각에 [3 x 3] 의 작은 커널을 구성 기존 ViT 의 큰 커널로 된 single convolutional layer 보다 성능이 좋음 For high-level semantic labels 실행중인 메모리를 보존하기 위해 해상도를 4배로 다운 샘플링 object instance 간의 차이를 식별하기 위해 학습 가능한 무작위로 샘플링된 embedding 을 추가 → instance embedding, 128 로 설정 For RGB images 간단하게 pretrained vision 백본으로 convolutional stem 정의 모든 modality expert embedding 은 RGB 를 포함하며, transformer layer 를 지나기 전에, pretrained positional embedding 을 추가한다.","s":"Modality-Specific Convolutional Stem","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#modality-specific-convolutional-stem","p":216},{"i":232,"t":"self-attention 의 계산 복잡도는 patch 수에 비례하므로, modality experts 의 수가 크면 쉽게 많은 메모리를 요구할 수도 있다. 이 이슈를 해결하기 위해 Experts Resampler 를 제안한다. For Experts Resampler 다양한 experts 를 input 으로 받음 고정된 수의 embedding 을 출력 language decoder 와 vision encoder 와 무관하게 self-attention 계산에 대해 일정한 메모리를 소모 모든 multi-modal features 에서 연결된 flattened embedding 을 cross-attend 하기 위해 pretrained latent query 를 학습 이후 multi-modal features 를 auxiliary knowledge distillation 형태처럼 latent query 의 수와 동일한 작은 수의 토큰으로 압축한다. 결국, 더 좋은 효과를 위해 multi-modal features 와 learned latent queries 를 연결하기 위해 key 와 value 로 설계","s":"Experts Resampler","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#experts-resampler","p":216},{"i":234,"t":"multi-modal features 의 표현력과 훈련성을 향상 시키기 위해 vision 과 language 백본 모델의 각 transformer layer 에 lightweight adaptor 를 삽입 For Lightweight Adaptor 먼저, input feature 를 non-linearity 적용으로 작은 차원으로 down-projection 한다. 훈련 안정성을 위해 Squared ReLU 를 사용한다. 이후, input 의 원래 차원으로 되돌리기 위해 up-projection 한다. residual connection 을 이용하여, identity function 을 일치시키기 위해 near-zero weights 로 모든 adaptor 를 초기화 한다. 위 adaptor 를 통해서, language decoder 에서 cross attention block 과 연결하여 domain 별 vision 및 language 백본을 vision-language 로 자연스럽게 변환시킨다.","s":"Lightweight Adaptor","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#lightweight-adaptor","p":216},{"i":236,"t":"저자는 Prismer 를 next token 을 autoregressive 하게 예측하기 위한 한 가지 목표로 훈련 시켰다. 표준 encoder-decoder 아키텍처에 따라 다음의 forward autoregressive factorisation 진행 L=−∑t=1T log p(yt∣y<t,z)L = - \\sum^T_{t=1}\\ log\\ p(y_t |y_{<t},z)L=−∑t=1T​ log p(yt​∣y<t​,z) vision encoder 의 multi-modal feature 예측값 zzz language decoder 는 TTT 길이만큼 text caption yyy 의 조건부 우도 (conditional likelihood)를 최대화하도록 학습 위 목표는 gradient 계산을 위해 한 번의 forward pass 만 요구되며, 다른 VLMs 보다 효과적이고 능률적이다. 하지만 모델은 multi-modal language generation 에 초점을 두기 때문에, image-text retrieval 이나 visual entailment 와 같은 mutli-modal discriminative task 에는 적합하지 못하다.","s":"3.4 Training Objective","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#34-training-objective","p":216},{"i":239,"t":"Prismer 말고도, Experts Resampler 없이 RGB 이미지 만으로 학습을 진행한 PrismerZ 도 있다. 두 모델은 vision encoder 에 pretrained CLIP, language decoder 에 RoBERTa 를 활용했다. 실험 초기엔 다른 언어 모델인 OPT 나 BLOOM 을 사용했지만 좋은 성능은 내지 못했다. 모델 사이즈는 LARGE, BASE 두 가지로 진행을 한다. BASE : ViT-B/16 and RoBERTaBASE_{BASE}BASE​ LARGE : ViT-L/14 and RoBERTaLARGE_{LARGE}LARGE​","s":"4.1 Prismer Model Variants","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#41-prismer-model-variants","p":216},{"i":242,"t":"in-domain 데이터셋 COCO Visual Genome web 데이터셋 Conceptual Captions SBU captions Conceptual 12M web 데이터셋은 image captioner 로 pre-filter 와 re-caption 을 거쳤다. 데이터셋은 11M image 또는 12.7M 의 image/text 쌍을 포함하고 있다.","s":"Pre-training Datasets","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#pre-training-datasets","p":216},{"i":244,"t":"Optimizer AdamW weight decay, 0.05 Model Sharding model parameters 의 일부만 훈련이 가능하여 고해상도 fine-tuning 할 때만 적용 모든 GPU 에 교차하여 optimiser states 와 parameter gradient 가 가능한 ZeRO Stage 2 기술을 채용 ZeRO Stage 분산 학습 및 추론을 효율적이고, 효과적으로 만드는 딥러닝 최적화 라이브러리 Mixed Precision 훈련 시간 감소를 위해 Automatic Mixed Precision (AMP) 사용 fp16 precision 적용 AMP 일반적으로 모델 학습 시 FP32 (부동소수점 표기법, 32bit) 를 사용하는데, 연산량 감소를 위해 FP16 을 적용하면 loss 가 올라가는 현상이 있음비트 수가 줄어든 만큼 backpropagation 을 진행하면서 정확한 수를 표현 못하기 때문이다. 이에 NVIDIA 측에서 이를 해결하고자 다음과 같은 automatic 방법을 제안한 것모델 최적화 및 훈련 속도 감소를 가능케 한다.","s":"Optimisation and Implementation","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#optimisation-and-implementation","p":216},{"i":246,"t":"image captioning 평가를 위해 텍스트 생성을 beam size 3 으로 beam search 를 사용한다. fine-tining 된 image captioning 에 \"A picture of\" 라는 접두사 prompt 를 input text 에 추가하니 품질 개선에 도움이 되는 것을 발견했다. VQA 및 image classification 평가에 대해서는 미리 정의된 답변 목록에서 token 단위로 log-likelihood 를 순위로 매겨서 closed ended 방식으로 평가한다. beam search NLP 분야의 Decoder 알고리즘 모든 단어 조합을 생성하고 그 중 가장 가능성이 높은 조합을 선택하는데, 이때 단어 조합 수를 파라미터인 \"beam size\" 를 설정한다. 즉, beam size 는 후보군 개수이다. Open-ended & Close-ended Open-ende 는 문제에 대한 미리 정의된 대답에 제한되지 않고, 개념적 이해나 문맥적 이해가 필요한 것. 예로 이미지 캡셔닝 작업에서 이미지에 대한 설명이나 이야기를 생성 Close-ended 는 미리 정의된 목록에서 선택할 수 있는 한정된 대답만 가지고 문제를 해결 하는 것. 예로 이미지가 주어졌을 때 미리 정의된 카테고리 목록에 해당하여 분류 되는지 봄","s":"Evalution Setting","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#evalution-setting","p":216},{"i":249,"t":"표준 cross-entropy loss 로 COCO Caption 을 fine-tuning 진행 이후, COCO Caption test 와 NoCaps validation, VQAv2 dataset 와 Visual Genome training samples 로 평가 다른 VLMs 모델들과 다음과 같이 비교를 하였다.","s":"Fine-tuned Performance COCO Caption, NoCaps and VQAv2","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#fine-tuned-performance-coco-caption-nocaps-and-vqav2","p":216},{"i":251,"t":"Fig 4 Prismer approach 는 zero-shot 생성도 가능하며, 추가적인 fine-tuning 없이 image captioning 에 직접적으로 적용이 가능하다. 위 중앙 테이블을 살펴보자. NoCaps 데이터셋에서, 140회 정도의 훈련만으로 SimVLM 과 경쟁력이 있다. 다음과 같은 Prismer 로 생성한 caption 목록 예제를 보여준다.","s":"Zero-shot Performance on Image Captioning","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#zero-shot-performance-on-image-captioning","p":216},{"i":253,"t":"few-shot 으로 ImageNet 데이터셋을 통해 평가를 진행 \"A photo of a [CLASS NAME]\" 과 같은 임시 caption 으로 각 카테고리를 매핑하여 classification task 로 변환하였으며, log-likelihood 를 사용하여 모든 caption 에 점수를 매긴다. Flamingo 는 gradient 업데이트 없이 in-context (문맥에 포함되는지) 를 통해 few-shot 한것과 달리, Prismer 는 가벼운 fine-tuning 으로 few-shot 하였다. Fig 4 의 오른쪽을 살펴보자. GIT 이나 Flamingo 보다는 좋은 실적을 내지 못함. few-shot 에서 백본 모델인 ViT-B 와 ViT-L 과 큰 차이로 성능이 좋음 위 사실로, 더 좋은 experts label 이나 vision backbone 으로 성능을 더 끌어올릴 수 있다는 것을 시사","s":"Few-shot Performance on ImageNet Classification","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#few-shot-performance-on-imagenet-classification","p":216},{"i":255,"t":"저자는 Prismer 에 대한 추가적인 조사와 발견을 위해 추가 실험을 수행, 여러 component 아키텍처 를 제거 모든 실험은 BASE 모델로 진행하였으며, 총 3M data 인 Conceptual Captions 와 SBU 를 결합하여 훈련 하였으며, 평가는 [224 x 224] 해상도의 VQAv2 로 평가했다.","s":"5. Additional Analysis","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":258,"t":"위 그림의 (a) 와 같이 더 많은 modality experts 를 추가하니 성능 개선이 나타남 이유는 모델에 더 많은 domain knowledge 를 제공할 수 있기 때문 하지만 끝내 성능이 정체되며, 이후 추가되는 modality experts 는 확실한 이득을 제공하진 않음","s":"More Experts, Better Performance","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#more-experts-better-performance","p":216},{"i":260,"t":"위 그림 (b) 와 같이 expert 의 퀄리티에 대한 영향을 평가 일정 수의 예측된 depth labels 를 손상된 depth 로 교체 (균일하게 분포된 무작위 noise 를 샘플링) 위 사항으로 좋은 quality experts 는 더 정확한 domain knowledge 를 제공한다는 사실을 관찰","s":"Better Experts, Better Performance","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#better-experts-better-performance","p":216},{"i":262,"t":"위 그림 (c) 와 같이Prismer 가 noise 를 예측하는 expert 를 포함해도 성능이 유지되는 것을 관찰 RGB 이미지만 학습한 것 보다 noise 를 추가한 것이 정확도가 좋다. 위 사항은 암묵적으로 정규화로 간주될 수 있으며, Prismer 가 유익하지않은 expert 에 대해서도 안전하게 학습하고 성능 저하를 일으키지 않는 다는 것이다 표준적인 multi-task 나 auxiliary learning 보다 더 효과적인 학습 전략이라는 것을 암시","s":"Robustness to Noisy Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#robustness-to-noisy-experts","p":216},{"i":265,"t":"adaptor 설계에 대한 ablation study 는 위 표에서 확인할 수 있다. 표준 residual connection 과 encoder-decoder 구조가 포함된, 간단한 adaptor design 이 가장 성능이 좋았다. 각 transformer layer 끝마다 adaptor 를 추가하거나 learnable gating 메커니즘을 구성한 복잡한 설계에 대해서는 성능이 좋지 않았다. 나아가, 단일 adaptor 에 큰 bottleneck hidden size 를 주니 개선된 성능을 보였다.","s":"Adaptor Design and Size","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#adaptor-design-and-size","p":216},{"i":267,"t":"resampler 설계에 대한 ablation study 는 위 표에서 확인할 수 있다. 간단한 설계가 학습에 가장 적합했다. 무작위로 non-learnable 샘플링한 접근법은 learnable resampler 보다 성능이 낮았고, resampler 를 RGB 를 포함하여 모든 input signal 을 받아 들이니 (Prismer design 은 RGB 에 대해선 받지 않음) 성능 감소가 일어났다. 마지막으로 resampler 크기를 키우니 이득을 얻지 못하였다.","s":"Resampler Design and Multi-modal Sampling Strategy","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#resampler-design-and-multi-modal-sampling-strategy","p":216},{"i":269,"t":"모델을 freezing 한 것과, pre-training 및 fine-tuning 을 비교한 실험을 진행 freezing pre-trained 파라미터가 좋은 성능이 나타났으며, 과적합 및 학습하며 배운 knowledge 을 잊는 것을 피하였다. 또한 이 파라미터들을 freezing 을 하니 GPU 메모리의 상당 수의 양을 save 하였다. 심지어 다른 downstream task 에 fine-tuning 할 때도 이득을 얻었다.","s":"The Effect of Frozen Backbones","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#the-effect-of-frozen-backbones","p":216},{"i":271,"t":"이 논문의 결론으로 Prismer 가 적은 수의 trainable components 를 활용하여, Image captioning, VQA, image classification 등에 좋은 성능을 보인다는 것을 말한다.","s":"6. Conclusions, Limitations and Discussion","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":216},{"i":273,"t":"zero-shot in-context generalisation 은 큰 언어 모델에만 존재하는 신생적인 특성 Prismer 는 효율적인 학습을 중점으로 두어, 작은 규모라서 few-shot in-context prompting 수행 능력이 없음","s":"Multi-modal In-context Learning","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#multi-modal-in-context-learning","p":216},{"i":275,"t":"다른 데이터셋으로 pre-train 한 segmentation expert 로 pre-train 된 Prismer 의 추론을 실험 동일한 언어 모델로 semantic label 을 인코딩하지만, 서로 다른 semantic 정보에 대한 experts 에 대해 제한된 적응성을 보여, 성능 저하를 일으킴","s":"Zero-shot Adaptation on New Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#zero-shot-adaptation-on-new-experts","p":216},{"i":277,"t":"위 내용과 비슷하게, Prismer 가 pretraining 할 때 포함되는 모든 experts 의 multi-modal features 에 얽매이는 것을 발견 따라서 추론 중 일부 experts 만 있으면 성능 저하를 일으킴 마스킹된 auto-encoding 같은 다른 훈련 목표로, Prismer 를 임의의 수로 experts 를 기반으로 추론하니 성능 저하가 일어남","s":"Free-form Inference on Partial Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#free-form-inference-on-partial-experts","p":216},{"i":279,"t":"Prismer 는 모든 experts 에 대해 후 처리 후 이미지와 동일한 3차원 텐서로 변환하는데, object detection labels 을 텍스트 토큰 시퀀스로 변환과 같은 domain knowladge 을 나타내는 효과적인 방법도 있으며, 이는 앞으로의 연구에서 더 강한 추론과 안정적인 훈련이 가능할 것으로 보임.","s":"Representation of Expert Knowledge","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#representation-of-expert-knowledge","p":216},{"i":281,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/1706.03762.pdf","s":"Attention Is All You Need","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":283,"t":"우세한 sequence transduction 은 encoder 및 decoder 를 포함한 RNN, CNN 기반으로 한다. 이를 attention mechanism 만 사용하는 Transformer 를 제안 두 기계번역 task 에서 뛰어난 퀄리티를 보여주는데, 더욱 병렬적이면서도 훈련 시간을 크게 줄임 WMT 2014 에서 SOTA (ensemble) 보다 2 points 높은 28.4 BLEU 달성 (single model) Transformer 가 다른 task 에서도 잘 일반화되는 것을 보여줌","s":"Abstract","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":285,"t":"RNN 은 LSTM 및 Gated RNN 등 많은 노력으로 encoder-decoder 아키텍쳐의 경계로 계속 넓혀져 왔다. 일반적으로 input 및 output sequences 의 symbol positions 에 따라 계산을 분해 hidden state hth_tht​ 는 이전 ht−1h_{t-1}ht−1​ 및 position ttt 의 input 으로 생성 순차적인 특성으로 인해 병렬화 불가능 sequence 길이가 길어질수록 메모리 제약으로 배치 제한 Attention mechanism 은 input 및 output 거리를 고려하지 않고 종속성을 모델링할 수 있게 해주어 다양한 task 에서 필수적이게 되었지만, 대부분 RNN 과 함께 사용한다. 본 연구에서는 RNN 을 배제하고 완전히 attention mechanism 에만 의존하여 input 과 output 사이의 global dependencies 를 도출하는 Transformer 제안 병렬화를 허용 8개 P100 GPU 에서 12시간 훈련만으로 SOTA","s":"1. Introduction","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":287,"t":"순차 계산을 줄이기 위해 CNN 을 사용한 연구 [Extended Neural GPU, ByteNet, ConvS2S]가 있었으며, input 및 output position 에 대해 병렬로 hidden representation 을 계산하지만, 필요한 연산 수가 위치 간의 거리에 따라 증가한다. ConvS2S 의 경우 선형적으로, ByteNet 의 경우 로그함수적으로 증가 Transformer 는 이를 일정 수 감소시키지만, averaging attention-weighted positions 로 인해 resolution 이 감소하는 효과가 있는데, 이는 Multi-head Attention 으로 상쇄시킨다. Self-attention 은 서로 다른 위치를 관련시켜 sequence 의 representation 을 계산하는 attention mechanism reading comprehension, abstractive summarization, textual entailment 및 tkas-independent sentence representation 등 다양한 task 에서 성공 End-to-End memory networks 는 sequence-aligned recurrence 대신 recurrent attention mechanism 을 기반으로하며, simple-language question answering 과 language modeling task 에서 잘 수행한다. 하지만 Transformer 는 sequence-aligned RNN 및 CNN 을 사용하지 않고 input 및 output representation 계산을 완전히 self-attention 에만 의존하는 최초의 transduction model","s":"2. Background","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":289,"t":"경쟁력 있는 sequence transduction model 은 encoder-decoder 구조를 갖고 있다. encoder : symbol representations input sequence (x1,…,xn)(x_1, \\dots, x_n)(x1​,…,xn​) 을 continuous representations sequence z=(z1,…,zn)z = (z_1, \\dots, z_n)z=(z1​,…,zn​) 로 매핑 decoder : 각 단계에 하나씩 symbol output sequence (y1,…,ym)(y_1, \\dots, y_m)(y1​,…,ym​) 생성 각 단계에서 model 은 auto-regressive 하며, 다음 생성 때 이전에 생성된 symbols 를 추가 입력으로 사용 Transformer 는 위 아키텍처를 따르며, encoder 및 decoder 에 stacked self-attention 및 point-wise, fully connected layer 를 사용","s":"3. Model Architecture","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":292,"t":"encoder 는 N=6N = 6N=6 의 동일한 layer stack 으로 구성된다. 각 layer 는 두 개의 sub-layers 로 구성 multi-head self-attention position-wise fully connected feed-forward network 각 sub-layer 에 residual connection 사용하고, 그 다음 layer normalization 수행 각 sub-layer 의 출력은 LayerNorm(x+Sublayer(x))\\text{LayerNorm}(x + \\text{Sublayer}(x))LayerNorm(x+Sublayer(x)) Sublayer(x)\\text{Sublayer}(x)Sublayer(x) : sub-layer residual connection 을 용이하게 하기 위해 모델 내의 all sub-layers 및 embedding layers 는 output dimension dmodel=512d_{\\text{model}} = 512dmodel​=512 생성","s":"Encoder","u":"/docs/Paper/NLP/Model/Transformer","h":"#encoder","p":280},{"i":294,"t":"decoder 또한 N=6N = 6N=6 의 동일한 layer stack 으로 구성된다. encoder layer 와 같은 two sub-layers 에 추가 third sub-layer 삽입 이는 encoder stack 의 output 에 대해 multi-head attention 수행 encoder 와 유사하게, 각 sub-layer 에 residual connection 및 layer normalization 사용 decoder stack 의 self-attention 을 수정하여 position 이 subsequent position 에 attending 하는 것을 방지 이 masking 은 output embedding 이 한 위치 만큼만 offset 되어, position iii 에 대한 예측을 iii 보다 적은 이전 position 정보만 사용할 수 있도록 보장","s":"Decoder","u":"/docs/Paper/NLP/Model/Transformer","h":"#decoder","p":280},{"i":296,"t":"Attention function 은 query 및 key-value 쌍들을 output 으로 mapping 하는 함수다. query, key, value : 모두 vector output : weighted sum of values 각 value 에 할당된 weight 는 상응하는 key 와의 호환성 함수 (compatibility function)에 의해 계산됨","s":"3.2 Attention","u":"/docs/Paper/NLP/Model/Transformer","h":"#32-attention","p":280},{"i":298,"t":"저자는 이 특정 attention 을 Scaled Dot-Product Attention 이라 한다. (Fig. 2) input 은 dimension dkd_kdk​ 의 queries 및 keys, dimension dvd_vdv​ 의 values 로 이루어짐 all keys 와 query 에 dot product 를 계산하고, 각각 dk\\sqrt{d_k}dk​​ 로 나누고 softmax 함수를 적용하여 values 에 대한 weight 를 얻는다. 저자는 queries 를 하나의 matrix QQQ 로 묶어 attention function 계산한다. keys 및 values 또한 matrix KKK 및 VVV 로 묶어서 계산한다. 다음 output matrix 를 계산한다. Attention(Q,K,V)=softmax(QKTdk)V\\begin{equation} \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V \\end{equation}Attention(Q,K,V)=softmax(dk​​QKT​)V​​ 일반적으로 사용되는 attention functions 은 additive attention 과 dot-product (multi-plicative) attention 이다. Dot-product attention : 저자의 알고리즘과 동일하지만, scailing 인자 1dk\\frac{1}{\\sqrt{d_k}}dk​​1​ 가 다르다 Additive attention : single hidden layer 인 feed-forward network 를 사용하여 compatibility function 계산 위 두 메커니즘은 이론적 복잡성은 비슷하지만, dot-product attention 은 고도로 최적화된 matrix multiuplication code 를 사용하여 구현되기 때문에 훨씬 더 빠르고 공간 효율적이다. small values dkd_kdk​ 에 대한 두 메커니즘은 유사한 성능을 발휘하지만, larger valuyes dkd_kdk​ 에 대한 scaling 없이 사용하는 additive attention 은 dot-product 보다 우월하다. 저자는 large values dkd_kdk​ 에 대해 dot-product 가 매우 큰값을 갖게되어, softmax function 을 extremely small gradients 를 갖도록 하기 위해 dot-product 를 1dk\\frac{1}{\\sqrt{d_k}}dk​​1​ 로 scaling 한다.","s":"3.2.1 Scaled Dot-Product Attention","u":"/docs/Paper/NLP/Model/Transformer","h":"#321-scaled-dot-product-attention","p":280},{"i":300,"t":"dmodeld_{\\text{model}}dmodel​ dimensional keys, values, queries 로 single attension function 을 수행하는 대신, 저자는 learned linear projections 을 사용하여 dkd_kdk​, dkd_kdk​ 및 dvd_vdv​ dimensions 으로 queries, keys 및 values 를 hhh 번 linearly project 하는 것이 유익한 것을 발견 이러한 projected queries, keys 및 values 각각에 대해 병렬로 attention function 을 수행하여 dvd_vdv​ dimensional output values 를 얻는다. 이후 이들을 연결(concatenated)하고 다시 한 번 project 하여 Fig. 2 처럼 최종값을 얻는다. Multi-head attention 은 서로 다른 representation subspaces 에서 서로 다른 position 에서 정보를 공동으로 attend 하도록 한다. single attention head 의 경우, 평균화로 이를 억제한다. MultiHead(Q,K,V)=Concat(head1,…,headh)WOwhere headi=Attention(QWiQ,KWiK,VWiV)\\begin{align*} \\text{MultiHead}(Q,K,V) &= \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h) W^O \\\\ \\text{where} \\ \\text{head}_i &= \\text{Attention}(QW^Q_i, KW^K_i, VW^V_i) \\end{align*}MultiHead(Q,K,V)where headi​​=Concat(head1​,…,headh​)WO=Attention(QWiQ​,KWiK​,VWiV​)​ projections 은 parameter matrices WiQ∈Rdmodel×dk,WiK∈Rdmodel×dk,WiV∈Rdmodel×dvW_i^Q \\in \\mathbb{R}^{d_\\text{model} \\times d_k}, W_i^K \\in \\mathbb{R}^{d_\\text{model} \\times d_k}, W_i^V \\in \\mathbb{R}^{d_\\text{model} \\times d_v}WiQ​∈Rdmodel​×dk​,WiK​∈Rdmodel​×dk​,WiV​∈Rdmodel​×dv​ 본 연구에선 parallel attention layer 또는 heads 로 h=8h = 8h=8 을 사용 각 head 는 dk=dv=dmodel/h=64d_k = d_v = d_{\\text{model}}/h = 64dk​=dv​=dmodel​/h=64 를 사용 각 head 의 차원이 축소되었기 때문에, 총 계산 비용은 전체 차원의 single-head attention 과 유사","s":"3.2.2 Multi-Head Attention","u":"/docs/Paper/NLP/Model/Transformer","h":"#322-multi-head-attention","p":280},{"i":302,"t":"Transformer 는 multi-head attention 을 세 가지의 다른 방식을 사용 encoder-decoder attention layers 에서, query 는 previous decoder layer 에서 가져오고, memory key 와 value encoder 의 output 에서 가져온다. 이를 통해 decoder 의 각 position 이 input sequence 의 all positions 에 attend 를 줄 수 있다. 이는 sequence-to-sequence 의 전형적인 encoder-decoder attention machanism 을 모방한다. encoder 는 self-attention layer 를 포함한다. self-attention layer 에서 모든 keys, values 및 queries 는 동일한 위치를 가져온다. 이 경우엔 이전 encoder layer 의 output 이다. encoder 의 각 위치는 이전 encoder layer 의 모든 위치에 attend 할 수 있다. decoder 의 self-attention layer 는 decoder 의 각 위치가 해당 위치를 포함한 decoder 의 모든 위치에 attend 할 수 있다. self-attention 의 leftward information flow 를 방지하여 auto-regressive 속성을 보존해야 한다. 저자는 scaled dot-product attention 내부에서 softmax 의 입력에 대한 모든 값 중 잘못된 연결에 해당하는 값을 masking out (−∞-\\infin−∞ 로 설정)하여 이를 구현. (Fig. 2)","s":"3.2.3 Applications of Attention in our Model","u":"/docs/Paper/NLP/Model/Transformer","h":"#323-applications-of-attention-in-our-model","p":280},{"i":304,"t":"attention sub-layers 외에도 encoder 및 decoder 의 각 레이어는 각 위치에 대해 별도로 동일하게 적용되는 fully connected feed-forward network 를 포함 이는 two linear transformations 과, 사이에 ReLU activation 을 사용한다. FFN(x)=max⁡(0,xW1+b1)W2+b2\\begin{equation} \\text{FFN}(x) = \\max(0, xW_1 + b_1)W_2 + b_2 \\end{equation}FFN(x)=max(0,xW1​+b1​)W2​+b2​​​ linear transformations 는 여러 position 에서 동일하지만 layer 마다 서로 다른 parameters 를 사용 이를 설명할 방법으로, kernel size 1 인 two convolution 으로 표현할 수 있다. input 및 output 차원은 dmodel=512d_\\text{model} = 512dmodel​=512 이며, inner-layer 의 차원은 dff=2048d_{ff} = 2048dff​=2048","s":"3.3 Position-wise Feed-Forward Networks","u":"/docs/Paper/NLP/Model/Transformer","h":"#33-position-wise-feed-forward-networks","p":280},{"i":306,"t":"다른 sequence transduction model 과 유사히게, input tokens 을 차원 dmodeld_\\text{model}dmodel​ 인 vector 로 변환하기 위해 learned embedding 사용 또한 decoder output 을 predicted next-token 확률로 변환하기 위해 learned linear transformation 과 softmax function 사용 이 모델에선, two embedding layers 와 pre-softmax linear transformation 사이에 same weight matrix 를 공유한다. embedding layers 에서는 해당 weights 를 dmodel\\sqrt{d_\\text{model}}dmodel​​ 로 곱한다.","s":"3.4 Embedding and Softmax","u":"/docs/Paper/NLP/Model/Transformer","h":"#34-embedding-and-softmax","p":280},{"i":308,"t":"이 모델에는 recurrence 와 convolution 이 없기 때문에 sequence 의 순서를 사용하기 위해 sequence 내의 토큰의 상대적 또는 절대적 위치에 대한 정보를 주입해야 한다. 이를 위해 encoder 와 decoder stacks 의 아래쪽에 positional encodings 를 추가한다. positional encodings 의 차원은 embedding dmodeld_\\text{model}dmodel​ 과 동일하므로 두 값을 합할 수 있다. learned 및 fixed 여러 positional encodings 선택지가 있다. PE(pos,2i)=sin(pos/100002i/dmodel)PE(pos,2i+1)=cos(pos/100002i/dmodel)\\begin{align*} PE(pos, 2i) &= sin(pos / 10000^{2i / d_\\text{model}}) \\\\ PE(pos, 2i + 1) &= cos(pos / 10000^{2i / d_\\text{model}}) \\end{align*}PE(pos,2i)PE(pos,2i+1)​=sin(pos/100002i/dmodel​)=cos(pos/100002i/dmodel​)​ pospospos : position, iii : dimension 즉 positional encoding 의 각 차원은 사인 함수에 해당 파장은 2π2\\pi2π 에서 10000⋅2π10000 \\cdot 2\\pi10000⋅2π 까지 기하급수적 진행을 형성 fixed offset kkk 에 대해 PEpos+kPE_{pos + k}PEpos+k​ 를 PEposPE_{pos}PEpos​ 의 linear function 으로 표현할 수 있기 때문에 모델이 상대적 위치를 쉽게 attention 할 수 있다는 가설을 세움 또한 learned positional encoding 을 사용하여 실험했으며, 두 버전이 거의 동일한 결과를 내는 것을 발견 (Table 3. E) 저자는 사인 함수 버전을 택했는데, 이는 모델이 학습 중 long sequence 를 추론할 수 있기 때","s":"3.5 Positional Encoding","u":"/docs/Paper/NLP/Model/Transformer","h":"#35-positional-encoding","p":280},{"i":310,"t":"symbol representations 의 한 variable-length sequence (x1,…,xn)(x_1, \\dots, x_n)(x1​,…,xn​) 를 다른 같은 길이의 sequence (z1,…,zn)(z_1, \\dots, z_n)(z1​,…,zn​) 로 매핑하는데 사용되는 recurrent 및 convolutional layers 와 self-attention layers 를 다양한 측면에서 비교 이러한 sequence 는 sequence transduction encoder 또는 decoder 의 hidden layer 같은 것으로, xi,zi∈Rdx_i, z_i \\in \\mathbb{R}^dxi​,zi​∈Rd self-attention 은 다음 세 가지 요구 사항을 고려 layer 당 총 계산 복잡성 병렬화할 수 있는 계산 양 network 내의 long-range dependencies 사이의 path length long-range dependencies 를 학습하는 것은 sequence transduction tasks 에서 어려운 과제다. 이러한 dependencies 를 학습할 수 있는 능력에 미치는 요소 중 하나는 network 에 forward 및 backward signals 가 이동하는 path length 이다. input 및 output sequences 의 모든 positions combination 간의 이러한 path 가 짧을수록 long-range dependencies 를 학습하기가 쉽다. 따라서 저자는 서로 다른 layer 유형으로 구성된 network 내에 two input 및 output position 간의 maximum path length 도 비교한다. Table 1 과 같이, self-attention layer 는 모든 position 을 일정한 수의 sequential operations 로 연결하는 반면, recurrent layer 는 O(n)O(n)O(n) 의 sequential operations 이 필요 계산 복잡성 측면에서, sequence length nnn 이 representation dimension ddd 보다 작은 경우 recurrent layers 보다 빠르다. very long sequence 를 처리하는 tasks 의 계산 성능을 향상시키기 위해 self-attention 을 input sequence 의 해당 output position 을 중심으로 size rrr 의 이웃만 고려하도록 제한 가능 이렇게 하면 maximum path length O(n/r)O(n/r)O(n/r) 로 증가 kernel k<nk < nk<n 인 single convolutional layer 는 input 및 output 의 all paies 를 연결하지 않는다. contiguous kernels 의 경우 O(n/k)O(n/k)O(n/k) 개 convolution layers dilated convolution 의 경우 O(logk(n))O(log_k(n))O(logk​(n)) 개 스택 필요 이는 network 내의 two positions 간의 longest path 를 증가시킴 convolutional layers 는 일반적으로 recurrent layer 보다 비용이 크며, kkk 의 배수 separable convolution 은 복잡성을 O(k⋅n⋅d+n⋅d2)O(k \\cdot n \\cdot d + n \\cdot d^2)O(k⋅n⋅d+n⋅d2) 으로 상당히 줄이지만, k=nk = nk=n 인 경우에 복잡성은 self-attention 과 point-wise feed-forward layers 의 복잡성과 동일 추가로, self-attention 은 해석 가능한 모델을 제공하며, attention distribution 을 조사(appendix 참고)하고 개별 attention heads 는 명확히 서로 다른 작업을 수행하는 것으로 나타나며 많은 attention head 가 문장의 문법 및 의미적 구조와 관련된 동작을 보인다.","s":"4. Why Self-Attention","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":313,"t":"약 4.5M 의 sentence pairs 를 가진 WMT 2014 English-German dataset 에서 훈련 문장은 byte-pair encoding 을 사용하여 인코딩되어 있으며, 약 37000 tokens 의 source-target vocabulary 를 갖는다. English-French 의 경우, 36M 문장의 더 큰 2014 English-French dataset 사용, 32000 word-piece vocabulary 의 token 으로 분할 sentence pairs 은 sequence length 별로 배치됨 각 training batch 에는 약 25000 source tokens 및 25000 target tokens 이 포함","s":"5.1 Training Data and Batching","u":"/docs/Paper/NLP/Model/Transformer","h":"#51-training-data-and-batching","p":280},{"i":315,"t":"8 NVIDIA P100 GPUs 로 모델 훈련 각 훈련 단계는 약 0.4초 소요 100,000 steps 또는 12 시간 훈련 대형 모델의 경우, step 당 1.0 초 소요되며, 300,000 steps (3.5일) 흔련","s":"5.2 Hardware and Schedule","u":"/docs/Paper/NLP/Model/Transformer","h":"#52-hardware-and-schedule","p":280},{"i":317,"t":"Adam optimizer 를 사용했으며, β1=0.9,β2=0.98\\beta_1 = 0.9, \\beta_2 = 0.98β1​=0.9,β2​=0.98 및 ϵ=10−9\\epsilon = 10^{-9}ϵ=10−9 설정 훈련 동안 learning rate 를 조정했으며, 다음 수식에 따라 조정 lrate=dmodel−0.5⋅min⁡(step_num−0.5,step_num⋅warmup_steps−1.5)\\begin{equation} lrate = d_{\\text{model}}^{-0.5}\\cdot \\min (step\\_ num^{-0.5},step\\_ num\\cdot warmup\\_ steps^{-1.5}) \\end{equation}lrate=dmodel−0.5​⋅min(step_num−0.5,step_num⋅warmup_steps−1.5)​​ 첫 warmup_stepswarmup\\_ stepswarmup_steps training steps 에 대한 learning rate 를 linear 하게 증가시키고, step number 의 역 제곱근에 비례하여 감소시킨다. warmup_steps=4000warmup\\_ steps = 4000warmup_steps=4000","s":"5.3 Optimizer","u":"/docs/Paper/NLP/Model/Transformer","h":"#53-optimizer","p":280},{"i":319,"t":"training 중 세 가지 regularization 사용 Residual Dropout​ 각 sub-layer 의 output 에 dropout 적용 input 에 추가되기 전에 normalize 진행 또한 encoder-decoder stacks 의 embedding 및 positional embedding 의 합에도 dropout 적용 base model 에 Pdrop=0.1P_{drop} = 0.1Pdrop​=0.1 사용 Label Smoothing​ training 중 label smoothing value ϵls=0.1\\epsilon_{ls} = 0.1ϵls​=0.1 사용 이는 더 불확실해지도록 학습되기 때문에 perplexity 에 해를 끼친다. 하지만 accuracy 와 BLEU score 는 향상시킨다.","s":"5.4 Regularization","u":"/docs/Paper/NLP/Model/Transformer","h":"#54-regularization","p":280},{"i":322,"t":"WMT 2014 English-to-German task 의 경우 big transformer model (Table 2) 은 이전의 모든 모델 (앙상블 포함)보다 2.0 BLEU 이상의 성능 및 SOTA 성능의 BLEU 28.4 달성 훈련은 8 P100 GPUs 에서 3.5 일 걸림 base model 도 이전 모든 모델 및 앙상블을 능가하며, 경쟁 모델 중 어느 것보다 적은 훈련 비용을 이룸 WMT 2014 English-to-French task 의 경우 big model 이 BLEU 41.0 을 달성하여 모든 single model 보다 우수한 성능을 보여줌 이전 SOTA 의 훈련 비용 1/4 에 불과 해당 task 를 위해 훈련된 Transformer (big) 은 dropout rate Pdrop=0.1P_{drop} = 0.1Pdrop​=0.1 사용 base model 의 경우 마지막 5개의 checkpoint 를 평균화하여 single model 을 사용했으며, 10분 간격으로 기록됨 big model 의 경우 마지막 20개의 checkpoint 를 평균화 beam size 4 length penalty α=0.6\\alpha = 0.6α=0.6 추론 중 input length + 50 을 설정했지만, 가능한 경우 early stop Table 2 에서 결과를 요약하며, 번역 품질 및 훈련 비용을 비교 저자의 모델이 훈련 시간, 사용 GPU 수 및 각 GPU 의 floating-point capacity 의 추정치를 곱하여 계산","s":"6.1 Machine Translation","u":"/docs/Paper/NLP/Model/Transformer","h":"#61-machine-translation","p":280},{"i":324,"t":"Transformer 의 다양한 components 의 중요성을 평가하기 위해, 다양한 방식으로 변형하고, nettest2013 의 English-to-German dev set 에서 성능 변화 측정 beam search 를 사용했지만 checkpoint 펻균화는 사용하지 않음 (A) 행에서 attention head 수와 attention key 및 value dimensions 를 변화시키며 계산 양을 일정하게 유지했다. single-head attention 은 best setting 보다 BLEU 0.9 더 나쁘지만, many head 또한 품질을 저하시킨다. (B) 에선 attention key 크기를 줄이면 모델 품질이 저하된다. 이는 호환성을 결정하는 것이 쉽지 않으며, dop product 보다 더 정교한 호환성 함수가 유익할 수 있음을 시사 (C) 및 (D) 행에선 큰 모델이 더 좋으며, dropout 이 과적합을 피하는데 도움이 됨을 관찰 (E) 행에선 저자의 sinusodial encoding 을 learned positional embedding 으로 대체하여 base model 과 거의 동일한 결과를 관찰","s":"6.2 Model Variations","u":"/docs/Paper/NLP/Model/Transformer","h":"#62-model-variations","p":280},{"i":326,"t":"Transformer 가 다른 tasks 에 대해 일반화될 수 있는지 평가하기 위해 영어로 구성된 parsing tasks 에 실험 수행 이 task 는 specific challenge 를 제공: output 은 strong structural contraints 를 따르며 input 훨씬 길기 때문. 게다가 RNN sequence-to-sequence model 은 small-data 체제에서 SOTA 를 얻지 못함 Penn Treebank 의 WSJ 부분에서 40K training sentences 를 사용하여 dmodel=1024d_{model} = 1024dmodel​=1024 인 4-layer transformer 를 훈련 약 17M sentences 가 있는 larger high-confidence 및 BerkleyParser corpora 를 사용한 semi-supervised setting 도 훈련 WSJ 을 대상으로 하는 설정에선 16K tokens 의 vocabulary 를 사용했으며, semi-supervised setting 에서는 32K tokens 의 vocabulary 사용 저자는 22 dev set 에서 dropout, attention 및 residual, learning rate 및 beam search 를 선택하기 위해 일부 실험한 수행 다른 모델 매개변수는 English-to-German base translation model 과 동일하게 유지 inference 중 maximum output length + 300 으로 증가시키고, WSJ 만 대상으로 하는 설정과 semi-supervised learning 설정 모두 beam search 21 및 α=0.3\\alpha = 0.3α=0.3 사용 task-specific tuning 없는 경우에도 잘 수행되어, 이전의 모든 모델보다 우수한 결과를 얻었다. RNN sequence-to-sequence model 과 달리, transformer 는 40K setences 만 훈련시켰을 때도 BerkeleyParser 를 능가","s":"6.3 English Constituency Parsing","u":"/docs/Paper/NLP/Model/Transformer","h":"#63-english-constituency-parsing","p":280},{"i":328,"t":"본 연구에선 Transformer 제안 완전히 attention 에 기반한 sequence transduction model 로, encoder-decoder 아키텍처에서 가장 일반적인 recurrent layers 를 multi-head attention 으로 대체 translation tasks 에서 Transformer 는 recurrent 또는 convolutional layers 아키텍처보다 훨씬 빠르게 훈련될 수 있다. WMT 2014 English-to-German 및 WMT 2014 English-French translation task 에서 SOTA 달성. 심지어, 앙상블도 능가","s":"7. Conclusion","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":330,"t":"Attention Visualizations","s":"Appendix","u":"/docs/Paper/NLP/Model/Transformer","h":"","p":280},{"i":332,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2204.03649.pdf","s":"Unsupervised Prompt Learning for Vision-Language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":334,"t":"CLIP 같은 모델이 visual 과 langauge 간의 Contrastive learning 을 통해 훌륭한 tranasfer learning 을 보이고, 추론 과정에 proper prompt (text description) 형태가 필요해졌다. 후속으로, 힘든 prompt engineering 을 피하기 위해 CoOp, CLIP-Adapter 및 Tip-Adapter 같은 연구들은 downstream image recognition task 에 few-shot, zer-shot learning 으로 잘 일반화시키기 위해서 vision-language model (VLM)을 채택하였다. 본 논문은 다른 시나리오에 대해 탐구한다. target 데이터를 제공하지 않는, CLIP-like VLM 의 transfer 성능을 향상하는 동시에 prompt engineering 을 피하는 approach 인 Unsupervised Prompt Learning (UPL) 을 제안한다. unsupervised learning 을 prompt learning 에 도입한 것은 이 논문이 처음이며, 실험적으로도 UPL 은 CLIP 과 prompt engineering 측면에서 ImageNet 이나 다른 데이터셋에서 좋은 성능을 보였다. 향상된 버전의 UPL 은 8-shot CoOp 이나 8-shot TIP-Adapter 와 경쟁력 있었다. 코드는 https://github.com/tonyhuang2022/UPL 에서 확인하자.","s":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":336,"t":"최근, CLIP 및 FLIP 은 기존 visual framework 와 달리, 대규모의 image-text pair 데이터를 두 개의 아키텍처 image encoder 와 text encoder 를 공유된 임베딩 공간에서 align 하도록 훈련한다. downstream task 에 최적화하도록 transfer 하기 위해, 알맞은 텍스트 설명인 prompt 가 필요한데, Figure 1a 처럼 CLIP 에서는 \"a photo of a [CLS]\" 형태의 prompt 템플릿을 사용했다. 하지만 proper prompt 를 식별하는 것은 쉽지 않아, domain knowledge 와 힘든 prompt engineering 이 필요하다. hand-crafted prompt 를 피하고 transfer 성능을 올리기 위해, supervised 방법으로는 CoOp, CLIP-Adapter 및 Tip-Adapter 가 있으며 downstream image recognition task 를 위해 LLM 을 사용하여 target dataset 의 적은 셋을 사용한다 (Figure 1b). CoOp 은 hand-crafted prompt 를 continuous prompt representation 으로 교체 CLIP-Adapter 는 정제된 feature 를 학습하기 위해 추가적인 네트워크 사용 TIP-Adatper 는 few-shot supervision 으로 query-key cache 모델을 구성하여 CLIP-Adapter 확장 위 방법들은 annotated sample 이 필요하므로 모델 확장에 한계가 있다. 저자는 다른 설정을 탐구하며, 이는 target dataset 을 제공하지 않고 UPL 로, downstream image recognition task 에 대한 VLM 을 효과적으로 사용하면서도 prompt engineering 을 피하는 것이다 (Figure 1c). UPL 은 CLIP 을 활용하여 target image 에 대한 pseudo label 을 생성하고, 샘플된 pseudo label 에서 learnable prompt representation 을 최적화하는 것으로 self-training 과정을 수행한다. 그리고 hand-crafted prompt 를 최적화된 prompt representation 으로 바꾸는 것으로 CLIP 의 성능을 향상시킬 수 있다. threshold 기반 self-training 과 대조적으로, 저자는 다음의 관찰된 사항들에 따른 self-training 을 위해 각 class 에서 샘플링된 것을 top-KKK 로 택한다. VLM 은 서로 다른 클래스에 편향된 성능을 가지며, 불확실한 샘플링을 걸러내기 위해 threshold 를 사용하는 것은 불균형한 pseudo label 데이터 분포를 초래함 confidence score 와 pseudo label 정확도 간의 상관관계가 없어, noisy pseudo label 을 동시에 도입할 수 있지만, 실험적으로 모든 클래스에 동일한 prompt representation 을 사용하기 때문에 nosity 가 robust 하다는 것을 발견함. CLIP 에서 제안한 prompt 앙상블 전력에 영감을 받아, pseudo label 앙상블과 prompt representation 앙상블을 도입하여 저자의 방법론을 더 강화하였다. 다음 세 가지 contribution 으로 요약할 수 있다. prompt engineering 을 피하고 VLM 활용을 위해 UPL 을 제안하며, VLM 에 unsupervised learning 을 prompt learning 에 도입한 첫 연구 pseudo-labeling 에 대한 CLIP 의 특성을 분석하여, top-KKK 전략을 사용하며, transfer 성능 향상을 위해 prompt representation 앙상블을 시도 10 가지 image classification task 데이터셋에서 CLIP 의 promnpt engineering 보다 성능이 좋으며, 8-shot CoOp 및 8-shot TIP-Adapter 보다 대부분의 데이터셋에서 성능이 우수했음","s":"Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":339,"t":"VLM 은 대규모의 iamge-text 쌍을 학습하여 visual representation learning 에 대한 큰 잠재력을 입증했다. CLIP : 4 억개 데이터셋 수집 ALIGN : 18억개 noisy image-text 쌍 이용 FLIP : vision-language pretraining 의 fine-grained 를 위해 3 억개의 수집 Wukong : 서로 다른 multi-modal pre-training 의 벤치마킹에 대한 1 억개 데이터 포함 Florence : FLD-900M 라는 9 억개의 image-text 쌍 데이터셋 포함 위 VLM 은 vision encoder, text encoder 두 아키텍처로 다음을 활용 vision encoder : ResNet, ViT 또는 Swin Transformer text encoder : Standard Transformers image 와 text 를 embedding space 에서 align 하기 위해 contrastive learning 을 채택함. representation framework CLIP 은 object detection, semantic segmentation, action recognition, video caption 및 3D recogmnition 등에 채택되어 왔다.","s":"Vision-language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#vision-language-models","p":331},{"i":341,"t":"Pretrained VLM class embedding 생성을 위해 prompt (예; \"a photo of a [CLS]\") 를 사용한다. proper prompt 식별 및 prompt engineering 이 힘드므로 NLP 의 prompt learning 에 영감을 받아, CoOp : continuous prompt optimization 전략을 제안하여 prompt design 을 피한다. CLIP-Adapter : 추가적인 adapter network 를 사용하여 text feature 와 image feature 를 새로운 embedding 공간에서 매핑하여, 더 좋은 target dataset 을 채택하게 된다. Tip-Adapter : key-query cache 모델의 weight 를 만들어 CLIP-Adapter 를 확장한다. 하지만 위 방법들은 few-shot labeled data 에 의존하며, 모델 용량을 스케일링하는데 한계가 있는 반면, UPL 은 VLM 의 trnasfer 성능을 향상시키면서도 annotation target dataset 을 필요로 하지 않는다.","s":"Prompt Learning","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-learning","p":331},{"i":343,"t":"Self-training 은 간단한 semi-supervised learning 접근법이다. 잘 학습된 모델로 unlabaled dataset 에서 pseudo label 을 생성한 후 labeled data 와 pseudo-labeld data 를 사용하여 finetuning 한다. 최근, self-training 은 image classification, object detection, semantic segmentation, speech recognition, action recognition 및 machine traslation 분야의 딥러닝에 큰 진보를 보여주고 있다. VLM 은보통 대규모 image-text 쌍에 pretraining 하며 prompting 으로 좋은 성능을 보여준다. 저자는 UPL 을 제안하여 target dataset 에 대한 pseudo label 을 생성하며 self-training 으로 continuous prompt representation 를 최적화한다. 기존의 self-training 은 네트워크의 모든 layer 를 finetuning 하는 반면, UPL 은 네트워크를 고정하여 유지하면서도 (image, text encoder) continuous prompt representation 을 최적화 한다.","s":"Self-training","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#self-training","p":331},{"i":345,"t":"UPL 을 도입하며 transfer 성능을 향상시키며 prompt engineering 을 피한다. 기존 supervised 방법과 달리, target dataset 의 annotation 을 필요하지 않는다. UPL 의 overview target image 에 대한 pseudo label 생성 self-training 을 통해 prompt representation 최적화","s":"Method","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":347,"t":"Figure 2 에서 전체 개요를 보여 준다. UPL 은 pseudo label generation 과 prompt representation optimization 두 모듈을 포함한다. pretrained VLM (예; CLIP) 을 활용하여 target dataset 에서 unlabeled image 의 pseudo label 을 생성한다. 이는 다음의 두 가지 관찰을 기반으로 한다. pseudo label 정확도와 confidence score 간의 상관관계가 낮음 VLM 은 각각의 클래스에 편향된 정확도를 가지므로, 각 클래스에 확실한 샘플링을 위해 top-KKK 를 택한다. 이는 threshold 보다 confidence score 가 더 높다. CoOp 에서 영감을 얻어 learnable prompt representation 를 정의 prompt representation 은 모든 카테고리에 교차로 공유되며 생성된 pseudo-label 와 선택된 unlabeled sample 을 최적화한다. 추론 단계에서, hand-crafted prompt 를 최적화된 prompt representation 으로 교체하여 CLIP 의 inference pipeline 을 따름","s":"Overview of UPL","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#overview-of-upl","p":331},{"i":350,"t":"저자는 CLIP 의 inference 에 대해 다시 다루었으며, CCC class 를 포함한 target dataset 이 주어지면, CLIP 은 \"a photo of a [CLS]\" 와 같은 prompt 를 소문자의 byte pair encoding (BPE) representation 으로 변환한다. 여기서 각 카테고리에 대한 class embedding 을 생성시키기 위해 CLIP 의 text encoder 를 지난다. 저자는 클래스 임베딩의 집합을 {fctext}c=1C\\{ f^{text}_c \\}^C_{c=1}{fctext​}c=1C​ 로 표기하며, 여기서 fctextf^{text}_cfctext​ 는 ccc-th 카테고리의 클래스 임베딩을 나타낸다. 이미지 III 의 경우, CLIP 의 image encoder 로 추출한 visual feature 를 fimagef^{image}fimage 로 표기한다. 클래스 ccc 가 될 확률은 다음과 같이 계산한다. pc=exp⁡(<fctext,fimage>/τ)∑j=1Cexp⁡(<fjtext,fimage>/τ)(1)p_c = \\frac{ \\exp (< f^{text}_c , f^{image} > / \\tau ) }{ \\sum^C_{j=1} \\exp (< f^{text}_j, f^{image} > / \\tau ) } \\tag{1}pc​=∑j=1C​exp(<fjtext​,fimage>/τ)exp(<fctext​,fimage>/τ)​(1) 여기서 τ\\tauτ 는 CLIP 에서 학습된 temperature parameter 이며, <⋅,⋅>< \\cdot, \\cdot ><⋅,⋅> 은 cosine similarity 이다. 이제 prediction y^\\hat{y}y^​ 를 쉽게 구할 수 있다. y^=arg max⁡c pc(2)\\hat{y} = \\underset{c}{\\argmax} \\ p_c \\tag{2}y^​=cargmax​ pc​(2)","s":"Inference of CLIP","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#inference-of-clip","p":331},{"i":352,"t":"pretrained CLIP 으로 식 1, 식 2 를 사용하여 target dataset 으로부터 unlabeled sample 에 대한 pseudo 를 생성할 수 있다. Self-training 과 semi-supervised learning 은 threshold 보다 score 가 높은 confident sample 을 유지하지만, 이를 CLIP 에 바로 적용시키기 힘들다. 이는 두 가지 이유가 있다. CLIP 은 downstream image recognition task 에 transfer 할 때 서로 다른 클래스에 대한 편향된 성능을 보인다. 이는 pretraining dataset 과 target dataset 간의 domain 차이 때문이다. 이 현상은 Figure 3 에서 확인할 수 있다. pseudo-labaled data 의 임밸런스 분포에서 unconfident sample 을 필터링하기 위해 고정된 threshold 를 사용하면 최적화가 저해된다. Self-training 은 condidence (probability) 가 pseudo label 의 퀄리티를 잘 반영할 것으로 예상한다. 따라서 threshold (예; 0.9) 는 하이 퀄리티 샘플을 선택하기 위해 사용될 수 있지만, CLIP 에서 confidence score 와 pseudo label 정확도 간의 상관관계가 비교적 약하다는 것을 관찰하였으며 이는 Figure 4 에서 확인할 수 있다. 그러므로 저자는 최적화를 위해 식 1, 2 를 사용하여 confident sample 을 top-KKK 선택을 지지한다. 이는 대규모의 샘플들이 훈련 중 overwhelm 되는 것을 예방한다. 이는 대규모의 샘플들이 훈련 중에 overwhelm 되는 것을 예방하며, 저자는 K=16K = 16K=16 으로 설정한다.","s":"Pseudo Label Generation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-generation-1","p":331},{"i":354,"t":"CLIP 은 다음의 visual model 을 포함한다. ResNet-50, ResNet-101, ResNet50x4, ResNet-50x16, ResNet-50x64 ViT-B/32, ViT-B/16, ViT-L/14 저자는 CLIP 의 여러 아키텍처가 Figure 5 처럼 클래스에 편향된 정확도를 가지는 것을 관찰했다. 이 결과를 바탕으로, pseudo label 의 퀄리티를 향상시키기 위해 간단한 pseudo label ensemble 전략을 제안한다. 특히, 다양한 아키텍처의 CLIP model MMM 이 주어지면, 식 1 을 활용하여 mmm-th CLIP model 로 예측된 pimp^m_ipim​ 확률을 얻는다. 그리고 간단하게 pˉi=∑m=1MpiM/M\\bar{p}_i = \\sum^M_{m=1}p^M_i / Mpˉ​i​=∑m=1M​piM​/M 으로 평균화하여 pˉi\\bar{p}_ipˉ​i​ 확률을 얻을 수 있다. 그 후, 향상된 pseudo label 을 생성하기 위해 pˉi\\bar{p}_ipˉ​i​ 에 식 2 를 적용한다. 위 과정이 끝나면, unsupervised prompt representation 최적화를 위해 pseudo-labeled data 를 사용한다.","s":"Pseudo Label Ensemble","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-ensemble","p":331},{"i":356,"t":"기존의 CLIP 에선 transfer learning 을 위해 \"a photo of a [CLS]\" 처럼 다양한 prompt 템플릿을 정의했는데, proper prompt 를 식별하는 것은 domain knowledge 와 prompt engineering 이 요구되어 힘든 작업이다. 그리고 prompt 에 약간의 변화만 있어도 성능이 크게 변한다. CoOp 은 hand-crafted prompt 를 피하기 위해 적은 labeled data 에서 continuous prompt representation 를 최적화하였다. UPL 은 CoOp 과 비슷하지만, target dataset 에서 어떠한 annotation 도 요구하지 않는다.","s":"Prompt Representation Optimization","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-representation-optimization","p":331},{"i":358,"t":"목표는 CLIP 의 transfer 성능 향상을 위해 pseudo-labeled data 에 prompt representation 을 학습하는 것이다. learnable prompt representation 을 V∈RD×LV \\in \\mathcal{R}^{D \\times L}V∈RD×L 로 표기하며, DDD 는 word embedding 의 차원 (CLIP 의 경우 512), LLL 은 hypter-parameter 를 표기하는 것으로 default 는 16 이다. CCC classes 를 포함하는 target dataset 이 주어지면, class ccc (1≤c≤C1 \\leq c \\leq C1≤c≤C) 에 대한 continuous prompt Vc∈RD×(L+1)V_c \\in \\mathcal{R}^{D \\times (L + 1)}Vc​∈RD×(L+1) 를 정의한다. Vc=[V,wc],(3)V_c = [V, w_c], \\tag{3}Vc​=[V,wc​],(3) wc∈RDw_c \\in \\mathcal{R}^Dwc​∈RD 는 class ccc 의 fixed word embedding 이다. identical prompt representation VVV 는 모든 클래스에 공유된다. 훈련 과정은 Figure 2 (right part) 에서 보여준다. 각각의 pseudo labeled image 의 경우, 저자는 image 을 CLIP 의 vision encoder 를 지나 visual feature fimagef^{image}fimage 를 추출한다. {Vc}c=1C\\{ V_c \\}^C_{c=1}{Vc​}c=1C​ 는 CLIP 의 text encoder g(⋅)g( \\cdot )g(⋅) 을 지나 class embedding 을 얻는다. ccc-th class 의 확률은 다음과 같이 계산할 수 있다. pc=exp⁡(<g(Vc),fimage>/τ)∑j=1Cexp⁡(<g(Vj),fimage>/τ)(4)p_c = \\frac{ \\exp (< g(V_c), f^{image} > / \\tau) }{ \\sum^C_{j=1} \\exp (< g(V_j), f^{image} > / \\tau) } \\tag{4}pc​=∑j=1C​exp(<g(Vj​),fimage>/τ)exp(<g(Vc​),fimage>/τ)​(4) 여기서 τ\\tauτ 는 temperature parameter 이다. training image 의 경우, 식 4 를 이용하여 모든 클래스의 확률을 계산하고 pseudo label 로 cross-entropy loss 를 최소화한다. gradient 는 text encoder g(⋅)g( \\cdot )g(⋅) 을 통해 back-propagate 하여 text encoder 의 풍부한 knowledge 를 이용한다. 마지막으로, learnable prompt representation VVV 를 업데이트 한다. 여기서 image encoder 와 text encoder 는 훈련 중에는 weight 가 변하지 않는다는 것을 알야야 한다.","s":"Learnable Prompt Representation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#learnable-prompt-representation","p":331},{"i":360,"t":"prompt representation VVV 의 최적화가 끝나고, target dataset 이 주어지면, {Vc}c=1C\\{ V_c \\}^C_{c=1}{Vc​}c=1C​ 를 CLIP 의 text encoder 를 지나 모든 클래스에 대한 class embedding 을 얻는다. test image 의 경우, 이미지를 CLIP 의 image encoder 를 지나 visual feature 를 추출하고 식 4를 적용하여 image recongnition 을 위한 확률값을 계산한다.","s":"Inference","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#inference","p":331},{"i":362,"t":"기존 CLIP 은 transfer 성능 향상을 위해 다양한 prompt 를 정의하였으며, 이는 저자의 approach 에서 다양한 초기화로 multi prompt representation 학습에 영감을 주었다. 정확히는, NNN 개의 random 하게 초기화된 prompt representation 을 각각 독립적으로 최적화한다. inference 단계에서, 모든 prompt representation 의 예측 확률 값을 계산하고 평균화하여 최종 예측 확률값을 만든다.","s":"Prompt Representation Ensemble","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-representation-ensemble","p":331},{"i":366,"t":"ResNet-50 이 있는 CLIP 을 베이스라인으로 UPL 에 적용한다. 결과는 Figure 5 에서 볼 수 있다. CLIP 의 여러 vision encoder 는 다양한 카테고리에 대한 성능을 가지고 있어, pseudo label 의 퀄리티를 향상시키기 위해 저자는 ResNet-101, ResNet50x4, ResNet50x16, ResNet50x64, ViT-B/32, ViT-B/16 및 ViT-L/14 를 포함하는 다양한 vision 아키텍처의 추가적인 CLIP 모델을 사용한 UPL* 이라는 향상된 버전을 정의했다. Pseudo label 에만 다양한 비전 아키텍처를 사용했기 때문에 UPL* 은 여전히 UPL 과 같은 아키텍처 (CLIP with ResNet-50)을 사용한다.","s":"Vision-language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#vision-language-models-1","p":331},{"i":368,"t":"CLIP 에선 ImageNet 에 대해 80 개의 hand-crafted prompt 로 inference 를 설계한다. CLIP 으로 pseudo label 생성된 모든 prompt 를 수반하면 prompt engineering 을 피하는 것이 불리해진다. 따라서, 가장 간단한 prompt 를 사용하여 pseudo label 을 생성한다. 예로, ImageNet 에선 \"a photo of a [CLS]\" prompt 를 사용한다. 그리고 클래스 당 top-16 confident sample 을 하여 prompt representation 을 최적화한다.","s":"Pseudo Label Generation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-generation-2","p":331},{"i":370,"t":"prompt representation 은 zero-mean 가우시안분포와 0.02 표준 편차로 무작위 초기화한다. 식 3 에서 length L=16L = 16L=16 을 설정한다. 그리고 16 개 prompt representation 을 앙상블한다.","s":"Learnable Prompt Representation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#learnable-prompt-representation-1","p":331},{"i":372,"t":"SGD lr 0.002 cosine decay learning rate schedular 50 epoch 32 batch size warm up in the first epoch with lr 1e-5","s":"Training Details","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#training-details","p":331},{"i":374,"t":"11 개의 image classification dataset ImageNet Caltech101 DTD EuroSAT FGVCAircraft Food101 Flowers102 OxfordPets SUN397 StandfordCars UCF101","s":"Dataset","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#dataset","p":331},{"i":376,"t":"11 데이터셋에 대한 결과는 위 테이블 1 에서 확인할 수 있다. 저자의 approach 와 다른 모델들을 비교한다. 기존 CLIP 의 prompt engineering supervised method (CoOp, Tip-Adapter) UPL 은 prompt engineering 을 피할 뿐만 아니라 CLIP 보다 4.2 point 성능이 더 좋았다. ResNet-50 의 single CLIP 을 사용하면서 pseudo-labeling 에서 여러 CLIP 모델을 사용하여 정확도를 68.37 로 boost 하였다. 또한 8-shot 의 CoOp 이나 Tip-Adapter 와 경쟁력있는 성능을 보인다.","s":"Main Results","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":378,"t":"처음으로 unsupervised prompt learning UPL 을 도입하여 prompt engineering 을 피하며 CLIP 의 transfer 성능을 끌어올린다. CoOp, CLIP-adapter 및 TIP-Adapter 같은 supervised approach 보다 좋은 성능을 가진다.","s":"Conclusion","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":331},{"i":380,"t":"논문 및 이미지 출처 : https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf","s":"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":382,"t":"chain-of-thought 로 intermediate reasoning step 의 series 를 생성하여 LLM 의 complex reasoning 능력을 크게 향상하는 방법 탐구 chain-of-thought prompting 이란 간단한 방법을 통해 reasoning 능력이 자연스럽게 나타나는 것을 보임 3개의 LLM 에 실험 arithmetic, commonsense 및 symbolic reasoning task 에 성능 향상 empirical gain 이 현저할 수 있음 8개의 CoT exemplar 로 PaLM 540B 를 prompting 할 경우, math word problem 의 GSM8K 벤치마크에서 SOTA 달성 -> finetuned GPT-3 능가","s":"Abstract","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":384,"t":"최근, LM 의 크기 확장이 성능 및 샘플 효율성이 향상되는 여러 이점을 준다는 사실을 입증 하지만, 크기 확장만으론 arithmetic, commonsense 및 symbolic reasoning 같은 어려운 task 에서 높은 성능은 부족 본 논문은 두 가지 아이디어에 기반한 방법으로 LLM 의 reasoning 능력을 탐구 arithmetic reasoning 기술은 final answer 로 이어지는 근거를 생성하여 이득을 얻을 수 있음 처음부터 훈련 또는 pretrained model 을 finetuning 하여 intermediate steps 에 자연어 생성 능력 부여 언어 대신 neuro-symbolic 방법도 존재 LLM 은 prompting 을 통해 in-context few-shot learning 의 흥미로운 가능성 제공 new task 마다 별도의 LM checkpoint 를 finetuning 하는 대신, few input-output exemplar 를 사용하여 간단한 \"prompt\" 가능 위 두 아이디어는 각각 주요 제한 사항 존재 rationale-augmented training 및 finetuning 의 경우 고품질의 근거셋을 생성하는 것은 간단한 input-output 보다 훨씬 복잡하며 비용이 큼 few-shot prompting 의 경우, 추론 능력을 필요로하는 작업에 대해 성능이 나쁘고 모델 크기가 증가함에 따라 크게 향상되지 않음 구체적으로 <input, chain of thought, output> 세 가지를 포함한 few-shot prompting 의 reasoning task 의 수행 능력을 탐구 approach : chain-of-thought prompting 저자의 접근법은 arithmetic, commonsense 및 symbolic reasoning 벤치마크에 평가하여 standard prompting 을 능가 math word problem 인 GSM8K 의 경우, CoT 를 사용한 PaLM 540B 이 standard prompting 을 큰 폭으로 능가하여 SOTA 달성 prompt-only approach 는 대규모 훈련셋을 필요로 하지 않으며 single model checkpoint 가 일반성을 잃지 않고 많은 task 를 수행하므로 이 또한 중요한 특성이지만 본 논문은 어떻게 LLM 이 few examples 로 task 를 학습할 수 있는지 관한 연구인지 강조한다.","s":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":386,"t":"복잡한 추론 task 인 multi-step math word problem 을 고려해보자. 일반적으로 문제를 intermediate steps 로 분해하고 각각 해결 후 final answer 를 제시한다. 저자는 충분히 큰 언어 모델이 CoT 의 few-shot prompting exemplar 가 제공되면 CoT 를 생성할 수 있다는 것을 보여준다. (Fig 1 참고) CoT 는 multi-step 을 intermediate step 으로 분해할 수 있으며, 더 많은 추론 단계가 필요한 문제에 추가적인 계산 할당 CoT 는 모델의 동작을 해석 가능하게 하여 답변에 도달하는 방식을 시사 및 잘못된 추론 경로를 찾는 기회 제공 CoT 추론은 arithmetic, commonsense 및 symbolic reasoning 같은 task 에 사용 가능 CoT 추론은 CoT 에 few-shot prompting 예제로 간단히 포함하여 off-the-shelf LM 에 쉽게 유도 가능","s":"2. Chain-of-Thought Prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":388,"t":"LM 의 arithmetic reasoning 능력을 측정 540B parameter LM 에 CoT prompting 을 사용하여 여러 task 에서, task-specific finetuning 모델들과 비교 (GSM8K 에서 SOTA)","s":"3. Arithmetic Reasoning","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":391,"t":"GSM8K : math word problems SVAMP : 다양한 구조의 math word problems ASDiv : 다양한 math word problems AQuA : algebraic word problems MAWPS : algebraic word problems","s":"Benchmarks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#benchmarks","p":379},{"i":393,"t":"Fig 1 의 왼쪽. input-output pair 의 in-context 예제에 맞춘 standard few-shot prompting","s":"Standard prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#standard-prompting","p":379},{"i":395,"t":"저자의 approach : few-shot prompting 의 각 exemplars 와 관련된 답변에 CoT 로 보강하는 것 기존 데이터셋은 evaluation 으로만 분리되어, 저자는 8개의 few-shot exemplars 를 직접 작성 Fig 1 오른쪽. CoT exemplar, AQUA 를 제외한 벤치마크는 각각 8개 CoT 를 사용. AQuA 는 mutiple choice 형태이므로 4개의 exemplar 와 solution 을 사용","s":"Chain-of-thought prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#chain-of-thought-prompting","p":379},{"i":397,"t":"5가지 LLM 평가 GPT-3 (350M, 1.3B, 6.7B, 175B) LaMDA (422M, 2B, 8B, 68B, 137B) PaLM (8B, 62B, 540B) UL2 (20B) Codex 각 모델은 greedy decoding 으로 샘플링 LaMDA 의 경우, 각 seed 가 서로 다른 무작위로 섞인 exemplar 순서를 가진 5개의 seed 에서 평균 : 다른 seed 간의 큰 분산이 보이지 않아 연산량을 줄이기 위해 single exemplar 사용","s":"Language models","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#language-models","p":379},{"i":399,"t":"CoT prompting 은 model scale 의 새로운 능력 작은 모델 대신, 약 100B 정도의 모델과 함께 사용할 때만 성능 향상 작은 모델에선 유창하지만 논리적으로 부적절한 CoT 생성 CoT prompting 은 더 복잡한 문제에서 더 큰 성능 향상 GSM8K (baseline 성능이 가장 낮은 데이터셋)에서, GPT 및 PaLM 같은 LLM 에서 성능이 두 배 이상 향상 해결을 위한 단계가 하나만 필요한 MAWPS 의 경우, 성능 향상이 부정적이거나 매우 작음 LLM 을 통한 CoT prompting 은 task-specific model 을 finetuning 한 것과 비교 PaLM 540B 에 CoT 를 사용하여 여러 task 에 SOTA 달성 CoT prompting 의 동작을 더 잘 이해하기 위해 GSM8K 에 대한 LaMDA 137B 에서 생성한 CoT 를 수동으로 검토 50개 무작위 예제를 생성한 CoT 는 2개를 제외하고 모두 논리적 및 수학적으로 올바른 것을 나타냄 또한 모델이 잘못된 답변을 반환한 50개의 무작위 예제도 조사 PaLM 62B 에서 발행한 오류가 PaLM 540B 에서도 발생하는 지 조사. 62B 의 one step 누락 및 의미 이해 오류의 큰 부분이 수정","s":"3.2. Results","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#32-results","p":379},{"i":401,"t":"CoT prompting 의 이점이 다른 유형의 prompting 으로도 얻을 수 있는지, ablation 연구 진행","s":"3.3. Ablation Study","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#33-ablation-study","p":379},{"i":403,"t":"CoT prompting 이 도움되는 이유 중 하나는 평가에 수학적 수식을 생성하기 때문. 그래서 답변 제공 전 수학적 수식만 유도하여 테스트. Fig 5 를 보면 equation only prompting 은 GSM8K 에 큰 도움이 되지 않는 것을 확인 의미론이 CoT 의 추론 단계에 직접 수식으로 번역하기 어렵기 때문 one-step / two-step problem dataset 의 경우, 질문에서 수식을 도출할 수 있어 equation only prompting 이 도움이 됨","s":"Equation only","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#equation-only","p":379},{"i":405,"t":"CoT model 이 어려운 문제에 더 많은 계산 (i.e. intermediate tokens)을 사용하도록 허용하는 것 → 변수 계산의 영향을 CoT 의 이론적 추론과 격리하여, 문제 해결에 필요한 수식의 문자 수와 동일한 점(.) 개수만을 출력하도록 유도 baseline 과 비슷한 성능을 보이며, variable compute only 만으로는 CoT 의 성공 원인이 아니며, intermediate steps 로 표현하는 데 유용성이 있는 것으로 보임","s":"Variable compute only","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#variable-compute-only","p":379},{"i":407,"t":"CoT prompting 의 다른 잠재적 이점은 pre-training 중 얻은 지식을 더 잘 활용한다는 것. → 답변 이후에만 CoT prompting 을 제공하는 설정으로 테스트 위 설정으로 모델이 최종 답변을 내기 위해 CoT 에 의존하는 것을 격리함 이는 baseline 과 비슷한 성능을 보이며, CoT 내의 순차적 추론이 knowledge 활성화 이상으로 유용하다는 것 시사","s":"Chain of thought after answer","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#chain-of-thought-after-answer","p":379},{"i":409,"t":"서로 다른 annotators 가 작성한 CoT 에 대한 Robustness 를 평가 CoT prompting 을 위해 동일한 few-shot exemplars 에 annotator A, B 및 C 등 독립적으로 CoT 작성. A 는 원래 CoT 보다 더 간결히 CoT 를 작성 ([Training Verifiers to Solve Math Word Problems] 의 설정을 따른 것) Fig 6 은 LaMDA 137B 의 GSM8K 및 MAWPS 결과 다양한 CoT annotators 사이에 분산이 있지만, baseline 보다 높은 성능 CoT 의 성공적인 사용이 특정 스타일에 의존하지 않음을 시사 CoT prompting 이 다양한 exemplars 에도 잘 작동하는지 확인을 위해 GSM8K 훈련셋에 8개 샘플 3 셋에 실험 Fig 6 은 CoT prompting 이 수동으로 작성한 exemplar 와 비슷한 결과를 보여줌 standard prompting 보다 훨씬 높은 성능 annotator, 독립적으로 작성된 CoT, 다양한 LM 에 대한 robustness 외에도, arithmetic reasoning 을 위한 CoT prompting 이 다른 exemplars 에 대해서도 robust 하다는 것을 발견","s":"3.4. Robustness of Chain of Thought","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#34-robustness-of-chain-of-thought","p":379},{"i":412,"t":"CSQA 사전 지식이 필요한 복잡한 의미를 가진 상식적 질문 StrategyQA multi-hop 전략 추론을 요구 BIG-bench 의 두 가지 특정 평가셋 Date Understanding : 주어진 문맥으로 날짜 추론 Sports Understanding : 스포츠 관련 문장이 타당한지 불가능한지 판단 SayCan 로봇 동작 순서로 매핑","s":"Benchmarks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#benchmarks-1","p":379},{"i":414,"t":"CSQA 및 StrategyQA 경우 무작위 예제를 선택하고 few-shot CoT example 을 사용하기 위해 수동으로 구성 BIG-bench task 두 개의 경우 훈련셋이 없어, 10개 예제를 few-shot CoT example 로 선택 SayCan 경우 훈련셋에서 6개 example 을 사용하고 수동으로 CoT 구성","s":"Prompts","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#prompts","p":379},{"i":416,"t":"모든 task 에 대해, 모델 크기를 스케일 업하면 standard prompting 성능 향상되지만 CoT prompting 은 더 큰 향상을 이끌어 냄 (특히 PaLM 540B) 위 결과로 CoT prompting 이 상식적 추론 능력의 다양한 범위를 필요로 하는 task 에 대해서도 성능 향상을 시킬 수 있음을 시사","s":"Results","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#results","p":379},{"i":418,"t":"CoT prompting 이 challenging symbolic reasoning 을 수행할 뿐만 아니라, 미리 본 적 없는 입력에 대한 추론에도 일반화하는데 용이한 다는 것을 보여줌","s":"5. Symbolic Reasoning","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":420,"t":"다음 두 toy task 를 사용","s":"Tasks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#tasks","p":379},{"i":422,"t":"모델에게 이름에서 단어의 마지막 글자를 연결하도록 요청하는 task. (e.g. \"Amy Brown\" → \"yn\") 첫 글자 연결보다 어려운 버전 인구 조사 데이터 (https://namecensus.com/) 에서 상위 1000개 이름을 임의로 연결하여 전체 이름 생성","s":"Last letter concatenation","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#last-letter-concatenation","p":379},{"i":424,"t":"모델에게 동전을 던지거나 던지지 않은 후에도 동전이 여전히 앞면인지 아닌지 대답 요청. (e.g. \"동전이 앞면입니다. Phoebe 가 동전을 던졌습니다. Osvaldo 가 동전을 동전을 던지지 않았습니다. 동전은 여전히 앞면입니까?\" → \"아니오\") last letter concatenation 의 경우, 모델이 2개 단어로된 이름만 보고, 3개 및 4개 단어의 이름에 대해 수행한다. 이는 Coin flip 에서도 동일한 방식을 적용한다. (Fig 3 참고) Fig 8 결과, PaLM 540B 의 CoT prompting 은 거의 100% 해결. 적은 수의 CoT exemplar 로 완벽한 solution structure 가 제공되어 \"toy task\" 라 부름 Out-of-Domain (OOD) 에서는 standard prompting 이 두 task 모두에서 실패. 하지만 CoT 는 상승하는 curves 를 보이며, 충분한 규모의 LM 에서의 CoT prompting 은 일반화에 용이함을 시사","s":"Coin flip","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#coin-flip","p":379},{"i":426,"t":"저자는 multi-step 을 유도하는 간단한 메커니즘인 CoT prompting 을 탐구 arithmetic reasoning 에서 큰 폭의 성능 향상 다양한 annotators, exemplar, LM 에 robust 한 개선 commonsense 실험에서, CoT reasoning 의 특성이 일반적으로 적용되는 것 강조 symbolic 실험에서, OOD 일반화를 긴 시퀀스로 용이하게 하는 것 보여줌 model scaling 결과 standard prompting 은 flat scaling curves 를 갖는 reasoning task 에서, CoT prompting 은 upward scaling curves CoT prompting 은 LLM 이 잘 수행할 수 있는 task 범위를 확장 여전히 많은 의문점이 존재 CoT 는 실제로 \"reasoning\" 을 하는지? few-shot exemplar 에 CoT 수동 추가의 비용은 미미하지만, finetuning 의 비용은 매우 클 수 있음 올바른 reasoning path 를 보장할 수 없어, 올바른 답변/부정확한 답변 모두 발생 가능 LLM 에서만 CoT reasoning 이 발생하여, 실제 응용에서는 비용이 클 수 있음 → 작은 모델에서도 CoT 를 유도하는 연구 필요","s":"6. Discussion","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":428,"t":"이 연구는 가장 관련성 높은 두 가지 방향의 논문에서 영감을 받음 reasoning 해결을 위해 intermediate step 을 사용 [Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems] 최종 출력보다 step-by-step 으로 예측하는 것이 성능이 우수 prompting [The power of scale for parameter-efficient prompt tuning] 을 자동으로 학습하거나 지침을 제공하여 prompting 입력을 개선/보완 반면, 저자는 언어 모델의 출력을 CoT 로 보강하는 상반된 방향","s":"7. Related Work","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":430,"t":"CoT prompting 은 LM 에서 reasoning 향상을 간단하고 일반적으로 적용 가능한 방법에 탐구 arithmaric, commonsense 및 symbolic 등으로 CoT reasoning 이 모델 규모에 결과를 보여주며, CoT reasoning 은 충분히 큰 LM 이 reasoning task (다른 이들은 flat scaling curves 를 가짐) 에서 잘 수행하도록 하는 새로운 model scaling 속성을 가지는 것을 발견","s":"8. Conclusions","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":379},{"i":432,"t":"논문 및 이미지 출처 : http://boyangli.org/paper/Jiaxian-CVPR-2023-Img2LLM.pdf","s":"From Images to Textual Prompts: Zero-shot Visual Question Answering with Frozen Large Language Models","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":434,"t":"Large Language Modes (LLMs) 는 새로운 task 에 대한 zero-shot 일반화가 우수하지만 visual question-answering (VQA) zero-shot 에 활용하는데는 어려운 과제가 있다. LLM 과 VQA 간의 modality disconnect 와 task disconnect 때문이며, multimodal data 를 End-to-End 학습을 하여 해소할 수 있지만, 유연함이 없고 계산 비용이 크다. 이를 해결하기 위해 저자는 Img2LLM 를 제안한다. LLM 이 end-to-end 학습 없이 zero-shot VQA task 를 수행할 수 있도록 plug-and-play module 로 LLM prompt 를 제공한다. LLM-agnostic model 을 개발하여 이미지 내용을 exemplar question-answering 쌍으로 설명, 이는 효과적인 LLM prompt 로 입증된다. Img2LLM 은 다음 benefit 을 제공한다. end-to-end training 에 의존한 방법보다 경쟁력있고 성능이 나음. 예로, VQAv2 에서 Flamingo 보다 5.6% 성능이 좋고, A-OKVQA 에서 few-shot 방법으로 최대 20% 까지 성능이 좋다. VQA 수행을 위해 LLM 을 넓은 범위로 유연하게 interface 로 연결 end-to-end finetuning 으로 LLMs 를 specialize 할 필요성을 제거하고 고도의 specialized LLMs 를 사용자에게 제공하여, 비용을 줄인다. 코드는 https://github.com/salesforce/LAVIS/tree/main/projects/img2llm-vqa 에서 확인 가능하다.","s":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":436,"t":"VQA 는 실세계 응용에 중요한 vision-language task 이다. 다양한 VQA 데이터셋이 제안됐으며, 몇몇은 이미지 인식이나 논리적 추론에 초점을 맞추었지만, 인간의 주석을 얻는 것은 비용적으로 비싸고 인간의 편향이 개입할 수도 있다. 이는 VQA 시스템이 새로운 답변 스타일과 질문 유형을 취약하게 만든다. 위 사항들로 인해 연구자들은 ground-truth question-answering annotation 을 필요로 하지 않는 zero-shot VQA 방법을 사용하여, 더 잘 일반화가 가능한 VQA 시스템을 구축하는 추세이다. 최근, LLMs 가 zero in-domain task 를 수행하고 논리적 추론 및 NLP task 의 commonsence knowledge 를 적용하는데 우수한 능력을 입증한다. 그 결과, 최근 approach 는 zero-shot VQA 에서 LLMs 활용한다. 하지만, VQA task 에 LLMs 를 적용하는 건 쉽지 않은데, vision 과 language 사이의 modality disconnect language modeling 과 question answering 사이의 task disconnect 때문이다. 일반으로 vision 과 language representation space 간의 align 을 위해 LLM 과 vision encoder 를 공통적으로 finetuning 하는데, 이는 계산 및 데이터 비용이 크다. 예로, Flamingo 는 수천 개의 TPU 로 수십억 개의 image-text 쌍을 finetuning 하는데 다가, finetuning 에 specialize 되며 vision encoder 와 LLM 사이에 상호의존성이 커진다. 또한 LLM 을 새 버전으로 업그레이드 한다면, 전체 모델을 비용이 큰 재학습을 수행해야 한다. LLM 을 VQA 와 통합하는 end-to-end 대신, 본 논문에선 frozen off-the-shelf LLM 으로 구축한 modular VQA 를 제안한다. 이는 두 가지 이점이 있다. 배치 비용을 줄이고 간단함 LLM 업그레이드가 간단 하지만 end-to-end training 없으면 modality disconnect 와 task disconnect 해결이 힘들다. PICa 는 image 를 caption 으로 변환하여 훈련 데이터에서 예시 QA 쌍을 LLM 에게 prompt 로 제공한다. 하지만 주석된 훈련 데이터가 존재한다는 가정을 전제로 하여, 성능이 few-shot 선택에 민감하다. 이에 저자는 Img2LLM 을 제안한다. 이는 off-the-shelf LLMs 가 zero-shot VQA 을 수행할 수 있도록 하는 plug-and-play module 이다(규격품을 연결만하면 쉽게 사용할 수 있는 모듈). Img2LLM 의 핵심은 vision-language model (예; BLIP) 과 question-generation model 을 활용하여 이미지 내용을 QA 쌍으로 변환하는 것이다. 이러한 예시 QA 쌍은 이미지 내용을 언어로 설명하여 modality connect 를, LLM 에게 QA task 시연하여 task disconnect 를 해결한다. 특히, 예시 QA 쌍은 test image 와 question 을 기반으로 구성되며, PICa 에서 필요한 similar few-shot 예제가 practical zero-shot 시나리오에서 항상 사용 가능하지 않으므로 사전에 제거한다. 오픈 소스인 OPT language model 을 적용했을 때, Img2LLM 은 비용이큰 end-to-end training 을 수행하는 방법들과 비교 가능하거나 우수한 zero-shot VQA 성능을 달성한다. 본 논문의 contribution 은 다음과 같다. 저자는 current image 와 질문을 기반으로 image 를 합성된 QA 쌍으로 변환하는 plug-and-play 모듈인 Img2LLM 을 제안. 이는 visual 과 language 간의 modality disconnect 와 language modeling 과 VQA 간의 task disconnect 를 연결해준다. Img2LLM 은 비용이 큰 end-to-end training 이나 특화된 QA 네트워크 없이 off-the-shelf LLM 이 zero-shot VQA 를 수행할 수 있게 한다. 그래서 낮은 비용과 유연한 모델 배치 및 간편한 LLM 업그레이드가 가능하다. 실험 결과, Img2LLM 이 적용된 OTP 모델이 end-to-end 로 학습된 모델과 비교 가능하거나 우수한 zero-shot VQA 성능을 달성한다. 예로, VQAv2 에서 Flamingo 보다 5.6% 우수하고, 많은 few-shot VQA 방법보다 우수하다.","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":439,"t":"VQA 는 이미지에 따라 자연어 question 에 대답하는 모델을 요구하는 multimodal 평가 벤치마크로 활발한 연구 초점이 되었다. 대규모 image-text pretraining 후 VQA 데이터셋의 finetuning 과 함께 지난 몇년간 빠른 성능 향상이 이루어졌다. knowledge 기반 VQA 해결을 위해 최근 연구는 ConceptNet 이나 Wikipedia 같은 외부 지식을 포함하지만, 이러한 방법들은 복잡한 추론을 필요로 하는 question 에 대한 answer 이 여전히 어려움을 나타낸다.","s":"2.1 Recent Advances in VQA Method","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#21-recent-advances-in-vqa-method","p":431},{"i":441,"t":"LLMs 를 웹 규모의 말뭉치로 학습되어 자연어 이해와 추론에 강하다. task data 추론을 위해, LLMs 는 보통 autoregressively 하게 target token 을 생성한다. 구체적으론 prompt CCC 및 task input xxx 이 주어지면, LLM 은 target token 인 Y={yi}i=1nY = \\{ y_i \\}^n_{i = 1}Y={yi​}i=1n​ 을 생성한다. 여기서 yi=arg⁡max⁡pθ(yi∣y<i,C,x)y_i = \\arg \\max p_{\\theta}(y_i | y_{<i},C,x)yi​=argmaxpθ​(yi​∣y<i​,C,x) 이며 θ\\thetaθ 는 모델 파라미터다. LLM 을 이용한 이전 VQA 방법은 주로 두 가지 범주인 multi-modal pretraining 과 language-mediated VQA 로 나뉜다.","s":"2.2 LLM for Zero/Few-Shot VQA Tasks","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#22-llm-for-zerofew-shot-vqa-tasks","p":431},{"i":443,"t":"이 접근법은 Figure 1(a) 에서 보여주며, 추가적인 alignment module 을 훈련하여 visual 과 language embedding 을 align 한다. LLMs 가 효율적으로 finetuning 하기엔 큰 것을 고려할 때, [Multimodal Few-Shot Learning with Frozen Language Models] 논문에서는 visual encoder 만을 finetuning 하는 것을 택하고, Flamingo 는 cross-modality 상호작용을 모델링하기 위해 추가적인 cross-attention layer 를 훈련한다. 그러나 이 패러다임엔 두 가지 단점이 있다. 계산 비효율적. visual backbone 과 LLM 을 동시에 정렬하기엔 계산 자원이 많이 필요하다. 치명적인 forgetting. align 단계가 LLMs 와 visual model 이 함께 훈련되면, LLMs 의 추론 능력에 해가 될 수 있다.","s":"Multi-modal pretraining","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#multi-modal-pretraining","p":431},{"i":445,"t":"이 패러다임은 벡터화된 representation 대신, intermediate representation 으로 자연어를 사용하며, 비싼 pretraining 을 필요로 하지 않는다. Figure 1(b) 처럼, 현재 이미지를 언어 설명으로 변환한 다음, 설명을 frozen LLM 에 입력한다. few-shot 설정에서 PICa 는 image caption 을 생성하고, in-context exemplar 로 훈련 데이터 샘플을 선택하지만, exemplar 가 제외되면 성능이 크게 저하된다. 동시에 진행되는 zero-shot 방식으로 question 과 관련된 caption 을 생성한다. zero-shot 요구사항 때문에 in-context exemplar 를 제공할 수 없으며, in-context 학습의 이점을 누릴 수 없다. 결과적으로 이 접근법은 고성능 달성을 위해 QA 전용 LLM 인 UnifiedQAv2 에 의존한다.","s":"Language-mediated VQA","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#language-mediated-vqa","p":431},{"i":447,"t":"LLM 을 zero-shot VQA 에 효과적으로 활용하는데 주요 두 장애물이 있다. modality disconnection : LLMs 은 이미지를 처리하지 않으며 visual 정보를 LLMs 이 처리할 수 있도록 인코딩하는 것도 어렵다. task disconnection : LLMs 는 언어 모델링 task 에서 생성적 또는 노이즈 제거 목적으로 pretraining 한다. LLMs 은 QA 이나 VQA task 의 특성을 알지 못하여 answer 를 생성할 때 contextual 정보르 활용하지 못하는 경우가 있다. VQA 에서 modality disconnect 는 이미지를 dense vector 대신 intermediate language description 으로 변환한다. task disconnect 는 few-shot in-context exemplar 나 QA 에 직접 finetuning 된 LLM 을 사용하여 해결해야한다. 이는 zero-shot 설정에 일반적인 LLM 에서 task disconnection 을 어떻게 다룰지 분명하지 않다. 이에 저자는 새로운 zero-shot 기술인, 일반적인 LLM 의 task disconnect 를 해결하기 위해 Img2LLM 을 제안한다. 이는 image 관련 exemplar prompt 를 생성한다. question QQQ 와 image 가 주어지면, 핵심은 current image 의 in-context exemplar 로써 합성된 QA 쌍을 생성할 수 있다. 이러한 exemplar 는 QA task 를 보여줄 뿐만 아니라 이미지 내용을 LLM 에 전달하여 question QQQ 에 대한 answering 생성하는 데도 기여한다. Img2LLM 은 LLM-agnostic 이며, off-the-shelf LLMs 의 지식과 추론 능력을 활용해 zero-shot VQA 에 강력하면서 유연한 솔루션을 제공한다.","s":"3. Method","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":449,"t":"VQA image 에서 in-context learning 을 위해, 이미지 내용을 exemplar 로 통합하기 위해서, 저자는 먼저 합성된 question 에 대한 answering 으로 사용될 수 있는 단어를 찾는다. question 관련 caption 생성 모듈을 사용해 여러 개의 caption 을 생성한다. 최근 논문을 따라, 명사구(고유명사 포함), 동사구, 형용사구, 숫자, '예' 와 '아니오' 같은 부울 타입의 단어를 answer 후보로 추출한다.","s":"3.1 Answer Extraction","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#31-answer-extraction","p":431},{"i":451,"t":"추출된 answer 후보 집합 {a^}j=1U\\{ \\hat{a} \\}^U_{j=1}{a^}j=1U​ 로, 각 answer 후고군에 대한 특정 question 을 생성하기 위해 question generation network 를 직접 사용할 수 있다. 본 논문에서는 template 과 neural 기반의 question-generation 방법에서 실험한다. zero-shot 요구사항을 위반하는 것을 피하기 위해, VQA 데이터에 접근이 없는 순전히 textual 기반으로 한다.","s":"3.2 Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#32-question-generation","p":431},{"i":453,"t":"off-the-shelf parser 를 사용해, 각 answer 의 품사를 얻고, 각 POS 타입의 특정 question 템플릿을 설계한다. 예로, noun answer : \"What object is being taken in this image?\" verb answer : \"What action is being taken in this image?\"","s":"Template-based Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#template-based-question-generation","p":431},{"i":455,"t":"[All You May Need for VQA are Image Captions] 논문에 영감을 받아, textual QA 데이터셋에서 neural question 생성 모델을 훈련시킨다. answer 로 question 을 생성하도록 pretrained T5-large 모델을 finetuning 한다. 모델의 input 은 \"Answer: [answer]\\textup{[answer]}[answer]. Context: [context]\\textup{[context]}[context]\" 을 포함한다. 여기서 textual QA 데이터셋으로부터, [answer]\\textup{[answer]}[answer] 은 answer text 을, [context]\\textup{[context]}[context] 은 context text 를 나타낸다. 추론 중에는, [answer]\\textup{[answer]}[answer] 을 추출된 answer 후보로, [context]\\textup{[context]}[context] 는 해당 추출된 answer 로부터 생성된 caption 으로 교체된다. 모델은 5 가지 textual QA 데이터셋으로 finetuning 한다. SQuAD2.0 MultiRC BookQA CommonsenseQA SocialIQA 위 question 생성 방법으로, 합성된 question-answer 쌍 {q^j,a^j}j=1U\\{ \\hat{q}_j, \\hat{a}_j \\}^U_{j=1}{q^​j​,a^j​}j=1U​ 을 얻는다. 이 쌍을 LLM in-context learning 의 exemplar 로 사용하며, 주어진 이미지 내용으로 QA task 를 수행하도록 가이드하고 language modeling 과 VQA 간의 task disconnect 를 연결해준다. 위 테이블로 exemplar QA 쌍의 효과를 보여준다. 저자는 exemplar QA prompt 가 caption prompt 보다 더 우수함을 관찰했다. 이는 exemplar QA 가 LLM pretraining 과 VQA task 간의 task disconnection 을 연결한다는 효과를 입증한다. 또한, exemplar prompt 가 이미지의 많은 내용을 설명하고 있어, modality disconnection 도 연결하는데 도움이 되며, 이에 caption 을 추가하는 것은 크게 새로운 정보를 제공하지 않으며 성능 향상이 제한적이다.","s":"Neural Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#neural-question-generation","p":431},{"i":457,"t":"합성된 exemplar QA 쌍와 추가적으로, question-relevant image captions 를 LLM 에 제공한다. 저자는 question 이 이미지의 특정 객체나 지역을 묻지만 기존 네트워크로 생성된 일반적인 caption 은 관련 정보를 포함하지 않을 수 있는 것을 관찰했다. 위 Figure 2 에서 , question \"What items are spinning in the blackground which can be used to control electricity?\" 는 wind turbine 에만 관련있다. 그러나 전체 이미지에서 생성된 caption 은 salient orange boat 에 초점을 맞출 가능성이 높으며, LLM 은 question 에 대한 answer 정보가 없게 된다. 이 문제를 해결하기 위해 question 관련 이미지 부분에 대한 caption 을 생성하고, LLM 에게 이 prompt 에 포함시킨다. 이를 위해 저자는 BLIP 의 Image grounded Text Encoder (ITE) 를 사용하여 question 관련된 이미지 영역을 결정한다. ITE 는 image vvv 와 textual question qqq 쌍에 대한 유사도 점수 sim(v,q)\\textup{sim}(v, q)sim(v,q) 을 할당한다. ITE 와 함께 GradCAM 이라는 feature-attribution 해석 기술을 사용하여 주어진 question 과 맞는 image 영역을 강조하는 coarse localisation map 을 생성한다. 간단히 말해, GradCAM 은 Transformer 의 croiss-attention score를 ITE 유사도 함수인 sim(v,q)\\textup{sim}(v, q)sim(v,q) 에 대한 gradient 와 결합하여 계산한다. patch 관령성 rrr 을 얻은 후, 이와 비례하는 확률로 이미지 패치의 하위 집합을 샘플링한다. 그 후, top-k 샘플링으로 샘플링된 image patches 로 caption 을 생성한다. 의미있는 caption 을 생성하기 위해, 짧은 prompt \"a picture of\" 는 text encoder 에 입력한다. MMM 개의 다양한 caption 을 생성하기 위해 이를 MMM 번 반복한다. 그리고 다른 caption 의 정확한 문자열이 아닌 caption 만 유지한다. 하지만, top-k 샘플링은 비결정적인 특성이 있어서, caption model 은 성능에 부정적인 영향을 미치는 노이즈 캡션을 생성할 수도 있다. 노이즈 캡션을 제거하기 위해, ITE 를 사용하여 생성된 캡션과 샘플링된 question 관련 이미지 패치 간의 유사도 점수를 계산한다. 그리고 매칭 점수 0.5 이하인 캡션들을 필터링한다. 위 과정으로, question 과 관련된, 다양한 및 깨끗한 합성 캡션을 얻을 수 있으며, visual 과 language 정보를 연결 역할을 제공한다.","s":"3.3 Question-relevant Caption Prompt","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#33-question-relevant-caption-prompt","p":431},{"i":459,"t":"합성 question 관련 캡션과 question-answer 쌍으로, 저자는 instruction, caption 및 QA exemplar 를 연결하여 LLM 에 완전한 prompt 를 구성한다. Instruction text : \"Please reason the answer of question according to the contexts\" caption prompt : \"Contexts: [all captions]\\textup{[all captions]}[all captions]\" 같은 형태 QA exemplar : \"Question: [question]\\textup{[question]}[question] Answer: [answer]\\textup{[answer]}[answer]\" 같은 형태 current question 은 prompt 마지막 부분에 위치 시킴 : \"Question: [question]\\textup{[question]}[question]. Answer: \". answer 을 얻기 위해, LLM 에서 greedy decoding 을 수행하고, Flamingo 와 같이 무의미한 token 을 제거한다. 또한 LLM input 에는 최대 길이 제한이 있다 (예; OPT, GPT3 에선 2048). 따라서 prompt 구성을 위해 question 관련 캡션과 question-answer 쌍의 subset 선택이 필수적이다. 정보가 풍부한 prompt 선택을 위해, 저자는 100 개의 생성된 캡션에서 합성된 answer 후보의 빈도를 계산한다. 또한, 빈도가 가장 높은 30 개의 answer 후보를 선택하고 각각에 대해 한 개의 question 을 생성한다. 그리고, 빈도가 가장 낮은 30 개의 answer 와 각각을 포함하는 캡션 하나를 포함시킨다.","s":"3.4 Prompt Design","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#34-prompt-design","p":431},{"i":461,"t":"다른 zero-shot 및 few-shot VQA 방법들과 비교한다. 그 후에, prompt patterns 및 caption selection 전략과 같은 설계 선택에 있어 ablation 연구를 수행한다.","s":"4. Experiment","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":464,"t":"VQAv2 : 214,354 question, 107,394 test-dev OK-VQA : 5,046 test question A-OKVQA : 1,100 validation question, 6,700 test question 위 데이터셋에서 approach 를 평가한다.","s":"Datasets","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#datasets","p":431},{"i":466,"t":"question 관련 caption prompt 를 얻기 위해, BLIP 을 사용하여 caption 을생성하고 image-question 매칭을 수행한다. question 관련 이미지 영역의 지역화를 위해, BLIP image-grounded text encoder 의 cross-attention layer 로부터 GradCAM 을 생성한다. 그런 다음, GradCAM 을 기반으로 K′=20K' = 20K′=20 이미지 패치를 샘플링하고, 이를 이용해 100 개의 question 관련 caption 을 얻는다. LLMs 의 경우, 여러 다른 크기의 오픈 소스 OPT 모델을 주로 사용한다. ablation study 는 다양한 다른 LLMs 를 실험하여 저자의 방법의 일반화 능력을 보여준다. 저자는 LLMs 를 사용하여 auto-regressively 한 answer 를 생성사며, answer list 나 훈련 샘플에 액세스 하지 않으므로 zero-shot VQA 를 용이하게 한다.","s":"Implementation details","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#implementation-details","p":431},{"i":468,"t":"이전 VQA 와 비교하며 세 가지 카테고리로 나뉜다. PICa 와 같은 frozem LLM 을 사용한 Zero-shot method Flamingo, Frozen, VL-T5, Few VLM 및 VLKD 와 같은 multi modal pretraining 을 수행하는 Zero-shot mothod few-shot method 결과도 포함하며, PICa, FewVLM 및 ClipCap 결과가 포함된다. 위 방법들은 대규모의 vision-language 데이터셋이 필요하고 업데이트 비용이 많이 든다. 이 카테고리엔 VQ2^22A 나 WeaQA 도 결과로 포함하지만, 실제론 answer 후보에 접근할 수 없어 주의가 필요하다. 그러므로 이 결과에 대해선 주의하여 해석해야 한다.","s":"Competing methods","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#competing-methods","p":431},{"i":471,"t":"Img2LLM 은 zero-shot with frozen LLMs 인 PICa 보다 크게 능가 (OK-VQA 에서 45.6 대 17.7) 또한 PICa 는 frozen LLM 을 사용하지만 prompt 구성을 위해 훈련 샘플이 필요하지만 저자의 방법은 VQA 샘플에 접근하지 않고도 question-answer 을 생성하므로 zero-shot 요구사항도 충족","s":"SOTA results on zero-shot evaluation with plug-in frozen LLMs","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#sota-results-on-zero-shot-evaluation-with-plug-in-frozen-llms","p":431},{"i":473,"t":"LLMs parameter 를 6.7B 에서 175B 로 키웠을 때, VQA 에서 3-10 point 의 향상을 관찰했다. 이는 강력한 언어 모델이 qustion 을 더 잘 이해하고, 더 정확한 answer 을 주는데 도움이 된다는 것이다. 이 경향은 OK-VQA 및 A-OKVQA 에 명확하고 일관성 있으며, 이러한 데이터셋의 question 은 LLM 이 제공하는 상식적 추론과 외부 지식을 요구하기 때문이다. 이는 LLM 이 VQA 에 유익하다는 것을 뒷받침한다. 다른 흥미로운 점은 LLMs 스케일링이 크기가 클 때 명백하다는 것이다. 30B 이상에선 효과가 있지만, 작은 모델 (6.7B, 13B)에선 예측이 힘들었다.","s":"Scaling effect of LLMs and their emergent capabilities on VQA","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#scaling-effect-of-llms-and-their-emergent-capabilities-on-vqa","p":431},{"i":475,"t":"Img2LLM 은 대부분의 end-to-end training 모델과 몇몇 few-shot 설정에서 평가된 모델보다 우수하다. VQAv2 에서 저자의 방법은 500K TPU hour 과 십억 개 규모 데이터셋을 사용한 Flamingo80B_{80B}80B​ 보다 5.6 point 이상 앞섰다. A-OKVQA 에선 Img2LLM 이 최고의 결과이며 ClipClap 을 두 배 앞선다. Img2LLM 은 대부분의 supervised model 보다 성능이 좋은데, 이는 zero 훈련 데이터를 사용하고 zero-shot setup 에서 평가되었는데도 불구하고 효과적임을 입증한다.","s":"Competitive performance with end-to-end pretraining and few-shot methods","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#competitive-performance-with-end-to-end-pretraining-and-few-shot-methods","p":431},{"i":477,"t":"Img2LLM 을 OPT 와 다른 오픈 소스 LLM (GPT-J, GPT-Neo 및 BLOOM) 에서 성능 평가를 진행한다. 실험 결과 Img2LLM 은 zero-shot VQA task 수행에 있어 다양한 LLMs 가 가능하며, zero-shot PICa 및 Fozen 성능 만큼 도달했다. 이는 저자의 방법의 일반화 성능이 강하다는 것을 보여준다.","s":"4.3 Experimental Results of Different LLMs","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#43-experimental-results-of-different-llms","p":431},{"i":479,"t":"image caption 및 question-answer 생성에 추가 비용 발생 8XA100 기기에서 175B OPT 의 추론 시간에 비해 약 24.4% 의 추가 계산 요구 prompt 를 줄여 오버헤드를 줄일 수 있으며, 이는 정확성을 희생하고 속도를 얻겠다는 것이다. 특히, 저자의 방법은 Flamingo 의 경우인 500K TPU 시간 이상 소요되는 비싼 end-to-end multimodal representation 정렬을 피하는 것이다.","s":"5. Limitation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":431},{"i":481,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2305.07922v2.pdf","s":"CodeT5+: Open Code Large Language Models for Code Understanding and Generation","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":480},{"i":483,"t":"현재 code LLMs 는 두 가지 주요 한계점 존재 specific architecture (encoder-only, decoder-only) 또는 encoder-decoder network 에 의존 전자는 응용하는데 있어 inflexibility 후자는 모든 task 에 대한 single system 을 다루어 subset 에 대해 suboptimal 성능을 보임 관련없는 downstream task 로 pretraining limited set 을 사용 이를 해결하기 위해, component modules 를 유연하게 결합하여 넓은 범위의 downstream code task 에 적합한 encoder-decoder LLMs 의 CodeT5+ 를 제안 이러한 유연성은 pretrain-finetune 불일치성을 완화하기 위해 pretraining objectives 의 mixture을 제안 이 objectives 는 단일 또는 이중의 code 말뭉치에서 span denoising, contrasive learning, text-code matching 및 causal LM pretraining tasks 수행 가능 또한 모델을 효율적으로 scale up 하기 위해 CodeT5+ 를 처음부터 훈련하지 않고 frozen off-the-shelf LLMs 으로 초기화하는 방법 그리고 instruction-tuning 을 탐구 저자는 CodeT5+ 를 20개의 code-related benchmarks 에 광범위하게 평가를 했으며, zero-shot, finetuning, instruction-tuning 을 포함한다. code generation/completion, math programming 및 text-to-code retrieval task 같은 다양한 code-related task 에서 SOTA 를 달성","s":"Abstract","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":480},{"i":485,"t":"LLMs 는 대규모 코드 기반 데이터 (예; GitHub 공개 데이터)로 pretrain 하여 다양한 코드 관련 downstream task 로 transfer 할 수 있다. 하지만 기존의 많은 모델이 특정 downstream task 만 잘 수행되도록 설계가 되어 있다. 이는 주로 아키텍처와 pretraining task 수행 과제에 대한 두 제한으로 인한 것으로 주장한다. Architecture 기존의 code LLM 은 understanding / generation task 에만 잘 수행되는 encoder-only / decoder-only 모델을 채택한다. 특히, text-to-code retrieval 같은 understading task 용이한 encoder model, code generation 같은 generation task 에 대한 decoder model 이 강력한 성능을 보인다. 그러나 디코더 모델은 인코더 모델에 비해 검색 및 감지 작업같은 understading task 에 이상적이지 않으며, 최근 encoder-decoder architecture 를 많이 채택한다. understanding 과 generation 모두를 지원하지만, 여전히 최적의 성능을 내지 못한다. Unixcoder 는 encoder-decoder 모델이 검색 및 코드 완성 작업에서 SOTA 인 encoder 및 decoder-only 모델을 능가하지 못하는 것을 발견했다. 이 결함은 주로 모든 작업에 적응되는 단일 모듈 아키텍처의 한계다. 요약하자면, 기존 접근방식은 개별 구성 요소가 다른 downstream task 에 더 활성화될 수 있도록 설계되지 않았다. 현재 제한된 훈련셋으로 사용하여, pretrain, transfer 사이의 불일치로 인한 downstream task 의 성능 하락을 야기함. 예로 T5 기반 모델은 종종 span denoising 목적으로 훈련된다. 그러나 코드 생성 같은 downstream task 의 대부분 SOTA 모델은 프로그램 토큰을 하나씩 auto-regressively predict 하여 다음 토큰을 예측하는 목적으로 pretrain 한다. 최근 시도는 위 문제 완화를 위해 contrastive learning 을 도입하지만, text 와 code representation 사이의 alignment 를 무시한다. 저자는 CodeT5+ 의 모델 크기를 확장하기 위해 계산 효율적인 pretrain 전략을 사용하여 CodeT5+ 의 구성 요소를 초기화하는데 존재하는 code LLMs 를 활용한다. pretrained checkpoint 로 encoder, decoder 를 초기화하고 cross attention layer 로 연결하는 \"shallow encoder, deep decoder\" architecture 를 채택한다. deep decoder LLM 은 고정하며, shallow encoder 와 cross attention layer 만 훈련하여 효율적인 조정을 위해 훈련 가능한 매개 변수의 수를 크게 줄인다. 마지막으로, NLP 분야의 최근 연구인로 Instruction tuning 으로 탐구한다. 20개 이상의 code 관련 벤치마크에서 CodeT5+ 를 광범위하게 평가했다. zero-shot, finetuning 및 instruction tuning 을 포함한다. 결과는 CodeT+ 가 많은 downstream 작업에서 SOTA baseline 에 비해 상당한 성능 향상을 보여준다.","s":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":480},{"i":488,"t":"code understanding 및 generation task 를 위한 새로운 open code LLMs 인 CodeT5+ 를 개발. encoder-decoder 를 기반으로한 CodeT5+ 는 unimodal 및 bimodal 데이터에 대한 다양한 pretrain objectives 를 통해 다양한 모드에서 작동 가능한 유연성을 갖추고 있다. unimodal pretraining 첫 단계로, 계산 효율적인 목적으로 대규모 코드 데이터로 pretrain bimodal pretraining 두 번째 단계로, cross-modal 학습 목적으로 code-text data 의 smaller set으로 모델을 계속 pretrain 각 단계에서 여러 pretrain objective 를 동일한 가중치로 공통 최적화 위 접근 방식이 모델이 다양한 데이터에 노출되어 풍부한 context representation 을 학습하는 데 효율적이란 것을 발견","s":"3. CodeT5+: Open Code Large Language Models","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":480},{"i":490,"t":"먼저, CodeT+ 를 대규모 코드 unimodal data 로 사전학습. GitHub 의 오픈 소스로, 코드 및 주석이 포함되어 있음. 두 번째로, code-text 쌍의 데이터로, Span Denoising 및 CLM task 를 사전학습한다. 이 작업은 모델이 다양한 범위의 code context 를 복구하는 방법을 학습할 수 있도록 한다.","s":"3.1. Unimodal Pretraining on Code Data","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#31-unimodal-pretraining-on-code-data","p":480},{"i":492,"t":"encoder input 에 15% 토큰을 무작위 mask 로 대체하고, decoder 가 복구하도록 한다.","s":"Span Denoising","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#span-denoising","p":480},{"i":494,"t":"두 가지 변형으로 auto-regressive generation 을 위해 최적화. 임의로 피벗 위치를 선택하여, 그 이전의 context 를 source sequence 로, 이 후의 시퀀스를 target output 으로 간주. 이를 seq2seq 와 언어 모델링 목적으로 표기 피벗 위치는 전체 sequence 의 10% - 90% 사이에서 균등하게 샘플링되도록 제한하고 source sequence 에 특수 토큰 [CLM] 을 추가 decoder 전용 generation task 로, 첫 번째 변형의 극단적인 경우. [CLM] 토큰을 encoder 에 입력으로 전달하고, decoder 에게 전체 코드 시퀀스를 생성하도록 요구.","s":"Causal Language Modeling (CLM)","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#causal-language-modeling-clm","p":480},{"i":496,"t":"두 번째 단계로, 저자는 text-code bimodal data 로 pretrain 하였다. 여기서 각 text-code 쌍은 code function 과 대응하는 docstring describing 을 포함한다. 이런 bimodal data 는 모델 훈련이 cross-modal understanding 과 generation 에 용이하도록 한다. bimodal tasks 는 cross-modal contrastive learning, matching 및 causal LM task 를 포함한다.","s":"3.2. Bimodal Pretraining on Text-code Data","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#32-bimodal-pretraining-on-text-code-data","p":480},{"i":498,"t":"이 tasks 는 text 및 code representations 의 feature space 를 정렬하기 위해 positive text-code paris 는 모으고 negative text-code pairs 를 분리하는 것을 목표로 한다. Guo et al. [2022] 는 code understanding task 에서 이점을 입증했다. 이 task 는 encoder 에서만 활성화하며, text 나 code snippet 을 bidirectional self-attention 을 통해 continuous representation 으로 인코딩한다. BERT 와 유사하게, 저자는 input 앞에 special token [CLS] 을 붙이고, 최종 Transformer layer 의 output embeddings 를 해당 input text 나 input code 의 representations 으로 간주한다. 또한, linear layer 를 추가하고 L2 normalization 을 사용하여 출력을 256-dimensional embeddings 로 매핑한다. negative samples 를 보강하기 위해, momentum encoder 를 사용하여 이전 mini-batches 의 임베딩을 저장한다. 구체적으로, momentum encoder 는 현재 mini-batch 의 샘플을 enqueue 하고 가장 오래된 mini-batch 는 dequeue 하여 queuing 시스템을 유지한다. 기존의 encoder 와 momentum encoder 의 linear interpolation 을 통해 momentum encoder 를 업데이트하여 training step 간의 representation 일관성을 보장한다.","s":"Text-Code Contrastive Learning","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-contrastive-learning","p":480},{"i":500,"t":"이 task 는 decoder 를 활성화시키고 text 와 code snippet 이 동일안 의미를 가지는지 예측하는 것을 목표로 함. 이는 text 와 code modalities 간의 fine-grained alignment 를 포착하는 더 나은 bimodal representations 를 학습 하는데 도움이 된다. code sample 이 주어지면 decoder 는 embedding layer 및 causal self-attention layer 를 통과시킨 후, self-attention representation 은 cross attention layer 로 전달되어 encoder 로부터 받은 text representation 와 관련한 signal 을 query 한다. task-specific [Match] token 은 code input sequence 의 맨 앞에 추가되어 decoder 에 text-code matching functionality 를 제공해주며, [EOS] token 은 code input 끝에 추가된다. decoder 는 causal self-attention mask 를 사용하며 last decoder token 만 전체 context 에 참여할 수 있어, [EOS] 의 output embedding 을 text-code cross-modal 의 alignment representation 으로 다룬다. 마지막으로, binary matching task 를 위해 decoder 의 output embedding 위에 linear layer 를 사용하여 text-code pair 가 positive (match) 인지 negative (unmatched) 인지를 예측한다. 정보가 많은 negative 를 찾기 위해, 저자는 hard negative mining 전략을 사용한다. 특히, 현재 샘플과 momentum encoder 가 유지하는 queue 내의 이전 샘플 간의 contrastive-based similarity score 에 따라 hard negative 를 샘플링한다. 이렇게 하면 harder negative 가 선택될 가능성이 높아진다. positive pairs 의 batch 의 경우, code/text query 를 사용하여 text/code queue 에서 negative 를 mining 하여 negative pairs 의 두 batch 를 구성한다.","s":"Text-Code Matching","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-matching","p":480},{"i":502,"t":"이 task 는 encoder 및 decoder 모두 활성화시키며, text-to-code 및 code-to-text 생성으로 dual multimodal conversion 을 통한 cross-modal generative 목표에 초점을 둔다. 구체적으로, text sample 이 input 일 경우, decoder 의 input sequence 에 [CDec] token 을 앞에 추가한다. 이 경우, decoder 는 code generation funtionality 로 작동한다. 반대로, input 이 code sample 인 경우엔 decoder 의 input sequence dp [TDec] token 맨 앞에 추가하여, deocder 는 text generation functionality 로 작동한다. 이런 유형의 Causal LM 은 code summarization 같은 multimodal generative downstream tasks 에서 pretrain-finetune gap 을 줄이기 위한 효과적인 learning objective 로 입증되었다.","s":"Text-Code Causal LM","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-causal-lm","p":480},{"i":504,"t":"모델을 첨부터 pretraining 하지 않고 효율적으로 확장하기 위해, 저자는 CodeT5+ 의 component (encoder, decoder)를 off-the-shelf pretrained LLM 로 초기화하는 compute-efficient pretraining 전략을 제안한다. (Fig 2. 오른쪽) 이 확장을 위해, [Li et al., 2022b] 의 영감을 받아, 기존 T5 모델과 동일한 크기의 encoder 와 decoder 대신 \"shallow encoder and deep decoder\" architecture 를 사용한다. [Li et al., 2022b] 에 따르면, T5-based model 의 decoder 는 종종 생성 작업에서 더 높은 복잡성을 처리해야 하므로, 더 많은 neural parameters 로 강화해야 한다. 분리되어 pretrain 된 encoder 와 decoder 를 연결하기 위해, 저자는 self-attention layer 이후 decoder block 에 무작위로 초기화된 cross-attention layer 를 삽입한다. efficient tuning 을 위해, cross-attention layer 는 top-LLL decoder layer (본 실험은LLL=1)에만 삽입한다. small encoder 와 cross-attention layer 만 trainable 하도록 유지하면서, 대부분의 decoder parameter 는 고정한다. 또한, training stability 향상을 위해 gating function 을 추가하거나 특정 frequency 로 multiple cross-attention layer 를 삽입하는 등의 설계도 탐구한다. 하지만, 상당한 성능 향상은 관찰되지 않았으며, 더 좋지 않은 결과로는 이런 설계 선택은 계산 비용이 너무 많이 들게 된다.","s":"3.3. Compute-efficient Pretraining with Frozen Off-the-shelf LLMs","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#33-compute-efficient-pretraining-with-frozen-off-the-shelf-llms","p":480},{"i":506,"t":"pretraining 의 두 단계 후, CodeT5+ 는 다양한 모드에 유연하게 작동하여 Seq2Seq generation task, decoder-only tasks 및 understanding-based tasks 를 포함한 다양한 task 를 지원할 수 있다.","s":"3.4. Adaptation to Downstream Understanding and Generation Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#34-adaptation-to-downstream-understanding-and-generation-tasks","p":480},{"i":508,"t":"encoder-decoder model 인 CodeT5+ 는 code generation 및 summarization 같은 Seq2Seq generation task 에 자연스럽게 적응할 수 있다. 또한, encoder 를 사용하여 code snippets 를 검색하고, 이를 code generation 을 위해 encoder 및 decoder 모두 사용하는 retrieval-agumented generation model 로 적용할 수 있다.","s":"Seq2Seq Generation Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#seq2seq-generation-tasks","p":480},{"i":510,"t":"이 설정에선, encoder input 에 항상 [CLM] 토큰을 주입하고, source sequence 를 prefix context 로 decoder 에 전달한다. encoder 와 decoder 의 cross-attention layers 의 weight 를 고정한다. 이 전략은 decoder 파트만 활성화하며 기술적으로 전체 model parameter 의 약 절반을 줄인다. 저자는 next-line code completion task 를 사용하여 CodeT5+ 의 decoder 전용 generation 능력을 평가한다.","s":"Decoder-only Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#decoder-only-tasks","p":480},{"i":512,"t":"CodeT5+ 는 understanding tasks 를 두 가지 방식으로 지원할 수 있다 encoder 를 사용하여 text/code embedding 을 얻어 이를 detection task 나 retrieval task 를 위해 binary classifier 에 전달할 수 있다. encoder 를 decoder 와 결합하여 text-to-code retrieval task 에 대한 text-code matching score 를 예측할 수 있다.","s":"Understanding Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#understanding-tasks","p":480},{"i":515,"t":"최근 출시된 GitHub Code 데이터셋을 사용하여 CodeSearchNet 의 pretraining dataset 을 확장했다. 9 개의 PLs (Python, Java, Ruby, JavaScript, GO, PHP, C, C++, C#)를 선택하였고, 허용 라이선스를 가진 코드와 50 ~ 2000 tokens 을 가진 파일들만 필터링 하였다. 또한, GitHub repository name 을 확인하여 CodeSearchNet 과 다른 downstream tasks 에서 중복되는 부분을 필터링했다. 중복 데이터는 exact match 를 기준으로 필터링되어 중복되는 부분이 있을 수 있지만, 이 중복은 모델 성능에 큰 영향을 미치지 않을 것으로 예상된다. 저자는 CodeT5 tokenizer 를 사용하여 다국어 데이터셋을 토큰화했으며, 이로 인해 5150억 개의 토큰이 생성되었다. 이는 CodeSearchNet 보다 약 50배 큰 크기이다. Table 1 에는 unimodal code 및 bimodal text-code pretrained dataset 의 통계이다. 표에서 보이듯, GitHub 코드로부터 정리된 데이터셋은 CodeSearchNet bimodal data 의 function level 보다 훨씬 큰 데이터 크기를 가지고 있어, 모델이 pretrain 의 첫 단계에서 풍부한 representation 을 학습할 수 있게 해준다. CodeT5 와 달리 저자는 CodeSearchNet 의 bimodal 데이터만을 CodeT5+ 의 두 번째 단계 pretrain 에 사용한다. 이 단계에서는 주로 text-code 관련 task 인 text-to-code retrieval 및 generation 에 모델을 적응시킨다.","s":"4.1. Pretraining Dataset","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#41-pretraining-dataset","p":480},{"i":517,"t":"저자는 CodeT5+ models 을 두 그룹으로 pretrain 한다. CodeT5+ 220M 및 770M 은 T5 의 아키텍처에 따라 처음부터 train 된다. CodeT5+ 2B, 6B, 16B 는 decoder 를 CodeGen-mono 2B, 6B, 16B model 에서 초기화하고 encoder 를 CodeGen-mono 350M 에서 초기화한다. scaing 전략을 주목하자, 원래의 CodeGen 모델과 비교하여 후자의 CodeT5+ 모델 그룹은 무시할 만한 학습 가능한 매개변수를 도입합니다(2B, 6B, 16B 모델에 대해 350M 인코더와 36M, 67M, 151M의 크로스 어텐션 레이어 하나). 이 두 그룹의 모델에는 각각 CodeT5 토크나이저와 CodeGen 토크나이저를 사용합니다. 사전학습에서는 16개의 A100-40G GPU가 장착된 Google Cloud Platform의 클러스터에서 CodeT5+를 대규모의 단모달 데이터셋과 이후 작은 이중모달 데이터셋에 대해 단계적인 전략으로 사전학습합니다. 첫 번째 단계에서는 10,000번의 학습 단계 동안 모델을 스팬 노이즈 제거 작업으로 예열한 후, 두 개의 CLM 작업과 같은 가중치로 합동 훈련을 100,000번의 단계 동안 진행합니다. 스팬 노이즈 제거 작업에 대해 선형 감쇠 학습률(LR) 스케줄러를 사용하며, 최대 학습률은 2e-4이고 배치 크기는 노이즈 제거에는 2048, CLM에는 512로 설정합니다. 입력 및 출력 데이터를 준비하기 위해 스팬 노이즈 제거 작업의 최대 길이를 512로 설정하고, 코드 완성 CLM의 소스 및 타겟 시퀀스의 최대 길이를 각각 768과 600으로, 디코더만을 사용한 생성 CLM의 최대 길이를 1과 1024로 설정합니다. 두 번째 단계에서는 대조 학습, 매칭 및 두 개의 CLM 손실을 동일한 가중치로 10 에폭 동안 합동으로 최적화합니다. 배치 크기는 256이고 최대 시퀀스 길이는 코드와 텍스트 시퀀스 각각 420과 128로 설정합니다. 모든 실험에서는 0.1 가중치 감쇠를 가진 AdamW 옵티마이저 [Loshchilov and Hutter, 2019]를 사용합니다. 또한 DeepSpeed의 ZeRO Stage 2 [Rasley et al., 2020]와 FP16의 혼합 정밀도 훈련을 사용하여 훈련 가속화를 수행합니다. CodeT5+ 2B, 6B 및 16B의 훈련에는 FP16로 고정된 디코더 가중치를 사용하고 다른 학습 가능한 가중치는 FP32로 유지합니다. CodeT5+ 6B 및 16B 모델에 대해서는 DeepSpeed ZeRO Stage 3의 매개변수 분할을 사용합니다.","s":"4.2. Pretraining Setup","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#42-pretraining-setup","p":480},{"i":519,"t":"논문 및 이미지 출처 : https://aclanthology.org/2022.acl-short.1.pdf","s":"BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":521,"t":"저자는 BitFit 이라는 sparse-finetuning 도입 이 방법은 모델의 bias-terms 만 (or subset of them) 수정 small-to-medium training data 에서, pre-trained BERT 에 BitFit 을 적용하면 full fine-tuning 과 competitive (때론 더 좋음) large data 에선, 다른 sparse fine-tuining methods 와 competitive 위 결과는 유용성 외에도, fine-tuning 이 new task-speciifc knowledge 학습이 아닌, language-modeling training 에 의해 유도된 knowledge 를 노출시키는 것이라는 가설을 지원하는 것과도 관련 있다.","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":523,"t":"BERT 계열의 bidirectional masked language model 은 많은 NLP task 에서 성과를 이끌어내고 있다. 이런 모델은 일반적으로 corpora 에서 LM objective 로 pre-training 된 후 task-specific supervised data 에 fine-tuning 된다. 이런 모델은 크기가 상당하기 때문에 훈련 비용 및 배포 비용도 상당하며, fine-tuning 이 original model 을 얼마나 변화시켜야 하는지도 문제다. 이로 인해 최근 model parameter subset 만 식별하여 end-tasks 에서 성능을 유지하며 나머지는 유지하는 변형을 고려하고 있다. 이에 저자는 fine-tuning 에 대한 간단하고 효과적인 접근법 제시. 이점은 다음과 같다. fine-tuned task 당 very few parameters 변경 모든 tasks 에 대해 동일한 parameter set 변경 (task-invariance) 변경된 parameter 는 all parameter space 에 걸쳐 isolate 및 localize small-to-medium training data 의 경우, 이러한 parameter 변경으로 fine-tuning 의 정확도에 도달하거나 때론 향상 구체적으로, 대부분의 network 를 freezing 하고 bias-term 만 fine-tuning 하는 것이 효과적임을 보여줌 성능이 약간 저하되게 되면, two bias components (\"query\" 및 \"middle-of-MLP\" bias-terms) 만 fine-tuning 할 수 있으며, 이는 bias parameter 중 절반에 해당하여, all model parameter 의 0.04% 에 해당 위 결과는 메모리 제한적인 환경에서 multi-task fine-tuned model 을 배포하는 데 실용성이 있으며, 대부분의 parameter 가 fix 된 채 학습할 수 있는 길을 열어줌 또한 pre-trained network 에서 bias-terms 의 역할과 fine-tuning 과정의 원동력에 관한 연구 방향을 열어줌","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":525,"t":"fine-tuning 을 통한 transfer learning 에서, pre-trained encoder network 는 input 을 받아 contextualized representations 를 생성 이후 task-specific classification layer (여기선 linear classifier 고려)가 encoder top 에 추가되고 전체 network (encoder + task specific classifiers)는 task loss 를 최소화하기 위해 end-to-end 훈련 Desired properties​ task 당 fine-tuning 은 매우 효과적이지만, 각 pre-trained task 마다 큰 모델을 생성하므로 fine-tuning processd 에서 무엇이 변경되는지 이해하기 어렵고, 특히 task 수가 증가함에 따라 배포가 어렵다. 이상적인 fine-tuning 은 다음과 같아야 한다. (i) fully fine-tuned model 의 결과와 일치 (ii) model parameter 의 small portion 만 변경 (iii) all dataset 에 동시에 access 하는 대신, task 가 순차적으로 오게 함 (iv) 효율적인 hardware 기반 배포를 위해 변경된 값의 parameter set 이 여러 task 에 걸쳐 일관되야 함 Learning vs. Exposing​ 위 요구 사항을 충족할 가능성은 large pre-trained LM 의 fine-tuning process 의 근본적인 질문이 생길 수 있다: fine-tuning process 가 new capabilities learning, vs. pre-training process 에서 학습된 existing capabilities exposing. 둘의 정도가 무엇인가? Existing approaches​ 위 두 연구는 parameter small subset 만 변경하여 다양한 end-tasks 에 adaptation 이 가능함을 보여줌 Adapter (Houlsby et al. 2019) : pre-trained model layers 사이에 trainable task-specific \"adapter\" modules 삽입 original parameters 는 task 간에 공유됨 Diff-Pruning (Guo et al. 2020) : original parameters 에 task-specific difference-vector 추가 difference-vector 는 sparse 하게 정규화 위 두 방법 모두 task 당 trainable small parameter 만 추가 가능하며 (ii), 각 task 는 이전 task 에 방문하지 않고 추가 (iii) 또한 (i) 을 부분적으로 충족시키며, full fine-tuning 과 비교하여 성능이 약간 감소 Adapter 는 Diff-Pruning 보다 parameter-efficiency 이 떨어지지만 (특히 new parameter 추가하지 않음), task score 도 더 높게 달성 experiments section 에서 Diff-Pruning 및 Adapter 를 비교하고 (iv) 를 충족시키며, 많은 task 에서 우수한 성과 보여줌","s":"2. Background: fine-tuning and parameter-efficient fine-tuning","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":527,"t":"저자는 BitFit (BIas-Term FIne-Tuning) 을 제안 대부분의 transformer-encoder parameters 를 freezing 하고 bias-terms 및 task-specific classification layer 만 훈련 핵심 속성은 다음과 같다. (i) fully fine-tuned model 결과와 동일 (ii) task 를 순차적으로 오는 것이 가능하며, 이 방법은 all dataset 을 동시에 access 할 필요가 없는 방법 (iii) model small parameter 만 fine-tuning 이 접근법은 parameter-efficient 각 new task 는 bias terms parameter vectors 및 task-specific final linear classifer layer 만 저장하면 됨 (전체 parameter 의 약 0.1% 보다 적음) 구체적으로, BERT encoder 는 LLL layer 로 구성 각 layer ℓ\\ellℓ 은 MMM self-attention heads 로 시작 self-attention head (m,ℓ)(m, \\ell)(m,ℓ) 은 key, query 및 value encoder 를 가짐 각각 linear layer 형태를 취함 Qm,ℓ(x)=Wqm,ℓx+bm,ℓqKm,ℓ(x)=Wqm,ℓx+bm,ℓqVm,ℓ(x)=Wqm,ℓx+bm,ℓq\\begin{align*} Q^{m, \\ell}(x) = {\\color{blue}{W^{m, \\ell}_q}x} + {\\color{red}{b^{m, \\ell}}_q} \\\\ K^{m, \\ell}(x) = {\\color{blue}{W^{m, \\ell}_q}x} + {\\color{red}{b^{m, \\ell}}_q} \\\\ V^{m, \\ell}(x) = {\\color{blue}{W^{m, \\ell}_q}x} + {\\color{red}{b^{m, \\ell}}_q} \\end{align*}Qm,ℓ(x)=Wqm,ℓ​x+bm,ℓq​Km,ℓ(x)=Wqm,ℓ​x+bm,ℓq​Vm,ℓ(x)=Wqm,ℓ​x+bm,ℓq​​ xxx : 이전 encoder layer 의 output (first encoder layer xxx 는 embedding layer 의 output) 이들은 new parameter 를 사용하지 않는 attention mechanism 을 사용하여 결합 h1ℓ=att(Q1,ℓ,K1,ℓ,V1,ℓ,..,Qm,ℓ,Km,ℓ,Vm,ℓ)h^\\ell_1 = att(Q^{1, \\ell}, K^{1, \\ell}, V^{1, \\ell}, .., Q^{m, \\ell}, K^{m, \\ell}, V^{m, \\ell})h1ℓ​=att(Q1,ℓ,K1,ℓ,V1,ℓ,..,Qm,ℓ,Km,ℓ,Vm,ℓ) 이후 MLP with layer-norm (LM) 이 주입 h2ℓ=Dropout(Wm1ℓ⋅h1ℓ+bm1ℓ)h3ℓ=gLN1ℓ⊙(h2ℓ+x)−μσ+bLN1ℓh4ℓ=GELU(Wm2ℓ⋅h3ℓ+bm2ℓ)h5ℓ=Dropout(Wm3ℓ⋅h4ℓ+bm3ℓ)outℓ=gLN2ℓ⊙(h5ℓ+h3ℓ)−μσ+bLN2ℓ\\begin{align} h^\\ell_2 &= &\\text{Dropout}(&{\\color{blue}{W^\\ell_{m1}}} \\cdot h^\\ell_1 &+ &&{\\color{red}{b^\\ell_{m1}}}) \\\\ h^\\ell_3 &= & {\\color{blue}{g^\\ell_{LN_1}}} \\odot &\\frac{(h^\\ell_2 + x) - \\mu}{\\sigma} &+ &&{\\color{red}{b^\\ell_{LN_1}}}\\\\ h^\\ell_4 &= &\\text{GELU}&({\\color{blue}{W^\\ell_{m2}}} \\cdot h^\\ell_3 &+ &&{\\color{red}{b^\\ell_{m2}}})\\\\ h^\\ell_5 &= &\\text{Dropout}&({\\color{blue}{W^\\ell_{m3}}} \\cdot h^\\ell_4 &+ &&{\\color{red}{b^\\ell_{m3}}})\\\\ \\text{out}^\\ell &= &{\\color{blue}{g^\\ell_{LN_2}}} \\odot &\\frac{(h^\\ell_5 + h^\\ell_3) - \\mu}{\\sigma} &+ &&{\\color{red}{b^\\ell_{LN_2}}} \\end{align}h2ℓ​h3ℓ​h4ℓ​h5ℓ​outℓ​=====​Dropout(gLN1​ℓ​⊙GELUDropoutgLN2​ℓ​⊙​Wm1ℓ​⋅h1ℓ​σ(h2ℓ​+x)−μ​(Wm2ℓ​⋅h3ℓ​(Wm3ℓ​⋅h4ℓ​σ(h5ℓ​+h3ℓ​)−μ​​+++++​​bm1ℓ​)bLN1​ℓ​bm2ℓ​)bm3ℓ​)bLN2​ℓ​​​ all matrices collection W(⋅)ℓ,(⋅){\\color{blue}{W^{\\ell,(\\cdot)}_{(\\cdot)}}}W(⋅)ℓ,(⋅)​ 및 vectors g(⋅)ℓ,b(⋅)ℓ,(⋅){\\color{blue}{g^\\ell_{(\\cdot)}}}, {\\color{red}{b^{\\ell, (\\cdot)}_{(\\cdot)}}}g(⋅)ℓ​,b(⋅)ℓ,(⋅)​ : network parameters Θ\\ThetaΘ vectors subset b(⋅)ℓ,(⋅){\\color{red}{b^{\\ell, (\\cdot)}_{(\\cdot)}}}b(⋅)ℓ,(⋅)​ : bias terms bias terms 은 덧셈 연산 BERTBASE_\\text{BASE}BASE​ 및 BERTLARGE_\\text{LARGE}LARGE​ 의 bias parameter 는 각각 총 parameter 중 0.09% 및 0.08% 차지 all parameter W(⋅){\\color{blue}{W^{(\\cdot)}}}W(⋅) 및 g(⋅){\\color{blue}{g^{(\\cdot)}}}g(⋅) 를 freezing 하고 additive bias terms b(⋅){\\color{red}{b^{(\\cdot)}}}b(⋅) 만 fine-tuning 하여, full fine-tuning 과 comparable 한 transfer learning 성능을 달성할 수 있다. (때론 능가) 저자는 또한 bias parameter subset 만 fine-tuning 할 수 있음을 보여줌 즉, query 와 second MLP layer (only bq(⋅){\\color{red}{b^{(\\cdot)}_q}}bq(⋅)​ 및 bm2(⋅){\\color{red}{b^{(\\cdot)}_{m2}}}bm2(⋅)​) 만 fine-tuning 하여 full fine-tuning 과 필적한 성능","s":"3. Bias-terms Fine-tuning (BitFit)","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":529,"t":"Datasets​ BitFit 을 GLUE 에서 평가 이전 연구 (Houlsby et al. 2019; Guo et al. 2020) 를 따라, WNLI task 는 제외한다 (BERT 대부분이 능가하지 못함). Models and Optimization​ 저자는 Huggingface 를 사용하여 pre-trained BERTBASE_\\text{BASE}BASE​, BERTLARGE_\\text{LARGE}LARGE​ 및 RoBERTaBASE_\\text{BASE}BASE​ 사용 Comparison to Diff-Pruning and Adapters (Table 1)​ 먼저 BitFit 을 Diff-Pruning 및 Adapter 와 비교. 이때 fewer parameter 를 사용 Table 1 에서 Diff-Pruning 및 Adapter 와 비교한 dev-set 및 test-set performance report 이 실험에서 BERTLARGE_\\text{LARGE}LARGE​ 사용 validation set 에서 BitFit 은 9 tasks 중 4 개에서 Diff-Pruning 능가 trainable parameter 를 6x 적게 사용 text-set 결과는 Diff-Pruning 과 비교하여 2개 능가 Adapter 와 비교하여 4개에서 능가 및 45x fewer trainable parameter Different Base-models (Table 2)​ 다양한 base-models (smaller BERTBASE_\\text{BASE}BASE​ 및 better performing RoBERTaBASE_\\text{BASE}BASE​) 와 BERTLARGE_\\text{LARGE}LARGE​ 결과를 반복 Table 2 결과는 일관된 추세를 보임 Are bias parameters special?​ 편향 매개변수는 특별한가요? 아니면 임의의 부분 집합이면 괜찮은 건가요? 우리는 BitFit에서와 동일한 수의 매개변수를 전체 모델에서 무작위로 추출하고 그것만을 미세조정했습니다 (\"rand uniform\" 표 3의 줄). 모든 작업에서 결과는 상당히 나빴습니다. 매개변수를 매트릭스의 완전한 행/열로 무작위로 추출할 때 비슷한 패턴이 관찰되었습니다 (\"rand row/col\" 표 3의 줄). Fewer bias parameters (Table 3)​ bias-parameter subset 만 fine-tuning 할 수 있을까? 저자는 bias vector bbb 의 변화량을 1dim⁡(b)∥b0−bF∥1\\frac{1}{\\dim(b)}\\parallel b_0 - b_F \\parallel_1dim(b)1​∥b0​−bF​∥1​ 로 정의하며, 즉 initial LM values b0b_0b0​ 와 fine-tuned values bFb_FbF​ 간의 dimension 간 평균 절대 변화량이다. Fig. 1 은 RTE task 에 대한 bias term 및 layer 의 변화를 보여준다. 'key' bias bk{\\color{red}{b_k}}bk​ 는 변화가 없으며, 이는 Cordonnier et al. 2020 의 관찰과 일치 반면 'query' bias bq{\\color{red}{b_q}}bq​ 및 intermediate MLP layer bias bm2{\\color{red}{b_m2}}bm​2 는 가장 많이 변화했다. Table 3 은 BERTBASE_\\text{BASE}BASE​ 에서 bq(⋅){\\color{red}{b^{(\\cdot)}_q}}bq(⋅)​ 및 bm2(⋅){\\color{red}{b^{(\\cdot)}_{m2}}}bm2(⋅)​ bias term 만 fine-tuning 했을 때의 devset results report 결과는 all bias parameter 를 조정할 때보다 약간 낮을 뿐이다. bq(⋅){\\color{red}{b^{(\\cdot)}_q}}bq(⋅)​ 및 bm2(⋅){\\color{red}{b^{(\\cdot)}_{m2}}}bm2(⋅)​ 중 하나만 tuning 하면 현저히 나쁜 결과를 얻었으며, 이는 두 bias type 이 필수임을 나타냄 기대대로, frozen BERTBASE_\\text{BASE}BASE​ 를 사용하면 훨씬 나쁜 결과를 얻음 Generalization gap​ 대부분의 경우 full fine-tuning 은 거의 100% train accuracy 에 도달하는 반면, BitFit 은 generalization gap (Shalev-Shwartz and Ben-David, 2014) - training error 와 test error 간의 차이가 현저히 작다 Token-level tasks​ GLUE task 는 모두 sentence level 이다. 저자는 token-level PTB POS-tagging 에서도 실험 진행 BERTBASE_\\text{BASE}BASE​, BERTLARGE_\\text{LARGE}LARGE​ 및 RoBERTaBASE_\\text{BASE}BASE​ 에 대한 Fyll-FT 결과는 97.2, 97.4, 97.2 이며 BitFit 결과는 97.2, 97.4, 97.1 이다. Size of training data​ GLUE 결과는 BitFit 이 Full-FT 성능에 달성하는 능력과 training set size 간의 역상관 관계를 시사 이를 테스트하기 위해 SQuAD v1.0 크기가 점점 커지는 subset 에 훈련 (Rajpurkar et al. 2016a) Fig. 2 에서 명확한 추세가 보여짐: BitFit 은 smaller-data 에서 Full-FT 를 압도하며, training data 가 많아지면서 추세가 반전된다. 저자는 BitFit 이 small-to-medium data 에서 targetted fine-tuning method 라는 결론을 내림","s":"4. Experiments and Results","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":531,"t":"good performance 를 위해 fine-tuning 해야하는 최소한의 parameter set 을 식별하는 문제는 model compression 의 실용성과 함께 pre-training 및 fine-tuning process, 각각에 유도된 \"linguistic knowledge\" 및 \"generalization\" 과 관련 있다. Over-parameterization​ Large LM 은 over-parameterized 임을 입증 inference 에 필요한 것보다 more parameter 를 포함하고 있음을 보여줌 (Buciluaˇ et al., 2006; Hinton et al., 2015; Urban et al., 2017; Karnin, 1990; Reed, 1993; Augasta and Kathirvalavakumar, 2013; Liu et al., 2014; Han et al., 2015; Molchanov et al., 2017) Gordon et al (2020) 은 overparameterization 이 fine-tuning 에 활용될 수 있음을 입증 다시 말해, pruned network 가 transfer setting 에서 잘 수행된다는 것을 보여줌 저자는 모델 전체는 유지하되 일부 파라미터만 업데이트하는 보완적인 환경에서 작업 이런 작업은 lottery-ticket hypothesis (Frankle and Carbin. 2019; Chen et al. 2020; Prasanna et al. 2020) 에 흥미를 일으킴 이 가설은 pre-trained Large model 이 필요한 이유는 (높은 확률로) correct inductive bias 로 초기화된 subnetwork 의 존재를 유도하기 위해서이다. 이런 sparse networks 가 종종 여러 task 에 잘 transfer 되는 결과를 제공 Bias terms​ Bias terms 과 그 중요성은 거의 논의되지 않음 Zhao et al (2020) 은 masking-based fine-tuning 을 설명하고 bias term 을 무시하는 것이 \"성능에 긍정적인 효과를 관찰하지 못했다\"고 언급 Wang et al. (2019) 는 예외로, attribution method 관점에서 bias term 분석 last layer bias values 가 predicted class 에 초래하며, 이 중요성을 back-propagation 하는 방법을 제안 Michel and Neubig (2018) 은 NMT system 에서 output softmax 의 bias 를 fine-tuning 하여 output vocabulary 를 personalize Frankle et al. (2020) 은 batch-norm layer 만 훈련 후에도 randomly-initialized CNN 이 합리적인 정확도 달성을 입증 저자의 작업과 유사한 Cai et al. (2020) 은 bias 만 fine-tuning 하는 것이 pre-trained vision model 의 adaptation 에 효과적임을 입증 저자의 작업은 bias parameter 의 중요성과 힘을 실험적으로 보여줌","s":"5. Related Work","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":533,"t":"저자는 BitFit 이란 localizing 에 대한 새로운 방법 제안 이는 pre-trained transformers 를 end-task 에 대해 fast fine-tuning 가능 fine-tuning 으로 mode parameter 중 특정 부분인 bias 에 집중시키고, GLUE 에서 좋은 성능 유지 parameter small group 을 수정하는 데 중점을 두고, NLP task 간에 모델 대다수 parameter 를 공유하여 배포도 용이 pre-trained weight 로 대부분의 network computation 을 hardware 에 지원하며, inference 시 일부 변형만 허용 효과적인 bias 만 fine-tuning 하는 방법은 pre-trained transformer 의 fine-tuning dynamic 과 bias term 및 LM 과 new task 간의 transfer 에 대한 흥미를 불러옴","s":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/Composition/BitFit","h":"","p":518},{"i":535,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2210.11416.pdf","s":"Scaling Instruction-Finetuned Language Models","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":537,"t":"instruction 으로 finetuning 한 모델은 모델 성능이나 unseen task 에 대한 생성 능력을 향상 시킨다. 저자는 다음 instruction finetuning 을 탐구 scailing the number of tasks scailing the model size finetuning on chain-of-thought data 저자는 다양한 모델(PaLM, T5, U-PaLM), prompt setups(zero/few-shot, CoT), evaluation benchmarks 에 대해, 극정인 성능 향상을 보이는 것을 발견","s":"Abstract","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":539,"t":"저자는 instruction finetuning 의 두 가지를 접근 instruction finetuning 의 scaling 영향 task 수와 model size 가 함께 잘 확장 되는 것 발견 instruction finetuning 의 추론 작업 수행 능력 CoT (chain-of-thought) 를 포함하지 않은 instruction finetuning 은 CoT 평가에 저하를 일으킴 9개의 CoT dataset 을 추가하니 모든 평가에 대해 더 나은 성능을 보임 540B 의 Flan-PaLM 을 훈련(1.8K Tasks, CoT data)한 결과 Massive Multi-task Language Understanding (MMLU) 에 대해 75.2% 달성 PaLM 과 비교하여 TyDiQA 에 one-shot 으로 14.9% 향상 instruction finetuning Flan-T5 모델은 zero-shot, few-shot 및 CoT 능력이 T5 보다 뛰어남 Flan-T5 11B 는 T5 11B 보다 십의 자리 더 뛰어나며 BIG-Bench task 에서 PaLM 62B 보다 뛰어남 전체적으로 instruction tuning 는 model, prompting, evaluation 전역에서 성능이 향상","s":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":541,"t":"Fig 2 와 같은 데이터 소스를 모아 Fig 3 과 같은 여러 instruction template 으로 instruction finetuning 이 프로세스는 Flan 이며 이러한 과정으로 finetuning 된 모델 앞에 \"Flan\" 을 붙인다. (e.g. Flan-T5)","s":"2. Flan Finetuning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":544,"t":"[Finetuned Language Models Are Zero-Shot Learners] 은 instruction 과 함께 finetuning 의 task 수를 늘려 unseen task 에 대한 일반화를 향상 시켰다. 본 논문에선, 이전 연구의 Muffin (80 tasks), T0-SF (193 tasks), NIV2 (1554 tasks) 및 CoT 를 결합하여 1,836 task 로 확장","s":"Task mixtures.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#task-mixtures","p":534},{"i":546,"t":"CoT annotation 을 포함하여, CoT 에 대한 finetuning 이 unseen task 에 대한 추론 성능 향상시키는지 조사 9 가지 데이터셋의 혼합을 만들며, 이에 arithmetic reasoning, multi-hop reasoning, natural language inference 등을 포함한다.","s":"Chain-of-thought finetuning mixture.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#chain-of-thought-finetuning-mixture","p":534},{"i":548,"t":"Muffin, T0-SF 및 NIV2 의 경우, 데이터셋 창작자가 만든 instructional template 을 사용 CoT 의 경우, 9 가지 데이터셋 각각에 10 개의 instruction template 수동 작성 few-shot template 생성에는, \"Q:/\"\"A\" 같이 다양한 examplar 구분을 작성하며, 이를 무작위 example level 로 적용 (Fig 3)","s":"Templates and formatting.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#templates-and-formatting","p":534},{"i":550,"t":"T5, PaLM, U-PaLM 등 다양한 모델에 instruction finetuning 을 적용 각 모델들의 학습 절차는 learning rate, batch size, dropout, finetuning step 등 일부 hyperparameter 를 제외하고 동일하게 적용 일정한 schedule 및 Adafactor optimizer 사용 multiple training example 을 single sequence 에 결합하기 위해 [T5] 의 packing 을 사용했으며, input 과 target 을 eos sequence token 을 사용하여 분리한다. optimal step 은 held-out-tasks 의 periodic evaluation (모델 크기에 따라 2k ~ 10k step 마다) 를 기반으로 선택됨.","s":"2.2. Finetuning procedure","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#22-finetuning-procedure","p":534},{"i":553,"t":"Flan-PaLM 의 world knowledge 및 reasoning task 성능 평가를 위해 finetuning 에 포함하지 않은 held-out-task 에 평가 MMLU : mathematics, history, medicine 등 57 task 의 exam question 포함 BBH : BIG-Bench 로부터 23 challenging task 포함 TyDiQA : QA benchmark 로, 8 typologically language 포함 MGSM : math 단어 문제로 10 languages 포함","s":"Evaluation benchmarks.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#evaluation-benchmarks","p":534},{"i":555,"t":"MMLU (five-shot), BBH (three-shot) : direct prompting 을 통한 answer 예측 및 CoT prompting 을 통한 추론 능력 모두 평가 TyDiQA (one-shot) : 복잡한 추론을 요구하지 않아, direct prompting exact-match 점수를 측정 MGSM (8-shot) : direct prompting 성능이 낮아, CoT prompting 정확도만 측정 또한 BIG-Bench 에 따른 normalized average metric (macro-average) 을 보고.","s":"Evaluation mathods and metrics.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#evaluation-mathods-and-metrics","p":534},{"i":557,"t":"모델 사이즈 및 finetuning task 수에 대한 scaling 효과 검토 PaLM 모델 8B, 62B 및 540B 에 대해 실험 CoT, Muffin, T0-SF 및 NIV2 를 순차적으로 추가하여 mixture multi-task instruction fietuning 및 no finetuning 을 비교하여 9.4% ~ 15.5% 의 성능 향상 finetuning task 를 늘리면 성능 향상이 있지만, 최대 282 tasks 에서 나타나며, 여기엔 두 가지 이유가 있음 추가 task 가 특별히 다양하지 않아 새로운 knowledge 를 제공할 수 없음 이미 pretraining 에서 알고 있던 knowledge 라서 큰 도움이 되지 않음 모델 사이즈를 한 단계씩 확장하는 것 (8B → 62B or 62B → 540B)이 finetuning 및 non-finetuning 모두 성능 향상","s":"3. Scaling to 540B parameters and 1.8K tasks","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":559,"t":"instruction finetuning mixture 에 CoT 를 포함한 효과를 탐구 여러 벤치마크에서 이전 모델을 능가하는 Flan-PaLM 의 향상된 추론 능력 CoT finetuning data 를 제거하고 CoT 없이 finetuning 수행 시 실제로 추론 능력 하락 CoT finetuning 가 어려운 BIG-Bench task 에서 \"let's think step-by-step\" 으로 zero-shot 추론이 가능한 것을 보여줌","s":"4. Finetuning with chain-of-thought annotations","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":561,"t":"저자는 CoT annotation 을 9 개의 데이터셋 finetuning mixture 에 포함시키는 것이 추론 능력을 향상시켜 주는 것을 보여준다. CoT prompting 이 [self-consistency] 와 결합하여 여러 벤치마크에서 SOTA 를 달성 MMLU 에서 Flan-PaLM 540B 은 75.2% 달성 다국어 math problem 인 MGSM 에서 CoT + SC 로 크게 개선하여 SOTA 달성 GSM8K 에서 Flan-PaLM + CoT + SC 가 83.9% 로 SOTA 달성 저자는 특정 특화된 모델과 비교하여 Flan-PaLM 이 SOTA 를 달성하지 않은 점도 주목 symbolic 조작만 요구되는 BBH-algo 의 경우, CoT + SC 로도 능가하지 못함 one-shot TyDiQA 에서 PaLM 보다 성능은 높지만 SOTA 모델과는 비교할 수준이 아님","s":"4.1. Finetuning on chain-of-thought improves reasoning on held-out tasks","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#41-finetuning-on-chain-of-thought-improves-reasoning-on-held-out-tasks","p":534},{"i":563,"t":"다음으로는, instruction finetuning 에 9개의 CoT 데이터셋을 제거해 본다. CoT 및 non-CoT fintuning 을 결합한 것이 이 CoT 만 finetuning 한 것 보다 성능이 좋았다. 이를 통해 non-CoT task 에서의 성능을 저하시키지 않음을 확인 Fig 5-왼쪽 에서 중요한 점은 CoT 에 대한 finetuning 이 추론 능력 유지에 중요하단 것을 보여준다. Non-CoT 만 finetuning 하는 것은 CoT 성능을 상당히 저하 unseen task 가 finetuning task 와 동일한 prompting paradigm (i.e. non-CoT, CoT)에 속할 때, instruction tuning 이 효과적으로 성능 향상 즉, non-CoT 및 CoT 데이터 모두 모델 향상에 필요","s":"4.2. Some chain-of-thought data is needed to maintain reasoning ability","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#42-some-chain-of-thought-data-is-needed-to-maintain-reasoning-ability","p":534},{"i":565,"t":"exemplar 를 포함하거나 포함하지 않은 CoT 데이터에 대한 instruction finetuning 의 최종 이점은 모델이 zero-shot 세팅에 대한 CoT 추론을 수행하는 것이다. Fig 6 에서 23개의 unseen challenging 인 BBH 벤치마크에서 Flan-PaLM 이 \"let's think step-by-step\" 구문을 사용하여 CoT 추론 수행 성능을 향상시켰다. Fig 7 에서 PaLM 및 Flan-PaLM 의 zero-shot 을 보여준다.","s":"4.3. Unlocking zero-shot reasoning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#43-unlocking-zero-shot-reasoning","p":534},{"i":567,"t":"instruction finetuning 의 일반화를 다양한 사이즈, 아키텍처 및 training objective 의 여러 모델을 적용하여 보여준다. decoder-only 아키텍처인 PaLM 에 대항하여 encoder-decoder 아키텍처인 T5 를 instruction finetuning PaLM 62B 모델에 500B token 을 pretraining 한 cont-PaLM 을 instruction tuning PaLM 540B 에 UL2 objective 로 20k 추가적인 step 으로 pretraining 한 U-PaLM instruction finetuning 은 모든 model 에 비해 큰 마진으로 normalized average 가 향상 instruction finetuning 하지 않은 T5 의 경우 LM-adapted model 을 사용하여 standard language modeling objective 로 100B 추가 토큰으로 훈련 T5 는 non-finetuned 모델과 비교하여 instruction- finetuning 은 이점을 얻음 위 결과로 다음을 얻음 3B 의 Flan-T5-XL : MMLU 52.4% score instruction finetuning 및 UL2 continued pre-training 을 결합한 U-PaLM model 사용 instruction 및 UL2 continued pre-training 은 model scale 을 증가시키지 않고 성능을 향상시키는 compute-efficient method","s":"5. Putting it all together","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":569,"t":"190개 예제로 구성된 평가 생성 5가지 카테고리 (creativity, reasoning over contexts, complex reasoning, planning 및 explanation) 각각 20개 question 포함 60개 examples (complex reasoning, planning 및 explanation) 에는 CoT 구문 (e.g. \"let's think step-by-step\") 생성하여 CoT zero-shot 가능 여부 평가 160개 zero-shot input 에 instruction finetuning 없이 잘 수행되는 30개 few-shot 을 포함 temperature sampling 은 τ=0.7\\tau = 0.7τ=0.7 로 설정하여 5개의 response 를 랜덤으로 선택 length normalization 없이 log probability score 로 rank 매김 score 절반 위로만 선택하는 filtering step 후, best score 선택 이 단계로, 원치 않는 반복 생성을 제거 예로 5개의 생성의 log probability 가 -20 이면, -3 은 반복 생성일 확률이 높아 제거 결과, 평가자들은 PaLM 및 Flan-PaLM 의 190개 examples 에 대해, Fla-PaLM 생성이 79% 의 선호도를 보임 모든 zero-shot 에 대해선 Flan-PaLM 이 큰 폭으로 선호도가 높음 CoT 구문을 사용한 경우, Flan-PaLM 이 10% 정도 증가 few-shot 의 경우, 비교할만한 성능은 없었다. instruction finetuning 된 모델이 open-ended zero-shot input 에 더 좋은 응답을 할 수 있는 능력은 [Training language models to follow instructions with human feedback, InstructGPT] 에서 finetuning LM 이 human feedback 으로 강화학습하여 human evaluation 을 개선시키는 것과 일관성 있다. 또한 PaLM 의 생성을 보면, pretraining on next-token prediction objective 만으로 강력한 성능을 보이지만 좋은 zero-shot 을 충분히 활용하지 못함을 볼 수 있다. PaLM 으로 만들어진 불필요한 행동은 다음을 포함한다. 질문에 답변하는 대신 관련된 텍스트 계속 생성 입력 질문을 약간 수정하여 반복 텍스트 생성을 멈추는 시점을 모름","s":"6. Usability evaluation of open-ended generation","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":571,"t":"본 연구는 instruction finetuning 을 확장 finetuning task 수 확장 모델 사이즈 확장 CoT 데이터에 finetuning instruction-finetuned model 결과 few-shot, zero-shot 및 CoT 등 전역에 성능 향상 다음은 논문 요약이다.","s":"7. Discussion","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":573,"t":"instruction finetuning 의 핵심 키는 모델 사이즈 및 finetuning task 수 확장이 성능 향상으로 이어진다는 것 저자는 scaling curve 를 그렸을 때, 모델 사이즈 및 task 수를 모두 확장하면 계속 성능이 향상될 것이라 예상 했지만, 앞서 282 task 와 1,836 task 가 큰 차이가 없는 것으로 보아, 누적 수를 더할 수록 이득이 줄어드는 경향이 있다. instruction finetuning 을 하지 않은 모델 대비하여 수행한 모델은 개선 폭이 감소하지 않는 것으로 보아 의미있은 역할을 계속 할 것으로 보임.","s":"Scaling curves for instruction finetuning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#scaling-curves-for-instruction-finetuning","p":534},{"i":575,"t":"CoT finetuning 은 추론 능력에 중요한데, 이전 연구에선 unseen non-CoT task 에 대한 non-CoT finetuning 이 성능 향상되는 것을 보였지만, 본 논문에선 이로 인해 CoT task 에 성능 저하가 발생하는 것을 발견 해결책으로 non-Cot 및 CoT 데이터에 jointly finetuning 을 수행 non-CoT 성능을 유지하며 더 나은 CoT 성능을 가능케 함 큰 모델에 대한 CoT finetuning 이 held-out task 에서의 성능을 개선하며 non-CoT 작업의 성능 향상 유지","s":"CoT finetuning is critical for reasoning abilities","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#cot-finetuning-is-critical-for-reasoning-abilities","p":534},{"i":577,"t":"다양한 모델 (decoder-only, encoder-decoder), 사이즈 (T5-80M ~ PaLM-540B) 및 pre-training objectives (causal LM, span corruption 및 prefix LM + span corruption)에 instruction finetuning 을 적용하여, 일반화를 관찰 이는 decoder-only 및 encoder-decoder 에 효과적임을 보여줌. 또한 instruction finetuning 이 UL2R 과 결합하여 강력한 모델 (Flan-U-PaLM)을 만드는 데 잘 결합되는 것을 보여줌","s":"Instruction finetuning generalizes across models","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-generalizes-across-models","p":534},{"i":579,"t":"pre-trained checkpoint 직접사용하면 non-experts 에 challeng next token prediction objective 만으로 언제 생성을 멈출지 모름 사용자 입력에 계속 생성하는 실수를 저지름 Flan-PaLM 출력은 human evaluation 에서 상당한 결과를 보임 (complex reasoning, planning 등의 CoT). 유해한 언어 피해를 측정하는 벤치마크에서도 PaLM 보다 우수한 결과를 보임 이를 통해 instruction finetuning 이 인간의 선호와 일치하는 출력을 생성하는 것을 발견","s":"Instruction finetuning improves usability and mitigates some potential harms","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-improves-usability-and-mitigates-some-potential-harms","p":534},{"i":581,"t":"LM 크기 확장은 성능 향상에 신뢰적이지만, 상당한 계산량이 필요 instruction finetuning 은 상대적으로 적은 양의 컴퓨팅으로 성능을 개선시킨다. PaLM 540B 의 경우, instruction finetuning 은 pre-training 의 0.2% 만 필요, 전반에 걸쳐 평균 9.4% 향상 instruction finetuning 은 작은 모델로도 우수한 성능을 냄","s":"Instruction finetuning is relatively compute-efficient","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-is-relatively-compute-efficient","p":534},{"i":583,"t":"instruction finetuning 으로 확장하여 Flan-PaLM 을 을 훈련 540B parameter 로 확장 1.8K finetuning task 로 확장 chain-of-thought (CoT) 포함 실험 결과 모델 성능이 크게 향상 이전 연구에선 instruction finetuning 이 CoT task 에 성능 저하를 일으키지만, CoT 를 포함하여 jointly finetuning 한 결과 CoT 및 전체 평가에 성능 향상","s":"9. Conclusions","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":534},{"i":585,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2205.05638.pdf","s":"Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":587,"t":"Few-shot in-context learning (ICL)은 pre-trained language model (LM) 이 input 의 일부에 적은 수의 training examples 를 feeding 하여 unseen task 를 gradient-based training 없이 수행하게 했다. ICL 은 all training examples 를 처리해야 하여 계산, 메모리 및 저장 비용이 큼 Parameter-efficient fine-tuning (PEFT) (e.g. adapter modules, prompt tuning, sparse update, etc) 은 모델이 new task 를 수행하도록 훈련된 parameter small set 을 제공하는 paradigm 본 논문은 few-shot ICL 과 PEFT 를 비교하여 PEFT 가 better accuracy 및 lower computational cost 제공을 입증한다. 이 과정에 learned vector 로 activations 를 확장하는 new PEFT 인 (IA)3(IA)^3(IA)3 소개 tiny new parameter 만 도입하여 더 강력한 성능 T0 model 에 기반하는 T-Few 로, new tasks 에 대한 task-specific tuning 또는 modifications 없이 적용할 수 있는 simple recipe 제안 T-Few 를 RAFT benchmark 에 적용함으로써 unseen tasks 에 대한 효과성 검증 super-human 성능을 최초로 6% 로 능가하여 SOTA 달성","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":589,"t":"pre-trained LM 은 NLP 의 중요한 요소 모델로 target task 에 대한 data-efficient 를 크게 향상. 즉, pre-trained LM 을 초기화에 사용하여 less labeled data 에 better results common approach 는 pre-trained LM 의 parameter 를 초기화에 사용한 다음, target downstream task 에 gradient-based fine-tuning 수행 fine-tuning 은 SOTA 를 도출하지만, new parameter set 값을 가지는 single task 에 특화된 모델을 생성하여 여러 downstream task 에 fine-tuning 할 경우 불필요하게 복잡해짐 [Language models are unsupervised multitask learners, Language models are few-shot learners] 에서 인기 있는 alternative approach 는 in-context learning (ICL) 이다. ICL 은 모델이 prompted example 을 inputting 하여 downstream task 를 수행하도록 유도 Few-shot prompting 은 input-target pairs 를 예측이 필요한 single unlabeled example 을 따라, human-understandable instructions 및 example 로 변환 ICL 은 gradient-based training 이 필요하지 않아, single model 은 즉시 다양한 task 에 수행 가능 따라서, ICL 은 pre-training 중에 모델이 학습한 능력에만 의존하며, 이 특성으로 인해 ICL 방법에 관심이 쏠림 ICL 은 위 이점에도 불구하고 여러 단점 존재 모델이 예측할 때마다 prompted input-target pairs 를 모두 처리하면 상당한 계산 비용 발생 ICL 은 일반적으로 fine-tuning 보다 성능 떨어짐 prompt 의 exact formatting (단어 선택 및 예제 순서 포함)이 모델의 성능에 미치는 영향을 예측 불가능 최근 ICL 이 incorrect labels 를 제공해도 잘 수행하는 점을 보여주며, 얼마나 많은 학습이 이루어지는지에 대한 의문 제기 model 이 new task 수행을 위해 minimal updates 로 모델을 활성화하는 추가적인 패러다임인 parameter-efficient fine-tuning (PEFT) pre-trained model 에 추가 또는 선택된 small parameter 만 update 하여 fine-tuning 최근 전체 모델의 subset parameter (e.g. 0.01%)만 update 하거나 추가하여 fine-tuning 과 동등한 성능 달성 특정 PEFT 은 batch 내의 examples 를 다르게 처리하는 mixed-task batches 를 허용하여 PEFT 및 ICL 은 multitask models 모두에 적합 PEFT 의 이점은 fine-tuning 의 일부 단점을 해소하지만, 매우 적은 양의 label data 만 사용 가능할 경우 PEFT 방법이 잘 작동하는지에 대한 연구가 적다. 본 논문의 주요 목표는 이 공백을 메우기 위해 model, PEFT method 및 fixed hyperparameter set 을 사용하여, 모델의 일부 parameter 만 업데이트하며 novel, unseen task 에서 강력한 성능을 달성하는 recipe 제안 저자의 approach 는 T0 model 을 기반 이 모델은 T5 의 변형으로 다양한 prompt dataset 의 multitask mixture 을 fine-tuning 한 것 classification 및 multiple-choice tasks 성능 향상을 위해 unlikelihood 및 length normalization-based loss term 추가 intermediate activations 를 learned vectors 와 곱하는 PEFT method (IA)3(IA)^3(IA)3 개발 (IA)3(IA)^3(IA)3 은 parameter 를 최대 10,000배 적게 업데이트하며 full fine-tuning 보다 강력한 성능 달성 저자의 T-Few recipe 는 ICL (16배 큰 모델과 비교) 에 비해 상당히 더 나은 성능 발휘 real-world few-shot learning 벤치마크 RAFT 에서 처음으로 human 능가 less compute 및 inference 중 mixed-task batches 가능","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":592,"t":"PEFT 는 small storage requirement 및 computational cost 로 model 을 new task 에 adapting 할 가능성을 제시하여 ICL 의 대안으로 유망함 따라서 저자는 computational 및 storage cost 를 최소화하며 inference 중 mixed-task batches 가 가능한, limited labeled examples 로 new task 에 높은 정확도를 달성할 수 있는 recipe 개발이 목표 여기서 recipe 란 new task 에서 강력한 성능을 제공하는 model 및 hyperparameter 설정을 의미하며, manual tuning 이나 per-task adjustments 없이 강력한 성능을 보장할 수 있는 것이다. 이를 평가하기 위해 limited labeled data 만 사용 가능한 few-shot settings 에서 approach 가 실질적인 옵션임을 보장할 수 있다.","s":"3. Designing the T-Few Recipe","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":594,"t":"limited labeled examples 로 fine-tuning 후에도 성능이 높은 이상적인 pre-trained model 선택에 있어, PEFT method 적용으로 best 성능을 달성한 T0 채택. T0 는 T5 기반이며, unlabeled text data 인 large corpus 의 masked language modeling objective 로 pre-training 한 encoder-decoder Transformer dataset multitask mixture 을 기반으로 T5 를 fine-tuning 하여 zero-shot generalization 가능 (i.e. additional gradient-based training 없이 task 수행) T0 training 에 사용된 dataset examples 는 Public Pool of Prompts (P3) 의 prompt templates 를 적용한 prompted 이며, prompted text-to-text format 으로 변환 T0 는 3B 와 11B parameter 를 제공하며 각각 \"T0-3B\" 및 \"T0\" 로 지칭 T0 는 zero-shot generalization 을 위해 설계되었지만, 저자는 few labeled example 만으로 fine-tuning 후에도 강력한 성능을 달성하는 것을 증명 T0 generalization 능력 테스트를 위해 multitask training mixture 에서 제외할 task 선택 sentence completion (COPA, H-SWAG 및 Stroy Cloze datasets) natural language inference (ANLI, CB 및 RTE) coreference resolution (WSC 및 Winogrande) word sense disambiguation (WiC) 또한 RAFT 벤치마크에서 T-Few 의 능력을 Sectiopn 4.3 에서 테스트 RAFT 는 validation 및 held-out test set 없이 unseen \"real-world\" few-shot collection 평가에는 \"rank classification\" 을 사용하며, all possible label strings 에 대한 모델의 log-probabilities 는 순위를 지정하며, 가장 높은 순위의 choice 는 가 올바른 답일 경우 모델 예측이 올바르다 간주 Rank classification evaluation 은 classification 및 multiple choice tasks 모두와 호환 모델 성능은 prompt template 에 따라 크게 다르므로 각 데이터셋에 대한 all prompt template 를 median accuray 로 보고 test label 이 public 이 아닐 경우 (e.g. SuperGLUE) test set 또는 validation set 에 대한 정확도를 보고 본문에선 위에서 언급한 9개 데이터셋에 대한 median accuracy 보고","s":"3.1 Model and Datasets","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#31-model-and-datasets","p":584},{"i":596,"t":"PEFT 연구 전에, 저자는 LM 의 few-shot fine-tuning 의 성능 향상을 위한 두 가지 additional loss terms 탐구 LM 은 보통 cross-entropy loss LLM=−1T∑tlog⁡p(yt∣x,y<t)L_{LM} = -\\frac{1}{T} \\sum_t \\log p (y_t | \\text{x}, y_{<t})LLM​=−T1​∑t​logp(yt​∣x,y<t​) 로 훈련된다. input sequence x\\text{x}x 에 대한 correct target sequence y=(y1,y2,…,yT)\\text{y} = (y_1, y_2, \\dots, y_T)y=(y1​,y2​,…,yT​) 의 probability 가 증가하도록 훈련 평가를 위해, 모델의 correct/incorrect choice 의 probability 에 따라 다른 rank classification 사용 LUL=−∑n=1N∑t=1T(n)log⁡(1−p(y^i(n)∣x,y^<t(n)))∑n=1NT(n)\\begin{equation} L_{\\text{UL}} = -\\frac{\\sum^N_{n=1} \\sum^{T^{(n)}}_{t=1} \\log (1 - p (\\hat{y}_i^{(n)}|\\text{x}, \\hat{y}^{(n)}_{<t}))}{\\sum^N_{n=1}T^{(n)}} \\end{equation}LUL​=−∑n=1N​T(n)∑n=1N​∑t=1T(n)​log(1−p(y^​i(n)​∣x,y^​<t(n)​))​​​ 모델이 incorrect target sequence 의 tokens 을 예측하는 것을 억제한다. incorrect target sequence y^(n)=(y^1,y^2,…,y^T(n)\\hat{\\text{y}}^{(n)} = (\\hat{y}_1, \\hat{y}_2, \\dots, \\hat{y}_{T^(n)}y^​(n)=(y^​1​,y^​2​,…,y^​T(n)​ 는 NNN 개 incorrect target sequence 의 nnn-th LULL_{\\text{UL}}LUL​ 을 추가하여 rank classification 결과가 개선될 것으로 가정 이는 모델이 incorrect choice 에 더 낮은 확률을 할당하도록 훈련되므로 correct choice 가 가장 높은 순위로 ranking 될 가능성이 향상될 것으로 예상 training example 에 대한 possible target sequence 는 길이가 다양하며, 특히 multiple-choice tasks 에서 더 그렇다. 각 choice 를 proability 에 따라 ranking 매기면 모델은 더 shorter choice 를 선호한다. 이는 각 token 에 할당된 확률이 ≤1\\leq 1≤1 이기 때문이다. 이를 보정하기 위해 rank classification 수행 시에 length normalization 사용을 고려한다. length normalization 은 모델이 각 possible answer choice 에 대한 score 를 choice token 수로 나누어 계산하는 방법 (GPT-3 에서 사용됨) evaluation 중 length normalization 을 사용할 때는 training 중 length-normalized evaluation 을 더 정확히 반영하는 additional loss 도입 먼저, 주어진 output sequence 의 length-normalized log probability β(x,y)=1T∑t=1Tlog⁡p(yt∣x,y<t).\\beta(\\text{x}, \\text{y}) = \\frac{1}{T}\\sum^T_{t=1} \\log p(y_t|\\text{x},y_{<t}).β(x,y)=T1​∑t=1T​logp(yt​∣x,y<t​). 을 계산 그 후, Eq. 2 의 softmax cross-entropy loss 를 최소화함으로써 correct answer choice 의 length-normalized log probability 최대화 LLN=−log⁡exp⁡(β(x,y))exp⁡(β(x,y))+∑n=1Nexp⁡(β(x,y^(n)))\\begin{equation} L_{\\text{LN}} = - \\log \\frac{\\exp(\\beta(\\text{x}, \\text{y}))}{\\exp(\\beta(\\text{x}, \\text{y})) + \\sum^N_{n=1} \\exp(\\beta(\\text{x}, \\hat{\\text{y}}^{(n)}))} \\end{equation}LLN​=−logexp(β(x,y))+∑n=1N​exp(β(x,y^​(n)))exp(β(x,y))​​​ LLML_{\\text{LM}}LLM​, LULL_{\\text{UL}}LUL​ 및 LLNL_{\\text{LN}}LLN​ 을 사용하여 모델을 training 할 때 이 loss 들을 단순히 합한다. 이는 few-shot setting 에 tuning 하기 어려운 hyperparameter 도입을 파하기 위함 LLML_{\\text{LM}}LLM​ 추가로 정확도가 60.7% → 62.71% 향상 모두 포함하면 63.3% 로 더 개선 이러한 loss 들은 additional hyperparameter 를 도입하지 않고도 성능을 향상시키므로 저자의 recipe 에 포함하고 이후 모든 실험에도 사용","s":"3.2 Unlikelihood Training and Length Normalization","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#32-unlikelihood-training-and-length-normalization","p":584},{"i":598,"t":"few-shot ICL 과 유리한 비교를 위해 다음 PEFT 특성이 필요 storage 및 memory cost 발생하지 않기 위해 가능한 한 few parameter 만 추가하거나 업데이트 new task 에 대해 few-shot training 후에도 강력한 정확도 달성 ICL 기능 중 하나인 mixed-task batches 허용성 mixed-task batches 이 가능하면서 PEFT 방법을 지키려면 모델 자체를 수정하면 안된다. 위를 만족시키기 위해선 batch 의 각 examples 를 다른 모델 또는 computational graph 로 처리해야 한다. example 이 어떤 task 에 해당하는지에 따라 batch 의 각 examples 에 독립적이고 비용이 저렴하게 수행 가능하여 모델의 activations 를 직접 수정하는 방법이 대인일 수 있다. Prompt tuning 및 Prefix-tuning 은 learned vectors 를 activation 또는 embedding sequence 에 연결하여 작동하므로 mixed-task batches 를 허용하는 activation-modifying PEFT method 의 예이다. 하지만 합리적인 정확도를 얻지 못하였으며, 성능이 좋은 다른 PEFT method 는 mixed-task batches 를 허용하지 않음 위 사항으로 저자는 새로운 PEFT 방법을 개발 대안으로, 저자는 모델의 activations 와 learned vector 간의 element-wise multiplication (i.e. rescaling) 을 탐구 저자는 l⊙xl \\odot xl⊙x 형태의 adaptation 고려 l∈Rdl \\in \\mathbb{R}^dl∈Rd : learned task-specific vector ⊙\\odot⊙ : element-wise multiplication x∈RT×dx \\in \\mathbb{R}^{T \\times d}x∈RT×d : activations 의 length-TTT sequence \"broadcasting notation\" 을 사용하여 l⊙xl \\odot xl⊙x 의 (i,j)th(i, j)^{th}(i,j)th entry 는 ljxi,jl_j x_{i,j}lj​xi,j​ 이다. 예비 실험에선, Transformer 모델의 각 activation set 에 대한 learned rescaling vector 를 도입할 필요가 없음을 발견 대신, self-attention 및 encoder-decoder attention 매커니즘에서 key, value 에 rescaling vector 도입 position-wise feed-forward network 의 intermediate activation 에도 rescaling vector 를 도입 구체적으로, 다음과 같이 attention 매커니즘 도입 position-wise feed-forward 네트워크의 중간 활성화에도 재조정 벡터를 도입하는 것이 충분하다는 것을 발견했습니다. 구체적으로, Vaswani et al. [33]의 표기법을 사용하여 우리는 다음과 같이 attention 메커니즘에 도입합니다: softmax(Q(lk⊙KT)dk)(lv⊙V)\\begin{equation} \\text{softmax}\\left ( \\frac{Q(l_k \\odot K^T)}{\\sqrt{d_k}} \\right ) (l_v \\odot V) \\end{equation}softmax(dk​​Q(lk​⊙KT)​)(lv​⊙V)​​ 또한 position-wise feed-forward network 에서는 (lff⊙γ(W1x))W2(l_{ff} \\odot \\gamma (W_1 x))W_2(lff​⊙γ(W1​x))W2​ 형태로 도입 γ\\gammaγ : feed-forward network nonlinearity 각 Transformer layer block 마다 별도의 lkl_klk​, lvl_vlv​ 및 lffl_{ff}lff​ vector set 을 도입 이로 인해 LLL-layer-block Transformer encoder 에 L(dk+dv+dff)L(d_k + d_v + d_{ff})L(dk​+dv​+dff​) new parameter 추가 LLL-layer-block decoder 에는 L(2dk+2dv+2dff)L(2d_k + 2d_v + 2d_{ff})L(2dk​+2dv​+2dff​) (self-attention 및 encoder-decoder attention 모두가 있어 2 factor 존재) 가 추가 lkl_klk​, lvl_vlv​ 및 lffl_{ff}lff​ 는 모두 1로 초기화되어 있으므로 이러한 vecotrs 가 추가 되면 모델이 계산하는 전반적인 함수는 변경되지 않는다. 저자는 위와 같은 방법을 (IA)3(IA)^3(IA)3 이라 부르며, \"Infused Adapter by Inhibiting and Amplifying Inner Activations\" 의 약자다. (IA)3(IA)^3(IA)3 은 batch 내의 각 activations sequence 는 learned task vector 에 의해 별도로 및 저렴하게 multiple 되므로 mixed-task batches 를 가능하게 함 또한 모델이 single task 에만 사용될 것이라면, (IA)3(IA)^3(IA)3 의 도입으로 인한 수정은 weight matrices 에 영구적으로 적용하여 elementwise multiplication 이 필요하지 않고 model architecture 가 변경되지 않도록 할 수 있다. 이는 (IA)3(IA)^3(IA)3 에서 수행된 element-wise multiplication 이 항상 matrix multiplication 과 동시에 발생하기 때문이다. l⊙Wx=(l⊙W)xl \\odot W x = (l \\odot W) xl⊙Wx=(l⊙W)x 이 경우, original model 과 비교하여 (IA)3(IA)^3(IA)3 는 additional computational cost 를 부담하지 않는다. (IA)3(IA)^3(IA)3 검증을 위해, held-out task 의 few-shot dataset 에서 fine-tuning T0-3B 에 대한 저자의 설정에서 다양한 adaptation methods 를 비교 9 가지 강력한 PEFT 방법들과 비교한다. BitFit : bias parameter 만 update Adapters : self-attention 및 position-wise feed forward networks 후 task-specific layer 도입 Compacter 및 Compacter++ : low-rank matrices 및 hypercomplex multiplication 을 사용하여 adapter 개선 Prompt tuning : model input 에 연결되는 task-specific prompt embeddings 학습 FISH Mask : Fisher information 에 기반하여 업데이트할 parameter subset 을 선택 Intrinsic SAID : low-dimensional subspace 에서 optimization 수행 Prefix-tuning : model 의 activations 에 연결되는 task-specific vectors 학습 LoRA : parameter matrices 에 low-rank 를 할당 추가적으로 저자는 baseline full fine-tuning 및 layer normalization parameter 만 업데이트하는 것 포함 결과는 Fig. 2 에서 확인 가능 (IA)3(IA)^3(IA)3 은 full fine-tuning baseline 보다 높은 정확도 달성 다른 PEFT 는 parameter update 또는 introduce fewer parameter 이지만 (IA)3(IA)^3(IA)3 은 훨씬 우수한 성능 발휘 Compacter 및 Compacter++ 는 few-shot setting 에서 full fine-tuning 보다 뛰어나다 하며, prompt tuning 은 full fine-tuning 과 일치할 수 있다고 발견 했지만, 두 경우엔 다양한 hyperparameter choices 시도 위 경우는 다른 모델 및 다른 데이터셋에서 비롯되어, 검증셋 성능이 training 과정 중 급격하게 변동할 수 있어 최적화 문제 가능성 시사","s":"3.3 Parameter-efficient fine-tuning with (IA)3(IA)^3(IA)3","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#33-parameter-efficient-fine-tuning-with-ia3","p":584},{"i":600,"t":"최근 prompt tuning 에서 prompt embeddings 를 pre-training 하는 것이 downstream few-shot tasks 를 fine-tuning 할 때 성능 향상시키는 것 보여줌 이전 연구에서 unlabeled text data 에 적용되는 self-supervised tasks 를 사용하거나 separate task 또는 multitask mixture 로부터의 embeddings 를 사용하는 것을 고려했다. 저자는 전자를 따라, (IA)3(IA)^3(IA)3 에 의해 도입된 new parameter 를 T0 훈련에 사용된 동일한 multitask mixture 에 간단히 pre-training 한다. 16 batch size 로 100,000 steps pretraining 후 (IA)3(IA)^3(IA)3 parameter 를 각 개별 downstream dataset 에 대해 fine-tuning 저자의 pre-training 이 fine-tuning 정확도를 64.6 에서 65.8 로 향상시켜 recipe 에 추가","s":"3.4 Pre-training (IA)3(IA)^3(IA)3","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#34-pre-training-ia3","p":584},{"i":602,"t":"요약하면 T-Few recipe 는 다음과 같이 정의 T0 모델을 백본으로 사용 downstream task adaptation 을 위해 (IA)3(IA)^3(IA)3 사용 T0 와 동일한 multitask mixture 에서 pre-training 한 (IA)3(IA)^3(IA)3 으로 초기화된 parameter objective 로는 standard language modeling loss LLML_{\\text{LM}}LLM​, incorrect choices 에 대해선 unlikelihood loss LULL_{\\text{UL}}LUL​ 및 length-normalized loss LLNL_{\\text{LN}}LLN​ 사용 다음 hyperparameter 로 학습 learning rate 3e−3e^{-3}e−3 linear decay schedule 60 step warmup Adafactor optimizer 8 sequence 의 batch size 1,000 steps training 및 inference 중 downstream dataset 에 prompt template 을 적용하여 각 example 을 instructive text-to-text 형태로 변환 중요한 점은, 위 recipe 를 각 downstream dataset 에 동일한 방식으로 적용하며 per-dataset hyperparameter tuning 및 modifications 없이 사용 이는 recipe 가 validation sets 가 적은 few-shot learning setting 에서 실용적인 옵션으로 사용될 수 있다.","s":"3.5 Combining the ingredients","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#35-combining-the-ingredients","p":584},{"i":604,"t":"T-Few recipe 를 T0-3B 에 설계 및 확립 후, T0 (11B) 에 적용하여 strong few-shot ICL baseline 과 성능 비교 그리고 모든 task 에 대해 동일한 recipe 및 hyperparameter 를 사용","s":"4. Outperforming ICL with T-Few","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":606,"t":"먼저 T0 의 training mixture 에서 제외된 dataset 에 대한 T-Few 성능 평가 저자는 T0 의 zero-shot learning 과 비교한다. (T0 에 대한 zero-shot 보다 few-shot ICL 이 성능이 떨어지는 것을 확인하였기 때문) T5+LM 으로 few-shot ICL (T0 기반으로 하는 next-step-prediction LM) GPT-3 의 6.7, 13 및 175B 의 few-shot ICL T-Few 는 다른 방법보다 훨씬 큰 마진으로 성능 우수 특히 16배 작은 크기에도 GPT-3 175B 의 few-shot ICL 보다 6% 높은 정확도 달성 smaller GPT-3 보다 훨씬 큰 마진으로 성능 높임 T-Few 는 T0 zero-shot learning 및 T5-LM 의 few-shot ICL 보다 높은 정확도 달성","s":"4.1 Performance on T0 tasks","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#41-performance-on-t0-tasks","p":584},{"i":608,"t":"T-Few 가 ICL-based models 을 크게 앞선 성능을 보여줬으므로 이제 각 few-shot learning approach 에서 상대적인 cost 를 비교한다. 단순성을 위해, Transformer-based LM 에 대한 FLOPs-per-tokens estimates 를 사용한다. 구체적으로, NNN parameter 를 가진 decoder-only Transformer (e.g. GPT)가 interence 에는 2N2N2N FLOPs per token 을 사용하고 training 에는 6N6N6N FLOPs per token 을 사용한다고 추정 T0 및 T5 같은 encoder-decoder 모델 (encoder 와 decoder 가 동일한 layer 수 및 크기를 가지는 경우) 은 각 token 을 encoder 또는 decoder 중 하나만 처리하므로 FLOPs per token estimates 는 inference 및 training 에 각각 NNN 및 3N3N3N 이 사용된다. FLOPs 는 real-world computational cost 가 아니므로 latency, power usage 및 other costs 등에 따라 다양한 비용 발생 가능. 하지만 하드웨어 설정이 크게 다를 것으로 예상되므로 FLOPs 에 중점을 둠 cost 에 대한 요약은 Table 1 에서 제공 저자는 dataset 의 중간 수의 shot (41) 사용 rank evaluation 및 unlikelihood loss 두 경우엔 unlabeled example 에 대한 prediction 을 얻기 위해 모든 possible output choice 를 처리해야 한다. input 및 all possible target 에 대해 combined tokenized sequence length 중간 값은 저자가 고려한 데이터셋에서 103 이다 few-shot ICL 로 처리된 in-context examples 의 경우 correct target 만 필요하므로, median sequence length 는 98 이다. ICL 로 single example 을 처리하는데 필요한 것은 41×98+10341 \\times 98 + 10341×98+103 token 이다.","s":"4.2 Comparing computational costs","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#42-comparing-computational-costs","p":584},{"i":610,"t":"향상된 정확도 외에도 few-shot ICL 을 피하는 주된 이점은 inference costs 가 크게 낮아지는 것 T-Few 를 사용하여 single input 및 all target choice 를 처리하려면 11e9×103=1.1e1211e9 \\times 103 = 1.1e1211e9×103=1.1e12 FLOPs 가 필요하다 GPT-3 175B 를 사용한 few-shot ICL 은 2×175e9×(41×98+103)=1.4e152×175e9× (41 × 98 + 103) = 1.4e152×175e9×(41×98+103)=1.4e15 FLOPs 가 필요 Section 2.1 에서 언급했듯이, same in-context examples set 을 재사용할 때 key 와 value vectors 를 caching 하면 ICL 의 computational cost 를 줄일 수 있다. 이는 약 41배 정도만 감소시켰으며, GPT-3 ICL costs 를 T-Few 만큼 충분히 낮추진 못한다.","s":"Inference cost","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#inference-cost","p":584},{"i":612,"t":"T-Few 는 updating parameter 를 수반한 방법이기 때문에 training cost 발생 11B encoder-decoder model 을 103 length sequence 의 8 batch size 로 1,000 steps training 하는데 약 3×11e9×1,000×8×103=2.7e163 × 11e9 × 1, 000 × 8 × 103 = 2.7e163×11e9×1,000×8×103=2.7e16 FLOPs 가 필요 few-shot ICL 을 사용한 GPT-3 175B 의 single example 처리에 필요한 FLOPs 의 약 20배 더 크다. T-Few training cost 는 GPT-3 175B 를 사용한 few-shot ICL 로 20 examples 처리하는데 드는 비용만큼 사용 single dataset 에서 T-Few 로 T0 를 fine-tuning 하는데 single NVIDIA A100 GPU 로 약 30분 밖에 안걸림","s":"Training cost","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#training-cost","p":584},{"i":614,"t":"T-Few 는 가장 큰 Storage cost 발생 (IA)3(IA)^3(IA)3 에 의해 추가된 parameter 는 single-precision floats 로 저장될 때, 4.2MB dist space 를 차지 반면, ICL method 는 tokenized in-context example 만 저장하므로 (일반적으로 32-bit integers), 41×98×32bits=1641 × 98 × 32 bits = 1641×98×32bits=16kB disk space 요구 하지만 4.2MB 는 model checkpoint 와 비교하면 미미 10,000 개 task 에 대한 adaptation vectors (IA)3(IA)^3(IA)3 를 저장하는 데는 T0 checkpoint (41.5GB) 만큼의 space 필요 그러나 4.2MB는 모델 체크포인트 자체의 디스크 크기와 비교하면 미미합니다. 10,000개의 작업에 대한 (IA)3 적응 벡터를 저장하는 데는 T0 체크포인트(약 41.5GB)만큼의 공간이 필요합니다.","s":"Storage cost","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#storage-cost","p":584},{"i":616,"t":"inference 중 memory usage 는 model parameter 에 의해 발생 T-Few 는 inference 중에 더 낮은 memory usage 소요 training 중에는 backpropagation 을 위해 intermediate activations 를 caching 하고 Adafactor 의 gradient accumulator 변수를 위한 memory usage 소요 하지만 위에서 언급했듯, T-Few recipe 를 single 80GB A100 GPU 로 사용 가능","s":"Memory usage","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#memory-usage","p":584},{"i":618,"t":"few-shot learning 에 대해 성능 평가를 하며, real world 에서의 T-Few 성능을 더 잘 평가하기 위해 RAFT 에서 평가 RAFT 는 real-world applications 를 반영하는 11 가지 task 구성 각 RAFT datasets 는 validation 및 test set 없으며 public label 이 없는 50 training example 만 가지고 있음 unrealistically-large validation set 또는 test set 에 tuning 하는 속임수를 쓸 수 없다는 점 T-Few 를 adapting 하기 위해 dataset 과 함께 제공된 standard prompt 사용 top-5 정확도는 Table 2 에 표시 T-Few 는 75.8 의 SOTA 정확도 달성 인간 기준 (73.5%) 능가 위 결과로 T-Few 가 강력한 성능을 달성하기 위해 new real-world task 에 즉시 적용 가능함을 검증","s":"4.3 Performance on Real-world Few-shot Tasks (RAFT)","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#43-performance-on-real-world-few-shot-tasks-raft","p":584},{"i":620,"t":"T-Few design 실험은 T0-3B 에서 진행하여, T0 에서 T-Few Ablation 실험 수행 각 구성 요소를 추가함으로써 얻는 이득이 각 개별 데이터셋의 정확도를 크게 증가시키진 않지만, 데이터셋 전체에서 평균 성능을 일관되게 향상 pre-training 을 제거하면 정확도가 1.6% 감소하며, unlikelihood training 및 length normalization 을 제거하면 정확도가 4.1% 감소하며, 모두 제거하면 2.5% 감소했다.","s":"4.4 Ablation experiments","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"#44-ablation-experiments","p":584},{"i":622,"t":"저자는 T-Few recipe 소개 few-shot learning 에 대한 computational cost 가 낮은 parameter-efficient recipe few-shot ICL 보다 높은 정확도 달성 T-Few 에 (IA)3(IA)^3(IA)3 라는 새로운 PEFT 방법 사용 learned vectors 로 inner activations 를 rescales full fine-tuning 보다 훨씬 적은 additional parameter 로 더 나은 성능 T-Few 는 incorrect choice 에 대한 lower probability 를 outputting 하고 다양한 answer choices 의 length 를 고려하기 위해 두 가지 loss 사용 T-Few 를 그대로 RAFT 에 적용할 때, human 성능을 뛰어 넘음 computational costs 의 detailed characterization 을 통해 T-Few 가 few-shot ICL 과 비교하여, inference 중 1,000배 이상 fewer FLOPs 를 사용 single NVIDIA A100 GPU 에 30 분 만에 훈련 가능 모든 실험은 classification tasks 이기 때문에 summarization 및 QA 같은 generation task 에 대해서도 T-Few 적용 가능할 것으로 보이며, LLM 을 사용한 few-shot learning 을 최적으로 수행하는 것에 대한 새로운 관점의 제공을 추후 연구 필요","s":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Composition/IA³","h":"","p":584},{"i":624,"t":"논문 및 이미지 출처 : https://aclanthology.org/2023.emnlp-main.22.pdf","s":"Parameter-efficient Tuning for Large Language Model without Calculating Its Gradients","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":626,"t":"large language models (LLMs) 의 fine-tuning 은 상당한 자원과 시간 소모가 필요하다. 최근 adapter tuning, prefix tuning 및 LoRA 같은 peft method 가 나오고 있지만, gradient 및 backpropagation 이 여전히 필요하여 약 30% 의 훈련 메모리 요구만 절약한다. 본 논문에선 gradients 계산이 필요없는 새로운 PEFT 를 제안한다. 동일한 task 에서 LLMs 및 SLMs 로 학습된 PEFT module 의 유사성을 활용하여, SLMs 로부터 파생되어 초기화한 peft module 을 LLMs 로 transferring 하는 전략 부드럽고 효과적인 adaptation process 를 보장하기 위해, Bridge model 을 도입하여 모델 간의 동적인 상호작용을 동시에 수행하며, 차원적 일관성을 보장 T5 및 GPT-2 를 SuperGLUE 에 평가하여 효과성을 입증 gradient-based optimization 없이 fine-tuning 및 peft 와 comparable 다른 peft 와 비교하여 약 5.7X 메모리 절약","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":628,"t":"GPT3, GPT4, T5-XXL, LLaMA 등 LLMs 의 놀라운 능력을 보여주지만 일반적인 하드웨어로 fine-tuning 하기에 매우 어렵다. 이에 일부 작은 파라미터만 수반하여 이들만 fine-tuning 하는 peft methods 가 등장한다. Adapter tuning : Transformer 의 layers 에 small task-specific modules 을 삽입하여 task-specific information 만 학습 Prefix tuning : task-specific trainable prompt tokens 를 모든 Transformer layer 의 hidden states 앞에 붙임 LoRA : 각 layer 의 frozen weights 에 low-rank 및 trainable matrices 를 병합 Fig. 1(a) 에선 RTE dataset fine-tuning 에서의 PEFT GPU memory 사용량을 보여준다. 30% 의 GPU memory 사용을 절약하지만 여전히 gradient-based optimization 을 사용한다. 이를 해결하기 위해, 저자는 gradients 계산이 필요 없는 새로운 PEFT 를 제안한다. LLMs 및 SLMs 은 task-specific 특성을 유사하게 학습 RTE task 에 peft method 를 실험했을 때 이 가설을 검증할 수 있다. (Fig. 1(b)) GPT2-XL 및 GPT2-base 또는 GPT2-medium 의 peft modules 간의 유사성을 계산한 결과 cosine similarity 가 75% 에 도달하였다. 위 관찰에 감명받아, SLMs 에서 훈련된 task-specific 특성을 LLMs 에 transfer 한다. 이에 gradient-based optimization 없이 LLM 에 task-specific 능력의 질을 높일 수 있다. 먼저 downstream task 의 task 특성을 학습하기 위해 기존 peft 를 SLM 에 활용한다. 이후 SLM 으로부터 얻은 peft module 을 LLM 에 직접적으로 적용하면 dimention mismatch 및 limited interaction 으로 인한 이슈가 발생하므로, 이를 해결하기 위해 저자는 projection module 을 채택한다. SLMs 및 LLMs 사이의 peft dimension 을 align PEFT 및 LLM 사이의 interaction 질을 높여줌 Bridge model 을 도입하여 LLM knowledge 를 유지해주며, LLM dimensions matching 및 peft module interaction 을 얻을 수 있다. 마지막으로 inference 를 위해 peft module 을 LLM 에 plug 한다. T5 및 GPT2 로 SuperGLUE 벤치마크에서 효율성을 입증한다. 추가로 다른 peft 와 비교하여 5.7X memory 를 절약할 수 있다. SLMs 와 LLMs 의 downstream task 에 대한 peft 적용에서 상당한 task simiarity 를 발견 SLM 에서 학습된 peft modules 를 LLM 에 adaptation 하는 gradient-free method 제안 T5 및 GPT2 를 SuperGLUE 에 실험하여 효과성을 입증하고 다른 peft 와 비교하여 5.7X 메모리 사용량 절약","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":630,"t":"먼저 training stage 중 peft method 를 사용하여 SLM 에 task-specific 특성을 학습한다. 이후 Bridge model 및 peft module 을 fine-tuning 하여 peft module 의 knowledge 를 향상시킨다. 마지막으로, inference state 중에 peft module 을 LLM 에 plug 한다. Plug-in and Bridge Model Fine-tuning​ 먼저 SLM 에 Adapter, LoRA, Prefix-tuning 같은 peft 를 활용하여 downstream task 특성을 학습한다. 이를 LLM 에 직접 적용하면 두 가지 이슈가 발생한다. dimension mismatch 이를 해결하기 위해 linear projection module WplugW_{plug}Wplug​ 를 Plug-in model 로 사용하여 peft module 의 dimension 을 align SLM 은 보통 LLM 보다 적은 layers 를 가지므로, peft module 의 layers 를 duplicating 하여 layer mismatch 를 해결 이 duplication 은 LLM 와의 layer alignment 를 가능하게 함 limited interaction peft 를 LLM 에 성공적으로 adapting 하려면 상당한 상호작용이 필요 interaction 향상을 위해, Bridge model 을 도입하여 LLM knowledge 를 유지하면서 peft module 과 interacting pruning method 인 Laddersize-tuning (Sung et al., 2022) 을 채용하여 Bridge model 로 사용. LLM fff 의 각 layer 을 pruning 하는 과정을 포함한다. 저자는 linear projections 을 사용하여 LLM fff 의 각 intermediate activations 및 word embeddings 를 lower-dimensional Bridge model ggg 로 downsampling reduction factor rrr 은 8, 16, 32, 64 등 사용 LLM 의 주요 정보를 유지하기 위해 Fisher information 을 활용하여 LLM 의 파라미터를 pruning 하고 initial Bridge model ggg 를 얻는다. Fisher information 은 LLM parameter 의 중요성을 효과적으로 평가할 수 있다. backbone network 의 W∈Rdb×dlW \\in \\mathbb{R}^{d_b \\times d_l}W∈Rdb​×dl​ 이 dld_ldl​-dim vectors 를 dbd_bdb​-dim space 로 매핑하는 경우, 다음 식을 통해 각 weight vector importance 를 계산한다. W=1∣D∣∑i=1∣D∣(▽Wlog⁡p(yi∣xi))2,W = \\frac{1}{|D|}\\sum^{|D|}_{i=1}(\\triangledown_W \\log p(y_i|x_i))^2,W=∣D∣1​i=1∑∣D∣​(▽W​logp(yi​∣xi​))2, (xi,yi)(x_i, y_i)(xi​,yi​) : data DDD 의 samples WWW 의 rows 및 columns 을 유지하여 dbr\\frac{d_b}{r}rdb​​ 및 dlr\\frac{d_l}{r}rdl​​ importrance score 를 가진다. Transformer 각 layer 에 위 과정을 반복하여, weight matrices set WB∈Rdbr×dlrW_B \\in \\mathbb{R}^{\\frac{d_b}{r} \\times \\frac{d_l}{r}}WB​∈Rrdb​​×rdl​​ 를 얻으며, backbone network 에 1/r1/r1/r 번 prunining 을 겪게하고, 이를 Bridge model 로 초기화하여 활용 이후, SML 에서 학습된 peft modules (Adapter, LoRA, Prefix tuning) 이 Bridge model 과 상호작용하도록 하기 위해 linear projection module WdownW_{down}Wdown​ 을 peft 에 적용하고 Bridge model ggg 와 함께 peft module 을 fine-tuning 한다. 위 fine-tuning 과정으로 두 목표를 달성할 수 있다. match LLM dimension enriching modules knowledge Inference​ peft module 및 Bridge model ggg 는 한 번의 훈련으로 완성되며, LLM 의 knowledge 로 향상된 peft module 을 LLM 에 통합시킨다. 위 통합으로 LLM 은 inference 중 gradient-based optimization 없이 peft 로 capute 한 task-specific knowledge 를 활용할 수 있게 된다.","s":"2. Method","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":633,"t":"SuperGLUE 의 8개 NLU task 에서 실험을 수행 BoolQ CB COPA MultiRC RTE WiC WSC ReCoRD accuracy 또는 F1-score 로 report autoregressive language model GPT2 및 sequence-to-sequence model T5 ㅇ에서 효과성을 평가한다. GPT2 의 경우 GPT2-base 를 small model 로, GPT2-XL 을 large model 로 지정 T5 의 경우, T5-base 및 T5-large 를 small model 로, T5-3B 및 T5-XXL 을 large model 로 지정 Bridge model 을 얻기 위해, reduction factor r=16r = 16r=16 로 설정 Bridge model 이 LLM parameter 보다 상당히 작다는 것을 볼 수 있다. 저자의 목표는 SLM 에 학습된 peft module 이 gradient-based optimization 없이 LLM 에 효과적으로 adapt 되어 full fine-tuning 및 다른 peft 와 comparable 한 성능을 달성하는 것. baseline 은 다음과 같다. Fine-tuning​ vanilla Transformer fine-tuning Adapter tuning​ 각 Transformer layer 의 self-attention module (and MLP module) 및 subsequent residual connection 사이에 small task-specific module 을 삽입 Prefix tuning​ 각 Transformer attention layer 의 Key 및 Value 에 trainable continuous prompt vectors 추가 LoRA​ Transformer 각 frozen weighted layer 에 low-rank 및 trainable matrices 를 병합 Adapter tuning Plug-in​ Adapter tuning method 를 SLM 에 적용하여 LLM 에 adapt 할 수 있는 peft module 을 얻음","s":"3.1 Experimental Settings","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#31-experimental-settings","p":623},{"i":635,"t":"Prefix tuning method 를 SLM 에 적용하여 LLM 에 adapt 할 수 있는 peft module 을 얻음 LoRA Plug-in​ LoRA tuning method 를 SLM 에 적용하여 LLM 에 adapt 할 수 있는 peft module 을 얻음","s":"Prefix tuning Plug-in","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#prefix-tuning-plug-in","p":623},{"i":638,"t":"GPT2-base 를 slm, GPT2-XL 을 llm 으로 사용 llm vanilla fine-tuning 및 peft methods 와 comparable result BoolQ 및 COPA task 에서 prefix-tuning method 에 대해 약간의 성능 향상을 증거로 효과성 입증","s":"3.2.1 Experiments on GPT-2 Series of Models","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#321-experiments-on-gpt-2-series-of-models","p":623},{"i":640,"t":"Table 3 : T5-base 를 slm, T5-3B 를 llm 으로 사용 8개의 SuperGLUE tasks 에서 comparable results 달성 특히, BoolQ, CB, RTE, ReCoRD 에서 full fine-tuning 과 유사한 수준 달성 prefix-tuning 에서 비교하면, CB, COPA, WSC task 에서 약간 향상 Table 4 : T5-large 를 slm, T5-XXL 을 llm 으로 사용 마찬가지로 comparable results 달성 prefix-tuning 에서는 BoolQ, CB, ReCoRD 에서 약간 향상 LLM size 가 증가하면서 peft 는 약간의 parameter 를 추갛하지만, 저자의 방법은 parameter augmentation 이 필요하지 않고, plug-in 을 통해 llm 의 능력을 최적으로 사용한다. 이 방법은 llm 의 parameter updating 없이 knowledge 를 효과적으로 활용하며, llm 응용에 대한 잠재적인 제시도 준다.","s":"3.2.2 Experiments on T5 Series of Models","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#322-experiments-on-t5-series-of-models","p":623},{"i":642,"t":"reduction factor rrr 의 영향을 고려하여, CB, RTE 및 WiC 에서 검증 분석을 실험한다. rrr 의 증가에 따른 모델 성능의 점진적 감소를 발견 눂은 rrr 값은 llm 에서 Bridge 로의 knowledge 유지를 감소시키기 때문 위 관찰을 통해 Bridge model 의 parameter 는 slm 보다 작아야 함을 알 수 있다. Bridge model 의 parameter 가 sml 과 비교 가능한 경우, 저자의 방법은 성능을 저하시키지 않고 모델을 유지 모델 성능과 Bridge model 의 parameter 사이의 균형을 맞추기 위해, r=16r = 16r=16 을 선택하는 것이 적절한 선택지","s":"3.2.3 Importance of the Reduction Factor rrr","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#323-importance-of-the-reduction-factor-r","p":623},{"i":644,"t":"저자의 method 는 parameter updating 없이 full fine-tuning 과 peft 와 comparable 성능을 달성할 뿐만 아니라 memory 사용량도 상당히 줄여준다. GPT2-XL 모델 사용 시 sequence length : 512 batch size : 8 vanilla fine-tuning 와 비교하여 7.1X 메모리 절약 기존 peft 와 비교하면, 5.3x, 5.6x 및 5.7x 메모리 절약을 달성 T5-3B 모델 사용 시 sequence length : 512 batch size : 1 vanilla fine-tuning 와 비교하여 5.1X 메모리 절약 기존 peft 와 비교하면, 3.6x, 3.5x 및 3.6 메모리 절약을 달성 저자의 접근법은 LLM 에 더 효과적으로 적용할 수 있고, inference 에서 속도를 down 시키지 않는다. plug-in 을 활용하여, llm 의 knowledge 를 직접적으로 활용하여 inference 에서 속도를 늦추지 않는다.","s":"3.2.4 Memory Usage","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#324-memory-usage","p":623},{"i":646,"t":"질문 : 왜 Bridge model 을 직접적으로 peft 로 학습하지 않고 SLM 을 사용하며, peft module 을 LLM 에 적용하지 않을까? 직관적으로는, 저자는 LLM 의 dimension match 를 위해 project 할 projection model 이 필요하지만, projection model 은 interaction 만 잘 학습한다. peft 및 linear projection modules 를 직접 초기화하여 Bridge model 을 훈련시키고 Bridge model 만으로 학습할 수 있는지 조사한다. T5-3B 를 사용하여, COPA, RTE, WiC 및 WSC task 에 실험 수행 Bridge model 로 학습된 peft module 을 SLM → T5-3B 로 plugging 하여 성능을 비교 Bridge model 을 직접적으로 사용하면 일관적으로 성능이 나쁜 것을 발견 위 결과는 Bridge model 혼자로는 활용할 수 없다는 것을 표시","s":"3.3 Utilize Bridge Model Directly?","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"#33-utilize-bridge-model-directly","p":623},{"i":648,"t":"Fine-tuning and Parameter-efficient Tuning​ LLM 은 downstream task 에 도입하여 pre-trained LM 의 모든 parameter 를 업데이트하고 저장해야하므로, 모델 사이즈가 점점 증가하는 현대에 full fine-tuning 이란 어렵다. 이에 PEFT 방법으로 LLM 은 frozen 한 채 작은 파라미터만 tuning 하여 vanilla fine-tuning 과 comparable result 를 얻을 수 있게 되었다. Adapter tuning : Transformer layers 에 small-scale task-specific module 을 추가하여 task-specific information 학습을 목표 Prefix tuning : Transformer layers 에 additional parameter 도입 LoRA : Transformer 각 layer 의 frozen weight 에 low-rank 및 trainable matrices 병합 BitFit : frozen parameter 유지한 채 모델의 bias 를 최적화하는 간단한 방법 하지만 존재하는 peft method 는 일반적으로 gradient-base optimization 이 필요하고 여전히 메모리 사용량 수반 저자의 방법은 메모리 사용량을 상당히 절약하고, 성능은 유지 Gradient-free Optimization​ 최근, Ladder side-tuning (Sung et al. 2022) 의 downstream task 에 pruned model 을 직접 적용하여 gradient 가 필요없지만 LLM 의 knowledge 를 완전히 활용하지 않는 방법이 있다. Offsite-tuning (Xiao et al. 2023) 은 full parameter access 없이 LLM 을 downstream task 에 adapting 할 수 있는 효과적인 transfer learning framework 를 제안했지만, compute-intensive distillation techiques 를 사용하여 큰 모델에 대해 비용이 크게 들 수 있다. 저자의 방법은 LLM 에 포함된 knowledge 를 더욱 활용하며, LLM 의 성능을 유지하면서도 간단하게 메모리를 절약할 수 있다.","s":"4. Related Work","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":650,"t":"gradient 계산 없이 LLM 에 적용할 새로운 peft method 제안 SLM 에 peft module 을 학습한 후, peft module 과 LLM 사이의 dimension mismatch 및 interaction 을 가능하게 할 Bridge model 과 함께 LLM 에 adapting SuperGLUE 에 실험 결과 full fine-tuning 및 peft 와 비교하여 gradient-base optimization 없이도 comparable result 달성","s":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":652,"t":"weights 를 얻을 수 없는 LLM 의 경우 직접적으로 사용할 수 없으며, 다른 아키텍처의 LM 에 적용할 때는 한계가 존재한다. 서로 다른 아키텍처 및 모델 전역에 효과적이고 능력을 향상시킬 수 있는 것을 목표로 하는 방법에 대해 후속 연구","s":"Limitations","u":"/docs/Paper/NLP/PEFT/Mixture/PEFT without Its Gradients","h":"","p":623},{"i":654,"t":"논문 이미지 및 출처 : https://arxiv.org/pdf/1902.00751.pdf","s":"Parameter-Efficient Transfer Learning for NLP","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"","p":653},{"i":656,"t":"pre-trained model fine-tuning 은 NLP 에서 효과적인 transfer mechanism 이다. 하지만, downstream task 가 많을 경우, 모든 task 마다 entire new model 이 요구되어 비효율적이다. 이 대안으로 저자는 adapter module 을 사용한 transfer 제안 모델이 간결하고 확장 가능 task 당 few trainable parameters 만 추가 및 이전 작업 수정 없이 new task 에 추가 가능 기존 모델의 parameter 는 고정하며, 고도의 parameter sharing 이 가능 Adapter 효과성 입증을 위해 BERT 를 26 task 를 포함한 GLUE 에서 transfer task 당 few parameter 만으로, 거의 SOTA 에 가까운 성능을 얻음 GLUE 에서 task 당 3.6% parameter 만 추가하여 full fine-tuning 성능 0.4% 안으로 차이남 반면 full fine-tuning 은 parameter 100% 훈련","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"","p":653},{"i":658,"t":"pre-trained model transfer 은 NLP task 에서 강력한 성능을 내며, 특히 unsupervised loss 로 large text corpora 를 학습한 Transformer network 인 BERT 는 text classification 및 extractive question answering 에서 SOTA 성능을 달성한다. 본 논문은 oneline setting (tasks arrive in a stream) 에 대처 목적은 모든 new task 에 entire new model 을 훈련하지 않고 잘 수행하는 시스템 구축 클라우드 서비스같은 응용 분야에서 task 간 고도의 sharing 이 필요한데, 순차적으로 오는 여러 task 해결 이를 위해 compact 하고 extensible 한 downstream model 을 생성하는 transfer learning 전략 제안 Compact Model : task 당 small number additional parameter 를 사용하여 많은 task 해결 Extensible Model : 이전 작업을 잊지 않고 new task 를 해결할 수 있도록 점진적으로 훈련될 수 있음 저자의 모델은 성능을 희생하지 않고 모델 생성 NLP 에서 일반적인 transfer learning 은 feature-based transfer 및 fine-tuning 이다. 대신, 저자는 adapter 에 기반한 대안법 제시 (Rebuffi et al. 2017) Feature-based transfer : real-valued embedding vector 를 pre-training 이런 embedding vector 는 word (Mikolov et al. 2013), sentence (Cer et al. 2019) or paragraph (Le & Mikolov, 2014) level 에서 이루어질 수 있음 이후 embedding 은 custom downstream model 에 주입 Fine-tuning : pre-trained network 의 weight 를 복사하고 해당 weight 를 downstream task 에 맞게 tuning 최근 연구에 따르면 fine-tuning 은 종종 feature-based transfer 보다 나은 성능 (Howard & Ruder, 2018) feature-based transfer 및 fine-tuning 모두 각 task 에 대한 new weight set 필요 network lower layer 이 task 간에 공유되면 fine-tuning 는 parameter-efficient 하지만, 저자의 adapter tuning 은 더욱 parameter-efficient Fig. 1 에서 trade-off 를 보여줌 xxx-axis 는 task 당 trained parameter 수 나타냄 Adapter-based tuning 은 fine-tuning 에 비해 fewer parameters 를 두 자릿수 더 적게 요구하며 비슷한 성능 달성 Adapter 는 pre-trained network 사이에 추가된 new modules Adapter-based tuning 과 feature-based network 에는 다음과 같은 차이가 있다. parameter www 를 가진 function (neural network) ϕw(x)\\phi_w(x)ϕw​(x) 를 고려하자. Feature-based transfer 은 ϕw(x)\\phi_w(x)ϕw​(x) 와 new function Xv\\mathcal{X}_vXv​ 을 결합하여 $ Xv(ϕw(w))\\mathcal{X}_v(\\phi_w(w))Xv​(ϕw​(w)) 생성 이후 new task-specific parameters vvv 만 훈련 Fine-tuning 은 각 new task 에 대해 original parameter www 를 조정하며 수행. 이는 간결성에 제한됨 Adapter Tuning 의 경우, new function ψw,v(x)\\psi_{w,v}(x)ψw,v​(x) 정의 parameter www : pre-training 에서 복사 initial parameter v0v_0v0​ : new function 이 original 과 유사하도록 설정: ψw,v0(x)≈ϕw(x)\\psi_{w, v_0}(x) \\approx \\phi_w(x)ψw,v0​​(x)≈ϕw​(x) 훈련 중, vvv 만 tuning deep network 의 경우, ψw,v\\psi_{w,v}ψw,v​ 는 일반적으로 original network ϕw\\phi_wϕw​ 에 new layer 를 추가하는 것을 포함 ∣v∣≪∣w∣|v| \\ll |w|∣v∣≪∣w∣ 를 선택하면 많은 task 에 parameter (∼∣w∣)(\\sim |w|)(∼∣w∣) 가 필요한 모델이 생성됨 www 는 고정되어 있어, model 은 이전 task 에 영향을 미치지 않고 새로운 작업으로 확장 가능 Adapter-based tuning 은 multi-task 및 continual learning 과 관련 있다. Multi-task learning 또한 compact model 결과로 가져옴 하지만 모든 task 에 동시 액세스가 필요하여 Adapter tuning 에서는 불필요 Continual learning 은 endless stream task 학습을 목표 이는 network 가 re-training 후 이전 task 를 forget 하기 때문에 어려움이 있음 Adapter 는 task 가 상호작용하지 않고 shared parameter 는 freezing 되어 있어 다르다. 이는 small task-specific parameter 를 사용하여 이전 task 에 대한 완전한 기억을 갖고 있는 특징이 있다. 저자는 adapter 가 NLP 에 parameter-efficient tuning 임을, 크고 다양한 text classification task 에서 입증 핵심은 effective adapter module 과 base model 의 통합하는 설계이다. GLUE 에서 fully fine-tuned BERT 성능과 일치하지만 task-specific parameter 는 3% 에 불과 (fine-tuning 은 100%) 17 dataset 및 SQuAD extractive questiuon answer 에서 유사한 결과 관찰. 요약하여, adapter tuning 은 single, extensible model 을 제공 가능하며 text classification 에서 SOTA 달성","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"","p":653},{"i":660,"t":"저자는 여러 downstream task 에서 large text model tuning 전략 제안. 이에는 세 가지 주요 특성이 존재 좋은 성능 달성 task 를 순차적으로 훈련. 즉, 모든 데이터셋을 동시에 액세스할 필요가 없음 task 당 추가 파라미터 수를 적음. 이러한 특성은 클라우스 서비스에서 유용하며, 많은 downstream task 을 훈련해야 하므로 고도의 공유가 바람직하다. 이 특성에 달성하기 위해, 저자는 new bottleneck adapter module 을 제안 apdater module 을 사용한 tuning 은 new parameter 를 추가하는 것으로 이루어지며, downstream task 에 훈련 adapter module 은 pre-trained network 를 downstream task 용으로 재사용되기 위해 architectual 수정 특히, adapter tuning 전략은 원래 네트워크에 new layer 주입을 포함 original network 의 weight 는 건드리지 않은 채로, new adapter layer 는 random initialize fine-tuning 에선 new top-layer 및 original weight 을 공동 훈련 반면 adapter tuning 은 original network 는 freezing 하므로 많은 task 에서 공유될 수 있음 Adapter module 은 두 특징이 있다. small parameter adapter module 은 original network 의 layer 에 비해 작아야 함 이는 많은 task 가 추가될 때 total model size 가 상대적으로 천천히 증가함을 의미 near-identity initialization adapted model 의 안정적인 훈련을 위해 필요 경험적 실험으로, adapter 를 near-identity function 으로 초기화 시 훈련 시작 때 original network 에 영향을 주지 않음 훈련 중, adapter 는 network 를 통해 activation distribution 을 바꾸기 위해 활성화될 수 있다 adapter module 은 필요하지 않은 경우 무시될 수 있음 어느 adapter 가 많은 영향을 미치는지 관찰하여, 초기화가 far-identity function 이면 훈련에 실패할 수 있다.","s":"2. Adapter tuning for NLP","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"","p":653},{"i":662,"t":"Transformer 에 대한 adapter-based tuning 을 인스턴스화 이 모델은 다양한 task 의 NLP 에 SOTA 달성. 저자는 standard Transformer architecture 고려한다. Adapter module 은 많은 architectural 선택지를 제공한다. 저자는 좋은 성능을 달성하는 간단한 설계를 제공 복잡한 설계 여러 가지를 실험해보았지만, 다음 전략이 다양한 dataset 에서 다른 방법들과 마찬가지로 잘 수행됨을 발견 Fig. 2 는 adapter architecture 및 Transformer 에 적용을 보여줌 Transformer 의 각 layer 는 two primary sub-layers 포함: attention layer 및 feedforward layer 두 layer 모두 input layer size 로 매핑하는 projection 각 sub-layer 는 skip-connection 적용 각 sub-layer 의 output 은 layer normalization 에 주입 저자는 이 sub-layer 각각 뒤에 two serial adapter 삽입 adapter 는 항상 skip-connection 다음에 바고 적용 projection 을 통해 input size 로 돌아간 후 적용되지만 skip-connection 다음에 삽입 adapter output 은 그 다음 layer normalization 에 직접 전달 parameter 수를 제한하기 위해 bottleneck architecture 제안 adapter 는 먼저 original ddd-dimensional feature 를 smaller dimension mmm 으로 projection 한 다음 nonlinearity 적용하고 다시 ddd dimension 으로 projection layer 당 추가되는 파라미터는 biases 포함하여 총 2md+d+m2md+d+m2md+d+m m≪dm \\ll dm≪d 로 설정하여, task 당 추가되는 parameter 수를 제한 실제로 model parameter 중 약 0.5−8%0.5 - 8\\%0.5−8% 사용 bottleneck dimension mmm 은 성능을 parameter-efficient 와 trade-off 하는 간단한 수단 adapter module 자체에 내부적으로 skip-connection skip-connection 을 사용하면, projection layer parameter 가 near-zero 로 초기화된 경우 module 이 approximate identity function 으로 초기화된다. adapter module 의 layer 와 함께 각 task 에 대해 new layer normalization parameter 를 훈련 이는 conditional batch normalization (De Vries et al. 2017), FiLM (Perez et al. 2018) 및 self-modulation (Chen et al. 2019) 와 유사 layer 당 2d2d2d parameters 만 사용하여 network 의 parameter-efficient adaptation 제공 단순히 layer normalization parameter 만을 훈련하는 것은 좋은 성능을 얻기에 충분치 않","s":"2.1 Instantiation for Transformer Networks","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#21-instantiation-for-transformer-networks","p":653},{"i":664,"t":"저자는 adapter 가 text task 에 대해 parameter-efficient transfer 달성을 보여줌 GLUE 벤치마크에서 BERT 의 fine-tuning 과 0.4% 차이만 나지만, fine-tuning 의 parameter 3% 만 추가 이 결과로 17 classification task 와 SQuAD question answering 에 대해 확인 분석 결과 adapter-based tuning 이 network higher layer 에 자동으로 집중하는 것을 보져여","s":"3. Experiments","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"","p":653},{"i":666,"t":"public pre-trained BERT Transformer 를 base model 로 사용 BERT 사용으로 classification 수행을 위해 Devlin et al (2018) 을 따른다. 각 sequence 의 first token 은 special \"classification token\" 이다 이 token 의 embedding 에 linear layer 을 연결하여 class label 을 예측 훈련 절차도 Devlin et al (2018) 을 따름 optimizer Adam 사용 Adam 의 learning rate 는 처음 10%10\\%10% 를 선형적으로 증가. 그 후 선형적으로 감소하여 0 으로 줆 4개의 Google Cloud TPUs 에서 32 batch size hyperparameter sweep 하고 validation set 에 정확도에 따라 best model 선택 BERT 의 fine-tuning 과 비교하며, NNN 개 task 에 대한 fine-tuning 은 pre-trained model parameter 의 NNN 배 필요 저자는 fine-tuning 보다 적은 parameter 로 동등한 성능 달성을 목표로 한다. 이상적으로는 1×1\\times1× 에 가까운 수준이다.","s":"3.1 Experiments Settings","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#31-experiments-settings","p":653},{"i":668,"t":"GLUE 에서 평가를 진행 300M parameter 및 24 layers 를 포함한 pre-trained BERTLARGE_{\\text{LARGE}}LARGE​ 에서 transfer hyperparameter sweep 수행 learning rate {3⋅10−5,3⋅10−4,3⋅10−3}\\{3 \\cdot 10^{-5}, 3 \\cdot 10^{-4}, 3 \\cdot 10^{-3}\\}{3⋅10−5,3⋅10−4,3⋅10−3} epochs {3,20}\\{3, 20\\}{3,20} fixed adapter size (bottleneck 수) 및 {8,64,256}\\{8,64,256\\}{8,64,256} 를 task 당 best size 선택 adapter size 는 tuning 한 adapter-specific hyperparameter 훈련 불안정성을 위해 서로 다른 random seed 5번 re-run 후 validation set 에 대한 best model 선택 Adapter 는 GLUE score 평균 80.0 달성. full fine-tuning 은 80.4 optimal adapter size 는 dataset 당 다양함 MNLI 의 경우 256 RTE 의 경우 8 size 를 64 로 제안하면 평균 79.6 으로 약간 감소 fine-tuning 은 BERT 의 9×9\\times9×, Adapter 는 1.3×1.3\\times1.3×만 필요하다.","s":"3.2 GLUE benchmark","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#32-glue-benchmark","p":653},{"i":670,"t":"Adapter 의 간결함과 우수한 모델 생성의 검증을 더 하기 위해, text classification task 를 추가 진행 example 이 900 ~ 330k 까지, class 는 2 ~ 157 까지, 평균 text length 는 57 ~ 1.9k 32 batch size 사용 데이터셋이 다양하여 learning rate 범위를 넓게 sweep: {1⋅10−5,3⋅10−5,1⋅10−4,3⋅10−3}\\{1\\cdot10^{-5},3\\cdot10^{-5},1\\cdot10^{-4},3\\cdot10^{-3}\\}{1⋅10−5,3⋅10−5,1⋅10−4,3⋅10−3} 데이터 수가 많아 epochs sweep: {20,50,100}\\{20, 50, 100\\}{20,50,100} fine-tuning 과 adapter 의 optimal value 선택 adapter size {2,4,8,16,32,64}\\{2, 4, 8, 16, 32, 64\\}{2,4,8,16,32,64} 일부 dataset 은 작으므로, fine-tuning 하는 것이 optimal 하지 않을 수 있으므로, 추가적인 base model 실행 이를 위해 top nnn layer 만 fine-tuning 하고 나머지는 freezing n∈{1,2,3,5,7,9,11,12}n \\in \\{1,2,3,5,7,9,11,12\\}n∈{1,2,3,5,7,9,11,12} 이 실험에선 BERTBASE_\\text{BASE}BASE​ model 및 12 layers 사용 GLUE task 와 달리 적절한 SOTA set 이 없어, BERT-based model 이 경쟁력있는지 확인을 위해 벤치마크 성능 수집 표준 모델에 large-scale hyperparameter 수행 Zoph & Le (2017); Wong et al (2018) 과 유사한 single-task Neural AutoML algorithm 실행 이는 TensorFlow Hub 로 공개된 pre-trained text embedding module 위에 샇인 feedforward 및 convolutional network space 에서 search 각 task 에 대해 30대 machines 로 CPU 에서 일주일간 AutoML 실행 평균적으로 task 당 10k 개 이상의 모델 탐색 검증셋의 정확도에 따라 best model 선택 Auto 벤치마크 에 대한 fine-tuning, variable fine-tuning, adapter-tuning 을 Table 2 에 보고 AutoML baseline 은 BERT 가 경쟁력 있음. 수천 개의 model 을 탐색하여, BERT 가 평균적으로 나은 성능 발휘 GLUE 와 유사한 결과 패턴 보임 adapter tuning 의 성능이 fine-tuning 과 거의 비슷 (0.4%) fine-tuning 은 BERT$\\text{BASE}$ parameter 의 17배 필요 variable fine-tuning 은 조금 더 나은 성능 발휘하며, fewer layer 로 훈련. variable fine-tuning 의 optimal set 은 평균 52% 훈련, 총 9.9배 줄음 adapter 는 훨씬 더 간결하며, task 당 1.14% new parameter 만 도입하여 모든 17개 task 에 대해 1.19배 parameter 생성","s":"3.3 Additional Classification Tasks","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#33-additional-classification-tasks","p":653},{"i":672,"t":"adapter size 는 parameter-efficient 를 제어 smaller adapter 는 fewer parameter 를 도입하지만 성능 손실 발생할 수 있음 이러한 trade-off 를 연구하기 위해 다양한 adapter size 를 고려하고 두 가지 baseline 비교: BERT$\\text{BASE}$ 의 top kkk layers 만 fine-tuning layer normalization parameters 만 tuning Fig. 3 은 각 sweep 의 모든 classification task 를 통합한 parameter/performance trade-off 를 보여줌 GLUE 에선 fewer layers 가 fine-tuning 될 때 성능 급격히 감소. additional task 중 일부는 fewer layers 훈련이 이점을 줌. 따라서 fine-tuning 의 성능 감소는 훨씬 적다 adapter 는 두 가지 범위의 크기에서 매우 좋은 성능 제공 Fig. 4 는 두 GLUE task, MNLIm_mm​ 및 CoLA 에 대해 더 자세히 조사 top layers 를 tuning 하며 all k>2k > 2k>2 에 대해 더 많은 task-specific parameter 를 훈련 비슷한 수의 task-specific 을 사용하여 fine-tuning 할 때 성능 크게 감소 약 trainable parameter 9M 의 top-layer 만 fine-tuning 하여 MNLIm_mm​ 에 77.8%±0.1%77.8\\% \\pm 0.1\\%77.8%±0.1% validation accuracy 달성 반면 64 size 인 adapter tuning 은 약 trainable parameter 2M 으로 83.7%±0.1%83.7\\% \\pm 0.1\\%83.7%±0.1% validation accuracy 달성 full fine-tuning 은 84.4%±0.02%84.4\\% \\pm 0.02\\%84.4%±0.02% 달성 CoLA 에서도 유사한 추게 관찰 나아가 비교를 위해, layer normalization 의 parameter 를 tuning 이 layer 는 point-wise addition 및 multiplication 만 포함하므로 매우 적은 trainable parameter 도입 BERTBASE_\\text{BASE}BASE​ 의 경우 40k 하지만 성능 저하 발생 CoLA 에서 약 3.5%, MNLIm_mm​ 에서 약 4% 성능 감소 요약하여 adapter tuning 은 parameter-efficient 가 높고 강력한 성능을 가진 compact model 생성 full fine-tuning 과 비교하여 성능이 1%1\\%1% 내외로 유지 original model 의 0.5%−5%0.5\\% - 5\\%0.5%−5% size 로 adapter 를 훈련시키면, BERTLARGE_\\text{LARGE}LARGE​ 의 경쟁력 있는 결과에 근접","s":"3.4 Parameter/Performance trade-off","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#34-parameterperformance-trade-off","p":653},{"i":674,"t":"마지막으로, adapter 를 classification 외의 task 에서도 작동하는지 확인을 위해 SQuAD v1.1 에서 실행 Fig. 5 는 SQuAD validation set 에서 fine-tuning 및 adapter parameter/performance trade-off 를 보여줌 question 및 Wikipedia paragraph 이 주어지면, 이에 대한 answer span 을 선택 Fine-tuning 의 경우, trained layers 수를 sweep: learning rate {3⋅10−5,5⋅10−5,1⋅10−4}\\{3\\cdot10^{-5},5\\cdot10^{-5},1\\cdot10^{-4}\\}{3⋅10−5,5⋅10−5,1⋅10−4} epochs {2,3,5}\\{2,3,5\\}{2,3,5} adapter 의 sweep: learning rate {3⋅10−5,1⋅10−4,3⋅10−4,1⋅10−3}\\{3\\cdot10^{-5},1\\cdot10^{-4},3\\cdot10^{-4},1\\cdot10^{-3}\\}{3⋅10−5,1⋅10−4,3⋅10−4,1⋅10−3} epochs {3,10,20}\\{3,10,20\\}{3,10,20} classification 처럼, adapter 는 fewer parameter 를 사용하면서도 full fine tuning 과 유사한 성능 달성 adapter size 64 (2% parameter) 는 F1 90.4% 얻음 fine-tuning 은 90.7% 달성 SQuAD 는 small adapter (0.1% parameter) 로도 잘 작동. F1 89.9% 얻음","s":"3.5 SQuAD Extractive Question Answering","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#35-squad-extractive-question-answering","p":653},{"i":676,"t":"저자는 adapter 의 영향을 관찰하기 위해 ablation 실험 수행 이를 위해 일부 trained adapters 를 제거하고 validation set 에서 model 재평가 (재훈련 없이) Fig. 6 은 MNLI 및 CoLA 에서 adapter size 64 로 BERTBASE_\\text{BASE}BASE​ 에서 all continuous layer span 에서 adapter 제거했을 때의 변화를 보여줌 single layer adapter 제거는 성능 영향을 주지 않음을 관찰 heatmap 의 대각선 요소는 single layer 에서 adapter 제거의 성능 가장 큰 성능 하락은 2% 대조적으로, all adapter 제거하면 성능 크게 감소 MNLI 37%, CoLA 는 69% 로 감소 위 결과는 각 adapter 가 전체 network 에 미치는 영향은 작지만, 전체적인 영향이 큼을 나타냄 Fig. 6 은 lower layer 가 top layer 보다 적은 영향을 미침을 시사 MNLI 의 0-4 layer 에서 adapter 제거해도 성능 영향을 거의 미치지 않음 이는 adapter 가 자동으로 top layer 를 우선 처리하여 adapter 가 잘 작동함을 시사 실제 top layer 에 집중하는 것은 fine-tuning 에서 널리 사용되는 전략 (Howard & Ruder, 2018) top layer 는 공유되는 lower-level feature 를 추출하고, top layer 는 다른 task 의 고유 feature 를 구축 이는 일부 task 에서는 top layer 만 fine-tuning 하는 것이 full fine-tuning 보다 우수한 결과를 얻음과 관련 있다 (Table 2 참조) initialization scale 에 대한 robustness 조사 메인 실험에서 adapter module weight 의 표준편차가 10−210^{-2}10−2 인 zero-mean Gaussian 으로 추출 initialization scale 의 영향 분석을 위해 표준 편차를 [10−7,1][10^{-7}, 1][10−7,1] 구간으로 테스트 두 데이터셋 모두 adapter 성능이 10−210^{-2}10−2 이하의 표준 편차에 robust initialization scale 이 너무 크면 성능 저하. 특히 CoLA adapter module 의 뉴런 수에 대한 robustness 조사 all task 에 대해 일정한 adapter size 를 선택할 때 모델 품질이 안정적임을 발견 각 adapter size 에 대해 최적의 학습률과 에폭을 선택하여 8 classification task 에서 평균 검증 정확도 계산 어댑터 크기 8, 64 및 256 에 대한 평균 검증 정확도는 각각 86.2%, 85.8% 및 85.7% 이는 Fig. 4, 5 의 안정적인 성능을 보여주는 것임 마지막으로, adapter architecture 의 여러 확장을 했지만 성능 향상은 미미 adapter 에 batch/layer normalization 추가 adapter 당 layer 수 증가 tanh 같은 다양한 activation function attention layer 내부에만 adapter 삽입 main layer 와 병렬로 adapter 추가 multiplicative interaction 이 있는 경우도 가능 모든 경우가 Section 2.1 의 bottleneck 과 유사한 성능 따라서 간단함과 강력한 성능을 감안할 때, 원래의 adapter architecture 권장","s":"3.6 Analysis and Discussion","u":"/docs/Paper/NLP/PEFT/Module/Adapter","h":"#36-analysis-and-discussion","p":653},{"i":679,"t":"논문 및 이미지 출처 : https://aclanthology.org/2023.emnlp-main.567.pdf large language model 의 성장으로, model 을 new task 에 fine-tuning 하는 과정이 parameter-intensive 하게 되었다. prompt-tuning 은 Pre-trained language models (PLMs) 을 adapting 하는 효과적이고 효율적인 approach 로 등장한다. 하지만 대부분 input layer 에만 prompt 를 도입하여 성능이 제한되지만 개선할 여지는 크다. 본 논문에선 PLMs 의 효율적인 adapting 을 위한 novel Attention Prompt tuning 인 APROMPT 제안 기존 prompt-tuning 을 attention prompt tuning 의 특정 경우도 고려할 수 있음을 입증 fine-tuning 중 attention computation 을 guide 하기 위해 query, key 및 value prompts 를 attention layer 에 통합 SuperGLUE 에서의 실험 결과 SOTA baseline 및 PLMs 의 다양한 scale 의 fine-tuning 보다 일관되게 우수함 prompt 설계의 효과와 저자의 방식의 효율성을 검증","s":"APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":681,"t":"PLMs 는 NLU task 에서 상당한 인기를 얻어왔으며, 모델 크기를 확장하며 성능이 향상된다. LLaMA, GPT, PaLM 등의 PLMs 도 점차 보급되고 있다. 하지만 효과적인 성능에도 불구하고 PLMs 의 fine-tuning 은 all parameter 에 대한 gradient 및 update 로 인해 매우 parameter-inefficient 하며, 각 task 에 대한 fine-tuned copy 를 저장하고 배치해야하여 연산 비용도 발생하여 model adapting 을 방해하는 문제도 있다. full fine-tuning 대체를 위해, parameter-efficient tuning 이 제안되며, 이는 partial tuning 및 extra module 기술이 포함된다. partial tuning (Yosinki et al. 2014): classifier head 또는 last few layers 같은 backbone 의 일부만 fine-tuning extra module : learnable bias terms (Cai et al. 2020) 도입하거나 추가 adapters (Houlsby et al. 2019) 을 도입 위 전략들은 pretrain-then-finetune 패러다임 내에서 작동하며 learnable parameter 수를 효과적으로 줄였다. 하지만 이 방식은 full fine-tuning 과 성능 간격이 크게 벌어진다. 최근 prompt tuning approach (Lester et al. 2021; Li and Liang. 2021; He et al. 2022b; Yang et al. 2023)이 제안됐으며, 이는 learnable soft prompts 를 input 에 prepend 한다. 이 prompt 는 fine-tuning 과정 중 업데이트되는 continuous embedding 으로 구성된다. prompt-tuning 은 다른 parameter-efficient fine-tuning 에 비해 더 단순하고 유연한 방법을 제공하며, PLMs 에서는 full fine-tuning 에 더 가깝게 작동하는 것이 입증되었다. prompt-tuning 은 일반적으로 모델 매개변수의 0.5% 미만으로 구성되어 fine-tuning 의 대안으로 제공 하지만, 기존 prompt-tuning 은 주로 input layer 를 수정하고 self-attention mechanism 의 아키텍처는 철저히 탐색하지 않음 따라서 성능이 낮으며 개선할 여지가 있음 본 논문에선 PLMs adapting 을 위한 novel Attention Prompt tuning 인 APROMPT 을 제안 Prompt tuning 을 재검토하고, input prompt 가 특수화된 key-value prompt 로 간주될 수 있다는 것을 이론적 및 경험적으로 입증하여 APROMPT 소개 이전의 prompt tuning 과 달리, APROMPT 는 query, key 및 value prompt 세 가지 set 을 포함 이 prompt 는 Transformer layer 내의 self-attention block 에 각각의 matrix 에 prepend 이 Attention prompt 가 new task 에 attention computation 을 더 효과적으로 guide 하여 original input prompt 와 함께 학습되어 adapting 중 빠르고 정확하게 tuning SuperGLUE 에서 APROMPT 가 SOTA 에 비해 우수한 성능 보여줌 ablation study 결과 Attention Prompt 의 효과성과 효율성을 강력하게 입증 main contributions input prompt 가 attention prompt 의 툭수한 형태의 관점을 입증하고, 저자의 방식에 대한 이해 향식 input prompt 와 함께 query, key 및 value prompt 를 self-attention computation 에 통합하여 새로운 방식의 tuning 을 가능케하는 새로운 Attention prompt tuning 설계 SuperGLUE 의 다양한 task 에 포괄적인 실험으로 SOTA 에 비해 효과적임을 입증","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":683,"t":"Pre-trained Language Models​ PLM (Yang et al., 2019; Ainslie 등, 2020; Zaheer et al., 2020; Zhao 등, 2023)은 다양한 NLP task 에서 성공을 거두었다. BERT (Devlin et al, 2019) 및 RoBERTa (Liu et al, 2019)와 같은 선구적인 연구는 masked language model (MLM) 및 next sentence prediction task 로 문맥 표현을 학습한다. 최근에는 GPT-3 (Brown et al, 2020), T5 (Raffel et al, 2020), 및 PaLM (Chowdhery et al, 2022)을 포함한 다양한 PLM 이 다양한 pre-training design 등장했다. 그러나 parameter 수의 지수적 증가로 인해 fine-tuning 에 어려움이 있다. 각 task 에 대한 fine-tuning 된 parameter 를 저장하고 유지하는 것은 cost 가 많이 든다. Parameter-Efficient Tuning​ PLMs 크기가 커짐에 따라 copy 를 저장하고 업데이트하는 것이 점점 부담스러워 진다. parameter-efficient fine-tuning 이 LLM 에 등장하여, partial tuning 및 extra module 에 따라 카테고리가 나뉜다. partial tuning : bias terms 및 last layers 의 모듈 일부 업데이트 extra module : SideTuning 및 adapter 를 포함한 model 의 다양한 위치에 task-specific parameter 동;ㅣㅂ Prompt Tuning​ virtual token 으로 모델에 learnable parameter 를 model input 에 삽입 또는 각 layer 에 삽입할 수 있다. 최근 prompt-tuning 의 성능과 안정성 개선을 위해 residual connection 을 추가하고, prompt-tuning 의 지속적인 학습 환경이 확장되고 있다. 하지만 대부분 input layer 에만 prompt 를 추가하여 성능이 제한된다. 가장 최근엔 MixPrompt (Yang et al, 2023) 및 E2VPT (Han et al, 2023) 등 제안되어, prompt 를 key-value prompt 와 결합한다. 이는 저자의 attention prompt tuning 의 경우로 취급할 수 있다","s":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":686,"t":"Prompt tuning 은 PLMs 의 downstream task 에 빠른 적응을 위한 parameter-efficient task-specific prompts 또는 prompt token P∈Rd×mP \\in R^{d\\times m}P∈Rd×m 을 도입 이 prompt 를 input sequence X∈Rd×nX \\in R^{d\\times n}X∈Rd×n 에 prepend 되어 new input Xnew=[P,X]∈Rd×(m+n)X_{new} = [P, X] \\in R^{d\\times (m+n)}Xnew​=[P,X]∈Rd×(m+n) 생성 (Fig. 2 left) mmm : prompt token length nnn : input sequence length ddd : embedding vector dimension 이 prompts 는 backbone 은 freezing 한 채 downstream task 에 fine-tuning","s":"3.1 Preliminary","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#31-preliminary","p":678},{"i":688,"t":"prompt-tuning 의 작동을 깊이 조사하고 traditional input prompt 가 constrained key-value prompts 와 동등함을 보여줌 prompt-tuning 에선 prompt token 이 input 에 prepend 된다. 이후 new sequence Xnew=[P,X]X_{new} = [P, X]Xnew​=[P,X] 가 next layer 의 text token 의 contextual embedding 을 계산하기 위해 Transformer encoder layer 에 feed Attn([P,X])=softmax(QTKnewd)VnewAttn([P, X]) = softmax(\\frac{Q^TK_{new}}{\\sqrt{d}})V_{new}Attn([P,X])=softmax(d​QTKnew​​)Vnew​ Q=HqX,Knew=HkXnew,Vnew=HvXnewQ = H^qX, K_{new} = H^kX_{new}, V_{new} = H^vX_{new}Q=HqX,Knew​=HkXnew​,Vnew​=HvXnew​ Q, KnewK_{new}Knew​, VnewV_{new}Vnew​ : new query, key 및 value embedding matrices HqH^qHq, HkH^kHk 및 HvH^vHv 는 pre-trained model parameter 로, freezing query Q 의 경우, original text token XXX 만 업데이트되어 next layer 에서 사용되므로 새로 계산할 필요가 없다. 그러면 다음과 같다. Knew=HkXnew=[HkP,HkX]=[Pk,K]K_{new} = H^kX_{new} = [H^kP, H^kX] = [P_k, K]Knew​=HkXnew​=[HkP,HkX]=[Pk​,K] 유사하게, Vnew=[Pv,V]V_{new} = [P_v, V]Vnew​=[Pv​,V] 를 갖는다. 따라서 prompt-tuning 중 prompt tokens PPP 를 추가하는 것은 key prompts PkP_kPk​ 및 value prompts PvP_vPv​ 를 각각 original key 와 value matrices 에 prepend 하는 것과 동일하다고 할 수 있다. (Fig. 2) 이러한 key-value prompts 는 input prompts PPP 에 의해 제약되거나 결합된다.","s":"3.2 Connection with Key-Value Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#32-connection-with-key-value-prompts","p":678},{"i":690,"t":"더욱 검증하기 위해, SuperGLUE 의 세 task 에서 T5-Large backbone 으로 Prompt Tuning, Fixed Key-value Prompt, Key-value Prompt 및 Prompt Tuning + Key-value Prompt 를 수행 Fixed Key-value Prompt 는 Prompt Tuning 에서 학습된 optimal prompts P∗P^*P∗ 를 fixed key 및 value prompts 에 추가 즉, 어떠한 tuning 없이 Pk=HkP∗P_k = H^kP^*Pk​=HkP∗ 및 Pv=HvP∗P_v = H^vP^*Pv​=HvP∗ Key-value Prompt 는 fine-tuning 중 optimal key 및 value 를 학습 Prompt Tuning + Key-value Prompt 는 fine-tuning 중 input prompts 및 key-value prompts 함께 학습 비교는 Table 1 에 제시되어 있다. Fixed Key-value Prompt 는 Prompt Tuning 과 동일한 결과를 달성 저자의 기대와 일치하며, input prompts 가 제약된 key-value prompts 사이의 동등성을 검증 fine-tuning 중 key-value prompts 를 학습할 경우 Fixed key-value prompts 보다 성능 향상 이유는 fixed key-value prompts 가 제약 없는 key-value prompts 의 search space 내의 특수한 경우로 볼 수 있기 때문 fine-tuning 중 input prompts 와 key-value prompts 결합이 가장 높은 성능 달성 저자의 가설은 key-value prompts 가 input prompts 에 포함된 정보를 포함할 수 있는 잠재력이 있지만, 실제로는 input prompts 가 fine-tuning 과정에서 추가적인 가치를 제공함을 시사","s":"3.3 Empirical Study","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#33-empirical-study","p":678},{"i":692,"t":"저자는 attention prompt tuning 을 Transformer layer 에 도입하여 attention computation 을 용이하게 하는 방식을 제안 저자의 모델은 다른 parameter 들은 고정한 채로 오직 세 가지 구성 요소만 학습 Input prompts PiP_iPi​. 각 Transformer encoder layer 의 input sequence 의 시작 부분에 삽입 attention prompt 는 각각 query, key 및 value matrices 내에 통합된 PqP_qPq​, PkP_kPk​ 및 PvP_vPv​ 이러한 prompt 는 fine-tuning data 로부터 새로운 attention pattern 학습 task-specific head 는 specific task 에 특화된 lightweight module 이며 효율적으로 학습","s":"4. Attention Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":694,"t":"전통적인 prompt-tuning 과 유사하게, input prompts 는 ddd-dimension embedding vector set 으로 구성하며, 차원은 text token 과 일치 이런 prompts 는 각 Transformer encoder layer 의 input sequence 시작 부분에 삽입되고 모든 text token 과 상호작용 이는 task-specific embedding 학습에 도움되며 모델이 new task 의 성능을 효과적으로 guide 공식적으로, 이 input prompts 는 Pi={Pi1,Pi2,…,PiN}P_i = \\{ P^1_i, P^2_i, \\dots, P^N_i \\}Pi​={Pi1​,Pi2​,…,PiN​} 로 정의 PijP^j_iPij​ : jthj_{th}jth​ Transformer encoder layer 의 learnable input promps NNN : 전체 레이서 수 encoder layer 는 다음과 같이 표시 Z1=L1(Pi1,E)Z^1 = \\textcolor{blue}{L_1}(\\textcolor{red}{P^1_i}, E)Z1=L1​(Pi1​,E) Zj=Lj(Pij,Zj−1)j=2,3,…,NZ^j = \\textcolor{blue}{L_j}(\\textcolor{red}{P^j_i}, Z^{j-1}) \\quad j = 2, 3, \\dots, NZj=Lj​(Pij​,Zj−1)j=2,3,…,N ZjZ^jZj : jthj_{th}jth​ encoder layer 로 계산된 text tokens 의 contextual embedding 서로 다른 색상은 trainable\\textcolor{red}{\\text{trainable}}trainable 및 frozen\\textcolor{blue}{\\text{frozen}}frozen 을 나타낸다. EEE : backbone 으로부터 초기화된 text token embedding","s":"4.1 Input Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#41-input-prompts","p":678},{"i":696,"t":"input prompts 는 new task 에 대한 knowledge 학습에 효과적이지만, 각 encoder layer 내의 정보 상호작용을 guide 하는 능력은 없다. new data 로 fine-tuning 중 word distribution 은 pre-training 중 본 예제와 크게 다를 수 있다. 따라서 fine-tuning data 로부터 새로운 정보를 포착하는 능력을 향상시키는 것이 중요하다. 이는 input tokens 사이에 더 나은 attention 을 가능하게 함으로써 task-specific context 에서 나타나는 new pattern 을 효과적으로 학습하는 것을 의미한다. 이를 위해, 각 encoder layer 내의 attention block 에 통합된 novel attention prompts 를 소개 이러한 attention prompts 는 query-key prompts 와 key-value prompts 두 그룹으로 분류될 수 있다. query-key prompts 는 PqQKP^{QK}_qPqQK​ 및 PkQKP^{QK}_kPkQK​ 로 표시되며, attention module 내의 original query 및 key 에 append 되는 small matrices 로 구성 이러한 query-key prompts 를 통합함으로써 token 간의 attention map computation 을 향상시킨다. key-value prompts 는 PkKVP^{KV}_kPkKV​ 및 PvKVP^{KV}_vPvKV​ 로 표시되며, key 및 value matrices 에 각각 삽입된 두 개의 supplementary matrices (few columns) 로 구성 이러한 key-value prompts 는 input tokens 가 attention 할 수 있는 추가 정보를 제공하여 learned embedding 의 representation 을 강화 query-key 및 key-value prompts 모두 통합함으로써, fine-tuning 과정 중 더 효과적인 information interaction 을 가능하게하고 new patterns 를 포착할 수 있게 한다. new query, key 및 value matrices 는 이런 new attention prompts 로 확장된다. (Fig. 4) new key matrix 는 query-key 및 key-value prompts 모두에서 추가된다. 그럼 new attention computation 은 다음과 같다. L(⋅)=MLP(LN(MSA(⋅)))L(\\cdot) = \\textcolor{blue}{MLP} ( \\textcolor{blue}{LN} ( \\textcolor{red}{MSA} (\\cdot) ) )L(⋅)=MLP(LN(MSA(⋅))) MSA(⋅)=softmax(QnewTKnewd)VnewMSA(\\cdot) = softmax(\\frac{\\textcolor{red}{Q^T_{new}K_{new}}}{\\sqrt{d}})\\textcolor{red}{V_{new}}MSA(⋅)=softmax(d​QnewT​Knew​​)Vnew​ MLP 및 LN : frozen multi-layer perceptron 및 layer norm MSA : Transformer encoder layer 내의 multi-head self-attention 이렇게 하여 attention prompts 는 new task 에 대한 model adaptation 을 효과적으로 guide","s":"4.2 Attention Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#42-attention-prompts","p":678},{"i":698,"t":"각 downstream task 의 경우, very small module 이며 specific task 에 특수화되는 task-specific head 를 를 fine-tuning 하여 predictions 를 생성 y=Head(ZN)y = \\textcolor{red}{Head}(Z^N)y=Head(ZN) ZNZ^NZN : encoder 의 top layer 의 output contextual embedding","s":"4.3 Task-specific Head","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#43-task-specific-head","p":678},{"i":701,"t":"이전 prompt-tuning 연구에 따라 NLU task 인 SuperGLUE 에서 실험 수행 BoolQ, CB, COPA, MRC, ReC, RTE, WiC 및 WSC","s":"5.1 Datasets","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#51-datasets","p":678},{"i":703,"t":"SOTA prompt-tuning 과 비교한다. Fine-Tuning : T5 standard full fine-tuning Prompt-Tuning : vanilla prompt tuning. input layer 에 input prompts 추가 P-Tuning v2 : 각 transformer layer 에 개별적인 prompts 삽입 XPrompt : 가장 작은 important token-level 및 piece-level prompts 를 pruning ResPrompt : prompt tuning 의 안정성 및 성능을 높인 residual connection 추가","s":"5.2 Baselines","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#52-baselines","p":678},{"i":705,"t":"APROMPT 는 Prompt Tuning 연구를 위해 OpenPrompt 를 사용하여 구현 16개 NVIDIA Tesla V100 GPU 에서 학습 각 SuperGLUE 를 따라 text-to-text 형식으로 변환 세 가지 규모의 PLMs 사용: T5-base, T5-large, T5-XL 이전 연구를 따라, input, query-key 및 key-value pomrpts length 를 조정하며 훈련 input prompts 10 으로 설정하고, query-key 및 key-value prompts 의 최적 길이를 {1,5,10,20,50}\\{1,5,10,20,50\\}{1,5,10,20,50} 에서 search Adafactor optimizer 사용하여 weight decay 1e-5 훈련","s":"5.3 Implementation Details","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#53-implementation-details","p":678},{"i":707,"t":"APROMPT 는 다양한 backbone 으로 일관되게 prompt-tuning baseline 능가하며, attention prompt 의 효과적인 설계를 보여줌 T5-large 의 Boolq 에서, APROMPT 의 acc 점수는 XPrompt 및 P-Tuning v2 와 비교하여 각각 5.62% 및 2.76% 개선 기존 prompt-tuning 방식이 주로 input prompt token 을 설계하고, new data 내에서 상호 작용을 포착하지 못함을 시사 반면, 저자의 attention prompt 는 이러한 갭을 줄여 향상된 성능을 얻는다. APROMPT 는 대부분의 경우 full fine-tuning 보다 우수한 성능 발휘하며, T5-base 같은 small backbone 에서 여전히 일부 격차가 있긴 하다. 이 관찰은 다양한 NLU task 에 효과적임을 보여주며, backbone 의 약 0.4% 만 훈련하여 달성하였으며, 매우 parameter-efficient 하다. APROMPT 가 추가적인 attention prompt 를 도입하더라도 input prompt 의 길이가 크게 줄었음도 가치 있다 (fix 10) 따라서 P-Tuning v2 와 비교하여 trainable parameter 가 적다. backbone 모델 크기가 증가함에 따라 fine-tuning 과 다른 prompt-tuning method 간의 gap 을 줄이는 것에 가치가 있음 이는 이전 연구 (Lester et al. 2021; Ma et al. 2022) 와 일치하며, fine-tuning 과 대안 prompt-tuning 간의 수렴 추세를 강조","s":"5.4 Main Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"#54-main-results","p":678},{"i":709,"t":"Results on Low-resource Scenario​ 저자는 APROMPT 및 baseline 을 low-resource setting 에서의 성능을 평가 (Schick and Schütze, 2021) 를 따라, 저자는 fixed random seed 를 사용하여 각 task 에 대한 32 examples 를 선택하여 new training set 으로 사용 저자는 limited training set 에 prompt model 을 학습하고 best checkpoint 로 Table 3 에 report limited data 에서는 모든 method 가 상당한 성능 저하를 경험하지만, APROMPT 는 Boolq, CB, RTE 및 WSC 같은 task 에서 baseline 을 일관되게 능가 대부분의 prompt-tuning 이 fine-tuning 과 비교하여 더 나은 결과를 관찰 이는 limited data 로 훈련할 때 overfitting 의 어려움에도 불구하고, prompt-tuning 이 fine-tuning 에 비해 우수한 일반화 능력을 보여줌 Impact of Difference Prompts​ 다양한 prompt 의 영향을 조사하기 위해, 다양한 prompt combinations 를 탐구하여 ablation study 수행 구체적으로, 네 가지 추가적인 모델로 실험 수행 input prompts 없이 query-key prompts 없이 key-value prompts 없이 query-key 및 key-value prompts 없이 결과 모델 성능이 trainable prompts 중 하나를 제거할 때 감소하는 것을 볼 수 있다. input prompts 없이 APROMPT 의 성능 감소가 attention prompt 없는 모델과 비교하여 비교적 작음을 관찰 이는 input prompts 와 비교하여 query-key 및 key-value prompts 의 중요성을 보여줌 (Section 3 의 타당함) APROMPT 의 모든 prompts 결합이 최상의 성능 Impact of Prompt Length​ APROMPT 에서 query-key 및 key-value prompt 의 length 가 조정해야하는 hyperparameter 다. 다양한 prompt length 가 모델 성능에 미치는 영향을 분석하기 위해, 저자는 prompt length 를 {1,5,10,20,50}\\{1, 5, 10, 20, 50\\}{1,5,10,20,50} 으로 수정하여 실험 모든 조합의 성능 결과는 RTE 와 WSC 에 대해 Fig. 6 에 나와 있다. 모든 task 에 걸쳐 일관되게 최고의 성능을 달성하는 optimal prompt length 는 없다는 것을 알 수 있다. 예로, RTE 에서 10 query-key prompt 로 best 성능을 얻음 서로 다른 task 와 dataset 이 서로 다른 데이터 분포를 보이며, \"hard\" task 는 데이터의 pattern 과 knowledge 를 효과적으로 포착하기 위해 longer prompts 가 필요하다 가설 세움 하지만 이는 trainable parameter 수가 증가하는 대가가 이루어짐 그럼에도 일정 범위 내에서는 성능이 비교적 안정적임 Impact of Prompt Positions​ 이는 모델 성능에 대한 prompt position 의 영향을 평가 encoder 와 decoder 에 다양한 prompt 위치를 적용하여 다섯 가지 추가 모델 훈련 first layer, last layer, first 12 layers, last 12 layers all encoder 및 decoder layer 에 prompt 를 삽입하는 것이 best 성능 얻음 (놀라운 일은 아님) 또한 input layer 또는 output layer 에만 prompt 넣는 것은 성능 저하를 일으키는 것을 관찰 이는 다른 prompt-tuning 연구에서의 관찰과 일관됨 Effect of Attention Prompts Balancing​ APROMPT 의 query-key 및 key-value prompt 는 모델 성능 각각에 다른 기여를 함 상관 관계와 효과를 더욱 조사하기 위해, trainable parameter 수를 고정하고 key-value prompt 비율을 조정하여 실험 수행 비율은 {0,0.25,0.5,0.75,1}\\{0, 0.25, 0.5, 0.75, 1\\}{0,0.25,0.5,0.75,1} 로 조정 task 간에 다른 패턴 관찰 WSC 는 0.75 비율일 때 최고 CB 는 비율이 0.5 일 때 최고 대부분 비율이 0 또는 1 일 때는 성능 저하를 관찰 Variants of APROMPT​ performance-scale trade-off 분석을 위해 APROMPT 의 두 가지 변형 비교 input prompt 를 제거하고 attention prompt 만 유지한 변형 XPrompt 의 pruning 을 적용하여 important 가 낮은 prompt 를 제거한 변형 Table 5 에서 input prompt 의 기여가 크지 않다는 것을 관찰 이는 Section 3 결과와 일치 prompt pruning 적용 후, trainable parameter 수는 감소하지만, 성능은 task 간에 다양하게 나타났으며, prompt 수와 모델 성능 사이의 trade-off 를 찾는데 있어 탐구할 여지가 있어 보임","s":"6. Analysis and Discussion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":711,"t":"본 연구는 prompt-tuning 을 attention prompt-tuning 과 연결하여 보여주며, input prompt 를 attention layer 의 key-value prompt 의 특수한 경우로 간주 가능함 이 관찰로, query, key 및 value prompt 란 세 가지 new prompts set 을 소개하며, 이를 attention layer 에 통합하여 fine-tuning 중 attention computation 으로 guide SuperGLUE 실험에서 여러 baseline 에 비해 우수한 성능을 보여준다.","s":"7. Conclusions","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":713,"t":"저자의 APROMPT 모델에는 두 가지 한계가 존재 다른 prompt-tuning 및 fine-tuning 방식을 능가하지만, attention prompt 의 optimal combination 을 식별하는 것에는 어려움이 존재 optimal prompt length 를 확인하는 searching 은 수행했지만 체계적인 해결책 필요 현재 모델은 각각의 개별 task 에 대해 task-agnostic prompts 를 학습 이를 해결하기 위해 parametric network 를 탐구하여 모델의 유연성과 multiple task 에 대한 adaptability 를 향상시킬 예정","s":"Limitations","u":"/docs/Paper/NLP/PEFT/Soft Prompt/APrompt","h":"","p":678},{"i":715,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2106.09685.pdf","s":"LoRA: Low-Rank Adaptation of Large Language Models","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":717,"t":"GPT-3 175B 의 파라미터를 fine-tuning 하기에는 매우 부담. 이에 저자는 Low-Rank Adaptation, LoRA 제안 pre-trained model weights 를 freeze Transformer layer 에 trainable rank decomposition 을 주입 downstream task 에 대한 trainable parameter 를 매우 크게 줄임 Adam 으로 fine-tuning 한 GPT-3 175B 와 비교하여, LoRA 는 trainable parameter 수를 10,000배 줄이고 GPU 메모리 요구사항 3배 줄임 RoBERTa, DeBERTa, GPT-2 및 GPT-3 에서도 더 좋은 성능 LoRA 는 adapter 와 달리, 추가적인 inference latency 없음 language model (LM) 의 adaptation 에서 rank-deficiency 에 대한 경험적 연구 제공하여 LoRA 의 효과 제공","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":719,"t":"보통 multiple downstream 에 적응하기 위해 하나의 LLM 에 의존한다. task 에 adaptation 할 때 일반적으로 fine-tuning 을 하지만, 모든 파라미터를 훈련하는 것이 큰 단점이다. 이에, 몇몇 파라미터만 adapting 하거나 new task 를 위한 외부 모듈을 학습하는 시도도 있다. task 마다 pre-trained model 에 적은 수의 task-specific parameter 를 저장하고 로드하여, 모델 사용 시 효율이 향상한다. 하지만, depth 확장이나 sequence 길이를 줄이는 등 모델 품질과 효율성간의 trade-off 설정이 힘들다. 저자는 이전 연구에서 learned over-parameterized models 이 사실은 low intrinsic dimension 에 존재한다는 것을 보고 영감을 받았다. model adaptation 중 weight 의 변화가 낮은 \"intrinsic rank\" 를 가질 것이라는 가설을 기반으로 Low-Rank Adaptation (LoRA) approach 를 제안 pre-trained weights 를 고정한 채, model adaptation 중 dense layer 의 변화에 대한 rank decomposition matrices 를 최적화하여 신경망의 일부 dense layer 를 간접적으로 학습하게 함 예로, GPT-3 175B 사용 시, LoRA 를 사용하면 low rank 는 full rank (ddd) 가 12,288 와 같아도 충분 이로써 LoRA 는 저장 및 계산 효율적 LoRA 핵심 이점 pre-trained model 은 여러 task 에 대해, 매우 작은 LoRA 모듈을 구축하여 공유 및 사용 가능 shared model 을 freeze 하고 Fig 1 의 행렬 AAA 와 BBB 를 교체하여 task 를 효율적으로 전환 저장 요구사항 및 task-switching overhead 크게 줄임 LoRA 는 adaptive optimizer 를 사용할 때 더 효율적인 학습 가능 및 hardware barrier 3배 줄임 대부분의 parameter 에 대한 optimizer states 를 유지하거나 gradient 계산 불필요 주입된 smaller low-rank matrices 만 최적화 이 설계는 사용 시, trainable matrices 및 frozen weights 를 병합할 수 있게 함 full fine-tuned model 과 비교하여, inference latency 가 없음 LoRA 는 이전 방법들과는 독립적 그리고 prefix-tuning 같은 다양한 방법과 결합 가능","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":721,"t":"Transformer 아키텍처를 빈번히 언급하니, 이 차원에 대한 용어 사용 Transformer layer 의 input 및 output dimensions : dmodeld_{model}dmodel​ self-attention module query/key/value/output projection matrix : WqW_qWq​, WkW_kWk​, WvW_vWv​, WoW_oWo​ pre-trained weight matrix : WWW 및 WOW_OWO​ adaptation 중인 accumulated gradient update : △W\\triangle W△W LoRA Module : rrr Transformer MLP feedforward dimension : dffn=4×dmodeld_{ffn} = 4 \\times d_{model}dffn​=4×dmodel​","s":"Terminologies and Conventions","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#terminologies-and-conventions","p":714},{"i":723,"t":"LoRA 는 training objective 와 상관없이 모두 사용가능하지만, 본 논문은 LM 에 focus 하여 설명 GPT 같은 pre-trained autogressive LM Pϕ(y∣x)P\\phi(y|x)Pϕ(y∣x) 가 있다 가정 downstream task 는 context-target paris 데이터셋이 있다면, Z={(xi,yi)}i=1,…,N,\\mathcal{Z} = \\{ (x_i, y_i) \\}_{i=1, \\dots,N,}Z={(xi​,yi​)}i=1,…,N,​ 로 표현 xix_ixi​ 및 yiy_iyi​ : token sequence 기존 fine-tuning 은, pre-trained weight ϕ0\\phi_0ϕ0​ 로 초기화 후 objective 최대화를 위해 gradient 를 반복적으로 업데이트하여 ϕ0+△ϕ\\phi_0 + \\triangle \\phiϕ0​+△ϕ max⁡ϕ∑(x,y)∈Z∑t=1∣y∣log⁡(Pϕ(yt∣x,y<t))(1)\\underset{\\phi}{\\max} \\sum_{(x,y) \\in \\mathcal{Z}} \\sum_{t=1}^{|y|} \\log (P_{\\phi}(y_t | x, y_{<t})) \\tag{1}ϕmax​(x,y)∈Z∑​t=1∑∣y∣​log(Pϕ​(yt​∣x,y<t​))(1) full fine-tuning 의 단점은 각 downstream task 마다 차이가 있는 parameter set △ϕ\\triangle \\phi△ϕ 을 학습한다는 것 이 parameter 의 dimension ∣△ϕ∣|\\triangle \\phi|∣△ϕ∣ 는 ∣ϕ0∣|\\phi_0|∣ϕ0​∣ 과 동일 따라서 pre-trained model 이 크면 fine-tuned model 을 저장하고 배포하기에 실용성 없음 본 논문은 parameter-efficient approach 를 채택 task-specific parameter 의 증가 △ϕ=△ϕ(θ)\\triangle \\phi = \\triangle \\phi (\\theta)△ϕ=△ϕ(θ) 는 더 적은 크기의 parameter set θ\\thetaθ 로 적절히 인코딩 (∣θ∣≪∣ϕ0∣|\\theta| \\ll |\\phi_0|∣θ∣≪∣ϕ0​∣) 따라서 △ϕ\\triangle \\phi△ϕ 를 찾는 것은 θ\\thetaθ 의 최적화 max⁡θ∑(x,y)∈Z∑t=1∣y∣log⁡(Pϕ0+△ϕ(θ)(yt∣x,y<t))(2)\\underset{\\theta}{\\max} \\sum_{(x,y) \\in \\mathcal{Z}} \\sum_{t=1}^{|y|} \\log (P_{\\phi_0 + \\triangle \\phi(\\theta)} (y_t | x, y_{<t})) \\tag{2}θmax​(x,y)∈Z∑​t=1∑∣y∣​log(Pϕ0​+△ϕ(θ)​(yt​∣x,y<t​))(2)","s":"2. Problem Statement","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":725,"t":"기존 연구에서도 PEFT 를 다루었다. adapter layer 추가 및 input layer 일부 형태를 최적화하는 등이 있었다. 하지만 large-scalie 및 latency 에 제한사항이 있었다.","s":"3. Aren't Existing Solutions Good Enough?","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":727,"t":"여러 adapter 가 있지만 다음 두 연구에 중점을 둠 [Parameter-Efficient Transfer Learning for NLP.] : Transformer 블록당 두 개의 adapter layer [Exploring versatile generative language model via parameter-efficient transfer learning.] : 블록당 하나의 adapter layer 와 추가적인 LayerNorm layer 및 multitask 에 활용하여 전체 latency 는 줄지만, adapter layer 의 추가 계산은 못피함. adapter layer 는 작은 bottleneck dimension 을 가지고 있어 few parameter (모델의 < 1%) 를 가지도록 설계되어 추가 FLOPs 가 제한됨 하지만 Transformer 는 latency 를 낮추기 위해 하드웨어 병렬처리를 사용하지만 adapter layer 는 순차처리하게 되어 Table 1 을 보면 추가 작업이 증가한 것을 볼 수 있다.","s":"Adapter Layer Introduce Inference Latency","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#adapter-layer-introduce-inference-latency","p":714},{"i":729,"t":"이 방법엔 대표적으로 prefix tuning 가 이쓴데, 최적화가 어렵고 성능이 단조적으로 증가하지 않고 진동하는 경우가 논문에서 관측된다. 근본적으로 sequence 의 일부를 adaptation 을 위해 보류해야 하여 downstream 처리 시 sequence 길이가 줄어들어 효과가 덜하다는 것이 한계","s":"Directly Optimizing the Prompt is Hard","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#directly-optimizing-the-prompt-is-hard","p":714},{"i":731,"t":"본 논문은 Transformer 에 초점을 두지만, 다른 딥러닝에도 적용 가능","s":"4. Out Method","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":733,"t":"많은 network 의 dense layers 는 행렬곱으로 이루어져 있다. 그리고 이 weight matrices 는 보통 full-rank 를 가진다. 기존 연구에서, specific task 에 adapting 중, pre-trained LM 이 \"low instrisic dimension\" 을 가지며 더 적은 subspace 으로의 random projection 에도 여전히 효과적인 학습을 하는 것을 보여준다. pre-trained weight matrix W0∈Rd×kW_0 \\in \\mathbb{R}^{d \\times k}W0​∈Rd×k 의 경우 이를 low-rank decomposition W0+△W=W0+BAW_0 + \\triangle W = W_0 + BAW0​+△W=W0​+BA 로 표현 여기서 B∈Rd×rB \\in \\mathbb{R}^{d \\times r}B∈Rd×r, A∈Rr×kA \\in \\mathbb{R}^{r \\times k}A∈Rr×k rank rrr 은 r≪min⁡(d,k)r \\ll \\min (d, k)r≪min(d,k) training 중 W0W_0W0​ 는 freeze 및 gradient update 하지 않음 AAA 및 BBB 는 trainable parameter 를 포함 W0W_0W0​ 및 △W=BA\\triangle W = BA△W=BA 는 동일한 input 과 곱해자며, 각 output vectors 는 coordinate-wise 로 합산 h=W0xh = W_0xh=W0​x 에 대한 forward pass 는 다음과 같다. h=W0x+△Wx=W0x+BAx(3)h = W_0x + \\triangle Wx = W_0x + BAx \\tag{3}h=W0​x+△Wx=W0​x+BAx(3) AAA 는 random Gaussian 및 BBB 는 0 으로 초기화하여 △W=BA\\triangle W = BA△W=BA 는 training 에 0 으로 시작 이후 αr\\frac{\\alpha}{r}rα​ 으로 △W\\triangle W△W 를 scaling α\\alphaα 는 rrr 에 대한 상수 Adam 으로 최적화 시, α\\alphaα 를 tuning 하는 것은 초기화를 적절히 scaling 하는 것과 동일 이 scaling 은 rrr 을 변화시킬 때 hyperparameter 를 retuning 할 필요를 줄이는데 도움","s":"4.1 Low-Rank-Parameterized Update Matrices","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#41-low-rank-parameterized-update-matrices","p":714},{"i":735,"t":"모든 weight matrices 및 bias 에 LoRA 적용하여 훈련 시, full-rank → r-rank 을 통해 효율적인 학습이 가능하다. 하지만 한계점으로, MLP 가 필요하며 prefix-tuning 기반 방법의 경우 long input sequence 가 있어야 한다.","s":"A Generalization of Full Fine-tuning","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#a-generalization-of-full-fine-tuning","p":714},{"i":737,"t":"다른 downstream task 에 적용할 시, BABABA 대신 B′A′B'A'B′A′ 를 추가하여 빠른 작업 및 적은 메모리가 가능 이는 추가적인 inference latency 가 없음을 보장","s":"No Additional Inference Latency","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#no-additional-inference-latency","p":714},{"i":739,"t":"Transformer 에는 4 가지 weight matrix 가 있다. self-attention module (WqW_qWq​, WkW_kWk​, WvW_vWv​, WoW_oWo​) Encoder 및 Decoder 각각의 MLP module simplicity 및 parameter-efficiency 를 위해서, 위 둘 중 attention weight 의 adapting 만 연구하는 것으로 제한하며 MLP 는 freeze 한다. (downstream task 에서 훈련되지 않도록)","s":"4.2 Applying LoRA to Transformer","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#42-applying-lora-to-transformer","p":714},{"i":741,"t":"가장 큰 이점은 메모리 및 저장 공간 사용량 감소 Large Transformer 를 Adam 으로 훈련하는 경우 frozen parameter 에 대한 states 를 저장할 필요가 없어, r≪dmodelr \\ll d_{model}r≪dmodel​ 일 경우 최대 2/3 VRAM 사용량 감소 GPT-3 175B 의 VRAM 소비를 1.2TB 에서 350B 로 줄임 r=4r = 4r=4 이고 WqW_qWq​ 및 WvW_vWv​ 만 adapting 하는 경우 checkpoint 크기가 10,000배 감소 (350GB → 35MB) 대부분의 parameter 에 gradient 계산이 필요 없어, GPT-3 175B 훈련 중 25% 속도 향상 LoRA 는 한계점 또한 존재 서로 다른 task 에 사용 시, B′A′B'A'B′A′ 를 동적으로 선택해야 함","s":"Practical Benefits and Limitations","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#practical-benefits-and-limitations","p":714},{"i":743,"t":"RoBERTa, DeBERTa 및 GPT-2 에도 LoRA 실험 task 또한 natural language understanding (NLU), generation (NLG), WikiSQL (SQL queries), SAMSum (conversation summarization) 등 다양하게 실험","s":"5. Empirical Experiments","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":745,"t":"이전 연구의 설정을 재사용","s":"5.1 Baselines","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#51-baselines","p":714},{"i":747,"t":"일반적인 approach 이며, 마지막 두 layer 만 적응한 것을 FTTop2\\text{FT}^{Top2}FTTop2 로 표현","s":"Fine-Tuning (FT)","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#fine-tuning-ft","p":714},{"i":749,"t":"bias vectors 만 훈련하고 제외한 다른 것들은 freezing","s":"Bias-only or BitFit","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#bias-only-or-bitfit","p":714},{"i":751,"t":"input token 사이에 special token 을 삽입하는 것으로, 어디에 배치할지에 따라 성능이 달라진다. 저자는 \"prefixing\" 및 \"infixing\" 에 중점을 두고 실험 trainable parameter 는 ∣θ∣=dmodel×(lp+li)|\\theta| = d_{model} \\times (l_p + l_i)∣θ∣=dmodel​×(lp​+li​) lpl_plp​ : prefix lil_ili​ : infix","s":"Prefix-embedding tuning (PreEmbed)","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#prefix-embedding-tuning-preembed","p":714},{"i":753,"t":"prefix-embedding tuning 의 확장으로, word embedding 학습하는 대신 Transformer layer 이후의 activation 을 학습 이전 layer 로부터의 계산된 activation 은 학습 가능한 activation 으로 대체 trainable parameter 는 ∣θ∣=L×dmodel×+(lp+li)|\\theta| = L \\times d_{model} \\times + (l_p + l_i)∣θ∣=L×dmodel​×+(lp​+li​) LLL : Transformer layers number","s":"Prefix-layer tuning (PreLayer)","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#prefix-layer-tuning-prelayer","p":714},{"i":755,"t":"self-attention 과 residual connection 사이에 adapter layer 삽입 adapter layer 는 두 fully connected layer 와 bias 중간에 nonlinearity 로 구성되어 있다. 이 디자인을 AdapterH\\text{Adapter}^HAdapterH 라 부른다. adapter layer 를 MLP module 이후와 LayerNorm 이후에만 적용한 디자인도 있으며, AdapterL\\text{Adapter}^LAdapterL 라 부른다. 다른 설계로 Adapter-fusion 이 있으며 이는 AdapterP\\text{Adapter}^PAdapterP 로 부른다. 더 큰 효율성을 위해 일부 adapter layer 를 제거한 AdapterD\\text{Adapter}^DAdapterD 도 있다. 위 모든 케이스에서, 실험에선 ∣θ∣=L^Adpt×(2×dmodel×r+r+dmodel)+2×L^LN×dmodel|\\theta| = \\hat{L}_{Adpt} \\times (2 \\times d_{model} \\times r + r + d_{model}) + 2 \\times \\hat{L}_{LN} \\times d_{model}∣θ∣=L^Adpt​×(2×dmodel​×r+r+dmodel​)+2×L^LN​×dmodel​ 를 가짐 L^Adpt\\hat{L}_{Adpt}L^Adpt​ : adapter layer 수 L^LN\\hat{L}_{LN}L^LN​ : trainable LayerNorms 수","s":"Adapter tuning","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#adapter-tuning","p":714},{"i":757,"t":"기존 weight matrices 를 rank decomposition matrices 의 trainable pairs 를 추가 위에서 언급했듯이, 간단함을 위해 WqW_qWq​ 와 WvW_vWv​ 에만 LoRA 를 적용 trainable parameter : ∣θ∣=2×L^LoRA×dmodel×r|\\theta| = 2 \\times \\hat{L}_{LoRA} \\times d_{model} \\times r∣θ∣=2×L^LoRA​×dmodel​×r L^LoRA\\hat{L}_{LoRA}L^LoRA​ : LoRA 를 적용한 weight matrices 수","s":"LoRA","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#lora","p":714},{"i":759,"t":"RoBERTa 에서 LoRA 는 task 성능을 향상 시킴 HuggingFace Transformers 의 pre-trained RoBERTa base (125M) 및 RoBERTa large (335M) 사용 모든 task 는 동일한 배치 크기 및 128 sequence length MRPC, RTE 및 STS-B 의 경우 MNLI 에 adapted model 이 아닌 pre-trained model","s":"5.2 RoBERTa Base/Large","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#52-roberta-baselarge","p":714},{"i":761,"t":"DeBERTa 는 훨씬 큰 규모로 training 되어 GLUE 및 SuperGLUE 에 큰 성능 발휘 LoRA 는 DeBERTa XXL 에서도 여전히 성능 향상","s":"5.3 DeBERTa XXL","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#53-deberta-xxl","p":714},{"i":763,"t":"LoRA 가 NLU 에서 full fine-tuning 과 경쟁력있는 대안으로 보여, GPT-2 medium 및 large 에서도 우세한지 확인","s":"5.4 GPT-2 Medium/Large","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#54-gpt-2-mediumlarge","p":714},{"i":765,"t":"GPT-3 175B parameter 로 확장 Table 4 에서 보이듯, 3가지 데이터셋 모두 FT 와 비슷하거나 능가 Fig 2 에서 보이듯, 일부 방법은 더 많은 special token (prefix-embedding tuning 은 256개 이상 또는 prefix-layer tuning 의 경우 32개 이상)을 사용 시 성능 저하","s":"5.5 Scaling up to GPT-3 175B","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#55-scaling-up-to-gpt-3-175b","p":714},{"i":768,"t":"LoRA 에 대해 더 잘 이해할 수 있도록 경험적 실험들을 설명. 이에 대한 세 가지 질문이 있다. pre-trained Transformer 의 어떠한 가중치 행렬에 LoRA 를 적용해야 가장 높은 성능을 얻을까? 최적의 rank rrr 는 무엇일까? adaptation matrix △W\\triangle W△W 와 WWW 간의 상관관계","s":"7. Understanding the Low-Rank Updates","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":770,"t":"이전에, attention module 에만 고려했다고 언급했다. GPT-3 175B 의 경우, 1개의 attention weight 만 adapting 하면 r=8r = 8r=8 에 해당하는 18M (약 35MB 저장)의 parameter 를 설정하며, 2개의 attention weight 을 adapting 하면 r=4r = 4r=4 에 해당하는 parameter 를 모든 96개 layer 에 적용하게 된다. (Table 5) 모든 parameter 를 △Wq\\triangle W_q△Wq​ 또는 △Wk\\triangle W_k△Wk​ 에 두면 성능이 크게 저하되지만, WqW_qWq​ 및 WvW_vWv​ 둘 다 adapting 하면 최상의 결과를 얻는다. 이를 통해 rank 를 4 로 두면 충분히 △W\\triangle W△W 의 정보를 담을 수 있음을 시사한다.","s":"7.1 Which Weight Matrices in Transformer Should We Apply LoRA To?","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#71-which-weight-matrices-in-transformer-should-we-apply-lora-to","p":714},{"i":772,"t":"놀랍게도 매우 작은 rrr 에서도 LoRA 는 경쟁력있는 성능을 발휘했다. ({Wq,Wv}\\{ W_q, W_v \\}{Wq​,Wv​} 보다 WqW_qWq​ 에 더 많은 영향) 이는 update matrix △W\\triangle W△W 가 매우 작은 \"intrinsic rank\" 를 가질 수 있음을 시사","s":"7.2 What is the Optimal Rank rrr For LoRA?","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#72-what-is-the-optimal-rank-r-for-lora","p":714},{"i":774,"t":"Ar=8A_{r=8}Ar=8​ 및 Ar=64A_{r=64}Ar=64​ 가 주어졌을 때, 동일한 pre-trained model 을 사용하여 singular value decomposition (SVD) 수행하고 right-singular unitary matrices UAr=8U_{A_{r=8}}UAr=8​​ 및 UAr=64U_{A_{r=64}}UAr=64​​ 를 얻음 이때 UAr=8U_{A_{r=8}}UAr=8​​ (1≤i≤81 \\leq i \\leq 81≤i≤8) 의 top iii singular vectors 로 구성된 subspace 중, UAr=64U_{A_{r=64}}UAr=64​​ (1≤i≤641 \\leq i \\leq 641≤i≤64) 의 top jjj singular vectors 의 subspace 에 얼마나 포함되었을 까? 이를 Grassmann distance 기반으로 정규화된 subspace similarity 를 측정 ϕ(Ar=8,Ar=64,i,j)=∣∣UAr=8i⊤UAr=64j∣∣F2min⁡(i,j)∈[0,1](4)\\phi (A_{r=8}, A_{r=64}, i, j) = \\frac{|| U^{i\\top}_{A_{r=8}} U^{j}_{A_{r=64}} ||^2_F}{\\min (i, j)} \\in [0,1] \\tag{4}ϕ(Ar=8​,Ar=64​,i,j)=min(i,j)∣∣UAr=8​i⊤​UAr=64​j​∣∣F2​​∈[0,1](4) UAr=8i⊤U^{i\\top}_{A_{r=8}}UAr=8​i⊤​ : top-iii singular vectors 에 해당하는 UAr=8U_{A_{r=8}}UAr=8​​ 의 columns ϕ(⋅)\\phi ( \\cdot )ϕ(⋅) 는 [0,1][0,1][0,1] 범위 1 은 subspace 에 완전한 중첩 0 은 완전한 분리 iii 및 jjj 를 변화시키면 ϕ\\phiϕ 가 어떻게 변하는 지는 Fig 3 참고 위를 통해 다음 주요 관찰을 할 수 있다. Ar=8A_{r=8}Ar=8​ 의 △Wv\\triangle W_v△Wv​ (또는 △Wq\\triangle W_q△Wq​) 와 Ar=64A_{r=64}Ar=64​ 의 △Wv\\triangle W_v△Wv​ (또는 △Wq\\triangle W_q△Wq​) 는 dimension 1 의 subspace 를 공유하며 normalized similarity >0.5> 0.5>0.5 이며, 이것이 GPT-3 에 r=1r = 1r=1 잘 동작하는 이유","s":"Subspace similarity between different rrr","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#subspace-similarity-between-different-r","p":714},{"i":776,"t":"r=64r = 64r=64 로 무작위 seed 로 실행된 두 normalized subspace similarity 를 Fig 4 에서 확인 △Wq\\triangle W_q△Wq​ 는 △Wv\\triangle W_v△Wv​ 보다 높은 \"intrinsic rank\" 를 가질 것으로 보이며, △Wq\\triangle W_q△Wq​ 에 대한 두 실행 모두 학습된 common singular value direction 이 더 많이 있어, Table 6 의 관찰과 일치","s":"Subspace similarity between different random seeds","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#subspace-similarity-between-different-random-seeds","p":714},{"i":778,"t":"저자는 △W\\triangle W△W 와 WWW 간의 상관관계를 더욱 조사. WWW 는 △W\\triangle W△W 의 rrr-dimensional subspace 에 U⊤WV⊤U^{\\top}WV^{\\top}U⊤WV⊤ 를 계산하여 project 여기서 U/VU/VU/V 는 △W\\triangle W△W 의 left/right singular-vector matrix 이다. 이후, ∣∣U⊤WV⊤∣∣F||U^{\\top}WV^{\\top}||_F∣∣U⊤WV⊤∣∣F​ 와 ∣∣W∣∣||W||∣∣W∣∣ 간의 Frobenius norm 비교 비교를 위해 U,VU, VU,V 를 WWW 의 top rrr singular vectors 또는 random matrix 로 대체하여 ∣∣U⊤WV⊤∣∣F||U^{\\top}WV^{\\top}||_F∣∣U⊤WV⊤∣∣F​ 계산 위 Table 에서 다음 결론을 얻을 수 있음 △W\\triangle W△W 는 random matrix 와 비교하여, WWW 와 더 강한 상관관계를 가지며, △W\\triangle W△W 는 이미 WWW 에 있는 일부 기능을 강화 WWW 의 top singular direction 을 반복하는 대신, △W\\triangle W△W 는 WWW 의 강조되지 않은 direction 만을 강화 증폭 계수가 매우 큼: r=4r = 4r=4 에 대해, 21.5≈6.91/0.3221.5 \\approx 6.91/0.3221.5≈6.91/0.32","s":"7.3 How Does the Adaptation Matrix △W\\triangle W△W Compare To WWW?","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"#73-how-does-the-adaptation-matrix-triangle-w-compare-to-w","p":714},{"i":780,"t":"LLM 을 fine-tuning 하는 것인 많은 비용 및 시간이 듬 본 연구의 LoRA 라는 방법을 통해 inference latency 을 줄이며 sequence length 를 줄이지 않는 전략 대부분의 model parameter 를 공유하여 배포도 용이 Future work LoRA 를 다른 adaptation method 와 결합하여 개선 가능 fine-tuning 또는 LoRA 의 숨겨진 메커니즘 LoRA 를 adapting 할 weight matrix 선택 △W\\triangle W△W 의 rank 축소 가능한지 여부","s":"8. Conclusion And Future Work","u":"/docs/Paper/NLP/PEFT/Composition/LoRA","h":"","p":714},{"i":782,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.10512.pdf","s":"Adaptive Budget Allocation For Parameter-Efficient Fine-Tuning","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":784,"t":"large pre-trained language models (PLMs) 을 downstream tasks 에 fine-tuning 하는 것은 NLP 의 주요 패러다임 보통 pre-trained model 의 all parameter 를 fine-tuning 하는데, 이는 downstream tasks 이 많으면 비효율적이다. 많은 fine-tuning 방법이 제안되었으며, all pre-trained weights 의 incremental update 로 학습하는 효율적인 방법을 찾는데 사용 이 방법들은 종종 all pre-trained weight matrices 에 대한 incremental updates budget 을 균등하게 분배하며, 다른 weight parameter 의 중요성을 간과함 결과적으로 fine-tuning 성능은 sub-optimal 위 사항을 극복하기 위해 저자는 AdaLoRA 제안 weight matrices 의 importance score 에 따라 parameter budget 을 adaptively allocate AdaLoRA 는 singular value decomposition (SVD) 형식으로 incremental updates 를 parameterize 위 nodel approach 는 unimportant update 의 singular value 를 효과적으로 제거 근본적으로 parameter budget 을 줄이는 것이지만 고사양의 SVD computations 를 피하는 것이다. 저자는 natural language processing, question answering 및 natural language generation 에 여러 pre-trained model 을 광범위하게 실험하여 AdaLoRA 의 효과를 검증 결과 AdaLoRA 는 baseline 대비 획기적으로 개선하며, 특히 low budget setting 에서 높은 효과를 나타냈다.","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":786,"t":"fine-tuned PLMs 는 다양한 NLP 에 우수한 성능을 보여주지만 큰 메모리 공간을 필요로 한다. BERT 는 300M, T5 는 11B, GPT-3 175B 등 매우 큰 parameter 로 이루어져 있다. 이러한 PLMs 로 NLP 시스템을 구축할 때, 일반적으로 multiple tasks 를 동시에 다루어야 하는데, 다수의 downstream tasks 가 있을 경우, full fine-tuning 은 각 task 에 별도의 LM copy 를 유지해야하므로 메모리 소비가 과도하게 비싸진다. 이를 해결하기 위해 PLM 의 fine-tuning parameter 수를 줄이며 성능을 유지/향상 시키기 위한 두 가지 주요 연구 방향이 제시됐다. PLM 에 small neural modules 를 추가하고 각 task 에 대한 이 modules 만 fine-tuning base model 은 freezing 하고 tasks 간에 공유 적은 수의 task-specifc parameter 만 도압되고 업데이트되므로 large model 의 실용성 향상 예로, adapter tuning 은 base model 사이에 adapters 라는 small neural modules 삽입 prefix-tuning 및 prompt tuning 은 base model 의 input 또는 hidden layer 에 additional trainable prefix tokens 부착 위 방법들은 full fine-tuning 과 comparable 한 성능 달성하며 parameter 의 1% 미만을 업데이트하기 때문에 메모리 소비도 줄인다. model architecture 수정 없이, pre-trained weight 의 incremental update 를 parameter-efficient 방법으로 모델링 예로, Given pre-trained weight matrix W(0)W^{(0)}W(0) diff pruning 은 incremental update △\\triangle△ 를 sparse matrix 로 모델링 Diff pruning 은 △\\triangle△ 를 W(0)W^{(0)}W(0) 와 same dimension 으로 초기화하고 entry 규모에 기반하여 △\\triangle△ 를 element-wise 제거 diff pruning 은 important updates 를 adaptively retaining 및 unimportant 것은 제거하여 parameter-efficient 효율성 크게 높임 하지만 diff pruning 에는 여러 제한 사항 존재 unstructured sparse matrices 의 computation 을 가속화하기 위해 low-level implementation 에 의존하며, 이는 deep learning 에서 제대로 지원하지 않음 따라서 training 중 △\\triangle△ 를 dense matrix 에 저장해야 함 △\\triangle△ 의 각 entry 를 해당 gradient 로 업데이트하고 제거해야함 이로 인해 full fine-tuning 과 유사한 계산 비용 발생 위 단점을 극복하기 위해, LoRA 라는 메소드도 제안되었으며, 이는 △\\triangle△ 를 두 개의 smaller matrices 의 곱으로 low-rank matrix 로 parameterize W=W(0)+△=W(0)+BA,\\begin{equation} W = W^{(0)} + \\triangle = W^{(0)} + BA, \\end{equation}W=W(0)+△=W(0)+BA,​​ W(0)W^{(0)}W(0), △∈Rd1×d2\\triangle \\in \\mathbb{R}^{d_1 \\times d_2}△∈Rd1​×d2​, A∈Rr×d2A \\in \\mathbb{R}^{r \\times d_2}A∈Rr×d2​, B∈Rd1×rB \\in \\mathbb{R}^{d_1 \\times r}B∈Rd1​×r, r≪{d1,d2}r \\ll \\{ d_1, d_2 \\}r≪{d1​,d2​} fine-tuning 중, AAA, BBB 만 업데이트 rank rrr 은 dimension WWW 보다 작게 선택 (e.g. d1=d2=1024d_1 = d_2 = 1024d1​=d2​=1024 일 때 r=8r = 8r=8) additional trainable parameter 가 0.5% 미만인 상황에서, training overhead 를 full fine-tuning 대비 최대 70% 까지 줄임 LoRA 는 full fine-tuning 과 유사하거나 더 나은 성능 달성 한편, 두 small matrices 의 곱셈은 diff pruning 의 unstructured sparse matrices 보다 implement 및 deploy 가 더 쉬움 LoRA 는 여전히 제한 사항 존재 각 incremental matrix △\\triangle△ 의 rank rrr 을 동일하게 미리 지정 pre-trained models 를 fine-tuning 할 때 weight matrices 의 중요성이 modules 및 layers 간에 크게 다르다는 사실을 무시 이를 설명하기 위해 Fig. 1 에 구체적으로 제시 동일한 trainable parameter 수로 specific modules 또는 layers 를 fine-tuning 할 때 LoRA 의 성능 비교 Fig. 1a 에선 feed-forward networks (FFN) 를 fine-tuning 하면 self-attention modules 보다 더 나은 성능 달성 Fig. 1b 에선 top layers 의 weight matrices 가 bottom layers 보다 더 중요하단 것 보여줌 주요 weight matrices 에 더 맘ㄶ은 trainable parameter 를 추가하면 model performance 향상 가능. 반면, less important weight matrices 를 추가하면 향상되지 않거나 저해 가능 parameter budget, i.e. total trainable parameters 가 주어진 경우, 항상 important modules 에 더 많은 parameter 를 할당하는 것이 좋다. budget 을 모든 weight matrices/layers 에 고르게 분배하는 LoRA 및 다른 방법(e.g. adapter/prefix tuning)은 부적절한 성능을 낼 수 있음 위 사항으로 다음 질문 제기 importance modules 에 따라 parameter budget 을 adaptively 할당하여 PEFT 성능을 향상시키는 방법은 뭘까? 위 질문을 위해 새로운 방법 AdaLoRA (Adaptive Low-Rank Adaptation) 제안 LoRA-alike fine-tuning 동안 weight matrices 사이에서 parameter budget 을 동적으로 할당 구체적으로, AdaLoRA 는 incremental matrices 의 rank 를 조절하여 budget 을 제어한다. Critical incremental matrices 에는 high rank 가 할당되어 fine-grained 및 task-specific information 을 더 capture 가능 Less inportance ones 는 overfitting 을 방지하고 computational budget 절약을 위해 lower rank 로 제거 matrices approximation 의 기존 연구에서 matrices rank 를 제어하는 여러 방법이 있다. 대부분은 matrix 의 SVD 를 직접 계산한 다음 smallest singular value 를 truncate 이런 작업은 rank 를 명시적으로 조작할 수 있으며, resulting matrix 와 original matrix 간의 차이를 최소화한다. 하지만 fine-tuning large models 에서는 high-dimensional weight matrices 에 대한 SVD 를 반복적으로 적용하기엔 비용이 크므로 SVD 를 정확하게 계산하는 대신 △\\triangle△ 를 △=PΛQ\\triangle = P \\Lambda Q△=PΛQ 로 모델링하여 SVD 를 모방한다. diagonal matrix Λ\\LambdaΛ 에는 singular values 가 포함되어 있으며 orthogonal matrices PPP 및 QQQ 는 △\\triangle△ 의 left/right singular vectors 를 나타냄 PPP 와 QQQ 의 orthogonality 를 regularizing 하기 위해 training loss 에 additional penalty 를 추가 이러한 parameterization 은 SVD 의 intensive computations 을 피한다. unimportant singluar values 만 drop 하면서 singular vectors 는 유지 저자는 AdaLoRA 효과 입증을 위해 다양한 task 및 models 에 포괄적 실험 NLU (GLUE) 및 QA (SQuADv1, SQuADv2) dataset 에서 DeBERTaV3-base 성능 평가 BART-large 에 저자의 approach 를 적용하고 NLG (XSum 및 CNN/DailyMail) task 에서의 성능 평가 AdaLoRA 가 low budget setting 에서 우수한 성과 full fine-tuning 의 0.1% 미만의 trainable parameter 로 SQuAD2.0 dataset 에서 SOTA approach 와 비교하여 1.2% F1 개선","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":789,"t":"전형적인 Transformer model 은 LLL stacked blocks 로 이루어져 있다. 각 블록은 two submodules 를 포함한다 multi-head attention (MHA) 및 full connected FFN Given input sequence X∈Rn×dX \\in \\mathbb{R}^{n \\times d}X∈Rn×d, MHA 는 병렬로 hhh head 에서 attention function 을 수행 MHA(X)=Concat(head1,…,headh)Wo,head)i=Softmax(XWqi(XWki)⊤/dn)XWvi,\\text{MHA} (X) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h)W_o, \\quad \\text{head})i = \\text{Softmax}(XW_{qi}(XW_{ki})^\\top / \\sqrt{d_n})XW_{vi,}MHA(X)=Concat(head1​,…,headh​)Wo​,head)i=Softmax(XWqi​(XWki​)⊤/dn​​)XWvi,​ Wo∈Rd×dW_o \\in \\mathbb{R}^{d \\times d}Wo​∈Rd×d : output projection Wqi,Wki,Wvi∈Rd×dhW_{qi}, W_{ki}, W_{vi} \\in \\mathbb{R}^{d \\times d_h}Wqi​,Wki​,Wvi​∈Rd×dh​ : query, key 및 value projection of head iii dhd_hdh​ : 일반적으로 d/hd/hd/h set 다른 important module 인 FFN 은 two linear transformations 와 그 사이에 ReLU activation 을 포함 FFN(X)=ReLU(XWfi+b1)Wf2+b2\\text{FFN}(X) = \\text{ReLU}(XW_{fi} + b_1)W_{f2} + b_2FFN(X)=ReLU(XWfi​+b1​)Wf2​+b2​ Wf1∈Rd×dmW_{f1} \\in \\mathbb{R}^{d \\times d_m}Wf1​∈Rd×dm​ Wf2∈Rdm×dW_{f2} \\in \\mathbb{R}^{d_m \\times d}Wf2​∈Rdm​×d 마지막으로 residual connection 이 사용되며 layer normalization 수행","s":"Transformer-based Models","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#transformer-based-models","p":781},{"i":791,"t":"LoRA 는 two small matrices 의 곱으로 pre-trained weights 를 incremental update 모델링 h=W(0)h = W^{(0)}h=W(0) 의 경우, 수정된 forward pass 는 다음과 같다. h=W(0)x+△x=W(0)x+BAx,\\begin{equation} h = W^{(0)}x + \\triangle x = W^{(0)}x + BAx, \\end{equation}h=W(0)x+△x=W(0)x+BAx,​​ W(0)W^{(0)}W(0), △∈Rd1×d2\\triangle \\in \\mathbb{R}^{d_1 \\times d_2}△∈Rd1​×d2​, A∈Rr×d2A \\in \\mathbb{R}^{r \\times d_2}A∈Rr×d2​, B∈Rd1×rB \\in \\mathbb{R}^{d_1 \\times r}B∈Rd1​×r, r≪{d1,d2}r \\ll \\{ d_1, d_2 \\}r≪{d1​,d2​} 일반적으로 AAA 는 random Gaussian initialization 을 채택하고, BBB 는 training 초기에 △=0\\triangle = 0△=0 이 되도록 0 으로 초기화 Ai∗A_{i*}Ai∗​ 는 AAA 의 iii-th row, B∗iB_{*i}B∗i​ 는 BBB 의 iii-th column, Gi={Ai∗,B∗i}\\mathcal{G}_i = \\{ A_{i*}, B_{*i} \\}Gi​={Ai∗​,B∗i​} 는 iii-th doublet LoRA 는 주로 MHA 의 query 및 value projections 만 적용 [Towards a unified view of parameter-efficient transfer learning. He] 는 FFN 의 weight matrix (i.e. Wf1W_{f1}Wf1​, Wf2W_{f2}Wf2​) 에도 확장하여 성능 향상. 동시에 adapter tuning, prefix tuning 및 LoRA 를 포함한 다양한 efficient tuning 에 대한 통합된 관점 제안","s":"Low Rank Adaptation","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#low-rank-adaptation","p":781},{"i":793,"t":"저자는 두 가지 주요 구성 요소 포함 SVD-based adaptation. incremental matrices 를 singluar value decomposition 형태로 고안 Importance-aware rank allocation, 새로 디자인된 importance metric 을 기반으로 redundant singluar values 제거","s":"3. AdaLoRA Method","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":795,"t":"pre-trained weight matrices 의 incremental update 를 singular value decomposition 형식으로 parameterize W=W(0)+△=W(0)+PΛQ,\\begin{equation} W = W^{(0)} + \\triangle = W^{(0)} + P \\Lambda Q, \\end{equation}W=W(0)+△=W(0)+PΛQ,​​ P∈Rd1×rP \\in \\mathbb{R}^{d_1 \\times r}P∈Rd1​×r 및 Q∈Rr×d2Q \\in \\mathbb{R}^{r \\times d_2}Q∈Rr×d2​ : △\\triangle△ 의 left/right singular vectors diagonal matrix Λ∈Rr×r\\Lambda \\in \\mathbb{R}^{r \\times r}Λ∈Rr×r : singular values {λi}1≤i≤r\\{ \\lambda _i \\}_{1 \\leq i \\leq r}{λi​}1≤i≤r​ ( r≪min⁡(d1,d2)r \\ll \\min (d_1, d_2)r≪min(d1​,d2​) ) 를 포함 나아가, iii-th singular value 및 vectors 를 포함하는 triplet 을 G={P∗i,λi,Qi∗}\\mathcal{G} = \\{ P_{*i}, \\lambda_{i}, Q_{i*} \\}G={P∗i​,λi​,Qi∗​} 로 표시 실제론, Λ\\LambdaΛ 는 diagonal 이므로 Rr\\mathbb{R}^rRr 의 vector 로만 저장된다. Λ\\LambdaΛ 는 0 으로 초기화되고 PPP 및 QQQ 는 △\\triangle△ 가 training 초기에 0 이 되도록 하기 위해 random Gaussian 초기화를 채택 PPP 및 QQQ 의 orthogonality 강화를 위해 아래 regularizer 활용 R(P,Q)=∥P⊤P−I∥F2=∥QQ⊤−I∥F2.\\begin{equation} R(P,Q) = \\left \\| P^\\top P - I \\right \\|^2_\\text{F} = \\left \\| QQ^\\top - I \\right \\|^2_\\text{F}. \\end{equation}R(P,Q)=∥∥​P⊤P−I∥∥​F2​=∥∥​QQ⊤−I∥∥​F2​.​​ 저자의 방법에서, 각 gradient decent step 이후 rank 조절을 위해 Λ\\LambdaΛ 가 반복적으로 제거됨 모든 △\\triangle△ 에 대해 직접 SVD 를 계산하여 singular values 를 조작할 수 있다. 하지만 계산 복잡성은 O(min⁡(d1,d2)d1d2)O(\\min (d_1, d_2)d_1d_2)O(min(d1​,d2​)d1​d2​) 에 있다. 큰 수의 high-dimensional incremental matrices 에 대해 반복적으로 SVD 를 적용하는 것은 비용이 크다 반면, 저자의 parameterization 은 intensive SVD computation 을 피하므로 computational overhead 를 크게 줄인다. LoRA 는 structured pruning 을 적용하여 rank 를 제어할 수 있지만 (i.e. prune BABABA doublet-wise) 다음과 같은 단점이 있다. doublet 이 중요하지 않다 측정되면 해당 요소 모두 pruning 해야함 이로 인해, pruned dublet 을 다시 활성화하기가 거의 불가능 doublet entries 는 모두 제거되고 훈련되지 않으므로 잘못 삭제된 doublet 을 재활성화하는 가능성을 보존하지 않음 반면, adaLoRA 는 Eq. 3 에 기반하여 singular values 를 masking 하며 singular vectors 를 항상 유지 LoRA 의 AAA 와 BBB 는 orthogonal 이 아니므로, doublets 간에 종속성이 있을 수 있음 doublets 를 버리면 smallest singular values 를 truncating 하는 것보다 original matrix 와의 larger variation 발생 가능 따라서 rank allocation 의 각 step 에 incremental matrices 가 극도로 변경되어 훈련 불안정성을 유발하고 일반화에도 해를 입힐 수 있다.","s":"3.1 SVD-Based Adaptation","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#31-svd-based-adaptation","p":781},{"i":797,"t":"저자는 SVD-based adaptation 을 각 transformer layer 의 weight matrix Wq,Wk,Wv,Wf1W_q, W_k, W_v, W_{f1}Wq​,Wk​,Wv​,Wf1​ 및 Wf2W_{f2}Wf2​ 에 적용 budget 제어를 위해, training 중 importance score 에 대응하여 singular values 를 반복적으로 제거한다. kkk 로 incremental matrix 를 인덱싱. i.e. △k=PkΛkQk\\triangle_k = P_k \\Lambda_k Q_k△k​=Pk​Λk​Qk​ for k=1,…,nk = 1,\\dots, nk=1,…,n nnn : adapted weight matrices 수 Gk,i={Pk,∗i,λk,i,Qk,i∗}\\mathcal{G}_{k,i} = \\{ P_{k,*i}, \\lambda_{k,i}, Q_{k,i*} \\}Gk,i​={Pk,∗i​,λk,i​,Qk,i∗​} : △k\\triangle_k△k​ 의 iii-th triplet Sk,i∗S_{k,i*}Sk,i∗​ : importance score parameter set P={Pk}k=1n\\mathcal{P} = \\{ P_k \\}^n_{k=1}P={Pk​}k=1n​, E={Λk}k=1n\\mathcal{E} = \\{ \\Lambda_k \\}^n_{k=1}E={Λk​}k=1n​, Q={Qk}k=1n\\mathcal{Q} = \\{ Q_k \\}^n_{k=1}Q={Qk​}k=1n​ training cost C(P,E,Q)\\mathcal{C} (\\mathcal{P}, \\mathcal{E}, \\mathcal{Q})C(P,E,Q) With regularization Eq. 4, training objective L(P,E,Q)=C(P,E,Q)+γ∑k=1nR(Pk,Qk)\\mathcal{L}(\\mathcal{P}, \\mathcal{E}, \\mathcal{Q}) = \\mathcal{C}(\\mathcal{P}, \\mathcal{E}, \\mathcal{Q}) + \\gamma \\sum^n_{k=1} R(P_k, Q_k)L(P,E,Q)=C(P,E,Q)+γ∑k=1n​R(Pk​,Qk​) γ>0\\gamma > 0γ>0 : regularization coefficient ttt-th step 에서, 저자는 k=1,…,nk = 1, \\dots, nk=1,…,n 에 대한 Pk(t)P^{(t)}_kPk(t)​, Λk(t)\\Lambda^{(t)}_kΛk(t)​ 및 Qk(t)Q_k^{(t)}Qk(t)​ update 에 stochastic gradient step 사용 특히 Λk(t)\\Lambda_k^{(t)}Λk(t)​ 의 경우 Λ~k(t)=Λk(t)−η▽ΛkL(P(t).E(t),Q(t)),\\begin{equation} \\tilde{\\Lambda}_k^{(t)} = \\Lambda_k^{(t)} - \\eta \\triangledown_{\\Lambda_k} \\mathcal{L}(\\mathcal{P}^{(t)}. \\mathcal{E}^{(t)}, \\mathcal{Q}^{(t)}), \\end{equation}Λ~k(t)​=Λk(t)​−η▽Λk​​L(P(t).E(t),Q(t)),​​ η>0\\eta > 0η>0 : learning rate Given importance score Sk(t)S_k^{(t)}Sk(t)​, singular values 는 다음을 따라 pruning 됨 Λk(t+1)=T(Λ~k(t),Sk(t)),withT(Λ~k(t),Sk(t))ii={Λ~k,iitSk,it is in the top-b(t) of St,0otherwise,\\begin{equation} \\Lambda_k^{(t+1)} = \\mathcal{T} (\\tilde{\\Lambda}_k^{(t)}, S_k^{(t)}), \\text{with} \\mathcal{T}(\\tilde{\\Lambda}_k^{(t)}, S_k^{(t)})_{ii} = \\left\\{\\begin{matrix} \\tilde{\\Lambda}^{t}_{k,ii} & S^{t}_{k,i}\\ \\text{is in the top-}b^{(t)}\\ \\text{of}\\ S^{t}, \\\\ 0 & \\text{otherwise,} \\end{matrix}\\right. \\end{equation}Λk(t+1)​=T(Λ~k(t)​,Sk(t)​),withT(Λ~k(t)​,Sk(t)​)ii​={Λ~k,iit​0​Sk,it​ is in the top-b(t) of St,otherwise,​​​ St={Sk,i(t)}1≤k≤n,1≤i≤rS^{t} = \\{ S_{k,i}^{(t)} \\}_{1 \\leq k \\leq n, 1 \\leq i \\leq r}St={Sk,i(t)​}1≤k≤n,1≤i≤r​ : all triplets 의 importance score 포함 b(t)b^{(t)}b(t) : ttt-th step 에서의 나머지 singular values 의 budget less important singular values 를 제거함으로써 higher priority incremental matrices 에 더 많은 budget 을 부여 저자는 importance score 를 설계하기 위해 몇가지 옵션 도입","s":"3.2 Importance-Aware Rank Allocation","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#32-importance-aware-rank-allocation","p":781},{"i":799,"t":"모든 triplet 의 중요성을 quantify 하는 가장 직접적인 방법 중 하나. i.e. Sk,i=λk,iS_{k,i} = \\lambda_{k,i}Sk,i​=λk,i​ 이 방법으로 가장 중요하지 않은 singular values 만 제거된다. 이는 original matrix 와의 차이를 최소화하고 training 을 더욱안정화 시킨다. 기존의 많은 연구에서 이러한 criterion 을 사용하여 matrix rank 를 제어했다. 하지만, 이러한 simple metric 은 parameter 가 model performance 에 미치는 기여를 적절하게 quantify 할 수 없다는 점","s":"Magnitude of singular values","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#magnitude-of-singular-values","p":781},{"i":801,"t":"importance scoring 의 다른 대안으로, training loss 에 대한 parameters sensitivity 를 quantify 하지만 이전 연구에선 sensitivity 를 사용하여 single entries 의 importance 를 quantify 하고 weights elemen-wise 제거하는 unstructured pruning 적용 저자의 경우는, triplets 가 group-wise 로 제거되기 때문에, new metric 을 디자인해야 한다. 각 entry 의 sensitivity 를 고려하고 triplets 의 모델 성능에 대한 기여를 quantify 하기 위해 결합 따라서 저자의 triplets Gk,i\\mathcal{G}_{k,i}Gk,i​ 내의 singular value 및 vectors 를 모두 고려한 새로운 importance metric 제안 Sk,i=s(λk,i)+1d1∑j=1d1s(Pk,ji)+1d2∑j=1d2s(Qk,ij),\\begin{equation} S_{k,i} = s(\\lambda _{k,i}) + \\frac{1}{d_1} \\sum^{d_1}_{j=1} s(P_{k,ji}) + \\frac{1}{d_2} \\sum^{d_2}_{j=1} s(Q_{k,ij}), \\end{equation}Sk,i​=s(λk,i​)+d1​1​j=1∑d1​​s(Pk,ji​)+d2​1​j=1∑d2​​s(Qk,ij​),​​ 여기서 저자는 Pk,∗iP_{k, *i}Pk,∗i​ 및 Qk,i∗Q_{k,i*}Qk,i∗​ 의 mean importance 를 계산하여 Sk,iS_{k,i}Sk,i​ 가 Gk,i\\mathcal{G}_{k,i}Gk,i​ 의 parameter 수와 상관없이 조절되도록 함 s(⋅)s(\\cdot)s(⋅) : single entries 에 대한 specific importance function s(⋅)s(\\cdot)s(⋅) 로 sensitivity 를 채택할 수 있으며, 이는 gradient-weight 곱의 크기로 정의 I(wij)=∣wij▽wijL∣,\\begin{equation} I(w_{ij}) = \\left | w_{ij} \\triangledown_{w_{ij}} \\mathcal{L} \\right |, \\end{equation}I(wij​)=∣∣​wij​▽wij​​L∣∣​,​​ wijw_{ij}wij​ : any trainable parameter Eq. 8 은 parameter 가 제거했을 때, loss 의 변화를 근사화하는 것 parameter 의 제거가 큰 영향을 미친다면, 모델은 이에 민감하며 유지해야 한다. 하지만, [Platon] 은 Eq. 8 의 sensitivity 가 아직 신뢰할 수 있는 importance 지표가 아니라는 지적을 함. 이 score 는 sample mini batch 에서 sample 되어 그런 것으로 추정한다. stochastic sampling 및 complicated training 은 Eq. 8 을 사용하여 sensitivity 를 추정할 때 높은 변동성과 큰 불확실성을 초래 따라서 [Platon] 은 sensitivity smoothing 과 uncertainly quantification 제안 I‾(t)(wij)=β1I‾(t−1)(wij)+(1−β1)I(t)(wij)U‾(t)(wij)=β2U‾(t−1)(wij)+(1−β2)∣I(t)(wij)−I‾(t)(wij)∣,\\begin{align} \\overline{I}^{(t)}(w_{ij}) &= \\beta_1 \\overline{I}^{(t-1)}(w_{ij}) + (1-\\beta_1)I^{(t)}(w_{ij}) \\\\ \\overline{U}^{(t)}(w_{ij}) &= \\beta_2 \\overline{U}^{(t-1)}(w_{ij}) + (1-\\beta_2) \\left | I^{(t)}(w_{ij}) - \\overline{I}^{(t)}(w_{ij}) \\right |, \\end{align}I(t)(wij​)U(t)(wij​)​=β1​I(t−1)(wij​)+(1−β1​)I(t)(wij​)=β2​U(t−1)(wij​)+(1−β2​)∣∣​I(t)(wij​)−I(t)(wij​)∣∣​,​​ 0<β1,β2<1.0 < \\beta_1, \\beta_2 < 1.0<β1​,β2​<1. I‾(t)\\overline{I}^{(t)}I(t) : exponential moving average 을 사용한 smoothed sensitivity U‾(t)\\overline{U}^{(t)}U(t) : I(t)I^{(t)}I(t) 및 I‾(t)\\overline{I}^{(t)}I(t) 사이의 local variation 에 의해 quantify 된 uncertainly term importance 를 I‾(t)\\overline{I}^{(t)}I(t) 및 U‾(t)\\overline{U}^{(t)}U(t) 간의 곱으로 정의 이는 s(⋅)s(\\cdot)s(⋅) 에 대한 다른 option 이 될 수 있다. s(t)(wij)=I‾(t)(wij)⋅U‾(t)(wij).\\begin{equation} s^{(t)}(w_{ij}) = \\overline{I}^{(t)}(w_{ij}) \\cdot \\overline{U}^{(t)}(w_{ij}). \\end{equation}s(t)(wij​)=I(t)(wij​)⋅U(t)(wij​).​​ 다양한 importance metrics 비교를 위해 세부적인 ablation 은 Section 4.4 에서 제시 저자는 sensitivity variant (Eq. 11) 을 기반한 metric (Eq. 7)이 우수한 성능을 내는 것을 발견. 저자는 다음과 같은 알고리즘 요약","s":"Sensitivity-based importance","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#sensitivity-based-importance","p":781},{"i":803,"t":"rank 조절은 low-rank adaptation 의 맥락에서 parameter budget 을 제어하는 것이다. 따라서 저자는 all incremental matrices 의 total rank (i.e. total singular values 수) 를 budget b(t)b^{(t)}b(t) 로 정의한다. budget allocation 은 fine-tuning 중 반복적으로 수행된다. training 을 용이하게 하기 위해, 저자는 global budget scheduler 를 제안한다. 구체적으로, initial budget b(0)b^{(0)}b(0) 을 target budget b(T)b^{(T)}b(T) 보다 약간 높게 설정 (e.g. b(T)b^{(T)}b(T) 의 약 1.5배) 각 incremental matrix 의 intial rank 를 r=b(0)/nr = b^{(0)} / nr=b(0)/n 으로 설정 저자는 tit_iti​ steps 동아안 warm up training 그리고 budget b(t)b^{(t)}b(t) 가 b(T)b^{(T)}b(T) 에 도달할 때까지 b(t)b^{(t)}b(t) 를 감소시키기 위해 cubic schedule 따름 마지막으로, resulting budget 을 고정하고 모델을 tft_ftf​ 단계 동안 fine-tuning 이는 AdaLoRA 가 먼저 parameter space 을 탐색한 다음 가장 중요한 weight 에 집중할 수 있도록 한다.","s":"3.3 Global Budget Scheduler","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#33-global-budget-scheduler","p":781},{"i":805,"t":"AdaLoRa 를 구현하여 DeBERTaV3-base 와 BART-large 를 fine-tuning 하는데 사용 제안된 알고리즘의 효과를 NLU (GLUE), QA (SQuADv1 및 SQuADv2) 및 NLG (XSum 및 CNN/DailyMail) 에서 평가 all gain 이 p<0.05p < 0.05p<0.05 로 유의한 결과 얻음","s":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":807,"t":"저자는 PyTorch 로 모든 알고리즘 구현 구현은 publicly available Huggigface Transformers 코드 기반 모든 실험은 NVIDIA V100 GPUs 에 수행 LoRA 는 △x\\triangle x△x 를 α/γ\\alpha / \\gammaα/γ 로 scaling 했다. α\\alphaα : γ\\gammaγ 에 대한 상수 output 의 크기는 서로 다른 γ\\gammaγ 에 대해 일관되게 유지될 수 있으므로 γ\\gammaγ 를 변경할 때 learning rate 에 드는 노력을 줄임 α\\alphaα 는 16 또는 32 로 설정 되며 tuning 하지 않음 LoRA 에 따르면, Eq. 3 에 동일한 scaling 을 추가하고 α\\alphaα 를 LoRA 에 고정 또한, Algorithm 1 에서 저자는 모든 △T\\triangle_T△T​ steps (e.g. △T=100\\triangle_T = 100△T​=100) 에서 singular values 를 제거하므로 pruned triplets 는 이러한 간격 내에서 업데이트될 수 있으며 future iterations 에서 다시 활성화될 수 있음","s":"Implementation Details","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#implementation-details","p":781},{"i":809,"t":"AdaLoRA 를 다음 방법들과 비교 full fine-tuning : adaptation 을 위한 가장 일반적인 approach fine-tuning 중, 모델은 pre-trained weights 및 biases 로 초기화되고 모든 model parameter 가 gradient updates Bitfit : 효과적인 parameter-efficient fine-tuning pre-trained model 에서 bias vectors 만 fine-tuning Adapter tuning : transformer blocks 사이에 two-layer adapters 삽입 저자는 두 가지 유형의 adapter 와 비교 Houlsby adapter 는 self-attention module 및 FFN module 사이에 삽입하며 그 뒤 residual connection Adapter-fusion (Pfeiffer) 은 adapter 를 FFN module 과 LayerNorm module 이후에만 적용하는 효율적인 디자인 제안 trainable parameter 수는 layer 수, adapter 의 hidden dimension 및 inputs dimension 에 의해 결정 LoRA : parameter-efficient fine-tuning 의 SOTA method two small matrices 로 incremental updates 를 parameterize 하고 이 두 행렬만 fine-tuning trainable parameter 의 수는 rank rrr 및 adapted weight matrices 의 수 nnn 으로 제어 [Hu] 는 LoRA 에 query 및 value projection 에만 적용 저자는 LoRA 를 all weight matrices (i.e. Wq,Wk,Wv,Wf1,Wf2W_q, W_k, W_v, W_{f_1}, W_{f_2}Wq​,Wk​,Wv​,Wf1​​,Wf2​​) 에 적용하여 성능 향상을 발견 따라서 저자는 이 일반화된 LoRA 와 비교하여 성능 극대화","s":"Baselines","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#baselines","p":781},{"i":812,"t":"저자가 제안된 알고리즘으로 DeBERTaV3-base 의 fine-tuning 성능 평가 NLU (GLUE) 에서 실험 진행하며, 이 벤치마크에는 2 single-sentence classification tasks, 3 similarity 및 paraphrase tasks 및 4 natural language inference tasks 포함","s":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#models-and-datasets","p":781},{"i":814,"t":"DeBERTaV3-base 는 183M parameter 포함 저자는 여러 budget levels 에서 AdaLoRA 를 baseline 과 비교 trainable parameters 0.3/0.6/1.2M 고려 parameter budget 을 맞추기 위해, 저자는 adapter 의 hidden budget {8,16,32,64}\\{8, 16, 32, 64\\}{8,16,32,64} 에서 선택하며, LoRA 의 rank rrr 을 {2,4,8}\\{2, 4, 8\\}{2,4,8} 로 설정하며, AdaLoRA 의 final budget b(T)b^{(T)}b(T) 를 {144,288,576}\\{144, 288, 576\\}{144,288,576} 에서 선택 이후 AdaLoRA 에 대해 b(0)b^{(0)}b(0) 를 b(T)b^{(T)}b(T) 의 1.5배로 설정, regularization coefficient γ\\gammaγ 를 {0.1,0.3,0.5}\\{0.1, 0.3, 0.5\\}{0.1,0.3,0.5} 에서 선택 exponential moving parameters β1\\beta_1β1​ 및 β2\\beta_2β2​ 를 default value 0.85 로 설정 learning rate 는 {5×10−5,8×10−5,1×10−4,2×10−4}\\{5 × 10^{-5}, 8 × 10^{-5}, 1 × 10{^-4}, 2 × 10{^-4} \\}{5×10−5,8×10−5,1×10−4,2×10−4} 중에서 선택","s":"Implementation Details","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#implementation-details-1","p":781},{"i":816,"t":"다양한 budget setting 에서 AdaLoRA 를 baseline 과 비교 GLUE dev set 에서 all dataset 및 all parameter level 에서 AdaLoRA 를 기존 방법과 비교하여 더 나은 또는 동등한 성능 달성 parameter budget 이 0.3M 인 경우 AdaLoRA 는 RTE 에서 87.36% 달성하여 SOTA baseline 보다 1.8% 높음 AdaLoRA 는 매우 낮은 budget 에서도 종종 더 나은 성능","s":"Main results","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#main-results","p":781},{"i":819,"t":"제안된 알고리즘을 two QA (SQuADv1 및 SQuADv2) 에서 성능 평가 AdaLoRA 를 DeBERTaV3-base fine-tuning 에 사용 이 task 들은 sequence labeling problem 을 다룸 각 token 이 answer span 의 시작과 끝이 될 probability 예측","s":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#models-and-datasets-1","p":781},{"i":821,"t":"다양한 parameter budget 에서 baseline 과 AdaLoRA 비교 trainable parameter 수를 total pre-trained parameter 0.08%/0.16%/0.32%/0.65% 에서 선택 budget 요구사항을 맞추기 위해, adapter hidden dimension 을 {4,8,16,32,64}\\{ 4, 8, 16, 32, 64 \\}{4,8,16,32,64} 에서 선택 LoRA 의 rank rrr 은 {1,2,4,8}\\{ 1, 2, 4, 8\\}{1,2,4,8} 에서 선택 AdaLoRA 의 final total rank b(T)b^{(T)}b(T) 는 {72,144,288,576}\\{ 72, 144, 288, 576 \\}{72,144,288,576} 에서 선택 batch size 16 AdamW optimizer learning rate 1×10−31 \\times 10^{-3}1×10−3","s":"Implementation Details","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#implementation-details-2","p":781},{"i":823,"t":"4 가지 budget setting: total pre-trained parameters 0.08%, 0.16%, 0.32%, 0.65% 에서 DeBERTaV3-base fine-tuning 에서 실험 AdaLoRA 는 all budget level 에서 기존 방법를 능가 two metrics: EM 및 F1 에서 더 우수한 성능 발휘 Houlsby adapter 및 Pfeiffer adapter 의 성능은 parameter budget 을 줄이면 감소하는 반면, 저자의 방법은 일관된 성능","s":"Main Results","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#main-results-1","p":781},{"i":826,"t":"NLG tasks 의 SOTA 와 비교를 위해, 저자는 AdaLoRA 를 BART-large 모델을 fine-tuning 하는데 적용. 그리고 두 가지 데이터셋에서 모델 성능 평가 (XSum, CNN/DailyMail)","s":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#models-and-datasets-2","p":781},{"i":828,"t":"DeBERTaV3-base 와 유사하게, 저자는 low-rank/SVD-based adaptation 을 encoder 및 decoder layer 의 모든 weight matrix 에 적용 ROUGE 1/2/L scores report 15 epochs 8 beam length 64 batch size CNN/DailyMail 의 경우 4 beam search 32 batch size","s":"Implementation Details","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#implementation-details-3","p":781},{"i":830,"t":"4 가지 budget 에서 fine-tuning 성능 비교 trainable parameter 수는 total pre-trained parameter 의 0.13%, 0.26%, 1.10% 및 2.20% all budget levels 에서 두 데이터셋에 baseline 과 비교하여 AdaLoRA 는 더 나은 성능 달성","s":"Main Results","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#main-results-2","p":781},{"i":833,"t":"Fig. 2 에서 여러 budget levels 에서 DeBERTaV3-base 를 fine-tuning 한 실험 결과 세 데이터셋 (MNLI-m, SQuADv2, XSum) 에서 baseline 과 비교하여 AdaLoRa 는 모든 budget level 에서 일관된 성능 향상 XSum task 의 경우 budget 을 늘릴수록 성능 향상이 두드러지며, 이는 high budget 이 NLG task 에 도움이 되는 것을 시사 MNLI 및 SQuADv2 dataset 에선 low budget levels (≤1\\leq 1≤1%) 에서 AdaLoRA 는 SQuADv2 에서 88.87% F1 달성. 이는 high budget (4.65) 의 성능 (88.89% F1) 과 유사","s":"Different budget levels","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#different-budget-levels","p":781},{"i":835,"t":"Section 3.1 에서 언급했듯, LoRA 를 doublet-wise pruning 하여 rank allication 이 경우 doublets 가 완전히 제거되므로, 다시 활성화하는 장벽이 높아진다 crucial doublets 가 실수로 제거될 때 학습 불안정성을 초래하고 일반화에 해를 끼칠 수 있다. 이를 설명하기 위해 Table 4 에서 세 개의 데이터셋 (SST-2, RTE 및 CoLA) 에서 AdaLoRA 와 LoRA 의 pruning 을 비교 all budget levels 에서 AdaLoRA 가 모든 데이터셋에서 LoRA pruning 을 능가","s":"Comparison to low-rank parameterization","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#comparison-to-low-rank-parameterization","p":781},{"i":837,"t":"AdaLoRA 에서 importance score 는 Eq. 7 의 triplet 내의 every entry 의 sensitivity 및 uncertainly 로 정의 Table 4 에서 importance score 의 두 variants 조사 Eq. 7 의 s(⋅)s(\\cdot)s(⋅) 를 sensitivity 만으로 변경하는 경우 SiS_iSi​ 를 직접 ∣λi∣|\\lambda_i|∣λi​∣ 로 정의하는 경우 결과에서, 제안된 importance score 가 일반적으로 잘 수행 two variants 는 성능을 최대 0.9% 까지 저하","s":"Variants of the importance score","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#variants-of-the-importance-score","p":781},{"i":839,"t":"저자의 방법의 two components 인 SVD adaptation 및 adaptive budget allocation 이 성능 향상에 중요한 역할 하는 것을 언급 이를 증명하기 위해 다음과 같은 변형과 비교 SVD-LoRA : Eq. 3, 4 의 SVD-based adaptation 만으로 fine-tuning LoRAregu_{\\text{regu}}regu​ : LoRA 에 AAA 와 BBB 에 orthogonal regularization (Eq. 4) 적용 AdaLoRAγ=0_{\\gamma = 0}γ=0​ : AdaLoRA 에 orthogonal regularization (Eq. 4) 없이 Table 5 에서, SST-2 및 MNLI 에 DeBERTaVe-base 를 fine-tuning 한 결과 SVD adaptation 만 사용한 fine-tuning 이 LoRA 보다 향상을 보이지만 AdaLoRA 의 성능에 미치지 못함 SVD orthogonal regularization 없는 AdaLoRA 의 성능은 저하됨 이 결과로 두 component 가 모델 성능에 기여하는 것 확인","s":"The role of two components","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#the-role-of-two-components","p":781},{"i":841,"t":"Fig. 3 은 AdaLoRA 로 fine-tuning 된 DeBERTaV3-base 의 각 incremental matrix 의 resulting rank AdaLoRA 가 항상 FFN 및 top layers 에 더 많은 budget 을 할당하는 경향이 있다는 것을 발견 이러한 행동은 FFN module 의 weight matrices 와 top layers 의 weight matrices 가 모델 성능에 더 중요하다는 저자의 경험적 결론과 일치 따라서 이는 저자가 제안한 importance metric 기준이 AdaLoRA 를 crucial module 에 집중하도록 guide 한다는 것 확인 한편, AdaLoRA 에 의해 생성된 rank distribution 은 budget levels, task 및 modle 간에 일관 이는 remaining parameter 수가 b(T)b^{(T)}b(T) 와 linearly scaling 되므로 remaining parameter 를 제어하기 위해 b(T)b^{(T)}b(T) 를 조절할 수 있다는 것을 의미","s":"The resulting budget distribution","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"#the-resulting-budget-distribution","p":781},{"i":843,"t":"저자는 parameter-efficient fine-tuning method AdaLoRA 제안 importance scoring 에 따라 parameter budget 을 adaptively allocate weight matrices 의 incremental update 를 singular value decomposition (SVD) 형식으로 parameterize 이후 new importance metric 을 기반으로 singular values 를 조작하여 parameter budget 을 incremental matrices 간에 dynamically allocate 이 방식은 효과적으로 모델 성능 및 파라미터 효율성 향상 NLU, QA 및 NLG task 에 광범위하게 실험하여 기존 방법보다 우수한 성능 달성","s":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Composition/AdaLoRA","h":"","p":781},{"i":845,"t":"논문 및 이미지 출처 : https://aclanthology.org/2023.acl-long.35.pdf","s":"Pruning Pre-trained Language Models Without Fine-Tuning","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":847,"t":"Pre-trained Language Models (PLMs) 의 overparameterize 문제를 극복하기 위해, pruning 이 unimportant weights 를 직접적으로 제거하여 간단하고 직관적인 압축 방법으로 널리 사용한다. 이전의 first-order method 는 PLM 을 extremely high sparsity 로 압축하는데 성공하여, 약간의 성능 하락만 발생한다. 이런 방법들은 movement pruning 같은 first-order information 을 사용하여 PLM 을 pruning 하고 remaining weights 를 fine-tuning 하는 방식으로 작동한다. 본 논문에서는 first-order pruning 에 대한 fine-tuning 이 불필요하다 주장한다. first-order pruning 만으로도 PLM fine-tuning 없이 downstream task 에 수렴할 수 있기 때문 위 동기로 저자는 Static Model Pruning (SMP) 제안 target sparsity level 에 달성하는 동안 PLM 을 downstream task 에 adapting 하기 위해 first-order pruning 사용 추가로, SMP 를 더 개선하기 위해 new masking function 와 training objective 설계 다양한 sparsity levels 에서 광범위한 실험 결과, SMP 는 first-order 및 zero-order 보다 상당한 개선 이전의 first-order 과 달리 SMP 는 low sparsity 에서도 적용 가능하며 zero-oder 보다 우수한 성능 SMP 는 fine-tuning 이 필요하지 않아 다른 방법보다 parameter-efficient","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":849,"t":"BERT 같은 PLMs 는 large-scale corpus 로부터 knowledge transfering 으로 downstream task 에 강력한 성능을 보여주지만, large-scale parameter 가 필요하다. 이러한 parameter 는 대부분의 downstream task 에는 너무 많아서, transfer 및 copy 에 부담이 된다. PLM 을 압축하는 pruning 이 널리 사용되며, unimportant weights 를 제거하고 이를 zero 로 설정함으로써 이루어진다. 기존의 pruning 은 original complete network 대신 sparse subnetwork 를 사용함으로써 대부분의 weight 를 제거하여 original accuracy 를 유지할 수 있다. Magnitude Pruning (Han et al, 2015) : zero-order information 을 사용하여 weight 의 absolute value 게 기반하여 pruning 결정 downstream task adapting 과정에 PLM 의 weight value 는 이미 original value 로 결정됨 위 단점을 극복하기 위해 movement pruning (Sanh et al, 2020) 은 weight 가 absolute value 가 아닌 training 중 어떻게 변하는지에 따라 선택되는 first-order information 사용 위와 같이 대부분 movement pruning 과 같이 fine-tuning 과 함께 수행하여 training 중 sparsity 를 점진적으로 증가시킨다. Lottery Ticket Hypothesis (LTH) (Frankle and Carbin, 2018) 의 발전에 따라, 일부는 pruning 을 통해 PLM 의 특정 subnetwork 를 찾은 다음 pre-trained weight 에서 이 subnetwork 를 fine-tuning 또한 fine-tuned subnetwork 가 전체 PLM 의 성능과 일치하는 경우, 이 subnetwork 를 winning ticket 이라 함 본 논문에서는 간단하지만 효율적인 first-order method 제안 이전의 pruning 과 달리 fine-tuning 없이 pruning 만을 통해 PLM adapting 이 방법은 movement pruning 에 기반하여 pruning 결정을 내리며, movement pruning 에서의 movement 와는 다르다. 저자의 방법은 성능 향상을 위해 remaining weight 를 PLM 에 잘 맞게 하기 위한 new masking function 을 제안 또한 task-specifc head 에서 weight 를 fine-tuning 하지 않고 저자의 head initialization method 를 사용하여 더욱 효율적 PLM 고정함으로써, 다른 first-order 과 비교하여 trainable parameter 반을 줄이며, 다양한 sparisty levels 에서 각 downstream task 에 대한 new parameter 로 binary mask 만 도입 다양한 sparsity level 에서 광범위한 실험으로 SOTA pruning 을 능가 이전의 first-order (Sanh et al, 2020)이 low sparsity 에서 성능이 좋지 않은 반면, 저자는 low sparsity 에서도 적용 가능하며 zero-order 보다 우수한 성능 달성","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":851,"t":"PLM 의 overfitting 해결을 위한 여러 압축 방법이 제안되었다. 예로, model pruning (Han et al., 2015; Molchanov et al., 2017; Xia et al., 2022), knowledge distillation (Jiao et al., 2020; Wang et al., 2020), 양자화(Shen et al., 2020; Qin et al., 2022), quantization (Shen et al., 2020; Qin et al., 2022) 및 matrix decomposition (Lan et al., 2020) 등이 있다. Pruning 은 모델에 unimportant weights 를 식별하고 제거하는 데 초점을 둔다. Zero-order 과 first-order 는 PLM pruning 에 널리 사용된다. Zero-order : magnitude pruning (Han et al, 2015)는 단순히 weight 의 absolute value 를 기반으로 pruning 수행 Fist-order : pruning 결정을 위해 first-order Taylor expansion 을 기반으로 하며, L0L_0L0​ regularization (Louizos et al, 2017) 은 L0L_0L0​ norm regularization 을 추가하여 hard-concrete distribution 으로 sampling 하여 remaining weights 를 줄인다. Movement pruning (Sanh et al, 2020) : staight-through estimator (Bengio et al, 2013)을 사용하여 first-order information 계산 pruning 을 기반으로, Frankle and Carbin (2018) 은 Lottery Ticket Hypothesis (LTH) 제안 개별로 훈련시킬 때 거의 동일한 성능을 달성하는 subnetwork (winning ticket) 존재 확인 LTH 발전에 따라, PLM 에 중점을 둔 연구 등장 BERT 가 40 ~ 90% 의 sparsity 를 가진 winning tickets 을 포함하며, NLP 에서 winning ticket 이 downstream task 에 transfer 가능함을 발견 Liang et al. (2021) 은 winning tickets 의 일반화 성능이 임계점 이후 개선되고 나빠지는 현상을 이용하여, LTH 가 downstream task 성능에 성공적인 향상을 주는 것을 보여줌","s":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":853,"t":"a=Wx\\text{a} = \\text{Wx}a=Wx 를 PLM 의 fully-connected layer 라 하자. W∈Rn×n\\text{W} \\in \\mathbb{R}^{n\\times n}W∈Rn×n : weight matrix x∈Rn\\text{x} \\in \\mathbb{R}^nx∈Rn 및 a∈Rn\\text{a} \\in \\mathbb{R}^na∈Rn : input 및 output pruning 은 a=(W⊙M)x\\text{a} = (\\text{W} \\odot \\text{M})\\text{x}a=(W⊙M)x 으로 표현 M∈{0,1}n×n\\text{M} \\in \\{0,1\\}^{n\\times n}M∈{0,1}n×n : binary mask PLMs 에서 두 가지 common pruning 을 리뷰 해본다. magnitude pruning (Han et al, 2015) absolute value M=Topv(S)\\text{M} = \\text{Top}_v(\\text{S})M=Topv​(S) 에 따라 top vvv weight 를 유지하여 결정하는 zeroth-order information 에 의존 importance score S∈Rn×n\\text{S} \\in \\mathbb{R}^{n\\times n}S∈Rn×n 은 다음과 같다. Si,j(T)=∣Wi,j(T)∣=∣Wi,j−αw∑t<T(∂L∂Wi,j)(t)∣\\begin{equation} \\begin{align*} S^{(T)}_{i,j} &= \\left | W^{(T)}_{i,j} \\right | \\\\ &= \\left | W_{i,j} - \\alpha_w \\sum_{t<T} \\left ( \\frac{\\partial \\mathcal{L} }{\\partial W_{i,j}} \\right )^{(t)} \\right | \\end{align*} \\end{equation}Si,j(T)​​=∣∣​Wi,j(T)​∣∣​=∣∣​Wi,j​−αw​t<T∑​(∂Wi,j​∂L​)(t)∣∣​​​​ Si,jTS^{T}_{i,j}Si,jT​ : TTT steps update 이후 Wi,j(T)W^{(T)}_{i,j}Wi,j(T)​ 에 대응하는 importance score L및αw\\mathcal{L} 및 \\alpha_wL및αw​ : Wi,jW_{i,j}Wi,j​ 의 learning object 및 learning rate fine-tuning 중 high absolute values 의 weight 선택 movement pruning (Sanh et al, 2020) gradient 를 사용하여 importance scores S\\text{S}S 를 학습하는 것에 의존 S\\text{S}S 의 gradient 는 staight-through estimator 를 사용하여 근사하며, 이는 M\\text{M}M 에서 직접적으로 gradient 사용 importance scores S\\text{S}S 는 다음과 같다. Si,j(T)=−αs∑t<T(∂L∂Wi,j)(t)Wi,j(t)\\begin{equation} S^{(T)}_{i,j} = -\\alpha_s \\sum_{t<T} \\left (\\frac{\\partial \\mathcal{L}}{\\partial W_{i,j}} \\right )^{(t)} W_{i,j}^{(t)} \\end{equation}Si,j(T)​=−αs​t<T∑​(∂Wi,j​∂L​)(t)Wi,j(t)​​​ αs\\alpha_sαs​ : S\\text{S}S 의 learning rate magnitude pruning 과 비교하여, movement pruning 은 absolute value 를 증가시키는 weight 를 선택 target sparsity 달성을 위한 한 가지 공통된 방법은 automated gradual pruning (Michael H. Zhu, 218) sparsity level vvv 는 training step t0:vt=vf+(v0−vf)(1−t−t0N△t)3t_0: v^t = v_f + (v_0 - v_f) (1-\\frac{t-t_0}{N \\triangle t})^3t0​:vt=vf​+(v0​−vf​)(1−N△tt−t0​​)3 에서 시작하는 cubic sparsity scheduler 를 사용하여 점진적으로 증가된다. v0v_0v0​ 및 vfv_fvf​ : initial 및 target sparsity NNN : overall pruning steps △t\\triangle t△t : pruning frequency training 중, 이런 방법들은 pruning 과 fine-tuning 을 동시에 수행하기 위해 W\\text{W}W 와 S\\text{S}S 모두 업데이트해야 한다. fine-tuned weight 는 pre-trained value 에 가깝게 유지되므로 (Sanh et al, 2020), magnitude pruning 의 importance scores 는 pre-trained value 에 영향을 받아 high sparsity 에서의 성능을 제한한다. 하지만 magnitude pruning 은 여전히 low sparsity 에서 movement pruning 보다 우수한 성능을 보인다.","s":"3. Background","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":855,"t":"본 논문에선 간단한 first-order pruning 인 Static Model Pruning (SMP) 제안 이는 PLM 의 pruning 을 더 efficient 및 transferable 하기 위해 W\\text{W}W 를 고정 저자의 importance scores S\\text{S}S 는 다음과 같다. Si,j(T)=−αsWi,j∑t<T(∂L∂Wi,j′)(t)\\begin{equation} S^{(T)}_{i,j} = -\\alpha_s W_{i,j} \\sum_{t<T} \\left (\\frac{\\partial \\mathcal{L}}{\\partial W_{i,j}'} \\right )^{(t)} \\end{equation}Si,j(T)​=−αs​Wi,j​t<T∑​(∂Wi,j′​∂L​)(t)​​ Wi,j′W'_{i,j}Wi,j′​ : Wi,jMi,jW_{i,j}M_{i,j}Wi,j​Mi,j​ Wi,jW_{i,j}Wi,j​ 는 freezing 하기 때문에 binary masking term Mi,jM_{i,j}Mi,j​ 은 유지 Si,jS_{i,j}Si,j​ : Wi,j∂L∂Wi,j′<0W_{i,j} \\frac{\\partial \\mathcal{L}}{\\partial W'_{i,j}} < 0Wi,j​∂Wi,j′​∂L​<0 일 때 증가 remaining weight Wi,j′=Wi,jW'_{i,j} = W_{i,j}Wi,j′​=Wi,j​ 의 경우, movement trending −∂L∂Wi,j′-\\frac{\\partial \\mathcal{L}}{\\partial W'_{i,j}}−∂Wi,j′​∂L​ 가 Wi,jW_{i,j}Wi,j​ 의 absolute value 를 증가시키는 것을 의미 removed weight Wi,j′=0W'_{i,j} = 0Wi,j′​=0 의 경우, movement trending 이 0 을 Wi,jW_{i,j}Wi,j​ 에 가깝도록 하는 것을 의미","s":"4. Static Model Pruning","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":857,"t":"S\\text{S}S 을 기반으로 masks M\\text{M}M 을 얻기 위해, pruning structure 에 따라 두 가지 masking functions 고려 local masking function 의 경우, 각 matrix: M=Topv(S)\\text{M} = \\text{Top}_v(\\text{S})M=Topv​(S) 에 단순히 Topv\\text{Top}_vTopv​ function 을 적용 이는 S\\text{S}S matrix 에 따라 v%v\\%v% 의 importance weight 를 matrix 별로 선택 global masking function 의 경우, importance scores 를 함께 ranking 하는 것 (약 85M 의 bert-base)은 계선적으로 비효율적이며 최종 성능에도 해를 끼침 이를 해결하기 위해 각 weight matrix 의 overall score 를 기준으로 sparsity level 을 할당하는 new global masking function 제안 BERT 를 고려하면, 각 layer 에는 LLL transformer layers 를 가지며, 각 layer 에는 self-attention layer 와 feed-forward 가 포함 lllth self-attention block WQlW^l_QWQl​, WKlW^l_KWKl​, WVlW^l_VWVl​ 및 WOlW^l_OWOl​ 은 pruning 해야할 weight matrix 마찬가지로, WUlW^l_UWUl​ 및 WDlW^l_DWDl​ 는 lllth feed-forward layer 에서 pruning 해야할 weight matrix network 의 all parameter 를 ranking 하는 대신 각 weight matrix 의 sparsity level 먼저 계산 각 weight matrix v(⋅)lv^l_{(\\cdot)}v(⋅)l​ 의 sparsity level 은 다음과 같이 계산 v(⋅)l=R(S(⋅)l)L∑l′=1LR(S(⋅)l′)v\\begin{equation} v^l_{(\\cdot)} = \\frac{R \\left ( S^l_{(\\cdot)} \\right ) L }{\\sum^L_{l'=1} R \\left ( S^{l'}_{(\\cdot)} \\right )}v \\end{equation}v(⋅)l​=∑l′=1L​R(S(⋅)l′​)R(S(⋅)l​)L​v​​ R(S)=∑i,jσ(Si,j)R(S) = \\sum_{i,j}\\sigma(S_{i,j})R(S)=∑i,j​σ(Si,j​) : sigmoid σ\\sigmaσ 가 있는 S\\text{S}S 의 regularization term S(⋅)l\\text{S}^l_{(\\cdot)}S(⋅)l​ : weight W(⋅)lW^l_{(\\cdot)}W(⋅)l​ 의 importance scores (⋅)(\\cdot)(⋅) : {Q,K,V,O,U,D}\\{Q,K,V,O,U,D\\}{Q,K,V,O,U,D} 중 하나일 수 있음 sparsity level 은 다양한 layers 에서 동일한 유형의 matrix 에 importance scores 비율에 의해 결정된다.","s":"4.1 Masking Function","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#41-masking-function","p":844},{"i":859,"t":"task-specific head 를 처음부터 학습하는 대신, 저자는 해당 head 를 BERT token embedding 에서 초기화하고 훈련 중 freezing 을 유지한다. 최근 prompt tuning 의 영감을 받아, task-specific head 를 BERT token embedding 의 해당 label word 로 초기화 한다. 예로, \"great\" 및 \"terrible\" token embedding 을 사용하고, predicted positive label score 가 h[CLS]egreatTh_{\\text{[CLS]}} e^T_{\\text{great}}h[CLS]​egreatT​ 이다. h[CLS]h_{\\text{[CLS]}}h[CLS]​ : special token [CLS]\\text{[CLS]}[CLS] 의 hidden state egreate_{\\text{great}}egreat​ : \"great\" token embedding","s":"4.2 Task-Specific Head","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#42-task-specific-head","p":844},{"i":861,"t":"model 을 pruning 하기 위해, 저자는 warmup step 이 없는 cubic sparsity scheduling (Michael H. Zhu, 2018) 을 사용한다. ttt step 에서의 sparity vtv_tvt​ 의 다음과 같다. vt={vf−vf(1−tN)3t<Nvfo.w.\\begin{equation} v_t = \\left\\{\\begin{matrix} v_f - v_f (1-\\frac{t}{N})^3 & t < N \\\\ v_f & \\text{o.w.} \\end{matrix}\\right. \\end{equation}vt​={vf​−vf​(1−Nt​)3vf​​t<No.w.​​​ first NNN steps 에선 0 에서 target sparsity vfv_fvf​ 까지 sparsity 를 점진적으로 증가 NNN steps 이후, sparsity vt=vfv_t = v_fvt​=vf​ 를 유지 이 step 에서, remaining weights 수는 동일하지만, 이 weights 가 importance scores 에 따라 removed weights 로 대체될 수도 있다. 저자는 knowledge distillation 을 사용하거나 사용하지 않는 설정으로 평가 knowledge distillation 가 없는 setting 에서는 다음과 같은 loss function 을 optimizing L=LCE+λRvtvfR(S)\\begin{equation} \\mathcal{L} = \\mathcal{L}_{\\text{CE}} + \\lambda_R \\frac{v_t}{v_f}R(\\text{S}) \\end{equation}L=LCE​+λR​vf​vt​​R(S)​​ LCE\\mathcal{L}_{\\text{CE}}LCE​ : task 에 해당하는 classification loss R(S)R(\\text{S})R(S) : λR\\lambda_RλR​ hyperparameter 를 가진 regularization term Softmovement (Sanh et al, 2020) 에서 영감을 받아, thresholding masking function 을 사용하여 sparsity 를 증가시키기 위해 S\\text{S}S 를 감소시키는 regularization term 을 사용 저자는 regularization term 이 중요하다는 것을 발견 저자의 방법에선 λR\\lambda_RλR​ 이 충분히 크기 때문에 sparsity level vtv_tvt​ 가 vfv_fvf​ 에 가까울 때 most importance scores 는 zero 보다 작다. Si,j<0S_{i,j} < 0Si,j​<0 일 때 Si,jS_{i,j}Si,j​ 의 증가와 함께 gradient ∂R(S)∂Si,j=∂σ(Si,j)∂Si,j\\frac{\\partial R(\\text{S})}{\\partial S_{i,j}}=\\frac{\\partial \\sigma (S_{i,j})}{\\partial S_{i,j}}∂Si,j​∂R(S)​=∂Si,j​∂σ(Si,j​)​ 가 증가하여 remaining weights 에 해당하는 scores 가 removed weight 보다 더 큰 패털티를 받는다. 이는 vtv_tvt​ 가 vfv_fvf​ 에 거의 도달했거나 도달했을 때 M\\text{M}M 이 변경되도록 한다. knowledge distillation 이 있는 setting 에서는 다음과 같이 loss L\\mathcal{L}L 에 knowledge distillation loss LKD\\mathcal{L}_{\\text{KD}}LKD​ 를 추가한다. LKD=DKL(ps∣∣pt)\\begin{equation} \\mathcal{L}_{\\text{KD}} = D_{\\text{KL}} (\\text{p}_s||\\text{p}_t) \\end{equation}LKD​=DKL​(ps​∣∣pt​)​​ DKLD_{\\text{KL}}DKL​ : KL-divergence ps\\text{p}_sps​ 및 pt\\text{p}_tpt​ : student model 및 teacher model 의 output distribution","s":"4.3 Training Objective","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#43-training-objective","p":844},{"i":864,"t":"저자의 방법의 효과성을 보여주기 위해, MNLI, QQA, SQuAD 에서 실험 진행 또한 GLUE 벤치마크를 사용하여 low sparsity 의 성능 검증","s":"5.1 Datasets","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#51-datasets","p":844},{"i":866,"t":"이전 pruning model 을 따라 bert-base-uncased 를 사용하여 task-specific pruning 을 수행하고 encode 의 remaining weight 비율을 report task-specific head 의 경우, 각 ㅅask 의 label words 에 따라 초기화 SQuAD 의 경우, \"yes\" 및 \"no\" token embedding 을 answer 의 starting 및 ending classification 에 대한 weight 로 사용 task-specific head 를 포함한 BERT 의 all weights 를 freezing 하고 mask 만 fine-tuning optimizer : learning rate 2e-2 regularization term 의 hyperparameter λR\\lambda_RλR​ : 400 MNLI 및 QQP : 12 epochs SQuAD : 10 epochs 및 64 batch size low sparsity tasks (remaining weights > 70%)의 경우, cubic sparsity scheduling 의 NNN 을 7 epochs 로 설정 high sparsity tasks 의 경우, NNN 을 3500 steps 으로 설정 또한 GLUE 에서 all tasks 에 대해 bert-base-uncased 와 roberta-base 의 80% remaining weights 의 성능도 report batch size 및 learning rate 는 위와 동일 sparsity scheduling 의 경우, bert-base-uncased 와 동일한 scheduling 을 사용하고, roberta-base 의 경우, linear scheduling 사용 sparsity scheduling 의 NNN 은 3500 large tasks, MNLI, QQP, SST2 및 QNLI 의 경우, 12 epochs small tasks, MRPC, RTE, STS-B 및 COLA 의 경우, 60 epochs 위 epochs 에는 pruning steps 이 포함되어 있다. 예로, MRPC 에서 target sparsity 달성을 위해 약 43 epochs 를 사용","s":"5.2 Experiments Setups","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#52-experiments-setups","p":844},{"i":868,"t":"저자는 magnitude pruning (Han et al, 2015), L0_00​-regularization (Louizos et al, 2018), movement pruning (Sanh et al, 2020) 및 CAP (Xu et al, 2022) 와 비교 또한 GLUE 에서 직접 fine-tuning 및 super ticket (Liang et al, 2021) 과 비교 super ticket 의 경우, PLM 의 몇몇 subnetworks 가 포함되어 있음을 발견하여, 이를 fine-tuning 하여 full model 을 능가할 수 있다.","s":"5.3 Baseline","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#53-baseline","p":844},{"i":870,"t":"Table 1 은 high sparsity 에서 SMP 및 다른 pruning method 의 결과를 보여준다. 저자는 local masking function (SMP-L) 과 proposed masking function (SMP-S) 를 사용하여 SMP 구현 SMP-S 및 SMP-L 은 knowledge distillation 없이 다른 pruning 보다 일관된 성능을 보임 movement pruning 및 SMP-L 이 동일한 local masking function 을 사용하더라도, SMP-L 은 Table 1 의 모든 task 및 sparsity level 에서 2.0 이상의 개선 달성 이러한 이득은 3% remaining weights 임에서 유의미함 SMP-S 와 유사하게 remaining weights 을 비균일하게 할당하는 soft-movement pruning 은 SMP-L 보다 성능이 떨어짐 이전 연구를 따라, 저자는 Table 1 에 knowledge distillation 결과를 report knowledge distillation 으로 인한 개선은 SMP-L 및 SMP-S 에서도 명백함 SQuAD 의 F1 을 개선하기 위해 SMP-L 및 SMP-S 에서 3.3 및 4.1 개선 3% remaining weights 만으로도 SMP-S 가 MNLI 및 QQP 에서 soft-movement pruning 을 10% 능가 teacher model 로부터 contrastive learning objective 를 추가하는 CAP 와 비교하여, 저자의 방법은 auxiliary learning objective 없이도 일관된 성능을 나타냄 50% remaining weights 에서, MNLI 의 SMP-S 는 84.5 accuracy 의 full-model fine-tuning 과 비교하여 85.7 달성 저자의 방버은 또한 parameter efficient 다른 first-order 과 비교하여, BERT 와 task-specific head 를 freezing 를 유지한 채 trainable parameter 절반 절약 저자는 각 task 에 대해 다양한 sparsity level 에서 new parameters 로 binary mask θM\\theta_MθM​ 을 도입하는데, 다른 방법들은 θM\\theta_MθM​ 과 subnetworks 모두 저장해야 함 remaining weights 가 50%, 10% 및 3% 인 경우, 다른 pruning 과 비교하여 각각 42.5M, 8.5M 및 2.6M 의 parameter 절약 Fig. 1 은 binary mask θM\\theta_MθM​ 과 비교하여 3% ~ 80% 까지 remaining weight 에 대한 추가 결과 저자의 방법은 3%, 10%, 30%, 50% 및 80% remaining weights 에서 결과 보고 MNLI 및 SQuAD 에서 25% 이상의 remaining weights 에서 저자의 방법이 movement pruning 같은 first-order 를 밑돌고 있다는 것을 볼 수 있다. 20% remaining weight 와 같은 high sparsity 에서도, magnitude pruning 은 여전히 movement 및 soft-movement pruning 을 여전히 능가 (Fig. 1(c)). 이는 first-order 이 zero-order 에 비해 very high sparsity 에서만 이상적으로 수행하는 한계를 보여줌. 하지만 SMP-L 및 SMP-S 같은 first-order 는 위 sparsity 에서도 magnitude pruning 보다 나은 성능을 지속 knowledge distillation 없는 결과의 경우, SMP-S 및 SMP-L 은 훨씬 적은 remaining weights 로 soft-movement pruning 성능과 유사 knowledge distillation 결과에서 SMP-S 및 SMP-L 은 all sparsity level 에서 knowledge distillation 의 이점을 누림 encoder 에서 weights 를 70% 이상 제거한 후에도, 여전히 full-model fine-tuning 을 능가 또한 GLUE 에서 저자의 방법을 검증하고 Table 2 에서 80% remaining weights 를 report encoder 의 parameter 를 20% 만 제거하여 full-model fine-tuning 에 비해 나은 성능 달성 각 task 에 대해 8개의 서로 다른 sparsity level 을 searching 하는 SuperT 와 비교하여, 저자의 방법은 동일한 sparsity level 을 사용하여 나은 성능 달성 저자의 방법은 SuperT 와 비교하여 각 task 당 98M 이상의 new parameter 절약","s":"5.4 Experiments Results","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#54-experiments-results","p":844},{"i":873,"t":"Table 3 에서 knowledge distillation 없이 저자의 방법에서 다양한 masking function 의 결과를 보여줌 이전 pruning 과 달리, thresholding masking function TTT 는 training 중 sparsity 를 제어하는 어려움으로 인해 수렴하지 못한다. global masking function GGG 의 경우, all 85M BERT encoder weight 를 정렬하고 각 training step 에서 Top v%v\\%v% 의 weight 를 유지 local masking function LLL 에 비해 GGG 는 85M weight 를 정렬하는 계산 비용으로 인해 training times 가 두 배 이상 소요 오래 걸렸지만, 여전히 10% 및 3% remaining weight 에서 LLL 보다 성능이 낮음 GGG 와 달리, 저자의 masking function SSS 는 각 matrix 의 remaining weights 를 직접 할당하기 때문에 추가 훈련 없이도 LLL 을 능가 masking function SSS 및 LLL 의 추가 결과는 Table 1 및 Fig. 1 에서도 확인 가능 Fig. 2 는 10% remaining weight 를 가진 MNLI 의 다양한 layer 에서 remaining weight distribution 을 보여준다. 저자는 GGG 가 WUW_UWU​ 및 WVW_VWV​ 에 너무 많은 remaining weights 를 할당한다는 것을 발견했는데, 이는 다른 matrices 보다 네 배 크다. 이로 인해 WQW_QWQ​ 같은 remaining weight matrices 는 SSS 및 LLL 보다 더 sparse 하다. 이전 연구에 따르면(Sanh et al, 2020; Mallya and Lazebnik, 2018), overall sparsity 는 layer depth 와 함께 증가하는 경향이 있다. 하지만, WUW_UWU​ 및 WVW_VWV​ 만이 모든 all three matrices 에서 이러한 패턴을 따른다. WUW_UWU​ 및 WVW_VWV​ 가 각 layer 의 weight 중 60% 이상 차지하기 때문에, layer 의 overall distribution 도 이러한 경향을 따르게 된다. attention head 의 행동을 이해하기 위해, 저자는 각 head 의 remaining weights 비율을 Fig. 3 에 표시 각 행은 12 heads 를 포함하는 matrix WQW_QWQ​ 및 WKW_KWK​ 간의 유사한 분포로 인해, 저자는 WQW_QWQ​ 와 WVW_VWV​ 만 표시 각 head 에 sparsity 를 균일하게 할당하는 대신, 세 가지 masking function 에는 각 head 의 sparsity 는 균일하지 않음 대부분의 head 가 1% 미만 또는 remaining weight 가 1% 미만을 가지는 것을 볼 수 있다. SSS 와 LLL 의 경우, SSS 가 LLL 보다 중요한 head 에 더 많은 remaining weight 를 할당할 수 있으며, 9th layer 의 일부 head 는 60% 이상의 remaining weight 를 달성 global masking function GGG 의 경우, 대부분의 remaining weight 가 WUW_UWU​ 및 WDW_DWD​ 에 할당되기 때문에, GGG 에서 WQW_QWQ​ 및 WVW_VWV​ 의 평균 remaining weight 비율이 각각 3.2% 와 2.8% 로, GGG 가 다른 masking function 보다 성능이 떨어지는 원인이 된다.","s":"6.1 Masking Function","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#61-masking-function","p":844},{"i":875,"t":"저자의 task-specific head initialization 을 검증하기 위해, 처음부터 훈련하는 방법과 비교 Table 4 는 SMP-L 의 결과를 보여준다. MNLI 및 SQuAD 에서 80%, 10%, 3% 의 remaining weight 에 대한 결과를 보여준다. 처음부터 훈련하는 경우, 이전 pruning method 를 따라 learning rate 3e-5 로 랜덤하게 head 를 초기화하고 fine-tuning 결과 저자의 방법이 task-specific head 를 freezing 한 상태에서 더 나은 성능을 달성하는 것을 보여줌","s":"6.2 Task-Specific Head","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#62-task-specific-head","p":844},{"i":877,"t":"training objective 의 Regularization term 은 저자의 방법의 핵심 요소 Table 5 에서 regularization term RRR 없이는 high sparsity 에서 수렴하기 어려운 것을 발견 sparsity 가 증가함에 따라 RRR 이 있는 경우와 없는 경우의 성능 차이가 급격하게 증가한다. SMP-L 에서 RRR 없이는 SQuAD 의 10% 및 3% remaining weights 에서 수렴하지 못할 정도 Section 4.3 의 분석처럼, RRR 없이는 attention head 의 remaining weights 가 더 균일 예로, 10% 의 remaining weight 를 가진 MNLI 의 SMP-L 에서 RRR 이 있는 경우와 비교하여 각 attention haed 의 remaining weights 의 표준 편차는 3.75 즉, RRR 없이는 Fig. 3 과 같이 important head 에 더 많은 remaining weight 를 할당할 수 없다.","s":"6.3 Training Objective","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"#63-training-objective","p":844},{"i":879,"t":"본 논문에선 Static Model Pruning (SMP) 라는 간단하면서 효과적인 task-specific pruning 을 제안 이전 방법들은 PLM 의 downstream task apdatation 을 위해 pruning 과 fine-tuning 모두 수행하는 반면, 저자는 fine-tuning 이 이미 PLM 을 수렴시키는 first-order 의 pruning 에서 중복됨을 발견 위를 바탕으로 fine-tuning 대신 first-order pruning 을 사용하는데 초점을 맞춤 fine-tuning 없이도 저자의 방법은 다른 first-order method 를 능가 실험 결과도 다양한 sparsity 에서 SOTA 달성 BERT 의 lottery ticket hypothesis 에 대해, 저자는 training 없이 기존 성능을 달성하는 sparsity subnetworks 를 포함한다는 것을 발견 또한, 이런 subnetworks 는 80% remaining weight 에서 GLUE 에서 fine-tuning 된 BERT 보다 우수한 성능 달성","s":"7. Conclusion","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":881,"t":"unstructured pruning 방법과 마찬가지로 SMP 는 structured pruning 과 비교하여 추론 속도 향상이 어렵다. SMP 는 fine-tuning 없이 모델을 pruning 하기 때문에, 확장하는 것이 제한된다. 하지만 SMP 의 sparsity matrices 의 대부분 행은 high sparsity level 에서 완전히 pruning 되어 있다. 이로 인해 matrices size 를 직접 압축하여 더 빠른 추론도 가능 예로, MNLI 의 3% remaining weights 는 fine-tuning 이나 성능 손실 없이 실제 모델 크기의 47.43% 압축될 수 있다 (1.37배 추론 속도 향상) remaining weights 가 10 미만인 행을 제거하여, 실제 크기의 25.19% 압축 가능 (0.9 accuray 감소와 1.76배 추론 속도 향상) 훈련 중 신중히 설계된 loss function 은 더 작은 실제 모델 크기와 더 빠른 추론 속도 향상을 가능할 수 있음을 기대","s":"8. Limitation","u":"/docs/Paper/NLP/PEFT/Pruning/SMP","h":"","p":844},{"i":883,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.16199.pdf","s":"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":885,"t":"LLaMA-Adapter 는 LLaMA 를 instruction-following model 로 효율적으로 fine-tuning 하기 위한 경량 adaptation method 52K self-instruction 사용 LLaMA 7B model 을 freezing 한 채, LLaMA-Adapter 를 사용하면 1.2M learnable parameter 만 추가됨 8대의 A100 GPU 에서 1시간 이하의 fine-tuning cost 발생 구체적으로, learnable adaptation prompts 를 채택, 이를 상단의 Transformer layer 의 word token 앞에 추가 zero-initialized attention 메커니즘 및 zero gating 제안 new instruction 을 LLaMA 에 adaptively injects 하는 동시에 pre-trained knowledge 를 효과적으로 보존 LLaMA-Adapter 는 multi-model instruction 으로 확장 가능 ScienceQA 및 COCO caption 벤치마크에 우수한 reasoning 성능 달성 전통적인 비전 및 언어 task 에서 pre-trained model (ViT, RoBERTa)을 fine-tuning 하기 위해 zero-initialized attention 메커니즘을 평가하여 저자의 approach 의 우수한 일반화 능력 보여줌","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":887,"t":"LLM 이 크게 발전하는데 비해 instruction model 은 높은 비용 및 시간이 든다. 이를 해결하려, Stanford Alpaca 는 LLaMA 를 instruction-following model 로 fine-tuning 하는 방법을 제안하여 저렴하고 복제 가능한 모델을 만들었지만 여전히 시간이 많이 소요된다. 본 논문은 LLaMA-Adapter 도입으로 LLaMA 를 instruction-following model 로 효율적으로 fine-tuning 하는 방법 제안 training 을 목적으로 52K instruction-output data 활용 LLaMA 를 freezing 하여 efficiency 보존 LLaMA 상단의 transformer layer 에 learnable adaptation prompts 를 input instruction token 앞에 붙임 초기 훈련 단계에서 adaptation prompt 의 noise 를 피하기 위해, layer 의 vanilla attention 메커니즘을 zero-initialized attention 으로 수정하고 learnable gating 추가 다음 LLaMA-Adapter 는 Fig 1 에서 네 가지 특징 가짐 1.2M Parameters pre-trained LLaMA 7B 는 freezing 하고 1.2M parameter 인 adaptation prompt 만 학습 7B Alpaca 와 comparable instruction-following One-hour Fine-tuning zero-initialized gating 을 사용한 경량 adaptation module 덕에 8개의 A100 GPU 에서 1시간 미만으로 Alpaca 보다 3배 빠름 Plug with Expertise 여러 시나리오에 대한 여러 adapter 를 삽입하고 LLaMA 에 다양한 expert knowledge 를 부여하는 유연성 지님 Multi-model Instruction text instruction 뿐 아니라 image input 으로 multi-model reasoning 수행 가능 image tokens 을 adaptation prompts 에 추가함으로써 ScienceQA 및 COCO caption 벤치마크에서 comparable 한 성능 instruction-following model 뿐 아니라, vision 및 language models 에 대해서도 zero-initialized attention 이 parameter-efficient fine-tuning 으로 일반화 가능 pre-trained ViT 를 fine-tuning 하는데 저자의 approach 로 VTAB-1k 벤치마크에서 우수한 성능 달성 ReBERTa 의 경우 SQuAD v1.1 및 v2.0 에서 선도적인 결과 달성","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":891,"t":"52K instruction-output data 및 NNN-layer transformer 를 사용하는 pre-trained LLaMA 가 주어졌을 때, 저자는 instruction-following fine-tuning 을 위해 learnable adaptation prompts 셋 채택 {Pl}l=1L\\{ P_l \\}^L_{l=1}{Pl​}l=1L​ : LLL transformer layer 에 대한 prompts Pl∈RK×CP_l \\in \\mathbb{R}^{K \\times C}Pl​∈RK×C KKK : 각 layer 에 대한 prompt length CCC : LLaMA transformer 의 feature dimension prompt 를 transformer 의 가장 상단 LLL layer (l≤L)(l \\leq L)(l≤L) 에 삽입한 것을 주목하자. 이는 higher-level semantics 를 갖는 language representation 을 더 잘 tuning 하도록 해줌 예로 lll-th inserted layer (l≤L)(l \\leq L)(l≤L) 를 보자. Ti∈RM×CT_i \\in \\mathbb{R}^{M \\times C}Ti​∈RM×C : MMM-length word tokens input instruction 및 이미 생성된 response 표시 learnable adaptation prompt 는 token dimension 을 따라 TiT_iTi​ 과 prefix 로 연결 [Pl;Tl]∈R(K+M)×C\\begin{equation} [P_l; T_l] \\in \\mathbb{R}^{(K+M) \\times C} \\end{equation}[Pl​;Tl​]∈R(K+M)×C​​ PlP_lPl​ 에서 학습된 instruction knowledge 는 transformer block 의 attention layers 를 통해 subsequent contextual response 를 생성하도록 TiT_iTi​ 에게 효율적으로 가이드함","s":"3.1 Learnable Adaptation Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":893,"t":"adaptation prompts 가 무작위로 초기화되면, training 초기에 word token 에 혼란을 일으킬 수 있어, fine-tuning 의 안정성과 효과를 해칠 수 있음 이로 인해 저자는 last LLL transformer layers 에서 vanilla attention 매커니즘을 수정하여 zero-initialized attention 으로 수정 lll-th inserted layer 의 [Pl;Tl][P_l; T_l][Pl​;Tl​] 상단의 (M+1)(M + 1)(M+1)-th word 를 생성하는 상황을 가정 tl∈R1×Ct_l \\in \\mathbb{R}^{1 \\times C}tl​∈R1×C : 해당 (M+1)(M+1)(M+1)-th word token attention 매커니즘은 input tokens 을 queries, keys 및 values 로 변환하기 위해 linear projection 에 적용 Ql=Linearq( tl );Kl=Lineark( [Pl;Tl;tl] );Vl=Linearv( [Pl;Tl;tl] ).\\begin{align} & Q_l = \\text{Linear}_q (\\ t_l\\ ); \\\\ & K_l = \\text{Linear}_k (\\ [P_l; T_l; t_l] \\ ); \\\\ & V_l = \\text{Linear}_v (\\ [P_l; T_l; t_l] \\ ). \\end{align}​Ql​=Linearq​( tl​ );Kl​=Lineark​( [Pl​;Tl​;tl​] );Vl​=Linearv​( [Pl​;Tl​;tl​] ).​​ 이후 softmax function 전에 QlQ_lQl​ 와 KlK_lKl​ 의 attention scores 를 계산 Sl=QlKlT/C∈R1×(K+M+1)\\begin{equation} S_l = Q_l K_l^T / \\sqrt{C} \\in \\mathbb{R}^{1 \\times (K+M+1)} \\end{equation}Sl​=Ql​KlT​/C​∈R1×(K+M+1)​​ 이는 new word tlt_ltl​ 와 모든 K+M+1K+M+1K+M+1 tokens 간의 feature simiarities 를 기록하는 것. 한편 SlS_lSl​ 은 두 component 로 재정립될수 있다. Sl=[SlK;SlM+1]T\\begin{equation} S_l = [S_l^K; S_l^{M+1}]^T \\end{equation}Sl​=[SlK​;SlM+1​]T​​ SlK∈RK+1S^K_l \\in \\mathbb{R}^{K+1}SlK​∈RK+1 : KKK adaptation prompts 의 attention score learnable prompt 가 tlt_ltl​ 를 생성하는데 얼마나 많은 정보를 제공하는지 지표 훈련 초기 단계에 혼란을 야기할 수 있음 SlM+1∈R(M+1)×1S_l^{M+1} \\in \\mathbb{R}^{(M+1)\\times 1}SlM+1​∈R(M+1)×1 : M+1M+1M+1 word tokens learnable gating factor glg_lgl​ 을 도입하여 attention 의 SlKS_l^KSlK​ 를 adaptively control zero 로 초기화 glg_lgl​ 은 부적합한 prompt 의 영향을 제거한 후 LLaMA 에 더 많은 instruction semantics 제공을 위해 크기를 증가시킬 수 있음 저자는 Eq 6 의 두 component 에 독립적으로 softmax function 을 적용하고, 첫 번째 항을 glg_lgl​ 로 곱함 Slg=[softmax(SlK)⋅gl; softmax(SlM+1)]T\\begin{equation} S^g_l = [\\text{softmax}(S_l^K) \\cdot g_l ; \\ \\text{softmax}(S_l^{M+1})]^T \\end{equation}Slg​=[softmax(SlK​)⋅gl​; softmax(SlM+1​)]T​​ separate softmax function 은 두 번째 항이 adaptation prompt 와 관련 없도록 보장 glg_lgl​ 이 거의 0에 가까울 때, 기존 LLaMA pre-trained knowledge 를 토큰 tlt_ltl​ 에 전달하여 생성 가능 attention 내의 독립적으로 학습되는 여러 glg_lgl​ 을 도입하여 multi-head 매커니즘의 학습 다양성을 촉진 어텐션 내에서 서로 독립적으로 학습되는 여러 gl을 도입하여 다중 헤드 메커니즘의 학습 다양성을 촉진합니다. 마지막으로, lll-th attention layer 의 output 을 linear projection layer 를 사용하여 계산 tlo=Linearo(SlgVl)∈R1×C\\begin{equation} t_l^o = \\text{Linear}_o (S_l^g V_l) \\in \\mathbb{R}^{1 \\times C} \\end{equation}tlo​=Linearo​(Slg​Vl​)∈R1×C​​ 위의 zero-initialized attention 을 사용하면, adaptation prompts 는 점진적으로 transformer 에 새로 습득한 instructional signals 을 주입하는 동시에 LLaMA 의 pre-trained knowledge 를 통합하여 고품질 response 제공 가능","s":"3.2 Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#32-zero-initialized-attention","p":882},{"i":895,"t":"text instruction 외에도, LLaMA-Adapter 는 다른 modalities input 에 대한 answering 능력이 존재 ScieneceQA 를 예로 들자. visualtextual contextsquestionoptionanswer visual context 로 input image 가 주어진 경우 pre-trained visual encoder CLIP 을 활용하여, multi-scale global feature 추출 {Im}m=1M\\{ I_m \\}^M_{m=1}{Im​}m=1M​ Im∈R1×CI_m \\in \\mathbb{R}^{1 \\times C}Im​∈R1×C MMM : scale number 이후 channel dimension 을 따라 MMM-scale features 를 연결하고 learnable proejction network 적용 Ip=Projection(Concat({Im}m=1M))\\begin{equation} I_p = \\text{Projection} \\left( \\text{Concat} ( \\{ I_m \\}^M_{m=1} ) \\right) \\end{equation}Ip​=Projection(Concat({Im​}m=1M​))​​ Ip∈R1×CI_p \\in \\mathbb{R}^{1 \\times C}Ip​∈R1×C 이는 adaptation prompts 와 동일한 feature dimension 을 갖는 전체 image token 으로 간주 IpI_pIp​ 를 KKK 번 반복하고, 이를 모든 inserted transformer layer LLL 의 KKK-length 의 adaptation prompt 에 요소별로 더함 lll-th layer 에 대해 획득한 multi-modal prompt 를 다음과 같이 나타냄 Plv=Pl+Repeat(Ip)∈RK×C\\begin{equation} P_l^v = P_l + \\text{Repeat}(I_p) \\in \\mathbb{R}^{K \\times C} \\end{equation}Plv​=Pl​+Repeat(Ip​)∈RK×C​​ PlvP_l^vPlv​ : image context 로부터의 visual information 을 통합한 adaptation prompt 위 과정을 통해 LLaMA 는 vision-language input 에 대한 response 를 생성하도록 fine-tuning 되고, multi-modal understanding 으로 어려운 generation task 도 처리 가능","s":"3.3 Multi-modal Reasoning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#33-multi-modal-reasoning","p":882},{"i":897,"t":"zero-initialized attention 을 사용한 adaptation prompt 는 instruction model 에만 한정되지 않고, vision 및 language task 의 Large model 에도 활용 및 일반화 능력 발휘 가능","s":"3.4 Zero-initialized Attention for other Large Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#34-zero-initialized-attention-for-other-large-models","p":882},{"i":899,"t":"pre-trained ViT 를 활용하여 최상위 transformer layer LLL 개에 adaptation prompt 를 prefix 로 삽입 후, 모든 inserted layer 에 attention 작업을 zero-initialized 로 수정 ViT 를 고정한 채 모델의 일부 parameter 만 추가하고 VTAB-1k 벤치마크에서 full fine-tuning 과 유사한 결과 얻음","s":"Vision Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#vision-models","p":882},{"i":901,"t":"RoBERTa 를 활용하여 SQuAD QA task 에 zero-initialized attention 를 평가 P-tuning v2 위에 zero-initialized attention 을 구현 마찬가지로 fine-tuning 중 P-tuning v2 의 prompt token 과 저자의 zero gating factor 만 learnable 하게 설정 기존 language tasks 에서 우수성을 입증","s":"Language Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#language-models","p":882},{"i":905,"t":"Standord Alpaca 를 따라 52K instruction-following 활용, 175 instruction-output pairs 로 추가 확장 LLaMA-Adapter 를 8대 A100 GPU 에서 5 epoch fine-tuning warmup epoch 2 batch size 64 learning 0.009 weight decay 0.02 7B parameter 및 N=32N = 32N=32 transformer layer 를 가진 pre-trained LLaMA 사용 prompt length K=10K=10K=10 adaptation prompt 를 last L=30L=30L=30 layer 에 삽입 generation 단계 temperature 0.1 top-p=0.75\\text{top-p} = 0.75top-p=0.75 로 설정된 샘플링을 default decoding 로 설정 quantitative 평가 GPT-4 에게 80개 질문에 대한 instruction-following model 의 응답품질 평가하도록 요청 비교적 첫 번째 응답에 높은 점수 부여","s":"Settings","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#settings","p":882},{"i":907,"t":"Fig 4 에서 LLaMA-Adapter 와 Alpaca 의 response 비교 Alpaca 와 comparable 한 합리적은 응답 출력 Fig 6 에서 quantitative 결과 비교 GPT-4 평가에서 LLaMA-Adapter 가 비교적 많은 승리를 얻음 이를 통해 zero-initialized attention 메커니즘의 효과 입증","s":"Performance","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#performance","p":882},{"i":909,"t":"Table 1 에서 다양한 instruction-following 의 learnable parameter, 저장 공간 및 훈련 시간 비교 LLaMA-Adapter 는 1.2M parameter, 4.9M 저장 공간 및 1 시간 훈련으로 우수한 훈련 효율성 제공 모바일에서도 LLaMA 같은 LLM 을 fine-tuning 가능","s":"Efficiency","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#efficiency","p":882},{"i":912,"t":"Multi-modal 의 경우 input image 의 multi-sacle global feature 추출을 위해 CLIP 의 visual encoder 를 활용하여 learnable projection network 로 간단한 연속 MLP 사용 생성을 위한 ecoding 으로 greedy search 사용 다른 hyperparameter 는 LLaMA-Adapter 와 동일 ScienceQA 및 COCO Caption 에서 평가 visualtextual contextsquestionoptionanswer","s":"Settings","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#settings-1","p":882},{"i":914,"t":"LLaMA-Adapter 와 VQA methods 및 language models 를 ScienceQA 에서 비교 LLaMA-AdapterT_TT​ 는 1.2M Parameter 만으로 78.31% 성능 달성 0.6M 개 projection network 를 추가 주입하여 multi-modal 에 +6.88% 성능 향상 COCO Caption 에서는 BLIP 및 BLIP-2 같은 모델과 비교 많은 비용이 드는 모델들과 비교하여 LLaMA-Adapter 는 Caption 에서도 ClipCap 보다 나은 성능을 보임","s":"Performance","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#performance-1","p":882},{"i":917,"t":"transformer layer 에 삽입할 수를 조사. layer 수 증가시킬 수록 parameter 가 많아지지만 ScienceQA 에서 큰 성능 향상","s":"Insertion Layers","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#insertion-layers","p":882},{"i":919,"t":"zero-initialized 매커니즘은 LLaMA-Adapter 의 초기 훈련 중 안정성과 생성 능력에 필수 zero-initialized attention 으로 +43.08% 성능 향상 기여 반면 rand-init attention 은 40.77% 만 달성 Table 2 의 첫번 째 항인 Random Choice 와 동일한 성능 위는 zero-initialized attention 의 loss curves 로, rand-init attention 보다 더 빨리 수렴하고 더 낮은 loss 에 도달","s":"Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#zero-initialized-attention","p":882},{"i":921,"t":"LLM 의 fine-tuning data 는 보통 pre-trained 보다 작은 규모다. 이 때문에 over-fitting 방지를 위해 hyperparameter 조정에 조심해야 한다 위는 LLaMA-Adapter 가 over-fitting 에 상대적으로 견고함을 보여준다. 15 - 60 epoch 으로 변하는 과정에도 여전히 정확도가 상승하는 것을 볼 수 있다. 이는 parameter 가 가벼운 Adapter 만 학습하기 때문","s":"Robustness to Over-fitting","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#robustness-to-over-fitting","p":882},{"i":924,"t":"image classification 을 위해 ImageNet-21K dataset 에서 pre-trained ViT-B/16 을 fine-tuning VTAB-1K 사용하여 평가 진행 QA task 의 경우, RoBERTalarge_{large}large​ 모델을 SQuAD 에 평가 진행","s":"Settings","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#settings-2","p":882},{"i":926,"t":"저자의 approach 는 VPT 에 비해 각각 +3.26%, +2.00%, +1.77% 의 향상 SQuAD v1.1 및 v2.0 에서 zero-initialized attention 은 P-tuning v2 보다 향상","s":"Performance","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"#performance-2","p":882},{"i":928,"t":"LLaMA-Adapter 는 1.2M parameter 및 1시간의 훈련으로 Alpaca 와 comparable 훈련 안정성 및 좋은 성능을 위해 gating mamechanism 을 갖춘 zero-initialized attention 도입 instruction singal 을 적응적으로 통합 및 LLaMA 의 pre-trained knowledge 보존 multi-modal reasoning 을 잘 일반화하여 ScienceQA 및 COCO caption 에 comparable","s":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter","h":"","p":882},{"i":930,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2304.15010.pdf","s":"LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":932,"t":"최근 LLaMA-Adapter 가 LLMs 와 visual input 을 다루는 잠재력을 보여주지만 여전히 open-ended visual instruction 은 잘 처리하지 못하며 GPT-4 에 뒤쳐지고 있다. 본 논문에서는 parameter-efficient visual instruction model 인 LLaMA-Adapter V2 제안 LLaMA-Adapter 를 더 많은 learnable parameter (norm, bias 및 scale 등) 을 활용하여 보강 Adapter 외의 전체 LLaMA model 의 instruction-following 능력을 분산 visual token 을 early LLM layer 에만 주입하는 early fusion 전략을 제안 visual knowledge incorporation 개선 image-text pair 및 instruction-following data 의 joint training paradigm 을 도입 learnable parameter 의 분리된 그룹을 최적화 image-text alignment 및 instruction-following 두 작업 간의 간섭을 효과적으로 완화 소규모 image-text 및 instruction-following dataset 만으로 강력한 multi-modal reasoning 달성 inference 단계 LLaMA-Adapter 에 추가적인 expert models (e.g. captioning/OCR) 을 통합 training cost 발생하지 않고 image understanding 능력 더욱 향상 기존 LLaMA-Adapter 와 비교하여 LLaMA-Adapter V2 는 LLaMA 에 14M parameter 추가만으로 open-ended multi-modal instruction 수행ㅅ 가능 그리고 이 설계는 language-only instruction-following 을 더욱 강화시키며 채팅 상호작용에도 뛰어난 성능을 보임","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":934,"t":"최근 LLM 을 instruction-following model 로 변환하는 연구가 진행 Stanford Alpaca 는 InstructGPT model 로 생성된 instruction examples 를 사용하여 LLaMA 를 instruction-following model 로 fine-tuning 한다. LLaMA-Adapter 는 가벼운 Adapter 와 zero-initialized attention 의 도입으로 frozen LLaMA 에게 parameter-efficient fine-tuning 으로 multi-modal knowledge 를 주입한다. 가장 최근은 MiniGPT-4 및 LLaVA 같은 연구로, language-only instruction model 을 multi-modal 로 확장하여 visual reasoning 능력을 부여하는 새로운 연구 파동을 일으켰다. 본 논문은 parameter-efficient visual instruction model 설계를 목표로 한다. LLaMA-Adapter 기반의 새로운 method 인 LLaMA-Adapter V2 개발 LLaMA-Adapter 는 instruction-following model visual feature 를 adaptation prompts 로 주입하여 visual instruction model 로 변환 multi-modal instruction tuning data 의 부족으로 전통적인 vision-language model 로 제한됨 예로, COCO Caption 에서 훈련된 LLaMA-Adapter 는 \"“Generate caption for this image\" 같은 prompt 에 대해 짧은 caption 만 생성 가능 복잡한 visual reasoning 및 QA task 같은 open-ended multi-modal instruction 에는 adaptation 이 불가능 frozen LLaMA-Adapter 를 사용하여 image-text pairs 에서 visual projection layer 를 최적화하여 vision-language alignment 를 보장하도록 개선 visual feature 가 adaptation prompts 에 두드러지며 instruction-following 능력이 빠르게 저하되는 것 관찰 이를 대응하기 위해 image-text alignment 와 language instruction funing 두 가지 task 간의 간섭을 해결하는 간단한 early fusion of visual knowledge 제안 LLaMA-Adapter 의 dynamic visual prompts 는 last LLL layer 의 static adaptation prompts 에 통합 LLaMA-Adapter V2 에서는 dynamic visual prompt 를 처음 KKK layer 에만 분배 K<N−LK < N - LK<N−L NNN : total number of Transformer layers 이를 통해 image-text alignment 가 model 의 instruction-following 능력 방해하지 않음 joint training with disjoint parameter 고품질의 multi-modal instruction data 없이, image caption 및 instruction-following data 로 분리된 parameter 를 joint training 하여 우수한 visual instruction learning 가능 bias tuning of linear layers LLaMA-Adapter 를 normalization, layer bias 및 scale 같은 learnable parameter 를 unlocking 하여 보완 tunable capacity 를 증가시켜 instruction-following knowledge 를 LLM 전체에 분산 이러한 parameter 는 모델 전체의 약 0.04% 만 차지 이를 통해 parameter-efficient approach 유지 additional expert models (captioning, detection 및 OCR system) expert model 과 협력하여 LLaMA-Adapter V2 는 대규모 image-text pair 불필요 다양한 expert 를 plugging 가능하여 유연성 얻음 다음은 주요 기여 요약 Stronger Language Instruction Model parameter-efficient tuning 및 high-quality language instruction data 사용하여 LLaMA-Adapter 능가 Balanced Visual Instruction Tuning image-text alignment 와 instruction-following object 간의 간섭 해결을 위해 early fusion 전략 사용 multi-modal instruction training data 없이 captioning data 및 instruction-following data 의 분리된 parameter 를 joint training Integration of Expert Systems 다양한 expert model 통합","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":938,"t":"instruction-following 능력 습득을 위한 parameter-efficient fine-tuning LLaMA-Adapter 는 LLaMA 를 freezing 하고 1.2M 추가 adapter module 만 도입 adapter layer 는 LLaMA 의 Transformer layer 상단에 사용 leanable soft prompt set 을 word token 의 prefix 에 연결 new adapting knowledge 를 LLaMA 에 통합하기 위해 zero-initialized attention 사용 이를 통해 adaptation prompt word token 에 대한 기여를 학습 초기에 0으로 초기화된 gating factor 를 학습하여 조절 훈련 중 gating 크기는 점진적으로 커지며 LLaMA 에 주입 이 전략은 훈련 초기, LLaMA 의 언어 생성 능력을 보존하며 새로운 지식을 지속적으로 통합하여 강력한 instruction-following 능력을 만든다.","s":"Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#zero-initialized-attention","p":929},{"i":940,"t":"multi-modal reasoning 을 위해 image 및 video 통합 가능 pre-trained visual encoder 를 지닌 CLIP 으로 multi-scale visual feature 추출 learnable projection layer 를 통과하여 visual semantics 를 language embedding space 와 alignment 이후 visual feature 는 Transformer layer 상단에서 element-wisely added 위 과정으로 LLaMA-Adapter 는 text 및 visual input 을 기반으로 response 생성 가능하여 ScienceQA 에서 comparable","s":"Simple Multi-modal Variant","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#simple-multi-modal-variant","p":929},{"i":942,"t":"LLaMA-Adapter 를 사용하여 COCO Caption dataset 에서 adapter module 및 visual projection layer 를 fine-tuning 하는 실험 수행 새로운 visual 단서가 adaptation prompt 를 간섭하는 경향이 나타나 instruction-following feature 를 덮어버림. 따라서 LLaMA-Adapter V2 를 제안하여, multi-modal 잠재력을 완전히 발휘하도록 함","s":"Open-ended Multi-modal Reasoning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#open-ended-multi-modal-reasoning","p":929},{"i":945,"t":"LLaMA-Adapter 는 zero-initialized attention 으로 adaptation prompt 를 frozen LLaMA 에 사용 이는 new knowledge 를 통합하지만 LLM 내부 parameter 를 수정하지 않고는 parameter update 가 adaptation prompt 및 gating factor 로 제한됨 이 때문에 deep fine-tuning 수행 능력이 제한된다. 이를 고려하여 더욱 효과적인 통합을 위해 bias tuning 전략 제안 instruction-following data 를 adaptively handle 하기 위해 LLaMA 의 모든 normalization layers 를 unfreezing Transformer 의 각 linear layer 에 대해 learnable parameter 로 bias 및 scale factor 추가 특정 linear layer 및 pre-trained weights 를 x\\text{x}x 및 WWW 로 표시 LLaMA-Adapter V2 에선, bias bbb 및 scale sss 를 사용하여 linear layer 수정 \\begin{align} y = W \\cdot \\text{x} \\rightarrow y = s \\cdot (W \\cdot \\text{x} + b), \\tag{1} \\\\ \\text{where} \\ b = \\text{Init}(0),\\ s = \\text{Init}(1). \\tag{2} \\end{align} bias 와 scale factor 는 각각 0 과 1 로 초기화하여 초기 단계에 안정화 bias tuning 및 high-quality instruction data 를 통합하여 우수한 instruction-following 능력을 얻음 특히, newly added parameter 는 전체 LLaMA 의 0.04% (약 5M) 만 차지 LLaMA-Adapter V2 는 여전히 highly parameter-efficient approach","s":"4.1 Bias Tuning of Linear Layers","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#41-bias-tuning-of-linear-layers","p":929},{"i":947,"t":"bias tuning 은 이전 parameter-efficient method 와 유사 BERT fine-tuning 을 위한 BitFit 및 visual prompt tuning 을 위한 SSF 가 있음 BitFit 및 SSF 는 80M parameter scale 을 가진 comprehension task 를 위해 설계 저자의 approach 는 70B - 650B parameter scale 의 LLM 에서 효율성 나타냄 bias tuning 은 input 에 독립적이며, row-rank 를 사용하여 input 에 의존적인 bias 를 추가하는 LoRA 와는 달리, fine-tuning 비용을 더 줄임","s":"Discussion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#discussion","p":929},{"i":949,"t":"저자의 목표는 LLaMA-Adapter V2 에게 long language response 를 생성하는 능력과 multi-modal understanding 을 동시에 부여하는 것 저자는 LLaMA-Adapter V2 를 위해 image-text captioning data 및 language-only instruction examples 를 활용하기 위한 joint training paradigm 제안 500K image-text pairs 및 50K instruction data 사이의 데이터양 차이로 인해, instruction-following 능력에 피해가 갈 수 있음 따라서 이질적인 (disjoint) parameter groups 를 최적화 image-text captioning data : visual projection layer 및 초기 zero-initialized gating 과 관련된 부분만 학습 language instruction data : late adaptation prompts 와 zero gating, unfrozen norm 및 newly added bias 및 scale factor (선택적으로 low-rank adaptation) 가 사용 이를 통해 image-text understanding 과 instruction-following 간의 간섭 문제를 자연스럽게 해결","s":"4.2 Joint Training with Disjoint Parameters","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#42-joint-training-with-disjoint-parameters","p":929},{"i":951,"t":"joint training 전략 덕에 MiniGPT-4 와 LLaVA 같은 high-quality multi-modal instruction data 가 불필요 대신 image-text pairs 및 instruction-following 데이터만 요구 (Fig. 1 에서 비교) captioning data 는 Fig. 2 에서 처럼 short answers 를 포함하여 image understanding 에 대한 LLM 을 확장하는 역할을 해준다. 한편 language-only instruction data 는 long detailed sentences 를 생성할 능력을 보존하기 위해 사용한다. 위와 같은 상호보완적으로 조합하여 LLaMA-Adapter V2 는 high-quality instruction data 없이 소규모의 image-text 및 instruction-following data 만으로 우수한 multi-modal reasoning 을 달성","s":"Discussion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#discussion-1","p":929},{"i":953,"t":"vision 및 language fine-tuning 간의 간섭을 피하기 위해, visual prompts 와 adaptation prompts 간의 직접적인 상호작용 방지를 위해 early fusion 제안 LLaMA-Adapter 에선 visual prompt input 이 frozen visual encoder 에 의해 순차적으로 encoding 되고 learnable visual projection layer 에 의해 추가되어 각 inserted layer 에 adaptation prompt 결합 LLaMA-Adapter V2 는 encoded visual tokens 와 adaptation prompt 를 서로다른 Transformer layer 에 fusing 하지 않고 삽입 dataset-shared adaptation prompts : LLaMA-Adapter 를 따라, last LLL layers (e.g. L=30L=30L=30) 에 삽입 input visual prompts : first Transformer layer with zero-initialized attention 에서의 word token 에 직접 연결 이 early fusion 으로 두 가지 fine-tuning target 간의 충돌을 효과적으로 해결하는데 도움되며, proposed joint training 과 함께 사용하여 우수한 multi-modal reasoning 능력을 가짐","s":"4.3 Early Fusion of Visual Knowledge","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#43-early-fusion-of-visual-knowledge","p":929},{"i":955,"t":"MiniGPT4 및 LLaVA 모델들은 visual model 과 LLM 연결을 위해 대규모 image-text 훈련이 필요 이에 반해, LLaMA-Adapter V2 는 작은 규모의 image captioning data 에 fine-tuning 하여 높은 data-efficient 하지만 이 방법의 image understanding 능력이 비교적 약하여 때로 부정확하거나 관련 없은 응답을 유발 더 많은 image-text data 수집 및 강력한 multi-modal module 도입 대신, caption, OCR 및 search engines 같은 expert system 을 통합하여 additional visual reasoning proficiency 을 부여하는 것을 제안 저자는 caption, detection 및 OCR 같은 expert system 으로 visual instruction-following 능력 향상 input image 를 고려하여 pre-trained visual encoder 를 사용하여 visual context 를 encoding 하고 expert system 에게 textual context 의 caption 을 생성하도록 요청 COCO Caption 에 pre-trainig 된 LLaMA-Adapter 를 expert system 으로 채택 어떠한 image 및 text model 또는 search engine 을 이 expert system 으로 사용할 수 있음을 주목 위 approach 는 특정 downstream task 에 따라 다양한 expert system 간에 쉽게 전환 가능","s":"4.4 Integration with Experts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#44-integration-with-experts","p":929},{"i":959,"t":"LLaMA-Adapter V2 는 52K single-turn instruction data from GPT-4-LLM 및 567K captioning data from COCO Caption 에 훈련 MiniGPT-4 및 LLaVA 와 달리 어떠한 visual instruction data 도 사용하지 않음 또한 ShareGPT 의 80K conversation data 를 사용하여 chatbot system 훈련","s":"Training Data","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#training-data","p":929},{"i":961,"t":"32 Transformer layers 를 사용한 LLaMA-7B model 의 경우 static adaptation prompts 를 last 31 layers 에 삽입 dynamic visual prompts 는 prompt length 를 20으로 설정하고, 첫 번째 layer 에 삽입 normalization layers, linear layer bias 및 scalie 의 모든 parameter 는 training 중 update 되며, LLaMA 의 나머지 parameter 는 freezing 유지","s":"Implementation Details","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#implementation-details","p":929},{"i":963,"t":"bias tuning 및 high-quality instruction data 를 사용한 LLaMA-Adapter V2 는 LLaMA 의 instruction-following 능력을 향상 Table 1 의 결과에서 처럼, LLaMA-Adapter V2 는 인간의 지시에 포괄적인 답변과 상세한 설명 제공 knowledge updating 을 위해 bias tuning 에 더 많은 learnable parameter 를 수반했을 때, language context 에 대한 깊은 이해가 필요한 chatbot system 도 구축이 가능했다. 80K conversation data 를 훈련시키면, 더 강력한 chatbot model 개발 Fig. 11 은 7B 의 chatbot examples 이며, 시스템은 질문에 대답하지만 문맥 이해는 그리 정확하진 않다. 모델을 65B 으로 확장하면 (Fig. 10), chatbot 은 더욱 강력하고 대답도 잘 한다. Fig. 5 에서는 GPT-4 를 사용하여 response quality 평가. LLaMA-Adapter V2 는 total score 및 50/80 qustions 에 대해 ChatGPT 를 이기는 성능 보임","s":"5.2 Stronger Language Instruction Model","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#52-stronger-language-instruction-model","p":929},{"i":965,"t":"LLaMA-Adapter 는 주로 language instruction model / close-set vision-language model 인 반면, LLaMA-Adapter V2 는 caption 및 language-only instruction data 에 joinly training 한 강력한 vision instruction model. 이번 섹션에서 LLaMA-Adapter V2 의 image captioning 능력 및 어떻게 GPT-4 같은 일반적인 목적의 multi-modal understanding 시스템으로 확장하는지 보여줌. 또한 expert system 을 통합하여 instruction-following 능력을 더욱 향상","s":"5.3 Visual Instruction Model","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#53-visual-instruction-model","p":929},{"i":967,"t":"LLaMA-Adapter 는 단순히 adaptation prompts 에 visual feature 를 추가하여 multi-modal input 을 지원. COCO Caption dataset 에 fine-tuning 후, 강력한 image captioning model 로 변했다. 위 결과에서 LLaMA-Adapter 가 대규모 image-text pretraining 없이 BLIP 과 comparable 결과 달성하는 것 관찰. 하지만 LLM 능력을 재사용 불가능 및 특정 prompt (e.g. Generate caption for this image) 에는 민감하게 된다. early fusion 및 joint training 사용으로, LLaMA-Adapter V2 는 language instruction-following 및 image captioning 이 동시에 수행 가능한 강력한 visual instruction model 이 됐다. 위에서 LLaMA-Adapter 및 LLaMA-Adapter V2 의 image captioning 결과를 비교한다. LLaMA-Adatper 는 대답이 짧은 반면 LLaMA-Adatper V2 는 natural 하고 detail 한 설명을 생성한다. Failure Case 를 보면, 의도적으로 분포 밖의 예제 (카툰풍)을 선택했을 때 항상 정확한 이미지 설명을 생성하진 않음을 볼 수 있다. 이는 image-text alignment stage 가 부족한 것일 수 있다.","s":"Image Captioning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#image-captioning","p":929},{"i":969,"t":"Fig. 7 에서 보이듯, image content 에 대한 prompt 를 \"why is ...\" 및 \"what should ...\" 같은 형태로 질문했을 경우, 모델은 visual information 을 language context 와 통합하여 더 복잡한 reasoning 및 decision 을 하는 것을 볼 수 있다. image 에서 question 이 참조하는 객체나 특징을 식별하고 설명하며, context 기반으로 관련 정보나 제안을 해준다. 이는 image-text pairs 와 instruction data 간의 간섭을 해결하는 효과를 보여주며, language 및 vision understanding 이 모두 필요한 현실 세계 응용에 대한 잠재력을 보여준다.","s":"Visual Understanding","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#visual-understanding","p":929},{"i":971,"t":"visual understanding 향상을 위해, inference 중 visual expert models 를 통합하여 추가적인 textual contexts 를 제공 Fig. 8 에서 caption expert 를 포함한 LLaMA-Adapter V2 를 보여준다. image 의 visual contents 에 대한 정확하고 상세한 설명을 생성한다. Fig. 9 에서 DocVQA 의 OCR expert 를 사용한 예제를 볼 수 있다. image 에서 감지된 text 를 활용하여 안경의 가격 같은 구체적인 단서로 질문에 대한 정확한 답변을 생성.","s":"Integration with Experts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"#integration-with-experts","p":929},{"i":973,"t":"본 연구는 parameter-efficient visual instructions tuning system 인 LLaMA-Adapter V2 제안 joint training on image-text pairs 및 instruction-following data 이를 통해, pre-trained LLM 을 zero-shot visual instruction model 로 변환 zero-shot visual instruction-following 은 image-text pairs 와 instruction-following data 간의 간섭을 줄여 더욱 향상 chatbot 과 같이 강력한 multi-turn dialog 능력을 보유 부정확한 이미지 설명 문제 해결을 위해 expert system 과 통합 expert 통합으로 zero-shot instruction-following 은 수행 understanding 은 LLaVA 보다 뒤쳐지며, expert 로부터의 부정확한 정보 영향을 받을 수 있음 이후 visual-following 향상을 위해 multi-modal instruction dataset 또는 다른 PEFT 방법을 통한 fine-tuning 방법 탐구","s":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/LLaMA-Adapter V2","h":"","p":929},{"i":975,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2205.11961v2.pdf","s":"ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":977,"t":"본 논문은 multi-task parameter-efficient language model tuning 방법을 소개 다양한 tasks 에 대한 pre-trained small prefix embedding vectors - soft prompts 의 mixture 를 통해 다양한 tasks 전역의 knowledge 를 transfer learning 하는 ATTEMPT (ATTEntional Mixture of Prompt Tuning) 소개 large-scale source tasks 의 encoding 을 소수의 파라미터로 추출 각 instance 에서 target task 의 새로 초기화된 prompt 와 source prompt 를 interpolate 하기 위한 attention module 을 훈련하여 source prompt 를 얻음 훈련 중엔, target task prompt 와 attention weights 만 업데이트되며, 이 weights 는 multi-task training 에서 여러 tasks 간에 공유 original LM 과 source prompts 는 그대로 유지 ATTEMPT 는 높은 parameter-efficient (예: full fine-tuning 보다 2,300배 적은 parameter update), high-resource tasks 를 사용하는 task 에 대한 knowledge 를 활용하여 높은 성능 달성 pre-trained soft prompt 를 사용하여 modular 이며, 효과적인 knowledge transfer 를 위해 source prompt 를 자유롭게 추가 및 제거 가능 21가지 NLP datasets 실험 결과, ATTEMPT 가 prompt tuning 을 크게 능가","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":979,"t":"LLMs 의 full fine-tuning 은 target task 훈련에 맞추는 일반적인 방법이다. 최근 PEFT 가 등장하지만 효율성을 높이면 task 성능이 감소하게 된다. 게다가 훈련 데이터만 훈련하고 다른 NLP tasks 에 대한 이점이 없다. 저자는 PEFT methods 가 high-resource tasks 의 rich knowledge 를 활용하여 훈련 효율성 및 task 성능 모두 향상시킬 수 있다 주장한다. 본 연구는 새로운 parameter-efficient modular multi-task tuning 인 ATTEMPT(ATTentional Mixtures of Prompt Tuning, Fig. 1) 을 소개한다. 기존 LM 은 동결한 채, prepended trainable soft pomrpts 의 mixture 을 통해 multiple task 의 knowledge 를 효율적으로 통합 먼저, large-scale source tasks 에 transferable soft embeddings 를 pre-train → source prompts 이 source tasks 는 다른 tasks 에 이로운 지식을 포함할 가능성이 있다. 이후, ATTEMPT 는 target task 에 대한 new target prompt 를 초기화하고 source prompts 및 target prompt 의 attention-weighted combination 을 학습 attention module 은 여러 tasks 를 동시 학습 및 공유 가능한 가벼운 network ATTEMPT 는 이전의 multi-task fine-tuning 및 PEFT 보다 세 가지 이점 제공 full fine-tuning (FFT) 의 0.4% parameter 만 업데이트하면서 highly parameter-efficient 및 competitive performance 달성 pre-trained soft prompts 를 사용하여 modular multi-task learning 가능하며, 다양한 tasks 의 knowledge 를 유연하게 결합, 재사용 또는 제거가 가능하고 new tasks 를 source 또는 target task list 에 추가할 수 있다. 어떤 task 과 관련됐는지 미리 계산하는 것에 의존하는 이전 연구와 달리, ATTEMPT 는 많은 source task 에서 유용한 task 에 중점을 두도록 학습. 게다가 추론 시, single LM 에 여러 pre-loaded soft prompts 를 사용하여 multiple task 수행 가능 ATTEMPT 는 attention distributions 를 생성함으로써 multi-task learning 에서 underlying task similarities 에 대한 interpretability 를 향상 다양한 tasks, domains 및 output 형태에 대한 21 datasets 에서 수행 ATTEMPT는 이전 prompt tuning 기반 접근법보다 큰 차이로 성능 능가 특히 smaller datasets 에서, SOTA transfer 또는 FFT 와 비슷하다. 또한 few-shot domain adaptations (i.e. 4-32 shots) 에 효과적 저자는 ATTEMPT 가 parameter-efficient 이며 backbone LLM 에 competitive 한 결과를 보여준다고 한다. 그리고 ablation studies 를 통해 learned attentions, multi-task learning 및 multiple tasks 에서의 modular transfer 가 주로 성능에 기여하는 것을 시사했다고 한다. attention distributions 는 겉으로 보기엔 다른 tasks 사이의 underlying similarities (e.g. entailment 및 paraphrase detection) 를 보여주며, task 간에 효과적인 knowledge transfer 를 나타내는 signal 로 작용한다.","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":982,"t":"ATTEMPT 는 source tasks 의 knowledge 를 small parameter 로 인코딩한 source prompts 를 얻기 위해 parameter-efficient prompt tuning 을 활용한다. 그리고 모든 target task instance 에 대한 attention mechanism 을 통해 target task 를 새롭게 초기화된 source prompt 와 target prompt 을 통합함으로써 instance-level prompts 를 tuning ATTEMPT 는 source tasks 에 대한 source prompts P1,⋯ ,P2P_1, \\cdots ,P_2P1​,⋯,P2​ (Fig. 2 왼쪽)을 pre-training target task 에 대한 target prompt PtargetP_{target}Ptarget​ 을 초기화 이후 attention module G\\mathcal{G}G 을 사용하여 각 instance (x,y)(x, y)(x,y) 에 대한 embedded input XXX 및 soft prompts 간에 attention 계산 그 다음, ATTEMPT 는 계산된 attentions 을 기반으로 source prompts 와 target-task prompt 을 interpolating 함으로써 instace-wise prompt PinstanceP_{instance}Pinstance​ 을 제공 PinstanceP_{instance}Pinstance​ 은 frozen LM θ\\thetaθ 의 final input 형태가 되기 위해 input 에 prepend 된다. 훈련 중엔, 주어진 PinstanceP_{instance}Pinstance​ 와 xxx 으로 yyy 를 생성할 확률을 최대화하여 PtargetP_{target}Ptarget​ 및 G\\mathcal{G}G 의 weights 만 업데이트 한다. 중요한 점은 다양한 tasks 의 task-specific parameters ϕtarget\\phi_{target}ϕtarget​ 이 동일한 minibatch 에서 훈련될 수 있도록 prompt 또는 prefix tuning 의 특성을 활용한다 (Prompt Tuning, Prefix-tuning). 따라서 추가적인 parameter 및 inference efficiency 를 위해 shared attention G\\mathcal{G}G 와 multiple target task prompts 를 동시에 훈련시킬 수 있다.","s":"3. Method","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":984,"t":"먼저 MultiNLI, SQuAD 같은 ttt 개의 high-resource datasets 을 prompt tuning 을 통해 source prompt [P1,…,Pt][P_1, \\dots, P_{t}][P1​,…,Pt​] 를 얻는다. 각 source prompt 는 해당 source task 에 한번 만 훈련되며, 다른 target tasks 로 transfer 될 수 있다. 공식으로는 input sequence XXX 에 대한 source prompt 는 P=[p1,…,pm]∈Rm×dP = [p_1, \\dots, p_m] \\in \\mathbb{R}^{m \\times d}P=[p1​,…,pm​]∈Rm×d로 표현한다. mmm : prompt length ddd : LM dimension prompt 가 prepend 된 Input embedding [P;X][P; X][P;X] 는 frozen LM θ\\thetaθ 에게 주입된다. 훈련 중, 다음 목적함수를 최대화함으로서 target sequence yyy 를 생성할 확률의 우도를 높이기 위해 prompt embeddings 만 업데이트 한다. max⁡P pθ(y ∣ [P;X]).\\begin{equation} \\underset{P}{\\max}\\ p_\\theta (y\\ |\\ [P; X]). \\end{equation}Pmax​ pθ​(y ∣ [P;X]).​​","s":"3.1 Source Prompt Pre-training","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#31-source-prompt-pre-training","p":974},{"i":986,"t":"new target task 에 대한 soft prompt Ptarget(= Pt+1)P_{target}(=\\ P_{t+1})Ptarget​(= Pt+1​) 를 초기화한 후, 저자는 G\\mathcal{G}G 에 생성된 attention scores 로 source prompts 및 target task prompt 간에 interpolating 함으로써 target task 의 각 instance 에 대한 instance-wise soft prompts PinstanceP_{instance}Pinstance​ 를 학습한다. Eq. 1 과 유사하게, 저자는 제공된 instance-wise prompt 를 input 에 연결하고 우도를 최대화하여 ATTEMPT 를 훈련한다. max⁡Ptarget,G pθ(y ∣ [Pinstance;X]).\\begin{equation} \\underset{P_{target}, \\mathcal{G}}{\\max}\\ p_\\theta (y\\ |\\ [P_{instance}; X]). \\end{equation}Ptarget​,Gmax​ pθ​(y ∣ [Pinstance​;X]).​​ 훈련 중에는 new task prompt PtargetP_{target}Ptarget​ 및 G\\mathcal{G}G 는 PinstanceP_{instance}Pinstance​ 를 통해 업데이트되지만, source prompts 및 original LM θ\\thetaθ 는 이전 tasks 나 pre-training 로 학습된 knowledge 를 보존하기 위해 건드리진 않는다.","s":"3.2 Target Prompt Training","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#32-target-prompt-training","p":974},{"i":988,"t":"ATTEMPT 는 input-prompt attentions 를 계산함으로써 source prompts set 이 instance-wise prompt 에 미치는 영향을 조절한다. 구체적으로, attention module G\\mathcal{G}G 는 input XXX 에서 source prompts 및 new target prompt 를 모두 포함하는 prompts 로의 attention weights a1,…,at+1a_1, \\dots, a_{t+1}a1​,…,at+1​ 을 생성한다. input X∈Rl×dX \\in \\mathbb{R}^{l \\times d}X∈Rl×d 및 soft prompt Pj∈Rm×dP_j \\in \\mathbb{R}^{m \\times d}Pj​∈Rm×d 는 각기 다른 sequence lengths 를 가지기 때문에, 먼저 XXX 및 각 source prompt embedding 에 대한 각 dimension 에 대한 max-pool 연산을 수행하고 X^∈Rd\\hat{X} \\in \\mathbb{R}^dX^∈Rd 및 P^j∈Rd\\hat{P}_j \\in \\mathbb{R}^dP^j​∈Rd 를 얻는다. 이후 X^\\hat{X}X^ 를 G\\mathcal{G}G 에 주입하여 prompt space 로 project 한다. Khashabi et al. (2022, PROMPT WAYWARDNESS) 는 soft prompts 가 embedding space 에서 의미있는 tokens 에 해당하지 않을 수 있기 때문에 X^\\hat{X}X^ 와 P^\\hat{P}P^ 간의 유사성을 계산하는 것만으로 신뢰있는 score 를 얻을 수 없다고 주장한다. 효율성을 위해, G\\mathcal{G}G 는 다음과 같이 down 및 up projection layer 로 구성한다. Hdown=Wdown⊤(X^)Hup=W⊤up(NonLinear(Hdown))Hout=LayerNorm(Hup),\\begin{array}{ll} H_{down} &= W^\\top_{down}(\\hat{X}) \\\\ H_{up} &= W^\\top_{}up(NonLinear(H_{down})) \\\\ H_{out} &= LayerNorm(H_{up}), \\end{array}Hdown​Hup​Hout​​=Wdown⊤​(X^)=W⊤​up(NonLinear(Hdown​))=LayerNorm(Hup​),​ Wdown∈Rd×r(r<d)W_{down} \\in \\mathbb{R}^{d \\times r} (r < d)Wdown​∈Rd×r(r<d) 및 Wup∈Rr×d(r<d)W_{up} \\in \\mathbb{R}^{r \\times d} (r < d)Wup​∈Rr×d(r<d) : projection parameter 이며 훈련 중에만 업데이트 된다. non-linear layer 에 SiLU 사용 HupH_{up}Hup​ 에 Layer Norm 을 적용하는데, layer norm 을 적용하지 않으면 HupH_{up}Hup​ 은 빠르게 증가하고 gradients explode 를 관찰할 수 있었다. 마지막으로, attentions 계산을 위해 P^j\\hat{P}_jP^j​ 와 HoutH_{out}Hout​ 간에 product 를 계산하고, 다음과 같이 prompt 에 softmax 를 적용했다. aj=eP^jHout/T∑k=1t+1eP^kHout/T\\begin{equation} a_j = \\frac{e^{\\hat{P}_j H_{out}}/T}{\\sum^{t+1}_{k=1}e^{\\hat{P}_k H_{out}}/T} \\end{equation}aj​=∑k=1t+1​eP^k​Hout​/TeP^j​Hout​/T​​​ TTT : softmax temperature Eq. 3 의 logit 을 스케일링하여 attention module 이 over-confident 되지 않도록 함","s":"3.2.1 Input-prompt Attentions","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#321-input-prompt-attentions","p":974},{"i":990,"t":"instance XXX 에 대한 final soft prompt 는 Eq. 3 에 의해 생성된 attention 을 기준으로 prompt 의 weighted sum 으로 계산된다. Pinstance(X)=Ptarget+∑j=1t+1ajPj.\\begin{equation} P_{instance}(X) = P_{target} + \\sum^{t+1}_{j = 1} a_j P_j. \\end{equation}Pinstance​(X)=Ptarget​+j=1∑t+1​aj​Pj​.​​ 오른쪽의 두 번째 항은 같은 task 의 인스턴스마다 다른 반면, PtargetP_{target}Ptarget​ 항은 task-specific 이다. 이 attentions 는 다양한 prompts 의 영향을 제어하고 여러 tasks 의 knowledge 를 유연하게 구성하도록 하는 gate 역할을 한다. Eq. 4 에 보이듯, target-task-specific prompt Ptarget(=Pt+1)P_{target} (=P_{t+1})Ptarget​(=Pt+1​) 의 1+at+11+a_{t+1}1+at+1​ weights 선택은 sources tasks 의 어떠한 knowledge 도 instance XXX 에 유용하지 않을 경우, ATTEMPT 에게 source prompt 의 역할을 down-play (줄이도록) 허용해주면서 PtargetP_{target}Ptarget​ 의 영향을 유지하여 훈련 중에 적절히 업데이트되도록 한다.","s":"3.2.2 Prompt Interpolation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#322-prompt-interpolation","p":974},{"i":992,"t":"Training​ ATTEMPT 는 attention module G\\mathcal{G}G 및 mutliple target taks prompts 를 동시에 훈련 가능하다. 여기서 저자는 G\\mathcal{G}G 를 공유하여 target tasks 그룹에 대한 multi-task learning 접근법을 설명한다. 먼저 각 task ID 정보를 유지하며 훈련 데이터셋에 연결 훈련 중, task ID 에 따라 instance 에 해당하는 target task prompt 를 검색하고 prompt set 에 대한 attention 을 계산하며 Section 3.2 에서 설명한대로 instance-wise prompt 를 생산한다. 각 target-task prompt 에 대한 loss 는 prompt 가 사용될 때만 역전파되며, attention module 의 weights 는 각 iteration 에서 업데이트된다. 이 방식으로 target task 들은 느슨하게 연결되어 향상된 task-agostic attention module 에 기여하며, 특히 target task training data 가 적은 경우 효과적이다. 더구나, 각 task 당 업데이트해야 하는 parameter 수를 감소시키고 추론 시간의 효율성도 향상시킨다. Inference​ 추론 시점에, 저자는 source prompt, 모든 target task prompt 및 공유된 G\\mathcal{G}G 를 한번 만 로드한다. 각 instance 에 대해, ATTEMPT 는 target task prompt 를 검색하고 Eq. 4 와 같이 PinstanceP_{instance}Pinstance​ 를 생성한 다음 PinstanceP_{instance}Pinstance​ 를 input embedding 에 연결한다. instance prompt 생성 후의 추론 프로세스는 prompt tuning 과 동일하다. ATTEMPT 는 multiple target prompt 를 로드하고 multiple target tasks 를 동시에 수행하여 inference time model loading overhead 을 크게 감소시킨다. full fine-tuning 이나 Adapter 와 같은 기존 접근 방식은 각 target task 에 대해 모델 로딩이 필요하므로 multi-task inference pipeline 이 복잡해진다.","s":"3.3 Multi-task Training and Inference","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#33-multi-task-training-and-inference","p":974},{"i":994,"t":"각 task 에 대해, 저자는 new trainable soft prompt m×dm \\times dm×d 를 도입할 것이다. mmm : prompt length ddd : LM dimension attention module 은 두 projection matrices 와 layer norm 으로 구성되어 d×r+r×d+2d=2rd+2dd \\times r + r \\times d + 2d = 2rd + 2dd×r+r×d+2d=2rd+2d parameter 를 생성한다. rrr : projection dimension 이는 NNN 개의 target tasks 에 공유될 수 있으므로 각 task 당 추가 parameter 는 d×m+2rd+2dN=d(m+2(r+1)/N)d \\times m + \\frac{2rd+2d}{N} = d(m + 2(r+1)/N)d×m+N2rd+2d​=d(m+2(r+1)/N) 이다. ATTEMPT 또는 prompt tuning 의 특성은 LM layer 수에 독립적이라는 것이다. Adapter 나 fine-tuning 과 달리 ATTEMPT 는 soft prompt 만 업데이트하고 LM higher layers 는 수정하지 않으므로, 다른 방식과 비교하여 중간 정도의 parameter 증가가 발생한다. T5-XL 백본을 사용할 때, Adapter 와 BitFit 은 6M 및 2M parameters 를 업데이트하는 반면 ATTEMPT 는 각 task 당 172K parameter 만 업데이트 한다. (Fig. 7)","s":"3.4  Parameter Efficiency of ATTEMPT","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#34--parameter-efficiency-of-attempt","p":974},{"i":997,"t":"저자는 source tasks 로 6개의 large-scale datasets 을 사용하고, entailment, paraphrase detection, sentiment analysis, question answering, commonsense reasoning 등을 포함한 21가지 다양한 target tasks 에서 성능 평가 Source tasks​ GLUE, SuperGLUE 및 MRQA 에서 100k annotations 를 가진 데이터셋을 사용하여 source prompt 로 선택: MNLI, QNLI, QQP, SST-2, SQuAD, ReCoRD GLUE and SuperGLUE​ NLU 능력 테스트를 위해 8개 GLUE tasks 및 5개 SuperGLUE tasks 를 target datasets 으로 사용: BoolQ, CB, MultiRC, WiC, WSC, RTE, CoLA, STSB, MRPC, MNLI, QQP, QNLI 및 SST-2 GLUE source task 로 사용된 GLUE 데이터셋 중 4개 (MNLI, QQP, SST-2 및 QNLI)은 이전 PEFT 와의 포괄적인 비교위해 target tasks 로 포함 Question answering​ MRQA 2019 shared task data 를 사용하여 대규모 QA 데이터셋 4개에 대해 테스트 진행: Natural Questions, HotpotQA, NewsQA 및 SearchQA Others​ source tasks 와 관련된 tasks 이지만 도메인이 다른 4가지 다른 데이터셋에 대한 실험을 진행 SciTail 은 과학적 데이터셋, Yelp-2 는 Yelp 리뷰에 대한 감정 분석 데이터셋, WinoGrande 는 다항식 형식의 상식 추론 작업, PAWS-Wiki 는 Wikipedia 기반 Paraphrase detection dataset 이다.","s":"4.1 Source and Target Tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#41-source-and-target-tasks","p":974},{"i":999,"t":"Baselines​ 저자는 ATTEMPT 를 다음과 같이 비교: FT, PT target prompt embeddings 는 무작위로 샘플링된 top vocabularies 에서 초기화됨: SPoT: target prompts 는 다른 task 에서 훈련된 source prompt embedding 으로 초기화 Adapter, AdapterDrop 및 BitFit : GLUE 에서의 여러 SOTA multi-task 방법과 ATTEMPT 를 비교 위 방법들은 여러 task 에서 single model 을 훈련한다: FT-multi-task, Adapter-m, HyperFormer, HyperDecoder 및 AdapterFusion Implementation details​ 저자의 ATTEMPT 와 ATTEMPT-m 은 동일한 6개의 source prompt 를 사용하더라도, ATTEMPT-m 은 multi-task learning 을 통해 여러 target task 에 걸쳐 shared attention 을 훈련하는 반면, ATTEMPT 는 task-specific attention layer 를 별도로 훈련한다. 특별한 명시가 없다면 ATTEMPT 는 모든 baseline 에 대해 기본적으로 T5-base 를 사용한다. 데이터셋에 주석이 달린 public test split 이 없다면, 개발셋을 테스트셋으로 사용하거나 개발셋을 개발 및 테스트셋으로 분할한다. 10k example 보다 적은 데이터셋에는 20 epochs 로 훈련 10k 이상의 중간 규모는 10 epochs 훈련 MRQA 데이터셋은 5 epoch 훈련 Yelp-2 의 최대 훈련 데이터 수는 100k sample 로 제한 효율적인 knowledge transfer 을 위해 G\\mathcal{G}G 가 good prompt composition 을 학습하도록 하기 위해 G\\mathcal{G}G 에 대해 다양한 learning rate 를 도입하고 또한 G\\mathcal{G}G 의 weights 를 source tasks 에서 pretraining 하고 transferring 한다. Prompt initialization​ 각 source prompt 는 top vocabularies 로부터 무작위 샘플링 토큰으로 초기화된다. target task prompt 초기화의 경우, 훈련 안정성을 위해 무작위 vocabularies 샘플링을 하는 대신, non-QA tasks 에선 MNLI source prompt 를, QA 에선 SQuAD source prompt 를 사용한다.","s":"4.2 Baselines and Implementation Details","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#42-baselines-and-implementation-details","p":974},{"i":1002,"t":"Table 1 및 2 에서 GLUE 및 SuperGLUE 의 task 당 성능을 보여준다. Performance vs. efficiency​ Figure a, b 에서 GLUE 및 SuperGLUE 에서의 업데이트된 parameter 수에 비한 성능을 비교한다. ATTEMPT-m 은 PT, SPoT 및 BitFit 을 큰 폭으로 능가했으며, task 당 더 적은 parameter 와 LM 을 동결했음에도 Adapter 도는 FT 와 비슷하다. Table 1 에서 HyperFormer 또는 HyperDecoder 를 포함한 multi-task baseline 의 성능을 능가함을 보여주며, GLUE/SuerGLUE 에서 경쟁력 있는 성능에 더해, Table 2 에선 ATTEMPT-m 이 MRQA 에서 72.8 average F1 으로, parameter 의 두 배 사용하는 BitFit 을 능가 게다가, ATTEMPT-m 은 WinoGrande, Yelp, SciTail 및 PAWS 에서 85.65% 의 average accuracy 를 달성하여 BitFit (84.7%)를 능가하고 parameter 를 업데이트하는 Adapter (86.2%) 와 맞먹는다. ATTEMPT largely improves prompt tuning​ 이전 연구에서 지적한 대로 (Mahabadi et al. Compacter, Lester et al. Prompt Tuning, Sung et al. Lst), prompt tuning 은 hyperparameters 또는 초기화에 민감하며, CoLA (10.2%), BoolQ (61.7%) 또는 WiC (48.9%) 같은 데이터셋에서 성능이 크게 낮다. SPoT 은 다른 관련 task 에서 훈련된 prompt 로 target task prompt 초기화를 개선하지만 여전히 다른 방법보다 낮으며, 미리 source tasks 검색해야 한다. ATTEMPT 는 Table 2 와 같이 작은 데이터셋 (CB, RET) 및 대규모 MRQA 데이터셋에서 이러한 방법을 크게 능가한다.","s":"5.1 Main Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#51-main-results","p":974},{"i":1004,"t":"Table 2 에 나타난 것 처럼, ATTEMPT 는 특히 작은 데이터셋 (RTE, WSC) 에서 경쟁력 있다. Mahabadi et al. Compacter 를 따라 BoolQ, CB 및 SciTail 에서 few-shot 실험을 수행하여 제한된 리소스 환경에서 ATTEMPT 의 효과를 더 검증한다. 여기서 모든 모델 (FT, Adapter, HyperFormer, SPoT 및 ATTEMPT)은 먼저 GLUE 에서 훈련되고 그 다음 k(k=4,16,32)k (k=4, 16, 32)k(k=4,16,32)개만 무작위로 추출된 훈련 데이터를 사용하여 new tasks 에 transferring 한다. Table 3 은 ATTEMPT 가 다른 방법들을 크게 능가하는 것을 보여준다. 이는 few-shot domain adaptation 에서 multiple source tasks 에서의 knowledge 를 non-destructive 하게 transferring 하는 효과적인 방법임을 나타낸다.","s":"5.2 Few-shot Domain Adaptations","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#52-few-shot-domain-adaptations","p":974},{"i":1006,"t":"Power of scale​ 저자는 backbone LM 크기를 증가시키며 ATTEMPT 성능에 끼치는 영향을 경험적 분석을 한다. Fig. 4 는 세 개의 SuperGLUE 데이터셋에서 Adapter, ATTEMPT, PT 및 FT 모델의 LM 크기 성능을 요약 ATTEMPT 는 주로 증가된 크기에서 이득을 봄. 이는 Lester et al. Prompt Tuning 의 발견과 일치하며, prompt tuning 이 backbone LM 이 클 때 효과적임을 보여준다. ATTEMPT 는 T5-base 또는 T5-large 사용 시 FT 모델과 맞먹거나 능가. 이는 prompt tuning 이 backbone LM 이 작은 경우 성능이 저하되는 반면, ATTEMPT 는 그렇지 않다는 점이 다름 ATTEMPT 는 37배 적은 parameter 를 업데이트하면서 T5-3B 에서 Adapter 를 맞먹거나 능가 Ablation studies​ 저자는 ATTEMPT 의 다양한 변형을 비교하여 각 설계 선택의 효과를 확인 no target (a) : pre-trained source prompts 만 interpolating 하여 new task 에 대한 adaptation 타당성을 평가하기 위해, Eq. 4 의 target task prompt 를 초기화하거나 추가하지 않음 no attention (b) : Eq. 3 의 모든 source prompt 에 대한 constant score aj=1/ta_j = 1/taj​=1/t 를 부여하여, attentions 를 없앤다 single prompt (c) : multiple tasks 의 knowledge transferring 효과를 평가하기 위해 single source prompt 만을 사용 SPoT 과 유사하지만 초기화 및 훈련 중엔 source prompt parameter 를 업데이트하는 대신 source prompt 를 유지하고 target task prompt 를 업데이트하며 source 및 target prompt 를 interpolation Table 4 는 모든 components 가 성능 향상에 기여함을 보여준다. (a) trainable target-task-specific prompt (no target) 를 추가하는 것이 모든 데이터셋에서 좋은 성능을 얻는데 중요하며, 특히 BoolQ 및 WinoGrande Constant attention 는 BoolQ 및 NewsQA 에서 큰 성능 감소를 초래. 이는 multiple source prompt 를 간단히 평균하지 않고 학습된 attention 을 갖는 것이 중요함을 나타냄 Single prompt ablation baseline 은 ATTEMPT 의 non-destructive soft prompt transfer 덕분이라 생각되며, ATTEMPT 에 비해 현저한 성능 감소가 있다. 이는 multiple soft prompts 활용으로 여러 다양한 task 의 knowledge transferring 효과를 보여준다. Modularity: effects of variable source prompts​ ATTEMPT 의 묘듈성을 연구하여 source tasks 를 유연하게 추가하거나 제거할 수 있도록 한다. Fig. 5 는 source tasks 를 포함하는 방법이 ATTEMPT 의 최종 성능에 미치는 영향을 보여줌. BoolQ 및 RTE 에 대한 ATTEMPT 의 최종 성능에 source task prompt 를 추가하는 방법을 보여준다. 두 데이터셋 모두에서 더 많은 source task prompt 를 추가하면 성능이 향상되며, RTE 에서는 SQuAD 및 ReCoRD 를 추가할 때 예외가 있다. (full, Fig. 5a) 이는 QA 와 RTE 의 다른 특성 때문에 부정적인 transfer 이 발생할 수 있기 때문일 것으로 예상 이러면 두 QA source prompt 가 BoolQ 에서 도움이 되며, 이는 ATTEMPT 의 모듈성의 효과를 나타냄 이는 강력한 multi-task model 을 구축하기 위해 new task 를 유현하게 제거하거나 추가할 수 있는 효과적인 방법 Interpretability: analysis on attentions​ Fig. 6 은 ATTEMPT 에 의한 source 와 target task 간의 attention weight matrix 를 보여준다. target task prompt 에 대해서는 1 을 추가하기 전의 at+1a_{t+1}at+1​ weight 를 표시 Attention patterns 은 다양한 tasks 에 따라 다르다. 일반적으로 G\\mathcal{G}G 는 관련 source task 에 높은 attention 을 보인다. Yelp →\\rightarrow→ SST-2 PAWS-Wiki →\\rightarrow→ QQP 이는 동일한 task 이지만 서로 다른 domain 이다. QQP 는 여러 task 에서 높은 attention 을 받았으며, 이 tasks 들 간의 유사성이 낮은 paraphrasing (e.g. MultiRC, WNLI) 로 보인다. MNLI 는 RTE 처럼 크게 연관된 target tasks 로부터는 높은 attention 을 받지 않았다. 이는 target task prompt 가 MNLI source prompt 로 초기화됐기 때문일 것이며, ATTEMPT 가 다른 task 에 attention 을 try 할 것이라 가정한다. WingoGrande 또는 SciTail 의 경우, G\\mathcal{G}G 는 target task 내의 embedding 에 큰 attention 을 준다 (target). 이는 두 task 가 크게 다른 task format 또는 input domain 을 가지고 있어, G\\mathcal{G}G 가 source prompt 에 더 많은 attetion 을 주지 않는 것일 수 있다.","s":"5.3 Analyses","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"#53-analyses","p":974},{"i":1008,"t":"저자는 new PEFT 인 ATTEMPT 제시 source tasks 에서 학습된 재사용 가능한 multiple soft prompt 와 new task-specific prompt 를 interpolating 하여 instance-wise prompt 를 생성하는 동안 original LM 은 동결을 유지 large-scale 실험은 ATTEMPT 가 task 성능과 효율성 간의 훌륭한 균형을 달성하여 해석 가능하고 모듈화된 task transfer 을 소개 Limitations​ parameter-efficiency 및 경험적 결과에도 불구하고 몇 가지 제한 사항이 있다: prompt tuning 은 mmm 개 prompt tokens 로 input token length 를 늘리므로 memory 차지 공간 및 계산 비용 증가 Lester et al. Prompt Tuning 은 LLM 을 backbone 모델로 사용하면 prompt length 를 줄일 수 있는 것을 발견 soft prompt 를 통한 multi-task knowledge transfer 에 대해, 저자의 평가는 classification 및 QA 에 중점을 두어, long sequence generation (e.g. summarization)이 필요한 task 는 포함되지 않음 ATTEMPT 를 영어가 아닌 task 에서 테스트하지 않았으며, 비영어 언어에 대한 조사 및 cross language transferring 에 적용을 하지 않음","s":"7. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/ATTEMPT","h":"","p":974},{"i":1010,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2110.07602.pdf","s":"P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1012,"t":"Prompt tuning 은 language model (LM) 을 freezing 한 상태에서 continuous prompt 만 조정하여, training 중 task 당 저장 및 메모리 사용량을 크게 줄이는 것 하지만 Natural Language Understanding (NLU) 엔, 이전 연구에서 prompt tuning 이 일반적인 크기의 pre-trained model 에 대해서는 잘 수행되지 않음 기존의 prompt tuning 방법이 hard sequence labeling task 를 처리할 수 없다는 것 발견 위 사항은 범용성의 부족 저자는 적절하게 최적화된 prompt tuning 이 모델 규모와 NLU 작업의 넓은 범위에 걸쳐 보편적으로 효과적일 수 있는 새로운 경험적인 결과를 제시 fine-tuning 의 성능을 맞추면서도 tuned parameter 가 0.1 ~ 3% 에 불과 P-tuning v2 는 NLU 용으로 optimized 및 adapted Deep Prompt Tuning (Prefix-tuning, soft prompts) 의 구현 P-tuning v2 의 보편성과 간단함을 고려하면, fine-tuning 의 대체제로서 향후 연구를 위한 강력한 baseline 으로 기능 가능","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1014,"t":"Pre-trained LM 은 넓은 범위의 NLU tasks 의 성능을 향상시킨다. 널리 사용되는 방법으로는 다음이 있다. Fine-tuning (FT) : target task 에 대해, model parameter 전체를 update 좋은 성능을 얻는 반면, all parameters 에 대한 gradient 및 optimizer states 를 저장해야 하므로 training 중 메모리 소비가 심하다. inference 중 각 task 에 대한 model parameter 의 copy 를 유지하는 것은, 보통 LM 이 크기 때문에 여간 불편하다 Prompting : pre-trained LM 의 all parameter 를 freezing 하고 natural language prompt 를 사용하여 LM 에 query 하는 방식 sentiment analysis 의 경우, sample (e.g. \"Amazing movie!\") 에 \"[MASK]\" 라는 prompt 를 연결하고 pre-trained LM 에게 masked token 이 \"good\" 과 \"bad\" 인 확률을 예측하도록 요청하여 label 결정 prompting 은 training 을 필요로 하지 않으며 model parameter 의 single copy 만 저장 discrete prompting 은 fine-tuning 과 비교하여 성능이 부적절한 경우가 많음 Prompt tuning (PT) : discrete prompts 만 tuning 하는 아이디어 continuous embedding (prompts) 을 input word embeddings 의 original sequence 에 추가 training 중 continuous prompts 만 updates PT 은 많은 task 에서 prompting 을 개선하지만, 모델 크기가 10B parameter 이하의 경우 FT 를 능가하지 못함 hard sequence labeling task 에서 PT 가 prompting 에 비해 성능이 나쁜 것을 관찰 본 논문의 기여는 적절히 최적화된 PF 이 다양한 모델 규모와 NLU task 범위에서 보편적으로 fine-tuning 과 comparable 하다는 발견 이전 연구와 대조적으로 저자는 NLU 에 대한 PF 의 보편성과 잠재력 발견 새로운 개념은 아니며, 생성 및 지식 탐색을 위해 설계된 Deep Prompt Tuning (Prefix-tuning, soft prompts) 의 최적화 및 적응된 구현 input layer 뿐 아니라 pre-trained LM 의 모든 layer 에 continuous prompt 적용 Deep Prompt Tuning 은 continuous 의 용량을 증가시키고 모델 크기와 hard task 의 간격을 좁히는 데 기여 fine-tuning 과 유사한 성능 보장을 위한 최적화 및 구현의 중요한 세부 사항 제시 실험 결과 P-tuning v2 는 300M 에서 10B parameter 까지 다양한 모델 규모 및 extractive question answering 및 named entity recognition 같은 hard sequence tagging task 을 포함하여 다양한 task 에서 fine-tuning 과 유사한 성능을 보이며, task 당 trainable parameter 의 비율이 0.1% ~ 3% fine-tuning 과 비교하여 training 시간 메모리 비용 및 task 당 저장 비용을 크게 줄임","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1017,"t":"NLU task 를 두 가지로 분류 simple classification tasks label space 기반으로 하는 분류 포함 GLUE 및 SuperGLUE 포함 hard sequence labeling tasks token sequence 기반으로 하는 분류 포함 named entity recognition 및 extractive question answering 포함","s":"NLU Tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#nlu-tasks","p":1009},{"i":1019,"t":"LM M\\mathcal{M}M 의 vocabulary 를 V\\mathcal{V}V LM M\\mathcal{M}M 의 embedding layer eee discrete prompting 의 경우, prompt tokens {\"It\", \"is\", \"[MASK]\"} ⊂V\\subset \\mathcal{V}⊂V 를 영화 리뷰 분류에 사용될 수 있다. 예로, input text x\\text{x}x = \"Amazing movie!\" 가 주어지면, input embedding sequence 는 [e(x),e(\"It\"),e(\"is\"),e(\"[MASK]\")][e(\\text{x}), e(\\text{\"It\"}), e(\\text{\"is\"}), e(\\text{\"[MASK]\"})][e(x),e(\"It\"),e(\"is\"),e(\"[MASK]\")] 로 공식화 [prompt tuning. Lester, P-tuning] 는 frozen pre-trained LM 을 사용하여 NLU 에 대한 natural language prompts 대신 trainable continuous prompts 도입 trainable continuous embeddings [h0,…,hi][h_0, \\dots, h_i][h0​,…,hi​] 가 주어지면, input embedding sequence 는 Figure 2 처럼 [e(x),h0,…,hi,e(\"[MASK]\")][e(\\text{x}), h_0, \\dots, h_i, e(\\text{\"[MASK]\"})][e(x),h0​,…,hi​,e(\"[MASK]\")] 로 쓸 수 있다. Prompt tuning 은 간단한 classification task 에 10B model 을 FT 로 comparable 하게 할 수 있다.","s":"Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#prompt-tuning","p":1009},{"i":1022,"t":"[prompt tuning. Lester, P-tuning] 등 여러 NLP application 에서 효과적임을 입증했지만, 범용성 부족으로 인해 FT 를 대체하기엔 여전히 한계 존재","s":"3.1 Lack of Universality","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#31-lack-of-universality","p":1009},{"i":1024,"t":"[prompt tuning. Lester] 은 10B parameter 이상의 model scale 이 되면 PT 은 FT 와 comparable 하지만 일반적인 medium-sized model (100M ~ 1B) 의 경우에는, PT 는 FT 보다 훨씬 성능이 안좋다.","s":"Lack of universality across scales","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#lack-of-universality-across-scales","p":1009},{"i":1026,"t":"[prompt tuning. Lester, P-tuning] 등은 NLU 벤치마크 중 일부에 우위를 보였지만, sequence tagging task 에 대한 PT 의 효과는 검증되지 않았다. sequence tagging 은 각 input token 에 대한 label sequence 을 예측하는 task 로, 어려우며 동사화와 호환되지 않을 수 있다. 저자의 실험에서 (Section 4.2 및 Table 3 참조) [prompt tuning. Lester, P-tuning] 등은 FT 와 비교하여 전형적인 sequence tagging task 에서 성능이 좋지 않음을 보여준다. 위 어려움을 고려하여 scales 및 NLU task 에 걸쳐 범용적인 솔루션으로 deep prompt tuning 을 채택한 P-tuning v2 제안","s":"Lack of universality across tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#lack-of-universality-across-tasks","p":1009},{"i":1028,"t":"[prompt tuning. Lester, P-tuning] 에서 continuous prompt 는 input embedding sequence 에만 삽입된다. (Figure 2 참조) 이로 인해 두 가지 challenge 발생 sequence length 제안으로 인해 tunable parameters 의 수가 제한됨 input embeddings 는 model prediction 에 상대적으로 간접적인 양향만 끼침 위 과제를 해결하기 위해 P-tuning v2 는 Deep Prompt Tuning 아이디어 채택 Fig 2 에서 설명했듯, 여러 layers 의 prompt 가 prefix tokens 에 추가됨 P-tuning v2 는 더 많은 tunable task-specific parameters (0.01% ~ 3% 까지) 를 가지고 있어 조금 더 per-task capacity 을 허용하면서도 parameter-efficient 를 유지 deeper layers 에 추가된 prompt 는 model prediction 에 더 직접적인 영향을 미침","s":"3.2 Deep Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#32-deep-prompt-tuning","p":1009},{"i":1031,"t":"이전 연구에서 보통 trainable embeddings 를 변환을 위해 MLP 같은 reparameterization encoder 를 활용한다. 하지만 NLU 의 경우, 그 유용성이 task 및 dataset 에 의존적이다. 일부 dataset (e.g. RTE 및 CoNLL04) 의 경우, MLP 가 일관된 성능 향상을 가져오지만, 다른 dataset (e.g. BoolQ 및 CoNLL12) 에서는 결과에 미미하거나 음의 영향을 미친다.","s":"Reparameterization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#reparameterization","p":1009},{"i":1033,"t":"prompt length 는 P-Tuning v2 에서 중요한 역할을 한다. 다양한 NLU task 는 일반적으로 다른 prompt length 로 best 성능을 달성한다. 일반적으로 간단한 classification task 는 더 짧은 prompt (20 미만)을 선호하며, hard sequence labeling task 는 더 긴 prompt (약 100)을 선호한다.","s":"Prompt Length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#prompt-length","p":1009},{"i":1035,"t":"Multi-task learning 은 개별 tasks 에 대한 FT 전에 shared continuous prompts 로 여러 task 를 공동으로 최적화한다. Multi-task 는 P-tuning v2 에 선택적으로 적용 가능하지만 더 나은 최적화를 제공하여 성능을 더 향상시킬 수 있다.","s":"Multi-task Learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#multi-task-learning","p":1009},{"i":1037,"t":"verbalizers 예측을 위해 LM head 를 사용하는 것은 PF 에 중요했지만, full-dataset 설정에선 불필요하며 sequence labeling 과 호환되지 않는다. 대신 P-tuning v2 는 BERT 와 같이 token 위에 randomly-initialized classification head 를 적용한다. P-tuning v2 의 주요 기여를 쉽게 Table 1 에 기재한다.","s":"Classification Head","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#classification-head","p":1009},{"i":1039,"t":"P-tuning v2 효과 검증을 위해 다양한 pre-trained model 과 NLU task 에 대해 광범위한 실험 수행 이 연구는 FT 를 제외한 모든 방법을 frozen language model backbones 에서 진행하며, 이는 [prompt tuning. Lester] 의 설정과 일치하지만 [P-tuning] 의 tuning 설정과는 다르다. task-specific parameters 비율 (0.1%) 은 continuous prompt 의 parameter 와 transformer 의 parameter 를 비교하여 유도 또 주목할 점은 저자의 실험은 모두 few-shot 가 아닌 fully-supervised 설정에서 진행","s":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1041,"t":"P-tuning v2 의 NLU 능력을 테스트하기 위해 SuperGLUE 를 데이터셋에 포함 또한 named entity recognition, extractive Question Answering 및 semantic role labeling 포함","s":"NLU Tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#nlu-tasks-1","p":1009},{"i":1043,"t":"평가를 위해 BERT-large, RoBERTa-large, DeBERTa-xlarge 및 GLM-xlarge/xxlarge 포함 이 모델들은 모두 NLU task 를 위해 설계된 bidirectional model 로, 약 300M ~ 10B 까지 다양한 크기를 커버","s":"Pre-trained Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#pre-trained-models","p":1009},{"i":1045,"t":"multi-task 설정에서는 각 task type 의 데이터셋을 결합 (e.g. combing all training sets of semantic role labeling) 각 데이터셋에 대해 별도의 linear classification 를 사용하면서 continuous prompt 를 공유","s":"Multitask Learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#multitask-learning","p":1009},{"i":1047,"t":"Table 2 는 P-tuning v2 의 model scales 별 성능이다. SuperGLUE 에서 [prompt tuning. Lester, P-tuning] 은 smaller scales 에서 성능이 매우 저조할 수 있다. 반면 P-tuning v2 는 smaller scales 에서 모든 task 에서 FT 성능과 일치한다. larger scales (2B ~ 10B) 에서 GLM 을 사용하는 경우 [prompt tuning. Lester, P-tuning] 와 FT 간의 차이가 점차 좁혀짐 10B scale 에서는 [prompt tuning. Lester] 의 보고와 유사하게, PT 가 FT 와 comparable 즉, P-tuning v2 는 모든 scale 에서 FT 와 비교하여 0.1% 의 task-specific parameters 만 필요로 하면서 항상 FT 와 comparable","s":"4.1 P-tuning v2: Across Scales","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#41-p-tuning-v2-across-scales","p":1009},{"i":1049,"t":"Table 3 에서 우리는 P-tuning v2가 일반적으로 모든 task 에서 FT 와 유사할 수 있음을 관찰 QA task 중에서 가장 어려운 QA task 을 포함하여 [prompt tuning. Lester, P-tuning] 간의 성능 차이가 크다 [prompt tuning. Lester, P-tuning] 의 SQuAD 2.0 에서 일부 일반적이지 않은 결과 관찰. 이는 SQuAD 2.0 에는 unanswerable question 이 포함되어 있어 single-layer prompt tuning 의 최적화에 어려움을 주기 때문 QA 를 제외한 대부분의 task 에서 multi-task learning 은 P-tuning v2 에 대해 상당한 개선을 줌","s":"4.2 P-tuning v2: Across Tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#42-p-tuning-v2-across-tasks","p":1009},{"i":1052,"t":"이전 PT approach 방식에서 Verbalizer with LM head 는 중요한 구성 요소 였다. 하지만 supervised learning 설정에서 P-tuning v2 를 사용한 경우, 약 몇 천개의 parameter 를 가진 linear head 를 tuning 하는 것이 가능하다. 저자는 다른 hyperparameter 를 유지하고 [CLS] label 을 linear head 에서 LM head 로 변경하는 것 외에 간단한 비교를 제안 간단하게 SST-2, RTE 및 BoolQ 에 대해 \"true\" 및 \"false\" 를 사용하고, CB 에 대해 \"true\", \"false\" 및 \"neutral\" 를 사용 결과 Verbalizer 와 [CLS] 의 성능 간에 유의미한 차이가 없었음","s":"Verbalizer with LM head v.s. [CLS] label with linear head","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#verbalizer-with-lm-head-vs-cls-label-with-linear-head","p":1009},{"i":1054,"t":"[prompt tuning. Lester] 와 P-tuning v2 사이의 주요 차이점은 multi-layer continuous prompt 이다. 정확한 영향 검증을 위해 prompt 를 추가할 kkk layers 를 선택하고, 오름 및 내림차순으로 prompt 를 추가하도록 하여 특정 수의 layer 에 대해 실험을 수행하고 나머지 layer 에 대해서는 그대로 둔다. 동일한 parameter 양 (prompt 를 추가할 transformer layer 수)으로 내림차순으로 추가하는 것이 항상 오름차순 보다 나은 결과를 가져옴 RTE 경우엔 layers 17-24 에만 prompt 를 추가하는 것만으로 모든 layer 를 사용하는 것과 거의 유사한 성능 달성","s":"Prompt depth","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"#prompt-depth","p":1009},{"i":1056,"t":"P-tuning v2 제안 상대적으로 제한적인 혁신성을 가지지만, PF 이 모든 규모 (330M ~ 10B parameter)와 task 에 걸쳐 FT 와 comparable 한 새로운 발견에 기여 높은 정확도와 parameter-efficient 를 가지며, P-tuning v2 는 미래 연구의 강력한 baseline 이 될 수 있는 잠재적인 대안","s":"5. Conclusions","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning v2","h":"","p":1009},{"i":1058,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2309.05173v1.pdf","s":"DEPT: Decomposed Prompt Tuning For Parameter-Efficient Fine Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"","p":1057},{"i":1060,"t":"작은 trainable soft (continuous) prompt vectors 를 language models (LM) 의 input 에 붙이는 Prompt Tuning (PT) 는 parameter-efficient fine-tuning (PEFT) 에서 다양한 tasks 및 model 에서 유망한 결과를 보여줌. PT 가 다른 PEFT 보다 뛰어난데, fewer trainable parameter 로 competitive 하며, 모델 사이즈 확장에 따라 parameter 가 극적으로 커지지 않음. 하지만 추가적인 soft prompt tokens 을 도입하면, longer input sequences 가 초래하여 Transformer 의 quadratic complexity 로 인해 training/inference time 및 memory usage 에 상당한 영향이 감 이는 매일 많은 쿼리를 처리하는 Large Language Models (LLMs) 에게 특히 중요한 문제 Transformer's quadratic complexity input sequence length 에 비례하여 계산 비용이 제곱으로 증가하는 것. Transformer 의 self-attention 매커니즘에서, input sequence 의 length 가 N 이라 한다면 모든 단어 쌍에 대한 similarity 를 계산하므로, N x N 크기의 행렬이 생성된다. 이는 이후 연산에도 활용된다. 따라서 input sequence length 가 (N 이) 증가할수록 제곱 비례하여 증가하게 된다. 위 해결하기 위해 저자는 Decomposed Prompt Tuning (DEPT) 를 제안 soft prompt 를 shorter soft prompt 및 pair of low-rank matrices 로 분해 이후 두 가지 다른 learning rate 로 최적화 이를 통해 memory 및 time cost 를 vanilla PT 와 비교하여 20% 이상 절약하면서도 성능이 좋음 23 natural language processing (NLP) 및 vision-language (VL) tasks 에서 SOTA PEFT 및 full fine-tuning (FFT) 를 능가하기도 함 모델 사이즈 증가에 따라 효율성이 더 증가 few-shot learning 에서 parameter-efficient transfer learning (PEFL) 을 유연하게 통합하고 다양한 모델 아키텍처 및 사이즈에 대한 적응성이 좋다.","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"","p":1057},{"i":1062,"t":"FT : NLP tasks 에서 downstream task 의 성능 향상을 제공. 하지만 LMs 의 full parameter 업데이트 및 저장이 필요 (Fig. 1a) Prompt engineering : parameter 를 업데이트하진 않지만 설계가 어렵고 성능의 분산이 높다 (Fig. 1c). PEFT : 적은 수의 parameter 만 학습하면서 FFT 와 맞먹는 성능을 유지하는 것이 목표로, 최근 부상 PT : PEFT 에서 생겨나, trainable continuous prompt vector 를 input 앞에 붙인다 (Fig. 1b). PT 는 fewer trainable parameter 로 경쟁력있는 성능을 유지하고 모델 사이즈 확장에 따라 trainable parameter 가 극단적으로 커지지 않아 다른 PEFT 보다 좋다. PT 가 다양한 task 및 model 에서 좋은 결과를 내지만, 2 가지 한계점이 존재 느린 수렴 및 초기화에 민감 이 이슈를 해결하기 위해 PETL 등장 (Fig. 2a). 다양한 source tasks 에서 soft prompts 를 pre-training 하고 이 prompts 로 초기화 일부 연구에선 source tasks 에서 학습된 prompts 를 multiple target tasks 와 jointly training 으로 성능을 향상 (Multi-task Learning). 하지만 sequence length 증가로 인한 load 계산량 증가는 여전히 문제로 남음 input sequence 의 길이가 증가하여, Transformer 의 quadratic complexity 로 인해 계산량 증가 (i.e. train/inference time 및 memory cost) PETL 은 모델 수렴에 대한 training steps 은 줄일 수 있지만, optimization step 에서는 계산적으로 비용이 많이 든다. 중요한 것은 inference 단계 중, 효율성이 향상되지 않는 다는 것이며, 이는 LLMs 중요하다. 본 논문에서는 Decomposed Prompt Tuning (DEPT) 을 제안한다. trainable soft prompt 를 shorter soft prompt 및 couple of low-rank matrices 로 분해 low-rank matrices 의 곱을 frozen word embeddings 에 element-wise 로 더함 (Fig. 2b) shorter soft prompt 및 updated word embedding matrix 는 두 가지 다른 learning rate 를 사용하여 optimizing - 모델 수렴을 위해 중요한 단계 23 NLP 및 VL tasks 에서 SOTA PEFT 를 능가 (FFT 포함) 경험적으로 다양한 모델 아키텍처 및 사이즈에 훈련 효율성을 크게 향상시키고, vanilla PT 와 비교하여 training time 및 memory costs 를 20% 절약 중요한 점은 모델 사이즈가 증가하면 효율성도 증가. 이는 LLMs 에 이점이고 적합한 점이다. contribution 요약 DePT 는 input sequence length 를 줄이기 위해 soft prompt 를 분해함으로써 PT 의 효율적 한계점 해결. training 및 inference 효율성이 향상하고, time 및 memory costs 20% 이상 절약 23 NLP 및 VL 에서 FFT 를 포함하여 SOTA PEFT 능가. PETL 를 매끄럽게 통합하며 few-shot learning 에서 이점이 됨 모델 사이즈 증가에 따라 효율성도 증가하며 이는 LLMs 에 잘 맞는 특징. 다양한 PEFT (Adapter, LoRA) 와 orthogonal (독립적으로 작동 가능)하며 쉽게 결합될 수 있다.","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"","p":1057},{"i":1065,"t":"L=△{xi,yi}i=1NL \\overset{\\underset{\\mathrm{\\triangle}}{}}{=} \\{ x_i, y_i \\}^N_{i=1}L=△​{xi​,yi​}i=1N​ N : target task T\\mathcal{T}T 의 labelled training data backbone model Θ\\ThetaΘ 이 있을 때, 각 input text xix_ixi​ 는 word embeddings Wi∈Rs×dW_i \\in \\mathbb{R}^{s \\times d}Wi​∈Rs×d 와 관련된 sequence 와 매핑됨 PT 는 trainable prompt matrix P∈Rl×dP \\in \\mathbb{R}^{l \\times d}P∈Rl×d 를 frozen word embedding matrix WiW_iWi​ 앞에 붙임 lll : virtual tokens 수에 대한 hyper-parameter soft prompt PPP 는 랜덤 또는 top vocabularies 에서 word embeddings 를 샘플링하여 초기화 model 의 input 은 결합된 matrix 인 [P;Wi]∈R(l+1s)×d[P;W_i] \\in \\mathbb{R}^{(l + 1s) \\times d}[P;Wi​]∈R(l+1s)×d 가 됨 targeted loss function 은 다음과 같다. LPT=−∑ilog⁡P(yi∣[P,Wi];Θ),\\begin{equation} \\mathcal{L}_{PT} = - \\sum_i \\log P (y_i | [P, W_i]; \\Theta), \\end{equation}LPT​=−i∑​logP(yi​∣[P,Wi​];Θ),​​ 여기서 loss function 은 soft prompt matrix PPP 와 관련하여만 optimizing","s":"2.1 Background: Prompt Tuning (PT)","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#21-background-prompt-tuning-pt","p":1057},{"i":1067,"t":"The decomposition of the soft prompt​ Fig. 2b 와 같이, trainable prompt matrix P∈Rl×dP \\in \\mathbb{R}^{l \\times d}P∈Rl×d 를 two components 로 분해 shorter trainable prompt matrix Ps∈Rm×d;P_s \\in \\mathbb{R}^{m \\times d};Ps​∈Rm×d; smaller trainable prompt matrix 는 word embedding matrix 앞에 붙임 pair of low-rank matrices, A∈Rs×rA \\in \\mathbb{R}^{s \\times r}A∈Rs×r 및 B∈Rr×dB \\in \\mathbb{R}^{r \\times d}B∈Rr×d rank r≪min⁡(s,d)r \\ll \\min(s,d)r≪min(s,d) low-rank matrices 의 곱은 corrdinate-wise sum 으로 word embedding 업데이트 Wi′=Wi+△Wi=Wi+BA∈Rs×d,\\begin{equation} W'_i = W_i + \\triangle W_i = W_i + BA \\in \\mathbb{R}^{s \\times d}, \\end{equation}Wi′​=Wi​+△Wi​=Wi​+BA∈Rs×d,​​ WiW_iWi​ : frozen AAA 및 BBB : trainable. LoRA 설정에 따라, random Gaussian 초기화 사용 training 시작 시 △W=BA\\triangle W = BA△W=BA 는 0 loss function 은 다음과 같다. LDePT=−∑ilog⁡P(yi∣[Ps,Wi′];Θ)\\begin{equation} \\mathcal{L}_{DePT} = - \\sum_i \\log P(y_i | [P_s, W'_i]; \\Theta) \\end{equation}LDePT​=−i∑​logP(yi​∣[Ps​,Wi′​];Θ)​​ 저자는 실험에서, trainable parameters 사이즈를 유지하기 위해 l×d=m×d+(s+d)×rl \\times d = m \\times d + (s + d) \\times rl×d=m×d+(s+d)×r 식을 만족하는 mmm 및 rrr 을 선택한다. 따라서 mmm 은 r>0r > 0r>0 일 때 상상 lll 보다 작다. 이 설계는 memory 효율성을 향상시키고 shorter input sequence (i.e. m+s<l+sm + s < l + sm+s<l+s) 가 Transformer 의 quadratic complexity 로 인한 계산량을 줄여주듯이, vanilla PT 와 비교하여 계산량을 줄여준다. Two rates of learning​ shorter trainable prompt matrix PsP_sPs​ 를 learning rate α1\\alpha_1α1​ 으로, pair of low-rank matrices AAA 및 BBB 는 learning rate α2\\alpha_2α2​ 로 훈련시킴. α1\\alpha_1α1​ 은 α2\\alpha_2α2​ 보다 상당히 크게 한다. 위 선택은 경험적으로 실험하여 검증한다.","s":"2.2 Our Approach: Decomposed Prompt Tuning (DePT)","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#22-our-approach-decomposed-prompt-tuning-dept","p":1057},{"i":1070,"t":"Datasets and tasks​ DePT 를 21 NLP 및 2 NL tasks 에 평가 for NLP tasks, 다양한 source datasets 을 사용 GLUE MNLI QQP QNLI SST-2 STS-B MRPC RTE CoLA SuperGLUE MultiRC BoolQ WiC WSC CB MRQA 2019 Shared Task Natural Questions HotpotQA SearchQA NewsQA others WinoGrande Yelp-2 SciTail PAWS-Wiki for VL tasks, visual question-answering task VQA 및 image caption generation task MSCOCO 사용 Baselines​ 다양한 baselines 와 비교 fine-tuning FT : 각 downstream task 에 adaption 하기 위해 all parameter tuning vanilla PT : target prompt vectors 를 top vocabularies 에서 랜덤 샘플링하여 초기화하며, 추가적인 transfer 및 multi-task learning 사용 SPoT, ATTEMPT, APT SOTA PEFT : Adapters AdapterDrop BitFit HyperFormer HyperDecoder P-tuning LoRA LST multi-task learning 공평한 비교를 위해 published papers 의 metrics 및 T-5 BASE 사용 Implementation details​ 220M parameters 의 T5-BASE model 을 주로 사용 모든 tasks 에서 virtual tokens lll 을 100 으로 설정하고 trainable parameter 수를 유지하기 위해 DePT 의 hyper-parameters 조절 예로, vanilla PT 는 trainable parameters l×dl \\times dl×d 포함. hidden size ddd : 768 DePT 은 virtual tokens mmm 을 40 으로, low-rank matrices rrr 을 45 로 설정. 결과적으로, trainable parameters m×d+(s+d)×rm \\times d + (s + d) \\times rm×d+(s+d)×r 이 되며, 이는 전체적으로 76,800 trainable parameters 가 된다. VL tasks 의 경우, CLIP (frozen) 및 T5-BASE 를 결합한 CLIP-5 아키텍처 활용 이전 연구 (LST: Ladder side-tuning for parameter and memory efficient transfer learning.) 를 따라, CLIP 의 visual representation 과 T5-BASE 의 text embedding 을 붙임 trainable visual layer 은 text embedding 과 동일한 차원의 visual representation 을 align 하기 위해 CLIP 및 T5 사이에 사용된다. 확장하여 T5-SMALL (60M), T5-LARGE (770M), GPT2-SMALL (100M), GPT2-MEDIUM (345M) 및 GPT2-LARGE (774M) 을 포함하여 평가 few-shot 실험에선, kkk 개 examples 를 training set 에서 3번 무작위로 선택하고 kkk-shot 에 대해 mean 및 standard deviations 보고. PETL 의 이전 연구를 따라, MNLI, QQP, SST-2, SQUAD 및 ReCoRD 를 source tasks 로 사용. soft prompt 및 low-rank matrix pairs 는 source tasks 중 하나로부터 soft prompts 로 초기화","s":"3.1 Experimental Setup","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#31-experimental-setup","p":1057},{"i":1073,"t":"DePT 는 GLUE 및 SuperGLUE 에서 fewer trainable parameters 를 사용하면서도 Adapter, LoRA 및 LST 같은 SOTA PEFT 를 능가, 또한 FFT 도 능가 vanilla PT 및 추가 transfer learning 과 multi-task learning 을 추가 도입한 PT 도 능가 위 결과로 less training time 를 이루고 memory resources 를 줄여줌 DEPT 는 위의 PETL 와 orthogonal 한 것도 주목할만한 가치가 있다.","s":"3.2.1 Performance on GLUE and SuperGLUE benchmarks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#321-performance-on-glue-and-superglue-benchmarks","p":1057},{"i":1075,"t":"MRQA 2019 Shared Task 에서 PEFT 는 vanilla PT 및 additional transfer 과 multi-task learning 을 활용한 PT 를 추가적인 trainable parameter 없이 능가 PT 는 능가하지만, FFT baselines 과 비교하면 격차가 여전히 남아 있다.","s":"3.2.2 Performance on MRQA 2019 Shared Task and other NLP datasets","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#322-performance-on-mrqa-2019-shared-task-and-other-nlp-datasets","p":1057},{"i":1077,"t":"두 가지 VL tasks (VQA 및 MS COCO) 에서 DePT 는 다른 SOTA PEFT 성능을 능가 VQA dataset 에서 P-tuning 및 BitFit 같은 방법은 능가하지만, FFT 성능은 능가하지 못함","s":"3.3.3 Performance on Vision-Language tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#333-performance-on-vision-language-tasks","p":1057},{"i":1080,"t":"GLUE 의 8 tasks 에서 encoder-decoder (T5) 및 decoder-only (GPT-2) 의 세 가지 모델 사이즈로 soft prompt length mmm 대비 training 및 memory costs 평균을 비교 이 실험으로 soft prompt (l=200l = 200l=200) 을 small soft prompt 및 low-rank matrics 로 분해하는 것으로 시간 효율성을 향상시키고 memory resource 를 줄이면서도 경쟁력있는 성능을 만들었다. 특히, T5 model 에서 DePT 로 soft prompt length 20 을 사용하여 GLUE 에서 vanilla PT 평균 성능 능가 이 실험으로 다양한 모델 아키텍처 (특히 GPT) 와 적용성 및 적응성이 좋다. soft prompt (m=0m = 0m=0) 가 제거되고 T5/GPT-2 에 상관없이 pair of low-rank matrices 에 의존 할 때, 성능이 떨어지는 것에 주목할 만 하다.","s":"3.3.1 DePT improves and memory efficiency up to more than 20%","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#331-dept-improves-and-memory-efficiency-up-to-more-than-20","p":1057},{"i":1082,"t":"single PTX 3090 GPU 를 사용하여 GLUE 로 inference speed 측정하였으며 Huggingface Trainer Class 를 사용하여 계산 모델 크기 증가에 따라 inference samples 초당 평가 수의 상대적인 향상을 관찰 예로, T5-SMALL 에서 vanilla PT 는 초당 167.3개, DePT (m=20m = 20m=20) 은 178.3 샘플 평가. 추론 속도가 약 6.5% 향상 T5-LARGE 에서는 vanilla PT 는 초당 21.0 개, DePT (m=20m = 20m=20) 은 24.8 샘플 평가. 추론 속도 약 18.1% 상승 위 특징으로 DePT 가 특히 LLMs 에 유익하고 적합한 것을 나타냄","s":"3.3.2 DePT grows more efficient as the model size increases","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#332-dept-grows-more-efficient-as-the-model-size-increases","p":1057},{"i":1084,"t":"Few-shot Learning​ vanilla PT 는 few-shot tasks 에서 자주 저조했으며, DePT 도 동일 이 이슈를 피하기 위해, 저자는 PETL 연구에서 영감을 받은 transfer learning 을 채택 (Fig. 1a) few-shot tasks 에서, 저자는 target task 진행 전에 soft prompt 및 low-rank pair 를 source tasks 에 pre-training 이전 연구 (Karimi Mahabadi et al., 2021; Asai et al., 2022; Wang et al., 2023b; Shi & Lipani, 2023a) 를 따라, 저자는 14 NLP tasks few-shot 실험에서 DePT 의 효과성 평가 위 실험에서 두 가지 주요 관점 관찰 DePT 는 PETL approaches 를 자연스럽게 통합 few-shot task 에서 SOTA PEFT 보다 좋은 성능 full fine-tuning (FT), Adapters (AD), vanilla PT (PT), SPoT (ST), HyperFormer (HF), ATTEMPT (AT), MPT 를 포함한 PEFT 와 DePT 를 BoolQ, CB, SciTail 에서 효과성을 평가 Table 5 는 GLUE 및 SuperGLUE 에서 DePT 와 vanilla PT, MPT 의 성능 표시 vanilla PT 는 few-shot tasks 에서 어려움을 겪는 것을 보여주며, 이는 이전 연구에서 PT few-shot learning 에서 PETL 의 중요성을 시사 반대로 DePT 의 성능은 PETL framework 에서 큰 이득을 보고 있음 (Fig. 2a) 게다가, transfer learning 을 이용한 DePT 는 14 NLP tasks 에서 MPT 와 유사한 성능을 보이며, 다른 PEFT 성능도 능가하며 효과성 입증 The importance of different learning rate​ Fig. 5 는 세 가지 다른 learning rate 설정 결과를 보여준다. singular learning rate 3e−13e-13e−1 singular learning rate 5e−45e-45e−4 mixed learning rate; soft prompt - larger rate; low-rank pair - lower rate; 위 결과는 DePT 가 두 가지 다른 learning rate training 의 중요성을 보여준다.","s":"3.4 Further Analysis","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"#34-further-analysis","p":1057},{"i":1087,"t":"Conclusion​ DePT 로 vanilla PT (20% up) 및 SOTA PEFT 보다 효율성을 향상시키고 time 및 memory 를 절약 DePT 는 모델 사이즈 증가에 따라 효율성도 증가 Limitations and Broader Impact​ 추가 hyper-parameters (e.g. learning rate of low-rank) 의 도입이 주요 한계점 model training 의 hyperparameter optimization 단계 중 약간의 추가 계산 부하가 있을 수 있다. 하지만 model training 은 일회성이며, model inference 은 그렇지 않다. 이점에서 효율성 장점이 특히 중요해지며, LMs 에 대한 prompting 기술 활용에 초점을 둔다.","s":"5. Epilogue","u":"/docs/Paper/NLP/PEFT/Soft Prompt/DEPT","h":"","p":1057},{"i":1089,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2103.10385.pdf","s":"GPT Understands, Too","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1091,"t":"전통적인 fine-tuning 으로는 GPT model 의 natural language understanding (NLU) task 에 좋은 결과를 달성하지 못하는 반면, 저자는 trainable continuous prompt embeddings 를 사용한 P-tuning 을 통해 나은 결과를 얻을 수 있었다. knowledge probing (LAMA) 벤치마크에서 최고인 GPT 는 테스트할 때 additional text 없이 64% (P@1) 복구 (이전 best 의 +20%) SuperGlue 벤치마크에서 GPT 모델은 supervised learning 에서, 유사한 크기인 BERT 와 비슷하거나 더 나은 성능 달성 P-tuning 이 prompt engineering 의 필요성을 줄여, BERT 모델의 성능도 향상시킨다는 것 결과적으로 P-tuning 이 few-shot SuperGlue 벤치마크에서 SOTA 능가","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1093,"t":"이전 연구들은 pre-training 과정에 text 표현 뿐 아니라 문법, 구문, 상식 및 세계 지식 등의 요소를 학습한다는 증거를 제시하기도 한다. training objectives 에 따라 pre-trained language model (LM) 은 세 가지 범주로 나눌 수 있다. unidirectional language models for natural language generation (NLG) (e.g. GPT) bidirectional language models for natural language understanding (NLU) (e.g. BERT) hybrid language models for combining the first two paradigms (e.g. XLNet, UniLM) GPT 스타일의 모델이 fine-tuning 으로 NLU task 에 대한 성능이 좋지않아, language undetstanding 에 적합하지 않다고 가정해왔다. 하지만 manual prompt 사용으로 흥미로운 성능을 보여, large unidirectional model 와 manual prompt 가 NLU 에 적합하게 작용할 수 있음을 시사 그러나 best-performing prompt 란 사막에서 바늘찾기 이며, 현실적으로 불가능한 매우 큰 검증 데이터셋이 필요하다. 많은 케이스에서도, prompt engineering 은 테스트셋에 overfitting 하며, 큰 성능 하락을 일으키는 prompt 를 만들 가능성도 있다. 이러한 연구들을 통해 저자는 discrete prompts 를 자동으로 검색하고, 효과를 입증하는데 초점을 둔다. 하지만 neural networks 는 continuous 하므로 discrete prompts 는 sub-optimal 일 수 있다. 본 연구는 P-tuning 으로 GPT 와 NLU 간의 간격을 좁히기 위해 continuous space 에서 prompt 를 자동으로 검색하는 방법을 연구 few continuous free parameters 를 활용하여 pre-trained LM 에 입력으로 제공되는 prompt 역할 continuous prompt 를 discrete prompt searching 대신 gradient descent 를 활용하여 최적화 간단한 P-tuning 으로 GPT 에 상당한 개선을 가져왔다. 저자는 P-tuning 기반 GPT 을 두 가지 NLU 벤치마크에 검토 LAMA knowledge probing 64.2% 달성하여 이전 SOPTA prompt searching 방법인 45.2% 를 크게 능가 SuperGLUE few-shot 및 fine-tuning 을 함께 진행 동일한 규모의 BERT 와 유사한 성능이거나 일부 데이터셋에선 능가 BERT 스타일 모델에도 P-tuning 이 이점을 얻을 수 있음을 관찰 ALBERT 의 P-tuning 은 성능 크게 능가하고 few-shot SuperGLUE 에서 SOTA 위 방법은 GPT 는 언어를 이해하지 못한다는 고정관념을 부쉈다. P-tuning 은 pre-trained LM 을 downstream task 에 최상의 성능을 위해 fine-tuning 에도 작동한다. 본 논문의 기여는 다음과 같다. P-tuning 으로 GPT 의 NLU 가 BERT 와 comparable (때론 더 나음)하여, pre-trained LM 의 성능을 향상 시킴 P-tuning 은 few-shot 및 fine-tuning 설정에서도 GPT 및 BERT 를 모두 개선 LAMA knowledge probing 및 few-shot SuperGLUE 에서 SOTA 능가 LM 이 pre-training 중 생각보다 더 많은 지식을 습득했음을 시사","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1095,"t":"GPT-3 및 DALL-E 는 LLM 이 만병통치약임을 시사하지만, transferability 가 낮다는 것. downstream task 의 fine-tuning 은 trillion-scale model 에는 거의 작동하지 않는다. many-shot fine-tuning 에서도 빠르게 fine-tuning sample 을 메모리에 저장하기엔 너무 크다. 대안으로 GPT-3 와 DALL-E 는 downstream 을 위해 model fine-tuning 을 위해 manual prompt 를 활용하는 것이 보고 되었다. 그러나 manual prompt searching 은 큰 검증셋에 지나치게 의존하며 성능도 불안정하다. 최근 discrete prompts searching 을 자동으로 하는 것에 집중하며, training corpus 를 mining gradient searching separate model 저자의 목적은 미분하여 최적화될 수 있는 continuous prompt 를 찾는 것","s":"2. Motivation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1097,"t":"discrete prompt 와 유사하게 P-tuning 은 input 에 비침범적인 (noninvasive) 수정만 적용 pre-trained input embeddings 을 differential (미분계수) output embeddings 로 대체","s":"3. Method: P-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1099,"t":"pre-trained LM M\\mathcal{M}M 이 주어졌을 경우 discrete input token 의 sequence x1:n={x0,x1,…,xn}\\text{x}_{1:n} = \\{ x_0, x_1, \\dots, x_n \\}x1:n​={x0​,x1​,…,xn​} pre-trained embedding layer e∈Me \\in \\mathcal{M}e∈M 에 의해 input embeddings {e(x0),e(x1),…,e(xn)}\\{ e(x_0), e(x_1), \\dots, e(x_n) \\}{e(x0​),e(x1​),…,e(xn​)} 으로 매핑 특정 시나리오에선 context x\\text{x}x 에 대해, downstream 처리를 위해 target token y\\text{y}y 의 output embeddings 사용이 일반적 pre-training 에선, x\\text{x}x 는 unmasked tokens 을 나타내며, y\\text{y}y 는 [MASK] 를 나타냄 sentence classification 에선, x\\text{x}x 는 sentence token 을 나타내며, y\\text{y}y 는 [CLS] 를 나타냄 prompt p\\bold{p}p 의 역할은 context x\\text{x}x, target y\\text{y}y 및 template TTT 로 구성하는 것 예로, 국가 수도를 예측하는 작업 (LAMA-TREx P36) template \"The capital of Britain is [MASK].\" prompt \"The capital of ... is ... .\" context \"Britain\" target \"[MASK]\" prompt 는 context 또는 target 로 삽입할 수 있는 유연성을 지닐 수 있다. LM M\\mathcal{M}M 의 vocabulary 를 V\\mathcal{V}V, template TTT 의 ithi^{th}ith prompt token 을 [Pi][\\text{P}_i][Pi​] 라 하자. 간단하게, T={[P0:i],x,[Pi+1:m],y}T = \\{ [\\text{P}_{0:i}], \\text{x}, [\\text{P}_{i+1:m}],\\text{y} \\}T={[P0:i​],x,[Pi+1:m​],y} 가 주어졌다고 하자. traditional discrete prompts 와 비교하며, 이는 [Pi]∈V[\\text{P}_i] \\in \\mathcal{V}[Pi​]∈V 를 만족시키고 TTT 를 다음과 같이 매핑 {e([P0:i]),e(x),e([Pi+1:m]),e(y)}\\begin{equation} \\{ e([\\text{P}_{0:i}]), e(\\text{x}), e([\\text{P}_{i+1:m}]), e(\\text{y}) \\} \\end{equation}{e([P0:i​]),e(x),e([Pi+1:m​]),e(y)}​​ 반면, P-tuning 은 [Pi][\\text{P}_i][Pi​] 를 pseudo tokens 로 간주하고 template 를 다음과 같이 매핑 {h0,…hi,e(x),hi+1,…hm,e(y)}\\begin{equation} \\{ h_0, \\dots h_i, e(\\text{x}), h_{i+1}, \\dots h_m, e(\\text{y}) \\} \\end{equation}{h0​,…hi​,e(x),hi+1​,…hm​,e(y)}​​ hi(0≤i≤m)h_i (0 \\leq i \\leq m)hi​(0≤i≤m) : trainable embedding tensors 이를 통해 M\\mathcal{M}M 의 original vocabulary V\\mathcal{V}V 를 넘어 더 나은 continuous prompts 를 찾을 수 있게 됨 downstream loss function L\\mathcal{L}L 를 사용하여 continuous prompt hi(0≤i≤m)h_i (0 \\leq i \\leq m)hi​(0≤i≤m) 를 미분으로 최적화할 수 있다. h^0:m=argmin⁡h L(M(x,y))\\begin{equation} \\hat{h}_{0:m} = \\underset{h}{\\text{arg} \\min}\\ \\mathcal{L} (\\mathcal{M}(\\text{x}, \\text{y})) \\end{equation}h^0:m​=hargmin​ L(M(x,y))​​","s":"3.1 Architecture","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#31-architecture","p":1088},{"i":1101,"t":"continuous prompts 의 training idea 는 간단하지만 실제로 두 가지 최적화 문제를 직면 Discreteness M\\mathcal{M}M 의 original word embedding eee 은 pre-training 후 높은 discrete 성질을 가짐 hhh 가 random distribution 된 후 stochastic gradient descent (SGD) 로 최적화될 경우, small neighborhood 의 parameter 만 변경될 수 있음 위 optimizer 는 쉽게 local minima 에 빠질 수 있음 Association prompt embeddings hih_ihi​ 의 값이 독립적이 아닌 서로 종속되어야 한다는 것. prompt embeddings 를 서로 연관시키기 위한 매커니즘 필요 위 어려움을 대응하여 P-tuning 에선 hih_ihi​ 를 서로 종속적인 시퀀스로 모델링 하는 것을 제안 이를 위해 매우 가벼운 신경망으로 구성된 prompt encoder 를 사용하여 discreteness 및 association 해결 양방향 LSTM 을 선택하고 ReLU activated two-layer MLP 를 사용하여 discreteness 촉진 LM M\\mathcal{M}M 에 대한 실제 input embeddings hi′h_i'hi′​ 는 다음과 같이 유도 hi=MLP([h→i : h←i])=MLP([LSTM(h0:i) : LSTM(hi:m)])\\begin{equation} \\begin{align*} h_i & = \\text{MLP}([\\overrightarrow{h}_i \\ : \\ \\overleftarrow{h}_i]) \\\\ & = \\text{MLP}([\\text{LSTM}(h_{0:i}) \\ : \\ \\text{LSTM}(h_{i:m})]) \\end{align*} \\end{equation}hi​​=MLP([hi​ : hi​])=MLP([LSTM(h0:i​) : LSTM(hi:m​)])​​​ LSTM head 사용은 continuous prompts 의 training 에 일부 파라미터를 추가하지만, LSTM head 는 pre-training 보다 훨씬 작으며, inference 에서는 output embedding hhh 만 필요하므로 LSTM head 를 폐기할 수 있다. 또한 몇 개의 anchor tokens 추가하는 것이 SuperGLUE 의 일부 NLU task 에 도움되는 것을 발견 RTE task 의 경우, prompt template \"[PRE][prompt tokens][HYP]?[prompt tokens][MASK]\" 내의 \"?\" token 은 anchor token 으로 특별히 추가되어 성능에 큰 영향을 미친다. 이러한 anchor tokens 는 각 구성 요소를 나타내며, 이 경우 \"?\" 는 \"[HYP]\" 가 의문문 부분으로 작용","s":"3.2 Optimization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#32-optimization","p":1088},{"i":1103,"t":"NLU 벤치마크인 LAMA knowledge probing 및 SuperGLUE 에 포괄적으로 실험 결과, P-tuning 이 GPT 의 NLU 능력을 향상시키고 BERT 스타일 모델에도 이점이 있음을 보여줌","s":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1105,"t":"knowledge probing 또는 fact retrieval 은 LM 이 pre-training 에서 얼마나 세계 지식을 습득했는지 평가 LAMA dataset 은 knoledge base 에서 선택한 triple 에서 생성된 cloze test 로 평가 예로 triple 을 \"Dante was born in [MASK].\" 라는 handcraft prompt 로 변환한 다음 LM 에게 추론하도록 요청 pre-trained model 의 parameter 는 고정되어 있으므로, pre-training 에서 얻은 지식으로 평가","s":"4.1 Knowledge Probing","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#41-knowledge-probing","p":1088},{"i":1107,"t":"Datasets​ LAMA 의 모든 answers 를 single-token 으로 강제함 41개의 Wikidata relations 및 34,039개의 texting triples (즉, LAMA-34K) 로 구성된 original LAMA-TREx dataset 채택 (모두 BERT vocabulary 에 포함) GPT 와 BERT 의 vocabulary 가 서로 다르므로 교집합을 포함하는 다른 버전의 LAMA 를 설정 이 subset 은 약 29,000 tasting triples 를 추가하고, 이를 LAMA-29K 라고 명명 training 에 대해선 all prompt searching approaches 가 prompt 를 훈련하거나 찾기 위해 일부 추가 데이터가 필요. 저자는 AutoPrompt 설정을 따르며, original TRE-x dataset 에 training set 구축. 이 training set 은 test set 과 유사하지만 약간 다른 answer distribution 을 가지고 있다. Evaluation​ 원래, LAMA 는 Table 1 처럼 각 관계에 대한 handcraft prompt 를 제공했으며 이러한 prompt 는 효과적이지만 sub-optimal 이다. bidirectional masked language models 의 경우, \"[X]\" 를 subject entity 로, \"[Y]\" 를 [MASK] token 으로 데체 GPT 같은 unidirectional language model 의 경우, LAMA 의 원래 설정에 따라 Transformer-XL 에서 target position 앞의 network output 을 사용 P-tuning 진행 시, bidirectional models 에는 (3, sub, 3, obj, 3) template 을 사용 unidirectional models 에는 (3, sub, 3, obj) 을 사용 숫자는 prompt tokens 수를 나타낸다. 이 knowledge probing task 에서는 어떠한 anchor token 도 사용하지 않으며, training 중 learning rate 1e-5 및 Adam optimizer 사용","s":"4.1.1 Datasets And Formulation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#411-datasets-and-formulation","p":1088},{"i":1109,"t":"General performance​ P-tuning 은 LAMA-34K 에서 43.3% 를 50.6% 로 끌어 올림 LAMA-29K 에서 45.2% 를 64.2% 까지 향상 AutoPrompt 및 LPAQA 같은 discrete prompt searching approach 보다 뛰어남 위 결과는 prompt 를 개선하고 fine-tuning 없이 단순히 더 나은 prompt 를 찾음으로써, LM 이 생각보다 훨씬 더 많은 knowledge 를 capture 했다는 것을 시사 P-tuning v.s. Fine-tuning​ 저자는 pre-training 중 LM 이 얼마나 많은 지식을 습득하는지 평가 주요 연구는 GPT 같은 unidirectional model 에서 P-tuning 과 fine-tuning 을 비교하는 것 하지만 다음 질문이 발생할 수 있다. \"unidirectional 및 bidirectional model 은 P-tuning 에서 유사한 개선을 얻을까?\" 기존의 tuning 방법을 포괄적으로 검토하고자 다음 approach 포함 Manual Prompt (MP) : LAMA 의 original manual prompt 사용 Fine-tuning (FT) : subject 를 제시하고 object 를 예측하기 위해 모델을 FT Manual Prompt with Fine-tuning (MP + FT) : manual prompt 로 LM 을 FT P-tuning : continuous prompt 를 사용하면서 LM parameter freezing LAMA-29K 에서 네 가지 전략을 구현 (Table 2 오른쪽) 놀라운 점은 FT 가 LM 의 all parameter 를 tuning 하지만, P-tuning 은 그렇지 않으니 더 강력해야 한다는 것. 하지만 P-tuning 이 FT 기반 방법과 비슷하거나 더 나은 결과 knowledge probing 에선 reasoning 보다는 hard-coding 이 되야하는 경우가 많아, FT 는 치명적인 망각을 초래할 수 있음 반면 P-tuning 은 pre-trained LM's parameter 를 변경하지 않고, continuous prompt 로 저장된 knowledge 활용 BERT 와 GPT 의 P-tuning 에 대한 개선 사항 사이에 명확한 격차가 있다는 놀라운 점 high-quality MP + FT 를 사용한 fine-tuning 의 효과가 관찰되지만, GPT 는 BERT 만큼 MP+FT 에서 이점을 얻지 못함 P-tuning 은 unidirectional LM 과 더 어울린다는 것을 시사 11B 의 큰 모델인 MegatronLM2 의 경우, FT 가 거의 작동하지 않는 반면, P-tuning 은 여전히 적용 가능하여 SOTA 달성","s":"4.1.2 Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#412-results","p":1088},{"i":1111,"t":"P-tuning 평가를 위해 SuperGLUE 에서 실험 수행 SuperGLUE 는 총 8개의 NLU task 를 지님 ReCoRD 는 prompt 가 없으므로 P-tuning 이 불가능하여 포함하지 않아 7개의 task 를 다룸 question answering MultiRC textual entailment RTE co-reference resolution causal reasoning word sense disambiguation 실험 설정에서 fully-supervised 및 few-shot 모두 고려 fully-supervised 에선 전체 훈련셋 (Dtrain\\mathcal{D}_{train}Dtrain​) 사용하고 모델 선택 및 hyperparameter tuning 을 위해 개발셋 (Ddev\\mathcal{D}_{dev}Ddev​) 사용 few-shot 에선 SuperGLUE 의 few-shot 버전 (FewGlue) 채택 SuperGLUE 의 subset, 각 task 는 32개의 훈련 데이터 (Dtrain32\\mathcal{D}_{train32}Dtrain32​) 및 크기가 400~20000 까지 다양한 unlabeled 구성 (Dunlabeled\\mathcal{D}_{unlabeled}Dunlabeled​) 이전 연구에서 개발셋이 없고 고정된 hyperparameter 를 채택하여 테스트셋에 과적합되었음. 저자는 적절한 few-dev set (Ddev32\\mathcal{D}_{dev32}Ddev32​) 구성. 더 큰 개발셋은 추가적인 이점을 제공한다는 것이 입증되었기 때문 Ddev32\\mathcal{D}_{dev32}Ddev32​ 는 사용되지 않은 훈련셋에서 random sample 로 선택하여 구성되며, few-training set 의 크기보다 크지 않도록 제한 [Small language models are also few-shot learners] 와 동일한 matric 사용 저자는 NLU task 를 blank filling task 로 재구성. [Small language models are also few-shot learners] 와 달리 P-tuning 은 initial prompt embeddings 을 패턴 내의 다른 position 에 배치한 후 pre-trained model 과 함께 prompt embedding 을 FT fully-supervised 설정 linearly decayed learning rate 를 사용하는 AdamW optimizer 사용 hyperparameter 에 대해 greedy search 를 수행하고 Ddev\\mathcal{D}_{dev}Ddev​ 또는 Ddev32\\mathcal{D}_{dev32}Ddev32​ 에서 최상의 조합 선택 구체적으로 learning rate 1e-5, 2e-5, 3e-5 선택하고 batch size 16, 32 small datasets 의 경우 pre-trained model 을 20 epoch fine-tuning larger datasets 의 경우, 모델의 빠른 수렴을 위해 training epoch 을 10 으로 줄임. overfitting 피하기 위해 early stop 사용 few-shot learning 의 경우 동일한 hyperparameter prompt embeddings 의 FT 에 더 많은 단계가 필요하여 3500 으로 확장 P-tuning 은 bidirectional 및 unidirectional model 에 사용 가능 공정한 비교를 위해 연산량이 유사한 BERT-base 3 과 GPT2-base, BERT-large 와 GPT2-medium 비교 few-shot learning 을 위해 albert-xxlarge-v2 모델도 실험 각 사전 훈련 모델에 대한 결과로 표준 FT (즉, [CLS] 임베딩을 사용한 분류), PET FT [Small language models are also few-shot learners], PET zero-shot 및 P-tuning의 성능을 보고","s":"4.2 SuperGLUE","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#42-superglue","p":1088},{"i":1113,"t":"bert-base-cased 및 bert-large-cased model 모두 P-tuning 으로 7개 task 중 5개 task 가 우수한 결과 WiC 및 MultiRC 는 큰 훈련셋을 가져, FT 가 더 큰 이점을 취함 gpt2-base 및 gpt2-medium model 에 대해 P-tuning 은 모든 gpt2-base 중 가장 유망한 결과 위 결과로 bert 및 gpt 기반 모델의 NLU 성능 효과적으로 향상 gpt2-base with P-tuning 은 7개 task 중 6개에서 BERT-base 의 best 결과 능가하고 WiC task 에서 comparable BERT-large 와 비교하면 P-tuning 을 사용한 GPT2-medium 은 7개 task 중 4개에서 우위, RTE 와 WSC task 에선 comparable, 유일한 예외는 WiC WiC task 에선 FT 가 우수하며, 이는 word sense disambiguation task 가 prompt-based MLM prediction 에 적합하지 않음을 추측 모두 종합하여 P-tuning 을 사용하면 GPT2 가 BERT-based model 과 comparable 하거나 더 나은 성능 달성 이는 BERT 같은 bidirectional model 이 NLU task 에서 항상 GPT2 와 같은 unidirectional model 보다 더 우수하다는 것을 뒤엎음","s":"4.2.1 Fully-Supervised Learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#421-fully-supervised-learning","p":1088},{"i":1115,"t":"Sub-optimal and Sensitive Manual Prompts​ PEFT/iPET 는 manual prompt 로 SuperGLUE few-shot learning task 에 SOTA 달성 이 prompt 는 효과적이지만 sub-optimal 이며 노동이 필요하다. manual prompt 의 종합적 이해를 위해 비교 실험 진행 다양한 manual prompt 와 P-tuning 을 사용한 결과 (Table 6) 결과는 prompt 의 의미, 형식, 문법과 few-shot learning 성능 간에 명확한 상관 관계가 없음 합리적으로 여기는 prompt 가 LM 에 효과적이지 않을 수 있음 manual prompt 의 작은 변경 사항이 큰 성능 차이 일으킴 pre-trained LM 은 prompt 선택에 있어 민감 manual prompt 는 복잡하다 결론 Table 6 에서 Ddev32\\mathcal{D}_{dev32}Ddev32​ 사용으로 best manual prompt 찾는 것은 불가능 few-shot 환경에서도 optimal manual prompt 선택은 어려움 반면 P-tuning 은 훨씬 적은 수동 작업으로 더 나은 prompt 를 자동으로 검색하는 데 유망 Updated SOTA for SuperGLUE Few-shot Learning​ P-tuning 에 의해 SuperGLUE few-shot SOTA 달성함을 보여줌 유의할 점은 PET 는 manual prompt fine-tuning 외에도 데이터 증강, 앙상블 및 distillation 으로 성능 향상하고 있으며, 모델 선택 및 hyperparameter tuning 을 테스트셋에 overfitting 하여 수행 공정성을 위해 Ddev32\\mathcal{D}_{dev32}Ddev32​ 에서 재실험하며 모든 보조 기술 제거 Table 5 는 P-tuning 이 모든 작업에서 manual prompt 로 비교하여 PET 및 PET-best 보다 우수한 성능 P-tuning 이 manual prompt 보다 훨씬 우수한 prompt 검색 및 few-shot task 성능 크게 향상함을 입증 CB, WiC, RTE 및 WSC 등의 task 에서 P-tuning 은 데이터 증강, 앙상블 및 distillation 등 보조 기술로 PET/iPET 보다 우수한 성능 위 결과는 P-tuning 이 few-shot NLU task 의 이점 입증","s":"4.2.2 Few-Shot Learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#422-few-shot-learning","p":1088},{"i":1117,"t":"Table 3, 4 는 NLU 성능 향상을 위해 세 가지 tuning-based paradigm 제시 P-tuning 은 BERT-based model 에서 평균적으로 약 2 point, GPT-based model 에선 5 points 이상 우수한 성능 구체적으로, P-tuning 은 대부분 task 에서 best results 를 달성하였지만, WiC 에선 cloze questions 로 정식화하기 어려워, FT 가 우수한 성능 달성 P-tuning 과 MP+FT 를 비교하면 P-tuning 이 평균적으로 MP+FT 보다 큰 이점을 보여주며, 이는 MP+FT 가 좋은 manual prompt 찾기엔 어렵기 때문이다. 반면 P-tuning 은 자동으로 더 나은 prompt 를 검색 가능 P-tuning 은 fine-tuned model 의 parameter 를 tuning 하면서 광범위한 prompt space 탐색 가능하여 새로운 tuning paradigm 으로, fine-tuning 이 어려운 LLM 을 유도하는 데 경쟁력 있는 잠재력 입증","s":"4.2.3 Finetuning v.s. MP Finetuning v.s. P-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"#423-finetuning-vs-mp-finetuning-vs-p-tuning","p":1088},{"i":1120,"t":"본 연구에서 P-tuning 제안 continuous space 에서 더 나은 prompt 를 자동으로 탐색하여 pre-trained model 의 NLU 능력 강화 큰 검증셋에 덜 의존적이며, adversarial prompt 로부터의 피해를 덜 입고, overfitting 완화 test 동안 추가 text 를 제공하지 않고도 LLM 의 세계 지식의 64% (P@1) 복구 SuperGLUE 에서 GPT 스타일 모델에게 NLU 능력을 BERT 와 comparable 한 성능 부여 (과거엔 불가능하다 여김) bidirectional model 에 도움되며, SuperGLUE 에서 SOTA 성능 발휘 위 결과는 LM 이 pre-training 중 생각보다 더 많은 세계 지식을 습득한 것을 입증","s":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/P-tuning","h":"","p":1088},{"i":1122,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2104.08691.pdf","s":"The Power of Scale for Parameter-Efficient Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1124,"t":"본 연구는 Prompt Tuning 탐구 downstream task 수행을 위해 frozen language model (LM) 으로 soft prompt 를 학습하기 위한 간단하면서 효과적인 매커니즘 GPT-3 의 discrete prompt 와 달리, soft prompt 는 backpropagation 으로 학습되며, 여러 labeled examples 의 signals 를 통합하기 위해 tuning 가능 저자의 end-to-end learned appoach 는 GPT-3 의 few-shot learning 을 큰 폭으로 능가 T5 로 model size 에 대한 실험으로, 수십 억 이상의 parameter 를 가지면 prompt tuning 이 comparable 한 것을 보여줌 이 결과는 큰 모델은 sharing 및 serve 가 어려워 특히 중요하며, one frozen model 을 여러 downstream 에 재사용 가능한 능력은 이 부담을 줄여줌 저자의 방법은 prefix tuning 을 단순화한 것이며, 유사한 접근 방식과 비교한다. soft prompt 를 사용한 frozen model 을 설정하는 것이 domain transfer 에 대한 robustness 를 제공하고 효율적인 prompt ensembling 가능하게 함","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1126,"t":"LLM 의 성공으로 downstream task 에 맞게 tuning 하는 것이 등장. ELMo 는 frozen pre-trained model 로 per-layer representation 의 task-specific weight 를 학습하는 것 제안 GPT 및 BERT 이후엔 우세한 adaptation 기술이 model tuning (fine-tuning) 이며 adaptating 중 all model parameter 가 tuning 됨 [Universal language model fine-tuning for text classification. Howard, Ruder] 의 제안대로 model tuning 이루어짐 이후 [Language models are few-shot learners. Brown] 에서 prompt design (priming) 이 frozen GPT-3 의 동작을 text prompt 를 통해 효과적인 tuning 이 가능하단 것을 보여줌 prompt 는 일밥적으로 task description 및 여러 examples 로 구성된다. model size 가 증가함에 따라 pre-trained model 을 freezing 하는 것은 매력적이며, downstream task 마다 별도의 model copy 를 요구하지 않고, 하나의 모델이 동시에 많은 task 를 수행할 수 있다. 하지만 prompt-based adaptation 에는 주요 단점이 있다. task description 은 오류 발생이 쉽고 인간 개입이 필요 prompt 의 효과는 model input 에 얼마나 많은 conditioning text 가 fit 될 수 있는지 제한 downstream task quality 는 여전히 tuned model 의 quality 를 뒤쳐지게 함 예로 GPT-3 175B 의 few-shot 성능은 Fine-tuned T5-XXL 보다 낮다. (parameter 는 16배 큰데 낮음) prompt design 자동화를 위해 여러 연구가 진행됐다. [AutoPrompt. Shin] 은 downstream application program training data 에 의해 가이드되는 word discrete space 에서의 search algorithm 제안 manual prompt design 을 능가하지만 model tuning 과 비교하면 여전히 차이남 [Prefix-tuning. Li and Liang] 은 generation task 에 강력한 결과를 보여줌 frozen model parameter 로 tuning 중 각 layer 의 prepended activations 로 prefix 훈련 [WARP. Hambardzumyan] 는 masked LM 의 input 및 output subnetwork 로 제한된 trainable parameter 제안 classification 에 합리적인 결과 보여줌 본 논문은 adapting LM 에 대한 더 간단한 prompt tuning 제안 frozen entire pre-trained LM 으로 각 downstream task 마다 input text 에 additional kkk tunable tokens 만 prepend 이 soft prompt 는 end-to-end 로 training 되며 full labeled dataset 의 signals 압축하여 few-shot prompt 를 능가하고 model tuning 과의 quality gap 좁힐 수 있음 (Fig. 1) 동시에 single pre-trained model 이 all downstream task 에 재활용되므로 frozen model 의 efficient serving 이점 유지 (Fig. 2) 저자의 method 는 [Prefix-tuning. Li and Liang, WARP. Hambardzumyan] 와 달리, prompt tuning 만으로도 model tuning 과 comparable (with no intermediate-layer prefixes 또는 task-specific output layers) Section 2-3 에서, 자세한 실험으로 LM capacity 가 이러한 approach 를 통해 성공하기 중요한 요소임을 입증 Section 4 에서, 유사한 approach 와 비교 task-specific parameters 를 NLU 에 필요한 \"generalist\" parameters 로부터 명시적으로 분리하여 추가적인 혜택을 얻을 수 있음 Section 5 에서, prompt 에서의 task definition 를 capture 하면서 generalist parameters 를 고정시키면, domain shifts 에 대한 resilience (내구성) 향상시키며 classic model ensembling 보다 효율적임을 보여줌 Section 7 에서 learned soft prompt 의 해석 조사 주요 기여는 다음과 같다. prompt tuning 제안 및 LLM 영역에서의 model tuning 과 comparable 여러 design choices ablating 및 quality 와 robustness with scale 로 향상 보여줌 prompt tuning 이 domain shift problems 을 위한 model tuning 을 능가 prompt ensembling 제안으로 효과적임을 보여줌","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1128,"t":"T5 의 text-to-text approach 를 따라 all task 를 text generation 처리 some input 에 대한 output class 의 probability 같은 classification modeling Pr⁡(y∣X)\\Pr (y|X)Pr(y∣X) 대신에, 저자는 conditional generation 으로 모델링 XXX : 일련의 토큰 yyy : single class label T5 는 classfication 을 Pr⁡θ(Y∣X)\\Pr_\\theta (Y|X)Prθ​(Y∣X) 로 모델링한다. YYY : class label 을 나타내는 token sequence encoder-decoder 로 구성된 Transformer 의 weight θ\\thetaθ 로 parameterize Prompting 은 generation 중 condition 을 위해 extra information 을 추가하는 approach 일련의 tokens PPP 를 input XXX 에 prepend 하여 수행 correct YYY 의 likelihood Pr⁡θ(Y∣[P;X])\\Pr_\\theta (Y|[P;X])Prθ​(Y∣[P;X]) 를 최대화 parameter θ\\thetaθ 는 고정 GPT-3 에서는 prompt token P={p1,p2,…,,pn}P = \\{ p_1, p_2, \\dots, , p_n \\}P={p1​,p2​,…,,pn​} 의 representations 는 model 의 embedding table 일부로 구성 frozen θ\\thetaθ 로 parameterize 따라서 최적의 prompt 를 찾으려면 prompt token 을 선택해야 하며, 이는 manual search 또는 non-differentiable search method 로 이루어진다. prompt tuning 은 prompt PPP 가 θ\\thetaθ 로 parameterize 되어야 한다는 제한을 제거하고, 대신 prompt 에 자체적인 parameters θP\\theta_PθP​ 가 있어, update 할 수 있는 방식이다. prompt design 은 frozen embeddings 의 fixed vocabulary 에서 prompt tokens 를 선택하는 것을 포함한 반면, prompt tuning 은 special tokens 의 fixed prompt 를 사용하는 것으로 생각할 수 있으며, 이때 special tokens 의 embeddings 만 update 이제 새로운 conditional generation 은 Pr⁡θ;θP(Y∣[P;X])\\Pr_{\\theta;\\theta_P}(Y|[P;X])Prθ;θP​​(Y∣[P;X]) 이며, YYY 의 likelihood 를 최대화하기 위해 backpropagation 으로 훈련된다. 반면, θP\\theta_PθP​ 에는 gradient update 만 적용된다. nnn 개의 tokens {x1,x2,…,xn}\\{x_1, x_2, \\dots , x_n\\}{x1​,x2​,…,xn​} 이 주어지면, T5 는 먼저 이러한 token 을 embedding 하여 embedding space 의 dimension 이 eee 인 행렬 Xe∈Rn×eX_e \\in \\mathbb{R}^{n \\times e}Xe​∈Rn×e 를 형성한다. 저자의 soft prompt 는 parameter Pe∈Rp×eP_e \\in \\mathbb{R}^{p \\times e}Pe​∈Rp×e 로 표시, ppp : prompt length 이후 prompt 가 embedded input 에 연결되어 single matrix [Pe;Xe]∈R(p+n)×e[P_e; X_e] \\in \\mathbb{R}^{(p + n) \\times e}[Pe​;Xe​]∈R(p+n)×e 를 형성하고 encoder-decoder 를 통과한다. 저자의 모델은 YYY 의 probability 를 최대화하기 위해 훈련되지만, prompt parameters PeP_ePe​ 만 update 된다.","s":"2. Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1130,"t":"prompt representation 을 initialize 에 여러 방법이 있다. random initialization 으로 scratch training each prompt token 을 model vocabulary 에서 추출한 embedding 으로 initialization 개념적으론 저자의 soft prompt 는 frozen network 의 행동을 input 앞의 text 와 동일한 방식으로 조절하므로, word-like representation 이 좋은 initialization spot 으로 작용한다, classification task 의 경우, [Exploiting cloze-questions for few-shot text classification and natural language inference. Schick and Schütze] 의 \"verbalizers\" 와 유사하게, prompt 를 output classes 로 나열한 embedding 으로 초기화하는 것 저자는 모델이 output 에서 이러한 token 을 생성하기를 원하므로, prompt 를 유효한 target tokens 의 embedding 으로 초기화하면, 모델이 output 을 legal output classes 로 제한하도록 유도한다. 또 다른 design 고려 사항은 prompt length 다. 저자의 방법의 parameter cost 는 EPEPEP 이다. EEE : token embedding dimension PPP : prompt length prompt 가 짧을수록 tuning 해야할 new parameters 가 적기 때문에 성능이 여전히 우수할 최소한의 길이를 찾아야 한다.","s":"2.1 Design Decisions","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#21-design-decisions","p":1121},{"i":1132,"t":"autoregressive 인 GPT-3 와 달리 저자가 실험한 T5 모델은 encoder-decoder 로, span corruption objective 로 pre-training 한다. T5 는 input text 에서 unique sentinel tokens 로 표시된 masked span 을 reconstructing 하는 task 수행 all masked content 로 구성된 target output text 는 sentinel 로 분리되어, final sentinel 에 추가된다. 예로, text \"Thank you for inviting me to your party last week\" 에서 pre-training example 구성 가능 input : \"Thank you ⟨X⟩\\langle X \\rangle⟨X⟩ me to your party ⟨Y⟩\\langle Y \\rangle⟨Y⟩ week\" target output : \"⟨X⟩\\langle X \\rangle⟨X⟩ for inviting ⟨Y⟩\\langle Y \\rangle⟨Y⟩ last ⟨Z⟩\\langle Z \\rangle⟨Z⟩\" [Exploring the limits of transfer learning with a unified text-totext transformer. Raffel] 은 이런 아키텍처와 pre-training objective 가 traditional language modeling 보다 효과적임을 발견했지만, 이 설정이 prompt tuning 을 통해 쉽게 제어 가능한 frozen model 을 생성하기엔 적합하지 않음을 가정 span corruption 만 pre-training 한 T5 를 사용할 경우, 실제 natural input text (free of sentinel tokens) 을 본 적이 없어 실제 natural target 을 예측하지 못한다. 사실 T5 의 span corruption preprocessing 의 details 때문에, 모든 pre-training target 은 sentinel 로 시작한다. 이런 \"unnatural\" sentinel output 경향은 fine-tuning 으로 쉽게 극복할 수 있지만, prompt 만 사용하면 이런 경향을 덮어쓰기가 어려울 것으로 예상된다. decoder priors 를 조정할 수 없기 때문이다. 위 고려사항으로 T5 model 에 세 가지 설정으로 실험한다. Span Corruption frozen pre-trained T5 그대로 사용하고 downstream task 에 대한 expected text output 능력을 테스트 Span Corruption + Sentinel 동일한 모델을 사용하지만 all downstream target 에 sentinel 을 prepend 하여 pre-training 에서 관찰된 target 과 유사하게 만듦 LM Adaptation T5 의 self-supervised training 을 적은 수 추가 이때 LM objective 는 input 으로 natural text prefix 를 받고 output 으로 natural text continuation 생성 이 adaptation 은 한 번만 일어나며, downstream task 전역에 prompt tuning 을 하기 위해 재사용할 수 있는 frozen model 생성 LM adaptation 으로 저자는 T5 를 GPT-3 와 유사한 모델로 \"빠르게\" 변환하고, 항상 현실적인 text 를 출력하고 prompt 에 few-shot learner 가 잘 반응하기를 희망. 이 late-stage transformation 이 처음부터 pre-training 한 것과 비교하여 얼마나 성공적일진 모르지만, 다양한 adaptation length 를 실험하며 최대 100K steps 가지 실험한다.","s":"2.2 Unlearning Span Corruption","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#22-unlearning-span-corruption","p":1121},{"i":1134,"t":"frozen model 은 pre-trained T5 checkpoints 모든 사이즈에서 구축 (Small, Base, XL, XXL) public T5.1.1 checkpoints 를 활용 green ×\\times× 로 표시된 default configuration 는 T5 를 추가 100K steps 를 학습한 LM-adapted version class labels 초기화 100 tokens 의 prompt length Prefix-tuning 보다 default 10-token 보다 길지만 저자의 방법은 input layer 만 tuning 하기 때문에 여전히 훨씬 적은 task-specific parameter 사용 자세한 비교를 위해 Fig. 4 참조. 또한 model size 증가에 따라 훨씬 짧은 prompt 가 사용 가능한 것도 확인 가능 저자는 SuperGLUE 에서 성능 측정 8개의 어려운 NLU task 를 모아놓은 것 각 데이터셋과 관련된 dev set 에서 메트릭 보고 각 prompt 는 하나의 SuperGLUE task 에 대해 훈련 (no multi-task, mixing) 각 SuperGLUE dataset 에 따라 text-to-text 형식으로 변환, task example 에 task names 을 추가하진 않음 standard cross-entropy loss 를 사용하여 30,000 steps 동안 prompt 훈련 0.3 learning rate 32 batch size early stopping 으로 checkpoint 선택 모든 실험은 JAX 를 사용 Adafactor optimizer 1e-5 weight decay 0.8 β2\\beta_2β2​ decay parameter scaling off 모델은 Flax 로 구현","s":"3. Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1136,"t":"standard model tuning 비교를 위해, T5 에서 지정한 default hyperparameter (learning rate 0.001, Adafactor optimizer) 사용 두 가지 기준 고려 Model Tuning : apples-to-apples 비교를 위해, 각 task 별로 tuning Model Tuning (Multi-task) : competitive baseline 을 얻기 위해 T5 의 multi-task tuning 설정 사용. 이 경우 모델이 all task 를 함께 tuning 하며 task name 을 나타내는 text prefix 가 있음 Fig. 1 에서 scale 이 커짐에 따라 prompt tuning 이 model tuning 과 comparable XXL size (11B) 에서 prompt tuning 은 task-specific parameter 가 2만 배 이상 적음에도 불구하고 stronger multi-task model tuning 과 일치 prompt design 비교를 위해 SuperGLUE dev set 에 GPT-3 의 few-shot 성능 포함. Fig. 1 에서 prompt tuning 이 GPT-3 prompt design 을 큰 차이로 이김 prompt tuned T5-Small 은 GPT-3 XL (16배 큼)과 일치, prompt tuned T5-Large 는 GPT-3 175B (220배 큼)를 이김","s":"3.1 Closing the Gap","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#31-closing-the-gap","p":1121},{"i":1139,"t":"{1,5,20,100,150}\\{1, 5, 20, 100, 150 \\}{1,5,20,100,150} 의 다양한 prompt length 로 다른 설정은 고정한 채로 각 모델 크기에 대해 prompt 를 훈련 Fig. 3(a) 에서 대부분의 모델 크기에서 prompt length 를 single token 이상으로 늘리는 것이 좋은 성능을 위한 요소임을 보여줌 XXL 모델은 single token prompt 로 여전히 강력한 결과 제공 모든 모델에서 20 token 이상 늘린 경우엔 미미한 이득만 얻음","s":"Prompt Length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#prompt-length","p":1121},{"i":1141,"t":"모델 크기별로 다른 default value 로 hyperparameter 를 고정시켜 prompt initialization 의 효과를 ablating random initialization 의 경우, [−0.5,0.5][-0.5, 0.5][−0.5,0.5] 에서 균등하게 샘플링 sampled vocabulary 로부터 initializing 하는 경우, T5 의 SentencePiece vocabulary 의 \"common\" token 5,000 개로 제한 이 vocabulary 는 pre-training corpus 의 likelihood 로 정렬 class label initialization 의 경우, downstream task 의 각 class string representation 에 대한 embedding 을 가져와 prompt 의 one token 을 초기화하는데 사용 class label 이 multi-token 일 땐 token embedding 을 평균 longer prompt lengths 에서는 모든 prompt token 초기화하기 전에 class label 이 부족하여, prompt 를 채우기 위해 sampled vocab 전략으로 돌아감 Fig. 3(b) 에서 모델 크기별 initialization 전략의 실험 결과 보여줌 class based initialization 이 best smaller model size 에선 initialization 간의 큰 차이는 없지만, XXL 크기에선 차이가 두드러짐 class label initialization 에선, class label 이 일반적으로 learned prompt 에 유지되어 가장 가까운 token embedding (in cosine distance)이 초기화에 사용된 token 과 일치하는 경우가 많음","s":"Prompt Initialization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#prompt-initialization","p":1121},{"i":1143,"t":"Fig. 3(c, d) 에서 pre-training object 가 prompt tuning quality 에 영향을 미치는 것을 볼 수 있음 T5 의 span corruption objective 는 prompt condition 에 적합하지 않음 sentinel token 을 읽고 쓰도록 pre-traing 된 model 은 sentinel 이 없는 데엔 직접 적용하기 어려움 Fig. 3(c) 에서 target downstream 에 sentinel 을 추가한 \"workaround\" 조차 거의 이익이 없었다. LM adaptation 은 모든 모델 크기에서 가치를 더함 XXL 모델은 가장 관용적이고 span corruption 조차 강력한 결과 제공 LM adaptation 의 이점을 고려하려, 얼마나 오랫동안 adapting 이 도움이 되는지 탐색 Fig. 3(d) 에서 long adaptation 이 추가 이득 제공 최대 100K steps 까지 확장 span corruption 에서 LM objective 로의 전환이 간단하지 않으며, 효과적인 전환에는 training resources (original T5 pre-training 의 10% steps)가 필요하다는 것 시사 다른 실험과 마찬가지로 XXL 모델은 non-ideal 설정에도 robust 하며 adapting 이득은 미미 non-optimal span corruption 에선 모델 크기별로 불안정성 관찰 Small model 이 더 큰 Base, Large 및 XL 모델을 능가하는 경우가 많이 발생 중간 크기 모델은 많은 task 에 대해 legal class label 을 출력하는 방법을 학습하지 못하여 0% score 를 받게됨 두 가지 common error 는 input 에서 subspan 을 복사하는 것과 empty string 을 예측하는 것. 이러한 부정적인 성능은 prompt tuning 의 random variance 때문이 아닌 각 크기별로 3회 실행하여 low variance 를 관찰하기 때문이란 점 위 결과는 span corruption objective 로 pre-training 된 모델을 사용하는 것은 불안정하며, LM adaptation 은 신뢰성 있게 작동한다는 것","s":"Pre-training Objective","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"#pre-training-objective","p":1121},{"i":1145,"t":"continuous prompts learning 연구 검토 및 저자의 방법과 비교 비교의 중요한 측면 중 하나는 각 방법이 필요로 하는 task-specific parameter 의 수 있으며 Fig. 4 에서 볼 수 있다. learnable parameter method 중 prompt tuning 은 모델 크기가 1B 이상의 모델의 0.01% 미만의 task-specific parameter 만 필요로 하여 가장 parameter-efficient prefix-tuning 은 all transformer layer 마다 여러 additional prepended prefix sequence 학습 모든 layer 에서 examples 간에 고정된 activation 을 학습하는 것과 유사 반면 prompt tuning 은 embedded input 에 prepend 된 single prompt representation 을 사용하여 더 적은 parameter 만 필요 저자의 방법은 input example 로 contextualize 된 intermediate-layer task representations 을 update 할 수 있도록 transformer 에 허용 prefix-tuning 은 GPT-2 및 BART 에 기반 저자는 T5 에 focus 하고 model size 증가에 따른 성능 및 robustness 에 대한 design 선택 사항의 변화 검토 BART 사용하면 prefix-tuning 은 encoder-decoder network 에 모두 prefix 를 추가 prompt tuning 은 encoder 에만 prompt 필요 prefix-tuning 은 학습 안정성을 위해 prefix reparameterize 필요하여 학습 중 많은 parameter 필요 저자는 reparameterize 필요하지 않으며 SuperGLUE task 및 모델 크기 전반에 robust WARP 는 prompt parameter 를 input layer 에 추가 masked LM 과 함께 작동하며 [MASK] token 및 learnable output layer 를 사용하여 mask 를 class logit 으로 project model 을 single output 을 생성하도록 제한하여 classification 으로 제한됨 prompt tuning 은 input 또는 task-specific head 에 대한 어떠한 변경도 필요하지 않음 prompt tuning 의 성능도 model tuning 의 강력한 성능과 유사 P-tuning 은 learnable coninuous prompt 를 input 내에 교차로 삽입 저자는 이러한 복잡성을 제거하고 간단하게 input 에 prompt 를 놓은 것 강력한 SuperGLUE 결과를 위해선, P-tuning 은 model tuning 과 함께 사용해야 함 모델은 prompt 와 주요 parameter 를 업데이트하는 반면 저자는 original model 을 유지하면서 continuous prompt 만 추가 soft prompt 는 soft words 를 사용하여 pre-trained LM 에서 knowledge distillation 을 위해 prompt 를 학습하는 방법 prompt 는 hand-designed prompt prototype 를 기반으로 input 과 관련하여 위치시킴 각 layer 에는 learnable paramter △ie\\triangle^e_i△ie​ 를 포함하여 model depth 에 따라 parameter cost 발생 few-shot sequence learning 은 learnable prepended token 으로 transformer 를 다양한 task 에 adapting 하지만, 큰 데이터셋 대신 task representation 수용을 위해 설계된 작은 mixing dataset 에 중점을 둔다. base model 이 small trasnformer 이며 task representation 과 함께 훈련 반면 저자는 base model 을 유지하며 큰 transformer 로 크기를 확장하여 조사 task prompt 에 대한 작업은 \"adapters\" 와 밀접한 관련이 있다. adapter 는 LM 의 small bottleneck layers 를 의미하며 frozen pre-trained netwrok layer 사이에 삽입된다. task-specific parameter 를 줄이는 또 다른 수단으로서, BERT-Large 를 freezing 하고 2-4$ 의 추가 parameter 만으로 GLUE 성능을 model tuning 과 근접하게 달성하기도 했다. multiple adapter 을 사용하여 task specification 에서 language understanding 으로 분리하는 방식이 저자의 model behavior 을 변경하는 방법과 핵심적인 차이가 있다. adapter 는 실제로 input representation 에 작용하는 실제 함수를 수정하여 model behavior 을 변경하는 반면, prompt tuning 는 그대로 유지하며 새로운 input representation 을 추가함으로써 후속 input 처리에 영향을 미치게 한다.","s":"4. Comparison to Similar Approaches","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1147,"t":"frozen LM 으로, prompt tuning 은 모델이 언어에 대한 일반적인 이해도를 수정하지 못하게 한다. 대신 prompt representation 을 간접적으로 input representation 을 변형한다. 이는 모델이 특정 vocab 와 잘못된 상관관계를 기억하여 데이터셋에 overfitting 되는 것을 줄임 prompt tuning 이 domain shift 에 대한 robustness 를 향상을 시사 저자는 두 가지 task, QA 및 Paraphrase Detection 에 대한 zero-shot domain transfer 조사 QA 의 경우 MRQA 2019 사용 통합된 형식의 추출형 QA dataset 을 수집하고 in-domain dataset 에서 훈련된 모델이 out-of-domain dataset 에 어떻게 수행되는지 테스트 SQuAD 에서 훈련하고 각 out-of-domain 에 평가 Table 1 은 prompt tuning 이 out-of-domain 대부분의 데이터셋에 model tuning 보다 우수한 성능 보여줌 TextbookQA 의 경우 두 approach 간의 12.5% F1 차이를 보여줌 larger domain shift 의 경우 (BioASQ → Biomedical, TextbookQA → Textbooks)에는 prompt tuning 이 더 큰 이점 관찰 domain shift 에 대한 robustness 테스트를 위해 GLUE 의 두 paraphrase detection tasks 간의 transfer 탐구 QQP task 로, Q&A 사이트에서 가져온 두 개의 질문이 중복인지 물음 MPRC task 로, 뉴스 기사에서 추출한 두 문장이 부분적으로 동일한지 물음 both direictions (QQP ↔ MRPC) transfer 을 테스트하고 이전과 같이 \"in-domain\" task 에서 훈련하고 \"out-of-domain\" task 에서 zero-shot 평가 Table 2 는 QQP dataset 에서 lightweight prompt 를 훈련하고 MRPC 에서 평가 full model tuning 보다 훨씬 나은 성능 제공 other direction 에서의 결과도 유사하며, 정확도에서 작은 향상과 F1 에서의 작은 감소가 나타났다. 위 결과는 model tuning 이 training 을 과도하게 parameterize 하고 다른 domain 의 유사한 task 에 미치는 악영향을 고려하는 관점으로 볼 수 있다.","s":"5. Resilience to Domain Shift","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1149,"t":"model ensembling 은 동일한 데이터셋에 다른 initialization 으로 훈련된 여러 모델을 결합하여 task 성능을 향상시키는 것 하지만 모델 크기 증가에 따라, 앙상블은 어려워진다. 모델 저장에 필요한 공간 외에도 NNN 개의 모델을 실행하는 데 상당한 inference cost 가 들기 때문이다. 이를 해결하기 위해 prompt tuning 은 pre-trained LM 의 multiple adaptation 을 앙상블하는 더 효율적인 방법 제공 동일 task 에 NNN 개의 prompt 를 훈련하여 별도의 \"model\" 을 생성하면서도 LM parameter 를 모두 sharing prompt ensembling 은 inference 를 더 효율적으로 만든다. 예로, 한 example 처리를 위해 NNN 개의 다른 모델을 forward pass 를 실행하고 example 을 배치 내에서 복제하여 prompt 를 다양하게 설정 가능 위 이점은 Fig. 2 의 multi-tasking 에서 볼 수 있는 것과 유사 prompt ensembling 유효성을 보여주기 위해 각 SuperGLUE task 에 대해 다섯 개의 prompt 를 frozen T5-XXL 모델에서 사용하여 훈련 저자는 ensembling 에서 예측 계산을 위해 간단한 majority voting 을 사용 Table 3 은 all task 에서 앙상블이 single-prompt average 를 능가하며, 개별 best prompt 를 능가하거나 일치","s":"6. Prompt Ensembling","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1151,"t":"해석 가능한 prompt 는 task 를 명확히 설명하는 natural language 로 구성되어 있어 모델에 어떤 결과 및 동작을 요청하고, 모델로부터 어떤 동작을 유발하는지 이해하기 쉽게 말들어야 한다. prompt tuning 은 discrete token 이 아닌 continuous embedding space 에서 작동하여 해석이 더 어렵다. 저자의 learned soft prompt 해석 가능성을 테스트하기 위해 각 prompt token 에 대해 nearest neighbors 를 frozen model's vocabulary 에서 계산한다. similarity metric 로 vocabulary embedding vector 와 prompt token representation 사이의 cosine distance 를 사용한다. 특정 learned prompt token 에 대해 top-5 nearest neighbors 가 tight semantic clusters 를 형성하는 것을 관찰했다. 예로, {Technology / technology / Technologies / technological / technologies}\\{ Technology \\ /\\ technology \\ /\\ Technologies \\ /\\ technological \\ /\\ technologies \\}{Technology / technology / Technologies / technological / technologies} 와 같이 similar cluster 를 관찰 {entirely / completely / totally / altogether / 100% }\\{ entirely \\ /\\ completely \\ /\\ totally \\ /\\ altogether \\ /\\ 100\\% \\ \\}{entirely / completely / totally / altogether / 100% } 와 같이 더 다양한 related cluster 도 관찰 위와 같은 cluster 의 성격은 prompt 가 \"word-like\" representation 을 학습하고 있다는 것을 시사. 저자는 embedding space 에서 추출한 random vector 가 이런 유형의 semantic clustering 을 보여주지 않는 다는 것을 발견했다. prompt 를 \"class label\" 전략으로 초기화할 때, 종종 class label 이 훈련 후에도 지속된다. 구체적으로, prompt token 이 given label 로 초기화된 경우, 해당 label 이 tuned token 의 nearest neighbors 중 하나가 되는 경우가 많다. Random Uniform 또는 Sampled Vocab 방법으로 초기화하는 경우에도 class label 이 prompt 의 nearest neighbors 에서 발견되는 경우가 많다. 이는 모델이 prompt 에 expected output classes 를 참조로 저장하고, prompt 를 output class 로 초기화하면 이를 더 쉽게 centralize 한다는 것을 시사한다. longer prompt (e.g. 100) 을 조사할 때 종종 동일한 nearest neighbors 를 가진 여러 prompt tokens 를 찾을 수 있다. 이는 prompt 에 과도한 용량이 있거나 prompt representation 에 sequential structure 이 부족하여 모델이 특정 위치로 정보를 localize 하는 것이 어렵다는 것을 시사한다. sequence 로 가져온 learned prompt 는 해석 가능성이 없지만, BoolQ dataset 에서 훈련된 prompt 에 대해, \"science, technology 및 engineering\" 같은 단어가 높은 빈도로 나타난다. 그리고 질문의 20% 가 \"Nature/Science\" 범주에 속한다. 이는 prompt 의 한 가지 역할이 model 에 specific domain 또는 context (e.g. scientific) 에서 입력을 해석하도록 준비하는 것일 수 있음을 시사","s":"7. Interpretability","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1153,"t":"prompt tuning 이 frozen pre-trained LM 을 downstream task 에 adapting 하는 comaprable 한 기술임을 증명 SuperGLUE 에서 task performance 가 traditional model tuning 과 comparable model scale 증가에 따른 gap 줄임 zero-shot domain transfer 에서 prompt tuning 이 generalization 향상 general-purpose 의 language understanding parameter 를 동결하고 downstream learning 을 lightweight parameter footprint 제한하여 specific domain 에 overfitting 되는 것 피함을 시사 task quality metric 외에도, storage 및 serving cost 측면의 frozen pre-trained model moving 의 매력에 대해 논의. 이 move 는 efficient multi-task serving 과 efficient high-performing prompt ensembling 모두 가능하게 함","s":"8. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prompt Tuning","h":"","p":1121},{"i":1155,"t":"논문 및 이미지 출처: https://arxiv.org/pdf/2305.03937v1.pdf","s":"Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1157,"t":"Prompt Tuning 은 성공적인 PEFT 접근법 중 하나지만 (tuned soft prompts < 0.1% of total parameters) 로 인해 다른 PEFT 보다 성능이 안좋거나 hyper-parameter 에 민감 본 논문에서 저자는 RESIDUAL PROMPT TUNING 을 제안 간단하고 성능 및 prompt tuning 의 안정성을 크게 향상시키는 efficient method shallow network with a residual connection 을 사용하여 soft prompt embeddings 를 reparameterize Residual Prompt Tuning 은 T5-Large, T5-Base 및 BERT-Base 전역에 SuperGLUE 에서 prompt tuning 능가 Notably, T5-Base 에서 prompt tuning +7 points 도달 성능 손실 없이 prompt length X10 줄임 저자의 접근법은 learning rate 및 prompt initialization 선택에 있어 robust 하며 few-shot settings 에 효과적","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1159,"t":"Pre-trained language models (PLMs) 는 NLU task 에 큰 성능을 도달하고, scaling up 으로 성능을 더욱 향상시키고 있다. (e.g. GPT-3 175B, MT-NLG 530B) large-scale models 의 성능은 향상하지만 사이즈 때문에 응용에 있어 제한이 걸린다. fine-tuning 은 all model parameters 의 gradients 및 optimizer states 를 저장해야 하므로 비용이 만만치 않다. 또한 각 task 에 대한 fine-tuned model copy 도 있어야 하므로 billion-parameter models 로 현실적으로 어렵다. full fine-tuning 해결을 위해 prompt design 에 초점이 맞추어져 왔다. 이는 frozen model 에 natural language prompts 를 쿼리한다. 이 설정에선 all tasks 를 language modeling tasks 로 변환(e.g. 0/1 classes 를 \"True\"/\"False\" 로 인코딩할 수 있다.)하고 원하는 output 을 생성하도록 수동으로 선택한 prompts 를 frozen model 에 조건화시킨다. few-shot 성능에 강하지만, 최적의 prompt 를 수동으로 찾는 것은 어렵고 시간소비가 크며 서로 다른 prompts 는 최종 성능에 큰 분산을 일으킨다. 최근 prompt tuning 이 제안되었으며, 수동 prompt designing 대신 soft prompts 를 gradient descent 로 학습시킨다. soft prompts 는 input 앞에 붙여지는 continuous embedding 으로, training 으로 업데이트되며 일반적으로 < 0.1% of total parameter 만 구성된다. prompt tuning 은 모델이 클수록 full fine-tuning 에 가까운 성능을 보이며 11B 이상에선 차이가 거의 없다. 하지만 smaller model 에선 여전히 성능이 낮으며, 성능이 hyperparameter 선택에 의존된다. 게다가 안정적인 성능을 위해 long training 과 large tokens (over 100)이 요구된다. 이는 prompt 가 순차 학습되는 continual learning setup 이거나 context length 가 제한된 경우 주요 bottleneck 이 될 수 있다. 본 논문에선 prompt embeddings 의 residual reparameterization 을 통해 prompt tuning 을 향상시키고 안정적이게 한다. 이를 RESIDUAL PROMPT TUNING 이라 한다. shallow network 및 residual connection 으로 soft prompt embedding 을 통과시킴 그 후, reparameterized prompt 를 input 앞에 붙이고 LM 에 feed 이 prompt 는 모델이 각 prompt token 에 대한 개별 embedding 을 사용하는 것과 shared reparameterization network 에서 얻은 representation 사이를 결정하는데 더 많은 유연성을 제공 훈련 후에는, reparameterizatione network 는 버리고, original prompt embeddings 는 projections 로 대체할 수 있다. T5-Large, T5-Base 및 BERT-Base 로 SuperGLUE task 에서 실험 진행하여, T5-Base 에서 이전 prompt-tuning +7 points 를 달성하였다. 또한 Residual Prompt Tuning 은 다양한 learning rate/prompt initializations 에서 성능 분산을 줄였으며, fewer training iterations 에서도 강한 성능을 만들었다. 마지막으로, Residual Prompt Tuning 은 few-shot settings 에서도 prompt tuning 을 능가했다","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1162,"t":"downstream task 에 PLMs 를 adapting 하는 일반적인 approach 는 all parameters Θ 를 fine-tune classification task TTT, input text xxx 및 output scalar label yyy 에서, pΘp_ΘpΘ​ 는 full model weights Θ 에 의해 parameterize 된 output classes 의 확률 분포 max⁡Θ∑x,y∈Tlog⁡pΘ(y∣x).\\begin{equation} \\underset{Θ}{\\max} \\sum_{x,y \\in T} \\log p_Θ (y|x). \\end{equation}Θmax​x,y∈T∑​logpΘ​(y∣x).​​ all model parameter 업데이트로 LLM 에 대한 비용은 매우 크다.","s":"Fine-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#fine-tuning","p":1154},{"i":1164,"t":"prompt tuning 은 fine-tuning 의 경량화된 대안으로 제안되었다. 주요 아이디어는 virtual token embeddings 의 sequence 또는 soft prompt PPP 를 input text xxx 앞에 붙이고 model parameter 는 fix 한채 이들만 학습시키는 것이다. model parameters Θ 는 frozen PLMs 와 additional soft prompt parameter θP\\theta_PθP​ 가 결합되게 된다. max⁡θP∑x,y∈Tlog⁡pΘ(y∣[P;x]).\\begin{equation} \\underset{\\theta_P}{\\max} \\sum_{x,y \\in T} \\log p_Θ (y| [P; x]). \\end{equation}θP​max​x,y∈T∑​logpΘ​(y∣[P;x]).​​ Prompt tuning 은 많은 real-world 응용에 PLMs 를 parameter-efficient solution 을 제공하지만, soft prompts training 은 hyperparameter tuning 및 원하는 성능 도달을 위한 loger traning time 이 요구된다.","s":"Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#prompt-tuning","p":1154},{"i":1167,"t":"저자는 shallow network with a skip connection 으로 soft prompt 에 flexible reparameterization 사용을 제안. 특히 nnn 개의 virtual tokens [P1,…,Pn][P_1, \\dots , P_n][P1​,…,Pn​] 로 구성된 prompt embeddings PPP 의 sequence 를 reparameterized sequence P′P'P′ 로 project P′=[P1′,…,Pn′]=[Φ(P1),…,Φ(Pn)],\\begin{equation} P' = [P'_1, \\dots , P'_n] = [\\Phi(P_1), \\dots , \\Phi(P_n)], \\end{equation}P′=[P1′​,…,Pn′​]=[Φ(P1​),…,Φ(Pn​)],​​ Φ(⋅)\\Phi(\\cdot)Φ(⋅) : residual connection 한 shallow network ϕ(⋅)\\phi(\\cdot)ϕ(⋅) 로 구성된 reparameterization function Φ(⋅)\\Phi(\\cdot)Φ(⋅) 은 각 prompt token 에 독립적으로 적용됨 Φ(Pi)=ϕ(Pi)+Pi ,i∈{1…n}\\begin{equation} \\Phi(P_i) = \\phi(P_i) + P_i \\ , i \\in \\{1\\dots n \\} \\end{equation}Φ(Pi​)=ϕ(Pi​)+Pi​ ,i∈{1…n}​​ 저자의 ϕ(⋅)\\phi(\\cdot)ϕ(⋅) 는 일반적으로 사용되는 ResNet 및 adapter modules 를 따른 MLP 이다 down-projection Wdown∈Rd×mW_{\\text{down}} \\in \\mathbb{R}^{d\\times m}Wdown​∈Rd×m 및 up-projection Wup∈Rm×dW_{\\text{up}} \\in \\mathbb{R}^{m \\times d}Wup​∈Rm×d layers 로 구성 (Figure 2) 이 결합은 (ResNet 및 adapter modules) 에서 이미 연구됨 ddd : model embeddings 의 차원 mmm : MLP 의 bottleneck size downstream task 에 prompt embeddings θP\\theta_PθP​ 및 reparameterization parameters θϕ\\theta_{\\phi}θϕ​ 만 훈련하며 다른 parameters 는 freezing training objective 는 reparameterized soft prompt P′P'P′ 가 붙여진 input text xxx 에 대한 correct output yyy 의 log-likelihood 최대화 max⁡θP,θϕ∑x,y∈Tlog⁡pΘ(y∣[P′;x]).\\begin{equation} \\underset{\\theta_P, \\theta_\\phi}{\\max} \\sum_{x, y \\in T} \\log p_\\Theta (y|[P';x]). \\end{equation}θP​,θϕ​max​x,y∈T∑​logpΘ​(y∣[P′;x]).​​","s":"3.1 RESIDUAL PROMPT TUNING","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#31-residual-prompt-tuning","p":1154},{"i":1170,"t":"저자는 residual connection 이 RESIDUAL PROMPT TUNIONG 에 있어 성능 증가 및 수렴 속도 증가에 있어 중요한 역할을 하는 것을 발견 (Section 5.1) 저자는 residual learning 이 모델에게 각 prompt token 에 대한 개별 embedding 을 사용하는 것과 shared reparameterization network 에서 얻은 representation 사이를 결정하는데 더 많은 유연성을 준다고 가정한다. residual connection 의 이점은 Appendix B.2 에서 다룬다.","s":"Residual connection","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#residual-connection","p":1154},{"i":1172,"t":"two-layer MLP, up- 및 down-projection matrics WupW_{\\text{up}}Wup​ 및 WdownW_{\\text{down}}Wdown​ 은 additional trainable parameter 로 구성된다. hidden layer 의 차원 mmm 의 증가는 높은 성능을 보여주며(Section 5.6), prompt token 의 overparameterization 은 성능 향상에 중요하다. 자세한 parameter-efficiency 는 Appendix A.6","s":"Depth and width of MLP","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#depth-and-width-of-mlp","p":1154},{"i":1174,"t":"저자는 normalization layer 로 LayerNorm, non-linearity 로는 ReLU 를 선택 LayerNorm 은 성능 안정성에 도움이되며 non-linear layer 의 특정 선택의 효과는 덜 중요한 것을 발견","s":"Non-linearity and normalization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#non-linearity-and-normalization","p":1154},{"i":1176,"t":"저자는 각 virtual token embedding 에 shared reparameterization network Φ\\PhiΦ 를 적용했다. 다른 특정 설계는 각 prompt embedding 에 개별 network 를 적용했다. 두 가지를 비교한 결과 (Section 5.6), shared MLP 가 더 parameter-efficient 및 제한된 데이터에 대한 knowledge sharing 의 이점 제공을 가져왔다.","s":"Parameter sharing","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#parameter-sharing","p":1154},{"i":1178,"t":"training 중, 백본 모델은 freezing 하며 prompt embeddings PPP 및 reparameterization network Φ(⋅)\\Phi(\\cdot)Φ(⋅) 의 parameter 를 공동으로 최적화한다. reparameterized prompt 는 input text embeddings 전에 삽입되고 LM 에 feed 된다. 저자는 task-specific prompts 를 사용했으며, 이는 reparameterized prompt embeddings 가 input 에 의존하지 않는다는 것을 의미한다. 훈련 후, learned reparameterized network Φ(⋅)\\Phi(\\cdot)Φ(⋅) 으로 prompt embeddings 를 project 하고 original prompt embeddings 를 상응하는 projections P′=Φ(P)P' = \\Phi(P)P′=Φ(P) 로 교체한다. inference 중에는, reparameterization network 는 버리고 projected prompt embeddings P′P'P′ 를 사용한다. input text embeddings 앞에 P′P'P′ 를 삽입하고 frozen PLMs 에 함께 feed 한다.","s":"3.3 Training and Inference","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#33-training-and-inference","p":1154},{"i":1181,"t":"SuperGLUE 벤치마크인 NLU tasks 를 사용하며 8가지 datasets 을 사용한다. BoolQ, CB, COPA, MultiRC, ReCoRD, RTE, WiC, WSC","s":"4.1 Datasets","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#41-datasets","p":1154},{"i":1183,"t":"encoder-decoder T5 model 및 encoder-only BERT 모델에서의 성능을 실험하며, BERT-Base (110M), T5-Base (220M) 및 T5-Large(770M) 에 초점을 둔다.","s":"4.2 Architectures","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#42-architectures","p":1154},{"i":1185,"t":"sequence 앞에 trainable prompt 삽입하며 그 앞에 [CLS] token 삽입 LM 에는 x^\\hat{x}x^ 을 입력한다. x^=concat[E([CLS]),P′,E(S[EOS])]\\hat{x} = concat[E([CLS]), P' , E(S[EOS])]x^=concat[E([CLS]),P′,E(S[EOS])] P′P'P′ : reparameterized soft prompt 의 embedding matrix [CLS], [EOS] : special tokens E : tokenization 및 embedding 추출 input text x^\\hat{x}x^ 의 클래스 예측을 위해 BERT original 설정과 [CLS] token 의 encoder representation h[CLS]h_{[CLS]}h[CLS]​ 을 사용하며 www 로 parameterzie 된 linear transformation 과 softmax layer 을 추가한다. p(y=c∣h)=ewch[CLS]∑k∈Cewkh[CLS]p(y = c|h) = \\frac{e^{w_c h_{[CLS]}}}{\\sum_{k \\in \\mathcal{C}}e^{w_k h_{[CLS]}}}p(y=c∣h)=∑k∈C​ewk​h[CLS]​ewc​h[CLS]​​ 이후 prompt embedding, linear head, reparameterization network 에 gradient update 를 위해 cross-entropy loss 를 적용한다","s":"BERT","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#bert","p":1154},{"i":1187,"t":"T5 에선 all tasks 를 language modeling task 로 변환 이 설정에선, classification task 를 conditional generation 으로 모델링하며, 여기서 output 은 class label 을 나타내는 token 의 sequence 이다. input text embedding 앞에 reparameterized prompt embedding P′P'P′ 를 덧붙여 total input x^=concat[P′,E(S)]\\hat{x} = concat[P', E(S)]x^=concat[P′,E(S)] 이 PLM 에 전달된다. T5 은 input tokens 에 multi-headed self-attention 적용 후 position-wise feed-forward layers 로 target token 에 대한 분포 출력한다. cross-entropy loss 로 prompt embeddings 및 reparameterization network 의 parameter 를 훈련한다.","s":"T5","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#t5","p":1154},{"i":1189,"t":"Residual Prompt Tuning 를 두 카테고리: prompt reparameterization 및 PEFT 에 대해 비교한다. residual reparameterization 이 prompt tuning 을 얼마나 향상시키는지 연구하고 다른 기술과 비교 original prompt tuning (PT) PT with MLP reparameterization PT with LSTM fine-tuning residual prompt tuning 의 이점을 기존 PEFT 와 비교 AdapterDrop SPoT ATTEMPT","s":"4.3 Baselines","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#43-baselines","p":1154},{"i":1191,"t":"모든 prompt-tuning based 실험에서 prompt tuning 의 프로토콜을 따름 특별한 명시가 없다면 표준 메트릭을 사용한다고 한다. PEFT 비교에서는 PEFT 훈련 프로토콜을 따른다고 한다.","s":"4.4 Experimental setup","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#44-experimental-setup","p":1154},{"i":1195,"t":"Residual prompt tuning 및 기존 prompt tuning 과 두 가지 reparameterization methods (MLP 및 LSTM) 비교한다. 위는 각 모델에 10-tokens 및 100-tokens 를 비교한 결과다. residual prompt tuning 이 다른 방법보다 우수한 성능을 보인다 10-tokens 에서 T5B, T5L 에서 +3 points 개선, 100-tokens 에선 T5B 가 +7 points 이상 개선 Table 1 결과는 10-token prompt 로 실험했으며, 작업결로 일관된 개선을 보인다. Fig. 3 에서 보이듯, residual prompt tuning 은 다른 방법보다 더 빠른 수렴을 이끈다. reparameterization network 의 residual connection 은 성능 향상에 중요한 역할을 했다. (non skip connection MLP 는 prompt tuning 보다 느리게 수렴) 저자는 skip connection 이 identity function (linearity) 를 학습하는 것을 우회하고 original embedding 의 \"top\" 에 project 할 수 있게 한다고 가설을 세운다. (Appendix B.2)","s":"5.1.1 Comparison with prompt tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#511-comparison-with-prompt-tuning","p":1154},{"i":1197,"t":"저자는 SuperGLUE 에서 다양한 PEFT 들과 성능 비교 설정은 Prompt Tuning 을 따르며, 5개의 SuperGLUE task 에서 T5-Base 100-tokens prompt 로 훈련시킨다. Table 3a 에서 residual prompt tuning 이 평균적으로 +10 points 큰 성능 향상 이룸 저자의 방법 중 주요 이점은 강력한 결과를 위한 source task transfer learning 이 필요하지 않다는 것 이는 SPoT 과 ATTEMPT 와 대조적 Table 3b 에서 PEFT 내용을 비교 reparameterization network 는 훈련 후 폐기되어 original prompt tuning 과 추가 추론 비용이 같다 adapter-based 방법들과 비교해 25배 적은 파라미터만 필요 사전 훈련이 필요 없다 residual prompt tuning 의 parameter-efficient 에 대한 내용은 Appendix A.6.","s":"5.1.2 Other parameter-efficient methods","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#512-other-parameter-efficient-methods","p":1154},{"i":1199,"t":"넓은 범위의 learning rate 에서 RESIDUAL PROMPT TUNING 성능 연구 (Fig. 4) 이전 연구들은 prompt tuning 이 learning rate 에 민감하여 하이퍼파라미터 탐색이 필요하다 보고한다 [Prompt Tuning, SPoT]. 저자는 Prompt Tuning 의 learning rate {0.001, 0.01, 0.03, 0.3, 10} 으로 SuperGLUE 평가하고, 공정한 비교를 위해 안정적인 T5-Large 및 100 tokens prompt 사용. residual reparameterization 은 learning rate 범위에서 prompt tuning 성능을 안정화시키는데 도움 줌 기존 prompt tuning 은 변동이 있지만, RESIDUAL RPOMPT TUNING 은 견고하며, 0.01 ~ 10 사이인 경우, 성능이 안정적이며 평균 2 points 미만의 변동이 나타난다.","s":"5.2 Robustness to the choice of learning rate","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#52-robustness-to-the-choice-of-learning-rate","p":1154},{"i":1201,"t":"Prompt Tuning 연구에선 prompt parameter 초기화가 최종 성능에 영향을 미치는 것을 발견. 구체적으로, sampled vocalbulary embeddings 을 초기화하는 것은 random uniform initialization 에 비해 평균 SuperGLUE 성능 +10 points 향상 시켰다. 이에 대한 RESIDUAL PROMPT TUNING 성능에도 조사한다. 10 tokens prompt 를 사용한 T5B 모델을 사용 RESIDUAL PROMPT TUNING 이 프롬프트 초기화 방법에 견고한 것을 볼 수 있음 random uniform initialization 과 sampled vocabulary 두 결과가 비슷한 성능 달성 특이한 점은 초기화 효과가 데이터셋 크기가 작은 CB (250 sample)인 경우 더 두드러진다는 것이다.","s":"5.3 Robustness to the prompt initialization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#53-robustness-to-the-prompt-initialization","p":1154},{"i":1203,"t":"적은 양의 데이터로 실험을 더 진행했다. 각 클래스 당 5, 20, 100개 샘플 추출하여, 선택된 샘플로 인한 분산을 피하기 위 각 task 에 대해 모든 실험에서 동일한 학습 집합을 고정함. 저자는 T5-Large 및 100 tokens prompts 를 사용했다. RESIDUAL PROMPT TUNING 은 적은 양의 데이터에서도 효과적이며, 5 및 20개 샘플에 대해 각각 +7 및 +2 points 향상시켰다.","s":"5.4 Prompt tuning in few-shot setting","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#54-prompt-tuning-in-few-shot-setting","p":1154},{"i":1205,"t":"저자는 더 작은 prompt 로 성능을 평가하고, Prompt Tuning 과 평가 T5-Large 모델로 길이가 2, 10 및 100 tokens 인 prompt 의 성능을 탐색한다. RESIDUAL PROMPT TUNING 은 모든 prompt 길이에서 성능 향상이 있었으며, 각각 2, 10 및 100 tokens 에 대해 평균적으로 +2.6, +1.1 및 +0.8 points 향상 달성","s":"5.5 Performance and prompt length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#55-performance-and-prompt-length","p":1154},{"i":1208,"t":"각 prompt 가 MLP 로 skip connection 을 통해 reparameterization 될 때의 성능을 평가함으로써 sharing reparameterization network 의 영향을 ablation 한다. 네 가지 SuperGLUE task 를 선택 (CB, COPA, WiC, RTE) 했으며, 작은 데이터 범위에선 sharing reparameterization network 가 유리한 것을 발견했다. 더 큰 데이터셋에서는 더 많은 trained parameters 를 희생함으로써 더 나은 성능을 달성하였다.","s":"Parameter sharing.","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#parameter-sharing-1","p":1154},{"i":1210,"t":"최종 성능에 미치는 overparameterization 영향 연구를 위해 MLP width 를 albation 하여 MLP hidden layer 의 차원 범위를 변화시킴: {5, 10, 50, 100, 400, 1500} 차원 증가에 따라 성능 향상이 있으며, 차원이 50 Unit 이상으로 증가하면 성능이 포화된다.","s":"Overparameterization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#overparameterization","p":1154},{"i":1212,"t":"RESIDUAL PROMPT TUNING 을 제안하며, 이는 prompt embedding 의 residual reparameterization 으로 soft prompt 를 효과적으로 학습 이 방법에 대한 넓은 하이퍼파라미터 탐색, 긴 훈련 시간 및 source task 에서의 pre-train 없이 효과적으로 학습할 수 있게 한다. 이 방법은 SuperGLUE 에서 Prompt Tuning 등과 비교해 뛰어난 성능을 보이는 것을 보여준다. 또한 하이퍼파라미터 선택 (learning rate, prompt initialization)에 견고하며, 수렴을 빠르게 하고 적은 양의 데이터에도 효과적이다.","s":"7. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"","p":1154},{"i":1214,"t":"성능이 fine-tuning 과 비교하면 만족스럽진 않음. (예: T5-L with 100 tokens prompt 에서 SuperGLUE 평균 점수에서 7.8 points 차이) reparameterization network 훈련을 위해 prompt tuning 보다 약간 더 많은 매개변수 사용 본 논문은 encoder-decoder(T5) 및 encoder-only(BERT) 모델에 초점을 맞추어 있다.","s":"Limitations","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#limitations","p":1154},{"i":1218,"t":"RESIDUAL PROMPT TUNING 의 total trainable parameter 수는 다음과 같이 구성된다. trainable prompt embeddings reparameterization network down-projection Wdown∈Rd×mW_{down} \\in \\mathbb{R}^{d \\times m}Wdown​∈Rd×m layer up-projection Wup∈Rm×dW_{up} \\in \\mathbb{R}^{m \\times d}Wup​∈Rm×d layer ddd : embedding 차원 mmm : MLP bottleneck size NNN : prompt tokens 수 LayerNorm d×Nd \\times Nd×N osft prompt parameters 와 reparameterization network 의 m×d+d×+2d=2dm+2dm \\times d + d \\times + 2d = 2dm + 2dm×d+d×+2d=2dm+2d parameter 가 있다. 따라서, RESIDUAL PROMPT TUNING 은 2dm+2d+dN2dm + 2d + dN2dm+2d+dN trainable parameter 가 있는 셈이다. 그리고 훈련 후 이 reparameterization network 는 버릴 수 있으며, task-specific parameter dNdNdN 만 남는다.","s":"A.6 Parameter-efficiency of RESIDUAL PROMPT TUNING","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#a6-parameter-efficiency-of-residual-prompt-tuning","p":1154},{"i":1221,"t":"여기서 RESIDUAL PROMPT TUNING, prompt tuning 및 MLP reparameterization 을 통한 prompt tuning 의 수렴성을 연구한다. Fig. 7 에서 몇 가지 SuperGLUE 작업에서 훈련 중의 정확도와 손실의 진화를 보여줬다. 저자는 RESIDUAL PROMPT TUNING 이 Prompt Tuning 보다 수렴을 크게 가속화한다는 것을 관찰했다. 특히, reparameterization network 내의 residual connection 이 성능 향상에 핵심 역할을 한다. skip connection 없이 MLP-based reparameterization 은 사실 표준 프롬프트 튜닝보다 수렴 속도가 느림 (Fig. 7). 이는 skip connection 이 prompt embedding 을 최적화하기 쉽게 만들어서 설명될 것으로 추측 구체적으로, skip connection 을 통해 학습할 필요 없는 항등 함수를 우회하고 원래 임베딩 위에 projections 를 학습하는 대신, 처음부터 그것들을 학습하는 대신 \"위에\" projections 를 학습하도록 허용(ResNet 에서 비슷한 관찰). 따라서 residual prompt reparameterization 은 원래 prompt embedding 을 embedding projections 와 유연하게 결합하여 빠른 수렴과 개선된 성능을 달성","s":"B.2. Covergence of different prompt tuning approaches","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Residual Prompt Tuning","h":"#b2-covergence-of-different-prompt-tuning-approaches","p":1154},{"i":1223,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.02861.pdf","s":"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1225,"t":"Prompt tuning : pre-trained model 을 각 task 에 맞게 adapt 하는 방법. 학습된 prompt vector 에 의존하여 Large Language Model (LLM) 을 다양한 downstream task 에 효율적으로 adapt 하는 approach 로 등장. 기존 방법은 처음부터 soft prompt vectors 를 학습 multitask 에서 풍부한 cross-task knowledge 를 어떻게 활용해야 하는지 명확하지 않음 이에 저자는 다음을 제안 multitask prompt tuning (MPT) multiple task-specific source prompt 로 distilling knowledge 를 하여, single transferable prompt 를 학습 각 downstream target task 에 효율적으로 adapt 하기 위해 shared prompt 에 multiplicative low rank updates 를 학습 23개 데이터셋에 실험 결과, 최근 approach / method 와 비교하여 우수한 성능 보여줌 특정 경우엔, task-specific parameter 의 0.035% 만 tuning 하여, full finetuning baseline 을 능가","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1227,"t":"Finetuning pretrained language models (PLMs) 은 downstream task 에 큰 성능 향상을 이끌어 냄 하지만, full task-specific finetuning (FT) 은 현재 PLM 이 수십억 개의 파라미터로 인해 적용하기 어려워지고 있어, 효율적인 방법에 관심이 늘어나고 있다. 본 연구는 task 당 추가 파라미터를 적은 수로만 학습하여 full finetuning 과 비슷한 성능 달성을 목표 Prompt tuning (PT) 는 tunable continuous prompt vectors 를 앞에 덧붙여, PLM 에 parameter-efficient transfer learning 하는 approach 가 등장 PT 는 PLM 파라미터를 고정하고 task-specific prompt vectors 만 학습 여전히 full finetuning 과 큰 격차라 존재 초기화에 민감하며 때로는 full finetuning 보다 많은 훈련 시간 필요 최근 이 문제를 해결하기 위해 다양한 tasks 에 transferring prompt vectors 를 제안 multiple source tasks 에 soft prompt 훈련 이 pre-trained prompt 를 사용하여, similarity measure 를 기반으로 target task 에 더 많이 finetuning 하기 위해 prompt 를 초기화 (Fig 1. Top) 본 논문에선 이 연구 방향을 확장하여 multitask prompt tuning (MPT) 소개 multitask data 를 사용하여 target task 에 효율적으로 transfer 할 수 있는 single prompt 학습 shared prompt space 학습은 서로 다른 task 간의 공통점을 학습하고 간섭 최소화가 필요하여 힘듬 저자는 각 task 의 soft prompt (prompt matrix) 를 shared matrix 와 low-rank task-specific matrix 의 곱으로 분해 이 분해는 shared prompt matrix 보다 효과적임을 발견 이 분해는 일반적인 prompt tuning 에서 얻은 soft prompt 로 부터 knowledge distillation 을 통해 학습 new task 에 transfer 하기 위해, shared prompt matrix 에 low-rank multiplicative updates 수행 (Fig. Bottom) 23 task 에 실험 결과, 저자의 approach 가 SOTA prompt transfer 보다 효과적임을 입증 SuperGLUE 에 T5-Base 를 사용한 MPT 는 vanilla PT 를 16.3% 개선 multitask prompt transfer baseline (ATTEMPT) 보다 훨씬 적은 task-specific prompt parameter (77.6K vs 232K) 로 더 나은 성능 일부 벤치마크에 MPT 가 full finetuning 을 능가하는 경우 존재하며, task 당 0.035% 의 tunable parameter 만 필요 MPT 가 각 target task 에 4-32 label 로 수행하는 few-shot learning 에 효과적임을 발견","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1230,"t":"adapter 및 그 변형들은 trainable layers 를 삽입 BitFit 은 bias parameter 만 업데이트 Diff pruning 및 FISH 은 original PLM 와 sparse update 하게 학습 prompt tuning 은 input 앞에 붙인 soft prompt vectors 만 업데이트 generation task 에 대한 continuous prompts 최적화인 Prefix-tuning UNIPELT 는 gating 메커니즘으로 다양한 tuning 방법을 결합하여 학습 HyperPrompt 는 task-specific information 을 조건부화하여 prompt 생성 LST 는 ladder side network 로 parameter-efficient tuning 의 training memory 를 줄인다 Discrete prompt 는 많은 케이스에서 효율성을 보인다 저자는 prompt 의 transferability 에 더 관련 (Transprompt, SPoT, [On transferability of prompt tuning for natural language processing]) 있으며, 많은 task 에 걸친 prompt tuning 의 성능을 향상시키는데 중점 둠 Spot 는 similarity measure 을 통해 하나의 prompt 를 선택 ATTEMP 는 target task 데 대한 prompt 초기화를 위해 source prompt 에 대한 attention 메커니즘 저자는 위와 달리, source prompt 를 분해하여, knowledge distillation 으로 다양한 target task 에 효율적으로 adaptation 하기 위해 single shared prompt 학습","s":"Parameter-efficient transfer learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#parameter-efficient-transfer-learning","p":1222},{"i":1232,"t":"Multitask learning : single model 로 multiple related tasks 를 동시에 해결하는데 초점 둠 multiple source tasks 에서 finetuned model 을 다른 target task 로 transfer massive multitask learning 을 통해 LM 의 zero-shot 및 few-shot 능력 보여줌 specific parameter-sharing 전략을 설계하는 것 또한 multitask learning 의 최근 동향 저자의 approach 는 LM 의 parameter-efficient adaption 을 위한 multitask prompt transfer 에 중점","s":"Multitask learning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#multitask-learning","p":1222},{"i":1234,"t":"knowledge distillation 은 많은 task 에서 성능 및 효율성 향상에 사용 model compression, transfer learning, machine translation, question answering 및 document retrieval 등 포함 PANDA 는 similarity measure 로 하나의 source task 에서 target task 로 transfer 하는데 초점 저자의 MPT approach 는 prompt transfer 을 위해 multitask learning 을 활용하여 task 간의 cross-task knowledge 를 활용","s":"Knowledge distillation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#knowledge-distillation","p":1222},{"i":1236,"t":"Given: source tasks S={S1,S2,…,Sk}\\pmb{\\mathcal{S}} = \\{ \\mathcal{S}_1, \\mathcal{S}_2, \\dots, \\mathcal{S}_k \\}SS={S1​,S2​,…,Sk​} target tasks T={T1,T2,…,TT}\\pmb{\\mathcal{T}} = \\{ \\mathcal{T}_1, \\mathcal{T}_2, \\dots, \\mathcal{T}_\\mathcal{T} \\}TT={T1​,T2​,…,TT​} 저자의 목표는 각 task Ti\\mathcal{T}_iTi​ 가 adapt 될 수 있는 single soft prompt S\\mathcal{S}S 를 학습하는 것 Simply, S\\pmb{\\mathcal{S}}SS 에서 single soft prompt 학습 그 후, 각 Ti\\pmb{\\mathcal{T}}_iTTi​ 에 finetuning 하지만 finetuning 은 sub-optimal 이며, source task 의 공통적인 특징을 활용하지 못하면서, 동시에 간섭을 최고화하기 어렵기 때문 이를 위해, MPT 는 knowledge distillation 를 통해 S\\pmb{\\mathcal{S}}SS 의 task-shared knowledge 를 single prompt matrix ϕS\\pmb{\\phi_\\mathcal{S}}ϕS​ϕS​ 로 압축하여, T\\pmb{\\mathcal{T}}TT 의 성능을 향상시키고 transfer learning 에 덜 유용한 task-specific information 걸러냄","s":"3. Approach","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1238,"t":"Given: pre-trained LM with parameter θ\\thetaθ one target task T\\pmb{\\mathcal{T}}TT with training data (X,Y)={xi,yi}i=1N(X,Y) = \\{x_i, y_i\\}^N_{i=1}(X,Y)={xi​,yi​}i=1N​ standard approach 모든 parameter 를 바로 finetuning 하여 conditional probability P(Y∣X;θ)P(Y|X; \\theta)P(Y∣X;θ) 최대화 target tasks T\\pmb{\\mathcal{T}}TT group 을 고려할 때, 이 방식은 효율적이지 않을 수 있음 더 parameter-efficient 한 방법은 prompt tuning model parameter θ\\thetaθ 를 고정한 채, learnable prompt vectors (soft prompts) 의 소수를 무작위로 초기화하여 PLM 의 input embeddings 앞에 추가 공식화하면, token embedding 이 ddd 차원인 input sequence T=[t1,t2,…,tn]∈Rn×dT = [t_1, t_2, \\dots, t_n] \\in \\mathbb{R}^{n \\times d}T=[t1​,t2​,…,tn​]∈Rn×d 일 때, PT 는 동일한 차원을 가진 learnable prompt matrix P∈Rl×dP \\in \\mathbb{R}^{l \\times d}P∈Rl×d (lll 은 hyperparameter) 를 input embeddings 에 추가 그 후, 다음과 같은 loss function 으로 PPP 를 최적화 LPLM=−∑ilog⁡P(yi∣xi ; θ,P)(1)\\mathcal{L}_{PLM} = - \\sum_i \\log P (y_i |x_i \\ ; \\ \\theta, P) \\tag{1}LPLM​=−i∑​logP(yi​∣xi​ ; θ,P)(1) LM 의 input 은 [P;T]∈R(l+n)×d[P; T] \\in \\mathcal{R}^{(l+n) \\times d}[P;T]∈R(l+n)×d 위 approach 는 일부 task 및 모델엔 성공적이지만, vanilla PT 엔 가끔 성능 저하 (특히 작은 PLM) 수렴 속도도 느리며 parameter 초기화에 높은 민감도 관찰 최근 이를 해결하기 위해 multiple source tasks 에 prompt 를 training 하고, similarity measure 로 target task 의 prompt 로 초기화하는 방식을 다룸. 저자는 이를 확장하여 transfering multiple knowledge 으로 downstream target tasks T\\mathcal{T}T 로의 transfer learning 을 더 효과적이고 parameter-efficient 를 가능케 하는 framework MPT 제안","s":"Prompt tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#prompt-tuning","p":1222},{"i":1240,"t":"MPT framework 는 두 단계로 구성 source training second stage 에 재사용될 single soft prompt matrix 를 생성 구체적으로, source task 를 위한 prompt matrix 는 task-shared matrix (shared across all tasks) 와 low-rank task-specific matrix (prompt decomposition) 로 분해 분해된 task-shared/specific matrix 는 knowledge distillation 으로 학습 target adaptation 학습 후, shared prompt matrix 는 low-rank multiplicative update 를 통해 downstream target task 에 adapt","s":"3.1 Multitask prompt tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#31-multitask-prompt-tuning","p":1222},{"i":1242,"t":"prompt decomposition 목표 : source task S\\mathcal{S}S 간의 knowledge sharing 을 효율적으로 가능하게 하면서, 각 task 의 고유 parameters 를 유지하여 task-specific knowledge 를 인코딩할 수 있게 하는 것 kkk-th task 를 위한 soft prompt PkP_{k}Pk​ 를 두 부분으로 나눔 (Fig 3 참고) P∗∈Rl×dP^* \\in \\mathbb{R}^{l \\times d}P∗∈Rl×d : shared prompt across all tasks uk∈Rl,vk∈Rdu_k \\in \\mathbb{R}^l, v_k \\in \\mathbb{R}^duk​∈Rl,vk​∈Rd : 각 task kkk 에 대한 task-specific vectors task-specific vectors 는 rank-one matrix Wk=uk⨂vkTW_k = u_k \\bigotimes v_k^TWk​=uk​⨂vkT​ 으로 형성 WkW_kWk​ 는 shared prompt P∗P^*P∗ 와 동일한 차원 kkk-th source task 에 대한 task prompt P^\\hat{P}P^ 는 다음과 같이 매개변수화 함 P^=P∗∘Wk=P∗∘(uk⨂vkT)(2)\\hat{P} = P^* \\circ W_k = P^* \\circ (u_k \\bigotimes v_k^T) \\tag{2}P^=P∗∘Wk​=P∗∘(uk​⨂vkT​)(2) ∘\\circ∘ : hadamard product 위의 prompt decomposition 의 매개변수화는 low-rank method 에 영감을 받음 source task set 에 걸친 \"slow\" weight P∗P^*P∗ 로 일반적인 정보를 캡쳐 \"fast\" weight WkW_kWk​ 는 low-rank subspace 에서의 Sk\\mathcal{S}_kSk​ 에 대한 task-specific knowledge 를 인코딩","s":"Prompt decomposition","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#prompt-decomposition","p":1222},{"i":1244,"t":"multitask dataset S\\mathcal{S}S 에 직접 prompt decomposition 를 학습하면 shared component P∗P^*P∗ 가 큰 task 에 과적합하는 경향 있음 이에 좋은 decomposable prompt 를 학습하기 위해 효과적인 전략으로, 별도로 훈련된 source prompt 로 knowledge distillation 을 발견 일반적인 prompt tuning 으로 kkk-th source task 에 대한 teacher prompt Pk(teacher)P_k^{(teacher)}Pk(teacher)​ 을 얻음 상응하는 student prompt P^k=P∗∘(uk⨂vkT)\\hat{P}_k = P^* \\circ (u_k \\bigotimes v_k^T)P^k​=P∗∘(uk​⨂vkT​) 을 무작위로 초기화 모든 student prompts 는 P∗P^*P∗ 를 공유하고 위에서 설명한 대로 task-specific vecotrs 를 가짐 distillation 을 사용하여 cross-task knowledge 를 shared prompt matrix 로 transfer shared prompt matrix P∗P^*P∗ 및 task-specific parameters uku_kuk​ 와 vkv_kvk​ 에 대한 KL-Divergence 를 최소화하여 student 와 teacher 의 output probability distributions 를 일치시키기 위한 first loss 계산 LLogit=∑k∈S∣∑(xi,yi)∈SkKL [ P(yi∣xi ; θ,Pk(teacher))∣∣P(yi∣xi ; θ,P^k) ](3)\\mathcal{L}_{Logit} = \\sum_{k \\in \\mathcal{S} |} \\sum_{(x_i, y_i) \\in \\mathcal{S_k}} KL \\ [ \\ P ( y_i | x_i \\ ; \\ \\theta, P_k^{(teacher)}) || P (y_i | x_i \\ ; \\ \\theta, \\hat{P}_k) \\ ] \\tag{3}LLogit​=k∈S∣∑​(xi​,yi​)∈Sk​∑​KL [ P(yi​∣xi​ ; θ,Pk(teacher)​)∣∣P(yi​∣xi​ ; θ,P^k​) ](3) teacher 및 student model 의 output distribution 의 smoothness 를 제어하기 위해 temperature TTT 사용 pj=1Zexp⁡(zj/T)p_j = \\frac{1}{Z} \\exp (z_j/T)pj​=Z1​exp(zj​/T) ziz_izi​ : class jjj 에 대한 logit score ZZZ : normalization 요소 또한 teacher model 의 hidden states 에 mean squared loss 추가 LHidden=∑k∈S∣∑(xi,yi)∈Sk ( Hk,i−Hk,i(teacher) )2(4)\\mathcal{L}_{Hidden} = \\sum_{k \\in \\mathcal{S} |} \\sum_{(x_i, y_i) \\in \\mathcal{S_k}} \\ ( \\ H_{k,i} - H_{k,i}^{(teacher)} \\ )^2 \\tag{4}LHidden​=k∈S∣∑​(xi​,yi​)∈Sk​∑​ ( Hk,i​−Hk,i(teacher)​ )2(4) Hk,i(teacher)H_{k,i}^{(teacher)}Hk,i(teacher)​ 및 Hk,iH_{k,i}Hk,i​ ; 각각 teacher 및 student networks 의 hidden states iii-th input 에 대한 hidden vector 의 sequence 로 구성 intermediate states 에서의 추가적인 distillation loss 은 PLMs 에 distilling 한 결과, 개선된 것을 보여줌 target 측면으로 transfer 할 single shared prompt 를 얻기 위한 student source prompts 를 training 하는 데 사용되는 total loss function 은 다음과 같다. LTotal=LPLM+λ(LLogits+LHidden)(5)\\mathcal{L}_{Total} = \\mathcal{L}_{PLM} + \\lambda ( \\mathcal{L}_{Logits} + \\mathcal{L}_{Hidden} ) \\tag{5}LTotal​=LPLM​+λ(LLogits​+LHidden​)(5) LPLM=∑k∈∣S∣LPLMk\\mathcal{L}_{PLM} = \\sum_{k \\in |\\mathcal{S}|} \\mathcal{L}_{PLM}^kLPLM​=∑k∈∣S∣​LPLMk​ : all source tasks 에 대해 집계된 task losses λ\\lambdaλ : distillation loss 의 영향을 균형잡기 위한 가중치","s":"Prompt distillation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#prompt-distillation","p":1222},{"i":1246,"t":"target tasks 로의 transfer 할 single source prompt 의 training 에는 2 단계 필요 all source tasks 에 대한 teacher prompts 를 vanilla prompt tuning 으로 개별적 pre-training S={S1,…,Sk}\\mathcal{S} = \\{S_1, \\dots,S_k \\}S={S1​,…,Sk​} 에서 multitask training 수행하여 Eq 5 의 knowledge distillation loss function 으로 single shared prompt 를 공통적으로 학습 간단한 stochastic tasks sampling 전략을 채용하여, batch 당 task 수를 동적으로 변경 multitask samples 의 각 batch 에 대해, 먼저 [2,k][2, k][2,k] 에서 KKK 수를 무작위로 선택 S\\mathcal{S}S 에서 KKK 개의 tasks 를 무작위로 선택 해당 samples 를 mini-batches 로 구성 target adaptation 의 경우 target task Tt\\mathcal{T}_tTt​ 에 대한 target prompt 를 shared prompt matrix 와 task-specific low-rank prompt matrix 의 Hadamard product 로 초기화 i.e. P^t=P∗∘(ut⨂vtT)\\hat{P}_t = P^* \\circ (u_t \\bigotimes v_t^T)P^t​=P∗∘(ut​⨂vtT​) P∗P^*P∗, utu_tut​, vtv_tvt​ 에 대한 Eq 1 의 regular task loss 를 최적화 P∗P^*P∗, utu_tut​, vtv_tvt​ 각각 별도의 learning rate 를 사용 MPT 또한 target tasks T={T1,T2,…,TT}\\pmb{\\mathcal{T}} = \\{ \\mathcal{T}_1, \\mathcal{T}_2, \\dots, \\mathcal{T}_{\\mathcal{T}} \\}TT={T1​,T2​,…,TT​} 의 group 에서 multitask learning 에 사용될 수 있음 이 경우 P∗P^*P∗ 는 T\\mathcal{T}T 전체에 공유됨","s":"3.2 Source Training And Target Adaptation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#32-source-training-and-target-adaptation","p":1222},{"i":1248,"t":"각 task 에는 vanilla soft prompt 와 동일한 차원을 가지는 shared prompt l×dl \\times dl×d 와 더 적은 수의 task-specific vecotrs (l×d)(l \\times d)(l×d) 를 포함 → single target task 에 대한 tunable parameters 의 total number 는 (l×d)+(l×d)(l \\times d) + (l \\times d)(l×d)+(l×d) → training 후, 이를 l×d2l \\times d^2l×d2 사이즈의 single matrix 로 압축 가능 target task group 의 경우 tunable parameter 의 total number : (l×d)+(l×d)τ(l \\times d) + (l \\times d)\\tau(l×d)+(l×d)τ τ\\tauτ : target tasks number Table 1 에서 trainable parameter 의 수를 기준으로 비교","s":"Parameter-efficiency","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#parameter-efficiency","p":1222},{"i":1250,"t":"다양한 범위의 NLP dataset 에서 MPT 가 강력한 baseline 을 이기는 것을 보여줌 full-datset (Table 1, 2) few-shot (Table 3, 4) 기존 방법들보다 parameter-efficient","s":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1253,"t":"MPT 평가를 위해 100k 개 이상의 annotations 가 있는 6개 데이터셋을 source task 로 사용 MNLI QNLI QQP SST-2 SQuAD ReCoRD 4개 벤치마크의 23개 데이터셋를 target task 로 사용 SuperGLUE : MultiRC, BoolQ, WiC, WSC 및 CB GLUE : RTE, CoLA, STS-B, MRPC, MNLI, QQP, QNLI 및 SST-2 MRQA : Natural Questions, HotpotQA, NewsQA 및 SearchQA Others : WinoGrande, Yelp-2, SciTail 및 PAWS-Wiki generation task 의 adapting 을 위한 E2E 및 WebNLG","s":"Datasets and tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#datasets-and-tasks","p":1222},{"i":1255,"t":"prompt tuning 의 standard approach 를 따라, 주로 220M parameters 를 가진 공개된 pretrained T5-Baase 를 사용. 모든 벤치마크에 대해 100개의 prompt vectors 사용 (따라서, P^k∈R100×d\\hat{P}_k \\in \\mathbb{R}^{100 \\times d}P^k​∈R100×d) 저자의 ablation study 에서는 T5-Small (60M) 및 T5-Large (770M) 모델도 고려","s":"Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#models","p":1222},{"i":1257,"t":"MPT 를 다음 baselines 와 비교 Full finetuning (FT) : 모든 model parameters 를 각 downstream task 에 adaptation 하면서 tuning Vanilla prompt tuning (PT) : target prompt vectors 는 top vocabularies 를 무작위로 sample 하여 초기화 SPoT 및 ATTEMPT 를 포함하는 prompt transfer method : source prompts 검색 또는 집계하여 target prompts 초기화 Adapters 및 BitFit 을 포함하는 parameter-efficient method","s":"Baseline","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#baseline","p":1222},{"i":1259,"t":"source training 의 경우 examples-proportional mixing 전략 및 stochastic task sampling 을 사용하여 5 epochs 동안 MPT 를 source tasks 의 mixture 에서 훈련 prompt distillation 의 경우 T5 의 encoder 및 decoder 의 hidden states 에 대한 loss 계산 target adaptation 의 경우 MPT 의 shared prompt 를 재사용 target task-specific vector 를 초기화하기 위해 MPT 의 source task-specific 평균을 사용 모든 실험을 서로 다른 seed 로 세 번 실행하고 평균과 표준편차 보고 few-shot 실험에서는, 각 shot 수 kkk 에 대해 서로 다른 무작위 seed 로 training set 을 10번 샘플링하고 평균 성능 보고","s":"Implementation details","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#implementation-details","p":1222},{"i":1262,"t":"Table 1 (top) MPT 는 parameter-efficient finetuning 에 대해 SOTA 결과 보여줌 Table 1 (bottom) 더욱 parameter-efficient 측면으로 매우 큰 잠재력을 보임 Table 2 PT 에 비해 상당한 향상 프롬프트 길이 100 에서 300 으로 증가시키면 Adapters 와의 성능 차이를 줄이고, parameter-efficient 결과를 보임","s":"Full-dataset adaptation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#full-dataset-adaptation","p":1222},{"i":1264,"t":"few training examples (kkk = 4, 16, 32) 만 사용 가능한 new tasks 에 어떻게 일반화되는지 측정하기 위해 BoolQ, CB 및 SciTail 에 few-shot 실험 Table 3 MPT 는 PT 및 SPoT 모두 능가 다른 method 들도 few-shot learning 에서 어려움을 겪고 있음 Table 4 MPT 가 대부분의 dataset 에서 Vanilla PT 를 큰 폭으로 능가 위 결과는 source task 에서 target task 로 효과적으로 활용함을 보여줌","s":"Few-shot adaptation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#few-shot-adaptation","p":1222},{"i":1266,"t":"NLU task 에서 학습한 prompt decomposition 이 target NLG task 로 일반화되는지 테스트 6가지의 source task 를 사용하여 pre-trained T5-Large prompt 를 두 가지 NLG task 인 E2E 및 WebNLG 에 transfer Table 5 MPT 가 모든 metric 에서 PT 보다 큰 폭으로 우수한 성능 NLU 및 NLG 양쪽에서 효과적임 이는 source task 가 NLU task 임에도 NLG task 로의 knowledge transfer 가 효과적임을 나타냄","s":"Natural language generation tasks","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#natural-language-generation-tasks","p":1222},{"i":1268,"t":"3가지 SuperGLUE task 에서 pre-trained model 크기를 증가시키면서 MPT 성능 분석 Figure 4 (왼쪽) MPT 및 full finetuning (FT), Adapter, PT 및 ATTEMPT 를 사용한 세 가지 서로 다른 T5 model 의 성능을 보여줌 MPT 가 SOTA parameter-efficient 를 달성 60M ~ 770M parameter 전 범위의 model scaling 에서 효과적임","s":"Model scaling","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#model-scaling","p":1222},{"i":1270,"t":"MPT 를 사용하여 학습한 prompt 를 분석하고 cross-task knowledge 가 실제로 task-shared prompt 에 인코딩되어 target task 에 효과적으로 adapt 되는지, 자체 knowledge 를 인코딩하여 분석 target task 의 모든 pairs 간의 cosine similarity 를 계산하기 위해 prompt metrices 사용 각 ㅅask 는 task-shared 및 task-specific prompt 의 조합으로 표현 (single vector 를 얻기 위해 평균화) Figure 4 (오른쪽) SPoT 및 MPT 의 cosine similarity matrix 를 시각화 task embeddings 가 유사한 task 를 효과적으로 클러스터링 하는 것 발견","s":"Analyzing prompt metrices","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#analyzing-prompt-metrices","p":1222},{"i":1273,"t":"모든 hyperparameter 를 고정하고 MPT source training 을 재실행하여 transfer 된 prompt 의 여러 버전을 실험 prompt decomposition 효과 측정을 위해 source prompt 를 task-shared 및 task-specific components 로 구성된 decomposable prompt 로 대체하고 prompt distillation 없이 훈련 첫 번째 행에 비해 3.5% 성능 향상 MPT 의 prompt decomposition 의 중요성을 보여줌 shared component 가 target downstream task 에 유용한 cross-task knowledge 를 효과적으로 캡쳐하는 것을 보여줌 prompt distillation 효과 측정을 위해 모든 source task 에서 동일한 training loss 를 갖는 일반적은 prompt 를 훈련 첫 번째 행에 비해 1.1% 향상 prompt decomposition 과 결합하면 74.1% 성능 달성 따로 훈련된 source prompt 에서 knowledge 를 추출하는 것이 좋은 decomposable prompt 를 학습하기 위한 효과적인 전략임을 보여줌","s":"Prompt decomposition and distillation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#prompt-decomposition-and-distillation","p":1222},{"i":1275,"t":"prompt distillation 의 개별 component 를 조사하여 최종 성능에 미치는 영향 측정 Eq 5 의 hidden state loss 를 제거하고 이로 인해 SuperGLUE 에서 73.7% 성능을 얻음을 확인 logits 과 함께 hidden states 를 정규화하여 전체 성능에 도달하는 효과 검증 teacher 및 student prompt 간의 distance 최소화를 위해 loss 에 MSE loss 추가하여 두 prompt 를 일치시크는 distillation loss 변형 distillation loss 를 distance loss 로 대체하여 SuperGLUE 에서 73.6% 도달 logits 및 hidden state 기반의 distillation loss 보다 성능이 떨어짐","s":"Distillation objective","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#distillation-objective","p":1222},{"i":1277,"t":"논문의 실험들은 l=100l = 100l=100 prompt vectors 를 사용 Fig 5 에서 보이듯, 더 긴 prompt 를 사용하면 l=300l = 300l=300 까지 개선 가능하며, 더 늘리면 정확도가 감소하게 되어 오버피팅이 발생","s":"Prompt length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#prompt-length","p":1222},{"i":1279,"t":"source 에서 target task 로 shared prompt 를 transfer 할 때, task-shared component 만 업데이트하는 경우 (즉, task-specific vectors 제거) 또는 task-specific vectors 만 업데이트하는 경우 (즉, task-shared component 를 freezing) 결과가 부적절 (SuperGLUE 에 각각 62.5% 및 71.3%) 이는 target adaptation 을 위한 두 component 의 중요성을 보여줌","s":"Target adaptation strategy","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#target-adaptation-strategy","p":1222},{"i":1281,"t":"stochastic task sampling 제거 시, SuperGLUE 에서 73.7% 결과 (낮은 성능) 이는 multitask training 전략에서 이점을 보임","s":"Stochastic task sampling","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#stochastic-task-sampling","p":1222},{"i":1283,"t":"주요 실험은 6 개의 NLP task 에 추가적인 다양한 source task 를 포함하여 총 12개의 source task 통합 topic classification, multi-choice QA, OpenBookQA, ARC, adversarial NLI 및 commonsense reasoning 포함 Table 7 12 개의 task 를 사용하는 MPT 는 여전히 target adaptation 에 효과적 6 개의 task 를 사용한 MPT 보다 약간 우수한 성능","s":"Number of source tasks for pretraining","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"#number-of-source-tasks-for-pretraining","p":1222},{"i":1285,"t":"Multitask Prompt Tuning 연구 결과 다음과 같다. multiple source task 및 task-specific source prompt 에서 knowledge 를 decomposition 하고 distillation 하여 single transferable prompt 를 학습 task prompt 를 shared prompt matrix 와 rank-one task-specific matrix 를 Hadamard product 하여 decomposition shared component 가 target task 로 transfer 및 adapt 하여 tuning 실험 결과 다양한 NLP 벤치마크에서 target downstream task 로의 parameter-efficient transfer learning 이 가능 경우에 따라 훨씬 적은 task-specific parameter 로 tuning 하여 full finetuning 능가","s":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Multitask Prompt Tuning","h":"","p":1222},{"i":1287,"t":"논문 및 이미지 출처 : https://aclanthology.org/2021.acl-long.353.pdf","s":"Prefix-Tuning: Optimizing Continuous Prompts for Generation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1289,"t":"Fine-tuning (FT) 는 large pre-trained language models 를 downstream task 에 활용하는 표준 방법이다. 하지만 FT 는 language model (LM) parameter 를 수정하고 각 task 에 대한 full copy 를 저장해야 한다. 본 논문에선 natural language generation (NLG) tasks 에 대한 FT 의 경량적 대안인 prefix-tuning 를 제안 prefix-tuning 는 LM parameter 를 freezing 하는 대신 continuous task-specific vectors 의 sequence 인, prefix 를 최적화 LM prompting 에서 영감을 받아 subsequent tokens 가 이 prefix 를 \"virtual tokens\" 처럼 참조할 수 있게함 저자는 prefix-tuning 을 table-to-text generation 을 위해 GPT-2 에 적용하고 요약을 위해 BART 에 적용 0.1% parameter 만 수정함으로써, prefix-tuning 은 full data 설정에서 동등한 성능 및 low-data 설정에서 FT 를 능가하며, training 중 unseen topics 를 가진 examples 를 더 잘 추론","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1291,"t":"Fine-tuning (FT) 은 large pre-trained language model 을 사용하여 donwstream task (e.g. summarization) 를 수행하는 주요 패러다임. 하지만 FT 는 LM 의 모든 parameter 를 update 하고 저장해야 하므로 각 task 마다 수정된 모든 LM parameter 의 copy 를 저장해야 한다. 현재 LM 크기를 고려하면 비용이 매우 많이 든다. 예로, GPT-2 는 774M parameter, GPT-3 는 175B parameter 를 가지고 있다. 이 문제를 lightweight fine-tuning 으로, pre-trained LM 대부분의 parameter 를 freezing 하고 smaller parameter set 만 tuning 하는 것이다. 예로, adapter-tuning 은 pre-trained LM 의 layers 사이에 additional task-specific layers 를 삽입한다. adapter-tuning 은 NLU 및 NLG 에서 유망한 성능을 보이며 FT 와 유사한 성능을 달성하여 약 2-4% 정도의 task-specific parameter 를 추가한다. 극단적으로 GPT-3 는 어떠한 LM parameter 도 수정하지 않고 in-context learning 을 사용하여 배포 가능하다. in-context learning 은 prompting 의 한 형태로, natural language task instruction 와 몇 가지 예제를 task input 에 먼저 추가한 다음 LM 에서 task output 생성. 하지만 Transformer 는 제한된 길이의 context (GPT-3 의 경우 2048) 에만 의존할 수 있어, in-context learning 은 매우 작은 훈련셋으로 제한된다. 본 논문에서는 prompting 에 영감을 받은 lightweight FT 인 prefix-tuning 을 제안 task input 은 linearized table (e.g. \"name: Starbucks | type: coffee shop\") 이며 output 은 text description (예: \"Starbucks serves coffee\") Prefix-Tuning 은 input 에 continuous task-specific vectors sequence 인 prefix 를 앞에 추가 이 prefix 는 Figure 1 (아래) 에 빨간 블록으로 표시 각 토큰 생성 시, LM 은 prefix 에 참조할 수 있으므로 prefix 가 \"virtual token\" sequence 처럼 작동하지만 prefix 는 실제 토큰과 대응하지 않는 free parameter 로만 구성 반면 Figure 1 (위) 의 FT 는 모든 LM parameter 를 update 하고 각 task 마다 tuned model 의 copy 를 저장해야 함 결과적으로, 저자는 LLM 과 learned task-specific prefix 의 copy 만 저장하면 되므로 각 additional task 에 대한 매우 작은 overhead 발생 (e.g. 250K parameter for table-to-text)","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1294,"t":"input xxx 가 context 고 output yyy 가 token sequence 인 조건부 생성 작업을 고려 Figure 2 (오른쪽)에 나와 있는 두 가지 작업에 중점을 둔다. table-to-text 에서, xxx 는 linearized data table 에 해당하고 yyy 는 text description 이다. summarization 에서, xxx 는 article 이고 yyy 는 summary 이다.","s":"3. Problem Statement","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"","p":1286},{"i":1296,"t":"ϕ\\phiϕ (e.g. GPT-2) 에 의한 parameterized autoregressive neural language model pϕ(y ∣ x)p_{\\phi}(y\\ |\\ x)pϕ​(y ∣ x) 가 있다고 가정하자. Figure 2 (위)에 있는 것 처럼, z=[x;y]z = [x; y]z=[x;y] 으로, xxx 와 yyy 의 연결 Xidx\\text{X}_{\\text{idx}}Xidx​ 는 xxx 에 해당하는 indices sequence 로 나타냄 Yidx\\text{Y}_{\\text{idx}}Yidx​ 도 yyy 에 대해 동일하게 적용 iii time step 에서의 activation vector 는 hi∈Rdh_i \\in \\mathbb{R}^dhi​∈Rd 여기서 hi=[hi(1);⋯ ;hi(n)]h_i = [h_i^{(1)}; \\cdots; h_i^{(n)}]hi​=[hi(1)​;⋯;hi(n)​] 은 이 time step 의 all activation layers 를 연결 hi(j)h_i^{(j)}hi(j)​ 는 time step iii 에서의 jjj-th layer 의 activation vector autoregressive neural LM 은 다음과 같이 left context 에서 ziz_izi​ 와 past activations 의 function 으로 hih_ihi​ 계산 hi=LMϕ(zi,h<i),\\begin{equation} h_i = \\text{LM}_{\\phi} (z_i, h_{<i}), \\end{equation}hi​=LMϕ​(zi​,h<i​),​​ hih_ihi​ 의 last layer 는 next token: pϕ(zi+1 ∣ h≤i)=softmax(Wϕhi(n))p_{\\phi}(z_{i+1}\\ |\\ h_{\\leq i}) = \\text{softmax}(W_{\\phi} h_i^{(n)})pϕ​(zi+1​ ∣ h≤i​)=softmax(Wϕ​hi(n)​) 의 distribution 계산을 위해 사용 WϕW_{\\phi}Wϕ​ 는 hi(n)h_i^{(n)}hi(n)​ 를 vocabulary logits 으로 매핑하기 위한 행렬","s":"3.1 Autoregressive LM","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#31-autoregressive-lm","p":1286},{"i":1298,"t":"pϕ(y ∣ x)p_{\\phi}(y\\ |\\ x)pϕ​(y ∣ x) 모델링을 위해 encoder-decoder architecture (e.g. BART) 를 사용할 수 있다. xxx 는 bidirectional encoder 에 의해 인코딩된 것 decoder 는 yyy 를 autoregressively predict (encoded xxx 및 left context 에 조건을 둔 상태) 동일한 indexing 및 activation notation 은 Figure 2 (아래) 와 같이 표시 i∈Xidxi \\in \\text{X}_{\\text{idx}}i∈Xidx​ 는 bidirectional encoder 에 의해 계산 i∈Yidxi \\in \\text{Y}_{\\text{idx}}i∈Yidx​ 에 대한 각 hih_ihi​ 는 Eq. 1 을 사용하여 autoregressive decoder 로 계산","s":"3.2 Encoder-Decoder Archirecture","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#32-encoder-decoder-archirecture","p":1286},{"i":1300,"t":"full FT 에서, 저자는 pre-trained parameter ϕ\\phiϕ 를 초기화한다. 여기서 pϕp_{\\phi}pϕ​ 는 trainable LM distribution 이며, 다음 log-likelihood objective 를 따라 gradient update 를 수행한다. max⁡ϕ log⁡pϕ(y ∣ x)=max⁡ϕ∑i∈Yidxlog⁡pϕ(zi ∣ h<i).\\begin{equation} \\underset{\\phi}{\\max}\\ \\log p_{\\phi}(y\\ |\\ x) = \\underset{\\phi}{\\max} \\sum_{i \\in \\text{Y}_{\\text{idx}}} \\log p_{\\phi} (z_i\\ |\\ h_{<i}). \\end{equation}ϕmax​ logpϕ​(y ∣ x)=ϕmax​i∈Yidx​∑​logpϕ​(zi​ ∣ h<i​).​​","s":"3.3 Fine-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#33-fine-tuning","p":1286},{"i":1303,"t":"Prompting 은 parameter 를 변경하지 않고 LM 을 조절할 수 있는 적절한 context 에 조건을 둔다. 예로 LM 이 word (e.g. Obama) 를 생성하길 원하면, 해당 단어의 일반적인 공존어를 context 로 추가할 수 있으며 (e.g. Barack), LM 은 원하는 단어에 훨씬 더 높은 확률을 할당한다. single word 나 sentence 생성을 넘어, 이러한 intuition 을 확장하여 LM 을 NLG task 를 해결하도록 조절하는 context 를 찾기를 원한다. context 는 task input xxx 에서 추출할 내용을 가이드함으로써 task input xxx 의 인코딩에 영향을 미칠 수 있다. next token distribution 을 조절함으로써 task output yyy 의 생성에도 영향을 미칠 수 있다. 하지만 위같은 context 가 존재하는지 명백하지 않으며, natural language task instruction (e.g. \"summarize the following table in one sentence\") 를 사용하면 context 가 task 를 해결하도록 인간을 가이드할 수 있지만, 중간 규모의 pre-trained LM 에서는 실패한다. discrete instruction 최적화는 도움 될 수 있지만, computationally challenging discrete token 최적화 대신, instruction 을 저자는 continuous word embeddings 로 최적화할 수 있으며, 그 효과는 all Transformer activation layers 로 propagated upward 되고 subsequent token 으로 rightward 된다. 이는 실제 단어의 embeddings 로 제한되는 discrete prompt 보다 표현력이 높다. Prefix-tuning 은 표현력을 높이는데서 더 나아가 all activation layers 를 최적화함으로써 나아간다. 다른 이점으로는 network depth 에 따라 long computation paths 를 피하기 위해 representations 를 직접 수정할 수 있다.","s":"4.1 Intuition","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#41-intuition","p":1286},{"i":1305,"t":"Prefix-Tuning 은 autoregressive LM 에 prefix 를 덧붙여 z=[PREFIX;x;y]z = [\\text{PREFIX}; x; y]z=[PREFIX;x;y] 를 얻거나 encoder 및 decoder 모두에 prefix 를 덧붙여 z=[PREFIX;x;PREFIX′;y]z = [\\text{PREFIX}; x; \\text{PREFIX}'; y]z=[PREFIX;x;PREFIX′;y] 을 얻는다. (Fig 2 참조) 여기서, Pidx\\text{P}_{\\text{idx}}Pidx​ 는 prefix indices 의 sequence ∣Pidx∣|\\text{P}_{\\text{idx}}|∣Pidx​∣ 는 prefix length Eq. 1 의 recurrence relation 을 따르되, prefix indices 의 activation 은 free parameter 이며, dimension ∣Pidx∣×dim(hi)|\\text{P}_{\\text{idx}}| \\times \\text{dim}(h_i)∣Pidx​∣×dim(hi​) 의 matrix Pidx\\text{P}_{\\text{idx}}Pidx​ (θ\\thetaθ 에 의해 parameterized) 에 의해 주어진다. hi={Pθ[i,:],ifi∈PidxLMϕ(zi,h<i),otherwise.\\begin{equation} h_i = \\left\\{\\begin{matrix} P_\\theta [i, :], & \\text{if} i \\in \\text{P}_{\\text{idx}} \\\\ \\text{LM}_{\\phi}(z_i, h_{<i}), & \\text{otherwise.} \\end{matrix}\\right. \\end{equation}hi​={Pθ​[i,:],LMϕ​(zi​,h<i​),​ifi∈Pidx​otherwise.​​​ training objective 는 Eq. 2 와 동일하게 하지만 trainable parameters set 은 변경한다. LM parameters ϕ\\phiϕ 는 고정되고 prefix parameters θ\\thetaθ 만 trainable parameters 이다. 여기서 각 hih_ihi​ 는 trainable PθP_\\thetaPθ​ 의 function 이다. i∈Pidxi \\in \\text{P}_{\\text{idx}}i∈Pidx​ 인 경우 hih_ihi​ 는 PθP_\\thetaPθ​ 로 직접 copy 되기 때문에 clear 하다. i∉Pidxi \\notin \\text{P}_{\\text{idx}}i∈/Pidx​ 인 경우 prefix activation 은 항상 left context 에 있으며 right activation 에 어떠한 영향을 미칠 것이기 때문에 hih_ihi​ 는 여전히 PθP_\\thetaPθ​ 에 의존적이다.","s":"4.2 Method","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#42-method","p":1286},{"i":1307,"t":"PθP_\\thetaPθ​ 를 직접적으로 update 하는 것은 불안정한 최적화와 약간의 성능 저하를 유발 따라서 저자는 smaller matrix (Pθ′P'_\\thetaPθ′​) 로 large feedforward neural network MLPθ\\text{MLP}_\\thetaMLPθ​ 를 포함한 reparameterized matrix Pθ[i:0]=MLPθ(Pθ′[i,:])P_\\theta [i:0] = \\text{MLP}_\\theta (P'_\\theta [i,:])Pθ​[i:0]=MLPθ​(Pθ′​[i,:]) 을 만든다. 이제 trainable parameters 는 Pθ′P'_\\thetaPθ′​ 및 MLPθ\\text{MLP}_\\thetaMLPθ​ 의 parameter 를 포함한다. PθP_\\thetaPθ​ 와 Pθ′P_\\theta'Pθ′​ 는 rows 수는 같지만 column 수가 다르다. training 이 완료되면, 이런 reparameterization parameters 를 drop 하고 prefix (PθP_\\thetaPθ​) 만 저장하면 된다.","s":"4.3 Parameterization of PθP_{\\theta}Pθ​","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#43-parameterization-of-p_theta","p":1286},{"i":1310,"t":"table-to-text task 를 위한 세 가지 generation dataset 인 E2E, WebNLG 및 DART 에서 평가 dataset 은 복잡성과 크기에 따라 정렬됨 E2E 는 레스토랑 리뷰만 1 domain WebNLG 는 14 domains DART 는 Wikipedia 의 open domain table 사용 summarization task 의 경우, 뉴스 기사에 대한 요약 데이터셋 XSUM 사용 ROUGE-1, ROUGE-2 및 ROUGE-L 을 보고","s":"5.1 Datasets and Metrics","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#51-datasets-and-metrics","p":1286},{"i":1312,"t":"table-to-text generation task 대해 prefix-tuning 을 다른 세 가지 방법과 비교 full fine-tuning (FT-FULL), top 2 layers fine-tuning (FTTOP2), adapter tuning (ADAPTER)","s":"5.2 Methods","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#52-methods","p":1286},{"i":1314,"t":"table-to-text 에 대해 GPT-2-MEDIUM 및 GPT-2-LARGE 사용 summarization task 에 대해선 BART LARGE 사용 저자의 구현은 huggingface transformers 에 기반 training 시 AdamW optimizer 및 Hugging Face 의 기본 설정에 따른 linear learning rate scheduler 사용 hyperparameter 는 epochs, batch size, learning rate 및 prefix length 들을 조정 10 epochs 5 batch size 5⋅10−55 \\cdot 10^{-5}5⋅10−5 learning rate 10 prefix length model 은 TITAN Xp 또는 GeForce GTX TITAN X 에서 훈련 Prefix-tuning 은 22,000개 examples 에 대해 epoch 당 0.2 시간 걸림 Fine-tuning 은 epoch 당 0.3 시간 걸림 summarization model 은 Telsa V100 에서 훈련 XSUM dataset 은 epoch 당 1.25 시간 걸림 prefix-tuning 은 fine-tuning 보다 약 30% 시간 효율성이 좋음 GPU 메모리 효율성에선, 1 batch size 로 하는 prefix-tuning 은 총 GPU 메모리의 10% 차지 및 fine-tuning 은 50% 차지 디코딩 시엔 table-to-text task 에 대해 beam search 사용하며 크기는 5 summarization task 에선 6 beam 과 0.8 length normalization 사용 table-to-text 의 경우, batch 처리를 하지 않고 문장 당 1.2초, summarization 의 경우엔 10 batch size 를 사용하여 배치당 2.6초가 걸림","s":"5.3 Architectures and Hyperparameters","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#53-architectures-and-hyperparameters","p":1286},{"i":1317,"t":"0.1% 의 task-specific parameter 만 update 하여, prefix-tuning 은 table-to-text generation 에서 효과적 다른 lightweight baseline (ADAPTER 및 FT-TOP2) 를 능가하며 parameter 를 30배 적게 update 하면서도 (full) FT 와 comparable prefix-tuning 과 adapter-tuning 의 parameter 수를 0.1% 로 맞추면, Table 2 에서 prefix-tuning 이 ADAPTER 보다 큰 성능을 보임 평균적으로 데이터셋 당 4.1 BLEU 개선 fine-tuning (100%) 및 adapter-tuning (3.0%) 와 비교하여 prefix-tuning 은 두 시스템과 comparable 또는 나은 성능 이는 prefix-tuning 이 adapter-tuning 보다 Pareto efficient 이며, generation quality 향상 및 parameter 를 크게 줄임 DART 에서 좋은 성능을 달성하여, prefix-tuning 이 다양한 domain 과 많은 table 에 일반화될 수 있음을 시사 요약하면, prefix-tuning 은 GPT-2 를 table-to-text generation 에 적응시키는데 효과적이고 공간 효율적인 방법. 또한 GPT-2-LARGE 로 확장하면 성능 이득을 유지하며, GPT-3 같은 아키텍처로 더 큰 모델로의 확장에서도 잠재력이 있음을 시사","s":"6.1 Table-to-text Generation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#61-table-to-text-generation","p":1286},{"i":1319,"t":"위에서 보이듯 2% parameter 로 prefix-Tuning 는 FT 보다 약간 낮다. parameter 가 0.1% 일 때, prefix-tuning 은 full FT 에 못미친다. table-to-text dataset 과 XSUM 간에는 prefix-Tuning 이 table-to-text 에서 우위를 가지는 이유는 다음 차이점이 있다. XSUM 은 평균적으로 세 개의 table-to-text dataset 보다 4배 많은 예제 포함 입력 기사에는 평균적으로 table-to-text dataset 의 linearized table input 보다 17배 김 요약에선 기사로부터 주요 내용을 선택해야 하므로 table-to-text 보다 복잡","s":"6.2 Summarization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#62-summarization","p":1286},{"i":1321,"t":"table-to-text 및 summarization 결과를 기반으로, prefix-tuning 은 training example 수가 적을 때 비교적 이점을 가짐 low-data 설정에 대해 체계적으로 탐구하기 위해 전체 데이터셋의 sub-sample 을 사용 각 크기에 대해 5개의 다른 데이터셋을 샘플링하고 2개의 훈련 랜덤 시드에서 평균을 냈다. 따라서 low-data 설정마다 10개의 모델을 평균화하였다. 위의 오른쪽은 dataset size 가 커짐에 따라 간격이 좁아지지만, low-data 에서 prefix-tuning 이 평균적으로 2.9 BLEU 더 높은 성능을 보이고 smaller parameter 가 필요하다는 것을 시사한다. 왼쪽에선 다른 데이터 수준에서 훈련된 prefix-tuning 및 fine-tuning 모델에 의해 생성된 8개의 예제이다. 두 방법 모두 low-data 설정에서 table content 가 누락되는 경향이 있지만, prefix-tuning 은 fine-tuning 보다 믿음직 스러운 경향이 있다. 예로 fine-tuning (100, 200) 은 실제 평균 고객 등급을 낮게 평가하는 반면, prefix-tuning (100, 200) 은 테이블과 일치하는 설명을 생성한다.","s":"6.3 Low-data Setting","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#63-low-data-setting","p":1286},{"i":1323,"t":"table-to-text 및 summarization 의 unseen topic 으로 extrapolation 성능 조사 extrapolation 설정을 위해 기존 데이터셋을 분할하여 training 및 test 가 다른 topic 을 다루도록 함 table-to-text 의 경우 WebNLG 데이터셋은 table topic 으로 label 지정 training 및 dev 에 나타나는 9개 카테고리는 SEEN, text 에만 나타나는 5개의 카테고리는 UNSEEN 으로 표시 SEEN 카테고리에 훈련하고 UNSEEN 카테고리에 테스트 summarization 의 경우 두 가지 extrapolation data 분할을 구성 new-to-sports 에서, 뉴스 기사를 훈련하고 스포츠 기사를 테스트 within-new 에서, {world, UK, business} 뉴스를 훈련하고 나머지 뉴스 카테고리에서 테스트 table-to-text 및 summarization 모두에서 prefix-tuning 은 Table 4 와 Table 2 에 표시된 것과 같이 모든 메트릭에서 FT 보다 extrapolation 성능이 우수 또한 adapter-tuning 도 prefix-tuning 과 유사한 extrapolation 성능 달성하며, Table 2 에서 보이듯 이 공통된 경향은 LM parameter 를 보존하는 것이 extrapolation 에 긍정적인 영향을 미친다는 것을 시사","s":"6.4 Extrapolation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#64-extrapolation","p":1286},{"i":1326,"t":"longer prefix 는 더 많은 trainable parameter 를 통해 더 큰 표현력을 의미 prefix 증가에 따라 성능이 증가하다 임계값에 도달 (summarization 은 200, table-to-text 는 10) 후 약간의 성능 저하 임계값보다 긴 prefix 는 낮은 training loss 를 유발하지만 약간 더 나쁜 테스트 성능을 나타내어 training data 에 overfitting 가능성을 시사","s":"7.1 Prefix Length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#71-prefix-length","p":1286},{"i":1328,"t":"\"virtual token\" 의 continuous embedding 을 최적화하는 것을 embedding-only 라 부른다. word embedding 은 free parameter 이며 나머지 activation layers 는 Transformer 에 의해 계산된다. Table 5 상단에는 성능 하락을 보여주며, embedding layer 만 조정하는 것은 충분한 표현력이 부족하는 것을 시사 embedding-only 는 discrete prompt 최적화의 성능 상한선을 제시한다. 이유는 discrete prompt 가 embedding layer 를 정확하게 실제 단어의 embedding 과 일치시키도록 제한하기 때문이다. 따라서 다음과 같은 증가하는 표현력 chain 이 있다. discrete prompting < embedding-only < prefix-tuning","s":"7.2 Full vs Embedding-only","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#72-full-vs-embedding-only","p":1286},{"i":1330,"t":"sequence 내에서 trainable activations 위치에 따른 성능 조사 이러한 trainable activation 을 시작 부분 [PREFIX;x;y][\\text{PREFIX}; x; y][PREFIX;x;y] 에 배치한다. 또한 trainable activation 을 xxx 와 yyy 사이 (i.e. [x;INFIX;y][x; \\text{INFIX}; y][x;INFIX;y]) 에도 위치하며 이를 infix-tuning 이라 한다. Table 5 (하단) 에서 infix-tuning 이 prefix-tuning 보다 약간 성능이 낮다는 것을 보여준다. 이는 prefix-tuning 이 xxx 와 yyy 의 activation 에 영향을 미칠 수 있지만 infix-tuning 은 yyy 의 activation 에만 영향을 미칠 수 있기 때문이다.","s":"7.3 Prefix-tuning vs Infix-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#73-prefix-tuning-vs-infix-tuning","p":1286},{"i":1332,"t":"저자는 prefix 가 data 설정에 어떻게 initialization 되는지가 성능에 큰 영향을 끼지는 것을 발견 Random initialization 은 low performance, high variance 를 가짐 실제 단어의 activation 으로 초기화하는 것은 generation 을 크게 향상시킴 특히 summarization 과 text-to-text task 에 이와 관련된 단어로 초기화하면 \"elephant\" 나 \"divide\" 같이 관련 없는 단어보다 약간 더 나은 성능을 얻지만 random initialization 이 더 나은 성능을 보임 또한 전체 데이터 설정에서 initialization trick 은 영향을 미치지 않으며 random initialization 도 동일한 수준의 성능 제공 prefix 를 pre-trained LM 에 의해 계산된 실제 단어의 activation 으로 초기화하기 때문에 이 전략은 prefix-tuning 개념과 일치","s":"7.4 Initialization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#74-initialization","p":1286},{"i":1334,"t":"data efficiency 측면에서도 random initialization 을 사용한 prefix-tuning 과 전체 fine-tuning 의 성능을 비교하면 E2E task 의 5가지 데이터 규모 (10%, 20%, 40%, 60% 및 80%) 에서 성능 비교 Figure 6 은 20% 이상의 데이터를 사용할 때 prefix-tuning 이 fine-tuning 보다 성능이 우수함을 보여줌. 데이터 규모가 10% 인 경우 random initialization 을 사용한 prefix-tuning 이 full fine-tuning 과 유사하거나 약간 더 낮은 성능을 제공하여 이 low-data 범위에서 성능을 향상시키기 위해 initialization trick 이 필요함을 시사","s":"7.5 Data Efficiency","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#75-data-efficiency","p":1286},{"i":1337,"t":"1 에서 언급했듯, prefix-tuning 은 독립적인 훈련이 많은 task 에 유리 한 사례로 user privacy 보호를 위해 각 사용자의 데이터를 분리하고 각 사용자에 대해 별도의 개인화된 모델을 훈련한다고 했을 때, 각 사용자는 독립적인 task 로 간주할 수 있음 수백만 명의 사용자가 있을 경우 prefix-tuning 은 이 설정에서 확장 가능하며, 유연한 방식으로 사용자를 추가하거나 삭제할 수 있어 교차 오염없이 작동할 수 있다.","s":"Personalization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#personalization","p":1286},{"i":1339,"t":"동일한 personalization 설정에서도 prefix-tuning 은 다른 prefix 를 사용한 다른 사용자의 쿼리를 배치로 처리 가능 여러 사용자가 입력으로 클라우드 GPU 에 쿼리하는 경우, 동일한 배치에 넣는 것이 계산적으로 효율적 prefix-tuning 은 shared LM 을 그대로 유지하므로 배치를 만드는 것은 입력에 개인화된 prefix 를 추가하는 단순한 단계가 필요하며 나머지 계산은 변경되지 않는다. 반면, adapter-tuning 은 shared transformer layer 사이에 개인화된 adapter 가 있는 경우 서로 다른 사용자를 배치로 처리할 수 없다. 이러한 배치 이점은 동일한 task 에 훈련된 여러 prefix 의 효율적인 앙상블을 생성하는 데 도움이 될 수도 있다.","s":"Batching across users.","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#batching-across-users","p":1286},{"i":1341,"t":"Fine-tuning 은 all pretrained parameter 를 업데이트하는 반면, prefix-tuning 과 adapter-tuning 은 보존한다. LM 은 일반적인 목적의 corpora 에서 pretraining 되었으므로 LM parameter 를 보존하면 training 중의 unseen domain 에 대한 일반화에 도움 가능 이에 따라 prefix-tuning 과 adapter-tuning 이 inference 설정에서 큰 성능 향상을 보이는 것을 관찰 (6.4). 그러나 이러한 방법이 추론을 어떻게 개선하는지는 여전히 알려지지 않은 문제 Prefix-tuning 과 adapter-tuning 은 둘 다 pre-trained parameter 를 고정하지만 Transformer 의 activation layer 에 영향을 미치기 위해 다른 parameter set tuning. Prefix-tuning 은 LM 을 그대로 유지하며 prefix 와 pre-trained attention block 을 사용하여 이후 activation 에 영향을 미친다. 반면, adapter-tuning 은 LM layer 사이에 trainable module 을 삽입하여 activation 에 직접 residual vectors 추가. 더불어, prefix-tuning 은 adapter-tuning 에 비해 훨씬 적은 parameter 를 필요로 하는 것을 관찰했는데, 이는 prefix-tuning 이 pre-trained LM 을 가능한 한 그대로 유지하여, adapter-tuning 보다 LM을 더 활용하기 때문이라고 생각한다. 최근 연구는 intrinsic dimension 을 사용하여 fine-tuning 과 동일한 효과를 내는 low-dimensional reparameterization 수가 존재함을 보여줌. 왜 downstream task 에서 작은 수의 parameter 만 update 해도 좋은 정확도를 얻을 수 있는지를 설명한다. 저자의 연구는 small prefix 를 update 함으로써 좋은 생성 성능도 얻을 수 있음을 보여준다. 그러나 prefix-tuning 은 단순히 trainable parameter 의 크기뿐만 아니라 어떤 subset parameter 를 수정해야 하는지에 관한 것이다. 따라서 미래 연구에서 더 나은 accuracy-size trade-off 를 달성하는 다른 light-weight fine-tuning 방법을 탐구하는 것은 흥미로울 것.","s":"Inductive bias of prefix-tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/Prefix-Tuning","h":"#inductive-bias-of-prefix-tuning","p":1286},{"i":1343,"t":"논문 및 이미지 출처 : https://aclanthology.org/2023.emnlp-main.884.pdf","s":"SMoP: Towards Efficient and Effective Prompt Tuning with Sparse Mixture-of-Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1345,"t":"Prompt Tuning 은 full fine-tuning 을 대채하는 성공적인 parameter-efficient 이지만, 이전 연구는 성능 향상을 위해 long soft prompts 100 tokens 를 활용하여 확장된 inputs 으로 비효율성이 나타난다. 본 논문에서 저자는 새로운 prompt tuning 인, 효율적인 training 및 inference 를 위한 short soft prompts 를 활용하면서 longer soft prompts 으로부터의 성능 향상을 유지하는 SMoP (Sparse Mixture-of-Prompts) 소개 data subset 을 처리하는데 특화된 multiple short soft prompts 를 훈련하기 위해 gating mechanism 사용 entire data 를 커버하기 위한 single long soft prompts 에 의존하는 것의 대안 제공 실험 결과 SMoP 가 baseline 을 능가하며 training 및 inference 비용을 줄일 수 있음을 보여줌","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1347,"t":"Prompt Tuning 은 최근 full fine-tuning 의 parameter-efficient 대체로 주목받는다. 이는 model input 에 추가된 soft prompts 를 tuning 하여 trainable parameter 는 줄이면서도 full fine-tuning 과 comparable 한 성능을 만들어 낸다. 게다가 다른 PEFT 보다 간단하고 유연하며 모델 구조를 변경하지 않는다. Prompt Tuning 으로 파생된 여러 효율성 및 효과성에 대한 연구가 활성화 되었다. 일부는 model 의 각 layer 에 soft prompts 통합 (Li and Liang, 2021; Qin and Eisner, 2021; Liu et al. 2022) input-specific soft prompts 통합 (Jiang et al, 2022; Wu et al, 2022) soft prompt 를 pruning 및 rewinding (Ma et al, 2022) progressive training 을 통해 수렴 속도에 대한 prompt tuning 의 training efficiecy 를 향상시킨 FPT (Huang et al, 2022) 경험적 실험으로 prompt tuning 의 향상을 일으키지만, input sequence 확장의 결과로 인한 비효율성을 지나칠 수 있다. soft prompt length 증가 (일반적으로 100 tokens 이상) 이 모델 성능에 도움을 주는 것으로 알려져 있는데, longer input sequence 는 training 및 inference 에서 계산적 요구량을 증가시킴을 초래한다. (Fig. 1 참고) 그러므로, 저자는 longer soft prompts 으로부터 얻는 성능은 유지하면서 short soft prompts 활용을 조사한다. 끝으로, 저자는 SMoP (Sparse Mixture-of-Prompts) 를 제안 training 및 inference 중 short soft prompts 를 활용하느 새로운 prompt-tuning method short soft prompt 사용은 longer soft prompt 에 비해 성능이 떨어지는데, 저자는 data 의 다양한 subset 을 다루는데 특화된 multiple short soft prompts 를 훈련 이를 위해, sub-network (expert) 를 부분적으로 활성화하여 계산량을 비례적으로 증가시키지 않고 모델 용량을 증가시키는 Sparsely-Gated Mixture-of-Experts (Shazeer et al, 2017; Fedus et al, 2022) 에서 영감을 받음 저자는 이 개념을 SMoP 의 gating mechanism 을 사용하여 prompt-tuning 에 통합하고, 각 input instance 를 embedding representation 에 기반하여 short soft prompts 중 하나로 가이드 이런 sparse activation 은 계산 계산의 큰 증가나 성능 저하 없이 short soft prompt 를 효과적으로 활용 SMoP 효율 및 효과성 입증을 위해 SuperGLUE 의 6 task 에 평가 수행 prompt tuning 을 능가하며 training 및 inference cost 를 줄였다. SuperGLUE 의 6 tasks 에서 T5-base 는 2.5%p, T5-large 에선 3.4%p 로, prompt tuning 의 평균 성능 능가 Contribution efficient training 및 inference 를 위해 short soft prompt 를 활용하는 SMoP (Sparse Mixture-of-Prompts) 제안. soft prompt length 를 증가시켜 얻는 성능을 유지 SMoP 는 각 instance 를 embedding representation 에 기반한 multiple soft prompts 중 하나로 안내하는 gating mechanism 을 통해 short soft prompts 를 sparsely activate SMoP 를 shorter soft prompts 를 활용하여 T5-base 및 T5-large 에서 baseline 을 능가","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1350,"t":"Full Fine-tuning​ sequence-to-sequence model pϕ(y∣x)p_\\phi (y|x)pϕ​(y∣x) 을 사용하여 ϕ\\phiϕ 로 parameterize embedding representation X={x1,x2,…,xn}X = \\{x_1, x_2, \\dots, x_n\\}X={x1​,x2​,…,xn​} 의 nnn sequence 및 대응하는 label token embedding sequence YYY 가 주어졌을 때, model pϕp_\\phipϕ​ full fine-tuning 에 대한 objective function 은 다음과 같다. arg⁡max⁡ϕlog⁡pϕ(Y∣X).\\begin{equation} \\underset{\\phi}{\\arg \\max} \\log p_\\phi (Y | X). \\end{equation}ϕargmax​logpϕ​(Y∣X).​​ Prompt Tuning​ embedding dimension eee 와 length lll soft prompt 를 PθP_\\thetaPθ​ 로 정의하고 이를 θ∈Rl×e\\theta \\in \\mathbb{R}^{l\\times e}θ∈Rl×e 로 parameterize 한다면, prompt tuning 의 object function 은 다음과 같다. arg⁡max⁡ϕlog⁡pϕ(Y∣[Pθ;X]).\\begin{equation} \\underset{\\phi}{\\arg \\max} \\log p_\\phi (Y | [P_\\theta ; X]). \\end{equation}ϕargmax​logpϕ​(Y∣[Pθ​;X]).​​ 여기서 language model parameter ϕ\\phiϕ 는 더이상 업데이트하지 않는다. 아래 Fig. 2 (a) 에서 prompt-tuning 의 과정을 나타낸다.","s":"2.1 Preliminaries","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#21-preliminaries","p":1342},{"i":1352,"t":"SMoP 목표는 multiple short soft prompt 학습이다. 각 prompt 는 data subset 에 특화된다. 이를 위해, input instance 가 embedding representation 에 기반한 soft prompt 중 하나로 가기 위해 gating mechanism 을 사용한다. (Fig. 2(b)) μ∈Re×k\\mu \\in \\mathbb{R}^{e \\times k}μ∈Re×k 로 parameterize 된 small linear router model LμL_\\muLμ​ 사용 이는 input 이 어느 soft prompt 로 routing 되야 하는지에 대한 결정을 준다. 공식적으로, kkk soft prompt embeddings Pθ1,Pθ2,…,PθkP_{\\theta_1}, P_{\\theta_2},\\dots,P_{\\theta_k}Pθ1​​,Pθ2​​,…,Pθk​​ 이며, {θj}j=1k\\{\\theta_j\\}^k_{j=1}{θj​}j=1k​ 으로 parameterize θj∈Rl×e\\theta_j \\in \\mathbb{R}^{l \\times e}θj​∈Rl×e router model 은 input embedding Xˉ∈Re\\bar{X}\\in \\mathbb{R^e}Xˉ∈Re 을 input 으로, 평균을 받아 각 soft prompt 에 대한 routing probability p1,p2,…,pkp_1, p_2, \\dots, p_kp1​,p2​,…,pk​ 를 계산 jjj-th prompt 의 routing probability 는 다음과 같이 계산 pj(X)=[softmax(Lμ(Xˉ))]j⋅\\begin{equation} p_j(X) = [\\text{softmax}(L_\\mu (\\bar{X}))]_j\\cdot \\end{equation}pj​(X)=[softmax(Lμ​(Xˉ))]j​⋅​​ input 은 highest probability 의 soft prompt 로 routing 되며, final soft prompt 는 routed prompt 와 probability value 의 곱으로 얻어진다. 따라서, SMoP 의 objective function 은 다음과 같이 정의된다. arg⁡max⁡μ,θclog⁡p(Y ∣ [pc(X)⋅Pθc;X]),\\begin{equation} \\underset{\\mu,\\theta_c}{\\arg\\max}\\log p(Y\\ |\\ [p_c(X)\\cdot P_{\\theta_c}; X]), \\end{equation}μ,θc​argmax​logp(Y ∣ [pc​(X)⋅Pθc​​;X]),​​ ccc : highest probability value 의 prompt index total prompt length 는 k⋅lk \\cdot lk⋅l 이면서, 활용되는 prompt length 는 lll 만 남는다.","s":"2.2 SMoP: Sparse Mixture-of-Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#22-smop-sparse-mixture-of-prompts","p":1342},{"i":1354,"t":"Mixture-of-Experts (Chen et al, 2022b; Fedus et al, 2022) 는 training 중 experts 간의 load balance 가 성능에 중요한 역할을 한다는 것을 보여줬다. 다양한 prompt 를 통해 input exploration 을 촉진하여 soft prompt 간의 load balance 를 보장하기 위해, SMoP 의 training 중에 router perturbation 적용 구체적으로, training 중 router model 의 output value 에 scaled gaussian noise δ∼N(0,1)\\delta \\sim \\mathcal{N}(0,1)δ∼N(0,1) 추가 eq. 3 을 다음과 같이 수정 pj(X)=[softmax(Lμ(Xˉ) ∘ (1⃗+δ))]j.\\begin{equation} p_j(X) = [\\text{softmax}(L_\\mu(\\bar{X})\\ \\circ \\ (\\vec{1}+\\delta))]_j. \\end{equation}pj​(X)=[softmax(Lμ​(Xˉ) ∘ (1+δ))]j​.​​","s":"2.3 Router Perturbation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#23-router-perturbation","p":1342},{"i":1357,"t":"Tasks​ 다양한 NLP task 에서 SMoP 와 baseline 을 SuperGLUE 의 6 tasks 에서 평가 공식 test set 이 공개되지 않아, Chen et al (2022a) 를 따라 dev set 을 test set 으로 사용하고 original train set 을 90%/10% 로 train / validation set 으로 나눔 Models and Baselines​ HuggingFace 의 pre-trainde checkpoint 사용 T5 는 두 가지 scales: base 및 large 사용 SMoP 이점을 보여주기 위해, prompt tuning, P-tuning 및 full-fine tuning 과 비교 Evaluation Setup​ prompt tuning 에 대해, {5,20,50,100}\\{5, 20, 50, 100\\}{5,20,50,100} soft prompt tokens 에 대해 실험하고, SMoP 에 대해선 {2,4,10,20}\\{2, 4, 10, 20\\}{2,4,10,20} 개의 length {1,3,5,10}\\{1,3,5,10\\}{1,3,5,10} prompt 를 탐색 저자는 두 번 또는 세 번의 실행에서 평균 성능이 가장 우수한 설정과 해당 표준편차 report 훈련 시간 및 메모리 사용량을 훈련 비용으로, inference FLOPs 를 추론 비용으로 report","s":"3.1 Experimental Settings","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#31-experimental-settings","p":1342},{"i":1360,"t":"Table 1 에서 SMoP 및 baseline 성능 제시 SMoP 는 최소 훈련 및 추론 비용으로 가장 높은 성능 달성 T5-base 에서 평균 2.5%, T5-large 에선 3.4% 향상 SMoP 가 less training 및 inference cost 로 baseline 을 능가하는 사실은 short soft prompt 활용의 중요성을 강조 예로, T5-large 에서 100 soft prompt 를 사용한 prompt tuning 과 비교하여 14.6% training time, 22.9% 의 training memory, 27.2% inference FLOP 절약 full fine-tuning 은 input 에 추가되는 token 이 없어, inference 에 적은 FLOP 을 필요로 하지만, SMoP 는 가장 적은 추가 FLOP 도입","s":"3.2.1 Main Results","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#321-main-results","p":1342},{"i":1362,"t":"soft prompt 의 optimal length 및 number 조사를 위해 Table 2 에서 다양한 prompt length 및 number 를 사용한 결과 제시 20 soft prompt 를 50 이상으로 증가시키면 marignal 성능 향상 이는 이전 연구 (Lester et al, 2021; Li and Liang, 2021; Ma et al, 2022) 에서 특정 임계값 이상의 soft prompt 길이가 증가하면 성능 개선에 제한되는 것과 일치 20 soft prompt 사용은 일반적인 성능 저하 야기 SuperGLUE task 에서 몇몇 task 에 대한 훈련 데이터가 제한되어 soft prompt 훈련이 부족할 수 있기 때문으로 추측 (Wang et al, 2022) 위 결과를 고려해, 주로 각 5 개의 token 으로 구성된 4 개의 soft prompt 를 사용한 결과 report SMoP 는 prompt tuning 을 개선하지만, optimal soft prompt length 및 number 는 specific task 나 dataset 에 따라 다를 수 있다.","s":"3.2.2 Length and Number of Soft Prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#322-length-and-number-of-soft-prompts","p":1342},{"i":1364,"t":"gating mechanism 에서 routing method 영향을 검증하기 위해 다음 방법들에 실험 수행 router 없는 linear (w/o perturbation) 가장 높은 확률의 두 prompt 의 weighted sum 을 취하는 Top-2 router 출력 확률을 1 로 계산하는 Gumbel-Softmax routing prompt tuning 에 AdaMix 를 적용한 Stochastic routing (Zuo et al, 2022; Wang et al, 2022) 5 soft prompt 를 사용한 prompt tuning 과 동일한 no routing (Single) table 3 은 다양한 routing 방법에 대한 세 가지 SuperGLUE task 에서 실험 결과 original setting 인 routerperturbation 이 있는 top-1 linear 가 다른 router 를 능가 예외는 BoolQ 로, router routerperturbation 를 제거하는 것이 약간 더 나은 성능을 보인다. BoolQ 같은 고차원 환경에서는 각 soft prompt 의 충분한 훈련을 위해 router routerperturbation 가 필수적이지 않을 수 있다.","s":"3.2.3 Routing Methods","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#323-routing-methods","p":1342},{"i":1367,"t":"PLMs 는 NLP task 에서 놀라운 성능을 보여주지만, T5 및 GPT-3 같은 큰 모델의 등장으로 PLM full fine-tuning 은 훈련 및 배포 측면에서 비효율적으로 여겨짐 이를 해결하기 위해, parameter-efficient fine-tuning 제안 이 방법 중 하나인 prompt-tuning (Lester et al, 2021) 은 model input 에 learnable token embedding (soft prompt) 를 prepend 하여 이 embedding 만 fine-tuning 하는 간단하고 효과적인 방법이다. 단순성과 적응성은 soft prompt 구조를 수정하여 효율성 및 성능 향상으로 발전해왔다. (Liu et al, 2021; Li and Liang, 2021) using instance-specific prompts (Jiang et al, 2022; Wu et al, 2022) adjusting the training process (Huang et al, 2022; Ma et al, 2022). 또한 prompt tuning 은 soft prompt 구조를 수정하여 transfer 도 가능하다. (Vu et al, 2022; Asai et al, 2022; Wang et al, 2023) 이는 prompt tuning 의 성능을 향상시켰지만, long soft prompt 의 비효율성을 고려하지 않는다. SMoP 는 이를 완화하기 위해 설계되었으며, 기존 prompt tuning 과는 독립적이다.","s":"4.1 Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#41-prompt-tuning","p":1342},{"i":1369,"t":"Mixture-of-Experts 는 model output 이 gating 메커니즘을 통해 multiple sub-networks (experts) 에 의해 conditionally activate 되는 모델 구조다. 이를 통해 계산 비례 증가 없이 parameter 수를 증가시킬 수 있다. 일반적으로 routing 메커니즘이 specific tokens 를 처리하는 experts 를 결정한다. 또한 sequence 및 batch 를 routing 할 수 있다. Fedus et al (2022) 는 Sparsely-Gated Mixture-of-Experts layer 를 사용하는 Switch Transformers 제안 Zuo et al (2022) 는 stochastic (random) routing 을 사용하는 THOR 제안 최근 Wang et al (2022) 은 AdaMix 라는 parameter-efficient fine-tuning 을 제안했는데 이는 Mixture-of-Experts 의 개념을 Adapter (Houlsby et al, 2019) 에 통합되며 stochastic routing 및 multiple adapter module 과 병합으로 사용된다. SMoP 와 AdaMix 는 모두 Parameter-efficient fine-tuning 개선을 위해 Mixture-of-Experts 에서 영감을 받았지만 효율적인 short prompt 사용에서 동기가 다르다.","s":"4.2 Mixture-of-Experts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"#42-mixture-of-experts","p":1342},{"i":1371,"t":"short soft prompt 활용으로 효율적인 training / inference 유지 prompt length 증가와 관련된 성능 향상을 유지하는 SMoP 제안 각 instance 를 multiple soft prompt 중 하나로 routing 하는 게이팅 메커니즘 short soft prompt 활용으로 training / inference cost 를 줄이면서도 SMoP 가 prompt tuning 능가함을 보여줌","s":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1373,"t":"동일한 total prompt length 를 가질 때, SMoP 의 게이팅은 additional parameter 를 prompt tuning 과 비교하여 도입해, 추가적인 저장 요구 사항을 유발 T5-base 에서 길이가 20 인 soft prompt 를 사용하는 prompt-tuning (20,480 parameters) 와 길이가 5 인 soft prompt 4 개를 사용하는 SMoP (24,576 parameters) 를 비교하여, SMoP 는 20% 의 trainable parameter 추가되며, 많은 prompt 활용할수록 차이가 커짐 SMoP 의 대부분 baseline prompt-tuning 방법과 상관없이 작동","s":"Limitations","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SMoP","h":"","p":1342},{"i":1375,"t":"논문 및 이미지 출처 : https://aclanthology.org/2022.acl-long.433.pdf","s":"UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1377,"t":"최근 parameter-efficient language model tuning (PELT) 으로 적은 trainable parameter 로 fine-tuning 성능과 맞먹거나 적은 training data 에서 성능이 좋은 방법 등장 하지만 다양한 PELT methods 는 동일한 task 에 상당히 다른 성능을 보이며, 특정 task 에 대해 적절한 method 를 선택하는 것은 쉽지 않다. 특히 new PELT methods 외 task 가 늘어나고 있는 상황을 고려하면 더 어렵다. 모델의 다양성과 선택의 어려움을 고려하여, 저자는 UniPELT 를 제안 다양한 PELT 방법을 submodeuls 로 포함하고, 현재 data 나 task setup 에 적합한 방법들을 활성화시키기 위한 gating mechanism 을 통해 학습 GLUE 에서 UniPELT 는 일관성 있게 개별 PELT 보다 1~4% 성능 향상, 다양한 설정에서 fine-tuning 능가 일반적으로 submodules 를 개별 사용했을 때의 각 task 에 대한 best performance 를 취합산 상한선을 넘어서는 경향이 있어, 여러 PELT mixture 가 single 보다 효과적임을 시사","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1379,"t":"pre-trained language models (PLMs) 는 커져감에 따라, task 당 model parameter 개별적 복제를 수정하는 fine-tuning 은 점점 불가능해지고 있다. 이를 해결하기 위해, 최근 parameter-efficient language model tuning (PELT) 연구가 급증하고 있다. 기존 PELT 는 few trainable parameter 로 fine-tuning 과 comparable perforance 를 목표로 한다. 최근 방법의 parameter 는 PLM 의 total parameter 에 비해 무시할 수 있을 수준 (< 1%) 으로 줄었다. 더 어려우며 덜 연구된 문제는 fewer parameter 로 fine-tuning 보다 좋은 성능을 달성하는지 여부다. 최근은 training data 가 제한된 경우 PELT 가 overfitting 의 위험을 줄여 특정 task 에서 fine-tuning 보다 효과적임을 입증했다. 하지만 저자의 실험에서 발견한 것과 같이 (Table 1), 다양한 PELT 는 동일한 task 에 다양한 특성을 보이며, 특히 새로운 PELT 와 task 가 늘어나고 있어 가장 적합한 방법을 선택하기란 어렵다. PLET 간의 성능 차이와 최적의 방법을 선택하는 비용을 고려하여, 통합 PELT 인 UniPELT 제안 다양한 PELT 를 submodule 로 통합하고, data or task 에 가장 적합한 submodule 또는 그 조합을 동적으로 활성화하여 학습 모델 선택이 필요하지 않으며, 다양한 설정에서 일관된 성능 향상을 보여줌 각 submodule 의 activation 은 gating mechanism 으로 제어되며, 주어진 task 에 긍정적으로 기여하는 submodule 을 학습 (가중치를 더욱 할당) 각 submodule 의 parameter 수가 일반적으로 적어, 여러 방법을 결합해도 효율성 유지 저자는 네 가지 PELT 를 택하였다. Adapter (Houlsby et al. 2019) Prefix-Tuning (Li and Liang. 2021) LoRA (Hu et al. 2021) BitFit (Ben Zaken et al. 2021) 저자는 PELT 개별 특성과 여러 설정의 UniPELT 가 조화를 이룰 때의 효과성을 검토하는 두 가지 분석 셋 수행 GLUE 에서의 실험 결과 (32 setup - 8 tasks x 4 data sizes, 1,000+ runs) PELT 의 다양한 행동을 보여주며, 각 방법의 개별 사용보다 UniPELT 다 효과적이며 견고함을 보여줌 일관되게 best submodule 을 1~4 points 개선하며, 때론 fine-tuning을 능가하여 최상의 평균 성능 달성 일반적으로 각 task 에서 개별적으로 사용된 모든 submodule 의 최고 성능 초과 아는 다양한 설정에서 최적의 성능을 유지한다는 것을 시사 상한선을 능가한다는 사실은 PLM architecture 의 다양한 부분을 포함하는 PELT 방법이 mixture 이 single 보다 내재적으로 더 효과적임을 나타냄 Contributions PELT 에 대한 포괄적인 연구를 수행하고 성능 및 특성 측면에서 차이와 공통점을 검토 기존 PELT 를 submodule 로 포함하고 주어진 task 에 적합한 submodule 을 자동으로 활성화할 수 있는 통합 PELT 제안 UniPELT 는 다양한 설정에서 fine-tuning 및 PELT 보다 우수한 평균 성능 달성, 종종 best 성능을 발휘하고 결코 worst 성능은 되지 않으며 모델 효율성도 좋다.","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1382,"t":"PLM 은 top layers 또는 prediction head 만 additional parameter 없이 fine-tuning 될 수 있다. 하지만 fine-tuning 은 일반적으로 all parameter tuning 보다 훨씬 나쁜 성능을 내는 경우가 많다. 최근 BitFir 은 PLM 의 bias 만 tuning 하여, limited training data 에서 일부 task 에서 fine-tuning 과 유사한 성능을 달성할 수 있는 것을 실험적으로 보여줬다. 따라서 저자는 이 카테고리를 대표하는 분석을 위해 BitFir 을 선택했다.","s":"2.1 PELT Methods without Additional Parameters","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#21-pelt-methods-without-additional-parameters","p":1374},{"i":1384,"t":"대안으로 all PLM 을 고정하고 new trainable parameter 를 도입할 수 있다. 이 카테고리의 예시로 Adapter, Prefix-Tuning 등이 있다. Adapter​ PLM 의 각 Transformer layer 의 feedforward network 뒤에 trainable bottleneck layer 를 추가 bottleneck layer 은 token hidden states size 를 축소하고 복구하는 down+up projection pair 으로 구성된다. 수학적으로, feedforward network 후 residual connection 과 layer normalization 을 거친 output : hFNh_{FN}hFN​ hidden size : DhiddenD_{\\text{hidden}}Dhidden​ bottleneck size : DmidD_{\\text{mid}}Dmid​ bottleneck layer hAh_AhA​ 의 output 은 다음과 같다. hA=Wup⊤ϕ(Wdown⊤hFN),\\begin{equation} h_A = W^\\top_\\text{up} \\phi (W^\\top_\\text{down}h_{FN}), \\end{equation}hA​=Wup⊤​ϕ(Wdown⊤​hFN​),​​ Wdown∈RDhidden×DmidW_{\\text{down}} \\in \\mathbb{R}^{D_\\text{hidden} \\times D_{\\text{mid}}}Wdown​∈RDhidden​×Dmid​, Wup∈RDmid×DhiddenW_{\\text{up}} \\in \\mathbb{R}^{D_\\text{mid} \\times D_{\\text{hidden}}}Wup​∈RDmid​×Dhidden​, ϕ\\phiϕ : nonlinear activation function. 간결성을 위해 bias 는 제거 layer normalization 및 final prediction head parameter 도 특정 adapter 에 따라 fine-tuning Adapter 는 fine-tining 과 비슷한 성능이거나 low-resource 에서 더 효과적인 것으로 나타났다. Prefix-Tuning​ Prefix-Tuning 은 각 transformer layer 의 multi-head attention 의 input 앞에 task-specific trainable vectors 를 붙인다. 구체적으로, original sequence length : L0L_0L0​ trainable vectors number (i.e. prefix length) : LLL Transformer layer input : hin∈RDhidden×L0h_\\text{in} \\in \\mathbb{R}^{D_{\\text{hidden}} \\times L_0}hin​∈RDhidden​×L0​ three linear projections WQW_QWQ​, WKW_KWK​, WV∈RDhidden×DhiddenW_V \\in \\mathbb{R}^{D_{\\text{hidden}} \\times D_{\\text{hidden}}}WV​∈RDhidden​×Dhidden​ 는 hinh_\\text{in}hin​ 을 Query QQQ, Key KKK 및 Value VVV 로 변환 two prefix matrices PKP_KPK​, PV∈RDhidden×LP_V \\in \\mathbb{R}^{D_{\\text{hidden}} \\times L}PV​∈RDhidden​×L 는 KKK 및 VVV 앞에 붙임 optimization 안정화를 위해, prefix matrix PPP 는 feedforward network 를 통해 reparameterize P′=Wup⊤ϕ(Wdown⊤P),\\begin{equation} P' = W^\\top_\\text{up} \\phi (W^\\top_\\text{down}P), \\end{equation}P′=Wup⊤​ϕ(Wdown⊤​P),​​ Wdown∈RDhidden×DmidW_\\text{down} \\in \\mathbb{R}^{D_{\\text{hidden}} \\times D_{\\text{mid}}}Wdown​∈RDhidden​×Dmid​, Wup∈RDmid×2NlayerDhiddenW_\\text{up} \\in \\mathbb{R}^{D_{\\text{mid}} \\times 2N_\\text{layer}D_{\\text{hidden}}}Wup​∈RDmid​×2Nlayer​Dhidden​ NlayerN_\\text{layer}Nlayer​ : Transformer layers 수 위 두 network 는 training 후 폐기할 수 있으며, 2Nlayer2N_{\\text{layer}}2Nlayer​ prefix matrices ∈RDhidden×L\\in \\mathbb{R}^{D_\\text{hidden} \\times L}∈RDhidden​×L 만 필요 Prefix-tuning 은 원래 NLG 에서 평과되며, 저자는 이를 적용함. prompt-tuning (Lester et al. 2021) 이란 후속 방법은 prefix 를 첫 번째 layer 로 제한하여 task-specific parameters 를 더 줄이지만, 모델이 큰 경우에만 competitive performance 유지 Additive Methods​ Additive PELT 는 fine-tuning 후의 model parameter 를 pre-trained parameters θpre-trained\\theta_\\text{pre-trained}θpre-trained​ 와 task-specific differences δtask\\delta_\\text{task}δtask​ 의 합으로 취급 θpre-trained\\theta_\\text{pre-trained}θpre-trained​ fixed new (sub)set : θtask=θpre-trained+δtask\\theta_\\text{task} = \\theta_\\text{pre-trained} + \\delta_\\text{task}θtask​=θpre-trained​+δtask​ 추가 δtask\\delta_\\text{task}δtask​ 를 parameterize 하는 다양한 방법 : LoRA, diff pruning 및 side-tuning 존재 저자는 LoRA 를 대표적인 방법으로 채택하여 이를 UniPELT 에 통합 LoRA 는 trainable low-rank matrices 도입 및 이를 multi-head attention 의 original matrices 에 결합 특히, two matrices Wdown∈RDhidden×DmidW_\\text{down} \\in \\mathbb{R}^{D_\\text{hidden} \\times D_\\text{mid}}Wdown​∈RDhidden​×Dmid​ 및 Wup∈RDmid×DhiddenW_\\text{up} \\in \\mathbb{R}^{D_\\text{mid} \\times D_\\text{hidden}}Wup​∈RDmid​×Dhidden​ 은 original matrix WQW_QWQ​ 및 WK∈RDhidden×DhiddenW_K \\in \\mathbb{R}^{D_\\text{hidden} \\times D_\\text{hidden}}WK​∈RDhidden​×Dhidden​ 인 query 및 key projection 에 추가된다: Q=(WQ⊤+αWup⊤Wdown⊤)hin\\begin{equation} Q = (W^\\top_Q + \\alpha W^\\top_\\text{up}W^\\top_\\text{down})h_\\text{in} \\end{equation}Q=(WQ⊤​+αWup⊤​Wdown⊤​)hin​​​ α\\alphaα : task-specific differences 를 조절하기 위한 fixed scalar hyperparameter LoRA 의 trainable matrices 형태는 Adapter 나 Prefix-Tuning 과 유사하지만, 이들은 activation function ϕ\\phiϕ 가 없음","s":"2.2 PELT Methods with Additional Parameters","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#22-pelt-methods-with-additional-parameters","p":1374},{"i":1387,"t":"size ∣M∣|\\mathcal{M}|∣M∣ 인 PLM M\\mathcal{M}M 이 비용 또는 저장 문제로 fine-tuning 이 불가할 경우, PELT 목록 {mi}\\{m_i\\}{mi​} 이 있을 때 (i.e. ∑i∣mi∣≪∣M∣\\sum_i |m_i| \\ll |\\mathcal{M}|∑i​∣mi​∣≪∣M∣), 각각이 submodule 로 포함되어 {mi}\\{m_i\\}{mi​} 를 동적으로 활성화 (upweight)하고 적절한 시나리오에 따라 다양한 submodules 을 활성화하는 통합 PELT 를 설계하는 것이 목표. 이렇게 하여 모든 method x task x data 조합을 순열하는 번거로움 없이 효과성과 견고성 양측을 만족시킬 수 있다.","s":"3.1 Task Formulation","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#31-task-formulation","p":1374},{"i":1389,"t":"Motivation & Intuition​ 개별적으로 PELT 분석 중 저자는 다양한 특성과 same task 에 대해 다른 수행을 하는 PELT 들 관찰 Prefix-Tuning 은 training data 와 관계없이 NLG task 에 잘 수행 Fig. 1 과 같이, 다양한 PELT 방법들을 PLM 의 각기 다른 부분에 포함 (e.g. prefix-tuning 은 multi-head attention 이전 및 adapter 는 feedforward layer 이후) 이는 서로 직접 간섭하지 않고 여러 PELT 방법을 결합하는 것이 가능 위 두 가지 관찰을 고려하여, PELT 방법을 submodules 로 포함하는 hybrid 방식을 채용한 unified PELT framework 인 UNIEPLT 제안 high level 에서, UniPELT 는 여러 이유로 single PELT 보다 성능 개선 UniPELT 는 current task 나 specific data sample 에 가장 적합한 submodule 을 활성화 (upweight)하고 나머지는 비활성화 (downweight)하는 방식으로 학습 UniPELT 가 일반적으로 각 task 에 개별적으로 사용된 submodule 의 best performance 보다 더 나은 성능을 보이는 경향 발견 (PLM 의 다른 부분을 수정하는) multiple PELT 이 사용되면 모델 효과성을 향상시키는 일부 누적 효과가 있을 수 있음을 시사 Gating Mechanism​ submodule (de)activation 의 fine-grained 달성을 위해, 저자는 모든 Transformer layer 의 submodule mi∈{A, P, L}m_i \\in \\{\\text{A, P, L}\\}mi​∈{A, P, L} 마다 trainable gate Gmi\\mathcal{G}_{m_i}Gmi​​ 추가 (Fig. 1 참고) A, P, L : Adapter, Prefix-tuning, LoRA mim_imi​ 가 data x task (or instance) 에 유용하면, mim_imi​ 에 대한 gate output 은 높아져 더 중요한 역할을 함. 하지만 실제 submodule 의 상호작용은 submodule 간의 종속성과 multiple layer 의 누적 효과로 인해 더 복잡하다. adapter 의 경우, feedforward network 와 adapter submodule 간에 residual connection 존재하며, 이는 adapter input (before normalization) hFh_FhF​ 및 output hAh_AhA​ 의 합을 final output hA′=hA+hFh'_A = h_A + h_FhA′​=hA​+hF​ 를 생성 adapter 의 importance 를 sigmoid activation 을 사용하는 feedforward network 를 사용하여 직접 input hFNh_{FN}hFN​ 을 통해 추정하는 gating function G∈(0,1)\\mathcal{G} \\in (0, 1)G∈(0,1) 을 설계하고, output hA′=GAhA+hFh'_A = \\mathcal{G}_A h_A + h_FhA′​=GA​hA​+hF​ 를 scaling adapter submodule 은 G≈0\\mathcal{G} \\approx 0G≈0 일 경우 효과적으로 우회 ​prefix-tuning 의 경우도 유사하게, original tokens (KKK, VVV) 의 representation 은 유지한채 prefix vectors (PKP_KPK​, PVP_VPV​) 에 적용하는 gating function GP∈(0,1)\\mathcal{G}_P \\in (0, 1)GP​∈(0,1) 이 방식을 통해 prefix 의 영향은 prefix-tuning submodule 의 gating function output 이 낮은 경우 감소 gating function GP\\mathcal{G}_PGP​ 는 다른 feedforward network 를 사용하여 Transformer layer input hinh_\\text{in}hin​ 로 추정 LoRA 의 경우, 기존 설계에서 이미 constant scaling factor α\\alphaα 가 있다. 그래서 저자는 단순하게 이 factor 를 layer 마다 learnable 하게 변경 이를 위해 α\\alphaα 대신 hinh_\\text{in}hin​ 을 input 으로 사용하는 third feedforward network θtask=θpre-trained+GLδtask\\theta_\\text{task} = \\theta_\\text{pre-trained} + \\mathcal{G}_L \\delta_\\text{task}θtask​=θpre-trained​+GL​δtask​ 사용 UniPELT 는 다양한 시나리오에서 효과적으로 작동하도록 구현하는 것은 쉽지 않다. 다양한 PELT 를 hybrid 방식으로 결합하는 것은 개별 사용보다 더 나쁜 성능을 초래할 수도 있다.","s":"3.2 Proposed Method","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#32-proposed-method","p":1374},{"i":1391,"t":"세팅 당 8 tasks x 4 data sizes x 7 methods x 5 runs 에서 실험","s":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1393,"t":"Task Setup​ linguistic acceptability (CoLA), sentiment analysis (SST-2), similarity and paraphrase tasks (MRPCNLU, QNLI, RTE) 를 포함하는 NLU task 인 GLUE 에서 실험 수행 Adapter 및 BERT 실험에 따라 WNLI dataset 는 제외 Data Setup​ 저자는 주로 training data 가 제한적이며 다양한 방법의 성능이 크게 다를 low-resource 고려 각 task size K={100,500,1000}K = \\{ 100, 500, 1000 \\}K={100,500,1000} 의 small training subset 을 sampling 1,000 sample 을 training set 으로 사용하여 development set 에서 best checkpoint 선택하고 original development set 을 test set 으로 사용 variance 를 줄이기 위해 5 random seed 를 섞고 평균 성능을 report whole training set 을 사용하고 GLUE development set 의 best 성능을 report 하는 high-resource 도 고려 Compared Methods​ 주로 UniPELT 와 fine-tuning 및 PELT (prefix-tuning, BitFit, LoRA) 비교 2 및 3 PELT methods 를 통합한 UniPELT (AP) 및 UniPELT (APL) 도 비교 Implementation Details​ BERTbase_\\text{base}base​ 를 base model 로 실험에 사용 일관성 실험을 위해 BERTlarge_\\text{large}large​ 사용 공정한 비교를 위해 동일한 코드에서 모든 방법을 구현 및 평가 methods 의 default hyperparameter 를 따름 prefix length L=10L = 10L=10 adapter bottleneck size Dmid=48D_\\text{mid} = 48Dmid​=48 LoRA rank Dmid=8D_\\text{mid} = 8Dmid​=8","s":"4.1 Experiment Setup","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#41-experiment-setup","p":1374},{"i":1395,"t":"여러 training data size 에서 GLUE 성능을 보여준다. 8 tasks 에서 여러 방법의 평균 성능이 때론 비슷하지만, task 간의 차이는 특정 셋팅에서 상당히 다르며 특정 task (e.g. STS-B 및 MNLI, K=500K = 500K=500) 에서 5~9 points 더 높았다. Analysis of Adapter​ adapter 의 성능은 비교적 안정적 다양한 task or training data size 에서 fine-tuning 보다 좋거나 나쁜 것이 없음 일반적으로 대부분 case 에서 fine-tuning 보다 약간 성능이 안좋음 He et al. (2021) 처럼 각 task 에 대한 model hyperparameter 를 조정하지 않는 한, low-resource 환경에서 fine-tuning 보다 일관되게 성능이 높은 것을 관찰하진 못함. 이는 많은 task 가 있을 경우 계산적으로 불가능할 수 있음 그들은 {64,128,256}\\{ 64, 128, 256 \\}{64,128,256} 에서 bottleneck size DmidD_\\text{mid}Dmid​ 를 선택한 반면, 저자는 Dmid=48D_\\text{mid} = 48Dmid​=48 로 고정하고 모든 task 에서 실험 저자는 Pfeiffer et al. (2021) 를 따라 각 Transformer layer 에 one adapter 만 추가 위 두 차이로 인해, 저자의 Adapter 는 He et al. (2021) 에서 사용된 Adapter 보다 62.4% ~ 90.5% fewer parameter 를 가짐 Adapter 의 bottleneck size DmidD_\\text{mid}Dmid​에 대해 더 조사 DmidD_\\text{mid}Dmid​ 를 증가시키고 Adapter 의 성능이 좋지 않던 setup (CoLA, K=100K=100K=100) 을 재평가 Fig. 2 와 같이, Adapter 성능은 점진적으로 향상 Dmid=256D_\\text{mid} = 256Dmid​=256 일 때 뚜렷하게 향상 기존 Adapter (Dmid=48D_\\text{mid} = 48Dmid​=48) 보다 5.3x trainable parameters 를 포함. UniPELT (AP) 보다 4.3 x, UniPELT (APL) 보다 3.4x 많음 위는 Adapter 가 비효과적인 학습을 할 때, 더 큰 bottleneck size 가 유용함을 시사 반면 Adapter 가 다른 PELT 보다 우월한 성능을 보이는 specific task (e.g. STS-B)이 있음 이는 training data size 에 관계없이 Adapter 를 선호해야하는 상황이 있음을 시사 Analysis of Prefix-tuning​ prefix-tuning 은 K={100,500}K = \\{100, 500\\}K={100,500} 에서 수행 K$ 가 1000 에 달하면 fine-tuning 과 동등해짐 training data 가 제한적일 때 특정 task (e.g. K=100K=100K=100 on SST-2 및 K=500K = 500K=500 on QQP) 에서 효율적인 학습이 실패한다. 불만족스러운 성능 및 large variance 초래 이런 현사아은 few-shot prompt-tuning 에서도 관찰됨 prefix-tuning 의 안좋은 성능은 fewer trainable parameters 때문은 아니다. adapter 와 comparable 한 trainable parameter 가 되도록 prefix length L=50L = 50L=50 으로 증가시키고 K=100K = 100K=100 의 8 tasks 에서 평가 4 tasks (L=10L = 10L=10 로, SST2, CoLA, STS-B 및 QQP 에서 안 좋았던 성능) 의 경우, 3 tasks 가 상당히 향상. 다른 task (STS-B) 는 성능 크게 저하 이는 low-resource 에서의 훈련 불안전성이 있음을 시사. more trainable parameter 를 사용해도 여전히 문제 prefix-tuning L=50L=50L=50 은 4 task 중 3개에서 여전히 Adapter 나 UniPELT (AP) 보다 성능 좋지 않음 L=50L = 50L=50 의 prefix-tuning 8 task 에 대한 평균 성능은 L=10L = 10L=10 일 때보다 더 나쁘며, 이는 prefix length 증가가 만병통치약이 아님을 시사 large LLL 은 training/inference 에도 고비용의 multi-head attention 으로 저하를 일으킴 반면, prefix-tuning은 specific task (RTE 및 MNLI)에서는 좋은 성능을 보이며, 이는 특정 경우에는 prefix-tuning 을 선호해야 한다는 것을 나타냄. Analysis of BitFit & LoRA​ 저자의 실험에선 model bias 조정만으로는 만족스러운 결과를 얻지 못함 BitFit 은 저자의 실험에서 좋은 결과를 내지 못하며 다양한 data 및 task 에서 최악의 성능을 보임 따라서 이후 실험에서 BitFit 은 고려하지 않고, UniPELT 의 submodule 에서 BitFit 제외 LoRA 의 경우 STS-B 및 QQP (K={100,500}K = \\{100, 500\\}K={100,500}) 에서 효과적으로 학습하지 못하여, 실행 간 variance 가 높다. 그 외에는 fewer trainable parameter 를 사용해도 Adapter 같은 competitive 성능을 나타난다. ㅏ=1000ㅏ = 1000ㅏ=1000 일 때 8 asks 중 4 tasks 에서 최고 또는 2위 성능 달성 LoRA 는 저자의 static gating function 으로 볼 수 있는 scaling factor α\\alphaα 존재. 저자는 다양한 α\\alphaα 로 LoRA 를 평가하여 중요성 조사 Fig. 3 처럼, LoRA 는 scaling factor 에 민감. 여러 task 와 data setup 에 잘 작동하는 최적값이 보이지 않음. α\\alphaα 를 증가시키면 일관되게 빠른 수렴이 이뤄지는 것을 발견. 이는 큰 α\\alphaα 로 인해 trainable parameter 가 더 큰 gradient update 를 받기 때문","s":"4.2 Analysis of Individual PELT Methods","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#42-analysis-of-individual-pelt-methods","p":1374},{"i":1397,"t":"Low-Resource Performance​ UniPELT (APL) 및 UniPELT (AP) 를 training sample 수에 관계없이 development 및 test set 에서 일관되게 best 및 second best average performance 달성 이 결과는 hybrid 방식이 모델의 효과성 및 일반화에 이점을 줌 각 per-task level 에서 UniPELT (APL) 및 UniPELT (AP) 는 100/500/1,000 sample 로 훈련시켰을 때, 8 tasks 중 7/6/7 tasks 에서 best 및 second best performance 발휘. 어떤 설정에서도 worst performance 를 내지 않음 두 변형 모델을 비교할 때, UniPELT (APL) 은 100/500/1,000 sample 에서 8 tasks 중 4/6/8 tasks 에서 UniPELT (AP) 능가 이 결과는 UniPELT 가 견고하며 다양한 상황에서 신뢰 가능한 성능을 발휘함을 나타냄 UniPELT 의 개선은 일반적으로 fewer training sample 일 때 더 크다. 이는 UniPELT 가 low-resource 에서 특히 잘 수행됨을 시사 특히, CoLA 및 QQP task (K=100K = 100K=100) 에서 다른 PELT 는 효과적으로 학습하지 못할 때, UniPELT 는 fine-tuning 보다 우수한 성능 달성 UniPELT vs. Upper Bound​ Table 2 에서 UniPELT 와 각 task 에서의 submodule 의 best performance 를 고려한 상황 비교 UNIFPELT (AP) 및 UniPELT (APL) 이 상한과 유사하거나 나은 성능 발휘 이는 UniPELT 가 서로 다른 submodules 를 활용하고 다양한 설정에서 (거의) best performance 를 유지하는데 성공함을 시사 UniPELT 가 상한을 능가할 수 있는 사실은 PELT 의 혼합이 본질적으로 효과적임을 시사 UniPELT가 상한을 능가할 수 있는 사실은 PELT 방법의 혼합이(PLM 아키텍처의 제한된 범위를 갖는 단일 방법보다) 본질적으로 효과적일 수 있다는 가능성을 시사합니다. High-Resource Performance​ Table 3 에서 all training samples 를 사용했을 때의 성능을 나열 UniPELT 가 다시 best performance 달성 이러한 향상이 low-resource 보다는 덜 중요하다고 언급했다. 기존 PELT 방법은 일반적으로 충분한 데이터가 있을 때 fine-tuning 과 유사한 성능을 발휘하며 향상 잠재력이 그리 높지 않기 때문 그럼에도 UniPELT 는 8 task 모두에서 best 거나 second 이며, 개별로 submodule best performance 와 대체로 유사 여러 PELT 를 누적하여 사용하는 것이 gating 없이는 high-resource 에서 잘 작동하지 않는데, UniPELT-NoGate 는 각 task 에서 best performance 를 내지는 않지만, 그 평균 성능이 만족스럽지 않다. (-0.89 vs UniPELT)","s":"4.3 Analysis of UniPELT","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#43-analysis-of-unipelt","p":1374},{"i":1399,"t":"Table 4 에 trainable parameter 및 training/inference time 을 fine-tuning 과 비교 Parameter Efficiency​ PELT 의 trainable parameter 는 무시할 정도로 작아서 여러 방법을 결합해도 효율성에 손실을 초래하지 않는다. UniPELT 는 fine-tuning 과 비교하여 여전히 few trainable parameter 를 가진다. (0.99% ~ 1.26%) 이런 parameter 는 더 효율적인 변형을 사용하면 기본 버전과도 쉽게 교체 가능 more parameter-efficient 가 항상 더 나은 성능으로 이어지진 않음. 이는 저자의 실험과 이전 연구 (He et al. 2021; Pfeiffer et al. 2021) 에서 나타났음 Training and Inference Efficiency​ parameter efficiency 로 인해 모든 PELT 는 fine-tuning 보다 30% ~ 50% 빠르게 학습하며, 이들을 통합한다고 해서 학습 속도가 느려지지 않는 반면, PELT inference time 은 더 오래 걸렸음 이는 더 많은 FLOPs 를 포함하기 때문 UniPELT 는 약간 더 큰 inference overhead (가장 느린 submodule 대비 4% ~ 11%)를 가지고 있음 하지만 저자는 이를 무시 가능할 정도라 주장. 유사한 성능 향상을 달성할 수 있는 더 큰 모델 (e.g. BERTlarge_\\text{large}large​)은 약 300% 의 inference time 이 필요하기 때문","s":"4.4 Efficiency of PELT Methods","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"#44-efficiency-of-pelt-methods","p":1374},{"i":1401,"t":"Parameter-Efficient Tuning of PLMs​ 다양한 downstream task 를 위해 large PLM 전체를 copy 하고 훈련 및 저장하는 것이 현실적으로 점점 어려워져, few trainable parameters 를 사용하여 효율적으로 튜닝하는 것이 중요해짐 기존 PELT 는 new trainable parameter 의 도입 여부로 크게 두 가지로 나눌 수 있다. training model subset parameter (i.e. prediction head, bias terms) PLM 의 여러 부분에 task-specific parameter 도입 (i.e. multi-head attention 이전, feedforward layer 이후) PELT methods 수의 증가로 UniPELT 의 목적은 새로운 방법의 차이를 잘 이해하고 활용하는 것 Mixture-of-Experts​ UniPELT 는 다양한 input 에 따라 다양한 부분을 활성화시키는 방법과 관련 있다. 그 중 하나는 Mixture-of-Experts (MoE) (Jacobs et al. 1991; Shazeer et al. 2017) 이다. MoE 는 experts (neural networks) set 과 각 input 에 특화된 experts 의 조합을 선택하는, 하나 이상의 trainable gates 를 유지 개념적으로 유사하지만 UniPELT 와 MoE 는 다르다. UniPELT 의 submodules 는 MoE 처럼 명시적으로 합산되지 않고 순차적으로 영향을 미침 UniPELT 의 \"experts\" 는 일반적으로 MoE 의 동질적이거나 동일한 것과 달리 다양함","s":"5. Related Work","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1403,"t":"본 논문에서 저자는 parameter-efficient language model tuning (PELT) 에 대해 포괄적인 연구 및 unified framework 로 여러 PELT 를 submodules 로 통합하고 task / data 에 대해 적절한 submodules 를 활성화하여 학습하는 UniPELT 제안 UniPELT 는 다양한 설정에서 fine-tuning 및 submodules 보다 일관된 우수한 성능을 보임 개별 submodules 의 best performance 가 취하는 상한선을 일반적으로 능가 연구 결과 PELT 혼합이 모델 효과성과 견고성에서 선호될 수 있음을 시사","s":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/Mixture/UniPELT","h":"","p":1374},{"i":1405,"t":"논문 및 이미지 출처 : https://aclanthology.org/2022.acl-long.346.pdf","s":"SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1407,"t":"Pre-trained Language Models (PLMs) 를 downstream task 에 적용하기 위한 peft method 에 관심이 커지고 있다. Lester et al. (2021) 의 Prompt Tuning 은 다양한 task 수행을 위해 frzen PLMs 에 task-specific soft prompts 를 학습 시킨다. 저자는 SPoT: Soft Prompt Transfer 접근법으로 새로운 prompt-based transfer learning 을 제안한다. 먼저 하나 또는 그 이상의 source task 에 prompt 를 학습 이후 target task 에 prompt 를 초기화하여 사용 많은 task 에서 Prompt Tuning 의 성능을 촉진 SuperGLUE 에서 모든 모델 사이즈에서 model tuning (full fine-tuning) 을 비슷하거나 능가하고 27,000x 적은 파라미터 사용 SPoT 이 가장 효과적인 지점을 이해하기 위해, 26 NLP task 에서 large-scale study 수행하고, 많은 task 가 서로 prompt transfer 을 통해 이익을 얻음을 보여준다. 마지막으로, task prompts 를 task embeddings 로 해석하여 유사한 tasks 를 식별하고, novel target task 에 대해 가장 transferable source task 를 예측하는 효율적인 retrieval approach 를 제안","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1409,"t":"Large PLMs 가 과거부터 빠르게 개발되며 사이즈 또한 증가하며 best performacnce 를 보여준다. 이런 트렌드는 다양한 NLP 벤치마크에 대한 가능성 경계를 부수지만, 응용하는데는 어려움이 있다. fine-tuning 의 불가능을 우회하기 위해, Brown et al. (2020) Prompt Design 을 제안하여, 모든 downstream task 를 language modeling task 로 변환하고, frozen PLMs 은 추론 시 제공된 manual text prompts 로 다양한 task 수행 single frozen GPT-3 으로 few-shot 에 인상적인 성능을 보여주지만, prompt 선택에 의존하여 여전히 SOTA fine-tuning 에 못미침 최근 soft prompts 학습이 탐구되어, additional learnable parameter 를 모델에 주입 Lester et al. (2021) Prompt Tuning 을 제안하여, 각 downstream task 에 대해 adaption 중 small task-specific 을 학습하여 frozen model 을 conditioning Prompt Tuning 은 model tuning 과 comparable 하지만, 모델 크기가 작을 때 (< 11B), gap 이 존재 본 논문에서, SPoT: Soft Prompt Transfer 을 제안 먼저 하나 또는 그 이상의 source task 에 prompt 를 학습 이후 target task 에 prompt 를 초기화하여 사용 실험에서 task 및 model size 전역에서 prompt tuning 을 넘어선 향상을 제공 SuperGLUE 에서, T5-Base (220M) 및 T5-XXL (11B) 에서 +10.1 및 +2.4 average accuracy 향상 model size 전역에서 model tuning 과 comparable 하거나 outperform 위 결과에 동기부여받아, soft prompts lens 를 통해 task 간의 transferability 를 조사한다. 그리고 다음 질문이 발생할 수 있다. target task 가 주어졌을 때, source task prompt 를 언제 초기화하는 것이 성능을 촉진시키는가? source 및 target task 로, 160 조합의 26 NLP 를 사용하여 T5-model 연구 이 결과로 많은 task 는 prompt transfer 를 통해 서로 이득이 되는 것을 표시 task prompts 를 사용하여 어느 source tasks 가 novel target task 로 잘 transfer 할 지 효율적으로 예측할 수 있을까? task 의 semantic space 구성을 위해 learned task prompts 를 task embeddings 로 해석하고 task 간의 유사성을 공식화 저자는 task embedding simiarity 를 측정하여 positive transfer 할 가능성이 있는 source tasks 를 구별할 수 있는 retrieval algorithm 설계 summarization novel prompt-based transfer learning 인 SPoT 제안, model tuning 의 성능과 맞먹기 위해 prompt tuning 의 scalining 을 필요로 하지 않음을 보여줌 task transferability 에 large-scale 및 systematic study 를 수행하여, tasks 가 서로 prompt transfer 되어 이득을 얻음을 입증 task 의 semantic space 구성을 위해 task prompts 를 task embeddings 로 해석하고 서로 이득될 수 있는 task 를 식별하도록 task embedding simiarity 를 측정하는 효율적인 retrieval method 제안","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1411,"t":"target task 에 대한 Prompt Tuning 성능 향상을 위해, SPoT 은 language model pre-trainng 및 target prompt tuning 사이에 중간 training stage 로 source prompt tuning 을 도입 (Fig. 2, left) 하나 또는 그 이상의 source tasks 에 prompt 학습 (with frozen model) 시킨 후, target task 에 대한 prompt 를 초기화하여 사용 Prompt Tuning 의 계산적 이득을 유지하며, target task 에 대해 small task-specific prompt 저장만 요구하여, 모든 task 에 single frozen PLMs 를 재사용 가능 all target tasks 에 대해 single transferred prompt 를 재사용하는 것을 generic SPoT 로 표시","s":"2. Improving Prompt Tuning with SPoT","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1413,"t":"SMALL, BASE, LARGE, XL, XXL with 60M, 220M, 770M, 3B, 11B parameter 의 모든 T5 사이즈를 frozen model 로 사용","s":"2.1 Experimental setup","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#21-experimental-setup","p":1404},{"i":1415,"t":"SPoT 과 다음 baselines 비교 Prompt Tuning​ Lester et al. (2021) 의 vanilla prompt tuning 을 사용하며, 각 target task 에 prompt 를 독립적으로 직접 사용 Model Tuning & Multi-Task Model Tuning​ prompt tuning 을 standard fine-tuning (Devlin et al. 2019; Raffel et al. 2020;) 인 model tuning 과 비교 공정한 비교를 위해, 개별적으로 target task 에 fine-tuning 하기 전에 SPoT 에 사용된 source tasks mixture 를 사용한 Multi-Task Model Tuning 을 포함하며","s":"2.1.1 Baselines","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#211-baselines","p":1404},{"i":1417,"t":"GLUE 및 SuperGLUE 로부터의 다양한 set 에 downstream performance 연구 고정된 수의 step 으로 훈련하고 각 dataset 의 validation set 에 대한 결과를 report","s":"2.1.2 Evaluation datasets","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#212-evaluation-datasets","p":1404},{"i":1419,"t":"training data 의 선택은 성공적인 prompt transfer 에 중요하다. source training data 의 영향을 조사하기 위해, 다양한 set 의 source tasks 비교 A single unsupervised learning task:​ 먼저 C4 (Colossal Clean Crawled Corpus) dataset 의 일부를 prompt 로 훈련하는 것을 고려 이 훈련은 (Raffel et al. 2020) 의 \"prefix LM: 을 목적으로 수행 이미 frozen T5 model 을 pre-train 에 사용된 task 이지만, 여전히 일반적인 목적의 prompt 를 학습하는 데 도움이 될 수 있다. A single supervised learning task:​ 대체로, supervised task 를 사용하여 prompt 를 훈련할 수도 있다. MNLI 또는 SQuAD 를 single source task 로 사용 MNLI : sentence-level classification task 에 도움이 된다. SQuAD : QA task 에 잘 일반화할 수 있음 A multi-task mixture:​ T5 는 단순히 서로 다른 dataset 을 mixing 하였다. 저자는 GLUE, SuperGLUE, natural language inference (NLI), paraphrasing/semantic similarity, sentiment analysis, MRQA 의 question answering (QA), RAINBOW 의 commonsense reasoning, machine translation, summarization 및 GEM 의 natural language generation 등의 벤치마크를 섞는다. 위 tasks 에서 source task mixture 를 만들고, Raffel et al. (2020) 의 examples-proportional mixing strategy 을 사용하여 모든 데이터셋 (C4 + 55 labeled dataset) 으로 구성된 mixture 을 만든다. artificial dataset size limit K=219\\mathcal{K} = 2^{19}K=219 examples 사용","s":"2.1.3 Data for source prompt tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#213-data-for-source-prompt-tuning","p":1404},{"i":1421,"t":"저자는 Lester et al. (2021) 의 훈련 과정을 밀접하게 따름. source 와 target prompt tuning 중 도입되는 new parameters 는 각 (embedded) input sequence 에 prepend 된 shared prompt ρ∈RL×E\\rho \\in \\mathcal{R}^{\\mathcal{L} \\times \\mathcal{E}}ρ∈RL×E L,E\\mathcal{L}, \\mathcal{E}L,E : prompt length 및 embedding size 모든 케이스에서 L=100\\mathcal{L} = 100L=100 tokens 설정 및 고정된 수의 step S\\mathcal{S}S tuning Lester et al. (2021) 에선 S\\mathcal{S}S 가 30K 였지만, 저자는 large dataset 에서는 Raffel et al. (2020) 을 따라 예외적으로 S=s18=262,144\\mathcal{S} = s^{18} = 262,144S=s18=262,144 사용 source prompt tuning 에선 prompt token embeddings 는 sampled vocabulary (흔한 tokens 5,000개) 에서 초기화 500 steps 마다 checkpoint 저장하고 validation 성능 중 우수한 checkpoint 에서 결과를 report","s":"2.1.4 Training details","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#214-training-details","p":1404},{"i":1423,"t":"SPoT significantly improves performance and stability of Prompt Tuning​ T5 BASE 로 GLUE 및 SuperGLUE 벤치마크의 결과는 prompt transfer 이 Prompt Tuning 에 대한 성능 향상에 효과적이란 것을 시사 GLUE 및 SuperGLUE 에서 SPoT 는 vanilla Prompt Tuning 보다 +4.4 및 +10.1 point average accuracy 향상 ablation study 에선 longer tuning 이 best 성능을 위해 중요한 구성 요소인 것, prompt transfer 과 상호보완적임을 나타냄 longer tuning 이 생략되면, SPoT 이 실행 간의 안전성을 향상시키는 것 관찰 SPoT 내의 다양한 source mixture 의 효과를 비교 GLUE 의 source prompt tuning 이 GLUE 와 SuperGLUE 모두에서 best 성능을 얻어, 82.8 및 73.2 달성 흥미롭게, C4 에서의 unsupervised source prompt tuning 도 상당한 개선이 나타나며, SuperGLUE 를 사용한 것보다 SuperGLUE task 에서 우수한 성능 보임. MNLI 또는 SQuAD 를 single source dataset 으로 사용하는 것도 특히 target task 에 도움이 됨 다른 source mixture 은 일부 task 가 다른 것보다 더 많은 혜택을 보이는 이득도 가져올 수 있다. 모든 dataset 을 섞어도 best 성능을 달성하지 못할 수 있으며, 이는 interference/negative transfer 문제일 수 있다. 즉, 하나 또는 이상의 source task 에서 좋은 성능을 달성하면 target task 성능에 해를 끼칠 수 있다. SPoT helps close the gap with Model Tuning across all model sizes​ Lester et al. (2021) 에서 Prompt Tuning 이 XXL size 에서 model tuning 성능과 가깝게 일치했다. 하지만 작은 사이즈 모델에선 큰 gap 이 발생한다. 저자는 이 gap 을 줄이는데 도움을 주고, prompt tuning 의 계산적 이익을 유지하며 model tuning 의 성능을 넘어서 다양한 모델 사이즈에서도 큰 폭으로 넘었다. XXL size 에서, task-specific parameter 가 27,000x 더 적음에도 불구하고 SPoT 는 best average score 91.2 에 달성하여 multi-task model tuning 보다 +1.1 넘어 섰다. SPoT 효과 검증을 위해, XXL 모델의 예측을 SuperGLUE 리더보드에 제출하여, 89.2 score 달성 파라미터 효율적 adaptation 에서 이전 모든 submissions (GPT-3, 71.8) 보다 뛰어나며, 27,000x 적은 파라미터를 튜닝하였는데도 full fine-tuned T5-XXL (89.3) 과 맞먹는다","s":"2.2 Effect of SPoT","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#22-effect-of-spot","p":1404},{"i":1425,"t":"prompt transfer 은 prompt tuning 성능 향상을 가져오지만, 올바른 source task 선택이 중요하단 것을 보았다. 예로, GLUE 및 MNLI 가 각각의 GLUE 및 SuperGLUE task 로의 transfer 에 뛰어난 source task 란 것을 발견 사용자가 source task set 을 검색할 수 없는 제한된 resource 상황은 어떡할까?, 하나씩 테스트하지 않고도 어느 task 가 novel target task 로 잘 transfer 할지 예측할 수 있을까? 이를 조사하기 위해 26 NLP task 에 경험적 연구 수행. 먼저 모든 task combinations 의 transferability 측정 그 후, task prompt 를 task embedding 으로 해석하여 similar tasks cluster 로 묶는 semantic task space 구성 가능 위 관찰로, task embedding similarity 를 활용하여 novel target task 에 대해 어느 source task 를 사용할 지 선택하는 retrieval algorithm 제안 저자의 방법은 source task search space 의 69% 를 제거하면서 best-case quality gain 의 90% 유지","s":"3. Predicting task transferability","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1427,"t":"16 source dataset 및 10 target dataset 연구 160 possible source-target pairs 를 고려하고, 각 source task 에서 각 target task 로의 transfer 수행 모든 source tasks 는 data-rich 또는 이전 연구에서 positive transfer 을 보여줬음 현질적인 상황을 시뮬레이션하기 위해, target task 로 low-resource tasks (10L training example 미만)을 사용 계산 비용을 제한하기 위해, 모든 task transferability 실험은 T5 BASE 사용 source task 에 대해 262,144 prompt tuning step 수행 source task validation 성능이 가장 우수한 prompt checkpoint 를 선택하여 target task 의 prompt 로 초기화 target dataset 이 작기 때문에 각 target task 에선 100K prompt tuning steps 수행 각 실험은 서로 다른 random seeds 로 세 번 반복 훈련 세부 사항은 2.1.4 와 동일 Tasks benefiting each other via prompt transfer​ Fig. 3 에서 heatmap 결과 보여줌. many case 에서, prompt transfer 은 target task 에서 상당한 이득 제공 MNLI →\\rightarrow→ CB : 58.9% 의 오류 감소로 큰 향상 (average score 92.7 to 97.0) MNLI →\\rightarrow→ COPA (29.1%) 및 RECORD →\\rightarrow→ WSC (20%) 각 target task 에 대해, 48개 중 best source prompt 를 사용하면 10 target tasks 의 average score 가 74.47 to 80.7 극적으로 향상 전반적으로 large source tasks 로부터 효과적인 transfer 을 보여주며, 이는 sentences 간의 semantic relationships 에 대한 high-level reasoning 을 포함한 large source task (e.g. MNLI) 일때나 source 및 target task 가 유사할 때 발생 (e.g. CxC →\\rightarrow→ STS-B) 유사하지 않은 task 간에도 positive transfer 이 발생 가능 (e.g. RECORD →\\rightarrow→ WSC, SQuAD →\\rightarrow→ MRPC, CxC →\\rightarrow→ WiC)","s":"3.1 Measuring transferability","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#31-measuring-transferability","p":1404},{"i":1429,"t":"specific task 에 prompt tuning 중 prompt parameter 만 업데이트 되므로 learned prompts 는 task-specific knowledge 를 인코딩할 가능성이 높다. 이는 task 특성과 관계를 추론하는 데 사용될 수 있음을 시사한다. 이를 검증하기 위해 task prompts 를 task embeddings 으로 해석하고 task semantic space 를 구성 구체적으로, task 의 embedding 을 10K steps training 후의 prompt checkpoint 로 정의 early checkpoint 를 사용하면 novel target task 에 대한 task embedding 을 빠르게 계산할 수 있다. 두 task t1t^1t1, t2t^2t2 의 similarity 추정을 위해 해당 task embeddings e1e^1e1, e2e^2e2 간의 similarity 를 다음 metrics 로 사용 Cosine similarity of average tokens prompt tokens 의 average pooled representations 사이의 cosine similarity 계산 sim(t1,t2)=cos⁡(1L∑iei1,L∑iei2),sim(t^1, t^2) = \\cos(\\frac{1}{\\mathcal{L}}\\sum_ie^1_i, \\mathcal{L}\\sum_ie^2_i),sim(t1,t2)=cos(L1​i∑​ei1​,Li∑​ei2​), ei1e^1_iei1​, ei2e^2_iei2​ : e1e^1e1, e2e^2e2 의 prompt tokens cos⁡\\coscos : cosine similarity Per-token average cosine similarity 모든 prompt token pair (ej1e^1_jej1​, ej2e^2_jej2​) 간의 average cosine similarity 계산 sim(t1,t2)=1L2∑i∑jcos⁡(ej1,ej2),sim(t^1, t^2) = \\frac{1}{\\mathcal{L^2}}\\sum_i\\sum_j\\cos(e^1_j, e^2_j),sim(t1,t2)=L21​i∑​j∑​cos(ej1​,ej2​), Task embeddings capture task relationships​ Fig. 4 는 Cosine Similarity of Average Tokens metric 을 사용하여 task embedding 간의 cosine similarity 를 hierarchically-clustered heatmap 을 보여준다. 저자는 learned task embeddings 가 직관적인 task relationships 를 잘 capture 하는 것을 발견. 구체적으로 similarity task 가 함께 클러스터를 형성하는 것을 볼 수 있다. QA (SQuAD, ReCoRD 및 DROP; MultiRC, BoolQ), sentiment analysis (YELP-2, SST-2 및 CR), NLI (MNLI 및 CB; DICNLI 및 RTE), semantic similarity (STS-B 및 CxC), paraphrasing (MRPC 및 QQP) 및 commonsense reasoning (WinoGrande, HellaSWAG 및 CosMosQA) SQUAD dataset 에서 만들어진 NLI task 인 QNLI 는 SQuAD 와 밀접한 관련이 없었다. 이는 task embedding 이 domain similarity 보다 task type 에 더 민감하다는 것을 시사 또한 ReCoRD 의 high transferability 를 WSC 로 capture 그리고 same task 의 다양한 prompts 에서 유도된 task embedding 은 high similarity 를 가진다.","s":"3.2 Defining task similarity through prompts","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#32-defining-task-similarity-through-prompts","p":1404},{"i":1431,"t":"저자는 task embedding 을 활용하여 task transferability 를 예측하고 탐구. 구체적으로, target task 에 대해 가장 유익한 source task 를 예측하고, target task 성능 향상을 위해 source task prompt 를 활용하는 방법 탐구 source prompt set 을 확장하기 위해, 각 source task 에서 세 가지 prompt tuning run 의 prompt 를 사용하여 48개의 source prompt 를 얻음 task ttt 와 task embedding ete^tet 가 있을 때, similarity sim(es,et)sim(e^s, e^t)sim(es,et) 에 따라 내림차순으로 all source prompts ρs\\rho^sρs 와 관련된 embeddings ese^ses 를 순위매김 source prompts list 의 rank 를 ρsr\\rho^{s_r}ρsr​ 로 표시 rrr : rank (r=1,2,…,48r = 1, 2, \\dots, 48r=1,2,…,48) 순위가 지정된 source prompt 는 다음 세 가지 방법 실험 Best of Top-kkk top-kkk source prompt 를 선택하고 target prompt 로 초기화하여 개별적으로 사용 이 절차는 target task ttt 에 prompt tuning kkk 번 요구 효과성 평가를 위해 best 개별 결과를 사용 Top-kkk weighted average top-kkk source prompts ∑r=1kαrρsr\\sum^k_{r=1}\\alpha_r\\rho^{s_r}∑r=1k​αr​ρsr​ 의 weighted average 와 함께 target prompt 를 초기화하여 target task ttt 에 한번만 prompt tuning 수행 weights αr\\alpha_rαr​ 은 다음을 계산 αr=sim(esr,et)∑l=1ksim(esl,et),\\alpha_r = \\frac{sim(e^{s_r}, e_t)}{\\sum^k_{l=1}sim(e^{s_l}, e_t)},αr​=∑l=1k​sim(esl​,et​)sim(esr​,et​)​, esre^{s_r}esr​ : psrp^{s_r}psr​ 에 대응하는 task embedding Top-kkk multi-task mixture top-kkk prompts 에 속하는 source task 를 식별하고, Raffel et al. (2020) 의 example-proportional mixing 전략을 사용하여 이들의 dataset 과 target dataset 을 섞는다. 그 후, 이 multi-task mixture 에 대한 source prompt tuning 을 수행하고 final prompt checkpoint 를 사용하여 target prompt 를 초기화 각 방법이 달성한 all target task 의 average score report 비교를 위해 각 target task 에 baselines (only prompt tuning) 에 대한 향상도 측정 추가로, 각 target task 에 대해 48개의 source prompt 중 best 를 식별하기 위해 brute-force search 로 얻는 oracle 을 포함 Correlation between task similarity and task transferability​ Fig. 5 는 source 와 target task embedding 간의 similarity 에 따라 target task 에서의 relative error reduction 변화량을 보여줌. 전반적으로 task embedding similarity 와 task transferability 사이의 positive correlation 관찰 10개 target task 중 4개 STS-B (p<0.001p < 0.001p<0.001), CB (p<0.001p < 0.001p<0.001), WSC (p<0.01p < 0.01p<0.01) 및 RTE (p<0.001p < 0.001p<0.001) 에서 관찰. 다른 task 는 상대적으로 유의미하지 않았다. some cases (e.g. BoolQ) 에는 낮은 cosine similarity (0.4) 에도 불구하고 MNLI 의 source prompt 에 의해 19.0% 의 큰 error reduction 을 관찰 이는 task similarity 외의 요인 (data size, task difficulty, domain similarity, etc)도 transferability 결정하는데 역할을 할 수 있다는 것 시사 Retrieving targeted source tasks via task embeddings is helpful​ Table 3 은 target task 에 대해 어느 source prompt 가 유욕할지 식별하는 다양한 방법을 비교 결과는 best of top-kkk 가 효과적임을 보여줌 per-token average cosine similarity 를 사용하여, target task 와 best task embedding similarity 를 가진 source prompt 를 선택하는 것만으로 baseline 대비 큰 폭으로 향상 (74.7 to 47.7, 평균적인 error reduction 12.1%) target task 에 대해 top-3 (48 개 중) source prompt 를 시도하면 평균 점수가 77.5 kkk 의 큰 값으로 top-kkk weighed average 는 oracle 혜택을 유지하면서 (k = 9 일 때 80% 향상, k = 15 일 때 90%), candidate source prompt 의 2/3 제거할 수 있다. top-kkk weighted average 는 k=1k = 1k=1 에서 best of top-kkk 와 유사한 평균 성능을 갖지만 낮은 분산을 가짐. 따라서 target task 에 대한 러 prompt tuning 을 시도하는 것이 계산적으로 힘들면 best of top-kkk 를 대안으로 사용 가능 top-kkk multitask mixture 는 평균 점수가 77.8 로 강력한 성능 제공. k≤3k \\leq 3k≤3 인 경우 best of top-kkk 를 능가","s":"3.3 Predicting transferability via simiarity","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"#33-predicting-transferability-via-simiarity","p":1404},{"i":1434,"t":"다른 peft 는 특정 상황에서 prompt tuning 을 능가하므로, SPoT 와 유사한 접근 방식이 성공적으로 확장될 수 있음과 자체의 장점을 믿는다. LLM 이 점점 커지며 prompt tuning 의 다른 이점은 다음과 같다. 0.01% 미만의 task-specific parameter 만 필요한 효율적인 방법 prompt tuning 은 더 간단하며 아키텍처 수정하지 않아, task 간 transfer learning 을 용이하게 함 모델 용량 증가에 따라 model tuning 과 competitive soft prompts 는 natural instruction 으로 해석 가능 하지만 task embedding 가 transferability 에 미치는 모든 요소는 포착하지 못하여, 다른 방법으로 탐구 필요","s":"5. Limitations & Future work","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1436,"t":"본 논문에선 prompt tuning 의 transfer learning 연구 prompt tuning 이 model tuning 과 매치하는데 규모는 필요없음을 보여주었다. task transferability 에 대한 대규모 실험에서 prompt transfer 을 통해 서로 이득임을 확인 그리고 task prompt 를 task embedding 으로 해석하여 task 간의 similarity 를 형식화 마지막으로 task similarity 를 측정하여 어떤 source task 가 novel target task 에 이익을 줄 수 있는지 식별하는 간단한 retrieval 방법도 제안","s":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/SPoT","h":"","p":1404},{"i":1438,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.11366v3.pdf","s":"Reflexion: Language Agents with Verbal Reinforcement Learning","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1440,"t":"최근 LLMs 는 goal-driven agents 로 사용되는 것이 증가하고 있다. 하지만, 기존의 reinforcement learning 은 훈련 샘플이 많이 필요하고 모델의 fine-tuning 으로 비용이 많이 들어, 이러한 language agent 근 시행착오로부터 빠르고 효율적으로 학습하는 것은 어려운 과제다. 저자는 Reflexion 을 제안한다. weight 업데이트하는 대신 언어적 피드백으로 language agent 를 강화하는 것이다. Reflexion 은 feedback signal 을 반영한 후, 이러한 reflective text 를 episodic memory 에 유지하여 subsequent trial 에서 더 나은 의사결정을 유도한다. Reflexion 은 다양한 타입 (scolor value / free-form language) 및 소스 (외부/내부적 시뮬레이션) 의 feedback signal 을 유연하게 통합하며, 다양한 task (sequential decision-making, coding, language reasoning) 에서 baseline agent 에 비해 상당한 개선을 보인다. HumanEval coding bachmark 에서 91% pass@1 정확도를 달성하여, 이전 SOTA 인 GPT-4 의 80% 를 뛰어 넘었다. 또한, feedback signal, feedback incorporation 및 agent type 에 대한 분석 및 ablation 실험으로 성능을 비교한다.","s":"Abstract","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1442,"t":"최근 연구에선 LLM core 로 구축한 자동 의사결정 agent 의 가능성을 입증한다. 이 방법은 LLMs 를 사용하여 API 호출 및 환경에서 실행할 수 있는 text 및 'action' 을 생성할 수 있다. 하지만 방대한 파라미터 수를 가진 거대한 모델에 의존하여, 기존의 강화학습과 경사하강을 이용한 최적화 방법같은 전통적인 방식은 계산량과 시간이 많이 소비되어 문맥 내의 예제로 agent 에게 가르치는 방식으로 제한되어 있다. 본 논문은 agent 가 이전의 실패로부터 배우는 것을 돕기위해 언어적 강화를 사용하는 Reflexion 이란 대안적 접근법을 제안한다. 이는 환경으로부터 binary 또는 scalar feedback 을 텍스트 요약 형태의 verbal feedback 으로 변환하며, 이는 다음 에피소드에서 LLM agent 에 대한 additional context 로 추가된다. 이 self-reflective feedback 은 'semantic' gradient signal 역할을 하며, 구체적인 개선 방향을 제시하여 과제를 더 잘 수행하도록 도와준다. 이는 인간이 몇 번의 시도로 실패를 반영하여 개선하며 복잡한 작업을 달성하는 것과 유사하다. 예로, Figure 1 에서 Reflexion agent 는 trial, error, self-reflection 을 통해 decision-making, programming 및 reasoning task 를 해결하기 위해 자신의 동작을 최적화하는 방법을 배우게 된다. 유용한 reflective feedback 생성은 어디서 실수했는지를 잘 이해하는 능력과 개선을 위한 통찰을 담은 요약을 생성하는 능력이 필요하여, 매우 어려운 과제이다. 저자는 이러한 수행을 위해 3 가지 방법을 탐구한다. simple binary enviroment feedback pre-defined heuristics for common failure cases LLMs 을 이용한 binary classification 또는 self-written unitests (programming) 과 같은 self-evaluation 모든 구현에서, evaluation signal 은 long-term memory 에 저장될 수 있는 자연어 요약으로 증폭된다. Reflexion 은 policy 또는 value-based learning 같은 기존의 강화학습과 비교하여 몇몇 이점이 있다. 가벼우며 LLM finetuning 불필요 scalar 또는 vector reward 와 비교했을 때, 보다 더 정교한 형태의 feedback (예; action 에 대한 targeted changes)이 가능하며, 정확한 credit assignment 가 어려운 경우에도 수행 이전 경험보다 더 명시적이며 episodic memory 의 해석 가능한 형태 미래 에피소트의 action 에 대한 더 명시적인 힌트를 제공 동시에 LLM 의 self-evaluation capabilities (or heuristics) 의 힘에 의존하는 단점이 있으며, 성공에 대한 정규적 보증이 없다. 다음과 같은 실험 진행 decision-making task : 긴 경로를 통해 sequential action choice test reasoning task : knowledge-intensive, single-step generation improvement test programming task : compiler 및 interpreter 같은 외부 도구로 효과적으로 가르침 세 가지의 task 결과, decision-making task 인 AlfWorld 에선 22%, reasoning task 인 HotPotQA 에선 20%, programming task 인 HumanEval 에선 최대 11% 까지 개선되었다. 주요 contribution 은 다음과 같다. 'verbal' 강화를 위한 새로운 Reflexion 패러다임을 제안. 이는 policy 를 agent 의 memory encoding 과 LLM parameter 의 선택과 결합하는 방식으로 parameterize LLM 에서 나타나는 self-reflection 의 특성을 탐구하고, self-reflection 이 소수의 시도로도 복잡한 작업을 학습하는 데 매우 유용하다는 것을 경험적으로 보여줌 LeetcodeHardGym 을 도입하며, 19개의 프로그래밍 언어로 구성된 40개의 어려운 Leetcode 문제로 구성된 코드 생성 RL gym 환경이다. Reflexion 이 강력한 baseline 모델에 비해 여러 작업에서 개선을 이루며, 다양한 code generation benchmarks 에서 SOTA 달성","s":"1 Introduction","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1445,"t":"활용할 세 가지 모델을 다음과 같이 공식화 Actor model : text 및 action 을 생성할 MaM_aMa​ Evaluator model : MaM_aMa​ 로 생성된 output 의 score 를 나타내는 MeM_eMe​ Self-Reflection model : self-improvement 로 Actor 를 도와주기 위해 verbal reinforcement cues 를 생성할 MsrM_{sr}Msr​","s":"3 Reflexion: reinforcement via verbal reflection","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1447,"t":"Actor 는 state 관찰에 필요한 text 및 action 생성을 위해 특별히 prompted LLM 에 기반하여 만든다. 기존의 policy-based RL 설정과 유사하게, time ttt 에서의 current policy πθ\\pi_\\thetaπθ​ 로부터의 action 또는 generation ata_tat​ 을 샘플링 하고, environment oto_tot​ 로부터 관찰을 얻는다. Chain of Thought 및 ReAct 를 포함한 다양한 Act 모델을 탐구한다. 이러한 다양한 generation model 은 Relfexion framework 내의 text 및 action generation 의 다른 측면을 탐색하여 성능과 효과에 대한 유용한 통찰력을 제공 또한, agent 에게 추가적인 context 를 제공하는 memory component memmemmem 을 추가한다.","s":"Actor","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#actor","p":1437},{"i":1449,"t":"Reflexion framework 의 Evaluator component 는 Actor 로 생성한 output 의 퀄리티를 평가하는 데 중요한 역할을 함 생성된 trajectory 를 입력으로 받아, 주어진 task context 내의 성능을 반역하는 reward score 를 계산 semantic space 에 적용되는 효율적인 value 나 reward function 정의는 어려움으로, 다양한 Evaluator model 을 탐구한다. reasoning task : 생성된 output 이 expected solution 과 밀접하게 align 하기를 보장하는 exact match (EM) grading 에 기반한 reward function 탐구 decision-making task : evaluation criteria 를 명시하기 위해 맞춤형의 pre-defined heuristic function 사용 decision-making 및 programming task 에 대한 reward 생성하는 Evaluator 로서 LLM 의 다른 인스턴스를 사용하여 실험 위의 multi-faceted 접근법으로 생성된 output 에 대한 다양한 scoring 전략을 조사하여, 다양한 task 에 대한 효과성과 적합성에 대한 통찰력을 제공한다.","s":"Evaluator","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#evaluator","p":1437},{"i":1451,"t":"LLM 인 Self-Reflection model 은 future trials 에 대한 valuable feedback 을 제공하기 위해 verbal self-reflections 를 생성하는, Relfexion framework 에서 중요한 역할을 한다. binary success status (success/fail) 같은 reward signal, current trajectory 및 persistent memory memmemmem 이 주어지면, self-reflection model 은 세부적이며 구체적인 feedback 을 생성한다. 이 feedback 은 scalar rewards 보다 많은 정보를 주며, 이는 agent 의 memmemmem 에 저장된다. 예로 multi-step decision-making 에서, agent 가 failure signal 을 받았을 때 특정 동작 aia_iai​ 가 이후의 잘못된 action ai+1a_{i+1}ai+1​ 와 ai+1a_{i+1}ai+1​ 으로 이어질 수 있음을 추론 그럼 agent 는 다른 action ai′a'_iai′​ 을 취했어야 하며, 이는 ai+1′a'_{i+1}ai+1′​ 와 ai+2′a'_{i+2}ai+2′​ 를 발생할 것임을 말함 위의 경험을 memory 에 저장 이후의 trial 에서 agent 는 과거 경험을 통해 time ttt 에서의 decision-making approach 개선을 위해 action ai′a'_iai′​ 을 선택 이런 trial, error, self-reflection 및 persisting memory 과정을 통해 agent 는 정보성 있는 feedback signal 을 활용하여 다양한 환경에서 decision-making 능력을 빠르게 향상","s":"Self-reflection","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#self-reflection","p":1437},{"i":1453,"t":"Reflexion 과정의 핵심 컴포넌트는 short-term 과 long-term memory 개념. inference time 에, Actor 는 short 와 long-term moemory 에 의존하여 결정 내린다. 이는 인간이 최근 세부사항은 기억하며 장기 기억에서 중요한 경험을 회상하는 것과 유사하다. RL 설졍에선, trajectory history 가 short-term memory 에 작용하며, Self-Reflection model 의 output 은 long-term memory 에 저장된다. 이 두 memory components 특정 context 제공을 위해 함께 작동하지만, 여러 trial 에서 얻는 교훈에 영향을 받는다. 이는 Reflexion agent 가 다른 LLM action choice works 에 비해 주요한 이점을 가지고 있다는 것이다.","s":"Memory","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#memory","p":1437},{"i":1455,"t":"first trial 에서, Actor 는 환경과 상호작용하여 trajectory τ0\\tau_0τ0​ 을 생성 Evaluator 는 rt=Me(τ0)r_t = M_e(\\tau_0)rt​=Me​(τ0​) 으로 계산되는 score r0r_0r0​ 을 생성 rtr_trt​ 는 trial ttt 에 대한 scalar reward 으로, task-specific performance 가 향상됨에 따라 개선됨 first trial 후, LLM 으로 인한 개선을 사용할 수 있는 feedback 형식으로 r0r_0r0​ 을 강화하기 위해 Self-Reflection model 이 {τ0,r0}\\{ \\tau_0, r_0 \\}{τ0​,r0​} 집합을 분석하여 summary sr0sr_0sr0​ 을 생성하고 memmemmem 에 저장 srtsr_tsrt​ 는 trial ttt 에 대한 verbal experience feedback Actor, Evaluator 및 Self-Reflection model 은 루프를 통해 협력하여 작동하며, Evaluator deems τt\\tau_tτt​ 가 올바른 것으로 판단할 때까지 반복 memory 파트에서 언급했듯, Reflexion 의 memory component 는 효과성에 중요하다. 각 trial ttt 이후 srtsr_tsrt​ 는 memmemmem 에 추가된다. 실제론 최대 경험 저장 수 Ω\\OmegaΩ (보통 1-3)를 제한하여 max context LLM 제한을 준수","s":"The Reflexion process","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#the-reflexion-process","p":1437},{"i":1462,"t":"Reflxion 은 NL 로 policy optimization 하는 최적화 기법이다. policy optimization 은 경험을 통한 action choice 개선에 강력하지만, non-optimal local minima 에 빠질 수 있다. 본 연구는 long-term memory 를 maximum capacity 로된 sliding window 로 제한했지만, 향후 연구에선 vector embedding databases 또는 전통적인 SQL database 같은 고급 구조로 Reflexion 의 memory component 를 확장하는 것을 권장한다. code generation 에 특정하면, non-deterministic generator function, API 와 상호작용하는 impure function, 하드웨어 사양에 따라 output 이 다른 function, 병렬 또는 동시 동작을 호출하는 함수 등과 같은 정확한 input-output 매핑을 지정하는 데 많은 실질적 제한 사항이 있을 수 있다.","s":"5 Limitations","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":1437},{"i":1464,"t":"논문 및 이미지 출처 : https://aclanthology.org/2022.emnlp-main.758.pdf","s":"XPrompt: Exploring the Extreme of Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1466,"t":"Prompt tuning 은 frozen Pre-trained Language Models (PLMs) 를 conditioning 하기 위해 soft prompts 를 학습한다. 모델 규모가 커짐에 따라 prompt tuning 은 점차 fine-tuning 수준에 도달하지만, moderate 및 small scales (< 11B) 에선 여전히 성능 차이가 발생한다. 본 논문에서 저자는 trained prompt tokens 는 downstream task 에 negative 영향을 줄 수 있으며 성능 저하를 일으킬 것이라는 것을 경험적으로 보여준다. gap 을 줄이기 위해, 저자는 lottery tickets hypothesis 하에, Prompt tuning model with an eXtremely small scale (XPrompt) 를 제안 구체적으로, XPrompt 는 hierarchical structured pruning 을 통해 다양한 granularity levels 에서 negative prompt tokens 를 제거하여 더욱 parameter-efficient prompt 를 생성하여 competitive 성능 달성 SuperGLUE task 에서 포괄적 실험으로, smaller model scales 에서 성능 gap 을 줄여줌","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1468,"t":"PLMs 는 pretrain-then-finetune 을 통해 널리 사용되어 큰 성공을 거두지만, memory 공간에 gradient 및 optimizer 저장을 위해 trainable parameter 가 크게 차지하고 있어 fine-tuning 이 parameter-inefficient 하다. 최근 Prompt-Tuning (Lester et al. 2021) 으로 input 에 soft prompt 를 앞에 붙이고 훈련 중 prompt parameter 만 업데이트하여 위 이슈를 해결하는 것을 제안하였다. fine-tuning 대체제로, soft prompt scale 은 수만배 적음 더 간단하고 다른 peft (Adapter) 보다 유연하여 transformer layers 에 직관적으로 수정 가능 적은 tunable parameter 로 fine-tuning 성능과 competitive 위 gap 을 채우기 위해, 본 논문은 lottery tickets hypothesis (LTH) 관점에서 작성한다. 특정 task 에서 all prompt tokens 이 task 성능에 동등하게 기여하지 않는 관찰에 동기를 받아, 특정 prompt tokens 은 때론 negative 영향을 미칠 수 있다는 것이다. Fig. 2 에서 관찰 결과를 보여준다. negative prompt tokens 는 LTH 로 피할 수 있다. LTH 는 sub-network 를 포함한 over-parameterized network 가 독립적으로 훈련 및 초기화되면 original network 의 정확도와 맞먹거나 능가 이 sub-network 를 Lottery Ticket 이라 하며, PLMs 에서 이러한 ticket set 을 winning tickets 이라 한다. prompt tuning 에서 저자는 전체 prompt 사용의 성능과 동일하게 달성할 수 있는 positive prompt tokens 을 winning tickets 으로, negative prompt tokens 는 losing tickets 로 참조 그래서 핵심은 winning tickets 은 식별하고 losing tickets 은 제거하는 것 hierachical structed pruning 을 통해 losing tickets 을 제거하는 것 제안 token-level 에서 negative tokens 을 제거하고 granularity level (i.e. piece-level) 에서 남은 것들을 pruning LTH 와 일치하도록, 식별된 positive soft prompts 를 재훈련하기 위해 weight rewinding 채택 위 과정으로 negative prompt tokens 이 제거되어 parameter-efficient small scale prompt (XPrompt) 를 얻을 수 있다. XPrompt 의 효과성 검증을 위해, high-resource 및 low-resource 상황의 SuperGLUE 에서 실험 진행 Fig. 1 및 Table. 1 에서 모든 task 및 model scale 에서 prompt-tuning 의 향상을 볼 수 있다. moderate scale 의 모델의 경우, XPrompt 로 fine-tuning 과 comparable 한 성능 달성 및 gap 줄임 large scale 의 모델의 경우, XPrompt 가 Prompt-Tuning 을 넘은 성능을 얻었고, 대부분의 task 에서 fine-tuning 도 넘어섰다.","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1471,"t":"PLMs 는 NLP task 에서 큰 성공을 거두었다. BERT 및 RoBERTa 는 masked language model (MLM) 으로 context representation 을 학습하는 것을 개척 GPT-2, GPT-3 , ELECTRA, XLNet, BART 및 T5 같은 large PLMs 도 생겨남 하지만 parameter 수가 폭발적으로 커지며, fine-tuning model 은 parameter-inefficient 및 computationally expensive 하게 됨 게다가 다양한 task 에 대해 fine-tuning 하고 각각 저장하기까지 해야 한다.","s":"2.1 Pre-trained Language Models","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#21-pre-trained-language-models","p":1463},{"i":1473,"t":"GPT-3 의 개발과 함께, input 에 여러 prompt tokens 를 추가하여 효율적인 학습을 하는 prompt tuning 이 관심을 받고 있다. 이는 다양한 downstream task 에서 효과적임을 입증했다. 최근 discrete tokens (token in the vocabularies) 에서 continuous tokens (trainable embedding) 으로 확장 예로 (Lester et al. 2021), soft prompt 만 tuning 하고 PLMs 는 freezing 하는 효율적인 prompt tuning 제안 하지만 여전히 moderate scale 에서는 fine-tuning 과의 gap 이 존재 더 최근 (Vu et al. 2021) prompt-based transfer learning 인 SPoT 은 source task 에 prompt 를 학습하여 target task prompt 에 초기화하여 적용해 성능을 향상시킴 가장 최근 (He et al. 2022) HyperPrompt 는 hyper-prompts 를 생성하기 위해 hypernetwork 를 사용하여 우수한 성능 얻음 위는 all parameter 를 조정해야 하며, task-conditioned parameter 만 튜닝하는 것이 multi-task learning 에 대한 fine-tuning 과 competitive 결과를 얻는데 충분치 않다는 것을 보여줌","s":"2.2 Prompt Learning in NLP","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#22-prompt-learning-in-nlp","p":1463},{"i":1475,"t":"lottery ticket hypothesis 는 over-parameterized network 는, 초기화되어 독립적으로 학습하면 기존 network 의 정확도와 일치하거나 능가할 수 있는 subnetwork 를 가진 다는 것을 발견 이 subnetwork 를 lottery ticket 이라 함 NLP 에서의 lottery ticket set 은 winning ticket 이라 함 이러한 winning ticket 은 task 및 dataset 간의 transerability 를 입증 최근 Chen et al. (2021) 에서 PLM 이 lottery ticket 의 존재를 보여줌 Liang et al. (2021) 에선 winning ticket 의 일반화 성능이 full model 을 능가할 수 있음을 관찰","s":"2.3 Lottery Ticket Hypothesis","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#23-lottery-ticket-hypothesis","p":1463},{"i":1477,"t":"T5 의 text-to-text 기반으로 한 prompt tuning 은 all task 를 text generation 으로 고려하며 additional lll tunable soft prompt token 을 input 에 추가하고, inserted soft prompt token 의 parameter 만 업데이트 수행 구체적으로, nnn 개의 input token X={x1,x2,…,xn}X = \\{ x_1, x_2, \\dots, x_n\\}X={x1​,x2​,…,xn​} 이 있을 때, T5 는 먼저 token embeddings Xe∈Rn×eX_e \\in \\mathbb{R}^{n \\times e}Xe​∈Rn×e 을 생성한다. eee : embedding space dimension soft prompt embedding Pe={p1,p2,…,pm}∈Rm×eP_e = \\{ p_1, p_2, \\dots, p_m \\} \\in \\mathbb{R}^{m \\times e}Pe​={p1​,p2​,…,pm​}∈Rm×e 생성 mmm : soft prompt length 이후 soft prompts 는 [Pe;Xe]∈R(m+n)×e[P_e; X_e] \\in \\mathbb{R}^{(m+n) \\times e}[Pe​;Xe​]∈R(m+n)×e 형태로 input sequence 앞에 추가 prompt tuning 목표는 PeP_ePe​ 를 optimizing 하여 label YYY 의 likelihood 를 최대화 하는 것 arg⁡max⁡Pelog⁡p(Y∣[Pe;Xe])\\begin{equation} \\underset{P_e}{\\arg \\max} \\log p(Y|[P_e; X_e]) \\end{equation}Pe​argmax​logp(Y∣[Pe​;Xe​])​​ model scale 이 커짐에 따라 prompt tuning 은 더욱 효과적으로 작동한다. 하지만 small 및 moderate scale 에 대해서는 fine-tuning 과 성능 gap 이 존재한다. 저자의 가설은 target task 에 훈련 후 all soft prompt tokens 가 동등하게 성능에 기여하지 않을 것이라는 것이다. 특정 soft prompt tokens 은 task 에 negative impacts 를 줄 수 있다. 따라서 lottery ticket hypothesis 의 아이디어를 결합하여 저자는 XPrompt 를 제안한다. 이는 hierarchical structured pruning 을 사용하여 optimal soft prompts 를 식별하고 성능 차이를 줄인다.","s":"3. Preliminary","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1479,"t":"Fig. 3 은 XPrompt 은 전체 과정이며 세 가지 main stages 를 포함한다. Prompt-Tuning Hierarchical Structured Pruning Rewinding","s":"4. XPrompt","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1481,"t":"input 에 soft prompt tokens 을 붙여 PLM 은 fixing 한 채 soft prompt 만 tuning Prompt tuning 은 다양한 downstream task 에 효과적이다. 저자의 prompt tuning 은 Liang et al. (2021) 에 따르며, all soft prompt tokens 에 대한 embeddings 을 얻기 위해 target task 에 완전히 tuning 위의 trained soft prompts 는 hierarchical structured pruning 에 초기화되어 사용됨","s":"4.1 Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#41-prompt-tuning","p":1463},{"i":1483,"t":"Hierarchical Structured Pruning 은 trained prompt tokens 으로 부터 negative prompt tokens 을 분리하도록 설계하며 optimal soft prompt set 을 식별한다. Fig. 4 에서 접근법을 보여준다. token-level pruning : negative prompt tokens 을 식별하기 위해 먼저 사용 하지만, 남은 prompt tokens 에 nagative pieces 가 여전히 남아 있을 수 있다. piece-level pruning : 그래서, 각 prompt token 의 fine-grained negative prompt pieces 를 식별하기 위해 적용 두 pruning 을 통해 효과성과 효율성 간의 균형을 더욱 잡아 준다.","s":"4.2 Hierarchical Structured Pruning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#42-hierarchical-structured-pruning","p":1463},{"i":1485,"t":"trained prompt tokens 의 negative prompt token 을 식별하기 위해, soft prompt token vector pip_ipi​ 에 mask variable γi\\gamma_iγi​ 을 연결 P^e=γ⋅Pe\\begin{equation} \\hat{P}_e = \\gamma \\cdot P_e \\end{equation}P^e​=γ⋅Pe​​​ γ={γ1,γ2,…,γm}\\gamma = \\{\\gamma_1, \\gamma_2, \\dots, \\gamma_m\\}γ={γ1​,γ2​,…,γm​} γi∈{0,1}\\gamma_i \\in \\{0,1\\}γi​∈{0,1} 0 value : soft prompt token 이 제거된 것을 나타냄 이후, negative prompt tokens 을 구별하기 위해 각 token 의 importance score 계산 importance score 는 mask variables 에 대한 model output 의 예상 민감도로 정의된다. 공식화 하면, soft prompt token pip_ipi​ 의 importance score IpiI_{p_i}Ipi​​ 는 다음과 같이 계산된다. Ipi=Ex∼Dx ∣∂L(x)∂γi∣\\begin{equation} I_{p_i} = \\mathbb{E}_{x \\sim D_x} \\ |\\frac{\\partial \\mathcal{L}(x)}{\\partial \\gamma_i}| \\end{equation}Ipi​​=Ex∼Dx​​ ∣∂γi​∂L(x)​∣​​ L\\mathcal{L}L : loss function DxD_xDx​ : training data distribution 본질적으로, 각 soft prompt token 의 importance score 는 해당 token 이 model performance 에 개별적으로 기여하는 정도를 나타낸다. 낮은 score 는 모델에 small 또는 negative 기여를 나타낸다. 다시 말해, 해당 soft prompt token 은 output 생성에 무시할 만한 prompt information 을 포함하는 것을 의미한다. 반대로, 높은 score 는 의미 있는 prompt information 을 가진 주요 기여를 나타낸다. 따라서 importance score 가 낮은 prompt 는 negative prompt token 일 수 있으므로, token-level pruning 에서 제거된다.","s":"4.2.1 Token-level Pruning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#421-token-level-pruning","p":1463},{"i":1487,"t":"Token-level pruning 은 soft prompt token 을 찾지만, 각 soft prompt token 의 embedding 에 여전히 negative prompt pieces 가 남아 충분하지 않을 수 있다. embedding pieces 는 downstream task 에 다른 영향을 미칠 수 있으므로, 각 token 내의 negative prompt pieces 를 제거하기 위해 Piece-level pruning 을 수행한다. 특히, 각 soft prompt token 의 embedding vector piep_{i_e}pie​​ 를 kkk pieces 로 나누어 qe={q1e,q2e,…,qke}q_e = \\{ q_{1_e}, q_{2_e}, \\dots, q_{k_e}\\}qe​={q1e​​,q2e​​,…,qke​​} 로 만들고 각 piece 를 gradient updates 로 optimize 가능한 독립적인 단위로 취급 각 soft prompt token 의 piece 에는 negative prompt pieces 식별을 위한 mask variable ζi\\zeta_iζi​ 가 연결된다 q^e=ζ⋅qe\\hat{q}_e = \\zeta \\cdot q_eq^​e​=ζ⋅qe​ ζ={ζ1,ζ2,…,ζk}\\zeta = \\{\\zeta_1, \\zeta_2, \\dots, \\zeta_k\\}ζ={ζ1​,ζ2​,…,ζk​} ζi∈{0,1}\\zeta_i \\in \\{0,1\\}ζi​∈{0,1} 0 value : soft prompt token 이 제거된 것을 나타냄 이후, low-imortance pieces 제거를 위해 모든 prompt token embedding 의 각 piece 의 importance score IqiI_{q_i}Iqi​​ 를 계산한다. Iqi=Ex∼Dx ∣∂L(x)∂ζi∣\\begin{equation} I_{q_i} = \\mathbb{E}_{x \\sim D_x} \\ |\\frac{\\partial \\mathcal{L}(x)}{\\partial \\zeta_i}| \\end{equation}Iqi​​=Ex∼Dx​​ ∣∂ζi​∂L(x)​∣​​ token-level importance score 와 유사하게, piece 가 모델 성능에 small 또는 negative 기여를 나타낸다. 저자는 서로 다른 compression ratio 로 sub-prompt tokens 와 pieces 를 얻기 위해 token-level 및 piece-level pruning 을 반복 수행한다.","s":"4.2.2 Piece-level Pruning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#422-piece-level-pruning","p":1463},{"i":1489,"t":"LTH 에선 sparse subnetworks (unoruned prompts) 가 original network (all prompt) 와 동일한 정확도로 독립적으로 훈련될 수 있다 하며, pruning 후 unpruned weights 를 rewinding 하는 것을 제안 LTH 에 따르면, 두 단계의 hierarchical structured pruning 후 soft prompt 를 재훈련하기 위해 weight rewinding 을 채택 구체적으로, optimal soft prompt 의 parameter 를 prompt tuning 후의 value 로 리셋 다른 soft prompt 는 해당 mask values 를 0 으로 설정하여 pruning 된다. 마지막으로 prompt tuning 에서 사용된 original learning 전략을 사용하여 soft prompt 를 다시 훈련","s":"4.3 Rewinding","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#43-rewinding","p":1463},{"i":1492,"t":"저자는 NLP 에서 high-resource 및 low-resource 에서 SuperGLUE 의 다양한 데이터셋으로 평가 제한된 SuperGLUE testset 으로 인해 (Lester et al. 2-21; Ding et al 2021) 에 따라, training set 에서 고정된 steps 으로 prompt tuning 후 best checkpoint 를 사용하여 validation set 을 report","s":"5.1 Datasets","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#51-datasets","p":1463},{"i":1494,"t":"Fine-Tuning​ T5 의 standard fine-tuning (Raffel et al. 2020; Aribandi et al. 2021) 와 비교. all pre-trained parameter 를 각각의 target task 에 개별적으로 fine-tuning Prompt-Tuning​ (Lester et al. 2021) 의 vanilla prompt tuning 는 frozen PLMs 를 downstream task 에 adapting 하기 위한 competitive 기술 P-Tuning​ (Liu et al. 2021c) 의 P-tuning 은 target task 를 cloze problem 으로 변환하깅 위해 masked PLM 을 사용하는 prompt-based 방법이다. 이는 soft prompting 기술로 continuous space 에서 prompt 를 최적화. 또한 P-Tuning 의 두 번째 버전 P-TuningV2 와도 비교 Prefix-Tuning​ (Li and Liang. 2021) 은 자연어 생성 작업에 대한 대안으로, small continuous task-specific vector (called prefix) 를 최적화 prefix 를 각 transformer layer 의 input 에 독립적으로 추가","s":"5.2 Baselines","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#52-baselines","p":1463},{"i":1496,"t":"저자는 prompt learning을 위한 툴킷인 OnePrompt library 를 사용하여 구현 각 SuperGLUE dataset 을 text-to-text 형식으로 변환 단, 어느 task 속했는지를 나타내는 task name 은 input XPrompt 는 pre-trained T5 checkpoint (Large, XL, XXL) 에서 구축 Lester et al. 2021; Ding et al. 2021. 에 따라 훈련 설정 learning rate 0.3 batch size 16 epoch 100 token length 20 sampled vocabulary token pieces 16 pruning frequencies {10%,20%,30%,40%,50%,60%,70%,80%,90%}\\{10\\%, 20\\%, 30\\%, 40\\%, 50\\%, 60\\%, 70\\%, 80\\%, 90\\%\\}{10%,20%,30%,40%,50%,60%,70%,80%,90%} 에서 linearly search weight rewinding 은 한 번만적용되어 pruned soft prompt 를 re-train best checkpoint 는 dev set 에서 early stopping 으로 선택 Adafactor optimizer 를 사용하여 weight decay 1e−51e-51e−5 훈","s":"5.3 Implementation","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#53-implementation","p":1463},{"i":1499,"t":"Xprompt 는 all model scales 에서 prompt tuning 성능을 향상시키고 fine-tuning 과의 gap 을 줄이는데 도움을 줌​ Table 1 및 Table 8 (appendix) 는 SuperGLUE 의 main results XPRompt 는 Prompt-Tuning, Prefix-Tuning, P-Tuning 및 P-TuningV2 와 비교 vanilla Prompt-Tuning 을 all tasks 및 model scales 에서 능가 T5-Large, T5-XL 및 T5-XXL 의 average score 각각 3.26%, 2.96% 및 1.88% 의 개선을 보임 P-TuningV2 가 Prompt-Tuning 및 P-Tuning 을 능가하는데, XPrompt 는 P-TuningV2 보다 탁월한 성과를 거두어 효과적임을 입증 Prefix-Tuning 은 NLG task 를 위해 설계되어, 대부분의 NLU 에선 성능을 덜 발휘 Table 1 에서 보이듯, XPrompt 는 T5-XL 의 all tasks 에서 fine-tuning 과 맞먹고, T5-XXL 에서의 대부분 task 에서 fine-tuning 을 능가 T5-XXL 의 경우 WSC, CB, RTE, Boolq, MultiRC 에서 각각 97.11%, 100.00%, 94.94%, 90.87% 및 88.90% 의 best score 달성하여 fine-tuning 대비 +1.91%, +0.0%, +2.84%, +0.47%, +0.30% 개선 prompt tuning 과 fine-tuning 사이에 small 및 moderate scales 모델에서 일부 gap 이 있는 것을 볼 수 있다. (Fig. 1) 하지만 XPrompt 는 all model scales 에서 이 gap 을 줄이고, downstream task adapting 에 도움을 주는 효율적인 것을 볼 수 있다.","s":"6.1 Results on High-resource Scenarios","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#61-results-on-high-resource-scenarios","p":1463},{"i":1501,"t":"XPrompt 는 low resource scenarios 에서 더 좋은 성능​ 각 task 에 대해 고정된 random seed 를 사용하여 새로운 training set 으로 32 개의 example 을 무작위로 선택 저자는 32-shot 에서 prompt model 을 tuning 하고 best checkpoint 를 사용하여 report Table 2 에서 보이듯, XPrompt 는 prompt tuning 의 성능을 더욱 향상시키고 Boolq, WiC 및 RTE 에서 동일한 규모의 baseline 을 능가 WiC 에서 62.85% 의 best score 달성하여 Prompt-Tuning 대비 +2.04% 개선 이 k-shot 결과는 제한된 데이터로 훈련할 때 overfitting 이 심하더라도, XPrompt 가 일관되게 prompt tuning 의 성능을 향상시킨다는 것을 시사","s":"6.2 Results on Low-resource Scenarios","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#62-results-on-low-resource-scenarios","p":1463},{"i":1503,"t":"XPrompt 효과성을 이해하고 다양한 요소의 영향을 탐구하기 위해, ablation 연구 및 분석","s":"7. Analysis and Discussion","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1505,"t":"hierarchical structured pruning 을 통한 positive 및 negative prompts 을 식별​ positive prompt 에 대한 첫 번째 증거는 XPrompt 가 all task 및 model scales 에서 vanilla prompt tuning 에 비해 큰 성능 향상을 보여주어 효과를 입증 다른 증거는 pruning 의 high sparsities. appendix D 의 Fig. 9 와 Fig. 10 에서 WSC task 에 대한 importance score 의 original 과 pruned gradient saliency maps 를 보여준다. 즉, Fig. 10 의 회색 요소는 low importance score 로 인해 prompt tokens 나 pieces 가 pruning 되었다는 것을 나타내며, 남은 부분이 winning ticket 이라 할 수 있다. 15% positive sub-prompt 를 사용한 XPrompt 의 성능은 full prompt tuning 보다 4.8% 높다. negative prompts 는 Prompt Tuning 및 XPrompt 보다 낮은 성능​ negative prompt 의 존재와 효과를 더 조사하기 위해 다른 구성으로 prompt tuning 성능과 비교 vanilla Prompt-Tuning (all prompts) 와 XPrompt 외에도 세 가지 변형 소개 Reversed XPrompt : XPrompt 의 masked sub-prompt structures 를 반전시켜 low score prompt tokens 및 pieces 를 사용 Random Prompt : rewind stage 에서 tokens 및 pieces 를 무작위로 masking Length Prompt : XPrompt results 와 동일한 promptl ength 로 re-train XPrompt 가 best performance 달성을 보여준다. Reversed XPrompt 가 Random Prompt 및 Length Prompt 를 포함한 all prompt tuning 변형보다 현저히 나쁜 성능을 보여줌 이는 저자의 기대와 일치하며 negative prompt 의 존재를 더욱 확증 Length Prompt 는 평균적으로 Random Prompt 및 Prompt Tuning 보다 성능이 떨어짐 이는 저자의 hierarchical structured pruning 효과를 나타냄","s":"7.1 Do Positive Prompts and Negative Prompts Exist?","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#71-do-positive-prompts-and-negative-prompts-exist","p":1463},{"i":1507,"t":"XPrompt 는 Prompt-Tuning 보다 parameter-efficient​ Table 3 에서 tunable parameter 수를 비교한다. Prompt-Tuning 은 이미 parameter-efficient 이며, full model fine-tuning 에 비해 0.0014% 의 parameter 만을 tuning XPrompt 는 hierarchical structured pruning 을 통해 Prompt-Tuning 의 tunable parameter 수를 더욱 감소 시킨다. 예로, XPrompt 는 Prompt-Tuning 에 비해 parameter 의 15% 및 37.18% 만 tuning","s":"7.2 Parameter Efficiency","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#72-parameter-efficiency","p":1463},{"i":1509,"t":"Token-level pruning 및 fine-grained piece-level pruning 모두 중요​ two-level pruning 의 효과 조사를 위해 Table 4 에 네 가지 SuperGLUE task 에서 포괄적인 pruning 실험 수행 two level 의 pruning 은 vanilla Prompt-Tuning 보다 뛰어나며, toke-level 및 piece-level pruning 의 효과 입증 결과 최적화할 수 있는 trained prompts 의 sub-prompt structures 의 존재를 보여줌 XPrompt 는 개별적인 pruning 보다 우수한 성능을 보이며, 이는 two-level 의 structured pruning 을 결합하는 것이 더 많은 이점을 준다는 것을 시사","s":"7.3 Granularity of Pruning","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#73-granularity-of-pruning","p":1463},{"i":1511,"t":"Prompt Length (20 초과) 늘리면 XPrompt 제한적인 이득만 얻는다.​ Prompt Length 가 XPrompt 에 미치는 영향을 조사하기 위해 T5-XL 모델에 다양한 Prompt Length {10,20,100}\\{10, 20, 100\\}{10,20,100} 으로 XPrompt 훈련 결과는 Table 5 에서 report 결과에서 볼 수 있듯, Prompt Length 가 XPrompt 및 Prompt-Tuning 에 중요한 역할을 한다. 20 tokens 이상으로 늘리면 개선이 제한되는 것을 볼 수 있다. 이는 Lester et al. 2021 의 발견과 일치하며, 이는 모든 실험에서 20 tokens 으로 설정하는 이유","s":"7.4 Prompt Length","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#74-prompt-length","p":1463},{"i":1513,"t":"soft prompt transfer 접근법인 SPoT 에 영감을 받아 task transfer 및 다양한 prompt initialization 효과를 탐구하여, XPrompt Transer 을 도입 먼저 source task 에서 XPrompt 를 통해 prompt 훈련 learned prompts 를 target task 의 prompt 로 초기화 Prompt initialization 은 XPrompt 에서 중요한 역할을 하며, XPrompt Transfer 은 성능 향상을 이끌어 냄​ XPrompt 의 two sample initialization 을 비교하며, 이는 random uniform 및 sampled vocabulary 를 포함하여 Table 6 에 결과가 있다. sampled vocabulary 성능이 가장 좋은 것을 관찰 XPrompt 는 random uniform initialization 에 대한 성능 향상을 이끌어냄 Task Transfer 과 XPrompt Transfer 을 비교하여, Task Transfer 은 source task prompt 만으로 target prompt 로 초기화하며 Table 7 에 결과가 있다. XPrompt Transfer 이 rewinding stage 없이 Task Transfer 보다 우수한 성능 보임 pruning 과 rewinding 을 통해 큰 성능 향상 이끌어냄","s":"7.5 Prompt Initialization and Transfer","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#75-prompt-initialization-and-transfer","p":1463},{"i":1515,"t":"본 논문은 small, moderate scales model 에 대한 prompt tuning 과 fine-tuning 간의 큰 성능 차이를 줄이는 것을 목표 LTH 가설을 탐구하여, novel hierarchical structured pruning 방법인 XPrompt 제안 이 방법은 token-level 및 piece-level 에서의 positive prompt 와 negative prompt 분리 SuperGLUE 실험에서 small parameter-efficient 를 제공하며 성능 유지","s":"8. Conclusions","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1517,"t":"다양한 단계에서 negative prompt token 제거를 위해선 hierarchical structured pruning을 통해 pruned model 을 다양한 압축 비율로 rewinding 해야 한다. 다음 질문들에 대해선 아직 해결할 것들이 남아 있다. training 없이 optimal compression ratio 찾는 법 training process 를 자동화하고 효율성 향상시킬 수 있는 주요한 문제 다양한 시나리오를 추가하여 조사 필요 multitask learning 시나리오, out-of-domain (domain shift) 시나리오, 그리고 prompt ensembling 시나리오","s":"Limitations","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"","p":1463},{"i":1521,"t":"위는 WSC task 에서의 prompt tokens 및 prompt token pieces 분포의 importance scores 를 보여준다. 대부분의 prompt token 이 importance score 를 가지고 있으며, 일부 prompt token 만이 높은 importance score 를 가지고 있는 것이 명확하다. 위 결과는 negative prompt 의 존재와 이들의 안정성에 대한 우리의 가설을 더욱 입증","s":"B. Token and Piece Importance Score","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#b-token-and-piece-importance-score","p":1463},{"i":1523,"t":"Fig. 8 처럼, source task 와 target task 가 주어지면 XPrompt Transfer 은 먼저 source task 에서 XPrompt 를 사용하여 prompt 훈련 후 얻은 prompt 를 target task 의 prompt 로 초기화하기 위해 사용하며, 이후 target task 에서 XPrompt 를 훈련 SPoT 와 달리, learned prompt 를 target task 의 prompt 초기화하는 데 사용하지 않고, 저자의 방법은 prompt 에 more cross tasks information 을 제공할 수 있다. 다양한 prompt initialization 결과는 Table 6 에 있으며, XPrompt Transfer 결과는 Table 7 에 있다.","s":"C. XPrompt Transfer","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#c-xprompt-transfer","p":1463},{"i":1525,"t":"Fig. 9 및 Fig. 10 에서 WSC task 에서의 importance scores original 및 pruned gradient saliency maps 을 보여준다. Fig. 10 에서 회색 셀은 importance score 가 낮아 prompt token 및 piece 를 잘라내고 나머지는 winning ticket 을 의미한다.","s":"D. Importance Scores Visualization","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#d-importance-scores-visualization","p":1463},{"i":1527,"t":"SuperGLUE benchmark​ 이전 연구에 따라 ReCoRD task 를 제외하고 7개 task 에 중점을 둔다. ReCoRD 는 question answering 이기 때문이다.","s":"E. SuperGLUE Statistics, Metrics and Soft Prompt Templates","u":"/docs/Paper/NLP/PEFT/Soft Prompt/XPrompt","h":"#e-superglue-statistics-metrics-and-soft-prompt-templates","p":1463},{"i":1529,"t":"문제 해결을 위한 절차나 방법 수학 및 컴퓨터과학 측면의 알고리즘은, 보통 반복되는 문제를 풀기 위한 작은 프로시저를 의미 크게 3 가지의 표현 방법을 사용 의사 코드 pseudocode 순서도 프로그래밍 언어","s":"What is the Algorithm?","u":"/docs/Programming/Algorithm/","h":"","p":1528},{"i":1531,"t":"알고리즘의 소요 시간을 정확히 평가할 수 없으므로, 자료 수 nnn 에 따라 증가하는 대략적인 패턴을 시간 복잡도로 표기 Big-Ω(n)\\Omega(n)Ω(n) (빅 오메가) : 최선일 때 (best case)의 연산 횟수 표기 Big-Θ(n)\\Theta(n)Θ(n) (빅 세타) : 보통일 때 (average case)의 연산 횟수 표기 Big-O(n)O(n)O(n) (빅 오) : 최악일 때 (worst case)의 연산 횟수 표기 즉, 주어진 문제를 해결하기 위한 연산 횟수를 의미 ※ 파이썬에서는 대략 2,000만 ~ 1억 번의 연산을 1초의 수행 시간으로 예측 가능 일반적으로 O(n)O(n)O(n) 의 시간 복잡도를 기준으로 평가하여 좋은 알고리즘을 나눈다.","s":"Time Complexity","u":"/docs/Programming/Algorithm/","h":"","p":1528},{"i":1533,"t":"알고리즘을 통한 문제 해결 중 필요한 메모리 양을 공간 복잡도로 표기 일반적으로 시간 복잡도처럼 Big-O(n)O(n)O(n) 를 주로 사용 메모리가 상당히 많이 필요한 동적 계획법 을 제외하고는, 공간 복잡도는 시간 복잡도보다 중요도는 떨어진다. 임베디드, 펌웨어 등의 하드웨어 환경과 같이 극도로 한정되어 있을 경우는 공간 복잡도를 중요하게 보게된다.","s":"Space Complexity","u":"/docs/Programming/Algorithm/","h":"","p":1528},{"i":1536,"t":"tip input() Orange Banana input() 내장 함수는 parameter 로 prompt message 를 받을 수 있다. 따라서 입력받기 전 prompt message 를 출력해야 한다. 물론 prompt message가 없는 경우도 있지만, 이 경우도 약간의 부하로 작용할 수 있다. 하지만, sys.stdin.readline()은 prompt message를 인수로 받지 않는다. 또한, input() 내장 함수는 입력받은 값의 개행 문자를 삭제시켜서 리턴한다. 즉, 입력받은 문자열에 rstrip() 함수를 적용시켜서 리턴한다. 반면에 sys.stdin.readline()은 개행 문자를 포함한 값을 리턴한다. 결론 input() 내장 함수는 sys.stdin.readline() 과 비교해서 prompt message 를 출력하고, 개행 문자를 삭제한 값을 리턴하기 때문에 느리다. input 값이 많다면 sys.stdin.readline() 을 사용하자. This is an orange 🍊 This is a banana 🍌","s":"Array & List","u":"/docs/Programming/Algorithm/","h":"#array--list","p":1528},{"i":1538,"t":"구간 합은 합 배열을 통해 복잡도를 더 줄이는 알고리즘 합 배열 S 정의 S[i]=A[0]+A[1]+⋯A[i−1]+A[i]S[i] = A[0] + A[1] + \\cdots A[i - 1] + A[i]S[i]=A[0]+A[1]+⋯A[i−1]+A[i] 리스트 A [15,13,10,07,03,12][15, 13, 10, 07, 03, 12][15,13,10,07,03,12] 합배열 S [15,28,38,45,48,60][15, 28, 38, 45, 48, 60][15,28,38,45,48,60] 합 배열 S 를 만드는 정의 S[i]=S[i−1]+A[i]S[i] = S[i - 1] + A[i]S[i]=S[i−1]+A[i] 위와 같이 구현한 합배열로 구간 합을 쉽게 구할 수 있다. 구간 합 구하는 공식 S[j]−S[i−1]S[j] - S[i - 1]S[j]−S[i−1] A[2] ~ A[5] 구간 합을 구하는 과정 S[5]=A[0]+A[1]+A[2]+A[3]+A[4]+A[5]S[1]=A[0]+A[1]S[5]−S[1]=A[2]+A[3]+A[4]+A[5]\\begin{align*} &S[5] &&= A[0] + A[1] + A[2] + A[3] + A[4] + A[5] \\\\ &S[1] &&= A[0] + A[1] \\\\ &S[5] - S[1] &&= A[2] + A[3] + A[4] + A[5] \\end{align*}​S[5]S[1]S[5]−S[1]​​=A[0]+A[1]+A[2]+A[3]+A[4]+A[5]=A[0]+A[1]=A[2]+A[3]+A[4]+A[5]​","s":"구간 합","u":"/docs/Programming/Algorithm/","h":"#구간-합","p":1528},{"i":1540,"t":"2 개의 포인터로 알고리즘 시간 복잡도 최적 투 포인터를 사용하는 예로는 자연수 NNN 을 연속된 자연수의 합으로 나타낼 수 있는 가짓수이다. N 의 최댓값이 높으면, O(nlog⁡n)O(n \\log n)O(nlogn) 으로는 시간이 오래 걸리므로, O(n)O(n)O(n) 으로 해결하기 위해 투 포인터를 사용해야 한다. 배열 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15][1,2,3,4,5,6,7,8,9,10,11,12,13,14,15][1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] 에서 각 가짓수를 모두 구하기 보단, start_index 와 end_index 를 이동시키며 배열의 끝까지 탐색하며 합이 NNN 이 되는 경우의 수를 구하면 된다. 투 포인터 이동 sum > N: sum -= start_index; start_index++; sum < N: end_index++; sum += end_index; sum == N: end_index++; sum += end_index; count++;","s":"투 포인터","u":"/docs/Programming/Algorithm/","h":"#투-포인터","p":1528},{"i":1542,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2203.02155.pdf https://openai.com/blog/chatgpt 논문 제목 : Training language models to follow instructions with human feedback ChatGPT Blog","s":"Training language models to follow instructions with human feedback (+ ChatGPT)","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1544,"t":"큰 규모의 language 모델은 허위나 toxic 을 유저에게 생성할 수 있다. 다시 말해, 모델이 사용자의 원하는 답과 일치하지 않음을 뜻한다. 본 논문에서는 다음 방법을 제안한다. 라벨러가 쓴 prompt 와 OpenAI API 로 제출된 prompt 의 셋으로 입증된 데이터셋을 모음 지도 학습으로 GPT-3 를 supervised fine-tune 한다. 모델 output 에 랭킹을 매김 human feedback 으로 강화 학습을 진행하여 지도 학습된 모델을 fine-tune 위 과정을 통해 나오는 결과 모델을 InstructGPT 라 칭한다. 이 모델은 175B GPT-3 보다 100배 적은 1.3B 파라미터로 허위가 줄고, 신뢰있도록 개선되었다.","s":"Abstract","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1546,"t":"최근의 Large language models (LMs) 는 인터넷의 정보들을 토큰으로 예측하기 때문에 사용자가 원하는 지시와는 다를 수 있다. 따라서 이는 모델과 유저의 목표가 불일치하다고 할 수 있다. 따라서 사용자의 지시와 일치하는 행동을 하도록 훈련을 하여 aligning 한 언어 모델을 만든다. 여기에 aligning language model 를 위해 fine-tune 접근법에 초점을 맞춘다. 특히, broad class (instructions) 로 GPT-3 를 fine-tune 하기 위해 human feedback 으로 강화학습을 한다. ( RLHF ) 이 모델 (InstructGPT) 과정은 다음과 같다. 40명의 라벨러로부터 입증된 데이터셋을 모아 GPT-3 를 supervised fine-tune (SFT) 라벨러가 선호하던 output 으로 예측할 수 있도록 reward model (RM) 으로 훈련 이 RM 을 PPO optimization 으로 강화 학습 이 모델은 GPT-3 를 사용했으며, 사이즈가 1.3B, 6B, 175B parameter 를 가진다. 주요 결과는 다음과 같다. 라벨러가 GPT-3 결과보다 InstructGPT 결과를 더 선호 InstructGPT 가 GPT-3 의 truthfulness 를 개선 InstructGPT 가 GPT-3 의 toxicity 를 조금 개선, 그러나 bias 는 개선을 보이지 않음 RealToxicityPrompt 데이터셋으로 toxicity 를 측정 GPT-3 보다 25% 더 적은 toxic output 을 생성 Wingogender 와 CrowSPairs 데이터셋은 GPT-3 보다 나은 개선은 보이지 않았다. RLHF 를 수정하여 공개 데이터셋의 성능 저하를 최소화 RLHF fine-tuning 하는 동안 SQuAD, DROP, HellaSwag, WMT 2015 데이터셋에서 GPT-3 와 비교하여 성능 저하를 관찰했다. PPO 와 pretraining 분포의 log-likelihood 의 증가를 혼합하여 성능 저하를 감소 데이터를 생성하지 않은 보류중인 라벨러의 선호도를 일반화 공개 데이터셋에는 InstructGPT 에 사용된 방식을 반영하지 않음 InstructGPT 는 RLHF fine-tuning 에 벗어난 명령에도 좋은 일반화를 보임 InstructGPT 는 여전히 약간의 실수가 있음 log-likelihood 특정 확률 분포에서 주어진 데이터가 관찰될 가능성을 나타내는 값 간단히, 주어진 데이터가 특정 분포에 얼마나 잘 맞는 가를 측정하는 척도","s":"1. Introduction","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1550,"t":"방법론은 다음 세 가지 스텝을 따른다. 입증된 데이터를 모아, supervised policy 훈련 라벨러로부터 입증된 데이터 수집 pretrained GPT-3 를 supervised learning 하여 fine-tuning 비교 데이터를 모아, reward model 훈련 모델 output 을 비교하여, 라벨러가 어떤 것을 선호하는지 랭킹 부여 이후 reward model 을 훈련 PPO 로 reward model 에 대한 policy 를 최적화 RM 에 PPO 알고리즘을 사용하여 supervised policy 를 최적화하며 fine-tuning","s":"3.1 High-level methodology","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#31-high-level-methodology","p":1541},{"i":1552,"t":"본 논문의 데이터셋에는 OpenAI AIP 로 제출된 text prompt 가 포함되어 있디. 처음 InstructGPT 를 학습할 때, 라벨러에게 스스로 prompt 를 작성하라고 요청했다. 이 이유는 모델이 스스로 작동하기 위한 instruct-like prompt 초기 자원이 필요하다. 또한 라벨러에게 다음의 3가지 종류의 prompt 를 작성하길 요청했다. Plain : 간단한 arbitrary task 을 생산하면서도 다양성을 가지도록 함 Few-shot : instruction 과 이에 대응하는 질의응답 생산 User-based : OpenAPI API 의 application 사용사례를 가지고 있으므로, 라벨러에게 사용 사례에 대응하는 prompt 를 생산하도록 요청 세 가지의 데이터셋을 생산하여 fine-tuning 에 사용한다. SFT 모델의 훈련으로 사용할 SFT dataset (13k) RM 모델의 훈련으로 사용할, 모델의 출력에 라벨러가 랭킹을 매긴 RM dataset (33k) 라벨러 없이, RLHF fine-tuning 을 위한 input 으로 사용될 PPO dataset (31k)","s":"3.2 Dataset","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#32-dataset","p":1541},{"i":1554,"t":"훈련 task 는 두 가지의 형태를 지닌다. 라벨러가 작성한 promtpt dataset API 로 InstructGPT 에 제출된 prompt dataset 위의 prompt 는 generation, question, answer, dialog, summarization, extraction, other natural language task 를 포함하고 있다.","s":"3.3 Task","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#33-task","p":1541},{"i":1556,"t":"Upwork 및 ScaleAI 에서 40명과 계약 하여 정보 수집을 위한 팀을 고용","s":"3.4 Human data collection","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#34-human-data-collection","p":1541},{"i":1558,"t":"먼저, pretrained language model 인 GPT-3 로 시작한다. GPT-3 는 인터넷 데이터를 훈련한 것으로, 넓은 범위에서 downstream task 로 사용된다. 본 논문에서는 GPT-3 를 세 가지의 기술로 훈련한다. Supervised fine-tuning (SFT) supervised learning 으로 입증된 데이터를 통해 GPT-3 를 fine-tuning 한다. 다음 사항들로 훈련을 진행한다. 16 epochs cosine learning rate decay residual dropout 0.2 검증셋의 RM score 를 기반으로 최종 SFT 모델을 선택 SFT 모델이 1 epoch 이후의 검증 loss 가 overfit 하는 것을 발견 overfit 에도 불구하고, 더 많은 에폭을 훈련하면 RM score 와 라벨러의 선호도 랭킹에 도움이 되는 것을 발견 Reward modeling (RM) SFT 모델의 마지막 unembedding layer 를 제거하여 시작 prompt 와 response 를 사용하여 scalar reward 를 출력하도록 훈련시킨다. 175B RM 은 불안정하여 6B RM 을 사용 본 논문에서는 reward model 에 다음 loss function 을 사용한다. loss(θ)=−1(K2)E(x,yw,yl)∼D[log(σ (rθ (x,yw)−rθ(x,yl)))]\\textup{loss}(\\theta) = -\\frac{1}{\\binom{K}{2}}E_{(x,y_w,y_l) \\sim D}[log(\\sigma \\ (r_{\\theta} \\ (x, y_w) - r_{\\theta}(x, y_l)))]loss(θ)=−(2K​)1​E(x,yw​,yl​)∼D​[log(σ (rθ​ (x,yw​)−rθ​(x,yl​)))] rθ(x,y)r_\\theta(x, y)rθ​(x,y) 는 prompt xxx 에 대한 RM 의 scalar output, 파라미터 θ\\thetaθ 와 완성값 yyy ywy_wyw​ 는 ywy_wyw​ 와 yly_lyl​ 의 쌍 중에서 선호되는 완료값 DDD 는 사람이 비교한 데이터셋 RM loss 가 변하지 않아, bias 로 RM 을 normalization 한다. Reinforcement learning (RL) 과도한 optimization 을 막기 위해 SFT 모델로부터 토큰 당 KL 패널티를 추가 이 value function 은 RM 에서 초기화 된다. 이러한 모델을 PPO 라 칭한다. PPO 로 SFT 모델을 fine-tuning 한다. 공개 NLP 데이터셋에 성능 저하를 고치기 위해, PPO gradient 에 pretraining gradient 를 혼합한다. 이를 PPO-ptx 라 칭한다. RL learning 에 objective function 을 결합하여 maximize 한다. objective(ϕ)=E(x,y)∼DπϕRL[rθ(x,y)−βlog(πϕRL(y ∣ x)/πSFT(y ∣ x))]+γEx∼Dpretrain[log(πϕRL(x))]\\textup{objective}(\\phi) = E_{(x,y) \\sim D_{\\pi^{RL}_\\phi}}[r_\\theta(x,y) - \\beta log(\\pi^{RL}_\\phi(y\\ |\\ x) / \\pi^{SFT}(y \\ | \\ x))] + \\gamma E_{x \\sim D_{pretrain}}[log(\\pi^{RL}_\\phi (x))]objective(ϕ)=E(x,y)∼DπϕRL​​​[rθ​(x,y)−βlog(πϕRL​(y ∣ x)/πSFT(y ∣ x))]+γEx∼Dpretrain​​[log(πϕRL​(x))] πϕRL\\pi^{RL}_\\phiπϕRL​ 는 학습된 RL policy πSFT\\pi^{SFT}πSFT 는 supervised trained model DpretrainD_{pretrain}Dpretrain​ 는 pretraining distribution β\\betaβ 는 KL reward 계수, 0.02 γ\\gammaγ 는 pretraining loss 계수 PPO 에선 γ\\gammaγ 를 0, PPT-ptx 에선 γ\\gammaγ 를 27.8 본 논문에서 InstructGPT 는 PPO-ptx 모델을 선호 Baselines SFT 모델과 GPT-3 를 PPO 모델 성능을 비교 또한 InstructGPT 를 FLAN, TO 데이터셋에서 175B GPT-3 를 fine-tuning 한 것과 비교","s":"3.5 Models","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#35-models","p":1541},{"i":1560,"t":"aligned 모델을 평가 하기 위해선 context 에서 alignment 의 의미가 무엇인지 명확할 필요가 있다. 하지만 alignment 의 정의는 역사적으로도 애매하고 혼란스러운 주제이기도 하다. 결국 목표는 유저의 의도에 따르는 행동을 하는 훈련 모델인 것이다. 이전에 연구된 논문에서는 모델이 helpful, honest, harmless 하다면 aligned 한 모델이라 정의한다. helpful 모델이 helpful 하기 위해선 지시를 잘 따르고 의도를 잘 추론해야만 한다. 라벨러의 판단에 전적으로 의존하고, 주요 기준은 라벨러의 선호도를 따른다. honest 모델이란 큰 black box 이기 때문에 진실에 대한 추론을 할 수 없다. 대신 다음 두 가지 기준으로 진실함을 측정한다. 폐쇠적인 도메인 작업에 대한 모델의 경향 평가 TruthfulQA 데이터셋 사용 harmless 라벨러가 Playground API 에서 수집된 정보에서 유해한 것인지 평가 또한 RealToxicityPrompt, CrowS-Paris 같은 bias 와 toxicity 를 측정하기 위한 데이터셋을 벤치마킹","s":"3.6 Evaluation","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#36-evaluation","p":1541},{"i":1563,"t":"라벨러는 GPT-3 의 출력보다 InstructGPT 의 출력을 더 선호 훈련 데이터를 생성하지 않은 보류된 라벨러 의 선호도를 일반화 공개 NLP 데이터셋에는 InstructGPT 의 방식을 반영하지 않음","s":"4.1 Results on the API distribution","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#41-results-on-the-api-distribution","p":1541},{"i":1565,"t":"InstructGPT 모델은 GPT-3 보다 진실함에서 개선됨 InstructGPT 모델은 GPT-3 보다 toxicity 는 조금 개선했으며, bias 에선 개선점이 없음 RLHF fine-tuning 을 개선하여 공개 NLP 데이터셋의 성능 저하를 최소화","s":"4.2 Results on public NLP datasets","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#42-results-on-public-nlp-datasets","p":1541},{"i":1567,"t":"InstructGPT 는 RLHF fine-tuning 분포에서 벗어난 지시에 대해서도 일반화를 잘 함 위와 같이 InstructGPT 은 여전히 간단한 실수를 함 잘못된 전제를 가정하는 지시에 대해 혼동 질문에 대한 간단한 대답보다는 과도하게 얼버무림 지시에 여러 제약 조건이 있거나 언어 모델에 어려움이 있을 때 성능 저하를 일으킴","s":"4.3 Qualitative results","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#43-qualitative-results","p":1541},{"i":1570,"t":"위의 접근법은 무엇에 work 하고 무엇을 하지 않을지의 feedback loop 이 실증적이란 것을 제공한다. 이 feedback loop 는 alignment 기술을 개선하기 위해 필수적이다. 이러한 alignment 기술인 RLHF 는 초인적인 시스템을 align 하기 위한 몇몇 제안에서 중요한 building block 이다. 이러한 작업들로, 저자는 더 일반적으로 align 연구를 끌어당길 수 있다고 한다. 모델 align 을 증가시키는 비용은 pretraining 보다 상대적으로 적다. 64.9 petaflops/s-days (175B SFT + 175B PPO-ptx) vs 3,640 petaflops/s-days (GPT-3) InstructGPT 에게 지도하지 않은 설정에도 지시를 잘 따라 일반화 fine-tuining 으로 인한 성능 저하 대부분을 완화","s":"5.1 Implications for alignment research","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#51-implications-for-alignment-research","p":1541},{"i":1573,"t":"InstructGPT 의 행동은 계약자(라벨러)로부터 얻은 human feedback 에 의해 결정된다 → value judgment 는 라벨러의 성향, 신념, 개인의 살아온 역사 등에 의해 영향을 받는다는 한계 InstructGPT 는 완전히 aligned 이거나 완전히 안전하진 않음 → 분명한 prompt 가 없다면 여전히 toxic, violent, make up fact 를 생성함 InstructGPT 의 최대 한계는 실제 세계에 해롭더라도 유저의 지시에 따른다는 것이다 → 모델이 최대로 bias 되도록 지시하는 프롬프트에 대해, InstructGPT 는 동등한 크기의 GPT-3 보다 더 toxic 한 출력을 생성한다","s":"5.3 Limitations","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#53-limitations","p":1541},{"i":1575,"t":"ChatGPT 는 InstructGPT 의 형제와 같은 모델로서, prompt 의 지시에 따라 자세한 응답을 제공하는 모델","s":"ChatGPT","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":1541},{"i":1577,"t":"InstructGPT 와 동일한 방법(SFT+RLHF)을 사용하면서도 데이터 수집에서 약간 다르다: InstructGPT dataset + new dialogue dataset (AI Trainer 가 AI 와 대화하며 출력을 수정)","s":"Method","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#method","p":1541},{"i":1579,"t":"ChatGPT 는 그럴듯 하지만 부정확하거나 무의미한 답변 작성 RL 훈련 중 진실의 출처가 없음 더 신중하도록 훈련하면 올바르게 대답할 수 있는 질문도 거부 이상적인 답변은 모델이 아는 것에 따라 다르기 때문에 오도를 하기도 함 입력 문구를 수정 하거나 동일한 prompt 의 다중 시도에 민감 한 문구에 대해 모른다고 하거나 문구를 약간의 수정으로 올바르게 대답 가능 이상적인 모델은 모호한 쿼리에 대해 명확한 질문을 해야한다. 현재 모델은 의도를 추측 모델이 부적절한 요청에는 거부하도록 노력했지만 유해하거나 편향된 행동을 보임 지속적인 작업으로 Human Feedback 을 수집해야함","s":"Limitations","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#limitations","p":1541},{"i":1581,"t":"You have just learned the basics of Docusaurus and made some changes to the initial template. Docusaurus has much more to offer! Have 5 more minutes? Take a look at versioning and i18n. Anything unclear or buggy in this tutorial? Please report it!","s":"Congratulations!","u":"/docs/tutorial-basics/congratulations","h":"","p":1580},{"i":1583,"t":"Read the official documentation Modify your site configuration with docusaurus.config.js Add navbar and footer items with themeConfig Add a custom Design and Layout Add a search bar Find inspirations in the Docusaurus showcase Get involved in the Docusaurus Community","s":"What's next?","u":"/docs/tutorial-basics/congratulations","h":"#whats-next","p":1580},{"i":1585,"t":"Docusaurus creates a page for each blog post, but also a blog index page, a tag system, an RSS feed...","s":"Create a Blog Post","u":"/docs/tutorial-basics/create-a-blog-post","h":"","p":1584},{"i":1587,"t":"Create a file at blog/2021-02-28-greetings.md: blog/2021-02-28-greetings.md --- slug: greetings title: Greetings! authors: - name: Joel Marcey title: Co-creator of Docusaurus 1 url: https://github.com/JoelMarcey image_url: https://github.com/JoelMarcey.png - name: Sébastien Lorber title: Docusaurus maintainer url: https://sebastienlorber.com image_url: https://github.com/slorber.png tags: [greetings] --- Congratulations, you have made your first post! Feel free to play around and edit this post as much you like. A new blog post is now available at http://localhost:3000/blog/greetings.","s":"Create your first Post","u":"/docs/tutorial-basics/create-a-blog-post","h":"#create-your-first-post","p":1584},{"i":1589,"t":"Problem Difficulty Algorithm Date 2750: 수 정렬하기 브론즈 II 정렬구현 2024-01-28 11720: 숫자의 합 브론즈 IV 정렬구현문자 2024-01-28 1546: 평균 브론즈 I 수학사칙연산 2024-01-28 11659: 구간 합 구하기 4 실버 III 누적 합 2024-01-28 11660: 구간 합 구하기 5 실버 I 누적 합다이나믹 프로그래밍 2024-02-03 10986: 나머지 합 골드 III 누적 합수학 2024-02-03 2018: 수들의 합 5 실버 V 두 포인터수학 2024-02-04","s":"BackJoon","u":"/docs/Programming/Algorithm/Problems","h":"","p":1588},{"i":1591,"t":"Documents are groups of pages connected through: a sidebar previous/next navigation versioning","s":"Create a Document","u":"/docs/tutorial-basics/create-a-document","h":"","p":1590},{"i":1593,"t":"Create a Markdown file at docs/hello.md: docs/hello.md # Hello This is my **first Docusaurus document**! A new document is now available at http://localhost:3000/docs/hello.","s":"Create your first Doc","u":"/docs/tutorial-basics/create-a-document","h":"#create-your-first-doc","p":1590},{"i":1595,"t":"Docusaurus automatically creates a sidebar from the docs folder. Add metadata to customize the sidebar label and position: docs/hello.md --- sidebar_label: 'Hi!' sidebar_position: 3 --- # Hello This is my **first Docusaurus document**! It is also possible to create your sidebar explicitly in sidebars.js: sidebars.js module.exports = { tutorialSidebar: [ 'intro', 'hello', { type: 'category', label: 'Tutorial', items: ['tutorial-basics/create-a-document'], }, ], };","s":"Configure the Sidebar","u":"/docs/tutorial-basics/create-a-document","h":"#configure-the-sidebar","p":1590},{"i":1597,"t":"Docusaurus is a static-site-generator (also called Jamstack). It builds your site as simple static HTML, JavaScript and CSS files.","s":"Deploy your site","u":"/docs/tutorial-basics/deploy-your-site","h":"","p":1596},{"i":1599,"t":"Build your site for production: npm run build The static files are generated in the build folder.","s":"Build your site","u":"/docs/tutorial-basics/deploy-your-site","h":"#build-your-site","p":1596},{"i":1600,"t":"Test your production build locally: npm run serve The build folder is now served at http://localhost:3000/. You can now deploy the build folder almost anywhere easily, for free or very small cost (read the Deployment Guide).","s":"Deploy your site","u":"/docs/tutorial-basics/deploy-your-site","h":"#deploy-your-site-1","p":1596},{"i":1602,"t":"Docusaurus can manage multiple versions of your docs.","s":"Manage Docs Versions","u":"/docs/tutorial-extras/manage-docs-versions","h":"","p":1601},{"i":1604,"t":"Release a version 1.0 of your project: npm run docusaurus docs:version 1.0 The docs folder is copied into versioned_docs/version-1.0 and versions.json is created. Your docs now have 2 versions: 1.0 at http://localhost:3000/docs/ for the version 1.0 docs current at http://localhost:3000/docs/next/ for the upcoming, unreleased docs","s":"Create a docs version","u":"/docs/tutorial-extras/manage-docs-versions","h":"#create-a-docs-version","p":1601},{"i":1606,"t":"To navigate seamlessly across versions, add a version dropdown. Modify the docusaurus.config.js file: docusaurus.config.js module.exports = { themeConfig: { navbar: { items: [ { type: 'docsVersionDropdown', }, ], }, }, }; The docs version dropdown appears in your navbar:","s":"Add a Version Dropdown","u":"/docs/tutorial-extras/manage-docs-versions","h":"#add-a-version-dropdown","p":1601},{"i":1608,"t":"It is possible to edit versioned docs in their respective folder: versioned_docs/version-1.0/hello.md updates http://localhost:3000/docs/hello docs/hello.md updates http://localhost:3000/docs/next/hello","s":"Update an existing version","u":"/docs/tutorial-extras/manage-docs-versions","h":"#update-an-existing-version","p":1601},{"i":1610,"t":"Add Markdown or React files to src/pages to create a standalone page: src/pages/index.js → localhost:3000/ src/pages/foo.md → localhost:3000/foo src/pages/foo/bar.js → localhost:3000/foo/bar","s":"Create a Page","u":"/docs/tutorial-basics/create-a-page","h":"","p":1609},{"i":1612,"t":"Create a file at src/pages/my-react-page.js: src/pages/my-react-page.js import React from 'react'; import Layout from '@theme/Layout'; export default function MyReactPage() { return ( <Layout> <h1>My React page</h1> <p>This is a React page</p> </Layout> ); } A new page is now available at http://localhost:3000/my-react-page.","s":"Create your first React Page","u":"/docs/tutorial-basics/create-a-page","h":"#create-your-first-react-page","p":1609},{"i":1614,"t":"Create a file at src/pages/my-markdown-page.md: src/pages/my-markdown-page.md # My Markdown page This is a Markdown page A new page is now available at http://localhost:3000/my-markdown-page.","s":"Create your first Markdown Page","u":"/docs/tutorial-basics/create-a-page","h":"#create-your-first-markdown-page","p":1609},{"i":1616,"t":"Docusaurus supports Markdown and a few additional features.","s":"Markdown Features","u":"/docs/tutorial-basics/markdown-features","h":"","p":1615},{"i":1618,"t":"Markdown documents have metadata at the top called Front Matter: my-doc.md --- id: my-doc-id title: My document title description: My document description slug: /my-custom-url --- ## Markdown heading Markdown text with [links](./hello.md)","s":"Front Matter","u":"/docs/tutorial-basics/markdown-features","h":"#front-matter","p":1615},{"i":1620,"t":"Regular Markdown links are supported, using url paths or relative file paths. Let's see how to [Create a page](/create-a-page). Let's see how to [Create a page](./create-a-page.md). Result: Let's see how to Create a page.","s":"Links","u":"/docs/tutorial-basics/markdown-features","h":"#links","p":1615},{"i":1622,"t":"Regular Markdown images are supported. You can use absolute paths to reference images in the static directory (static/img/docusaurus.png): ![Docusaurus logo](/img/docusaurus.png) You can reference images relative to the current file as well. This is particularly useful to colocate images close to the Markdown files using them: ![Docusaurus logo](./img/docusaurus.png)","s":"Images","u":"/docs/tutorial-basics/markdown-features","h":"#images","p":1615},{"i":1624,"t":"Markdown code blocks are supported with Syntax highlighting. ```jsx title=\"src/components/HelloDocusaurus.js\" function HelloDocusaurus() { return ( <h1>Hello, Docusaurus!</h1> ) } ``` src/components/HelloDocusaurus.js function HelloDocusaurus() { return <h1>Hello, Docusaurus!</h1>; }","s":"Code Blocks","u":"/docs/tutorial-basics/markdown-features","h":"#code-blocks","p":1615},{"i":1626,"t":"Docusaurus has a special syntax to create admonitions and callouts: :::tip My tip Use this awesome feature option ::: :::danger Take care This action is dangerous ::: My tip Use this awesome feature option Take care This action is dangerous","s":"Admonitions","u":"/docs/tutorial-basics/markdown-features","h":"#admonitions","p":1615},{"i":1628,"t":"MDX can make your documentation more interactive and allows using any React components inside Markdown: export const Highlight = ({children, color}) => ( <span style={{ backgroundColor: color, borderRadius: '20px', color: '#fff', padding: '10px', cursor: 'pointer', }} onClick={() => { alert(`You clicked the color ${color} with label ${children}`) }}> {children} </span> ); This is <Highlight color=\"#25c2a0\">Docusaurus green</Highlight> ! This is <Highlight color=\"#1877F2\">Facebook blue</Highlight> ! This is Docusaurus green ! This is Facebook blue !","s":"MDX and React Components","u":"/docs/tutorial-basics/markdown-features","h":"#mdx-and-react-components","p":1615},{"i":1630,"t":"Let's translate docs/intro.md to French.","s":"Translate your site","u":"/docs/tutorial-extras/translate-your-site","h":"","p":1629},{"i":1632,"t":"Modify docusaurus.config.js to add support for the fr locale: docusaurus.config.js module.exports = { i18n: { defaultLocale: 'en', locales: ['en', 'fr'], }, };","s":"Configure i18n","u":"/docs/tutorial-extras/translate-your-site","h":"#configure-i18n","p":1629},{"i":1634,"t":"Copy the docs/intro.md file to the i18n/fr folder: mkdir -p i18n/fr/docusaurus-plugin-content-docs/current/ cp docs/intro.md i18n/fr/docusaurus-plugin-content-docs/current/intro.md Translate i18n/fr/docusaurus-plugin-content-docs/current/intro.md in French.","s":"Translate a doc","u":"/docs/tutorial-extras/translate-your-site","h":"#translate-a-doc","p":1629},{"i":1636,"t":"Start your site on the French locale: npm run start -- --locale fr Your localized site is accessible at http://localhost:3000/fr/ and the Getting Started page is translated. caution In development, you can only use one locale at a same time.","s":"Start your localized site","u":"/docs/tutorial-extras/translate-your-site","h":"#start-your-localized-site","p":1629},{"i":1638,"t":"To navigate seamlessly across languages, add a locale dropdown. Modify the docusaurus.config.js file: docusaurus.config.js module.exports = { themeConfig: { navbar: { items: [ { type: 'localeDropdown', }, ], }, }, }; The locale dropdown now appears in your navbar:","s":"Add a Locale Dropdown","u":"/docs/tutorial-extras/translate-your-site","h":"#add-a-locale-dropdown","p":1629},{"i":1640,"t":"Build your site for a specific locale: npm run build -- --locale fr Or build your site to include all the locales at once: npm run build","s":"Build your localized site","u":"/docs/tutorial-extras/translate-your-site","h":"#build-your-localized-site","p":1629},{"i":1642,"t":"논문 및 이미지 출처: https://www.sciencedirect.com/science/article/pii/S2666651022000183","s":"PTR: Prompt Tuning with Rules for Text Classification","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1644,"t":"최근, pre-trained language models (PLMs) 의 rich knowledge 를 NLP task 에 활성화하기 위해 prompt tuning 이 널리 적용된다. prompt tuning 이 sentiment classification 및 natural language inference 같은 few-class classification tasks 에 좋은 결과를 보여주지만, prompt 수동 설계는 무거우며 한편, prompts 자동 생성 또한 어렵고 시간 소요가 크다. 그러므로 복잡한 many-class classification 에 대한 효율적인 prompts 를 얻기란 여전히 challenge 로 남아있다. 본 논문에서 저자는 classification task 의 prior knowledge 를 rules 지정하여 encoding 하며, 그 후 rules 에 따라 sub-prompts 를 설계하고, task 를 처리하기 위해 sub-prompts 를 결합한다. 저자는 이를 Prompt Tuning method with Rules **\"PTR\"\" 로 명명한다. 존재하는 prompt-based method 와 비교하면, PTR 은 prompts 구축에 효과정 및 효율성 간의 tradeoff 를 잘 도달한다. relation classification, entity typing 및 intent classification 을 포함한 3개의 many-class classification tasks 에서 실험을 진행한다. 결과는 PTR 이 vanilla 및 prompt tuning baselines 를 능가하는 것을 보여주어, prompt tuning 의 rules 활용의 효과성을 나타냈다.","s":"Abstract","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1646,"t":"PLMs 는 효과적인 NLP 수단으로 나타나, large-scale corpora 의 linguistic, semantic, syntactic 및 world knowledge 를 capture 할 수 있다. task-specific data 를 fine-tuning 하여, PLMs 의 rich knowledge 로 다양한 downstream NLP task 에 활용한다. fine-tuning 의 성공에도 불구하고, 최근 연구들에서 critical challenge 가 나타난다. pre-training 및 fine-tuning 간의 object forms gaps Fig. 1(a) 에서 보이듯, PLMs 는 보통 cloze-stype task 를 pre-training 하지만 Fig 1. 1(b) 처럼 fine-tuning 은 all PLM's parameters 및 task-specific heads (e.g. linear layers for classification) with task-specific objectives tuning 이 필요. transfer learning 관점에서, 이 objective gap 은 PLMs's knowledge 을 downstream task 에 adaptation 하는 것을 저해할 수 있다. 위와 같은 objective forms gap 을 연결하기 위해, prompt tuning 이 도입되어 왔으며, 일반적인 prompt 는 template 및 label word set 으로 이루어진다. Fig. 1(c) 에서 보이듯, masked position [𝙼][𝙼][M] 을 예측하고 해당하는 class labels 을 predicted word 로 매핑하기 위해 input 과 template 을 결합하여, classification task 를 cloze-style objective form 으로 변환될 수 있다. label word set 은 predicting [𝙼][𝙼][M] 에 대한 candidate set 을 제공. 직관적으로, template \"<S1>.<S_1>.<S1​>. It was [𝙼][𝙼][M].\" 및 setiment classification 을 위한 label set {\"great\", \"terrible\"} 을 사용 그럼 <S1><S_1><S1​> 이 [𝙼][𝙼][M] 에 대한 PLMs 의 예측 \"great\" 또는 \"terrible\" 을 기반으로 positive 또는 negative 인지 결정할 수 있다. prompt tuning 은 natural language inference 같은 다른 few-class classification tasks 에서 좋은 결과에 도달하지만, many classes 가 있는 tasks 에서는, 다양한 classes 를 구별하기 위해 적절한 templates 및 알맞는 label words 를 수동으로 찾기란 어렵다. 예를 들어, many-class classification task 인 relation classification 은 text 에서 두 marked entities 단의 semantic relations 를 예측하는 것이 필요하다. relation \"person:parent\" 와 relation \"organization:parent\" 이 있을 때, template 및 이들을 구별할 label words 을 선택하기란 어렵다. 한 직설적인 솔루션은 Fig. 1(d) 처럼 prompts 를 자동으로 생성하는 것이다. 하지만 auto-generated prompts 는 생성과 검증에 대한 많은 연산 비용이 발생한다. 다른 솔루션은 Fig. 1(e) 처럼 discrete prompt tokens 대신 soft prompt 를 사용하는 것이다. 하지만 soft prompts 는 효과적이기 위해 모델 파라미터가 충분히 커야한다. 본 논문에서는, many-class classification 에 대해, rules 가 있는 prompt tuning (PTR) 을 제안한다. Fig. 2 처럼 classification task 가 주어지면, 먼저 rule 로 prior task knowledge 를 encoding 하고 task 를 sub-tasks 로 decomposing 한다. 그후, task 를 처리하기 위한 필수 sub-prompt 를 설계하고 마지막으로 rules 에 따른 sub-prompts 를 구성한다. 다른 prompt tuning 과 비교하면 PTR 은 두 가지 이점이 있다. Prior Knowledge Encoding prior task knowledge 는 specific tasks 해결에 도움을 준다. 예로, relation classification 에서 예측 결과가 sentence semantics 및 entity types 모두와 관련되어 있다 가정하면, two sub-prompts 에 기반하여 prompts 를 구축할 수 있다. 하나는 entity types 을 감지하고 다른 하나는 entities 간의 relational semantics 을 감지한다. entity typing 및 intent classification 같은 다른 tasks 에서도, 클래스 계층 구조는 prompt 설계에 좋은 prior knowledge 다. prior task knowledge 를 encoding 하여, 충분한 훈련 데이터 없이도 효과적인 모델을 얻을 수 있다. Efficient and Effective Prompt Design 각 class 에 대한 개별 template 및 label words 를 수동으로 설계하는 것보다, few simple sub-prompts 를 설계하고 복잡한 specific tasks 를 처리하기 위해 rules 에 따른 결합이 더 쉽다. auto-generated 및 soft prompts 보다, prompts 생성을 위한 rules 를 사용하는 것이 더 효율적이고 효과성이 있다. 직관적인 측면을 고려하면, 본 논문에선 PRT 소개를 위해 human-picked sub-prompts 를 사용하지만, open framework 및 sub-prompts 는 auto-generated 및 soft 한 것일 수도 있다. PTR 효과성 검증을 위해, relation classification, entity typing 및 intent classification 을 포함한 3가지의 many-class classification task 에서 실험을 수한다. 실험 결과는 PTR 이 vanilla fine-tuning 및 prompt tuning baselines 를 능가하고, prior task knowledge 및 복잡한 classification tasks 에 대한 PLMs 모두의 이점을 활용하는 접근법임을 나타낸다.","s":"1. Introduction","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1649,"t":"many-class classification tasks 에 대한 효과적인 prompts 설계의 어려움을 고려하려, 저자는 어려운 task 를 여러 simple sub-tasks 로 decomposing 하고 각 sub-prompts 를 설계하는 PTR 을 제안한고, 기존의 복잡한 task 의 더 나은 해결을 위해 rules 에 따른 sub-prompts 를 포함한다.","s":"3. Prompt tuning with rules (PTR)","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1651,"t":"PTR 은 basic human inferences 에 기반을 둔다. relation classification 을 예로, sentence 내의 two marked entities 가 \"person:parent\" 관계인지 궁금하다면, prior knowledge 를 활용하여 sentence 및 two marked entities 가 특정 조건을 만족하는지 확인해야 한다. two marked entities 가 인간이어야 하며; sentence 이 two marked entities 간의 parental semantics 를 나타내야 함 이에 영감을 받아, 모든 text classification task T={X,Y}\\mathcal{T} = \\{ \\mathcal{X}, \\mathcal{Y} \\}T={X,Y} 에 대해, task 를 일련의 conditional function set F\\mathcal{F}F 으로 decomposing 할 수 있다. 각 function f∈Ff \\in \\mathcal{F}f∈F 는 function input 이 특정 조건을 충족하는지 여부를 결정한다. 예로, f(a,f(a,f(a, person))) 를 설계하여 aaa 가 person 인지 결정하고, f(a,′f(a,'f(a,′s parent was ,b), b),b) 를 설계하여 bbb 가 aaa 의 parent 인지 결정할 수 있다. 직관적으로, 이러한 조건 함수는 본질적인 first-order rules 서술이다. 각 조건 함수 f∈Ff \\in \\mathcal{F}f∈F 에 대해, PRT 은 template Tf(⋅)T_f(\\cdot)Tf​(⋅) 및 label word set Vf\\mathcal{V}_fVf​ 를 설정하여 sub-prompt 를 구축한다. Y\\mathcal{Y}Y 의 semantics 에 따라, rules 을 사용하여 task 를 일련의 조건 함수 계산으로 변환할 수 있다. Fig. 2 에서 보이듯, relation classification 의 경우, entities aaa 및 bbb 가 \"person:parent\" 관계를 가지는지 여부를 결정하는 것은 다음과 같이 공식화할 수 있다. fes(a,person)∧fes,eo(a,′s parent was,b)∧feo(b,person)→\"person:parent\"\\begin{align*} & f_{e_s}(a, \\text{person}) \\wedge f_{e_s, e_o}(a,'\\text{s parent was}, b) \\wedge f_{e_o}(b, \\text{person}) \\\\ & \\rightarrow \\text{\"person:parent\"} \\end{align*}​fes​​(a,person)∧fes​,eo​​(a,′s parent was,b)∧feo​​(b,person)→\"person:parent\"​ fes(⋅,⋅)f_{e_s}(\\cdot, \\cdot)fes​​(⋅,⋅) : subject entity types 를 결정하는 조건 함수 feo(⋅,⋅)f_{e_o}(\\cdot, \\cdot)feo​​(⋅,⋅) : entities 간의 의미적 연결을 결정하는 조건 함수 위에서 언급한 rules 및 조건 함수를 기반으로, task T\\mathcal{T}T 를 처리하기 위해 rule-related conditional functions 의 sub-prompts 를 구성한다.","s":"3.1 Overall framework of PTR","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#31-overall-framework-of-ptr","p":1641},{"i":1653,"t":"tasks 를 sub-tasks 로 분해하는 기본 rule 은 structural information 을 사용하는 것이다. structural label 을 기반으로 rules 설계 classification tasks 의 label 은 internal structural information 을 가질 수도 있으며, 이 정보는 일반적으로 label tag 에서 반복적으로 나타나는 키워드로 표현된다. intent classification 을 예로, \"card_activating\" 과 \"card_linking\" 은 \"card\" 라는 동일한 단어를 공유 이 두 label 을 분류하는 것은 \"card\" 와 관련된 것인지, \"activating\" 이나 \"linking\" 이 의도된 것인지 분해될 수도 있다. intrinsic correlation 를 기반으로 rules 설계 일부 label tags 는 공통 키워드가 없을 수 있지만, \"uber\" 와 \"car_rental\" 같이 동일한 본질적 의미를 가질 수 있다. 위 rules 에 따라, many-class classification task 를 hierarchical classification 형태로 변환하고 각 계층에 대한 조건 함수를 설계할 수 있다. 이 rules 를 따라 complex classification tasks 를 처리하기 위해 여러 sub-prompts 를 쉽게 구축할 수 있다. Table 3, 6, 10 에서 예시를 보여주며, relation classification, entity typing 및 intent classification 을 어떻게 분해하는지 보여준다. 이 예시에서 manual sub-prompts 를 작성하는 데 필요한 노력이 어렵지 않다는 것을 볼 수 있다. tasks 를 어떻게 분해하고 rules 를 설계하는 법은 open problem 이며, structural information 외에도 더 복잡한 heuristic rules 을 사용하여 분해나는 것도 유망할 수 있다. 본 논문은 rule-based prompt tuning 의 framework 를 소개하는 데 중점을 둔다.","s":"3.2 Task decomposition","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#32-task-decomposition","p":1641},{"i":1655,"t":"각 조건 함수 f∈Ff \\in \\mathcal{F}f∈F 에 대한 sub-prompt 를 수동으로 설계한다. 일반적인 prompt 설정과 유사하게, sub-prompt 또한 template 및 label word set 으로 구성된다. 기본적인 조건 함수는 단항(unary) 함수이다. binary sentiment classification 을 위해, unary functions 는 sentence 가 positive 인지 negative 인지 결정할 수 있다. entity typing 에서는, unary functions 는 entity types 를 나타낼 수 있다. topic labeling 에서는, unary functions 는 article topics 를 예측하는 데 사용될 수 있다. relation classification 을 예로 들자. sentence x={…es…eo… }x = \\{ \\dots e_s \\dots e_o \\dots \\}x={…es​…eo​…} 이 주어졌을 때, 우리는 fes(⋅,{person | organization | … })f_{e_s} (\\cdot,\\{ \\text{person | organization | } \\dots \\} )fes​​(⋅,{person | organization | …}) 을 설정하여 ese_ses​ 의 type 을 결정할 수 있다. ese_ses​ : subject entity eoe_oeo​ : object entity fesf_{e_s}fes​​ 의 sub-prompt template 및 label word set 은 다음과 같이 공식화할 수 있다. Tfes=‘‘x the [𝙼] es\",Vfes={‘‘person\",‘‘organization\",… },\\begin{equation} \\begin{align*} & T_{f_{e_s}} = `` x\\ \\text{the} \\ [𝙼] \\ e_s\", \\\\ & \\mathcal{V}_{f_{e_s}} = \\{ ``\\text{person}\",``\\text{organization}\", \\dots\\}, \\end{align*} \\end{equation}​Tfes​​​=‘‘x the [M] es​\",Vfes​​​={‘‘person\",‘‘organization\",…},​​​ object entity eoe_oeo​ 의 경우, feof_{e_o}feo​​ 의 sub-prompt template 및 label word set 은 Eq. 1 와 유사하다. 또 다른 중요한 유형의 조건 함수는 이항(binary) 함수이다. natural language inference 에서 이항 함수는 두 문장 사이의 관계를 entailment(포함), neutral(중립), contradiction(모순) 으로 결정할 수 있다; relation classification 에서 이러한 함수가 두 entities 간의 복잡한 연결을 결정하는 데 사용될 수 있다. 만약 fes,eo(⋅,{’s parent was|was born in| … },⋅)f_{e_s, e_o}(\\cdot , \\{ \\text{'s parent was|was born in| } \\dots\\}, \\cdot)fes​,eo​​(⋅,{’s parent was|was born in| …},⋅), 으로 설정한다면, fes,eof_{e_s, e_o}fes​,eo​​ 의 sub-prompt template 및 label word set 은 다음과 같이 공식화할 수 있다. Tfes,eo=‘‘x es [𝙼][𝙼][𝙼] eo\",Vfes,eo={‘‘’s person was\",‘‘was born in\",… },\\begin{equation} \\begin{align*} & T_{f_{e_s, e_o}} = `` x \\ e_s \\ [𝙼] [𝙼] [𝙼] \\ e_o\", \\\\ & \\mathcal{V}_{f_{e_s, e_o}} = \\{ ``\\text{'s person was}\",``\\text{was born in}\", \\dots\\}, \\end{align*} \\end{equation}​Tfes​,eo​​​=‘‘x es​ [M][M][M] eo​\",Vfes​,eo​​​={‘‘’s person was\",‘‘was born in\",…},​​​ 보통, unary 및 binary functions 는 classfication tasks 처리를 위한 rules 를 구성하기에 충분하다. complex semantics 의 classification tasks 의 경우, 이러한 unary 및 binary functions 설계 방법을 multi-variable functions 로 확장하여 보다 강력한 sub-prompts 를 구축할 수 있다.","s":"3.3 Sub-prompts for conditional functions","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#33-sub-prompts-for-conditional-functions","p":1641},{"i":1657,"t":"다양한 조건 함수들은 서로 상호작용할 수 있다. 예로, probability P(fes,eo(a,′s parent was,b)=true)P(f_{e_s, e_o}(a,' \\text{s parent was}, b) = \\text{true})P(fes​,eo​​(a,′s parent was,b)=true) 는 P(fes(a,person)=true)P(f_{e_s}(a, \\text{person}) = \\text{true})P(fes​​(a,person)=true) 및 P(feo(b,person)=false)P(f_{e_o}(b, \\text{person}) = \\text{false})P(feo​​(b,person)=false) 의 높은 확률에 조건이 걸려 낮을 수도 있다. 그러므로, sub-prompts 를 따로 학습하는 대신, 여러 조건 함수들의 sub-prompts 를 결합하여 완전한 task-specific prompts 를 구성해야 한다. 본 논문에선 간단한 전략을 적용한다: conjunctive normal form(논리곱 표준형)을 사용하여 모든 rul-related functions 의 sub-prompts 를 직접 연결한다. 예로, Fig. 2 에서 Eq.1 과 Eq. 2 의 sub-prompts 를 집계한, 완전한 prompt template 은 다음과 같다. T(x)=[Tfes(x);Tfes,eo(x);Tfeo(x)]=‘‘x the[𝙼]1[𝙼]2[𝙼]3[𝙼]4 the [𝙼]5 eo\",\\begin{equation} \\begin{align*} & T(x) = [T_{f_{e_s}}(x); T_{f_{e_s,e_o}}(x); T_{f_{e_o}}(x)] = \\\\ & `` x \\ \\text{the}[𝙼]_1 [𝙼]_2 [𝙼]_3 [𝙼]_4 \\ \\text{the} \\ [𝙼]_5 \\ e_o \", \\end{align*} \\end{equation}​T(x)=[Tfes​​​(x);Tfes​,eo​​​(x);Tfeo​​​(x)]=‘‘x the[M]1​[M]2​[M]3​[M]4​ the [M]5​ eo​\",​​​ [⋅;⋅;⋅][\\cdot; \\cdot; \\cdot][⋅;⋅;⋅] : sub-prompts 의 aggregation function aggregated label word set 은 다음과 같다. V[𝙼]1={‘‘person’’,‘‘organization’’,…},V[𝙼]2={‘‘’s’’,‘‘was’’,…},V[𝙼]3={‘‘parent’’,‘‘born’’,…},L[𝙼]4={‘‘was’’,‘‘in’’,…},L[𝙼]5={‘‘person’’,‘‘organization’’,…}.\\begin{equation} \\begin{align*} &\\mathcal{V}[𝙼]_1 = \\{‘‘\\text{person}’’, ‘‘\\text{organization}’’, …\\}, \\\\ &\\mathcal{V}[𝙼]_2 = \\{‘‘’\\text{s}’’, ‘‘\\text{was}’’, …\\}, \\\\ &\\mathcal{V}[𝙼]_3 = \\{‘‘\\text{parent}’’, ‘‘\\text{born}’’,…\\}, \\\\ &\\mathcal{L}[𝙼]_4 = \\{‘‘\\text{was}’’, ‘‘\\text{in}’’, …\\}, \\\\ &\\mathcal{L}[𝙼]_5 = \\{‘‘\\text{person}’’, ‘‘\\text{organization}’’, …\\}. \\end{align*} \\end{equation}​V[M]1​={‘‘person’’,‘‘organization’’,…},V[M]2​={‘‘’s’’,‘‘was’’,…},V[M]3​={‘‘parent’’,‘‘born’’,…},L[M]4​={‘‘was’’,‘‘in’’,…},L[M]5​={‘‘person’’,‘‘organization’’,…}.​​​ aggregated template 는 multiple [𝙼][𝙼][M] tokens 를 가지고 있어, inference time 에 모든 masked positions 를 고려하여 예측해야 한다. 즉, p(y∣x)=∏j=1np([𝙼]j=ϕ(y)∣T(x))∑y~∈Y∏j=1np([𝙼]j=ϕ(y~)∣T(x))\\begin{equation} p(y|x) = \\frac{\\prod_{j=1}^n p([𝙼]_j = \\phi(y)|T(x))}{\\sum_{\\tilde{y} \\in \\mathcal{Y}} \\prod^n_{j=1}p([𝙼]_j = \\phi(\\tilde{y})|T(x))} \\end{equation}p(y∣x)=∑y~​∈Y​∏j=1n​p([M]j​=ϕ(y~​)∣T(x))∏j=1n​p([M]j​=ϕ(y)∣T(x))​​​ nnn : T(x)T(x)T(x) 의 masked positions 수 ϕj(y)\\phi_j(y)ϕj​(y) : class yyy 를 jjjth masked position [𝙼]j[𝙼]_j[M]j​ 의 label word set V[𝙼]\\mathcal{V}_{[𝙼]}V[M]​ 로 매핑하는 함수다. Eq. 5 는 PLMs 를 tuning 하고 classes 를 분류하는데 사용될 수 있다. 학습 중에는, 각 조건 함수의 independent probability 와 전체 task 에 대한 joint probability 를 최적화하는 데 중점을 둔다. PTR 의 final training loss 는 다음과 같다. L=1∣X∣∑x∈X[Lindep(x)+Ljoint(x)],Lindep(x)=−1n∑j=1nlog⁡p([𝙼]j=ϕj(yx)∣T(x)),Ljoint(x)=−log⁡p(yx∣x),\\begin{equation} \\begin{align*} \\mathcal{L} &= \\frac{1}{|\\mathcal{X}|} \\sum_{x \\in \\mathcal{X}} [L_{\\text{indep}}(x) + \\mathcal{L}_{\\text{joint}}(x)], \\\\ \\mathcal{L}_{\\text{indep}}(x) &= -\\frac{1}{n} \\sum_{j=1}^{n} \\log p([𝙼]_j = \\phi_j(y_{x})|T(x)), \\\\ \\mathcal{L}_{\\text{joint}}(x) &= -\\log p(y_{x}|x), \\end{align*} \\end{equation}LLindep​(x)Ljoint​(x)​=∣X∣1​x∈X∑​[Lindep​(x)+Ljoint​(x)],=−n1​j=1∑n​logp([M]j​=ϕj​(yx​)∣T(x)),=−logp(yx​∣x),​​​ Ljoint\\mathcal{L}_{\\text{joint}}Ljoint​ : Eq. 5 에 기반하여 구성","s":"3.4 Composing sub-prompts for tasks","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#34-composing-sub-prompts-for-tasks","p":1641},{"i":1659,"t":"어떤 케이스에선, injective mapping function ϕ\\phiϕ 를 사용하여 각 class 를 single label word 로 매핑하는 것만으로 충분하지 않을 수 있다. entity typing 을 예로, entity type class \"location/city\" 가 주어졌을 때, 해당 class 를 label word \"city\" 또는 \"urban\" 이나 \"town\" 처럼 \"city\" 와 크게 관련된 여러 단어로 매핑하는 것이 가능하다. 사실은, \"location/lake_sea_ocean\" 과 같이 연관된 일련의 entity 들을 가리키는 일부 entity types 도 존재한다. 이런 types 의 경우, single label word 에 할당하는 것은 어려울 수 있다. 하나의 label word 을 선택하는 대신, 각 class 를 여러 관련된 label words 로 매핑하는 것이 간단하며 효과적이다. 형식적으로, input sentence xxx 가 주어졌을 때, jjjth masked position [𝙼]j[𝙼]_j[M]j​ 에서의 해당 클래스 yxy_xyx​ 의 label words 을 ϕj(yx)=wj\\phi_j(y_x) = w_jϕj​(yx​)=wj​ 에서 ϕj(yx)={wj,1,wj,2,…,wj,m}\\phi_j(y_x) = \\{ w_{j,1}, w_{j,2}, …, w_{j,m} \\}ϕj​(yx​)={wj,1​,wj,2​,…,wj,m​} 으로 변경한다. template T(⋅)T(\\cdot)T(⋅) 과 함께, Eq. 6 의 조건 확률 p([𝙼]j=ϕj(yx)∣T(x))p([𝙼]_j = \\phi_j(y_x)|T(x))p([M]j​=ϕj​(yx​)∣T(x)) 는 다음과 같이 된다. 1m∑k=1mλk p([𝙼]j=wj,k∣T(x))\\begin{equation} \\frac{1}{m} \\sum^m_{k=1} \\lambda_k \\ p([𝙼]_j = w_{j,k}|T(x)) \\end{equation}m1​k=1∑m​λk​ p([M]j​=wj,k​∣T(x))​​ λk\\lambda_kλk​ : 각 label word 의 중요성을 나타내는 weighted average coefficient 실험에선 모든 λk\\lambda_kλk​ 을 1 로 설정","s":"3.5 Sub-prompts with multiple label words","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#35-sub-prompts-with-multiple-label-words","p":1641},{"i":1663,"t":"이 섹션에선 relation classification 의 결과를 보여줌. 저자는 다음 세 가지 데이터셋을 사용 TACRED : 가장 크고 널리 사용되는 relation classification. 42 relation types 를 포함 TACREV : TACRED 를 기반으로 구축된 데이터셋. training set 은 유지하면서 dev set 및 test set 의 일부 오류를 고침 ReTACRED : TACRED 의 다른 버전. 기존 TACRED 의 단점 보완하여 training, dev, test set 재구축","s":"Datasets","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#datasets","p":1641},{"i":1665,"t":"relation classification 에 대한 일반적인 모델들과 PTR 비교 Learning Models from Scratch relation classification 에 대한 일반적인 접근법. baselines 로 PA-LSTM 및 C-GCN 을 채택. 이 두 모델은 recurrent neural networks 및 graph neural networks 중 효과적인 모델 중 하나. Fine-Tuning PLMs 일부는 relation classification 에 PMLs 를 fine-tuning 하는데 집중을 했다. 이에 몇 가지 방법이 있다. vanilia fine-tuning : 특정 markers 를 input 에 추가하지 않고 RoBERTalarge_{large}large​ 를 직접 선택 Entity 정보가 관계적 의미를 이해하는데 중요하다 생각되어, knowledge-enhanced PLMs 는 knowledge bases 로 PLMs 를 향상시키기 위해 추가적으로 연구됨. SPANBERT, KNOWBERT, LUKE 및 MTB 를 baseline 으로 선택. Prompt Tuning Zhou and Chen (2021), Sentence-level relation extraction (RE) : entity marker 를 input 에 추가하는 several merker-based methods 소개. 이 중 ENT MARKER 는 entity position 을 나타내는 추가적인 순차 정보를 도입하여 Prompt 를 생성하는 방법 TYP MARKER 은 relation classification 을 위한 template 을 만드는 데 entity types information 를 추가적으로 도입 Chen et al (2021a), AdaPrompt : label word 를 adaptive selection method 을 도입하여 각 relation label 을 다양한 label words 로 분산시켜 복잡한 many-class problem 를 처리할 수 있다. Table 2 에서 이러한 Prompt-based fine-tuning method 의 몇 가지 template 예시를 보여준다. PTR 의 경우엔, Table 3 에서 relation-specific prompts 를 보여준다. PTR 는 Transformers 및 OpenNRE toolkit 을 기반으로 구현 대부분의 hyperparameter 는 이전 연구들을 따른다: RoBERTalarge_{large}large​ 을 backbone ㅇ,로 사용하고 learning rate {1e−5,3e−5,5e−5}\\{ 1e-5, 3e-5,5e-5 \\}{1e−5,3e−5,5e−5} 중 최적의 모델을 선택하여 10% steps 에 대해 linear warmup 을 적용 weight decay 은 1e−21e - 21e−2 모든 데이터셋에서 64 batch size 로 5 epochs 동안 모델 튜닝 dev set 의 성능을 기반으로 최적의 모델 checkpoint 선택 위 설정을 기준으로 여러 random seeds 를 사용하여 5번 샘플링하고 평균 결과를 얻는다.","s":"Baselines and implementation details","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#baselines-and-implementation-details","p":1641},{"i":1667,"t":"PTR 과 튜닝 기법 간의 비교는 Table 4 에서 표시한다. 기존의 방법들은 다양한 recurrent neural layers, attention neural layers 및 graph neural layers 를 포함한 복잡한 모델을 설계 위 복잡한 모델은 scratch learning 이 효과적이었지만, Vanilla PLM 인 RoBERTAlarge_{large}large​ 는 이 모델들을 쉽게 능가하므로 large-scale unlabeled data 에서 얻은 rich knowledge 이 downstream 에 중요함을 보여줌 PLMs 내부에서, knowledge-enhanced PLMs 는 Vanilla PLM RoBERTAlarge_{large}large​ 를 이김 이는 모델을 강화하기 위해 extra task-specific knowledge 를 도입하는 것이 효과적임을 보여준다. 하지만, 단순히 PLM 을 fine-tuning 하는 것만으로는 donwstream tasks 에 필요한 knowledge 을 완전히 이해하긴 어렵다는 것을 나타낸다. knowledge-enhanced PLMs 내부에서, LUKE 와 KNOWBERT 가 다른 모델들보다 더 좋은 성능을 보임 두 모델이 각각 fine-tuning 단계에서 향상된 아키텍처와 knowledge 를 data augmentation 처럼 사용하기 때문이다. 반면, SpanBERT 및 MTB 는 pre-training 단계에서 task-specific knowledge 를 parameters 에 주입하고 extra knowledge 없이 parameter 를 fine-tuning 한다. 위 결과들은 task-specific knowledge 가 이미 PLM 에 포함되어 있더라도, 이를 활용하는 것은 어렵다는 것을 보여준다. PTR 은 모든 baseline 보다 획기적인 성능 향상 얻음 knowledge-enhanced models 과 비교해도 TACRED 에선 여전히 이런 모델들을 능가 전반적인 실험결과는 pre-training 단계가 PLM 에 충분한 task-specific knowledge 를 포착할 수 있도록 해주며, downstream task 에 대한 knowledge 를 어떻게 자극하는 지가 중요하다는 것을 보여준다. 일반적인 fine-tuning 과 비교하여 PTR 은 task-specific knowledge 를 더 잘 자극할 수 있다.","s":"Comparison between PTR and fine-tuning","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#comparison-between-ptr-and-fine-tuning","p":1641},{"i":1669,"t":"Table 2 및 4 에서, prompts 를 PLMs 의 vocabulary 로 사용하는 것이 나은 결과를 가져오는 것을 확인했다. 특정 sub-prompts 를 설계하여, PTR 은 TYP Marker 와 유사한 결과를 달성할 수 있다. 게다가, PTR 은 추가적인 human annotations 없이 실험에서 효과를 입증한다. PTR 은 기존 relation type annotations 에만 의존하여 entity 의 sub-prompt label 을 도출하고, inference time 에는 entity type 을 예측한다. 한편, TYP Marker 는 extra human annotations 를 사용하고 모델에게 training 및 inference 단계에서 ground-truth entity types 를 준다. Prompt 를 사용하는 모델들과 비교하기 위해, few-shot learning 시나리오를 도입한다. Gao et al. (Making pre-trained language models better few-shot learners) 의 few-shot setting 을 따라, 기존의 training set 및 dev set 에서 각 클래스 당 KKK 개의 training instances 와 KKK 개의 validation instances 를 샘플링하여 모델의 기존 test set 에서 평가한다. KKK 를 {8,16,32}\\{ 8, 16, 32 \\}{8,16,32} 중 설정하고, 인스턴스를 샘플링하기 위해 고정된 5개의 random seeds 를 사용한다. Table 5 에서, PTR 이 full training dataset 을 사용하는 TYP Marker (PUNCT) 보다는 성능이 떨어진다. 그러나 TYP Marker (PUNCT) 는 training 및 testing 에 entity typing human-annotations 를 사용하므로 PTR 은 few-shot 상황에서도 유사하거나 더 나은 결과를 달성한다. 특히 데이터에 annotation error 가 적은 ReTACRED 에선 PTR 이 더 나은 성능을 보인다. TYP Marker (PUNCT) 와 AdaPrompt 와 비교하여, human knowledge 와 model knowledge 모두를 사용할 수 있다고 할 수 있다.","s":"Comparison between PTR and prompt tuning","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#comparison-between-ptr-and-prompt-tuning","p":1641},{"i":1672,"t":"Table 7 처럼, 다음 3 개의 dataset 에서 실험을 수행 FewNERT : 구조화가 잘 되어 있는 entity types 으로 large-scale manually annotated dataset 이며, 8개의 entity types 및 66개 세부 entity types OntoNotes : OntoNotes 5.0 dataset 에서 선택된 데이터. PLET 의 설정을 따라 86-classes 버전을 사용 BBN : Wall Street Journal text 의 Penn Treebank corpus 에서 선택된 데이터셋. PLET 의 설정을 따라 46-classes 버전을 사용 위 데이터셋에서, accuracy (ACC), loose micro F1 (MiF) 및 loose macro F1 (MaF) 을 metric 으로 사용한다.","s":"Dataset","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#dataset","p":1641},{"i":1674,"t":"entity typing 실험에서, vanila fine-tuning 및 PLET 을 baseline 으로 사용 PLET 도 prompt-based method 지만, 저자의 방법과 다르게 label words 예측을 위해 template 에서 하나의 masked position 만 사용한다. Table 6 에서 PTR 과 PLET 간의 type-specific prompts 설계의 차이에 대한 내용을 보여준다. PTR 은 Transformers 및 OpenPrompt toolkit 을 기반으로 구현되었다. 공정한 비교를 위해,PLET 와 동일한 설정을 따른다: BERT_base backbone 을 채택하고 learning rate {1e−5,3e−5,5e−5}\\{ 1e-5, 3e-5,5e-5 \\}{1e−5,3e−5,5e−5} 와 처음 500 steps 에 linear warmup 으로 모델을 최적화한다. 16 batch size weight decay 1e−21e-21e−2 supervised 설정에서, 각 모델은 10 epochs 동안 훈련 few-shot 에서는 30 epochs 동안 훈련. 1-shot, 2-shot, 4-shot, 8-shot, 16-shot 및 fully-supervised 설정에서 모델을 tuning 하며, KKK-shot 은 entity type 당 KKK 개의 training examples 을 의미 baseline 설정에 따라 다른 random seed 를 사용하여 데이터를 5번 샘플링하고 평균 결과를 얻음","s":"Baselines and implementation details","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#baselines-and-implementation-details-1","p":1641},{"i":1676,"t":"Table 8 은 세 데이터셋에서 PTR 과 baseline 의 성능을 보여준다. 표에서 다음과 같은 사실을 알 수 있다: PLET 및 PTR 은 모든 실험에서 vanilla fine-tuning 이는 Table 4 및 5 의 relation extraction 실험의 결론과 일치한다. 다양한 set 설정에서의 결과를 비교하면, training sample 수가 적을 때 PLET 및 PTR 이 vanilla fine-tuning 대비 개선되었다. 이는 entity typing 해결을 위해 많은 knowledge 가 PLM 에 오며, prompt 를 사용함으로써 PLM 에 분산된 entity information 을 더 잘 활성화할 수 있다는 것을 나타냄 결과에서 entity types 의 structured hierarchy information 를 명시적으로 학습할 수 있다는 다른 masked position 을 제공함으로써, PTR 이 PLET 보다 나은 결과를 보여줌 일반적으로, entity type schema 의 prior knowledge 를 규칙적으로 인코딩하여 고차원 및 세부 entity information 을 따르도록 prompt 를 설계함으로써 PLM 에게 entity type 을 더 잘 감지하 수 있도록 함","s":"Comparison between PTR and baselines","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#comparison-between-ptr-and-baselines","p":1641},{"i":1678,"t":"이 섹션에서는 task intent classification 에 대한 실험 결과를 제시","s":"4.3 The results on intent classification","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#43-the-results-on-intent-classification","p":1641},{"i":1680,"t":"Table 9 처럼, 다음 세 개의 데이터셋에서 실험을 수행: CLINC150 : 은행, 업무, 여행, 요리 및 일부 메다 정보와 같은 10개 domain 에서 fine-grained 150 가지 intents 를 다루는 데이터셋 BANKING77 : 은행 domain 에서 fine-grained intent detection 을 위해 생성된 데이터셋 HWU64 : 21 domain 에서 fine-grained 64 intents 를 다루는 데이터셋. 이 도메인은 주로 human-home robot 상호작용을 반영 위 세 데이터셋 모두 metric 으로는 accuracy (%) 를 사용한다.","s":"Dataset","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#dataset-1","p":1641},{"i":1682,"t":"intent classification 실험에서, CPET 논문 (Zhang et al., 2021a)의 설정과 동일하게 한다. RoBERTa_base 를 backbone 으로 사용하고 batch size 16 으로 설정 5-shot 및 10-shot (각 의도당 N개의 훈련 예제) 설정으로 모델 튜닝 learning rate {1e−5,3e−5,5e−5}\\{ 1e-5, 3e-5, 5e-5 \\}{1e−5,3e−5,5e−5} 중 모델을 최적화 모든 tuning 과정에는 30 epochs 소요 데이터셋 5개의 다른 seeds 로 무작위 샘플링하여 평균 결과 PTR 의 효과를 평가하기 위해 5가지 최신 intent classification model 과 비교: RoBERTa_base : vanilla fine-tuning USE : 16개 언어에 대해 pre-training 된 large-scale multilingual model 로 intent classification 을 위해 사용 ConveRT : 대화 데이터에서 retrieval-based response selection task 를 통한 pre-trained model ConvBERT : BERT 를 확장하여 open-domain dialogue corpus 에 대해 추가적인 fine-tuning 및 task-adaptive self-supervised training 을 수행한 모델 CPFT : intent classification 을 위해 contrastive pre-training 및 fine-tuning 을 사용하는 모델 여기선 contrastive pre-training 없는 CPFT 와 PTR 을 비교 prompt tuning 이 intent classification 에 널리 탐구되지 않아, 여기선 PTR 의 simplified one mask 버전인 \"PTINT\" 을 구현","s":"Baselines and implementation details","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#baselines-and-implementation-details-2","p":1641},{"i":1684,"t":"Table 11 은 3 가지 데이터셋에서 PTR 과 baselines 의 성능을 보여준다. 이를 통해 다음을 확인할 수 있다: PTINT 와 PTR 은 모든 상황에서 vanilla fine-tuning 보다 큰 성과 이는 PTR 을 tuning 하기 위해 prompt 사용이 효과적임을 시사 prompt tuning 외에도, large-scale intent-related data 를 강화하는 것은 intent classification 의 성능을 크게 향상시킬 수 있다. 직관적으로, prompt tuning 은 PLMs 의 task-specific knowledge 를 모방하는 것을 목표하지만, pre-training 을 강화하는 방법은 PLM 에 더 많은 task-specific knowledge 를 주입하는 데 초점을 맞춘다. 대부분의 상황에서, prompt-based methods 는 pre-training 을 강화하는 모델보다 더 좋은 결과를 얻음 이는 PLM 에 많은 intent-specific knowledge 이 저장되어 있으며, 기존의 내재된 knowledge 를 활용하는 방법이 중요하고 유망함을 나타냄 사실, pre-training 강화 및 prompt tuning 을 동시에 수행하는 것이 더 나은 성능을 가져올 수도 있다. (향후 연구) intent types 는 entity types 및 relation types 보다 덜 structure 하기 때문ㅔ, PTINT 는 잘 수행되며, PTR 대비 PTINT 개선은 약하다. 전반적인 결과는 relation classification 및 entity typing 와 일관성이 있으며, rules 를 사용한 prompt 작성이 효과적임을 보여준다. 본 논문의 rules 은 heuristic 하게 구축되어 있으며, 이는 충분히 효과적이지만 최적이 아닐 수 있다. (향후 연구)","s":"Comparison between PTR and baselines","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#comparison-between-ptr-and-baselines-1","p":1641},{"i":1686,"t":"다양한 prompt tuning 의 학습 효율성을 비교하기 위해 ReTACRED 와 FewNERD 두 데이터셋을 선택하여 각 훈련 과정의 성능 곡선을 보여줌 Fig.3 에서 볼 수 있듯, PTR 은 효과적이면서도 빠른 수렴을 이뤘다. 다른 prompt tuning 과 비교하여, 비록 PTR 의 template 은 최종적으로 더 복잡하고 모델에 많은 정규화를 가져오지만, PTR 의 수렴은 느려지지 않았다. 한편, PTR 의 prompt 는 보다 효과적이고 효율적으로 PLMs 의 knowledge 자극을 위해 더 많은 정보를 도입할 수도 있다. 또한 PLMs 에게 prior task knowledge 을 학습시키는 것은 curriculum learning 과 매우 유사하며, 이는 PTR 의 더 나은 수렴성의 이유다. 이러한 결과는 prompt tuning 과 rules 가 수렴에 대한 잠재적 긍정적인 영향을 나타낸다.","s":"4.4 The convergence of PTR","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"#44-the-convergence-of-ptr","p":1641},{"i":1689,"t":"본 논문에서, 저자는 many-clas text classification task 를 위한 prompt tuning with rules (PTR) 을 제시. rule 에 따라 sub-prompts 를 task-specific prompts 로 구성하여, prior task knowledge 를 prompt tuning 으로 인코딩할 수 있다. sub-prompts 의 도입은 template 및 label word set 설계의 어려움을 완화할 수 있다. relation classification, entity typing 및 intent classification 에 대한 실험 결과는 PTR 이 추가 model layer, manual annotations 및 augmented data 없이 기존의 comparable vanilla fine-tuning 및 prompt tuning baselines 를 능가할 수 있음을 보여준다.","s":"6. Conclusion","u":"/docs/Paper/NLP/Prompt Tuning/PTR","h":"","p":1641},{"i":1691,"t":"논문 및 이미지 출처 : https://dl.acm.org/doi/pdf/10.1145/3560815","s":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1693,"t":"NLP 의 새로운 패러다임으로 prompt-based learning 이 등장 기존 방식 supervised learning input xxx 를 사용하여 output yyy 을 예측하도록 P(y∣x)P(y|x)P(y∣x) 를 훈련 prompt-based learning 텍스트의 확률 직접적으로 모델링 기존의 input xxx 를 채워지지 않은 공백(unfilled slot)을 가진 텍스트 문자 prompt x′x'x′ 로 수정하여 사용 그 후, 미입력된 정보를 확률적으로 채워 최종 문자열 x^\\hat{x}x^ 를 얻음. 이를 최종 output yyy 으로 유도함 이 방식은 다음과 같은 이유로 강력함 LM 이 대량의 raw text 를 pre-trained 할 수 있게 함 새로운 prompting 함수를 정의하여, few/no labeled data 로 few/zero-shot learning 가능 본 논문은 prompting 패러다임을 소개하며 pretrained LM, prompt 및 튜닝 전략의 선택과 같은 다양한 측면의 리뷰를 소개함. 이 외에도 NLPedia-Pretrain 사이트를 제공하며, 지속적으로 업데이트되는 조사 및 논문 목록을 포함한다.","s":"Abstract","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1695,"t":"Fully Supervised Learning : task-specific model 이며, target task 에 대한 데이터셋에 의존 feature engineering : 연구자 또는 엔지니어가 raw data 에서 feature 를 추출하고 모델에 제공하는 방식 제한된 데이터를 학습하여 bias 가 내재 architecture engineering : NLP 의 neural network model 이 진보하며, 주요 feature 를 잘 학습하는 network architecture 구축에 초점을 둠 적절한 아키텍처 설계로 inductive bias 를 제공 2017~2019 에 NLP 의 큰 변화로 fully superviesd 패러다임은 축소됨 pre-train and fine-tune paradigm : language model (LM) 을 대규모 데이터셋에서 pre-train을 진행한 task-specific objective function 으로 fine-tune 을 진행한다. objective engineering : pre-training 및 fine-tuning 과정에 objective 맞게 훈련을 설계 대규모 문장 예측에 loss function 을 도입하여 pre-trained LM 이 text summarization 에 좋은 성능을 보여주며, pre-trained LM 의 몸체가 일반적으로 downstream task 에 대한 해결책으로 적절하게 fine-tuning 된다. 2021 에 다시 큰 변화가 일어나 \"pre-train and fine-tune\" 에서 \"pre-train, prompt, and predict\" 로 대체됨 pre-train, prompt, and predict : LM 을 downstream 에 object engineering 으로 적응시키는 대신 downstream task 와 유사하게 textual prompt 를 재구성 예시로 다음과 같다. \"나 오늘 버스 놓쳤어,\" 그리고 prompt \"내 기분은 _\" 으로 계속하여 LM 에게 공백을 채우도록 요청 \"English:I missed the bus today. French: _\" 으로 번역을 예측하도록 공백을 채우게 한다 이처럼 적절한 prompt 를 선택하여 task-specific training 없이 원하는 출력을 예측할 수 있음 장점으로 다양한 prompt 를 unsupervised 으로 LM 을 통해 많은 task 해결 가능 적절한 prompt 를 찾는 prompt engineering 이 필수","s":"1. Two Sea Changes in Natural Language Processing","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1698,"t":"NLP 의 기존 supervised learning 은 input xxx (보통 text) 으로 output yyy 를 예측하는, P(y∣x;θ)P(y|x;\\theta)P(y∣x;θ) 모델에 기반한다. yyy 는 label, text 또는 다른 형태의 output 일 수 있다. parameter θ\\thetaθ 를 학습시키기 위해, input 과 output 쌍의 데이터셋을 사용하며, 이의 확률 값을 예측하는 모델로 훈련시킨다. 먼저 text classification 에선 text xxx 로 label set Y\\mathcal{Y}Y 로부터 label yyy 를 예측하게 한다. sentiment analysis 에서 input xxx = \"I love this movie\" 로 label set Y\\mathcal{Y}Y = {++, +, ~, -, --} (positive, negative 정도) 중 label yyy = ++ 을 예측하도록 한다. conditional text generation 에서 필란드어 input xxx = \"Hyvää huomenta\" 로 영어 output yyy = \"Good morning\" 을 생성한다.","s":"2.1 Supervised Learning in NLP","u":"/docs/Paper/NLP/Survey/Prompting","h":"#21-supervised-learning-in-nlp","p":1690},{"i":1700,"t":"supervised learning 은 대규모의 annotated data 가 필수이다. prompt-based learning 은 이 문제를 해결하기 위해 3 단계의 prompting 으로 가장 높은 점수의 y^\\hat{y}y^​ 를 예측한다.","s":"2.2 Prompting Basics","u":"/docs/Paper/NLP/Survey/Prompting","h":"#22-prompting-basics","p":1690},{"i":1702,"t":"input xxx → fprompt(x)f_{prompt}(x)fprompt​(x) → prompt x′x'x′ prompting function fprompt(⋅)f_{prompt}(\\cdot)fprompt​(⋅) 은 template 를 적용하는 것으로, 두 가지 slot 이 있는 textual string input xxx 를 위한 input slot [X] yyy 로 매핑될 text zzz 가 있는 answer slot [Z] input text xxx 으로 slot [X] 를 채움 이전의 sentiment analysis 의 예시로 들면 다음과 같다. xxx = \"I love this movie,\" template = \"[X] Overall, it was a [Z] movie\" x′x'x′ = \"I love this movie. Overall, it was a [Z] movie,\" 위와 같은 과정으로 [Z] 를 예측하도록 한다. translation 의 예시로 한다면 \"Finnish: [X] English: [Z]\" 가 될 수 있겠다. 더 많은 예시는 Table 3 에서 볼 수 있다. 세 가지의 주목할 점이 있다. 위와 같은 prompt 는 z 를 채우기 위한 빈 슬롯을 middle, end 에 가진다. close prompt : middle prefix prompt : end 이러한 template 은 natural language token 가 아닌 다음과 같을 수 있다. continuous space 상의 embedding 될 수 있는 가상 단어 continuous vectors [X] 및 [Z] 슬롯은 task 에 따라 유연하게 변경할 수 있음","s":"2.2.1 Prompt Addition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#221-prompt-addition","p":1690},{"i":1704,"t":"LM 의 score 를 최대화하는, 가장 높은 score 의 text z^\\hat{z}z^ 를 찾아야 한다. zzz 는 언어 전체 범위나 작은 부분 집합일 수 있다. 예로, Z\\mathcal{Z}Z = {\"excellent\", \"good\", \"OK\", \"bad\", \"horrible\"} 괴 Y\\mathcal{Y}Y = {++, +, ~, -, --} 처럼 나타낼 수 있다. prompt x′x'x′ 의 [Z] 의 answer zzz 를 채울 ffill(x′,z)f_{fill}(x', z)ffill​(x′,z) 함수 정의 filled prompt : 위 함수로 채워진 prompt answered prompt : true answer 로 채워진 prompt (예; Table 2) pretrained LM P(⋅;θ)P(\\cdot ;\\theta)P(⋅;θ) 으로 filled prompt 의 확률을 계산하여 answer zzz 를 탐색 z^=searchz∈Z P(ffill(x′,z);θ).(1)\\hat{z} = \\underset{z \\in \\mathcal{Z}}{\\textup{search}} \\ P(f_{fill}(x', z); \\theta). \\tag{1}z^=z∈Zsearch​ P(ffill​(x′,z);θ).(1) 위 search 함수는 다음이 가능 argmax search : 가장 높은 score 의 output 을 찾는 함수 sampling : LM 확률 분포에 따른 무작위 output 생성","s":"2.2.2 Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#222-answer-search","p":1690},{"i":1706,"t":"마지막 단계로, 가장 score 가 높은 answer z^\\hat{z}z^ 으로 output y^\\hat{y}y^​ 을 낸다. 번역 같은 생성 작업에선 answer 에 대한 output 생성은 쉽지만, multiple answer 에 대해 동일한 output 을 내는 경우가 있다. 예로, single class (예; ++)를 나타내는 여러 감정 단어 (예; \"excellent\", \"fabulous\", \"wonderful\")를 사용할 수 있다. 이 경우, searched answer 와 output 간의 매핑이 필요하다.","s":"2.2.3 Answer Mapping","u":"/docs/Paper/NLP/Survey/Prompting","h":"#223-answer-mapping","p":1690},{"i":1708,"t":"수학적 공식을 알았으니, prompting 방법에 대한 기본적인 설계 고려사항을 보자. Pre-trained LM Choice P(x;θ)P(x;\\theta)P(x;θ) 를 계산할 다양한 pretrained LM Prompt Template Engineering task 에 따른 proper prompt 선택 정확도뿐만 아니라 model 수행에도 영향 끼침 Section 3 에서 fprompt(x)f_{prompt}(x)fprompt​(x) 로 template 선택법 설명 Prompt Answer Engineering task 에 따른 Z\\mathcal{Z}Z 설계 가능 경우에 따라선 매핑 함수와 함께 설계도 할 수 있음 Section 4 다양한 방법을 다룸 Expanding the Paradigm Section 5 에서 기본 패러다임을 확장하여 더욱 개선하고 적용 가능성을 높이는 방법을 다룸 Prompt-based Training Strategies prompt, LM 둘의 parameter 를 훈련시키는 방법도 있음 Section 6 에서 다양한 전략을 요약하고 이점을 설명","s":"2.3 Design Considerations for Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#23-design-considerations-for-prompting","p":1690},{"i":1710,"t":"Prompt template engineering : downstream task 에 효과적인 성능을 만다는 prompting function fprompt(x)f_{prompt}(x)fprompt​(x) 를 생성하는 과정 task 에 따른 최상의 template 을 위해서, Figure 1 과 같이 두 가지 접근법으로 원하는 shape 의 prompt 를 만들 수 있다.","s":"3 Prompt Template Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1712,"t":"앞서 close prompt 와 prefix prompt 를 언급했다. 이는 task 및 model 에 따라 선택이 갈린다. 생성 관련 task / 표준 auto-regressive LM 의 경우 : prefix prompt 가 더 유리 left-to-right 특성의 모델과 어울림 masked LM 의 경우 : close prompt 가 적합 pre-training task 형식과 유사 텍스트 재구성 모델의 경우 : close prompt 및 prefix prompt 함께 사용 가능 text pair classification 같은 multiple input 의 경우 : prompt template 은 [X1], [X2] 두 개의 input 또는 그 이상을 포함해야함","s":"3.1 Prompt Shape","u":"/docs/Paper/NLP/Survey/Prompting","h":"#31-prompt-shape","p":1690},{"i":1714,"t":"가장 자연스러운 prompt 는 사람의 심리를 기반한 직관적인 template 을 수동으로 생성하는 것이다. 예로, LAMA 데이터셋은 LM 의 knowledge 를 조사하기 위해 수동으로 생성된 close template 을 제공한다. Language Models are Few-Shot Learners 논문에선 question answering, translation 및 probing task 와 같은 일반적인 추론 task 를 포함한 다양한 영역을 처리하기 위해 prefix prompt 를 수동으로 만든다 Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference, Few-Shot Text Generation with Natural Language Instructions, It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners 논문들은 text classification 및 text generation task 에서 few-shot learning setting 에서 미리 정의한 template 을 사용","s":"3.2 Manual Template Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#32-manual-template-engineering","p":1690},{"i":1716,"t":"수동 제작된 template 은 직관적이고 다양한 task 를 어느 정도 해결할 수 있지만 몇 가지 이슈가 있다. prompt 를 생성하고 실험하는 시간 및 비용이 든다; 특히 의미 이해같은 복잡한 task 는 더 힒듬 경험이 많은 prompt 디자이너도 최적의 prompt 를 발견하는데 실패할 수 있음 이 문제를 해결하기 위해 template 을 자동으로 설계하는 프로세스가 제안됨 discrete prompt : 실제 텍스트 문자열 continuous prompt : LM 의 임베딩 공간에 직접 설명되는 prompt","s":"3.3 Automated Template Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#33-automated-template-learning","p":1690},{"i":1718,"t":"discrete prompt 방법은 다음과 같다. D1: Prompt Mining training input xxx 및 output yyy 에서 자동으로 template 를 찾는 마이닝 기법 large text corpus (예; 위키피디아) 에서, \"[X] middle words [Z]\" 와 같은 template 으로 xxx 와 yyy 간의 middle words 또는 dependency path 를 찾음 D2: Prompt Paraphrasing seed prompt 로 다른 후보 prompt 간에 paraphrase 하여 가장 높은 정확도를 선택하는 기법 prompt 를 다른 언어로 번역한 후 재번역하는 방법 시사어에 구절을 바꾸는 방법 정확도 향상에 특화된 neural prompt rewriter 사용하는 방법 특히 이 방법은 xxx 가 template 에 입력된 후 paraphrase 수행 후 각각의 input 에 다른 paraphrase 생성 가능 D3: Gradient-based Search 실제 토큰에 대한 gradient-based search 로 생성가능한 짧은 시퀀스를 찾는 기법 반복 수행 및 prompt 토큰에 순차 탐색 downstream 에 대한 training sample 로 탐색하여 강력한 성능을 보여줌 D4: Prompt Generation 텍스트 생성 모델로 prompt 를 생성 누락된 범위를 채우는데 특화된 T5 를 사용한 32 이 있음 template 내에 template token 을 삽입할 위치 지정 T5 가 template token 을 디코딩 하도록 training sample 제공 36 : prompt 생성 제어를 위해 강화 학습을 사용하기도 함 5 : T5 를 각 input 에 domain relevant feature (DRFs) 을 생성하도록 훈련하는 도메인 적응 알고리즘 제안 DRF (도메인 정보를 특징화하는 키워드 집합) 는 input 과 연결하여 template 을 형성하고 downstream task 에 의해 추가 사용 D5: Prompt Scoring 19 : knowledge base 의 task 를 조사 후 LM 을 이용하여 input(head-relation-tail)에 대한 template 설계 후보군 template 셋을 수동으로 작성하고 input 과 output slot 을 채워 prompt 를 형성 그 후, 단방향 LM 으로 filled prompt 를 평가하여 가장 높은 확률을 선택","s":"3.3.1 Discrete Prompt","u":"/docs/Paper/NLP/Survey/Prompting","h":"#331-discrete-prompt","p":1690},{"i":1720,"t":"continuous prompt : LM 가 효과적으로 task 를 수행하도록 인간이 이해 가능한 자연어가 아닌, LM 의 임베딩 공간에 직접 prompting 을 수행하도록 하는 방법이다. 이 방법은 두 가지 제약을 없앤다. template 단어의 임베딩과 자연어 단어의 임베딩이 일치해야 한다는 제약 완화 template 가 pretrained LM 의 파라미터화 되야 한다는 제약 제거 대신, downstream task 의 데이터에 따라 조정할 수 있는 자체 파라미터가 있음 아래 대표적인 방법들이 있다. C1: Prefix Tuning Prefix Tuning 17 : input 에 continuous task-specific vector 의 시퀀스를 접두어로 추가하는 기법. 동시에 frozen LM 파라미터를 유지 max⁡ϕlog⁡P(y∣x;θ;ϕ)=max⁡ϕ∑yilog⁡P(yi,h<i;θ;ϕ)(2)\\underset{\\phi}{\\max} \\log P(y|x;\\theta;\\phi) = \\underset{\\phi}{\\max}\\sum_{y_i}\\log P(y_i, h_{<i};\\theta;\\phi)\\tag{2}ϕmax​logP(y∣x;θ;ϕ)=ϕmax​yi​∑​logP(yi​,h<i​;θ;ϕ)(2) 수학적으로, matrix MϕM_{\\phi}Mϕ​ 와 pre-trained LM 의 파라미터 θ\\thetaθ 가 주어였을 때 log-likelihood 목표에 따라 최적화한다. h<i=[h<i(1);⋯ ;h<i(n)]h_{<i} = [h^{(1)}_{<i}; \\cdots;h^{(n)}_{<i}]h<i​=[h<i(1)​;⋯;h<i(n)​] 는 timestep iii 에 따른 모든 neural network 층의 연결이다. 해당 timestep 이 prefix (hih_ihi​ 가 Mϕ[i])M_{\\phi}[i])Mϕ​[i]) 내에 있는 경우, 직접 MϕM_{\\phi}Mϕ​ 에서 복하된다. 그렇지 않으면 pre-trained LM 으로 계산한다. 71 : continuous prefix-based learning 이 실제 단어로된 discrete prompt 보다 저데이터 설정에서 초기화에 더 민감하단 것을 관찰 67 : input 시퀀스에 특수 토큰을 추가하여 template 를 형성 하고 토큰의 임베딩을 직접 tuning 71 와 비교하여, 이 방법이 추가 매개변수를 도입하지 않아, 더 적은 매개변수를 사용 135 : 캡션 생성을 위해, frozen LM 을 사용하여 이미지를 임베딩 시퀀스로 인코딩하는 visual encoder 를 학습 visual-language task 에 대한 few-shot learning 이 가능한 것을 보여줌 위 두 논문과 달리, prefix 는 샘플에 따라 다르며, task embedding 이 아닌 input image 의 representation 이다. C2: Tuning Initialized with Discrete Prompt discrete prompt 탐색 기법으로 생성된 prompt 로 continuous prompt 를 초기화하는 기법 152 는 AutoPrompt 와 같은 discrete 탐색 기법으로 template 를 정의 이 prompt 를 기반으로 가상 토큰을 초기화 후 정확도 상승을 위해 임베딩을 finetuning 수동 template 로 초기화하면 탐색 기법보다 더 나은 starting point 를 제공한 다는 점 발견 103 : 각 input 에 대한 soft template 의 혼합을 학습한다. 각 template 의 가중치와 파라미터를 training sample 로 공동 학습한다. 초기 template 셋은 수동으로 만들거나 prompt mining 기법으로 얻는다. 40 : 수동 prompt template 의 shape 를 따르는 continuous template 을 사용한다. C3: Hard-Soft Prompt Hybrid Tuning 단순히 learnable prompt template 사용 대신, hard prompt template 를 tunable 임베딩에 삽입하는 기법 77 : P-tuning 을 제안 continuous prompt 를 학습 가능한 변수를 embedded input 에 삽입하여 학습됨 prompt token 간의 상호작용을 위해, prompt embedding 을 BiLSTM 의 출력으로 나타냄 성능 향상을 위해 template 에 고정된 anchor token 을 사용 41 : prompt tuning with rules (PTR) 제안 규칙 기반으로 완전한 template 을 만들기 위해 수동 제작된 sub-templates 를 사용 template ability 향상을 위해 training sample 을 통해, pretrained LM parameter 와 함께 tunable 가상 토큰을 삽입 PTR 의 template token 은 actual token 및 virtual token 포함 relation classification task 에 효과적","s":"3.3.2 Continuous Prompt","u":"/docs/Paper/NLP/Survey/Prompting","h":"#332-continuous-prompt","p":1690},{"i":1722,"t":"promt answer engineering : 예측 모델에서 answer space Z\\mathcal{Z}Z 를 탐색하고 output Y\\mathcal{Y}Y 와 매핑하는 것이 목표 answer shape 및 answer design 기법에 대해 고려해야함","s":"4 Prompt Answer Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1724,"t":"answer 의 모양은 세부도를 특징 짓는다. 일반적인 선택은 다음과 같다. Token : pre-trained LM 의 vocabulary 에 있는 token 중 하나 또는 vocabulary 의 하위집합 Span : 짧은 multi-token span. 보통 close prompt 와 사용됨 Sentence : 문장 또는 문서. 보통 prefix prompt 와 사용 answer shape 는 task 에 따라 다르다. token/text-span 의 answer space 는 classification (감정 분류; 144), relation extraction 100 또는 entity recognition 17 등 널리 사용된다. longer phrasal/sentential 의 answer space 는 언어 생성 105 이나 mutliple-choice question answering 55 task 등에 자주 사용된다.","s":"4.1 Answer Shape","u":"/docs/Paper/NLP/Survey/Prompting","h":"#41-answer-shape","p":1690},{"i":1726,"t":"적절한 answer space Z\\mathcal{Z}Z 을 설계하는 방법과 answer 이 최종 output 으로 사용되지 않을 경우 output space Y\\mathcal{Y}Y 를 매핑하는 방법이다.","s":"4.2 Answer Space Design Method","u":"/docs/Paper/NLP/Survey/Prompting","h":"#42-answer-space-design-method","p":1690},{"i":1728,"t":"manutal design : answer space Z\\mathcal{Z}Z 와 매핑할 Y\\mathcal{Y}Y 에 대해 관심사로 수동으로 만드는 기법 Unconstrained Spaces : answer space Z\\mathcal{Z}Z 는 모든 토큰 공간 100 , fixed-length spans 50 , 또는 token sequence 105 이다. identity mapping 으로 answer zzz 을 output yyy 와 직접 매핑하는 것이 일반적 Constrained Spaces : text classification / entitiy recognition / multiple-choice question answering 와 같은 제한된 라벨 공간에 대한 task 를 수행할 때 사용하는 기법 144 : input text 와 관련한 단어의 목록 (예; 감정 [\"anger\", \"joy\", \"sadness\", \"fear\"], topics [\"health\", \"finance\", \"politics\"]) 를 수동으로 설계 17 : named entity recognition (NER) task 에 대해 \"person\", \"location\" 같은 목록을 수동으로 설계 위 두 논문 같은 경우, answer Z\\mathcal{Z}Z 와 class Y\\mathcal{Y}Y 간의 매핑이 필수 155 : multiple-choice question answering task 에 대해선 LM 을 사용하여 여러 선택 중 하나의 출력 확률 계산이 일반적","s":"4.2.1 Manual Design","u":"/docs/Paper/NLP/Survey/Prompting","h":"#421-manual-design","p":1690},{"i":1730,"t":"수동 생성된 answer 으로 이상적인 예측 성능을 얻는 다는 것은 sub-optimal 이다. discrete answer search : 자동으로 answer search Answer Paraphrasing 초기 answer space Z′\\mathcal{Z}'Z′ 을 시작으로, paraphrasing 을 사용하여 answer space 를 확장 answer 및 output <z′,y><z', y><z′,y> 주어지면, answer para (z′)(z')(z′) 인 paraphased set 을 생성하는 함수 정의 최종 output 을 모든 answer 에 대한 마진 확률을 정의. P(y∣x)=∑z∈para(z′)P(z∣x)P(y|x) = \\sum_{z \\in \\textup{para}(z')}P(z|x)P(y∣x)=∑z∈para(z′)​P(z∣x) 51 : back-translation 방법을 사용 다른 언어로 번역한 다음, 다시 되돌려 여러 paraphrased answer 을 생성한다 Prune-then-Search : 그럴듯한 answers Z′\\mathcal{Z}'Z′ 를 초기 pruned answer space 에 생성한 후, 알고리즘으로 최종 answer 셋을 선택하는 기법 117, 115 : label yyy 에서 single answer toek zzz 로 매핑하는 함수를 정의. verbalizer 라고 함 최소 두 개의 알파벳 문자를 포함한 토큰 탐색 탐색 단계에서, 데이터의 likelihood 를 극대화하여 label yyy 에 대한 answer zzz 로의 적합도 계산 AutoPrompt : [Z] token 의 contextualized representation 을 입력으로 사용해 logistic classifier 를 학습 탐색 단계에서, 학습된 logistic classifier 로 top-kkk token 을 선택 선택된 토큰들로 answer 형성 32 : 훈련 샘플로 결정된 [Z] 위치의 확률값을 기반으로 top-kkk vocabulary 단어를 선택하여, pruned search space Z′\\mathcal{Z}'Z′ 를 구성 훈련 샘플에 zero-shot 정확도를 기반으로 Z′\\mathcal{Z}'Z′ 의 하위 집합을 선택하여 search space 를 더욱 pruning 함 탐색 단계에서, 고정된 template 와 모든 answer 매핑을 사용하여 LM 을 finetuning 한 후, 이의 정확도를 기반으로 가장 좋은 label word 를 선택 Label Decomposition 13 : 관계 추출 시, 관계 라벨을 구성 요소 단어로 자동으로 분해하고 answer 로 사용 예; per:city_of_death 의 경우, {person,city,death} 로 분해한다. answer span 의 확률은 각 토큰의 확률의 합으로 계산","s":"4.2.2 Discrete Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#422-discrete-answer-search","p":1690},{"i":1732,"t":"몇몇 연구는 경사하강법으로 최적화할 수 있는 soft answer token 을 사용하는 가능성을 연구한다. 40 에서는 각 class label 에 대한 가상 토큰을 할당하고 prompt token embedding 과 함께 각 클래스에 대한 token embedding 을 최적화한다. answer token 은 임베딩 공간에 직접 최적화할 수 있어, LM 으로 학습된 임베딩을 사용하는 대신 각 라벨을 처음부터 학습한다.","s":"4.2.3 Continuous Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#423-continuous-answer-search","p":1690},{"i":1734,"t":"multi-prompt learning : single prompt learning 을 확장하여 효율성을 향상한 방법","s":"5 Multi-Prompt Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1736,"t":"prompt ensembling : 추론 시, 여러 unanswered prompt 를 이용한 프로세스 multiple prompt 는 discrete prompt 또는 continuous prompt 일 수 있다. 서로 보완적인 prompt 의 이점을 활용 prompt engineering 비용 완화 downstream task 의 성능을 안정화 Prompt ensembling 은 머신 러닝의 긴 역사 중 멀티 시스템을 결합한 앙상블 방법을 이용한 것으로, 현재 효과적인 방법을 도출 Uniform averaging : 여러 prompt 의 확률값을 평균 P(z∣x):=1K∑iKP(z∣fprompt,i(x))P(z|x) := \\frac{1}{K} \\sum^K_i P(z|f_{prompt, i}(x))P(z∣x):=K1​∑iK​P(z∣fprompt,i​(x)) fprompt,i(⋅)f_{prompt, i}(\\cdot)fprompt,i​(⋅) 은 iiith prompt 52 : 가장 높은 정확도의 KKK 개 prompt 선택 후, 평균 로그 확률을 사용하여 [Z] 위치의 single token 에 대한 확률 계산 117 : unlabeled 데이터셋에 annotate 하기 위해 앙상블 모델을 사용할 때 간단한 평균화 시도 Bartscore : text generation task 에서, 다양한 prompt 를 사용하여 최종 생성 스코어의 평균을 사용 Weighted averaging : weight 가 있는 각 prompt 로 weight average 를 사용하여 앙상블 weight 는 prompt 성능에 따라 다르고 훈련셋으로 최적화된다. 52 : 훈련셋으로 target output 확률값을 최대화하여 각 prompt 의 weight 학습 103 : 위와 동일한 approach 지만, 데이터 의존적 전략 사용 117, 120 : 훈련셋에서 정확도에 비례하여 각 prompt 에 weight 를 설정 Majority voting : classification task 에서, 다양한 prompt 의 결과를 결합하기 위해 다수결 투표를 사용 (40, 67) Knowledge distillation : 성능 향상을 위해 우수한 모델을 단일 모델로의 knowledge distillation 117, 118, 120 : 수동 생성된 template-answer 쌍으로 모델 훈련 및 앙상블을 통해 unlabeled 데이터셋을 annotate 32 : 자동으로 생성된 template 에서 앙상블 사용 Prompt ensembling for text generation generation task 에 대한 prompt ensembling 연구는 상대적으로 적음 answer sequence 의 다음 단어의 앙상블될 확률 P(zt∣x,z<t):=1K∑iKP(zt∣fprompt, i(x),z<t)P(z_t|x,z_{<t}) := \\frac{1}{K} \\sum^K_i P(z_t|f_{\\textup{prompt, i}}(x), z_{<t})P(zt​∣x,z<t​):=K1​∑iK​P(zt​∣fprompt, i​(x),z<t​) 을 기반으로 output 생성 [118] : 각 prompt fprompt, i(x)f_{\\textup{prompt, i}}(x)fprompt, i​(x) 에 대한 별도의 모델을 훈련 각각의 finetuned LM 을 메모리에 저장하기 힘듬 대신 각 모델의 생성을 디코드한 다음, 생성 확률의 평균을 사용하여 평가","s":"5.1 Prompt Ensembling","u":"/docs/Paper/NLP/Survey/Prompting","h":"#51-prompt-ensembling","p":1690},{"i":1738,"t":"Prompt Augmentation ( Demonstration Learning ) : LM 에게 input xxx 로 인스턴스화된 실제 프롬프트에 대한 answer 를 제공하는데 사용될 수 있는 answered prompt 를 추가로 제공하는 것 \"중국의 수도는 [Z]\" 대신, \"영국의 수도는 런던. 일본의 수도는 도쿄. 중국의 수도는 [Z]\" 와 같이 prompt 를 제공할 수 있음 few-shot demonstration 으로 강력한 언어 모델이 반복 패턴을 학습하는 데 활용한다. 아이디어는 간단하지만 다음 어려움이 있음 Sample Selection : 가장 효과적인 예는 어떻게 선택? few-shot 시나리오는 선택에 따라 성능이 천차만별 32. 74 : 문장 임베딩으로 input 과 가까운 예제를 샘플링 87 : instruction 에 기반한 LM 의 일반화를 측정하기 위해, 주의할 사항을 강조하는 positive, negative sample 을 모두 제공 Sample Ordering : 선택한 샘플을 올바르게 정렬하는 방법은 무엇? 80 : answered prompt 의 정렬은 모델 성능에 중요한 역할하는 점 발견 및 다양한 후보 순열을 평가하기 위해 entropy 기반 방법 제안 62 : prompt augmentation 으로 훈련 예제의 좋은 순열을 찾고, prompt 사이의 separator token 을 학습하여 성능 증가 145 : prompting 을 통한 answered prompt 를 기반으로 meta-prompt 를 생성하는 것을 제안 37 : Prompt Augmentation 은 많은 textual context 를 제공하여 성능을 증가시키는 검색 기법과 관련 있음을 발견 99 : 37 방법은 prompt 기반 학습에도 효과적임을 발견 37 와의 차이는, prompt augmentation 은 template 과 answer 에 좌우되는 반면, larger context learning 은 그렇지 않다는 것","s":"5.2 Prompt Augmentation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#52-prompt-augmentation","p":1690},{"i":1740,"t":"Prompt Composition : 여러 하위 프롬프트를 사용하여 각 하위 작업에 수행하고, 해당 하위 프롬프트를 기반으로 composite prompt 를 정의하는 기법 relation extraction task 의 경우, 두 개체 간의 관계를 추출하는 것으로, 개체 식별 및 개체 분류를 포함한 하위 작업으로 분해할 수 있다. 41 : 개체 관계 및 관계 분류에 대한 수동 생성한 여러 sub-prompt 를 생성하고, 관계 추출 로직을 기반으로 완전한 prompt 로 조합","s":"5.3 Prompt Composition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#53-prompt-composition","p":1690},{"i":1742,"t":"한 샘플로 여러 예측을 수행하는 작업은 전체 input xxx 에 대한 holistic prompt 를 직정 정의하는 것으로 어려움 Prompt Decomposition : holistic prompt 를 여러 sub-prompts 로 분해하여 각 sub-prompts 를 개별적으로 answer 하는 기법 개체 식별 작업에서, input 을 text span 셋으로 변환하고, 모델은 각 span 에 대한 개체 타입 (\"Not an Entity\" 포함)을 예측하도록 prompt 될 수 있음. 이는 span 수가 많아서, 각 span 에 대한 여러 prompt 를 생성하고 개별적으로 예측한다. 17 : 개체 인식에 대한 prompt decomposition 의 접근법을 조사","s":"5.4 Prompt Decomposition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#54-prompt-decomposition","p":1690},{"i":1744,"t":"prompt 를 통해 모델을 훈련하는 방법을 보자.","s":"6 Training Strategies for Prompting Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1746,"t":"zero-shot learning : text P(x)P(x)P(x) 확률을 예측하는 간단한 모델로 훈련하지 않고 close / prefix prompt 를 채우는 것을 적용할 수 있다. 이는 특정 task 에 대한 훈련 데이터가 없는 zero-shot learning setting 이라 한다. full-data learning : 많은 수의 예제를 모델이 훈련 few-shot learning : 적은 수의 예제로 모델 훈련 훈련 예제가 충분하지 않고 모델이 올바르게 작동하는데 효과적 annotated 훈련 샘플을 downstream task 훈련 에 사용되지 않지만, downstream task 에 사용할 prompt 생성이나 검증에 사용된다. 이점은 96 에 따르면, downstream task 에 관련한 zero-shot learning 이 아니라고 한다.","s":"6.1 Training Settings","u":"/docs/Paper/NLP/Survey/Prompting","h":"#61-training-settings","p":1690},{"i":1748,"t":"prompt 기반 downstream task learning 엔 두 타입의 파라미터다 있다. pre-trained LMs prompts 다양한 시나리오에 적용 가능한 수준이 다르기 때문에, 파라미터 결정은 중요하다. 다음 여부에 따라 5 가지 tuning 전략을 소개 LM parameter 의 tuning 여부 prompt 관련 parameter 의 추가 여부 추가 prompt 가 있는 경우, 해당 parameter 의 tuning 여부","s":"6.2 Parameter Update Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"#62-parameter-update-methods","p":1690},{"i":1750,"t":"Promptless Fine-tuning : pretrained LM 의 모든 parameter (또는 일부 46, 98) 가 downstream task 훈련 샘플에서 prompt 없이 gradient 를 통해 업데이트하는 기법 BERT 및 RoBERTa : 위 방법으로 pretrained LM 을 finetuning 이 방법은 간단하며 강력하여 널리 사용되지만, 적은 데이터셋에선 과적합 및 안정적인 학습이 안될 수 있음 84 : 이러한 모델은 catastrophic forgetting 에 취약. 즉, LM 이 finetuning 전에 한 일을 할 수 없게 되는 것 Advantages : 간단, prompt 설계 불필요, LM 의 parameter 를 tuning 하여 큰 데이터셋에 fit 가능 Disadvantages : 적은 데이터셋에선 과적합 및 불안정","s":"6.2.1 Promptless Fine-tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#621-promptless-fine-tuning","p":1690},{"i":1752,"t":"Tuning-free Prompting : prompt 기반의 pre-trained LM 의 파라미터를 변경하지 않고 직접 answer 를 생성하는 기법 answered prompt 를 선택적으로 augmentation 하거나, in-context learning 으로 tuning-free prompting 과 prompt augmentation 을 조합 가능 일반적으로 tuning-free prompting 의 예로 LAMA 및 GPT-3 이 있음 Advantages : 효율적, 파라미터 업데이트 과정 없음, catastrophic forgetting 없음, zero-shot 설정 적용 가능 Disadvantages : 높은 정확도를 위해선 heavy engineering 필요. in-context learning 에서, 많은 answered prompt 가 제공되면 테스트 시간이 느리고 대규모 훈련셋에 쉽게 사용 불가","s":"6.2.2 Tuning-free Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#622-tuning-free-prompting","p":1690},{"i":1754,"t":"Fixed-LM Prompt Tuning : prompt 관련 파라미터가 추가되는 상황에, downstream task 훈련 샘플로 얻은 supervision 을 사용하여 prompt 의 파라미터 만을 업데이트하면서도 pretrained LM 은 변하지 않는 기법 일반적으로 Prefix-Tuning 및 Prompt-Tuning 이 있음 Advantages : tuning-free prompting 과 유사하게, LM 의 knowledge 유지 및 few-shot 에 적합. 종종 tuning-free prompting 보다 정확도 높음 Disadvantages : zero-shot 불가능, 대규모 데이터셋에선 representation 이 제한됨, hyperparameter / seed prompts 선택을 통한 prompt engineering 필수. 사람이 이해 및 조작할 수 없음","s":"6.2.3 Fixed-LM Prompt Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#623-fixed-lm-prompt-tuning","p":1690},{"i":1756,"t":"Fixed-prompt LM Tuning : pretraining 및 finetuning 으로 LM 을 tuning 하지만, 고정된 파라미터의 prompt 를 사용하여 모델의 동작을 지정하는 기법 few-shot 상황에 잠재적인 성능 향상을 가져옴 자연스러운 방법은 모든 훈련 및 테스트 예제에 적용되는 discrete textual template 을 제공하는 것 일반적으로 117, 118 및 32 이 있음 48 : LM finetuning 일부와 prompt answer engineering 의 조합으로 prompt engineering 을 줄일 수 있음을 관찰 input 과 mask 를 template word 없는 \"[X][Z]\" 로 직접 연결한 간단한 템플릿 null prompt 를 정의 경쟁력 있는 정확도를 달성 Advantages : Template 및 answer engineering 은 특정 task 에 더 경쟁력 있고 더 효과적인 학습을 함. 특히 few-shot 상황에 좋음. Disadvantages : prompt 가 없으면 Template 및 answer engineering 이 여전히 필요. 한 downstream task 에 finetuning 된 LM 은 다른 downstream task 에 비효율적","s":"6.2.4 Fixed-Prompt LM Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#624-fixed-prompt-lm-tuning","p":1690},{"i":1758,"t":"Prompt+LM Tuning : pretrained LM 의 파라미터의 일부나 모두를 prompt 관련 파라미터와 함께 finetuning 하는 기법 일반적으로 PADA 및 P-Tuning 이 있음 표준 pretraining 과 finetuning 패러다임과 유사하지만, prompt 추가로 모델 훈련 시작 시 추가 부스팅을 제공 Advantages : 표현력이 가장 뛰어난 방법, 높은 수준의 데이터에 적합 Disadvantages : 모든 모델의 파라미터를 훈련하고 저장이 필요. 적은 데이터셋에는 과적합","s":"6.2.5 Prompt+LM Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#625-promptlm-tuning","p":1690},{"i":1760,"t":"어떠 분야에 사용되었는지 관점으로 섹션 시작","s":"7 Applications","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1762,"t":"Factual Probing : prompting method 를 적용하여 사실을 탐색하는 가장 초기의 시나리오로, LM 의 representation 이 얼마나 사실적 지식을 많이 담는지 정량화하는 것 LM parameter 를 고정되고, 수동 / 자동으로 발견될 수 있는 close prompt 로 original input 을 변환하여 지식을 탐색 LAMA 및 X-FACTR 가 관련 데이터셋 포함 answer 가 미리 정의되어, 효과적인 template 및 다양한 모델의 결과 분석에 중점적 discrete template search [43, 50, 52, 96, 99, 100, 125] continuous template learning [77 103 152] 및 prompt ensemble learning [52 103] 가 탐구됨 Linguistic Probing : 대규모 pretrained LM 은 analogies 9, negations 25, semantic role sensitivity 25, semantic similarity 131, understanding 131 및 rare word understanding 116 가능 위 지식은 LM 이 완성해야할 자연어 문장의 형태로 lignuistic probing 작업을 제시하여 도출","s":"7.1 Knowledge Probing","u":"/docs/Paper/NLP/Survey/Prompting","h":"#71-knowledge-probing","p":1690},{"i":1764,"t":"Semantic Parsing : 자연어가 주어지면 구조화된 의미있는 representation 을 생성하는 작업 124 : LM 으로 few-shot semantic parsing 에 대한 task 를 탐구 의미있는 파싱 작업을 paraphrasing 작업으로 재구성 문법에 따라 유효한 출력만 허용하여 디코딩 in-context learning 으로 테스트 예제와 의미있게 가까운 answered prompt 선택 pretrained LM 으로 의미있는 파싱에 대한 paraphrasing 재구성의 효과를 입증","s":"7.2 Structure Prediction","u":"/docs/Paper/NLP/Survey/Prompting","h":"#72-structure-prediction","p":1690},{"i":1766,"t":"classification-based tasks 는 텍스트 분류와 자연어 추론과 같이 템플릿을 쉽게 구성할 수 있다. 핵심 prompting 은 적절한 prompt 를 구성하는 것이다. 예로, 144 에서는 \"이 문서의 주제는 [Z].\" 같은 prompt 를 사용하며, 이 prompt 는 슬롯을 채우기 위해 masked pretrained LM 에 입력된다. Text Classification 이전 연구들에선 대부분 close prompt 사용 prompt template engineering [32. 40, 67] 및 prompt answer engineering [32, 115, 117] 이 탐구되어, fixed-prompt LM Tuning 으로 few-shot 에서 텍스트 분류에 대한 prompt 효율성을 탐구 Text Pair Classification : 두 문장 간의 관계 (유사성, 함축 등)를 예측하는 작업 paraphrase 식별, 자연어 추론, 텍스트 유사성 예측 등의 작업 포함 text classification 과 유사하게, close prompt 일반적으로 사용 [117, 120] few-shot 의 template 에 중점을 두거나 answer space Z\\mathcal{Z}Z 를 vocabulary 에서 수동으로 선택하는 연구 존재","s":"7.3 Classification-based Tasks","u":"/docs/Paper/NLP/Survey/Prompting","h":"#73-classification-based-tasks","p":1690},{"i":1768,"t":"prompt 를 구성하는 데, 섬세함이 classification task 보다 더 필요 Relation Extraction : 문장 내의 두 개체 간의 관계 예측 13 : relation extraction 에서 처음으로 fixed-prompt LM Tuning 기법 적용 및 classification task 로 부터의 prompting 상속을 방해하는 두 가지를 논의 더 큰 label space (예; 80개 관계 추출 vs 이진 감정 분류) 는 prompt answer engineering 에 큰 어려움 초래 관계 추출에서 input sequence 의 여러 token 들은 중요도가 다름. 위 문제 해결을 위해, adaptive answer selection method 제안 task-oriented prompt template 구축 template 에서 entity mention 을 강조하기 위해 특수 마커 (예; [E]) 사용 41 : 위와 유사하게, multiple prompt 를 통해 개체 유형 정보를 통합 Named Entity Recognition : 문장 내의 named entity 식별 (예; 사람 이름, 지역) tagging task 에 prompt-based learning 적용이 어려움 예측 단위가 text 가 아닌 token 이나 span 임 token label 간의 잠재적인 관계가 존재 17 : BART 로 template-based NER 모델 제안 text span 열거 및 수동 생성된 template 내에서 각 타입의 생성 확률 고려 \"마이크는 어제 뉴욕에 갔다\" 가 주어지면 \"마이크는 [Z] 개체다.\" 라는 template 으로 결정 answer space Z\\mathcal{Z}Z 는 \"사람\", \"조직\" 과 같은 값으로 구성","s":"7.4 Information Extraction","u":"/docs/Paper/NLP/Survey/Prompting","h":"#74-information-extraction","p":1690},{"i":1770,"t":"신경망이 \"추론\" 을 하는지 \"페턴\" 을 인식하는지는 아직도 논쟁이다. 추론 능력 조사를 위해 다양한 시나리오를 포괄하는 벤치마크 작업을 정의하는 시도가 많다. Commonsense Reasoning : NLP 의 상식 추론을 테스트 하는 것. 많은 벤치마크 데이터셋 존재 [47, 72, 101, 107] 68 : 모호한 대명사를 선행 식별하거나 여러 선택 중 문장을 완성하도록 모델에게 요구하여 해결 전자의 경우, \"트로피가 갈색 가방에 못 들어가. 이것은 너무 커.\" 에서 \"이것\" 이 트로피인지 가방인지 추론 후자의 경우, \"Eleanor 은 손님에게 커피를 제안했다. 그녀는 깨끗한 [Z] 가 없단걸 깨달았다\" 에서 후보군은 \"컵\", \"그릇\", \"숟가락\" 이다. 134 : 잠재적 후보의 다양한 선택 확률을 계산하여 pretrained LM 으로 가장 높은 확률을 택하여 전자 해결 25 : 각 후보의 생성 확률을 평가하여 가장 높은 확률을 선택하여 후자 해결 Mathematical Reasoning : 산술, 함수 등과 같은 수학 문제를 해결하는 것 pretrained embedding 및 LM 은 작은 숫자에서 산술을 수행하지만, 숫자가 크면 실패하는 것을 발견 [9, 88, 139] 110 : 복잡한 수학 추론 문제 탐구 (예; f(x)=x∗xf(x) = x * xf(x)=x∗x, f(f(3))f(f(3))f(f(3)) =?) 및 질문에 대한 추론을 직렬화하여 LM 성능 향상","s":"7.5 \"Reasoning\" in NLP","u":"/docs/Paper/NLP/Survey/Prompting","h":"#75-reasoning-in-nlp","p":1690},{"i":1772,"t":"Question answering (QA) : context document 를 기반으로 input question 에 대한 answer 제공을 목표 QA 는 다양한 형태 존재 extractive QA [SQuAD] : context document 에서 answer 을 포함하는 내용 식별 multiple-choice QA [RACE] : 모델이 여러 선택지 중에 선택 free-form QA [NarrativeQA] : 모델이 임의의 텍스트 문자열을 answer 로 반환 이런 다양한 형태는 서로 다른 모델링 프레임워크로 처리하지만, prompting 을 통하면 한 프레임워크로 처리할 수 있다는 장점이 있다. 55 : context 와 question 으로 적절한 프롬프트 및 seq2seq pretrained T5 를 finetuning 하여 QA task 를 text generation 문제로 재구성 51 : seq2seq pretrained LMs (T5, BART, GPT2) 으로 QA task 를 관찰하여, 이러한 모델들의 확률이 QA 작업에 유용하지 않다는 점 발견","s":"7.6 Question Answering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#76-question-answering","p":1690},{"i":1774,"t":"Text Generation : 다른 정보에 따라 텍스트를 생성하는 작업들의 집합. prompting 방법은 prefix prompt 와 함께 autoregressive pretrained LM 으로 쉽게 적용 가능 105 : \"프랑스어 번역, [X], [Z].\" 같은 prompt 를 사용하여 텍스트 요약 및 번역의 생성 작업의 놀라운 성능 입증 9 : 텍스트 생성에 in-context learning 수행, multiple answered prompt 로 수동 템플릿 및 augmenting 와 함께 prompt 생성 118 : 수동 생성된 template 로 few-shot 텍스트 요약에 대한 fixed-prompt LM tuning 탐구 71 : few-shot 에서 텍스트 요약 및 data-to-text 생성에 대한 fixed-LM prompt tuning 을 탐구 learnable prefix token 을 input 앞에 붙임 pretrained LM 의 파라미터를 유지 23 : 텍스트 요약 task 에서 prompt+LM tuning 전략 탐구 learnable prefix prompt 사용 및 pretrained LM 의 파라미터와 함께 업데이트","s":"7.7  Text Generation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#77--text-generation","p":1690},{"i":1776,"t":"147 : 생성된 텍스트에 자동 평가를 prompt learning 으로 사용될 수 있음을 입증 pretrained seq2seq 을 사용하여 생성된 텍스트의 평가를 텍스트 생성 문제로 개념화하고 pretraining task 와 가깝게 평가하도록 하는 prefix prompt 사용 실험적으로 변역된 텍스트에 \"such as\" 문구를 추가하여, 독일어-영어 번역 평가에서 상당한 관계 개선을 가져올 수 있음을 발견","s":"7.8 Automatic Evaluation of Text Generation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#78-automatic-evaluation-of-text-generation","p":1690},{"i":1778,"t":"prompting 기술은 NLP task 뿐 아니라 다른 task 에도 모델을 훈련하는 데 유용한 요소로 작용 Domain Adaptation : 한 도메일에서 다른 도메인으로 적응 시키는 것 (예; 뉴스 → 소셜 미디아) 5 : 원본 텍스트 input 을 augmentation 하기 위해 self-generated DRFs 사용 및 seq2seq 모델로 시퀀스 태깅 수행 Debiasing 121 : LMs 가 biased / debiased instruction 에 따라 self-diagnosis / self-bebiasing 을 수행할 수 있음을 발견 self-diagnosis 의 경우 폭력적인 정보가 포함되었는지 self-diagnosis 하기 위해, \"The following text contains violence. [X][Z]\" 사용 가능 ㅤ[X] 를 채우고 [Z] 의 생성 확률을 본다. \"Yes\" 와 \"No\" 의 확률을 통해 폭력이 포함되었는지 아닌지 추정 debiasing 의 경우 input 이 주어지면 다음 단어의 확률 P(xt∣x<t;θ)P(x_t | x_{<t}; \\theta)P(xt​∣x<t​;θ) 계산 self-diagnosis input 을 원본 input 에 추가하여 다음 단어의 확률 P(xt∣[x<t;xdiagnosis];θ)P(x_t | [x_{<t};x_{\\textup{diagnosis}}];\\theta)P(xt​∣[x<t​;xdiagnosis​];θ) 계산 다음 토큰에 대한 위의 두 확률 분포를 결합하여 원하지 않는 속성을 막음 Dataset Construction 117 : 특정 instruction 이 주어지면 데이터셋을 생성하기 위해 pretrained LM 사용을 제안 의미적으로 유사한 문장으로 데이터셋 구성할 경우, 각 input 문장은 다음과 같은 template 을 사용할 수 있다. \"Write two sentences that mean the same thing. [X][Z]\" 그리고 같은 의미를 공유하는 문장을 생성할 수 있다.","s":"7.9 Meta-Applications","u":"/docs/Paper/NLP/Survey/Prompting","h":"#79-meta-applications","p":1690},{"i":1780,"t":"135 : NLP 의 prompt learning 을 multi-modal 에서 적용 fixed-LM prompting tuning 과 prompt augmentation 사용 각 이미지를 continuous embedding 의 시퀀스로 표현하고 파라미터가 고정된 pretrained LM 으로 프롬프트화하여 image caption 을 생성 위 결과는 few-shot learning 능력을 보여줌 → few demonstration (answered prompt) 을 통해 시스템이 새로운 객체와 시각점 카테고리에 대한 단어를 빠르게 학습","s":"7.10 Multi-modal Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#710-multi-modal-learning","p":1690},{"i":1782,"t":"prompt-based learning 의 본질 및 다른 learning method 와의 관계를 알아보자. Ensemble Learning : 여러 시스템의 상보성(complementarity) 의 이점을 사용하여 task 의 성능 향상을 목적 앙상블은 여러 시스템의 아키텍처, 학습 전략, 데이터 순서 또는 무작위 초기화로 생성 prompt template 의 선택 또한 여러 결과를 생성하는 하나의 방법 여러 번 학습할 필요가 없는 이점 예로, discrete prompt 사용 시 추론 단계에서 간단히 변경 가능 [52] Few-shot Learning : 적은 훈련 샘플로 데이터가 적은 상황에 훈련하는 것을 목표. 다양한 방법 존재 model agnostic meta-learning [29] : 새로운 task 에 빨리 적응하는 feature 학습 embedding learning [8] : 유사한 샘플이 서로 가깝도록 각 샘플을 저차원 공간에 임베딩 memory-based learning [53] : 각 샘플이 메모리에서 내용을 weighted average prompt augmentation [62] : few-shot 을 위한 방법으로 볼 수 있음. 파라미터 tuning 없이 pretrained LM 에서 knowledge 를 유도하여 여러 샘플을 더 추가 가능 Larger-context Learning : input 에 학습 데이터셋 [11] 또는 외부 데이터 소스 [38] 에서 검색된 추가적인 문맥 정보로 augmentation 하여 성능을 향상하는 것이 목표 Prompt Augmentation 은 input 에 관련 라벨 샘플을 추가하지만, larger-context learning 과의 차이점은 라벨 데이터가 반드시 필요하지 않다는 점 Query Reformulation : input query 를 관련된 용어로 확장하거나 paraphrasing 을 생성하여 관련성 높은 텍스트를 유도하는 것이 목표 정보 검색 [90] 및 QA task [10, 136] 에서 사용 prompt-based learning 와 query reformulation 간의 공통성이 있음 기존 지식 베이스를 더 잘 활용하기 위해 올바른 질문을 던짐 지식 베이스는 일반적으로 black-box 여서, 질문에만 기반한 최적화 방법을 학습해야 함 차이점 또한 존재 query reformulation : 지식 베이스는 search engine [90] / QA system [10] 에 사용 prompt-based learning : 지식 베이스를 LM 으로 정의 및 적절한 answer 유도를 위해 적절한 프롬프트 탐색 필요 위 차이점에도 불구하고, query reformulation 은 prompt learning 에 도움이 됨 QA-based Task Reformulation : 다양한 NLP task 를 question-answer 문제로 개념화 하는 것을 목표 어떤 task 를 수행할지 지정하기 위해 text question 을 사용하는 점에서 prompting 방법과 유사 61. 83 : 다양한 NLP task 를 QA 프레임워크로 통합을 시도한 초기 연구 정보 추출 [70, 142] 및 텍스트 분류 [12] 로 위 아이디어 더욱 연구 argRanker : 논쟁적인 관계 분류를 수동으로 연결한 두 문장의 랭킹 문제로 개념화 Controlled Generation : input text 외의 다양한 유형의 가이드를 생성 모델에 통합하는 것을 목표 guidance signal 은 style token [27, 123], length spacifications [56], domain tags [14] 또는 생성된 텍스트를 제어하기 위해 사용되는 다양한 다른 정보일 수 있다. 생성된 텍스트의 내용을 계획하기 위해 keywords [112], relation triples [154] 또는 highlighted phrases or sentences [34, 78] 일 수도 있다. 이 작업에서 prompt 는 task 지정에 사용되며, 다음 두 유형 사이에 공통점을 발견할 수 있음 나은 생성을 위해 input text 에 정보를 추가하며, 이러한 additional signals 는 learnable parameter 이다 \"controlled generation\" 을 seq2seq pretrained LM (예;BART) 로 얻었다면, input 종송적인 prompt 및 prompt+LM fine-tuning 전략을 가진 prompt learning 으로 간주 가능. 예; prompt 및 LM 파라미터로 tuning 가능한 GSum controlled generation 과 prompt-based text generation 의 차이 control 은 생성 스타일이나 내용 제어하는데 사용 [23, 27] 하면서도 동일한 task 상태로 유지. pretrained LM 이 필수적이지 않음 text generation 의 prompt 사용 동기는 task 명시 및 pretrained LM 활용 text generation 의 prompt learning 은 최근 연구에서 데이터셋 또는 task-level prompt 를 공유 [71] 몇몇 연구에서만 input 종속성에 대해 탐구하지만, contolled text generation 에서 일반적인 세팅이며 효과적이다. prompt learning 에 대한 미래 연구의 방향을 제공할 수도 있다. Supervised Attention : 데이터 기반 attention 은 과적합될 수 있어, 모델의 attention 을 supervised 로 제공하는 것을 목표 [76] 주요 정보에 attention 하는 것은, long text sequence [75, 129], images [130, 149] 또는 knowledge bases [23, 146] 과 같은 객체에서 유용한 정보를 추출하는데 핵심적인 단계 prompt learning 및 supervised attention 은 어떠한 단서로 주요 정보를 추출하는 아이디어가 같으며, 이 단서는 별도로 제공되야 한다. 이를 해결하기 위해, supervised attention 은 수동으로 라벨링된 corpus 에서 gold attention 예측을 위해 추가 손실 함수를 사용하여 학습을 시도 [31, 49, 102] Data Augmentation : 기존 데이터를 수정하여 훈련에 사용될 데이터 양을 늘리는 기술 [26, 109] 114 : prompt 추가가 분류 작업 전반에 걸쳐 100개 이상의 데이터 포인트 추가와 유사한 정확도 향상을 평균적으로 얻을 수 있음을 발견 downstream task 에 대한 prompt 사용이 data augmentation 을 암묵적으로 수행하는 것과 유사하다는 것을 시사","s":"8 Prompt-Relevant Topics","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1784,"t":"prompt-based learning 은 다양한 task 와 상황에 대해 상당한 잠재력을 보여주지만, 아직 몇몇 과제들이 있다.","s":"9 Challenges","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":1690},{"i":1786,"t":"다양한 LMs 가 있어, prompt-based learning 을 더 잘 활용하기 위해 선택하는 법도 과제이다. 현재까지 다양한 pretrained LM 에 대한 prompt-based learning 이점의 체계적인 비교가 거의 없거나 전무하다.","s":"9.1 Selection of Pre-trained LMs","u":"/docs/Paper/NLP/Survey/Prompting","h":"#91-selection-of-pre-trained-lms","p":1690},{"i":1788,"t":"Tasks beyond Classification and Generation : prompt-based learning 은 text classification / generation-based task 에 비해 information extraction / text analysis task 는 덜 다루어졌다. 이유는 prompt 설계가 덜 직관적이기 때문이다. 추후, 적절한 텍스트 형태로의 구조화된 출력을 표현하는 효과적인 prompt answer engineering 이나, 텍스트 분류 및 생성 작업처럼 재구성이 필요할 것으로 보임 Prompting with Structured Information : NLP task 에서 input 은 tree, graph, table, relational structure 등 다양하게 표현할 수 있는데, template / answer engineering 에서 어떻게 잘 표현할지가 과제 13 : 기존 연구는 entity marking 처럼, 어휘 정보를 인코딩하여 추가적인 marks 와 prompt 를 만들어서 단계를 나아간다. 1 : fine-grained web text 생성에 대해 hyper text markup language 를 기반으로 구조화된 prompt 제안 하지만 이 방법은 복잡한 구조의 다양한 형태로 확장하는 것은 아직 탐구되지 않아, 흥미로운 연구 주제일 수 있다. Entanglement of Template and Answer : 모델 성능은 사용 중인 template 과 고려 중인 answer 에 따라 달라진다. template 과 answer 의 최상의 조합을 동시에 탐색하거나 학습하는 방법은 여전히 어려운 문제 최근 template 선택 전에 answer 을 선택하지만 [32, 125] , 40 에서는 두 가지의 동시 학습의 잠재력을 입증","s":"9.2 Prompt Design","u":"/docs/Paper/NLP/Survey/Prompting","h":"#92-prompt-design","p":1690},{"i":1790,"t":"Many-class Classification Tasks : class 가 너무 많은 경우, 적절한 answer space 를 선택하는 방법은 어려운 최적화 문제 Long-answer Classification Tasks : multi-token answer 을 사용하는 경우, LMs 를 사용하여 다중 토큰을 잘 디코딩하는 방법은 아직 알려지지 않았으며, 몇 가지 다중 토큰 디코딩 방법이 제안되었지만 [50], 여전히 최적이지 않음 Multiple Answers for Generation Tasks : text generation 의 경우, 적절한 answer 는 의미는 동등하지만 문법적으로는 다양 거의 모든 연구가 single answer 에 의존하여 text generation 을 prompt learning 을 사용하며, 예외적인 경우는 거의 없음 [52] 멀티 레퍼런스로 학습 과정을 잘 가이드하는 방법은 여전히 크게 연구되지 않은 문제","s":"9.3 Prompt Answer Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#93-prompt-answer-engineering","p":1690},{"i":1792,"t":"prompt, LMs, 또는 둘 모두의 파라미터 튜닝에는 다양한 방법이 있다. 이 연구 분야의 초기 단계에서, 이러한 방법들 사이의 균형에 대한 체계적인 이해가 부족하다. 다양한 전략들 간의 균형에 대한 체계적인 탐구로 pretrain 및 finetune 패러다임에 수행되는 것과 유사학 이득을 취할 수 있을 것이다 [98].","s":"9.4 Selection of Tuning Strategy","u":"/docs/Paper/NLP/Survey/Prompting","h":"#94-selection-of-tuning-strategy","p":1690},{"i":1794,"t":"Prompt Ensembling : prompt ensembling 에서, prompt 를 많이 고려할수록 공간 및 시간 복잡도는 증가 다양한 프롬프트의 knowledge 를 추출하는 방법은 아직 충분히 탐구되지 않음 118, 120 및 117 : 앙상블 모델을 사용하여 다양한 프롬프트의 knowledge 추출을 위해 대규모 데이터셋에 annotation 을 달았다. 앙상블 할만한 프롬프트를 선택하는 방법도 아직 충분히 탐구되지 않음 텍스트 생성 작업의 경우, prompt ensemble learning 의 연구가 수행되오지 않았으며, 이는 텍스트 생성에서의 앙상블 학습이 비교적 복잡하기 때문 Refactor : 위 해결방안으로, neural ensembling method 제안 Prompt Composition and Decomposition : 다중 sub-prompt 를 도입하여 복잡한 task input 의 어려움을 제거하는 것이 목표. 좋은 선택을 해야 하는 것이 중요 token [81] / span [30] 예측 task (예; NER) 의 경우, prompt decomposition 를 고려할 수 있음 span relation [66] 예측 task (예; 개체 인식) 의 경우, prompts composition 이 더 좋은 선택일 것임 Prompt Augmentation : 기존의 prompt augmentation 은 입력 길이에 제한이 있다. 예로, 너무 많은 demonstration 을 input 으로 넣으면 실행 불가능하다. 정보를 가진 demonstration 을 선택하고 적절하게 정렬하는 방법은 흥미롭고 도전적인 문제다 [62] Prompt Sharing : 이전엔 주로 single task, domain, language 에 대한 prompt 적용이었지만 multiple 에 대해서도 prompt learning 을 적용하는 prompt sharing 을 고려할 수 있다. 다양한 task 에서 개별 prompt 를 설계 및 각각의 상호작용을 맞추는 법이 핵심 지금까지 많이 탐구되지 않은 분야 Fig. 3 에서 mutiple task 에 대한 multiple prompt learning 전략으로 prompt template 을 공유하는 것을 보여준다","s":"9.5 Multiple Prompt Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#95-multiple-prompt-learning","p":1690},{"i":1796,"t":"많은 상황에선 성공하지만, prompt-based learning 의 이론적 분석과 보장은 희박하다. 141 : soft-prompt tuning 은 downstream recovery (예; downstream task 의 ground-truth labels 을 복원하는 것)를 위해 필요한 non-degeneracy assumptions (각 토큰의 생성 확률은 선형적으로 독립) 을 완화시킬 수 있음을 입증 이는 task-specific 정보를 추출하기 쉽게 만들어줌 113 : 텍스트 분류 작업은 문장 완성 작업으로 재구성할 수 있음을 검증하여, 언어 모델링이 의미 있는 pretrained 작업이 될 수 있음을 보여줌 114 : 분류 작업 전반에 걸쳐 prompt 가 평균 데이터 포인트 수백 개에 해당하는 가치가 있다는 것을 경험적으로 보여줌","s":"9.6 Theoretical and Empirical Analysis of Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#96-theoretical-and-empirical-analysis-of-prompting","p":1690},{"i":1798,"t":"prompt 가 모델에 특화된 정도를 이해하고 prompt 의 전이성을 향상시키는 것 또한 중요한 주제 96 에선 tuned few-shot learning 상황 (prompt 를 선택하기 위해 더 큰 검증셋이 있는 경우)에서 선택된 prompt 가 유사한 크기의 모델에 잘 일반화되는 반면, true few-shot 상황 (학습 샘플이 몇 개 뿐일 경우)에서 선택된 prompt 는 전자보다 일반화되지 않는 다는 것을 보여줌. 모델 크기가 두 상황 모두에서 상당히 다른 전 경우, 전이성이 낮다.","s":"9.7 Transferability of Prompts","u":"/docs/Paper/NLP/Survey/Prompting","h":"#97-transferability-of-prompts","p":1690},{"i":1800,"t":"prompting 패러다임의 성공은 BERT 같은 pretrain 및 finetune 으로 개발된 pretrained LMs 의 top 에서 구축되었다. 하지만, 후자에 대한 효과적인 pretraining 방법이 전자에 그대로 적용할 수 있는지, 또는 다시 생각하여 정확성이나 prompt-based learning 의 적용 용이성을 더 개선할 수 있는지 중요한 연구 질문으로, 이에 대한 문헌은 충분히 다뤄지지 않았다.","s":"9.8 Combination of Different Paradigms","u":"/docs/Paper/NLP/Survey/Prompting","h":"#98-combination-of-different-paradigms","p":1690},{"i":1802,"t":"Calibration (보정)는 모델이 좋은 확률적 예측을 할 수 있는 능력을 말한다 33. answer 예측을 위해 pretrained LMs (예; BART) 의 생성 확률 사용 시, 확률 분포가 일반적으로 잘 보정되어 있지 않아 조심할 필요가 있다. 51 : QA task 에서의 pretrained LMs (예; BART, T5, GPT2) 의 확률이 잘 보정된다는 점 발견 151 : answered prompt 가 제공됐을 때, pretrained LMs 가 특정 answer 로 향하도록 편향되는 세 가지 문제점 (대부분 label bias, receny bias, common token bias)을 식별함 예로, 최종 answered prompt 가 positive label 이면, 모델은 positive words 를 예측하도록 편향됨 이를 해결하기 위해 context-free input (예; prompt 가 \"Input: Subpar acting. Sentiment: Negative\\n Input: Beautiful film. Sentiment: Positive\\n Input: N/A. Sentiment:\")을 사용하여 초기 확률 분포 P0P_0P0​ 을 얻는다 real input (예; prompt 가 \"Input: Subpar acting. Sentiment: Negative\\n Input: Beautiful film. Sentiment: Positive\\n Input: Amazing. Sentiment:\") 를 사용하여 확률 분포 P1P_1P1​ 를 얻는다. 이 두 분포를 사용하여 보정된 생성 확률 분포를 얻는다. 이 모델은 두 가지 단점이 있다. 적절한 context-free input (예; \"N/A\" 나 \"None\" 을 사용할지 여부)을 찾는 추가 비용 발생 pretrained LMs 의 확률 분포는 여전히 보정되지 않음 보정된 확률 분포가 있어도, input 에 대한 single gold answer 추정할 때 조심할 필요가 있다. 동일한 객체의 표면 형태가 유한한 확률 질량을 경쟁한다는 것을 의미 45 예로, \"Whirlpool bath\" 가 gold answer 이라면, 해당 생성 확률은 일반적으로 낮을 것이다. 이유는 \"Bathtub\" 단어는 동일한 의미를 공유하며 더 큰 확률 질량을 차지하기 때문이다. 이를 해결하기 위해 paraphrasing 을 사용하여 gold answer set 을 포괄적으로 구성하는 prompt answer angineering 을 수행 단어 확률을 context 내의 이전 확률에 기반하여 보정","s":"9.9 Calibration of Prompting Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"#99-calibration-of-prompting-methods","p":1690}],"index":{"version":"2.3.9","fields":["t"],"fieldVectors":[["t/3",[0,2.739,1,2.358,2,1.934,3,3.959,4,4.095,5,2.064,6,0.029,7,2.739,8,3.163,9,2.102,10,1.282,11,2.613,12,2.613,13,11.56,14,11.942,15,11.56,16,11.56,17,11.56,18,10.547,19,10.547,20,10.547,21,10.547,22,10.547,23,10.547,24,10.547,25,10.547,26,10.547,27,10.547,28,10.547,29,10.547,30,10.547]],["t/5",[13,10.288,14,11.005,15,10.288,16,10.288,17,10.288,18,8.606,19,8.606,20,8.606,21,8.606,22,8.606,23,8.606,24,8.606,25,8.606,26,8.606,27,8.606,28,8.606,29,8.606,30,8.606]],["t/7",[3,9.962,4,8.899,5,5.259,31,6.066,32,3.923,33,6.404,34,7.409,35,7.409,36,5.849,37,5.463,38,5.259,39,7.608,40,8.839,41,4.499,42,7.409,43,6.191,44,8.06,45,6.98,46,5.259,47,8.06,48,6.98,49,6.151,50,10.206,51,6.241,52,8.06,53,8.06,54,8.06,55,6.98,56,7.409,57,3.065,58,6.008,59,5.707,60,7.409,61,8.06,62,8.06,63,8.06,64,7.409,65,8.06]],["t/9",[3,8.623,4,8.92,5,6.141,6,0.053,31,5.594,32,4.581,33,7.477,37,6.38,48,8.15,58,7.016,66,8.651,67,6.829,68,7.477,69,6.141,70,6.829,71,9.411,72,8.651,73,9.411,74,9.411,75,9.411,76,8.651]],["t/11",[31,6.141,77,7.936,78,10.331,79,7.936,80,3.865,81,9.497]],["t/13",[31,6.071,69,6.665,82,8.115,83,4.242,84,7.412,85,9.389,86,10.214,87,10.214]],["t/15",[88,11.664,89,7.288,90,10.043,91,10.043,92,9.231,93,10.043,94,10.043,95,10.043,96,5.482,97,7.979]],["t/17",[5,5.749,31,6.412,43,6.768,83,3.659,84,6.394,92,8.099,97,7,98,3.466,99,10.719,100,5.208,101,7,102,4.363,103,7.313,104,11.171,105,6.568,106,8.099,107,8.811,108,8.099,109,4.919,110,1.195,111,8.811,112,9.917,113,8.099,114,5.167,115,8.811,116,8.811,117,7.63]],["t/19",[12,6.875,31,4.946,40,7.206,69,5.43,82,8.274,84,7.557,101,6.611,103,7.705,104,9.572,105,7.763,108,9.572,112,7.649,117,7.206,118,8.604,119,10.413,120,10.413,121,9.018,122,8.321,123,8.604,124,5.76,125,7.206,126,8.321,127,6.875,128,6.391,129,4.757,130,6.391,131,6.875,132,8.321,133,7.649,134,5.76,135,7.206,136,6.038,137,7.206,138,7.649,139,8.321,140,8.321]],["t/21",[6,0.074,141,10.331]],["t/23",[6,0.077,41,4.778,142,6.38,143,5.019,144,5.398,145,7.412,146,6.38,147,6.06,148,5.488,149,3.347,150,3.532,151,7.412,152,5.925,153,2.16,154,3.468,155,2.217,156,6.574]],["t/25",[6,0.078,146,4.084,147,5.566,148,3.513,151,6.808,152,5.442,153,1.984,157,4.744,158,1.657,159,3.024,160,1.079,161,5.036,162,5.036,163,5.036,164,2.713,165,2.787,166,5.478,167,1.871,168,1.533,169,4.245,170,1.785,171,3.575,172,4.744,173,3.455,174,4.084,175,4.208,176,1.889,177,4.744,178,5.036,179,3.094,180,3.513,181,5.478,182,5.478,183,4.353,184,5.478,185,1.671]],["t/27",[6,0.078,57,2.659,143,4.101,144,4.41,146,5.213,152,6.443,153,1.765,160,1.378,161,6.428,162,6.428,171,6.073,178,6.428,186,6.993,187,4.41,188,6.428,189,6.993,190,3.404,191,4.548,192,6.993,193,1.968,194,6.993,195,4.101,196,5.213,197,6.428,198,3.591,199,2.799,200,2.868,201,3.591,202,3.904,203,4.74,204,1.43]],["t/31",[6,0.078,171,5.307,177,7.043,205,8.133,206,8.133,207,1.83,208,1.217]],["t/33",[6,0.078,41,5.435,148,6.243,158,2.265,171,6.353,172,8.431,174,8.065,175,9.121,203,6.6,209,6.883,210,9.736,211,7.488,212,2.817,213,7.488,214,2.474,215,7.488]],["t/35",[6,0.078,147,7.086,171,6.53,173,6.311,216,4.524,217,6.002,218,7.814,219,3.11]],["t/38",[6,0.078,10,2.769,146,5.094,148,4.381,160,1.346,171,5.98,174,5.094,175,7.039,176,2.356,193,1.724,195,4.007,198,5.311,204,1.397,209,6.281,214,2.258,220,4.959,221,5.121,222,4.309,223,4.542,224,5.918,225,6.833,226,3.384,227,5.249,228,4.959,229,6.833,230,3.146,231,2.82,232,2.82,233,4.959,234,6.281,235,6.833,236,2.322,237,4.838,238,6.833,239,5.249,240,5.918]],["t/40",[6,0.077,142,6.442,171,6.956,174,6.442,175,8.88,214,2.855,224,7.483,228,6.271,241,7.14,242,7.943]],["t/42",[6,0.077,80,3.264,142,8.655,173,5.503,219,3.473,226,4.321,228,7.782,243,8.725,244,8.725]],["t/44",[6,0.077,142,6.837,146,6.837,147,6.494,152,6.349,153,2.314,193,1.725,220,6.655]],["t/47",[6,0.078,41,6.689,152,4.898,153,1.786,154,2.867,155,1.833,156,5.435,245,9.38,246,6.254]],["t/49",[6,0.078,152,3.875,153,1.413,158,1.693,196,4.173,214,3.074,222,5.035,230,2.577,246,3.327,247,3.589,248,5.598,249,4.173,250,7.792,251,5.598,252,4.173,253,5.412,254,3.822,255,5.598,256,2.34,257,6.441,258,5.598,259,5.598,260,5.598,261,3.056,262,2.658,263,4.062,264,4.173,265,5.146,266,5.598,267,4.848,268,1.988,269,5.146,270,5.146,271,5.598,272,5.598,273,5.598,274,5.598,275,5.598,276,5.598,277,5.598,278,5.598,279,4.625]],["t/53",[6,0.076,41,4.288,80,2.873,152,5.317,153,1.938,164,3.804,171,5.012,176,2.648,179,5.59,180,4.925,236,2.61,253,5.206,254,3.677,267,6.651,280,7.681,281,7.681,282,6.346,283,6.651,284,7.681,285,7.06,286,3.231,287,7.378,288,7.072,289,8.177,290,7.06,291,5.317,292,5.317,293,7.06,294,7.681,295,5.899,296,7.681,297,7.06,298,6.651,299,6.346,300,4.446,301,7.681,302,7.681,303,7.681,304,7.06]],["t/55",[6,0.077,142,8.215,171,5.954,188,8.387,257,7.629,305,5.036,306,5.423,307,9.124,308,6.185,309,7.902,310,8.387]],["t/58",[6,0.078,51,5.088,180,5.336,214,2.749,283,7.206,311,8.321,312,8.321,313,7.649,314,6.875,315,6.038,316,3.747,317,3.064,318,5.76,319,3.831]],["t/60",[6,0.077,169,5.082,203,6.38,320,9.411,321,6.969,322,8.15,323,8.15,324,9.411]],["t/63",[6,0.075,10,3.535,164,4.321,180,6.876,207,1.963,208,1.306,230,4.017,246,5.186,268,3.099,283,7.556,288,6.558,295,6.702,325,9.287,326,3.743,327,4.212,328,8.725,329,8.725,330,6.702,331,7.556,332,6.04,333,5.117,334,6.702,335,8.725,336,8.725,337,6.178]],["t/65",[6,0.076,142,7.09,310,8.742,321,5.904,325,8.236,327,4.591,338,9.511,339,9.511,340,7.858]],["t/68",[6,0.071,142,7.746,171,6.78]],["t/72",[6,0.074,152,7.111,153,2.592]],["t/74",[6,0.075,41,5.67,155,2.631]],["t/76",[6,0.077,146,6.35,147,6.032,151,7.377,153,2.667,155,2.207,156,6.543,160,1.678,171,6.895,174,6.35,175,6.543,193,1.602,220,6.182,308,5.774,341,8.518]],["t/78",[1,4.784,5,4.188,10,4.831,36,4.657,41,6.501,57,4.428,109,3.583,144,4.048,145,5.558,146,4.784,147,6.22,148,4.115,149,2.51,152,4.443,153,1.62,154,2.6,155,1.663,156,4.93,158,1.941,168,1.796,171,4.188,172,5.558,173,5.54,174,6.548,175,8.271,177,5.558,179,3.625,193,2.121,195,3.764,196,4.784,214,2.902,220,4.657,222,7.112,224,5.558,241,5.303,242,5.9,253,5.954,265,8.074,267,7.607,286,2.7,342,3.984,343,5.099,344,2.303,345,8.074,346,6.418,347,4.267,348,6.905,349,4.93,350,6.418,351,9.205,352,8.784,353,6.418,354,3.235,355,8.784,356,8.784,357,7.607,358,5.099,359,3.124,360,6.418,361,6.418,362,5.303,363,6.418,364,5.558,365,4.115,366,4.657,367,4.657]],["t/80",[80,3.615,114,5.668,149,3.78,176,3.332,179,5.459,236,3.284,285,8.884,287,7.204,288,5.909,289,7.985,292,7.895,293,8.884,295,7.423,368,7.013,369,7.678,370,9.664,371,9.664]],["t/82",[6,0.074,372,10.331]],["t/84",[6,0.077,144,5.725,150,3.747,169,4.902,170,3.85,373,4.001,374,1.119,375,5.539,376,6.034]],["t/86",[6,0.078,129,2.935,150,2.119,153,1.296,159,2.834,167,1.753,168,2.099,170,2.888,180,3.292,187,4.73,373,2.263,376,4.985,377,2.312,378,5.134,379,7.856,380,5.27,381,4.446,382,3.726,383,1.931,384,2.715,385,2.119,386,5.134]],["t/88",[6,0.078,32,2.887,159,3.273,167,4.132,169,3.202,170,3.129,180,5.332,376,6.919,377,5.449,382,4.304,387,3.87,388,3.803,389,4.106,390,5.451,391,5.931,392,4.304,393,5.931,394,4.106,395,5.136,396,4.9,397,4.9]],["t/91",[6,0.078,102,2.513,158,0.938,165,1.579,167,1.733,168,2.081,170,2.868,176,1.749,185,0.946,193,0.954,199,2.577,207,1.142,208,0.759,214,3.491,216,1.796,220,2.252,231,3.384,237,2.197,249,2.313,262,3.057,321,3.15,373,1.368,377,1.397,388,3.253,389,5.676,398,1.773,399,3.293,400,4.664,401,2.539,402,4.944,403,3.103,404,3.103,405,3.103,406,4.192,407,3.103,408,3.897,409,5.074,410,2.901,411,3.311,412,3.103,413,3.103,414,3.103,415,2.383,416,3.103,417,3.103,418,3.103,419,3.103,420,0.807,421,5.917,422,3.108,423,3.2,424,1.387,425,1.439,426,3.103,427,3.103,428,2.8,429,5.074,430,1.753,431,1.42,432,3.894,433,1.82,434,4.2,435,4.18,436,1.766,437,2.383,438,4.664,439,2.631,440,1.694,441,3.103,442,3.103,443,3.103,444,3.103,445,3.103,446,5.074,447,3.103,448,3.103,449,3.103,450,3.103,451,3.103,452,5.074,453,3.103,454,3.103,455,3.103,456,3.103,457,3.103,458,3.103,459,3.103,460,3.103,461,3.103,462,3.103,463,3.103,464,5.074,465,3.103,466,2.852,467,3.103,468,3.103,469,3.103,470,3.103,471,3.103,472,3.103,473,3.103,474,3.103,475,3.103,476,1.054]],["t/93",[6,0.078,129,4.41,167,2.634,169,4.165,170,2.514,207,1.736,208,1.154,376,6.596,377,3.473,379,5.598,380,3.755,399,3.093,402,8.428,434,4.357,435,5.211]],["t/95",[6,0.077,32,5.567,57,2.836,102,5.347,160,1.469,170,2.43,214,3.208,376,7.176,389,8.209,394,7.917,399,3.026,401,3.315,406,8.023,477,5.412,478,7.046,479,6.855]],["t/97",[6,0.078,10,2.677,168,1.849,169,4.838,193,2.05,207,2.287,208,1.521,231,2.727,261,3.606,263,4.794,349,5.075,374,0.814,379,4.794,380,3.216,389,4.574,399,2.792,401,2.256,402,5.075,425,3.065,431,3.05,432,3.138,435,4.255,480,3.298,481,3.732,482,6.607,483,6.607,484,4.794,485,3.459,486,2.661]],["t/99",[6,0.071,169,5.579,187,6.516,477,7.497]],["t/102",[6,0.074,57,4.233,129,4.547,153,2.007,180,7.513,193,1.496,325,8.764,374,0.98,381,6.887,383,4.187,396,6.571,397,6.571,487,3.594,488,7.953,489,7.953,490,6.319,491,7.953,492,7.953,493,7.953,494,4.046,495,6.571,496,5.771,497,7.953,498,7.953,499,7.953,500,8.764,501,7.31,502,7.953,503,6.887,504,6.319,505,4.009,506,5.286,507,7.953,508,7.953,509,7.953,510,4.547,511,7.953]],["t/104",[6,0.078,32,3.059,148,4.029,153,1.586,158,2.618,164,3.112,165,4.404,168,1.758,169,5.348,176,2.985,183,4.992,187,5.459,214,2.076,222,6.246,344,3.106,376,4.176,383,2.363,389,7.749,394,4.35,401,3.382,420,2.251,424,2.809,477,4.56,479,5.776,486,3.989,512,2.166,513,2.086,514,5.776,515,6.283,516,4.56,517,3.685,518,5.192,519,8.657,520,2.231]],["t/106",[6,0.074,10,4.384,160,1.745,164,5.359,169,5.843,183,7.035,187,5.584,193,1.665,207,1.992,208,1.325,236,3.009,288,5.414,330,8.312,521,8.139,522,6.601,523,8.854,524,8.854,525,8.854,526,8.854,527,8.854,528,5.497,529,7.668,530,8.854,531,7.668]],["t/108",[6,0.077,41,4.801,207,1.935,208,1.287,262,4.084,422,3.594,476,2.922,532,3.578,533,3.464,534,3.641,535,8.6,536,8.6,537,8.6,538,7.448,539,6.241]],["t/110",[6,0.077,150,3.566,169,5.757,171,5.639,183,6.866,344,3.1,376,5.744,504,6.866,512,2.979,518,7.14,531,7.483,540,6.866,541,4.397,542,7.14,543,7.14,544,8.641]],["t/112",[6,0.078,41,3.557,148,4.086,153,2.206,169,3.441,180,5.605,187,5.513,193,1.644,207,1.434,208,0.954,236,2.166,253,4.32,262,3.026,288,3.897,317,2.346,379,6.343,380,4.255,382,7.24,383,3.288,396,5.265,397,8.243,431,2.446,532,2.145,533,2.077,545,5.265,546,5.858,547,6.372,548,6.372]],["t/114",[6,0.077,169,6.271,170,2.279,179,6.745,183,8.312,187,4.41,193,2.246,431,3.341,477,6.754,518,7.69,531,6.056,549,6.993,550,6.993,551,6.993,552,6.993,553,9.307,554,9.215,555,6.993,556,8.06,557,7.149,558,8.555,559,5.257,560,6.993,561,6.993,562,6.993]],["t/116",[6,0.078,57,1.903,102,2.479,129,2.862,148,3.209,149,1.958,167,3.787,168,2.06,169,4.715,170,2.399,221,2.479,236,1.701,262,2.377,376,5.804,377,3.315,389,5.096,399,3.344,400,4.601,402,3.844,432,3.496,435,4.147,534,4.343,558,6.767,563,8.026,564,3.844,565,2.322,566,7.562,567,3.544,568,5.005,569,5.005,570,5.849,571,8.732,572,8.732]],["t/118",[6,0.076,153,2.202,169,6.27,176,3.008,180,5.595,373,3.846,374,1.075,377,5.228,389,6.04,424,3.9,541,6.162,557,6.702,573,4.631,574,8.725]],["t/120",[6,0.077,57,3.024,147,5.631,169,5.465,170,2.591,193,1.903,201,4.084,202,4.44,377,3.581,379,5.771,380,3.871,382,5.771,389,5.505,397,6.571,401,2.715,428,2.715,431,2.832,541,5.149,575,2.677]],["t/122",[6,0.074,576,10.331]],["t/124",[6,0.078,57,2.24,110,1.123,200,2.416,201,4.251,202,3.289,305,4.569,319,3.811,373,2.597,374,1.509,375,4.824,385,3.416,398,1.623,401,2.012,520,2.092,573,2.544,577,5.102,578,6.839,579,4.275,580,3.916,581,4.525,582,2.892,583,3.916,584,2.712,585,3.148,586,4.172,587,3.994]],["t/126",[6,0.078,57,3.067,110,0.904,144,2.764,170,1.428,200,3.308,201,4.628,202,4.503,212,1.648,305,3.679,317,1.613,319,3.068,374,1.509,375,4.543,385,3.329,401,2.276,425,2.033,432,3.165,520,2.864,532,1.475,573,1.892,575,1.475,577,3.795,578,6.664,579,3.18,580,2.913,582,3.272,583,5.361,584,3.068,587,4.518,588,3.366,589,1.354,590,2.017,591,2.017,592,1.724,593,3.18,594,4.382,595,1.831,596,2.764,597,3.33]],["t/128",[6,0.077,57,3.334,176,3.023,200,3.596,201,5.524,202,4.895,305,4.839,374,1.495,375,4.42,420,2.28,577,7.593,582,4.305,583,5.828,584,4.036,587,5.943,598,8.768]],["t/130",[6,0.078,57,2.355,80,1.49,185,2.614,200,3.808,201,3.903,202,4.242,214,2.046,316,1.794,317,2.28,319,1.834,374,1.056,385,1.644,398,2.361,401,2.115,420,1.036,425,1.848,481,2.25,505,2.008,520,2.699,573,2.675,578,5.118,579,4.495,580,4.117,582,3.731,583,6.819,584,3.498,585,3.31,587,5.151,589,1.231,593,2.891,599,3.165,600,3.984,601,3.662,602,3.292,603,3.984,604,3.984,605,3.984,606,3.984,607,3.984,608,7.423,609,3.984,610,3.984,611,3.984,612,3.984,613,6.194,614,6.194,615,3.984,616,3.984,617,3.984,618,3.984,619,3.984,620,3.984,621,3.984,622,1.215,623,2.107]],["t/132",[6,0.078,57,3.933,110,1.403,170,1.663,200,2.094,201,2.622,214,1.686,236,1.735,261,2.786,319,2.35,374,1.198,375,2.573,398,2.433,401,3.016,420,1.942,428,3.016,430,4.219,433,2.994,520,3.673,534,3.739,624,3.763,625,5.105,626,5.105,627,5.105,628,3.331,629,5.105,630,5.105,631,2.918,632,5.105,633,5.105,634,4.077,635,2.817,636,5.105]],["t/134",[6,0.077,57,3.636,374,1.397,401,3.265]],["t/136",[6,0.078,57,3.995,246,5.015,374,1.295,401,2.881,487,3.731,637,5.506]],["t/138",[6,0.078,57,3.705,83,2.53,164,4.825,185,1.858,214,2.013,236,3.579,246,5.036,268,2.163,319,2.804,367,4.42,374,1.519,401,2.08,637,6.357,638,3.222,639,3.815,640,6.092,641,4.541]],["t/140",[6,0.078,80,1.995,110,0.723,198,2.738,201,2.738,202,2.977,212,2.006,316,2.401,374,1.223,398,2.494,401,1.821,520,1.894,573,4.284,579,5.594,580,5.124,581,4.096,582,2.618,583,5.124,584,2.455,585,2.849,608,6.676,622,1.626,628,3.479,642,5.332,643,5.332,644,5.332,645,2.574,646,3.975,647,5.332,648,4.618,649,5.332,650,9.055,651,3.691]],["t/143",[6,0.078,169,3.202,170,2.71,176,2.045,179,3.35,200,3.939,201,3.046,202,3.311,212,2.231,295,4.555,317,2.183,327,2.863,330,4.555,374,1.025,375,2.99,398,1.633,425,2.751,428,2.025,487,2.106,490,4.712,532,2.799,573,2.561,579,4.304,580,3.942,582,4.083,583,3.942,584,2.73,602,4.9,622,1.809,623,3.137,624,2.527,638,3.137,652,5.931,653,5.451,654,5.451,655,5.708,656,4.106,657,4.199,658,5.451,659,3.574,660,4.106,661,5.931,662,5.931,663,3.252,664,3.478,665,4.555,666,5.931,667,5.931,668,5.931,669,5.451,670,5.451,671,5.931,672,7.644,673,2.463,674,5.451]],["t/145",[6,0.078,219,3.423,246,5.111,398,2.369,401,2.937,425,3.989,658,9.77,675,8.6]],["t/147",[6,0.078,110,1.183,200,2.604,226,3.145,573,2.742,582,3.117,593,6.328,608,5.499,665,4.877,672,5.837,674,5.837,676,3.545,677,4.985,678,2.839,679,6.328,680,4.396,681,7.551,682,6.35]],["t/149",[6,0.078,160,1.188,200,2.473,201,3.097,214,1.992,236,2.049,319,2.776,401,2.059,528,3.743,579,6.105,580,5.592,582,2.96,583,4.008,593,7.609,602,4.982,638,3.189,657,4.27,679,7.032,680,4.174,681,7.286,683,6.03,684,4.632,685,4.791,686,3.068,687,3.536,688,5.222,689,5.543]],["t/151",[6,0.076,57,3.418,200,3.686,201,5.608,202,5.017,236,3.711,374,1.108,582,4.412,583,5.974,584,4.137,637,5.864,641,6.7,690,8.987,691,8.987,692,8.987,693,6.7]],["t/153",[6,0.078,57,2.04,129,3.067,160,1.057,167,1.832,170,2.961,185,1.636,200,2.2,201,2.755,202,2.994,212,2.018,216,4.482,222,3.383,253,3.636,254,2.568,319,2.469,374,1.3,376,7.306,385,2.214,428,1.832,513,1.78,573,3.923,583,3.565,584,4.182,590,2.469,694,4.645,695,7.117,696,10.549,697,7.451,698,4.645,699,7.742,700,4.432,701,5.364,702,4.931,703,5.364,704,4.262,705,3.636,706,7.742]],["t/155",[6,0.078,57,2.525,149,2.597,160,1.584,176,1.504,200,2.724,201,4.13,202,2.435,212,3.025,214,1.441,236,3.802,268,1.549,319,3.057,374,1.496,385,2.74,436,1.518,582,2.141,583,4.414,584,3.702,593,3.165,641,3.251,681,3.777,693,3.251,707,4.361,708,2.355,709,2.435,710,4.361,711,4.009,712,5.018,713,4.361,714,4.361,715,4.361,716,4.361,717,4.361]],["t/157",[6,0.078,57,2.449,80,2.41,129,3.683,185,1.965,200,3.611,201,5.538,202,4.916,226,3.19,374,1.392,436,3.066,512,2.221,559,3.638,582,4.323,583,5.853,584,4.619,655,3.828,712,4.916]],["t/159",[6,0.078,57,1.721,110,0.927,150,1.868,160,1.346,202,2.527,212,1.702,216,2.62,319,2.083,374,1.362,375,3.443,385,1.868,401,2.332,436,1.576,520,1.607,575,1.523,579,3.284,580,3.008,582,2.222,583,3.008,585,2.418,587,3.068,622,1.38,657,3.205,660,4.728,663,1.77,718,2.444]],["t/161",[6,0.074,719,10.331]],["t/163",[6,0.078,57,2.071,98,2.142,110,0.739,160,1.073,200,3.21,201,2.796,202,4.369,226,2.697,317,2.005,326,2.336,366,3.951,374,1.435,375,2.745,420,1.416,476,1.85,582,5.424,589,2.418,623,2.88,638,2.88,686,2.77,720,4.715,721,6.83,722,3.691,723,3.769,724,3.856,725,3.33,726,5.445,727,2.796,728,3.236,729,3.856,730,4.683,731,5.445,732,4.182,733,4.499,734,4.326,735,4.499]],["t/165",[6,0.078,98,1.619,110,1.381,158,0.73,160,0.476,170,0.787,200,4.085,201,2.113,202,4.622,204,0.494,212,0.908,247,2.638,316,1.087,317,0.889,326,2.724,348,1.548,354,2.711,366,5.628,374,1.371,399,0.753,420,0.628,428,1.405,436,0.841,476,0.821,534,1.022,573,1.777,580,2.735,582,5.567,589,1.271,590,1.112,622,0.736,623,1.277,624,1.753,638,2.176,686,2.094,695,3.782,697,2.789,720,2.091,721,6.501,723,3.722,724,5.045,725,2.516,727,2.113,728,1.435,730,1.924,732,4.878,733,1.995,734,4.272,735,4.443,736,5.046,737,3.068,738,3.269,739,2.849,740,4.878,741,3.563,742,3.145,743,0.845,744,3.161,745,2.219,746,5.377,747,5.248,748,1.156,749,1.853,750,1.637,751,1.576]],["t/168",[6,0.078,32,2.996,57,2.34,98,2.421,110,1.599,129,3.518,158,1.861,200,3.5,201,3.161,202,3.436,342,3.82,374,1.207,425,3.958,582,5.193,638,3.255,697,4.172,721,6.361,723,4.26,724,4.358,725,3.763,728,5.072,732,4.727,736,6.78,737,4.588,738,4.89,739,4.26,740,6.554,741,5.329,750,4.172,751,4.016,752,6.154,753,6.154]],["t/170",[6,0.078,32,1.608,98,1.299,110,1.294,176,1.139,207,1.512,212,1.242,214,1.091,231,4.096,261,1.803,366,3.874,374,0.828,399,2.094,406,2.729,425,1.532,428,2.294,476,2.878,589,1.02,590,3.093,593,2.397,635,1.823,638,2.823,655,1.963,657,2.338,724,3.78,725,2.019,730,1.544,732,2.537,745,7.092,748,1.581,751,5.034,754,3.303,755,5.338,756,3.303,757,3.303,758,3.303,759,2.462,760,3.303,761,5.997,762,5.338,763,3.303,764,3.303,765,3.303,766,5.599,767,4.623,768,3.303,769,3.303,770,3.303,771,3.303,772,3.303,773,3.303,774,2.083,775,3.303,776,5.338,777,5.338,778,3.303,779,3.303,780,3.303,781,3.303,782,3.303,783,3.303,784,3.303,785,3.303,786,3.303,787,4.907,788,3.303,789,3.303,790,3.036,791,3.618,792,2.729,793,2.019,794,3.303,795,3.303,796,3.303,797,3.303,798,3.303,799,2.118,800,2.86,801,5.338,802,3.303,803,3.036,804,3.303,805,3.303,806,3.303,807,3.303,808,2.86,809,3.303,810,3.303,811,3.303,812,3.303]],["t/172",[6,0.077,32,5.126,57,2.316,110,1.429,167,2.08,168,2.371,220,4.42,226,4.196,348,5.433,375,3.071,399,1.899,424,2.723,428,2.08,534,2.579,589,1.882,590,4.485,728,3.621,749,4.387,750,6.604,774,3.842,800,5.275,808,5.275,813,6.092,814,6.092,815,2.685,816,8.473,817,4.84,818,3.325,819,6.092,820,6.092,821,6.092,822,6.092,823,8.473,824,8.473,825,6.092,826,6.092,827,8.473,828,6.092,829,6.092,830,5.599,831,4.049,832,6.092,833,6.092,834,6.092,835,6.092]],["t/174",[6,0.078,32,4.32,110,1.351,167,1.591,170,1.518,200,2.455,214,1.539,219,1.854,220,2.031,227,3.579,231,1.923,236,1.583,247,2.988,261,1.527,300,1.62,317,1.03,319,1.288,348,1.794,366,3.381,374,0.956,377,1.26,399,2.609,401,0.955,408,2.149,411,1.826,420,1.815,428,2.384,432,3.682,436,1.622,481,3.381,534,1.972,541,1.424,573,1.208,580,1.86,582,5.018,590,2.145,623,1.48,624,3.304,638,1.48,698,4.035,709,2.601,721,2.086,723,1.937,724,3.299,725,1.711,727,4.558,728,1.663,732,2.149,736,3.702,737,2.086,744,2.149,747,5.768,750,1.897,751,3.906,774,1.765,799,1.794,800,2.423,803,2.572,808,2.423,830,2.572,836,6.981,837,2.798,838,2.086,839,3.233,840,1.897,841,2.572,842,1.826,843,2.149,844,2.798,845,3.473,846,2.798,847,2.798,848,4.659,849,2.129,850,2.798,851,2.423,852,2.798,853,1.981,854,1.794,855,2.798,856,2.798,857,2.798,858,2.798,859,2.798,860,2.312,861,2.798,862,2.798,863,2.798,864,2.423,865,2.798,866,2.798,867,2.798,868,2.798,869,2.798]],["t/177",[6,0.078,57,3.493,98,1.789,193,1.29,200,3.384,201,3.521,202,2.539,214,1.503,236,1.546,319,4.537,366,3.301,374,0.845,385,2.829,399,1.418,428,1.553,432,2.16,480,1.675,487,1.615,573,3.966,582,2.233,590,2.094,638,3.626,655,4.075,663,3.227,673,2.847,697,3.083,721,3.391,723,6.358,730,4.607,734,5.447,735,3.758,738,3.614,739,3.149,740,6.337,838,3.391,870,6.302,871,4.549,872,4.549,873,4.549,874,8.251,875,8.251,876,4.549,877,8.251,878,4.549,879,4.854,880,5.937,881,4.181,882,4.549,883,3.939,884,4.549,885,6.856,886,4.549,887,4.549,888,6.856,889,3.614,890,4.181,891,4.181,892,3.614,893,4.549,894,4.549,895,4.549,896,4.181,897,3.939,898,4.549,899,4.549,900,4.549,901,4.549]],["t/179",[6,0.078,110,1.033,374,0.939,399,2.373,582,4.832,638,4.028,723,5.272,724,6.969,732,5.849,751,7.116]],["t/182",[6,0.077,159,4.116,168,2.717,169,4.027,170,2.43,185,2.275,187,4.703,200,3.059,214,2.464,226,4.808,236,2.534,240,6.458,286,3.137,288,4.56,327,3.6,344,2.675,424,3.334,428,3.905,514,6.855,590,3.433,622,2.275,624,4.137,663,2.917,677,4.264,698,6.458,727,3.83,839,4.027,870,6.855,902,7.457,903,6.855,904,5.728,905,3.985,906,4.116]],["t/185",[6,0.073,57,4.283,150,3.904,200,3.88,201,4.859,202,5.281,582,4.645,653,8.696,655,5.623,679,6.865,723,6.549,907,9.461,908,5.548,909,5.967,910,8.696,911,8.696]],["t/187",[6,0.076,702,8.742,738,8.976,739,7.821,880,9.784,881,8.742,912,9.511,913,7.305,914,9.511]],["t/189",[6,0.077,150,3.532,165,4.355,219,3.406,232,3.532,344,3.071,741,7.412,890,9.741,891,7.868,915,8.559,916,8.559,917,7.868,918,7.868,919,6.574,920,8.559,921,9.178,922,8.559,923,8.559,924,7.412,925,8.559,926,8.559]],["t/191",[6,0.076,195,4.926,300,6.064,593,6.095,656,7.251,724,5.947,740,8.767,892,8.322,913,6.451,927,10.474,928,6.834,929,4.689,930,9.628,931,7.72,932,9.07,933,4.585,934,7.72,935,7.72,936,7.72,937,5.48,938,6.261]],["t/193",[6,0.077,150,3.499,195,4.972,200,3.477,316,3.817,425,3.933,582,4.162,678,3.79,723,5.869,735,7.005,736,6.736,933,3.711,939,8.478,940,8.478,941,7.854,942,5.869,943,8.478,944,7.342,945,7.005,946,8.478,947,7.793]],["t/195",[6,0.074,234,8.932,425,4.507,436,3.383,736,9.09,945,8.028,947,8.932,948,9.717,949,9.717,950,9.717]],["t/197",[6,0.077,150,3.691,200,3.668,679,6.489,723,6.191,724,6.332,737,6.666,892,7.105,896,8.22,951,5.835,952,6.666,953,8.943,954,8.22]],["t/199",[6,0.076,195,5.193,200,3.632,300,5.126,593,6.425,697,6.002,740,8.976,892,7.035,897,9.371,929,4.943,930,8.139,931,8.139,932,7.668,933,3.876,934,8.139,935,8.139,955,8.854]],["t/201",[6,0.076,49,5.642,187,5.904,655,5.564,677,5.353,737,6.979,740,8.597,880,8.108,892,9.512,897,8.108]],["t/203",[6,0.078,32,4.967,110,1.384,200,3.693,201,3.418,207,1.498,348,6.543,399,2.806,573,3.888,590,3.064,638,3.52,737,4.962,750,7.98]],["t/205",[6,0.078,98,2.909,110,1.31,176,2.55,200,3.033,227,5.681,247,6.192,309,6.405,374,1.19,399,2.305,679,5.367,727,6.346,737,5.513,840,6.546,841,6.798,842,4.826,843,7.418]],["t/207",[6,0.077,80,4.048,326,3.798,374,1.539,575,2.981,956,7.668]],["t/209",[6,0.077,110,1.238,326,3.914,374,1.125,582,4.479,686,4.642,721,6.802,723,7.629,751,5.954]],["t/211",[6,0.074,957,10.272,958,10.272]],["t/213",[6,0.078,110,1.216,150,2.727,160,2.003,193,1.243,246,3.927,268,4.046,306,3.927,347,2.815,374,0.814,422,2.761,431,1.849,505,3.331,513,2.193,540,5.249,541,3.361,589,2.768,742,5.034,959,3.949,960,3.606,961,4.867,962,10.018,963,3.019,964,2.892,965,5.722,966,2.526,967,2.661,968,6.891,969,4.311,970,6.607]],["t/215",[6,0.078,12,3.513,49,1.512,83,1.042,98,2.562,101,1.993,110,1.144,143,1.471,149,0.981,150,1.035,160,1.283,185,0.765,193,1.669,199,1.004,204,1.131,207,1.64,208,1.383,219,0.999,246,3.288,268,3.661,306,3.871,317,3.106,327,1.211,344,0.9,347,2.357,374,0.682,377,1.13,401,0.857,420,1.105,422,1.049,431,0.702,494,1.277,513,0.833,520,0.891,565,1.164,575,0.845,582,2.087,645,1.211,648,2.173,656,1.737,742,2.105,959,2.87,961,4.038,962,2.306,964,3.465,966,2.115,968,2.882,969,1.637,971,1.737,972,1.434,973,3.085,974,3.863,975,3.863,976,3.682,977,1.668,978,2.306,979,1.327,980,2.943,981,2.509,982,2.509,983,2.509,984,2.509,985,4.331,986,1.993,987,1.701,988,0.914,989,0.775,990,3.01,991,3.513,992,1.182,993,1.582,994,1.637,995,1.13,996,2.073,997,2.073,998,0.987,999,1.668,1000,2.306,1001,2.509,1002,2.173,1003,2.173,1004,4.251,1005,4.251,1006,1.558,1007,2.509,1008,2.509,1009,2.509,1010,2.509,1011,2.509,1012,2.509,1013,2.509,1014,2.509,1015,1.701,1016,2.509,1017,2.073,1018,2.509,1019,2.509,1020,2.509,1021,2.509,1022,5.532,1023,2.509,1024,2.509]],["t/217",[6,0.074,1025,10.331]],["t/219",[6,0.078,150,2.932,153,1.793,185,2.167,207,1.598,208,1.063,375,5.315,436,2.473,532,2.391,533,2.315,589,3.258,742,4.657,743,2.485,748,3.401,1026,6.966,1027,5.755]],["t/221",[6,0.078,57,3.288,149,2.844,160,0.97,193,0.926,199,1.971,201,2.528,202,2.748,204,1.006,219,1.959,313,4.525,317,1.812,354,2.482,359,3.54,375,5.377,431,1.377,436,3.011,494,2.505,542,4.067,567,3.486,582,2.417,584,3.348,589,2.247,590,3.348,591,3.348,592,2.861,663,1.925,686,2.505,721,3.67,730,3.399,742,3.601,743,3.342,748,4.14,838,3.67,959,2.17,993,4.586,1026,5.368,1027,5.562,1028,3.212,1029,4.525,1030,4.525,1031,4.067,1032,2.781]],["t/225",[6,0.077,32,3.956,57,2.183,98,2.258,150,2.369,159,3.169,160,1.859,165,2.921,167,1.96,170,1.871,200,3.334,201,4.174,202,3.205,317,3.474,359,2.795,375,5.173,398,1.581,401,2.775,420,1.493,428,2.775,436,3.77,520,2.887,539,4.166,564,6.243,567,4.065,589,3.346,590,2.643,622,1.751,624,3.463,663,2.245,676,3.205,743,2.009,748,4.912,818,3.134,838,4.28,965,4.972,993,3.621,1026,6.37,1027,4.437,1028,3.746,1031,4.744,1033,5.741,1034,5.277,1035,3.974,1036,2.818,1037,3.46,1038,4.41,1039,4.744,1040,4.744,1041,2.233]],["t/227",[6,0.078,160,1.051,170,2.512,193,1.003,200,2.187,202,2.977,204,1.09,226,2.64,231,3.182,236,2.62,237,5.459,317,3.652,359,2.595,375,4.565,399,1.662,411,3.479,428,1.821,431,1.492,481,3.012,494,3.922,567,5.459,580,3.544,589,1.647,622,2.351,645,2.574,663,3.015,676,2.977,730,4.233,742,2.64,743,1.866,748,5.039,767,4.618,959,2.35,993,5.71,1026,3.31,1027,6.322,1032,3.012,1034,7.086,1037,3.213,1042,5.332,1043,5.332,1044,4.618,1045,5.332,1046,5.332,1047,4.901,1048,4.236,1049,5.332,1050,4.901,1051,5.332,1052,5.332,1053,5.332,1054,5.332,1055,3.048,1056,5.332,1057,5.332,1058,5.332,1059,5.332,1060,3.869]],["t/230",[6,0.078,57,2.569,80,2.527,148,7.053,158,2.751,168,3.078,169,3.648,170,2.202,176,2.329,190,3.289,200,2.771,212,2.541,317,3.349,375,3.406,399,3.428,435,3.209,494,3.437,564,6.986,582,4.465,663,3.557,665,5.189,676,3.772,730,3.158,748,3.235,1027,4.964,1061,6.756]],["t/232",[6,0.078,32,4.893,153,1.631,167,3.014,256,2.702,375,3.259,377,3.974,389,4.475,399,2.751,406,5.341,420,1.681,421,9.239,428,2.207,436,3.499,589,1.997,624,2.755,663,2.528,708,3.491,727,5.162,743,2.262,748,5.171,818,3.528,838,4.819,1027,5.895,1062,7.644,1063,5.341,1064,3.742]],["t/234",[6,0.078,32,4.473,102,4.55,167,2.342,168,1.919,170,2.235,173,4.326,216,3.971,236,2.331,262,3.258,375,5.223,385,2.831,388,4.398,420,2.389,436,2.388,439,3.557,440,3.744,538,5.94,589,3.419,595,2.867,624,2.923,742,3.397,748,3.284,818,3.744,941,5.113,1060,4.978,1065,7.057,1066,10.173,1067,5.45,1068,5.94]],["t/236",[6,0.077,32,3.276,57,2.559,98,2.648,374,0.83,375,3.393,398,1.854,428,3.098,430,3.802,436,3.158,584,3.099,589,2.803,590,3.099,622,2.767,624,3.866,628,4.392,631,5.867,639,3.031,660,6.28,722,4.563,728,4,748,4.913,1026,4.178,1069,6.03,1070,6.731,1071,6.731,1072,6.731,1073,6.731,1074,6.731,1075,6.731,1076,6.731,1077,5.17,1078,4.178,1079,4.474,1080,5.561,1081,4.766,1082,5.17,1083,6.731,1084,6.731]],["t/239",[6,0.077,169,5.465,344,3.631,375,4.009,428,2.715,513,3.359,557,6.108,564,6.108,589,2.457,624,3.389,663,3.11,1026,4.937,1027,4.341,1055,4.547,1062,6.887,1085,7.953,1086,5.391,1087,6.108,1088,7.31,1089,7.953,1090,6.887,1091,6.571]],["t/242",[6,0.076,57,4.115,431,2.478,566,7.668,584,5.604,590,4.076,655,5.263,739,6.129,742,4.385,1031,8.941,1092,8.139,1093,9.947,1094,8.139,1095,8.854,1096,8.854,1097,8.854,1098,8.854]],["t/244",[6,0.078,101,6.979,159,3.542,160,1.731,185,1.958,204,1.796,207,1.444,208,0.961,222,5.54,236,2.181,240,5.558,286,2.7,288,3.924,319,2.955,595,3.671,637,5.731,639,2.89,904,4.93,921,8.672,1099,6.418,1100,6.418,1101,4.115,1102,8.784,1103,8.074,1104,5.9,1105,6.418,1106,5.099,1107,4.93]],["t/246",[6,0.078,10,3.816,57,3.582,110,0.776,134,5.614,158,1.731,198,4.165,199,2.291,207,1.288,373,2.522,398,1.576,420,1.488,584,3.733,622,1.746,624,2.439,628,3.734,631,3.272,646,8.063,1108,5.26,1109,5.26,1110,3.356,1111,6.385,1112,6.714]],["t/249",[6,0.076,193,1.674,207,2.002,208,1.332,319,4.096,487,3.16,584,4.997,590,4.096,645,4.295,655,6.451,818,4.857,908,5.218,1081,6.301,1092,8.179,1113,6.633,1114,8.179,1115,5.441,1116,6.835]],["t/251",[6,0.077,57,3.27,176,2.965,207,1.935,208,1.287,533,2.802,584,4.893,595,3.594,954,7.905,1026,6.598,1114,7.905,1117,3.07,1118,3.959,1119,8.6]],["t/253",[6,0.078,169,4.886,176,2.312,180,4.3,199,2.685,207,1.509,208,1.004,317,2.469,321,4.163,374,0.826,375,3.38,425,3.111,532,3.691,533,3.573,584,4.166,628,4.375,631,3.834,639,3.019,659,4.041,725,4.1,815,2.956,1026,4.163,1027,3.66,1037,4.041,1117,2.393,1120,5.151,1121,6.746,1122,6.706]],["t/255",[6,0.077,190,4.186,268,3.054,513,2.854,584,3.959,1026,5.339,1032,4.858,1093,7.905,1094,7.905,1116,6.606,1123,8.6,1124,10.629]],["t/258",[6,0.078,742,4.342,743,3.068,748,5.15,1027,5.871]],["t/260",[6,0.077,317,3.166,567,7.526,659,5.183,742,4.259,743,3.009,969,5.612,1027,5.802,1125,7.106]],["t/262",[6,0.078,153,1.981,374,0.967,411,5.121,436,2.732,564,6.028,838,5.851,1026,6.23,1027,5.478,1125,8.292]],["t/265",[6,0.078,10,3.251,168,2.245,170,2.615,428,2.74,433,4.705,439,4.16,440,4.38,624,3.419,1066,10.805,1126,4.769,1127,5.439,1128,4.981,1129,4.201,1130,4.479,1131,5.236]],["t/267",[6,0.078,216,4.666,420,2.096,564,7.839,993,5.083,1026,5.003,1062,10.196,1126,4.79,1127,5.463,1128,5.003,1129,5.344]],["t/269",[6,0.078,159,4.489,193,1.931,207,2.31,208,1.536,374,1.002,431,2.872,480,2.994,743,2.845,1132,5.67,1133,8.133]],["t/271",[6,0.076,57,4.283,199,3.788,584,4.355,967,3.81,1026,5.873,1032,5.344,1110,5.548]],["t/273",[6,0.077,110,1.257,532,3.119,533,3.624,595,3.872,815,4.902,1026,5.752,1134,9.265]],["t/275",[6,0.077,193,2.029,202,4.919,317,3.244,431,3.019,676,6.023,1026,5.47,1027,5.889]],["t/277",[6,0.078,32,4.069,428,2.855,436,2.91,663,3.27,748,4.002,1026,6.483,1027,6.217,1035,5.787]],["t/279",[6,0.078,158,2.601,200,3.527,201,4.417,317,3.166,742,4.259,1026,5.339,1027,4.694,1135,8.6]],["t/281",[6,0.074,1136,10.331]],["t/283",[6,0.077,150,3.297,160,1.574,167,2.728,170,3.307,185,2.437,212,3.005,374,1.251,376,5.309,401,2.728,428,2.728,624,3.404,709,4.459,1137,6.136,1138,6.6,1139,5.122,1140,6.347,1141,5.797,1142,5.415,1143,7.343,1144,6.136]],["t/285",[6,0.078,97,5.192,150,2.697,159,3.607,167,3.036,170,2.129,374,0.805,401,3.036,420,2.821,428,2.231,433,3.832,435,4.223,520,3.59,624,2.785,678,2.921,680,4.524,845,4.871,1078,4.057,1101,4.19,1130,3.648,1138,8.964,1139,5.702,1145,5.192,1146,4.524,1147,6.535,1148,6.535,1149,6.535,1150,5.659]],["t/287",[6,0.078,143,3.378,149,2.253,159,3.179,160,1.605,167,3.843,170,2.655,236,1.957,300,3.334,337,4.078,374,1.004,376,5.415,377,3.668,401,3.227,420,2.118,432,2.735,433,3.378,435,3.869,436,2.005,495,4.759,520,2.893,534,4.35,589,2.517,591,2.651,592,2.266,601,5.294,733,4.759,972,3.293,1039,4.759,1082,4.424,1112,5.057,1137,4.424,1138,4.759,1139,5.223,1151,5.759,1152,8.146,1153,8.146,1154,5.759,1155,3.423,1156,3.904,1157,5.294,1158,3.179,1159,4.842,1160,6.073]],["t/289",[6,0.077,160,1.878,167,2.474,168,2.028,170,2.361,377,3.263,401,3.862,420,1.884,428,3.636,440,3.956,520,2.574,534,4.034,539,5.259,624,4.537,709,4.046,995,3.263,1035,5.017,1137,5.566,1146,7.371,1161,6.661,1162,5.876,1163,6.661,1164,7.247,1165,7.247,1166,7.247,1167,7.247,1168,7.247,1169,5.566,1170,4.307,1171,4.817]],["t/292",[6,0.077,149,2.893,165,3.763,167,2.525,168,3.545,354,5.962,377,3.33,399,2.305,428,2.525,432,3.512,435,3.512,436,2.575,439,5.007,440,5.87,520,2.627,1069,4.916,1169,5.681,1170,4.396,1171,4.916,1172,6.798,1173,6.798,1174,4.826,1175,7.396,1176,7.396,1177,7.396,1178,3.728,1179,7.396,1180,6.798]],["t/294",[6,0.077,165,3.544,167,3.17,168,3.338,354,5.263,377,3.136,399,2.171,428,3.565,432,3.308,435,5.288,436,2.425,439,3.612,440,3.802,520,3.297,573,3.008,624,3.956,1063,5.755,1169,8.02,1172,6.403,1173,6.403,1181,3.889,1182,6.403,1183,5.35,1184,6.403,1185,5.952]],["t/296",[6,0.077,167,2.965,236,3.633,256,5.053,385,4.413,394,6.011,422,3.629,520,3.797,708,6.256,727,5.491,1186,6.899,1187,7.982]],["t/298",[6,0.078,114,2.856,147,3.448,149,1.904,167,4.006,168,1.363,185,1.485,212,1.832,219,3.42,236,1.655,239,3.74,252,3.63,256,4.239,318,4.994,344,1.747,347,3.074,385,3.921,420,1.266,433,2.856,436,1.695,485,2.55,520,1.729,639,2.192,708,4.64,727,4.413,849,4.341,1069,3.237,1117,1.738,1162,6.232,1174,3.177,1178,3.637,1187,4.476,1188,7.995,1189,8.733,1190,4.476,1191,4.869,1192,3.74,1193,3.534,1194,4.869,1195,4.869,1196,4.869,1197,4.869,1198,4.64,1199,4.869,1200,7.214,1201,4.869,1202,3.448,1203,4.869,1204,4.217]],["t/300",[6,0.077,102,5.2,153,1.338,167,3.585,168,1.483,185,1.617,204,1.084,212,3.394,231,3.724,256,4.135,262,2.517,385,3.168,432,5.199,435,2.517,436,1.845,520,1.882,534,2.244,708,4.873,727,4.635,1063,4.38,1117,1.892,1162,2.926,1178,2.672,1189,7.056,1190,7.056,1205,5.301,1206,5.435,1207,5.301,1208,4.59,1209,4.38,1210,4.872,1211,3.951,1212,5.301,1213,5.301,1214,5.301,1215,4.872,1216,5.301,1217,5.301,1218,4.872,1219,5.301,1220,5.301,1221,5.301,1222,5.301,1223,5.301,1224,5.301,1225,2.625,1226,5.301,1227,9.024,1228,7.676,1229,5.301,1230,5.301,1231,5.301,1232,5.301,1233,5.301,1234,5.301,1235,5.301,1236,4.872,1237,5.301,1238,5.301]],["t/302",[6,0.078,167,3.974,168,3.182,170,1.769,185,1.656,219,2.161,256,3.264,318,3.758,377,4.504,401,3.123,420,1.412,428,3.883,432,2.578,435,3.709,436,1.89,520,2.774,539,3.939,573,2.344,624,4.846,708,4.217,727,4.011,1035,3.758,1063,7.558,1117,1.938,1158,2.996,1162,2.996,1188,3.844,1239,5.429,1240,5.429,1241,5.429,1242,3.104,1243,5.429,1244,3.844,1245,5.429]],["t/304",[6,0.077,10,2.878,148,4.555,149,2.778,167,2.425,168,2.95,170,3.065,204,1.452,214,2.347,241,5.869,262,4.466,354,3.581,384,3.757,420,1.847,428,2.425,435,3.373,440,3.877,520,2.523,624,3.027,1067,5.644,1069,4.722,1171,4.722,1174,4.635,1180,6.53,1181,5.25,1246,7.103,1247,7.103,1248,7.103,1249,7.103,1250,7.103,1251,7.103,1252,7.103,1253,7.103,1254,6.152,1255,7.103,1256,7.103]],["t/306",[6,0.077,153,2.533,160,1.546,168,2.808,170,3.27,236,3.41,262,4.766,318,6.947,385,3.239,398,2.764,399,3.448,401,2.68,420,2.041,422,3.28,431,2.196,481,4.433,520,2.787,624,3.344,722,5.32,849,3.586,1137,6.028,1181,4.381,1257,7.214,1258,5.851,1259,7.848]],["t/308",[2,3.3,6,0.078,148,3.46,153,1.962,158,1.632,167,1.843,214,1.783,249,4.023,262,2.563,333,4.56,385,2.227,399,1.682,401,3.113,410,3.085,428,3.761,435,5.231,485,2.825,512,1.86,624,2.299,1160,4.023,1169,4.145,1178,2.72,1184,4.96,1185,3.46,1257,4.96,1260,5.396,1261,7.776,1262,7.776,1263,5.396,1264,7.776,1265,7.776,1266,5.396,1267,5.396,1268,5.396,1269,5.396,1270,5.396,1271,5.396,1272,5.396,1273,5.396,1274,5.396]],["t/310",[1,2.566,2,4.832,6,0.078,10,1.394,97,6.278,148,5.919,149,3.09,167,3.55,168,3.154,212,1.295,214,1.137,241,4.559,247,3.538,374,0.68,377,4.156,392,2.498,401,3.55,410,3.949,420,2.055,423,2.171,428,1.175,432,2.621,433,2.018,435,4.108,485,1.802,486,3.718,512,1.187,520,2.806,534,2.336,624,1.467,700,4.559,709,1.921,793,2.105,839,1.858,842,2.246,993,2.171,1069,3.668,1137,4.239,1146,2.383,1160,5.891,1161,3.164,1162,3.046,1163,3.164,1170,2.046,1174,2.246,1178,1.735,1181,3.081,1275,2.566,1276,3.442,1277,3.442,1278,3.442,1279,2.981,1280,3.442,1281,6.907,1282,7.09,1283,3.442,1284,4.559,1285,5.518,1286,2.844,1287,2.074,1288,3.442,1289,3.442,1290,3.442,1291,3.442,1292,3.442,1293,3.442,1294,3.442,1295,3.442,1296,3.442,1297,2.735,1298,3.442,1299,3.442,1300,3.442,1301,3.442,1302,2.566]],["t/313",[6,0.077,164,3.693,193,1.403,398,3.15,401,2.546,428,2.546,476,3.3,486,3.003,487,3.448,623,5.135,718,5.83,972,5.551,1140,5.925,1141,7.046,1303,7.457,1304,8.293,1305,5.925,1306,6.855,1307,7.457,1308,4.137,1309,7.238,1310,6.855,1311,7.457,1312,3.407,1313,5.055,1314,9.71]],["t/315",[6,0.077,159,4.985,230,5.427,314,7.463,678,4.038,680,6.253,688,7.822,1107,6.938,1150,7.822,1315,6.733,1316,9.032,1317,7.463]],["t/317",[6,0.077,153,2.512,193,1.457,230,5.341,254,4.765,262,3.679,286,3.258,287,5.775,326,3.323,340,6.401,522,5.775,1318,7.747,1319,7.121,1320,7.747,1321,7.747,1322,7.747,1323,7.747,1324,7.747,1325,7.747,1326,7.747,1327,6.401,1328,7.747,1329,7.747,1330,7.747,1331,7.747,1332,7.747,1333,7.747,1334,7.747,1335,7.747,1336,5.485,1337,7.747,1338,7.747]],["t/319",[6,0.077,41,4.233,160,1.494,165,3.858,168,2.122,193,1.846,195,4.447,253,7.378,256,3.169,317,3.614,354,3.823,399,3.059,420,1.972,428,2.589,435,3.601,439,3.932,513,2.517,520,2.693,545,8.11,624,3.231,933,3.319,1144,5.825,1169,5.825,1339,6.971,1340,6.971,1341,7.583,1342,7.583,1343,7.583]],["t/322",[6,0.078,10,2.148,80,1.983,150,3.168,159,4.981,160,2.225,170,2.501,176,1.827,185,2.341,212,2.887,253,3.593,254,2.538,326,2.274,348,3.399,374,1.112,420,1.378,486,3.091,512,2.647,513,2.548,646,3.951,664,4.502,677,3.03,678,2.369,686,2.697,709,2.959,1140,6.099,1141,5.57,1143,4.872,1144,6.932,1150,4.59,1304,5.896,1305,4.211,1309,3.951,1317,4.38,1339,4.872,1340,4.872,1344,7.005,1345,4.59,1346,5.301,1347,5.301,1348,4.872,1349,5.301,1350,5.301,1351,4.38,1352,4.872,1353,4.211]],["t/324",[6,0.078,153,1.58,160,1.234,167,3.639,170,2.04,198,3.216,212,2.355,249,4.668,253,4.244,256,2.617,287,4.668,399,1.951,411,4.086,428,2.138,432,4.695,435,2.974,513,2.078,646,4.668,659,3.774,664,3.672,708,4.663,842,4.086,909,3.949,988,3.146,1032,3.537,1144,4.809,1178,3.157,1188,4.434,1304,4.809,1305,4.975,1354,6.261,1355,3.216,1356,4.335,1357,6.261,1358,6.261]],["t/326",[6,0.078,150,2.054,153,1.85,160,1.715,167,1.7,168,1.393,170,2.836,176,1.716,191,2.164,193,0.936,198,3.765,208,0.745,253,3.374,254,2.383,268,1.768,347,2.121,374,1.183,398,2.019,401,3.279,420,1.294,439,2.581,486,2.005,494,2.532,510,2.846,513,1.652,520,2.604,540,6.915,541,4.428,575,2.468,623,3.878,646,5.465,669,4.575,694,4.31,700,4.113,909,3.139,972,4.192,988,3.171,1138,6.058,1202,3.524,1304,3.823,1305,3.955,1359,4.575,1360,3.524,1361,4.977,1362,4.575,1363,4.575,1364,8.704,1365,6.739,1366,4.977,1367,4.977,1368,4.977,1369,3.823,1370,4.977,1371,3.955,1372,4.977,1373,4.575,1374,3.446,1375,4.31,1376,3.71,1377,4.977,1378,4.977,1379,4.977,1380,4.977]],["t/328",[6,0.077,148,5.122,150,3.297,160,1.574,167,3.465,168,2.84,170,3.307,374,1.251,401,2.728,428,2.728,432,3.794,436,2.781,624,3.404,1137,6.136,1140,8.063,1141,7.365,1160,7.565,1304,7.795,1305,6.347,1309,5.955,1374,7.025]],["t/330",[167,3.611,590,4.868]],["t/332",[6,0.074,1381,10.331]],["t/334",[6,0.078,57,2.278,67,6.077,110,1.547,153,2.877,155,2.501,160,1.18,180,3.841,374,0.738,375,3.02,383,2.253,476,2.036,480,2.205,532,2.016,533,3.407,587,4.06,589,1.851,590,2.758,622,1.827,678,3.743,1028,3.909,1055,5.977,1081,5.93,1118,2.758,1382,5.99,1383,4.465,1384,5.99,1385,4.759,1386,5.329,1387,6.243,1388,5.99,1389,5.93,1390,6.684,1391,5.99]],["t/336",[6,0.078,32,1.545,57,3.383,67,4.745,110,1.574,153,1.304,155,2.149,193,1.23,199,1.271,317,3.453,326,1.361,374,0.929,377,2.944,383,2.459,425,1.472,428,1.765,476,2.222,480,2.407,485,2.706,487,1.836,532,1.068,533,2.131,534,3.766,541,2.63,542,2.623,590,1.461,622,1.577,638,1.679,645,1.532,678,2.311,708,1.714,712,3.65,718,1.714,727,1.63,742,1.572,743,1.111,933,1.389,977,6.234,995,1.429,1028,3.373,1036,2.538,1055,5.943,1081,5.337,1120,2.438,1129,1.662,1159,1.887,1369,2.438,1385,2.522,1386,4.16,1387,4.874,1389,2.248,1390,4.526,1392,2.749,1393,2.071,1394,2.623,1395,2.197,1396,5.195,1397,5.402,1398,1.22,1399,2.522,1400,2.918,1401,2.623,1402,2.918,1403,4.107,1404,3.174,1405,2.197,1406,2.366,1407,3.174]],["t/339",[6,0.077,57,3.718,153,2.148,158,1.855,169,3.312,170,2.774,176,2.115,187,3.868,193,1.154,200,2.516,201,3.15,202,3.424,207,1.38,214,2.026,221,3.037,375,4.929,399,1.912,428,3.607,431,1.716,436,2.135,517,3.597,534,3.604,542,5.068,584,2.823,589,1.895,590,2.823,622,3.503,663,2.399,676,3.424,687,3.597,734,4.873,748,2.936,761,4.343,1028,4.002,1030,5.638,1055,4.867,1081,6.028,1159,5.06,1383,4.572,1392,5.311,1393,4.002,1408,6.133,1409,6.133,1410,6.133,1411,6.133,1412,6.133,1413,6.133,1414,6.133,1415,4.246,1416,6.133]],["t/341",[6,0.078,32,4.339,57,2.494,67,4.759,110,1.59,149,2.565,153,1.655,155,2.815,236,2.229,268,2.329,286,2.759,317,2.415,373,2.891,399,2.778,425,3.042,476,3.029,487,3.166,532,2.208,533,2.137,622,2.001,638,3.469,663,2.565,708,3.542,727,3.368,995,2.953,1055,5.097,1081,6.312,1120,5.038,1128,4.071,1385,5.211,1386,3.62,1387,4.889,1390,4.54,1395,4.54,1401,5.419,1417,6.559]],["t/343",[6,0.077,57,3.822,110,1.364,153,1.631,168,1.809,193,2.031,199,2.588,200,2.651,201,3.32,202,3.609,268,3.135,317,3.701,377,4.863,428,2.207,476,2.197,487,3.135,534,3.737,540,5.136,541,3.289,622,2.692,663,2.528,673,3.666,676,3.609,711,5.942,977,6.681,995,3.974,1028,5.76,1081,4.577,1390,6.11,1415,4.475,1418,6.464,1419,6.464,1420,5.341,1421,6.464]],["t/345",[6,0.077,57,3.318,110,1.455,193,1.641,317,3.212,377,3.929,383,3.282,476,3.644,487,3.099,534,3.694,541,4.439,638,4.615,977,5.8,1386,4.816,1390,7.424,1422,8.725]],["t/347",[6,0.078,57,2.406,98,2.489,110,1.522,185,1.93,191,2.751,286,2.661,317,3.941,476,2.15,485,3.313,487,2.247,534,4.531,645,3.054,663,2.475,712,3.532,933,3.808,968,5.896,977,7.115,1036,3.106,1055,4.973,1081,6.159,1129,3.313,1369,6.681,1387,4.717,1390,4.38,1396,5.027,1397,5.228,1403,5.027,1423,5.816]],["t/350",[6,0.078,32,2.777,57,2.169,110,0.774,191,2.48,204,1.166,332,3.949,399,1.778,410,4.626,415,7.222,425,3.753,428,3.21,476,1.939,481,3.222,487,2.026,534,2.415,590,2.626,622,1.74,718,3.08,929,3.185,1055,6.176,1120,4.382,1185,3.658,1306,5.244,1395,3.949,1424,5.705,1425,5.705,1426,8.091,1427,5.705,1428,5.705,1429,3.658,1430,5.244,1431,5.705,1432,4.94,1433,7.007,1434,7.437,1435,8.142,1436,5.244,1437,5.705,1438,5.705,1439,4.382,1440,4.94,1441,5.705,1442,5.705,1443,5.705,1444,5.705,1445,5.705,1446,5.705,1447,5.705]],["t/352",[6,0.078,57,1.919,153,1.274,158,1.527,176,1.74,185,2.259,193,1.393,214,2.447,268,1.793,287,3.763,317,2.727,374,0.622,377,3.335,383,1.898,476,2.517,480,1.858,485,2.643,487,3.116,540,4.01,541,2.568,645,4.666,663,2.897,712,4.135,742,2.499,933,3.242,968,3.421,977,6.425,1028,3.293,1036,2.478,1055,5.527,1369,6.74,1403,6.972,1448,5.047,1449,5.047,1450,5.047,1451,3.421,1452,7.407,1453,5.047,1454,5.047]],["t/354",[6,0.078,80,2.392,110,0.868,160,1.969,169,5.397,185,1.951,187,6.781,214,2.113,268,2.271,317,3.959,534,2.707,556,5.538,557,4.912,590,2.944,677,3.656,712,3.57,977,7.147,1055,6.147,1090,5.538,1142,4.335,1389,4.528,1429,4.101,1455,5.538,1456,5.879,1457,6.395,1458,6.395,1459,5.358,1460,6.395,1461,6.395,1462,6.395,1463,6.395,1464,8.762]],["t/356",[6,0.077,110,1.661,153,1.93,268,2.716,317,2.816,383,2.877,476,2.599,487,2.716,534,3.238,638,4.045,742,3.787,743,2.676,995,3.444,1055,4.372,1120,5.874,1385,6.076,1386,4.221,1387,7.358,1390,5.294,1395,5.294,1396,6.076,1397,6.319]],["t/358",[6,0.078,32,2.133,57,3.427,110,1.315,176,1.511,185,1.337,193,0.824,204,1.363,231,2.751,236,1.489,239,3.366,268,1.556,317,2.969,319,2.017,321,2.72,330,3.366,333,2.57,375,2.209,383,1.648,399,2.514,410,3.811,411,2.859,415,6.922,423,2.764,425,4.497,428,3.486,476,1.489,487,1.556,534,3.815,590,2.017,622,2.749,635,2.419,639,1.973,712,2.446,743,1.533,818,2.392,831,2.913,906,2.419,941,3.267,977,5.361,995,1.973,996,3.621,997,3.621,1055,5.152,1113,3.267,1129,3.49,1193,4.837,1312,3.045,1429,2.81,1430,4.028,1432,3.795,1433,5.772,1434,6.126,1435,6.985,1436,4.028,1439,3.366,1465,4.382,1466,6.665,1467,4.382,1468,4.382,1469,3.18,1470,4.382,1471,4.969,1472,4.382,1473,4.382,1474,4.382,1475,4.382,1476,4.382,1477,4.382,1478,4.382,1479,4.382,1480,4.382,1481,4.028,1482,4.028,1483,4.028,1484,6.665,1485,6.665,1486,4.382,1487,4.382,1488,4.382,1489,4.382]],["t/360",[6,0.077,32,3.995,57,4.295,110,1.114,176,2.83,399,2.558,425,3.807,428,3.525,476,2.789,487,2.915,534,3.474,590,3.778,622,2.503,908,4.813,1055,5.902,1193,5.956,1481,7.544,1482,7.544,1483,7.544,1490,8.207]],["t/362",[6,0.078,110,1.611,191,3.584,383,3.101,436,2.87,534,4.791,839,4.452,1055,4.714,1118,3.795,1491,4.405]],["t/366",[6,0.078,80,2.7,169,5.738,187,6.702,317,3.499,375,4.791,428,2.464,556,6.25,557,5.544,677,5.434,712,4.029,977,6.317,1055,6.456,1090,6.25,1390,7.818,1455,6.25,1456,6.634,1492,7.218,1493,7.218]],["t/368",[6,0.077,110,1.674,180,6.453,191,3.427,317,3.705,534,3.337,645,3.805,906,4.351,977,6.689,1036,3.87,1055,5.753,1120,6.055,1369,6.055,1386,4.351,1395,5.457,1396,6.263,1397,6.513,1494,5.144]],["t/370",[6,0.076,110,1.504,158,2.788,486,3.712,534,4.694,595,3.852,906,5.088,1495,7.08,1496,7.983,1497,9.218,1498,9.218]],["t/372",[10,3.874,80,3.577,153,2.413,164,4.735,173,6.03,179,6.402,254,4.578,288,5.847,292,6.619,295,8.705,332,6.619,529,8.28,677,5.467,905,5.109,1499,9.561,1500,9.561,1501,8.789,1502,5.683]],["t/374",[6,0.056,57,3.715,180,6.264,199,3.911,308,6.622,487,3.47,501,8.98,1503,9.769,1504,9.769,1505,9.769,1506,9.769,1507,9.769,1508,9.769,1509,9.769,1510,9.769,1511,9.769]],["t/376",[6,0.077,67,7.046,110,1.317,154,3.021,155,2.515,187,4.703,212,2.805,214,2.464,308,5.055,317,2.746,533,2.43,541,3.794,677,4.264,678,3.334,709,4.163,977,4.957,1055,6.539,1118,3.433,1386,5.359,1387,7.238,1390,5.162,1512,6.855,1513,7.457,1514,7.457]],["t/378",[6,0.076,67,6.621,110,1.495,153,2.303,155,2.855,383,3.432,541,4.642,1055,6.301,1118,4.2,1386,5.036,1387,6.802,1389,6.461,1390,6.316]],["t/380",[6,0.074,1515,10.214,1516,9.389,1517,10.214]],["t/382",[6,0.077,110,1.314,150,3.065,158,2.929,230,3.419,342,4.61,374,0.915,673,3.084,678,3.32,1146,5.141,1312,3.393,1398,3.723,1518,7.219,1519,7.438,1520,4.684,1521,5.705,1522,7.426,1523,5.389,1524,5.536,1525,5.141,1526,7.426,1527,6.431,1528,3.744,1529,4.61,1530,4.246,1531,4.762,1532,5.389,1533,5.389,1534,2.991]],["t/384",[6,0.078,83,1.785,110,1.475,150,1.774,153,1.085,160,1.294,193,0.808,212,1.617,230,1.979,246,2.555,342,2.668,374,1.185,420,2.072,517,3.851,520,2.83,532,3.236,533,2.597,592,1.691,663,1.681,664,3.851,673,3.31,815,1.895,989,2.029,1118,3.023,1146,5.517,1312,1.964,1398,3.065,1518,4.896,1519,5.044,1520,2.711,1521,4.802,1524,5.941,1525,4.546,1528,2.167,1529,2.668,1530,2.457,1531,2.756,1532,3.119,1533,3.119,1535,2.805,1536,4.298,1537,3.951,1538,2.058]],["t/386",[6,0.078,110,1.189,214,2.113,230,4.95,342,3.97,374,1.08,436,3.051,532,2.949,533,2.855,592,2.516,989,1.976,1117,2.283,1146,4.427,1312,2.922,1520,5.526,1521,3.195,1524,4.767,1525,4.427,1528,6.005,1529,3.97,1532,4.641,1535,4.173,1539,4.912]],["t/388",[6,0.076,110,1.264,150,3.844,204,1.904,374,1.375,575,3.135,673,3.868,989,3.447,1521,4.653,1524,6.943,1528,4.695,1531,5.972,1533,6.759]],["t/391",[6,0.074,342,7.827,1312,5.761,1532,8.611,1533,6.655,1540,9.171,1541,9.171,1542,8.43,1543,10.161,1544,7.942]],["t/393",[6,0.073,110,1.333,214,3.245,420,2.554,517,5.761,520,3.489,532,3.307,533,3.201,718,5.304,815,4.33,1117,3.506]],["t/395",[6,0.077,110,1.098,176,2.791,214,2.675,343,6.432,532,3.445,533,3.335,678,4.575,1117,2.89,1118,3.727,1528,5.658,1529,7.321,1542,9.408,1545,5.106,1546,7.442,1547,4.812]],["t/397",[6,0.077,80,3.775,158,2.395,212,2.978,624,3.374,641,5.902,1398,3.044,1529,6.265,1530,4.527,1531,5.077,1534,3.189,1548,7.278,1549,6.857,1550,7.278,1551,4.643,1552,8.739,1553,7.918,1554,6.291,1555,9.276,1556,7.918,1557,6.857,1558,6.291,1559,7.278,1560,7.918,1561,7.918,1562,7.123]],["t/399",[6,0.078,110,1.367,150,2.275,160,1.556,185,1.681,219,2.194,230,2.537,374,0.973,575,1.855,673,2.289,677,4.514,1398,3.036,1528,5.891,1530,5.759,1531,5.063,1533,5.73,1534,2.22,1544,4.773,1552,4.773,1557,4.773,1558,6.273,1563,5.067,1564,2.413,1565,3.422]],["t/401",[6,0.076,110,1.567,1126,5.87,1528,4.979]],["t/403",[6,0.078,80,2.898,110,1.492,230,4.581,342,4.809,487,2.751,1117,2.765,1181,4.325,1528,5.017,1533,5.622,1565,4.809,1566,9.952]],["t/405",[6,0.078,160,1.581,230,3.694,305,4.429,398,2.21,1275,5.981,1520,6.418,1528,5.635,1564,3.512,1567,4.705]],["t/407",[6,0.078,110,1.397,193,1.537,431,2.286,743,2.858,1528,5.965,1564,3.576]],["t/409",[6,0.078,110,1.484,158,1.782,193,1.108,226,4.099,342,3.657,411,3.844,517,3.455,532,1.983,533,1.92,638,5.489,659,3.551,678,2.634,989,1.82,1117,2.955,1312,2.692,1405,6.624,1521,2.944,1524,4.392,1528,6.241,1529,6.443,1532,4.275,1533,6.007,1544,5.102,1552,5.102,1557,5.102,1564,2.579,1568,5.892,1569,5.416]],["t/412",[6,0.078,45,7.377,436,2.966,960,5.768,1344,6.032,1570,7.83,1571,7.83,1572,7.83,1573,6.543,1574,7.83,1575,7.83]],["t/414",[6,0.077,226,4.239,326,3.671,374,1.055,532,3.567,533,3.453,1344,6.06,1528,5.803,1538,5.511,1570,7.868,1571,7.868,1573,6.574,1575,7.868]],["t/416",[6,0.078,110,1.555,374,1.298,517,4.972,1528,5.311,1530,4.847,1531,5.436]],["t/418",[6,0.077,110,1.284,1146,6.549,1360,6.699,1521,4.727,1528,4.769]],["t/420",[6,0.073,374,1.273,1576,9.497]],["t/422",[6,0.077,282,7.463,359,4.397,374,1.113,1577,9.032,1578,7.463,1579,9.032,1580,9.032]],["t/424",[6,0.078,110,1.361,158,2.663,176,2.221,185,1.965,327,3.109,343,5.118,359,3.135,365,4.13,374,1.085,510,3.683,517,3.777,678,2.879,742,3.19,919,4.947,989,1.99,1117,3.143,1210,5.921,1244,4.561,1392,5.578,1528,5.437,1529,3.998,1530,3.683,1531,4.13,1576,5.921,1581,6.441,1582,6.441,1583,6.441,1584,6.441,1585,5.921]],["t/426",[6,0.078,110,1.408,160,1.161,219,3.808,230,2.712,374,1.02,436,2.051,517,3.455,532,1.983,533,1.92,638,3.116,673,2.447,919,6.358,989,1.82,1146,4.079,1282,4.525,1398,3.183,1405,4.079,1521,5.665,1524,4.392,1525,4.079,1528,5.993,1529,5.139,1585,5.416,1586,5.416,1587,5.416]],["t/428",[6,0.077,33,6.209,98,3.074,110,1.498,153,1.972,204,1.598,208,1.169,219,3.11,230,5.082,342,4.851,379,5.671,1312,3.57,1520,4.928,1521,3.904,1528,3.939,1537,7.183,1543,7.183,1569,7.183,1588,6.209,1589,7.814,1590,2.939]],["t/430",[6,0.077,110,1.108,160,1.61,219,4.097,374,1.007,919,6.275,989,3.181,1146,5.656,1521,5.911,1525,5.656,1528,5.682,1586,7.51,1591,8.17]],["t/432",[6,0.074,1592,10.156,1593,10.156,1594,8.069,1595,10.156]],["t/434",[6,0.078,110,1.057,160,1.066,193,1.018,268,1.922,344,1.942,374,1.125,506,5.18,532,1.822,533,3.255,578,4.472,589,1.672,590,2.492,591,3.587,592,3.065,595,3.816,673,2.248,686,2.754,748,2.591,749,2.437,1110,6.208,1112,7.219,1116,4.157,1121,4.035,1398,4.554,1529,3.36,1596,4.975,1597,6.439,1598,4.3,1599,5.986,1600,3.669,1601,4.472,1602,4.472,1603,4.975,1604,4.3,1605,4.472,1606,5.412]],["t/436",[6,0.078,57,2.911,98,1.076,110,0.371,160,1.508,193,1.108,221,1.354,373,1.205,374,1.179,375,4.171,428,1.561,440,1.493,506,1.817,532,1.982,533,3.218,534,1.158,584,1.259,589,2.845,590,1.259,591,3.167,592,1.798,595,3.848,622,0.834,638,1.446,673,2.445,684,2.1,685,2.172,742,1.354,743,0.957,748,3.294,749,1.231,908,1.604,929,1.526,963,1.249,1087,2.1,1110,6.411,1112,6.13,1116,2.1,1118,1.259,1121,3.407,1159,1.625,1398,4.14,1406,2.038,1539,4.523,1597,7.257,1599,6.355,1600,3.098,1601,3.776,1604,2.172,1607,2.734,1608,2.259,1609,2.259,1610,3.631,1611,4.743,1612,2.172,1613,2.734,1614,1.984,1615,2.734]],["t/439",[6,0.078,57,2.984,591,4.62,592,3.087,622,2.394,663,3.07,673,3.259,743,2.746,1110,6.488,1598,6.236,1616,7.848,1617,6.485]],["t/441",[6,0.077,110,0.991,268,2.595,374,1.181,398,2.639,415,5.611,420,1.9,436,2.543,476,3.256,589,2.257,634,3.988,660,5.057,663,2.857,748,3.498,1110,5.618,1398,4.363,1618,7.306,1619,5.804,1620,7.306,1621,7.306,1622,7.306,1623,7.306,1624,5.611,1625,7.306,1626,7.306,1627,4.535,1628,7.306]],["t/443",[6,0.078,153,1.731,160,1.81,167,2.342,168,1.919,399,2.138,428,2.342,532,2.309,533,2.235,589,2.839,590,5.095,673,3.816,712,3.829,748,3.284,749,3.088,818,5.015,963,3.134,1037,4.134,1121,5.113,1159,6.158,1398,4.255,1598,5.45,1629,5.94,1630,5.667]],["t/445",[6,0.078,57,2.628,532,2.327,533,3.389,534,3.91,584,4.252,591,3.182,595,3.86,663,2.703,712,3.859,815,4.584,963,3.158,1398,3.551,1520,4.359,1529,6.456,1610,5.492,1611,3.732,1631,5.986,1632,6.912]],["t/447",[6,0.078,57,3.294,110,0.67,374,1.361,422,2.063,532,1.662,533,3.324,581,3.792,587,3.346,589,1.525,590,2.272,591,3.355,592,2.866,595,3.997,663,1.931,673,2.05,748,3.489,815,3.212,1110,5.609,1192,5.597,1398,4.59,1520,3.113,1529,5.937,1539,3.792,1597,8.821,1599,5.597,1602,4.079,1611,5.164,1614,3.582,1633,3.582]],["t/449",[6,0.078,57,3.065,153,2.034,584,4.698,591,4.698,592,4.015,815,3.552,1110,4.727,1529,5.003]],["t/451",[6,0.077,98,4.073,100,3.98,143,4.835,149,3.225,533,2.687,591,5.21,592,4.073,595,3.446,1110,4.835,1156,5.589,1634,8.245,1635,8.245,1636,8.245]],["t/453",[6,0.076,57,4.165,200,3.705,591,4.158,592,4.637,1415,6.253,1539,6.938,1637,9.032,1638,8.303,1639,9.032,1640,10.953,1641,10.953,1642,9.032]],["t/455",[6,0.078,57,1.952,80,1.921,110,1.202,117,4.446,143,3.011,153,1.296,160,1.012,344,1.842,374,1.201,420,1.335,584,4.486,589,1.586,591,4.486,592,4.259,622,2.288,663,2.933,673,3.115,748,2.458,815,3.906,1110,5.197,1156,6.007,1398,2.884,1529,6.435,1597,7.322,1611,6.037,1643,1.942,1644,8.145,1645,8.861,1646,4.719,1647,3.48,1648,5.134,1649,5.134,1650,5.134,1651,5.134,1652,5.134,1653,5.134,1654,5.134]],["t/457",[5,2.549,6,0.078,32,1.901,57,3.498,110,0.828,160,0.77,167,1.334,170,1.273,185,1.191,252,4.547,389,4.222,394,2.704,428,2.083,584,5.098,589,1.207,590,1.798,591,5.098,592,1.536,622,1.86,639,1.759,684,3,712,2.18,787,3.59,933,1.71,1036,2.994,1109,3.59,1156,2.648,1192,3,1193,2.834,1287,2.354,1398,2.885,1459,3.729,1529,2.425,1611,2.109,1612,3.103,1655,3.59,1656,3.103,1657,3.906,1658,3.906,1659,3.382,1660,3.906,1661,3.906,1662,3.906,1663,3.906,1664,3.59,1665,3.906,1666,9.198,1667,6.099,1668,6.099,1669,5.606,1670,3.59,1671,3.906,1672,3.906,1673,3]],["t/459",[6,0.078,51,4.936,110,1.464,157,4.925,327,2.745,398,1.566,420,1.479,584,4.321,591,5.517,592,4.714,622,1.735,624,2.423,641,4.239,815,3.558,1087,4.368,1121,4.239,1398,3.609,1521,2.841,1529,5.011,1611,4.359,1614,4.127,1644,5.227,1674,3.463,1675,5.227,1676,5.687,1677,5.687,1678,5.687,1679,8.073,1680,4.925,1681,3.477]],["t/461",[6,0.076,110,1.27,532,3.151,533,3.647,584,4.31,595,3.913,1110,5.49,1126,5.564,1682,7.438,1683,7.438]],["t/464",[6,0.074,591,5.691,908,6.99,909,5.843,1110,5.434,1115,5.666,1116,7.117,1118,4.265,1605,7.656,1684,9.265,1685,9.265,1686,7.656,1687,9.265,1688,9.265,1689,9.265]],["t/466",[6,0.078,11,5.459,57,3.407,110,0.896,167,2.256,168,1.849,327,3.189,428,2.256,533,2.153,539,4.794,584,4.68,591,5.017,592,3.524,595,2.761,622,2.015,684,5.075,818,3.606,1035,4.574,1087,5.075,1110,3.875,1126,3.927,1127,4.479,1398,3.909,1612,7.118,1669,8.235,1690,6.607,1691,6.607]],["t/468",[6,0.078,154,3.851,375,3.639,436,2.513,532,3.199,533,3.463,589,2.23,592,2.839,595,3.972,663,2.823,748,3.456,963,3.298,1081,5.111,1110,4.233,1121,5.38,1398,2.775,1610,7.551,1643,2.73,1692,7.218,1693,5.735,1694,7.218,1695,7.218,1696,7.218,1697,6.634,1698,7.218,1699,7.218]],["t/471",[6,0.077,110,1.15,533,3.433,591,3.903,592,3.335,595,4.403,963,4.814,1110,6.178,1398,4.051,1599,6.512,1610,8.371,1686,7.005,1700,8.478,1701,8.478]],["t/473",[6,0.078,158,2.148,204,1.452,326,3.047,591,3.27,592,2.794,709,3.966,1110,6.183,1398,4.315,1550,8.645,1551,4.166,1605,5.869,1686,5.869,1702,6.53,1703,7.103,1704,7.103]],["t/475",[6,0.078,160,1.52,193,1.451,368,5.598,532,2.596,533,3.234,541,3.924,595,4.148,709,4.306,1112,6.161,1116,5.925,1599,8.428,1604,6.129,1605,6.373,1608,6.373,1705,6.68,1706,7.09,1707,7.714,1708,7.714]],["t/477",[6,0.077,374,1.026,533,3.393,595,4.352,860,6.875,1087,6.391,1088,7.649,1110,4.88,1398,4.004,1534,4.194,1599,7.998,1610,6.611,1709,8.321,1710,8.321]],["t/479",[6,0.078,57,3.065,110,1.094,534,3.412,584,3.71,591,3.71,592,3.17,1087,6.191,1112,6.336,1121,6.008,1551,4.727,1598,6.404,1608,6.659,1705,6.98,1711,8.06,1712,8.06]],["t/481",[6,0.074,1713,10.331]],["t/483",[6,0.078,9,3.619,96,4.272,114,6.831,144,3.434,149,2.13,150,2.247,153,1.374,173,3.434,200,3.21,208,1.171,212,2.048,219,2.167,374,1.362,428,3.129,480,2.882,533,1.774,575,1.833,595,2.276,622,2.387,624,3.904,663,3.918,673,3.25,686,2.77,705,3.691,728,3.236,749,2.452,791,3.691,963,2.488,988,1.984,989,1.682,1032,3.076,1398,3.523,1532,3.951,1539,4.182,1588,4.326,1674,3.357,1681,3.33,1714,5.445,1715,5.445,1716,6.343,1717,3.076,1718,3.38,1719,4.715,1720,5.445,1721,4.182,1722,4.182,1723,5.445]],["t/485",[6,0.078,98,3.175,114,5.503,144,4.465,150,2.922,153,0.901,160,1.12,167,1.941,168,1.59,208,0.851,373,1.574,374,1.33,383,2.138,428,3.488,480,3.455,481,2.018,533,1.164,534,1.512,539,2.592,595,1.493,622,1.734,624,4.353,663,3.67,664,2.095,673,1.483,686,1.817,728,2.123,818,3.103,960,3.103,971,3.935,1035,2.473,1159,2.123,1383,2.663,1398,3.103,1564,1.563,1643,1.351,1674,2.438,1716,4.901,1718,2.217,1719,3.093,1724,3.093,1725,5.684,1726,3.572,1727,4.516,1728,3.283]],["t/488",[6,0.078,98,2.709,114,6.088,134,4.767,200,3.778,268,2.445,374,0.849,428,2.351,534,2.915,622,2.1,624,2.934,663,4.65,748,3.297,815,3.035,818,3.758,960,3.758,988,2.509,1398,2.648,1716,6.377,1729,7.977,1730,7.611,1731,4.274]],["t/490",[6,0.078,114,6.16,268,2.997,374,1.04,622,2.574,815,3.719,1718,5.238,1719,7.308,1724,7.308,1728,7.757,1729,7.308,1732,6.972]],["t/492",[6,0.075,420,2.582,428,3.391,573,4.289,624,4.232,1733,7.628]],["t/494",[6,0.078,98,3.789,326,3.159,374,0.908,401,3.665,428,2.515,476,2.503,520,2.616,539,5.345,624,4.104,815,3.247,1035,5.099,1308,4.104,1732,7.958,1734,5.491,1735,5.852]],["t/496",[6,0.077,98,3.214,114,6.61,153,2.062,268,3.656,374,1.269,385,3.372,622,3.14,663,3.195,705,5.538,748,4.928,818,5.619,960,4.459,989,2.524,1383,6.09,1721,6.275,1730,9.313,1736,8.17,1737,8.17]],["t/498",[6,0.078,32,2.683,114,6.506,164,4.568,165,2.804,167,1.882,168,2.209,170,1.796,193,1.037,221,2.73,230,2.537,262,3.75,263,4,289,8.323,374,1.137,377,2.482,398,1.518,399,2.461,420,2.399,424,2.464,428,3.788,435,2.618,506,3.664,520,1.958,534,4.265,622,3.252,645,2.661,718,2.976,960,3.009,974,2.304,975,2.304,995,2.482,1206,3.903,1395,3.816,1738,4.773,1739,4.901,1740,4.773,1741,3.422,1742,4.773,1743,3.816,1744,5.512,1745,4.234,1746,7.989,1747,5.512,1748,5.512,1749,5.512]],["t/500",[6,0.078,114,6.499,164,3.408,167,3.144,168,2.577,207,1.029,262,2.171,289,3.778,365,2.932,374,1.02,377,3.726,385,1.887,398,2.279,399,2.579,401,1.561,420,1.789,428,2.35,435,3.268,513,1.517,520,2.444,534,3.898,573,1.974,575,1.539,622,3.165,624,4.422,645,2.207,651,3.165,705,6.242,718,4.469,727,3.534,748,3.295,761,3.237,815,2.015,818,3.757,929,2.552,933,2.001,993,2.883,1159,4.09,1383,3.408,1721,5.286,1730,3.778,1739,6.685,1742,3.959,1750,5.686,1751,4.572,1752,4.873,1753,5.686,1754,6.882,1755,4.572,1756,4.572,1757,4.203]],["t/502",[6,0.077,98,4.32,114,6.724,153,1.699,200,2.761,374,1.118,385,2.778,398,2.499,401,3.098,420,2.856,428,2.298,480,2.478,622,3.35,624,4.68,645,4.379,663,2.632,673,2.795,748,3.222,818,3.674,854,4.316,989,2.08,1155,4,1598,7.208,1721,5.17,1758,6.731,1759,5.561,1760,6.731,1761,6.731,1762,6.731,1763,6.731,1764,6.731]],["t/504",[6,0.078,143,3.081,144,3.314,160,1.035,167,3.573,168,3.054,185,1.603,193,0.988,204,1.559,208,0.786,305,2.9,316,2.366,347,2.239,377,2.366,385,2.168,388,3.369,428,3.573,513,1.744,624,4.915,635,2.9,663,3.853,818,5.378,967,2.116,971,3.637,974,3.188,975,3.188,1032,2.968,1036,2.579,1117,1.875,1130,2.933,1398,2.02,1539,4.036,1590,2.869,1643,2.885,1716,3.637,1727,4.174,1765,5.535,1766,6.605,1767,5.254,1768,4.83,1769,4.55]],["t/506",[6,0.077,98,3.607,374,1.518,513,3.044,624,3.908,663,3.587,960,5.006,1716,6.349,1734,6.837]],["t/508",[6,0.077,98,4.709,114,6.708,160,2.07,374,1.04,428,3.906,624,4.476,728,5.015,1155,5.015,1716,5.842,1734,6.291,1742,7.308,1770,8.438]],["t/510",[6,0.077,98,3.142,114,4.685,138,7.343,160,1.574,167,2.728,168,2.235,204,1.633,236,2.715,374,0.984,401,2.728,420,2.077,428,3.465,624,5.001,722,5.415,815,3.521,818,4.36,1041,3.106,1308,3.404,1716,5.53,1732,6.6,1771,6.6]],["t/512",[6,0.077,114,6.054,201,4.215,374,1.461,399,2.558,428,3.525,622,3.149,624,3.497,651,5.681,705,5.563,728,6.136,744,6.304,933,3.592,960,4.48,1716,5.681,1757,7.544]],["t/515",[6,0.078,98,2.079,114,6.15,214,1.746,268,1.877,374,0.944,385,2.181,398,2.11,411,5.879,480,1.946,487,2.72,512,1.822,534,2.237,622,2.748,663,3.864,677,4.379,687,3.099,705,3.582,725,3.232,728,3.141,730,2.471,1716,6.237,1724,7.802,1729,4.577,1730,7.444,1772,10.487,1773,5.285,1774,5.285,1775,5.285,1776,5.285,1777,4.858,1778,5.285,1779,5.285,1780,5.285,1781,5.285,1782,4.367,1783,5.285]],["t/517",[6,0.078,49,2.433,158,1.221,159,2.228,160,1.233,176,1.392,185,1.232,193,0.759,214,1.334,222,3.947,295,3.101,314,3.336,326,1.732,330,4.807,334,3.101,428,1.379,528,2.506,595,2.616,624,1.72,663,1.579,665,3.101,904,3.101,906,2.228,974,1.687,975,1.687,985,2.4,1103,5.753,1104,3.711,1310,3.711,1548,5.753,1554,6.859,1643,1.527,1680,3.496,1716,7.375,1732,7.719,1745,3.101,1784,3.101,1785,3.208,1786,8.09,1787,9.342,1788,8.633,1789,6.259,1790,4.037,1791,4.037,1792,4.037,1793,3.01,1794,4.037,1795,3.711,1796,3.711,1797,4.037,1798,3.496,1799,3.711,1800,4.037,1801,4.037,1802,4.037,1803,4.037,1804,4.037,1805,6.259,1806,4.037]],["t/519",[6,0.074,1807,8.896,1808,10.272]],["t/521",[6,0.077,83,3.11,154,3.034,160,1.476,193,2.035,207,2.434,208,1.457,268,3.458,344,2.687,347,3.191,374,0.923,380,3.645,387,6.353,424,3.348,431,2.095,589,2.314,673,3.11,743,3.406,998,2.946,999,6.471,1681,4.579,1809,5.868,1810,4.392,1811,5.184,1812,6.883,1813,7.488]],["t/523",[1,3.461,6,0.078,129,2.654,149,2.723,160,1.959,193,1.571,200,1.904,204,2.328,207,2.562,208,1.704,221,2.299,268,2.473,333,2.723,347,1.978,373,2.046,374,1.334,380,4.839,424,2.075,431,1.948,434,2.622,436,1.616,532,1.563,541,2.362,573,2.005,575,1.563,589,1.435,727,2.384,988,1.692,989,1.435,992,2.187,1032,2.622,1112,2.882,1132,2.341,1181,2.592,1371,3.689,1681,2.839,1743,3.214,1810,4.899,1811,3.214,1814,4.643,1815,4.643,1816,4.021,1817,4.021]],["t/525",[6,0.078,49,2.284,83,2.474,149,2.33,153,1.857,155,2.349,160,1.45,168,1.667,193,1.706,199,1.517,204,2.132,207,2.347,208,1.561,262,1.8,319,1.745,344,1.36,347,3.136,374,1.482,383,1.426,387,2.473,420,0.986,422,2.49,428,2.513,431,2.537,487,1.346,534,1.605,575,2.808,744,4.576,749,1.707,933,1.659,967,2.399,974,2.49,975,2.49,985,2.253,988,1.381,989,1.171,992,2.807,998,1.491,1036,1.861,1112,4.569,1118,1.745,1171,2.519,1185,3.82,1590,1.426,1633,2.751,1681,2.318,1740,3.282,1818,3.79,1819,3.79,1820,3.79,1821,5.159,1822,3.79,1823,3.132,1824,5.476,1825,3.282,1826,4.576,1827,5.957,1828,5.341,1829,5.476,1830,5.957,1831,2.826,1832,5.848,1833,3.314,1834,4.733,1835,3.484,1836,2.43]],["t/527",[6,0.077,83,2.327,149,1.372,153,0.886,160,1.104,167,2.389,168,3.002,170,1.143,190,1.708,199,2.244,204,2.24,207,2.284,208,1.519,256,1.467,262,2.662,291,2.429,347,1.495,374,0.985,377,2.523,380,4.941,383,1.32,399,1.094,410,4,422,2.924,424,1.569,428,2.982,432,2.662,434,3.166,487,1.246,520,1.99,528,2.178,575,1.886,634,3.059,635,1.937,708,1.895,727,2.878,989,1.084,998,2.205,1132,2.825,1139,2.25,1171,2.332,1185,2.25,1198,1.895,1225,1.738,1459,2.146,1502,2.086,1535,2.29,1590,1.32,1627,2.178,1681,3.427,1809,2.115,1810,5.46,1821,3.039,1823,2.899,1837,9.311,1838,3.509,1839,3.509,1840,3.509,1841,5.604,1842,6.997,1843,6.997,1844,6.997,1845,6.997,1846,6.997,1847,5.604,1848,5.604,1849,3.509,1850,3.509,1851,3.509,1852,3.509,1853,3.509,1854,3.509,1855,3.509,1856,3.509,1857,3.509,1858,3.509,1859,3.509,1860,6.997,1861,3.509,1862,4.853,1863,3.509,1864,5.604,1865,3.509,1866,5.604,1867,3.509,1868,3.509,1869,3.509,1870,3.509,1871,3.509,1872,3.509,1873,3.509,1874,3.509,1875,3.509,1876,3.509,1877,3.225,1878,3.509,1879,3.509,1880,3.509,1881,3.509,1882,3.509,1883,3.509,1884,2.695,1885,2.788,1886,3.509,1887,3.225,1888,3.509,1889,3.509,1890,3.509,1891,1.769,1892,3.039,1893,3.225,1894,3.225]],["t/529",[6,0.078,10,1.905,49,1.705,59,2.003,98,1.85,109,1.579,154,1.146,155,1.821,158,2.126,160,1.189,168,1.316,176,1.621,185,2.144,193,1.583,195,1.659,204,1.824,207,1.755,208,1.26,214,1.993,217,2.173,256,1.965,268,2.496,286,1.19,327,1.366,347,1.206,374,0.961,380,4.993,390,2.601,398,1.295,422,1.182,424,1.265,431,0.792,434,1.598,476,0.961,487,1.005,506,1.88,512,2.902,513,1.561,565,1.312,622,0.863,687,1.659,708,1.528,727,1.453,730,2.82,854,3.015,908,2.757,909,1.784,963,1.293,967,1.894,972,1.617,974,2.937,975,2.937,985,2.795,988,2.842,989,0.874,998,2.373,1115,1.73,1117,1.678,1141,2.053,1178,1.426,1520,1.784,1638,2.601,1681,2.875,1731,2.919,1740,2.45,1809,5.841,1810,2.757,1811,1.958,1831,2.109,1832,6.197,1833,3.512,1834,2.248,1884,5.991,1885,5.584,1893,4.322,1894,4.322,1895,2.912,1896,2.45,1897,2.248,1898,6.033,1899,2.829,1900,3.869,1901,2.722,1902,2.919,1903,2.829,1904,2.829,1905,2.338,1906,4.322,1907,2.829,1908,1.958,1909,2.829,1910,2.829,1911,2.829,1912,2.829,1913,2.829,1914,2.829,1915,1.426,1916,2.829,1917,2.829,1918,2.829,1919,2.829,1920,1.814,1921,2.829,1922,2.829,1923,2.601,1924,2.829,1925,3.612,1926,2.829,1927,2.829,1928,3.07,1929,6.033,1930,4.702,1931,2.829,1932,1.528,1933,2.829,1934,2.829,1935,2.829]],["t/531",[6,0.078,49,3.614,98,1.504,149,2.346,154,1.549,155,0.99,160,1.458,164,1.893,168,1.678,191,1.662,193,1.392,204,1.513,207,2.174,208,1.446,256,1.598,291,2.646,318,2.646,344,2.152,365,2.451,374,0.471,375,1.927,376,2.541,379,2.774,380,5.236,383,2.256,387,2.494,425,1.773,431,2.071,481,2.159,513,1.269,520,2.13,565,1.773,573,1.651,623,2.022,656,4.152,657,2.707,743,1.337,791,2.591,928,2.494,973,2.774,974,4.833,975,4.833,985,5.742,988,2.185,989,1.181,990,4.247,996,3.158,997,3.158,1017,3.158,1141,2.774,1670,3.514,1810,4.915,1828,2.774,1833,1.721,1901,2.213,1936,3.037,1937,3.158,1938,3.158,1939,3.614,1940,2.936,1941,3.823,1942,3.823,1943,3.823,1944,4.607,1945,3.514,1946,3.823,1947,3.823,1948,3.823,1949,3.823,1950,3.823,1951,3.823,1952,3.037,1953,2.936,1954,3.514,1955,3.823,1956,3.158,1957,2.774,1958,2.591,1959,2.774,1960,5.194,1961,3.31,1962,2.936,1963,3.823,1964,3.037,1965,2.707,1966,3.514,1967,3.823,1968,3.823,1969,3.823,1970,3.514,1971,3.514]],["t/533",[6,0.078,83,2.785,129,3.834,149,2.623,170,2.949,191,2.915,193,1.926,204,2.094,207,2.467,208,1.641,236,2.279,305,3.701,347,2.857,373,2.956,374,1.262,380,4.986,383,2.522,431,2.866,516,4.866,843,5.151,989,2.072,1112,4.163,1596,6.164,1809,4.041,1810,3.932,1825,5.807,1895,3.237,1972,6.164]],["t/535",[6,0.074,1973,10.331]],["t/537",[6,0.077,10,3.325,110,1.114,147,7.31,160,1.617,268,2.915,374,1.272,533,2.674,673,4.691,937,5.355,1336,5.811,1518,6.118,1519,6.304,1528,4.137,1530,5.902,1545,5.176,1643,3.104,1674,4.428,1722,6.304,1974,6.781,1975,8.207]],["t/539",[6,0.078,10,2.451,110,0.821,160,1.662,208,0.906,219,2.408,268,2.149,374,1.294,436,2.106,487,2.149,532,2.037,533,3.163,589,1.869,595,2.529,673,4.586,687,3.548,960,3.303,1344,4.284,1518,4.51,1519,4.647,1528,5.567,1530,5.55,1531,3.88,1545,3.816,1558,4.807,1565,3.756,1573,4.647,1643,3.971,1674,4.905,1976,6.452,1977,5.562,1978,5.562,1979,4.807,1980,5.562,1981,4.999,1982,6.05,1983,5.717]],["t/541",[6,0.077,100,4.317,158,2.705,185,2.728,359,4.353,673,4.521,1117,3.886,1643,3.382,1674,4.67,1976,7.802]],["t/544",[6,0.077,160,1.671,374,1.549,533,2.763,589,2.62,595,3.543,673,4.375,937,5.532,1494,5.532,1528,4.274,1674,3.637,1984,6.32,1985,7.342,1986,5.347,1987,7.342,1988,8.478,1989,7.342,1990,8.478,1991,7.793]],["t/546",[6,0.077,191,3.888,374,1.102,436,3.113,505,4.508,589,2.763,638,4.73,673,3.714,687,5.244,937,5.835,1521,5.439,1524,6.666,1528,5.488,1572,8.22]],["t/548",[6,0.077,100,5.521,158,2.552,326,3.62,532,2.84,533,2.75,687,4.949,730,3.945,1117,3.012,1528,4.254,1538,4.04,1674,4.506,1985,7.308,1986,5.322,1987,7.308,1989,7.308,1992,8.438,1993,8.438]],["t/550",[6,0.077,10,2.948,153,1.836,164,3.603,193,1.369,212,2.737,230,4.911,253,4.932,254,3.484,286,4.019,316,3.276,374,0.897,398,2.004,401,3.262,420,1.892,476,2.473,673,3.968,889,5.781,917,6.688,1244,5.152,1530,5.463,1538,3.484,1545,4.589,1643,3.613,1674,3.121,1750,6.012,1974,6.012,1994,3.702,1995,5.424,1996,5.424,1997,7.276,1998,5.781,1999,7.276]],["t/553",[6,0.077,326,3.411,374,1.444,589,3.127,591,3.661,673,3.303,678,3.555,743,2.782,1244,5.631,1344,5.631,1360,5.631,1521,3.973,1530,4.547,1532,5.771,1573,6.108,1611,4.294,1722,6.108,1976,5.286,1979,6.319,1981,6.571,1998,6.319,2000,5.771,2001,7.31,2002,7.31,2003,7.953,2004,7.31,2005,7.953,2006,6.571,2007,5.631,2008,7.953,2009,6.887]],["t/555",[6,0.077,110,1.637,165,4.011,300,5.826,362,6.513,533,3.806,592,3.101,678,3.524,705,5.344,817,8.807,1344,5.582,1528,5.073,1565,4.893,1573,6.055,1782,6.513,1979,6.263,1981,6.513,2006,6.513,2009,6.827,2010,7.883,2011,4.971,2012,7.246]],["t/557",[6,0.078,216,3.853,219,2.649,374,1.408,436,2.317,663,2.603,673,4.743,743,3.15,1528,3.355,1530,3.805,1531,5.773,1555,8.276,1558,8.107,1674,2.855,1717,3.76,1985,5.764,1986,4.198,1987,5.764,1989,5.764,2013,6.656,2014,6.118,2015,6.656,2016,6.118]],["t/559",[6,0.077,77,6.247,230,4.725,268,2.888,374,1.002,533,2.65,595,3.399,673,4.906,1344,5.759,1528,5.955,1530,4.65,1573,6.247,1674,3.488,1717,4.594,1976,5.406,2017,7.043]],["t/561",[6,0.078,110,0.893,150,4.696,342,4.086,377,2.964,533,2.145,638,3.482,673,2.734,687,3.86,1146,4.557,1528,5.736,1530,6.222,1531,4.221,1532,4.777,1533,4.777,1565,4.086,1717,3.718,1976,6.744,1979,5.23,1980,6.051,1981,5.439,2006,5.439,2009,5.701,2018,6.583,2019,10.146,2020,6.583,2021,6.583]],["t/563",[6,0.078,80,2.566,110,0.931,208,1.027,216,6.68,374,1.277,673,4.792,687,4.023,729,4.857,937,4.476,1117,2.448,1528,6.459,1567,4.023,1674,3.941,2022,6.859]],["t/565",[6,0.077,77,6.136,226,3.956,230,4.672,533,3.307,559,4.512,595,4.241,673,3.317,937,5.212,1117,3.622,1360,5.656,1528,5.623,1529,4.959,1530,6.377,1674,3.426,1976,6.746,2006,6.6,2007,5.656,2017,6.918]],["t/567",[6,0.077,154,2.349,155,1.502,160,2.141,165,2.949,193,1.784,200,3.89,208,0.868,216,3.356,219,2.307,230,2.669,300,3.356,305,3.199,398,1.597,428,1.979,431,2.29,517,3.399,589,1.791,624,3.487,663,3.201,673,4.814,911,5.328,933,2.537,989,1.791,995,3.685,1530,6.449,1531,3.717,1558,4.606,1559,8.719,1563,5.328,1590,2.18,1643,3.897,1674,5.078,1974,6.762,1976,3.853,1979,4.606,2023,5.797,2024,5.797,2025,3.853,2026,3.656,2027,5.797]],["t/569",[6,0.078,51,2.654,77,3.333,80,2.999,134,3.004,158,1.313,160,0.855,165,2.208,193,0.816,200,1.78,230,3.691,315,3.149,326,1.862,359,2.113,398,1.195,420,1.72,481,2.451,486,1.748,532,2.227,533,3.447,566,3.758,589,1.341,591,1.998,595,4.034,596,5.056,631,3.782,645,2.095,663,1.697,673,3.33,686,3.366,722,2.942,815,1.913,933,3.509,989,1.341,990,3.073,1112,2.694,1355,2.229,1439,3.333,1451,4.485,1521,4.005,1523,4.801,1528,4.042,1530,6.048,1538,3.167,1545,2.737,1674,3.439,1976,5.329,2017,3.758,2028,6.616,2029,4.34,2030,6.081,2031,6.616,2032,3.758,2033,4.34,2034,4.34,2035,3.004,2036,1.968,2037,4.34,2038,4.34,2039,2.512,2040,4.485,2041,2.783]],["t/571",[6,0.077,160,1.762,374,1.102,532,3.01,533,3.548,595,3.737,673,5.073,1528,5.488,1674,4.67]],["t/573",[6,0.078,219,2.931,374,1.403,673,4.457,919,5.658,1674,4.131,1991,6.771,2016,6.771]],["t/575",[6,0.078,216,6.874,374,1.333,673,4.757,937,4.886,1244,5.302,1528,6.459,1998,5.95,2042,6.485]],["t/577",[6,0.077,193,1.502,200,3.276,428,3.465,431,2.235,624,5.001,673,4.215,989,3.136,1041,3.106,1530,5.802,1531,5.122,1643,3.021,1674,4.353,1718,6.3,1721,6.136,1974,6.6,1976,5.309,2043,7.343,2044,8.789,2045,7.988]],["t/579",[6,0.077,193,1.489,200,3.247,216,4.584,398,2.181,431,2.215,481,4.472,596,4.993,664,4.643,673,3.288,722,5.367,1027,4.322,1360,5.606,1521,3.956,1523,5.746,1528,3.991,1530,5.77,1545,4.993,1674,3.396,1976,5.263,2030,7.278]],["t/581",[6,0.077,193,1.595,431,2.372,673,4.76,989,2.62,1530,4.847,1531,5.436,1674,4.917,2014,7.793,2046,7.342]],["t/583",[6,0.077,204,1.67,374,1.269,673,4.914,1518,6.09,1519,6.275,1528,5.965,1530,4.671,1531,5.238,1674,4.415,1976,5.43,1977,7.51,2042,7.075]],["t/585",[6,0.074,2047,10.331]],["t/587",[6,0.077,83,4.207,110,0.757,150,2.303,153,2.01,155,1.446,160,1.57,193,1.905,195,3.273,204,1.899,207,1.256,208,1.39,226,2.764,305,3.08,337,3.951,347,2.378,359,2.716,374,1.32,384,2.951,387,3.641,420,1.451,422,2.332,431,1.561,513,1.852,532,3.41,533,2.596,575,1.878,589,1.724,596,3.519,639,2.513,729,3.951,749,2.513,815,2.46,937,5.198,988,2.033,989,1.724,1174,3.641,1538,3.814,1590,2.099,1722,4.286,1905,4.611,1986,3.519,2048,6.297,2049,4.85,2050,2.672,2051,5.13,2052,4.16,2053,3.152,2054,4.16,2055,5.58,2056,4.554,2057,5.13,2058,3.951,2059,4.434,2060,5.13]],["t/589",[6,0.078,79,3.645,83,1.971,110,1.065,150,1.181,153,1.535,154,1.923,160,1.848,164,3.011,165,1.455,191,1.244,193,1.592,199,1.145,204,1.833,207,2.258,208,1.502,212,2.287,268,2.16,305,1.579,316,1.288,317,2.239,319,1.317,333,1.678,334,2.197,347,1.219,359,1.393,373,1.261,374,1.269,384,1.513,420,1.581,422,1.196,431,2.196,476,2.405,480,2.239,486,1.152,487,1.016,496,2.076,513,2.018,532,2.382,533,1.982,589,1.466,596,2.993,637,3.096,639,2.137,693,2.133,718,2.562,815,1.261,906,1.579,937,1.867,960,1.561,968,1.939,988,1.729,989,1.879,998,1.125,1118,2.799,1389,2.026,1520,1.804,1538,3.388,1547,1.7,1590,1.785,1643,1.082,1674,1.227,1681,1.749,1717,1.616,1782,2.364,1810,1.678,1905,2.364,1920,1.834,1984,3.538,1986,1.804,1994,1.455,2000,2.076,2048,6.802,2049,4.292,2050,2.911,2054,3.538,2056,1.636,2058,3.36,2059,2.273,2061,2.133,2062,3.835,2063,2.861,2064,2.477,2065,2.364,2066,2.861,2067,1.98,2068,2.364]],["t/592",[6,0.078,9,6.03,83,4.262,155,1.744,156,5.17,160,1.788,164,3.333,191,2.926,208,1.007,268,2.39,305,5.007,317,3.34,347,2.868,374,1.413,532,2.266,533,2.193,637,4.392,988,2.452,1118,3.099,1538,3.222,1994,3.424,2048,4.563,2049,3.222,2053,5.124,2058,6.424,2069,7.496,2070,6.731,2071,4.474,2072,4.884]],["t/594",[6,0.078,9,2.696,98,3.023,100,3.71,110,1.343,154,1.643,160,1.237,170,1.322,191,1.763,193,1.761,195,2.378,199,3.077,200,1.663,204,0.829,207,1.729,208,1.15,227,3.115,268,1.44,316,1.826,317,3.186,344,1.455,359,1.974,374,0.947,428,1.385,431,1.757,487,2.73,495,3.351,496,2.943,505,2.045,513,1.346,532,2.587,533,2.504,573,1.751,589,1.94,595,2.625,622,2.344,624,1.728,631,2.319,639,1.826,687,2.378,908,4.507,937,2.646,968,2.749,972,2.319,980,2.808,988,2.8,1048,3.222,1115,3.84,1198,2.19,1244,2.872,1312,1.853,1355,2.083,1451,2.749,1538,3.68,1545,2.558,1547,3.733,1567,2.378,1643,2.375,1717,3.547,1771,3.351,1877,3.728,1915,2.045,1983,2.749,1986,6.729,1998,3.222,2000,2.943,2025,4.174,2036,2.848,2049,1.942,2056,2.319,2059,4.99,2062,3.961,2064,3.512,2073,4.99,2074,4.056,2075,2.872,2076,4.056,2077,4.056,2078,3.023,2079,4.056,2080,2.319,2081,4.056,2082,2.378,2083,3.023,2084,3.512,2085,3.512,2086,2.518,2087,4.056,2088,3.512,2089,3.115,2090,3.351,2091,5.773,2092,3.728,2093,1.605]],["t/596",[6,0.078,158,1.07,165,4.754,185,1.079,193,1.323,199,2.816,207,0.796,208,0.844,214,1.168,232,2.327,316,1.592,318,2.448,319,4.301,374,0.436,398,1.937,401,3.347,420,0.92,476,2.979,486,3.763,520,1.256,532,1.898,533,1.838,592,2.218,631,5.342,818,3.078,839,3.045,933,1.548,988,1.289,989,1.742,1113,4.204,1162,3.113,1198,3.798,1429,2.268,1451,5.44,1534,1.424,1538,1.693,1545,3.557,1547,6.236,1810,2.074,1964,5.588,1994,2.869,2036,3.976,2049,1.693,2058,2.504,2065,6.631,2089,4.332,2094,3.537,2095,3.537,2096,3.537,2097,3.251,2098,3.063,2099,3.537,2100,2.922,2101,3.537,2102,3.537,2103,3.537,2104,3.537,2105,3.537,2106,3.537,2107,3.537,2108,3.537,2109,3.537,2110,3.537,2111,3.537,2112,3.537,2113,3.537,2114,3.537,2115,3.537,2116,3.537,2117,5.184,2118,3.537,2119,2.81,2120,3.251,2121,3.251,2122,3.537,2123,4.884,2124,3.537,2125,3.537,2126,2.047,2127,3.537,2128,3.537,2129,3.537,2130,3.537,2131,3.537,2132,3.537,2133,3.537,2134,3.537,2135,5.184,2136,3.251,2137,3.537,2138,3.537,2139,3.537]],["t/598",[6,0.078,83,1.476,110,0.768,144,1.284,149,2.214,153,1.621,154,1.915,155,1.664,160,1.115,164,3.985,165,1.036,167,2.592,168,1.797,170,1.54,185,1.084,190,0.991,193,0.668,204,1.645,207,1.445,208,1.315,212,0.766,214,0.673,223,1.354,231,0.841,236,0.692,237,2.516,239,1.564,256,0.851,264,2.649,286,0.857,305,1.961,316,3.417,321,1.264,374,1.21,377,2.128,380,0.991,384,4.648,388,3.03,399,1.107,401,1.614,420,0.53,422,3.528,428,1.614,435,2.688,486,0.82,487,0.723,532,2.162,533,1.845,573,0.879,575,1.905,624,2.014,635,1.961,637,4.191,687,1.194,704,1.618,708,1.1,831,1.354,849,0.931,959,2.083,974,0.851,975,0.851,988,1.722,992,0.96,998,2.227,1041,1.382,1069,4.269,1078,1.264,1117,0.727,1158,1.124,1170,4.511,1174,4.191,1198,1.1,1206,1.442,1211,1.518,1225,2.34,1236,1.872,1242,1.164,1244,1.442,1254,1.764,1520,1.284,1538,2.263,1547,1.211,1564,1.555,1567,1.194,1681,1.245,1809,1.227,1862,6.968,1900,1.306,1986,1.284,1994,1.036,1998,1.618,2025,1.354,2036,1.612,2048,2.409,2049,3.634,2050,1.701,2053,2.007,2054,5.999,2069,1.683,2140,1.618,2141,3.905,2142,5.203,2143,3.553,2144,3.553,2145,2.037,2146,2.037,2147,2.037,2148,2.037,2149,2.037,2150,2.037,2151,1.872,2152,2.037,2153,2.037,2154,1.618,2155,2.037,2156,2.037,2157,2.037,2158,1.872,2159,2.037,2160,2.037,2161,2.037,2162,2.037,2163,2.037,2164,2.037,2165,2.037,2166,2.037,2167,2.037,2168,1.683,2169,3.553,2170,3.553,2171,3.553,2172,2.037,2173,2.037,2174,2.037,2175,2.037,2176,2.037,2177,1.764,2178,2.037,2179,2.037,2180,2.037,2181,2.037,2182,2.037,2183,2.037,2184,4.497,2185,2.037,2186,1.872,2187,1.872,2188,1.564,2189,0.975,2190,2.037]],["t/600",[6,0.077,10,2.697,83,2.764,110,1.222,164,3.296,193,1.919,204,1.841,207,2.296,208,1.636,230,3.064,268,2.364,314,5.499,374,1.258,377,2.997,399,2.806,431,2.855,480,3.315,487,2.364,532,2.24,533,2.169,541,3.386,622,2.03,663,2.603,906,3.674,968,4.512,1297,5.288,1717,5.086,1986,4.198,2054,6.712,2058,4.713,2062,5.678,2191,6.656,2192,6.656]],["t/602",[6,0.077,10,2.435,100,2.901,110,0.815,153,2.118,155,1.557,160,1.184,164,2.976,165,3.058,191,2.613,193,1.579,200,2.465,204,1.229,208,0.899,230,3.864,254,2.877,262,2.854,286,2.528,288,3.675,315,4.361,319,4.453,374,0.741,401,2.052,431,1.682,480,3.561,486,2.42,487,3.435,517,3.525,532,2.825,533,1.958,589,1.857,622,2.56,678,2.687,988,3.058,1115,3.675,1538,2.877,1547,3.572,1674,2.578,1717,3.395,1986,5.294,1994,4.27,1995,4.48,1996,4.48,2054,6.257,2056,3.436,2057,5.524,2058,6.849,2062,3.79,2065,4.966,2068,4.966,2072,4.361,2117,5.524,2135,5.524,2136,5.524,2193,6.01,2194,6.01,2195,4.775,2196,4.775]],["t/604",[6,0.077,374,1.097,532,3.654,533,2.9,694,7.706,1564,3.895,1983,6.032,1986,6.845,1994,4.527,2025,5.914,2048,6.032,2056,5.087,2058,7.685]],["t/606",[6,0.077,153,2.211,158,3.023,193,1.203,226,3.167,230,2.944,481,3.612,487,2.271,532,4.083,533,3.952,595,4.177,722,4.335,906,3.53,989,2.707,1534,4.026,1551,5.139,1643,2.419,1717,3.612,1731,3.97,1986,7.103,2048,7.635,2056,5.715,2197,6.395,2198,6.395,2199,5.081]],["t/608",[6,0.078,33,3.651,153,1.16,160,0.905,168,1.286,170,2.251,191,1.998,193,1.299,203,7.048,204,0.939,212,1.728,214,1.518,231,1.896,305,2.536,319,2.115,359,2.237,392,3.335,398,2.971,401,2.359,420,1.195,428,2.835,476,2.348,481,2.596,486,2.782,487,1.632,496,3.335,512,1.584,513,2.293,520,1.632,532,2.794,533,2.705,624,3.934,815,2.025,839,3.731,968,3.115,989,1.42,1118,2.115,1534,1.851,1538,3.974,1545,2.898,1547,2.731,1643,1.738,1964,3.651,1986,2.898,2000,3.335,2036,2.084,2048,5.627,2053,5.215,2056,2.627,2068,3.797,2072,6.7,2089,5.306,2091,4.224,2200,5.983,2201,4.595,2202,4.595,2203,4.595,2204,4.595,2205,3.426,2206,3.98,2207,3.53,2208,3.53,2209,5.489,2210,4.595,2211,4.595]],["t/610",[6,0.077,158,2.758,191,2.948,203,6.181,212,2.551,231,2.799,256,2.834,305,3.743,420,1.763,422,2.834,476,2.305,532,3.708,533,2.971,708,3.662,815,2.989,988,2.471,1258,5.055,1401,5.603,1534,3.672,1538,3.247,1547,4.031,1551,3.977,1836,4.348,2048,7.467,2053,5.819,2056,5.213,2207,7.004,2208,7.004,2209,5.388,2212,6.782,2213,6.782,2214,6.782,2215,6.782,2216,6.234]],["t/612",[6,0.077,10,2.677,51,4.04,158,2.71,159,3.647,160,1.302,164,3.272,193,1.912,203,6.073,204,1.351,207,1.487,208,0.989,212,3.823,214,2.183,230,3.042,401,2.256,428,2.256,486,2.661,487,2.346,532,3.835,533,2.919,624,2.815,678,4.005,686,4.558,1107,5.075,1534,3.608,1538,4.289,1551,5.254,1793,4.925,1983,4.479,1986,4.167,2048,6.073,2050,3.163,2053,5.06,2056,5.812,2196,5.249,2208,6.881,2217,6.607,2218,6.607,2219,6.607,2220,6.607]],["t/614",[6,0.077,154,2.758,155,1.763,160,1.341,204,1.392,212,2.56,221,5.111,334,7.021,374,0.839,398,1.875,422,2.845,518,7.553,532,2.291,664,5.361,815,3,905,4.885,921,5.895,1352,6.257,1538,3.259,1986,5.765,2048,4.614,2053,3.845,2054,6.815,2056,3.892,2069,5.625,2209,5.408,2221,10.321,2222,6.807,2223,6.807,2224,6.807,2225,6.807,2226,6.807,2227,9.141,2228,6.807]],["t/616",[6,0.077,159,4.489,160,1.602,191,4.462,193,1.53,204,1.663,212,3.059,384,4.301,532,3.455,639,3.662,1106,6.462,1158,6.208,1401,6.72,1520,5.129,1793,6.063,1996,6.063,2056,5.868,2058,5.759,2206,9.74,2229,7.476,2230,8.133]],["t/618",[6,0.078,80,2.367,83,2.628,110,0.859,150,2.611,153,1.597,155,1.639,185,1.93,193,1.19,208,0.947,308,4.289,317,2.33,344,2.27,374,1.072,487,3.089,496,7.213,512,2.182,517,3.711,532,3.777,533,2.062,677,3.618,908,5.101,988,3.622,1036,3.106,1115,5.319,1538,3.029,2000,7.213,2056,6.12,2059,7.898,2073,5.027,2231,5.228,2232,6.328,2233,6.328,2234,6.328]],["t/620",[6,0.078,165,4.101,193,1.92,322,6.98,431,2.255,486,3.246,532,3.436,1126,4.79,1128,5.003,1986,6.437,2025,5.357,2056,5.835,2068,6.659,2235,8.06,2236,6.98]],["t/622",[6,0.078,51,3.37,98,2.168,153,2.328,159,3.042,191,2.396,199,2.207,203,3.736,204,1.614,207,1.24,208,0.825,212,2.073,305,4.358,319,2.537,374,0.973,384,2.915,422,2.304,486,2.22,520,1.958,532,4.063,533,3.283,592,2.168,596,3.476,998,2.168,1107,4.234,1155,3.276,1198,2.976,1254,4.773,1398,2.119,1451,3.736,1547,4.693,1590,2.073,1611,2.976,1793,4.109,1900,3.534,2048,5.352,2049,2.639,2052,4.109,2053,4.46,2054,4.109,2056,6.343,2058,5.591,2059,4.379,2065,4.554,2142,5.067,2196,4.379,2237,4.109,2238,5.512]],["t/624",[6,0.074,2239,8.896,2240,10.272]],["t/626",[6,0.078,51,3.802,154,2.519,155,2.226,160,1.693,185,1.897,207,1.934,208,1.59,286,2.615,344,2.231,374,0.766,383,2.339,513,2.064,589,1.921,639,4.435,749,3.87,1041,2.418,1106,4.94,1398,3.787,1534,2.504,1643,2.352,1828,4.512,1891,3.135,2049,5.522,2093,2.46,2189,2.977,2241,5.95,2242,4.635,2243,5.385]],["t/628",[6,0.078,9,2.342,51,2.154,70,5.091,102,1.745,110,0.478,154,2.842,155,1.456,157,3.051,159,3.103,160,0.694,168,1.963,170,1.832,191,1.531,207,1.579,208,1.31,236,1.197,286,2.365,332,2.439,347,1.501,374,1.352,383,1.325,398,0.97,433,2.066,480,2.07,487,1.251,513,2.328,575,3.14,639,3.605,705,2.388,743,1.233,749,4.407,929,1.967,959,1.553,963,1.61,967,2.264,1041,1.37,1101,2.259,1117,2.007,1158,3.872,1159,2.094,1178,2.834,1225,1.745,1242,2.014,1398,4.294,1600,2.388,1629,3.051,1631,3.051,1643,2.653,1811,2.439,1915,2.834,2026,2.222,2036,1.598,2049,5.566,2093,2.224,2189,1.687,2241,6.776,2242,2.626,2243,4.869,2244,3.523,2245,2.187,2246,1.809,2247,6.196,2248,3.238,2249,3.523,2250,3.051,2251,3.051,2252,2.259]],["t/630",[6,0.078,9,2.048,70,4.649,102,3.173,149,1.973,154,2.044,155,1.659,160,2.077,168,2.455,170,1.004,191,2.785,193,0.58,204,0.63,207,1.666,208,1.386,221,1.526,222,1.943,223,2.048,231,2.082,236,1.715,262,3.042,268,1.094,269,2.833,270,2.833,286,1.296,374,0.79,384,1.63,399,0.96,422,2.109,423,1.943,480,1.135,513,1.023,565,1.429,575,1.698,631,1.762,639,1.387,645,1.488,678,1.378,705,2.089,743,2.858,749,4.931,853,2.182,905,1.647,906,1.701,933,1.349,974,1.288,975,1.288,988,1.123,1037,3.041,1041,1.962,1101,1.976,1159,2.999,1178,3.23,1206,2.182,1225,1.526,1242,2.885,1287,1.857,1312,1.408,1398,4.334,1520,1.943,1600,4.343,1741,1.913,1833,2.885,2049,5.396,2052,2.297,2187,4.638,2189,2.416,2241,4.435,2242,7.673,2250,4.369,2253,3.082,2254,5.045,2255,3.082,2256,2.669,2257,4.638,2258,6.807,2259,3.082,2260,2.546,2261,1.976,2262,3.082,2263,3.082,2264,3.082,2265,3.082,2266,5.045,2267,3.082,2268,1.701,2269,3.082,2270,3.082,2271,3.082,2272,2.546,2273,2.448,2274,3.082,2275,3.082,2276,3.082,2277,3.082,2278,3.082,2279,3.082,2280,3.082,2281,3.082,2282,2.833,2283,3.082,2284,3.082,2285,3.082]],["t/633",[6,0.077,110,0.65,154,1.941,155,2.61,160,2.214,167,2.434,168,2.382,170,3.072,195,2.81,204,0.98,207,1.915,208,1.637,223,3.185,236,1.628,256,2.003,286,2.015,344,3.053,347,3.627,374,0.878,377,2.157,401,2.434,422,2.003,434,2.706,439,2.484,440,2.615,513,2.825,575,1.613,589,1.48,639,2.157,660,3.317,678,2.142,708,2.587,749,4.537,933,2.097,942,3.317,959,2.112,961,2.294,963,2.189,967,2.871,995,2.157,998,1.885,1041,1.863,1183,3.68,1225,2.373,1398,3.273,1564,2.097,1600,3.248,1643,3.994,1647,3.248,1891,2.415,1902,2.974,1915,2.415,2025,3.185,2026,3.022,2036,2.173,2049,4.075,2075,3.393,2080,2.739,2082,2.81,2086,2.974,2093,1.896,2189,2.294,2241,4.934,2242,5.314,2245,2.974,2247,6.674,2260,3.959,2286,2.706,2287,3.248,2288,4.404,2289,4.404,2290,2.373]],["t/635",[6,0.077,154,4.371,155,2.795,208,1.615,749,4.858,1041,3.426,1398,4.148,1600,5.973,2049,5.165,2189,5.165,2241,7.468]],["t/638",[6,0.076,154,4.371,207,1.983,208,1.615,374,1.086,513,2.924,1041,3.426,1398,4.148,1891,4.442,1920,5.65,2026,5.557,2049,4.218,2075,6.239,2241,6.099,2247,7.639,2286,4.977,2290,4.363]],["t/640",[6,0.077,10,2.6,158,1.941,176,2.213,204,2.047,207,1.444,208,1.499,246,3.815,344,2.303,374,1.083,512,3.028,513,2.13,678,2.869,743,2.245,998,2.525,1041,3.416,1398,4.478,1600,4.351,1643,4.072,1891,4.428,1915,3.235,1920,5.632,2025,4.266,2049,3.073,2050,3.073,2075,4.545,2080,5.725,2082,3.764,2093,2.539,2241,6.081,2245,3.984,2286,4.961,2287,5.954]],["t/642",[6,0.078,160,2.081,204,2.16,223,4.74,743,2.495,1287,6.367,1398,2.742,1915,3.595,2080,4.077,2086,4.427,2241,4.937,2242,8.379,2260,5.893,2282,6.555,2288,6.555,2289,6.555]],["t/644",[6,0.078,10,3.542,154,2.582,164,4.329,191,3.8,204,1.303,207,2.245,208,1.493,214,2.105,323,5.519,330,6.714,401,2.985,486,3.52,678,2.849,743,2.23,998,2.507,1060,4.624,1158,3.517,1398,3.361,1600,4.32,1643,2.41,1891,3.213,2025,4.236,2026,4.019,2049,4.777,2050,3.051,2243,5.519,2247,4.512,2290,4.329,2291,6.372,2292,5.858,2293,6.372,2294,6.372,2295,6.372,2296,6.372]],["t/646",[6,0.078,70,4.691,102,5.349,160,2.396,262,3.07,374,0.797,705,4.382,749,4.526,1178,3.259,1398,3.394,1600,4.382,1643,3.338,1915,3.259,2025,5.867,2049,5.171,2075,4.577,2082,3.791,2086,4.013,2241,6.11,2242,8.7]],["t/648",[6,0.078,153,1.169,154,1.876,155,1.8,160,0.912,168,2.334,170,2.718,193,0.871,204,2.03,207,1.877,208,1.703,219,1.843,236,1.574,286,2.923,305,2.556,347,1.973,374,1.224,380,2.254,383,1.742,431,1.296,480,3.071,513,1.537,575,2.339,639,3.755,743,2.431,749,2.085,959,2.041,963,3.811,967,1.865,974,2.904,975,2.904,989,1.431,998,2.733,1041,1.801,1064,2.681,1198,2.501,1225,2.293,1242,2.648,1393,3.022,1398,4.01,1590,1.742,1594,3.679,1741,2.875,1809,2.791,1823,3.826,1833,2.085,1891,2.335,1920,2.969,2036,2.1,2049,3.327,2189,2.217,2252,2.969,2256,4.01,2290,2.293,2297,4.01,2298,3.826,2299,4.631,2300,4.631,2301,3.679,2302,4.631]],["t/650",[6,0.077,70,5.875,154,3.28,155,2.097,160,1.595,207,1.822,208,1.212,286,3.405,513,2.687,639,4.609,749,4.609,998,3.185,1178,4.081,1398,4.316,1891,4.081,1920,5.191,2049,5.646,2093,3.203,2241,5.605,2242,6.035,2250,7.011]],["t/652",[6,0.078,236,2.965,989,2.696,1398,3.355]],["t/654",[6,0.074,2303,10.331]],["t/656",[6,0.078,83,3.63,150,2.63,155,2.264,160,1.722,193,1.199,204,2.376,207,2.245,208,1.493,323,5.519,327,3.076,373,2.809,374,1.467,383,3.753,424,2.849,431,1.783,480,2.346,532,2.942,597,3.184,749,2.869,967,2.566,998,3.438,1139,4.086,1315,4.75,1895,4.219,2304,5.063,2305,5.063]],["t/658",[6,0.078,32,3.701,46,2.602,49,1.402,83,3.977,143,1.365,149,3.503,150,1.645,153,1.759,155,2.547,158,0.704,160,1.83,168,1.116,170,0.758,193,1.529,199,2.094,204,2.135,207,2.015,208,1.65,212,0.875,214,0.769,236,1.778,256,0.973,319,1.071,327,1.123,344,0.835,347,1.699,349,1.787,373,2.306,374,1.439,383,3.225,385,2.558,399,1.63,422,1.666,424,1.782,431,1.95,436,1.388,480,1.926,487,0.826,496,1.689,513,3.083,565,1.079,575,1.761,591,1.071,592,1.568,597,1.992,622,1.89,634,1.27,656,1.611,730,1.088,739,1.611,749,1.795,853,4.388,928,1.518,971,1.611,972,1.33,974,2.186,975,2.186,988,1.453,992,2.464,995,1.795,1017,1.923,1117,0.831,1132,1.173,1141,1.689,1171,1.547,1193,2.893,1198,1.257,1312,1.063,1336,1.648,1371,1.849,1389,1.648,1590,1.968,1630,1.923,1895,1.123,1900,1.492,1932,1.257,2052,1.735,2184,4.156,2304,1.849,2306,2.327,2307,2.327,2308,3.987,2309,5.231,2310,2.327,2311,3.987,2312,2.327,2313,2.139,2314,2.139,2315,1.923,2316,2.015,2317,2.015,2318,1.735,2319,2.327,2320,3.987,2321,2.327,2322,2.327,2323,2.327,2324,2.139,2325,2.327,2326,2.327,2327,2.015,2328,2.327,2329,2.327,2330,2.327,2331,2.327,2332,1.611,2333,2.327,2334,2.327,2335,2.327,2336,2.327,2337,1.611,2338,2.327]],["t/660",[6,0.078,10,1.763,83,4.013,149,3.982,155,3.046,160,1.582,168,2.512,193,0.818,204,1.355,207,0.979,208,1.446,236,2.252,344,1.561,347,1.854,374,1.345,384,2.301,385,2.735,431,1.217,480,3.306,565,3.075,622,1.327,749,4.584,793,2.66,941,5.986,992,4.553,1036,2.136,1068,5.74,1131,2.839,1132,2.193,1491,2.325,2339,3.999,2340,4.35,2341,2.622,2342,4.35]],["t/662",[6,0.078,10,2.434,32,1.865,49,2.309,83,1.591,102,4.514,144,5.292,149,1.498,150,1.581,155,2.853,160,0.755,164,1.897,165,4.637,167,1.308,168,3.371,170,2.734,185,1.168,204,2.201,208,0.573,354,4.23,373,1.688,374,0.913,377,1.725,385,1.581,420,1.562,423,3.789,440,4.975,484,2.78,487,1.36,513,1.272,517,2.247,520,2.133,595,1.601,648,3.317,656,2.652,749,4.104,928,2.5,941,2.856,974,3.097,975,3.097,992,1.805,1068,3.317,1079,2.546,1117,1.367,1131,3.92,1178,3.736,1181,3.354,1206,2.713,1459,3.673,1590,2.26,1731,2.378,1962,2.942,2168,3.165,2318,2.856,2332,2.652,2343,3.831,2344,7.242,2345,3.831,2346,3.317,2347,3.831,2348,3.831,2349,3.831,2350,3.831,2351,3.831,2352,3.521,2353,3.831,2354,3.521,2355,3.831,2356,3.831]],["t/664",[6,0.077,149,3.152,155,2.644,158,2.438,168,2.255,199,3.227,204,2.087,207,2.297,208,1.676,374,1.258,383,3.032,424,3.603,513,2.675,591,3.71,592,3.17,622,2.458,1315,6.008,1590,3.032,1895,3.891,1932,4.352,2337,5.579,2357,6.659]],["t/666",[6,0.077,10,2.443,153,1.522,160,1.909,164,2.986,168,1.687,170,1.965,176,2.079,193,1.582,199,3.368,204,1.72,207,2.18,208,1.45,254,2.887,261,3.292,262,2.864,286,2.536,317,2.22,374,0.743,398,2.669,399,1.879,401,2.059,424,4.332,425,2.797,431,2.354,506,4.008,513,2.002,522,6.272,839,4.543,905,3.222,928,5.49,974,3.516,975,3.516,988,2.197,1115,3.687,1355,3.097,1502,3.584,1608,4.982,1795,5.543,1796,5.543,1994,3.068,2073,4.791,2358,7.286,2359,6.03,2360,4.791,2361,6.03]],["t/668",[6,0.077,10,4.513,80,3.208,103,4.2,153,1.564,155,2.984,158,2.593,160,1.221,168,1.734,176,2.136,179,3.5,193,1.166,204,1.267,207,1.929,208,1.471,254,2.967,286,2.606,326,4.217,333,3.634,374,0.764,382,4.497,383,2.331,410,5.621,424,2.77,431,1.734,487,2.201,575,2.086,678,2.77,739,4.29,933,2.712,988,2.258,998,2.438,1115,3.789,1131,4.043,1355,4.403,1491,3.311,1562,3.973,1745,4.76,1895,4.139,1915,3.124,1994,4.362,2261,3.973,2360,4.923,2362,5.696,2363,6.197,2364,6.197,2365,6.197,2366,6.197,2367,6.197,2368,6.197,2369,6.197,2370,6.197,2371,3.459,2372,6.197,2373,6.197,2374,6.197]],["t/670",[6,0.078,10,2.426,51,2.332,83,1.584,143,2.237,148,2.446,149,1.492,150,1.574,153,0.963,155,2.5,160,1.792,164,1.889,168,2.068,176,1.315,179,2.155,185,1.826,193,0.717,198,1.959,199,1.527,204,1.511,207,2.419,208,1.678,212,1.435,219,1.518,221,1.889,254,1.826,256,1.594,286,3.109,344,1.368,367,2.768,374,1.244,399,1.189,424,3.304,425,1.769,431,1.067,484,2.768,486,1.536,487,1.355,512,1.315,513,1.987,622,2.254,656,2.641,677,2.181,678,1.705,680,2.641,749,1.718,839,2.06,889,3.031,903,3.506,905,3.199,906,2.105,928,2.489,974,1.594,975,1.594,988,2.181,1035,2.641,1036,1.873,1132,1.923,1275,5.509,1315,2.844,1355,1.959,1420,3.152,1538,1.826,1564,1.67,1884,2.93,1895,2.89,1900,2.446,1994,1.941,2004,3.506,2314,3.506,2337,4.145,2360,4.757,2375,3.815,2376,3.815,2377,3.815,2378,3.815,2379,3.815,2380,3.506,2381,3.506,2382,3.815,2383,3.815,2384,3.815,2385,3.815,2386,3.815,2387,3.815,2388,3.815,2389,3.815,2390,3.815,2391,7.39,2392,3.815,2393,3.815,2394,3.815,2395,3.506,2396,3.031,2397,3.815,2398,3.815,2399,3.815]],["t/672",[6,0.078,10,3.506,155,2.675,158,1.227,160,1.237,165,3.195,168,2.986,176,2.165,195,3.683,199,1.624,204,2.239,207,2.324,208,1.731,316,1.826,374,1.154,485,2.124,546,3.728,575,2.114,709,2.264,967,3.095,992,1.911,998,2.47,1036,3.773,1115,3.84,1117,2.242,1170,2.411,1198,3.391,1317,3.351,1365,3.728,1564,1.775,1590,2.362,1731,2.518,1884,3.115,1885,3.222,1895,3.032,1900,4.928,2184,3.222,2261,2.601,2318,4.682,2360,3.222,2395,3.728,2400,3.728,2401,7.686,2402,5.21,2403,4.056,2404,4.056,2405,4.056,2406,7.686,2407,4.056,2408,3.728,2409,4.056,2410,4.056,2411,4.056,2412,4.056,2413,4.056,2414,4.056,2415,4.056]],["t/674",[6,0.077,10,2.619,80,2.418,153,2.228,155,3.023,168,1.809,179,4.986,185,1.972,193,1.216,199,3.534,204,2.055,207,2.43,208,1.616,254,4.226,347,2.755,374,0.797,528,4.013,591,2.976,592,2.543,942,6.11,988,2.355,998,2.543,1115,3.953,1117,2.307,1617,5.341,1718,4.013,1900,4.145,1932,5.428,2261,4.145,2313,5.942,2318,4.819,2360,7.013,2380,8.114,2381,5.942,2400,5.942,2416,5.598,2417,6.464,2418,6.464,2419,6.464,2420,6.464,2421,6.464,2422,6.464,2423,6.464,2424,6.464,2425,6.464,2426,6.464,2427,6.464]],["t/676",[6,0.078,10,2.732,32,2.61,70,2.41,80,1.242,144,3.381,149,1.299,155,3.147,160,0.654,165,1.69,167,1.134,168,3.17,176,1.849,185,1.635,193,0.625,199,1.329,207,1.517,208,1.009,212,2.017,219,2.684,226,2.655,236,1.129,261,1.813,316,1.495,374,0.954,384,1.756,385,1.371,512,1.145,559,1.876,565,3.128,595,1.388,678,2.397,730,1.552,749,2.414,928,2.167,988,1.21,995,1.495,998,1.306,1036,4.459,1115,2.031,1117,2.407,1126,1.974,1131,2.167,1405,4.668,1495,2.551,1718,2.061,1745,2.551,1836,2.129,1884,2.551,2052,3.997,2216,3.053,2261,3.438,2316,2.876,2317,2.876,2371,3.764,2402,4.571,2428,2.876,2429,2.876,2430,3.053,2431,5.362,2432,5.362,2433,2.551,2434,3.321,2435,3.321,2436,3.053,2437,3.321,2438,3.053,2439,3.321,2440,3.321,2441,2.744]],["t/679",[6,0.078,83,2.538,110,1.596,150,2.523,155,2.2,160,1.923,167,3.601,168,2.376,193,1.15,204,1.25,207,2.196,208,1.761,219,2.433,256,2.555,305,3.374,344,2.193,374,0.753,420,1.589,431,1.71,589,2.624,708,3.301,727,3.139,751,3.988,964,4.272,1118,2.814,1564,2.675,2067,4.231,2093,2.418,2239,5.293,2301,4.856,2442,6.112,2443,4.695]],["t/681",[6,0.078,49,1.873,83,1.291,110,1.619,150,2.097,155,1.928,160,0.612,167,3.427,168,1.803,170,1.013,204,1.678,207,2.258,208,1.798,256,2.693,305,2.804,365,1.993,374,0.917,377,2.902,380,1.513,388,1.993,399,0.969,420,2.29,432,1.476,532,1.046,639,1.399,663,1.216,673,1.291,708,3.48,727,2.609,744,2.387,749,2.288,751,2.028,849,1.42,961,1.488,964,3.592,966,1.188,974,3.681,975,3.681,979,2.687,985,1.847,988,1.132,992,1.464,994,3.315,995,1.399,998,2.535,1003,2.692,1037,1.873,1118,1.431,1126,1.847,1127,2.107,1129,3.375,1139,1.993,1141,2.256,1406,2.317,1530,1.777,1534,1.252,1590,1.911,1594,2.47,1673,2.387,1765,2.256,1766,2.692,1810,1.823,1831,2.317,1971,2.857,2050,1.488,2067,2.152,2093,2.01,2246,1.596,2441,2.568,2443,5.717,2444,2.692,2445,2.028,2446,4.4,2447,4.037,2448,3.108,2449,1.661,2450,2.107]],["t/683",[6,0.078,49,4.818,110,1.433,155,1.119,158,1.306,160,1.762,167,1.475,168,2.237,193,1.24,204,2.076,207,1.799,208,1.704,256,1.805,365,2.769,373,1.904,374,1.102,380,2.102,398,1.19,420,1.714,424,1.931,431,1.844,439,2.239,440,2.358,481,2.44,573,1.865,575,1.454,589,2.037,708,2.332,722,2.928,749,2.968,964,3.499,972,2.469,974,4.663,975,4.663,985,5.316,1003,5.708,1086,2.928,1128,2.681,1129,2.262,1398,1.661,1530,2.469,1534,1.739,1578,3.569,1590,2.479,1594,6.351,1643,1.633,1741,2.681,1810,2.533,1952,3.432,1953,3.317,1966,3.97,2053,2.44,2358,3.74,2445,2.818,2446,5.708,2447,5.237,2451,4.319,2452,4.319,2453,3.74,2454,3.22,2455,4.319,2456,4.319,2457,2.99,2458,4.319,2459,4.319]],["t/686",[6,0.076,83,3.071,110,1.646,185,2.256,190,3.6,204,1.512,207,1.664,208,1.445,232,3.052,374,1.325,398,2.66,399,2.305,401,3.298,420,2.796,422,3.091,423,4.664,480,3.556,486,3.889,575,2.49,799,4.742,839,3.994,964,3.237,994,4.826,1037,4.457,1117,2.64,1132,3.728,1178,3.728,1459,4.522,1590,2.782,2460,7.396,2461,10.753,2462,7.396,2463,7.396,2464,7.396,2465,7.396,2466,7.396]],["t/688",[6,0.077,83,3.202,110,1.647,160,1.051,168,2.534,170,1.737,185,1.626,190,2.595,193,1.003,204,1.09,208,1.355,232,2.201,256,4.398,398,2.732,399,2.403,401,1.821,420,2.354,428,1.821,431,1.492,622,2.351,634,2.91,708,5.683,722,5.226,727,3.959,992,3.632,994,5.03,1117,1.903,1132,2.688,1174,3.479,1225,3.818,1633,3.869,2467,4.406,2468,4.901,2469,5.332,2470,5.332,2471,5.332,2472,5.332,2473,5.332,2474,5.332,2475,5.332,2476,7.709,2477,5.332,2478,5.332,2479,6.676,2480,5.332,2481,5.332,2482,5.332,2483,5.332,2484,5.332,2485,5.332,2486,5.332,2487,5.332,2488,4.901,2489,5.332,2490,5.332,2491,5.332,2492,5.332,2493,5.226,2494,4.406,2495,4.618]],["t/690",[6,0.078,110,1.766,198,2.508,207,2.285,208,1.782,214,1.613,221,2.418,256,5.244,286,3.04,333,6.236,344,1.752,374,0.602,420,2.641,512,1.683,708,6.775,1037,2.943,1643,1.847,2093,1.932,2496,4.034,2497,4.883,2498,4.883,2499,4.883,2500,4.883]],["t/692",[6,0.077,110,1.53,167,3.85,168,2.652,170,3.089,204,1.47,207,1.618,208,1.419,256,3.004,268,2.553,305,3.968,374,1.168,401,2.455,420,2.465,428,2.455,432,3.414,575,3.191,708,3.882,727,3.692,749,3.237,1065,5.522,1225,3.56,1682,5.712,2494,5.94,2495,6.225,2501,6.608,2502,7.189]],["t/694",[6,0.077,83,2.496,110,1.421,158,1.818,168,2.93,170,2.735,185,1.833,208,0.899,214,1.986,374,1.034,398,2.884,399,3.263,401,2.052,420,2.722,422,2.512,423,3.79,428,3.575,478,4.361,575,2.023,622,3.194,751,3.922,839,3.245,860,4.966,988,2.19,1037,3.622,1129,3.147,1162,4.633,1178,3.03,1633,4.361,2503,6.01,2504,6.01,2505,6.01,2506,6.01,2507,6.01,2508,6.01,2509,8.394,2510,6.01,2511,6.01,2512,6.01,2513,6.01,2514,6.01,2515,6.01,2516,6.01,2517,5.524,2518,6.01,2519,6.01,2520,6.01,2521,6.01]],["t/696",[6,0.078,70,2.84,83,4.5,110,1.578,153,0.988,155,1.014,160,0.771,167,3.855,168,2.576,170,1.276,176,1.35,193,0.736,207,1.691,208,1.125,256,4.26,268,2.17,291,2.71,305,3.372,347,1.668,374,0.926,377,1.762,388,2.51,394,2.71,398,2.07,399,1.22,410,2.238,420,1.954,428,2.566,431,1.095,432,1.859,434,2.211,436,2.127,438,3.598,466,3.598,532,1.318,534,1.657,575,1.318,708,6.353,727,5.234,743,1.369,749,1.762,751,3.987,793,2.393,815,1.725,849,1.789,963,1.789,992,1.844,1117,1.397,1225,4.204,1242,2.238,1312,1.789,1682,4.854,2067,2.71,2273,3.11,2522,3.914,2523,3.914,2524,3.914,2525,3.914,2526,3.914,2527,3.914,2528,3.914,2529,3.914,2530,3.914,2531,3.914,2532,3.914,2533,3.914,2534,3.914,2535,3.914]],["t/698",[1,6.536,6,0.076,168,2.453,207,1.973,208,1.312,347,3.736,374,1.434,399,2.733,428,2.994,432,4.164,480,3.228,481,4.953,520,3.114,575,3.621,749,3.948,1036,4.305,1633,6.363,2536,8.768,2537,8.768,2538,8.768]],["t/701",[6,0.075,110,1.29,208,1.423,374,1.172,738,7.557,961,4.553,1915,4.795,2075,6.734,2080,5.438,2082,5.578,2086,5.904,2093,3.763,2286,5.372,2539,9.511]],["t/703",[6,0.076,110,1.7,150,3.239,168,2.808,170,2.557,207,2.258,208,1.875,232,3.239,398,2.162,420,2.609,439,4.069,440,4.284,517,4.603,730,4.691,998,3.087,1313,5.32,1643,2.968,1833,3.534,2268,4.332,2290,3.887,2540,3.993,2541,4.73,2542,7.848]],["t/705",[6,0.077,80,2.767,110,1.459,159,4.082,198,3.798,208,1.107,236,2.513,256,4.036,286,3.111,288,4.522,292,5.12,326,3.172,344,2.653,420,2.511,486,2.979,513,2.455,622,2.946,708,6.156,727,4.96,906,4.082,964,3.237,1107,5.681,1643,4.067,1996,5.513,2026,4.664,2093,2.926,2443,5.681,2543,6.798,2544,7.396,2545,6.405,2546,6.798,2547,7.396]],["t/707",[6,0.078,83,2.169,110,1.593,154,2.116,167,3.056,204,1.553,207,2.014,208,1.757,232,3.134,268,1.855,326,2.241,333,3.063,344,1.874,347,2.226,374,0.644,398,1.439,420,1.975,513,1.734,854,3.349,961,2.501,967,2.104,974,3.174,975,3.174,979,2.763,998,2.055,1037,5.922,1315,3.894,1564,2.286,1590,1.965,1643,2.872,1741,3.243,2286,2.95,2443,7.547,2449,2.791,2540,3.864,2541,3.148,2548,4.801,2549,5.223,2550,5.223,2551,4.316]],["t/709",[6,0.078,9,3.662,80,1.583,83,1.036,110,1.685,154,1.011,158,1.666,160,0.492,167,1.881,168,2.354,193,0.796,204,1.126,207,0.952,208,1.087,214,0.824,219,0.993,226,1.236,256,3.298,261,1.362,268,1.503,286,1.049,306,2.515,326,1.815,333,1.463,349,1.916,365,2.713,374,1.037,392,1.811,420,2.052,428,1.445,435,2.009,486,2.925,487,0.886,512,1.459,520,0.886,624,1.803,664,1.463,680,2.929,686,1.269,708,5.438,727,4.053,743,0.873,905,1.333,959,1.865,967,2.613,979,1.32,988,2.007,1117,0.891,1126,1.483,1127,1.691,1355,2.829,1491,1.333,1502,2.515,1538,1.195,1562,1.6,1564,1.852,1673,3.25,1682,1.982,1752,1.767,1833,1.905,1834,1.982,1836,2.713,1901,1.444,1902,1.549,1915,2.777,1920,1.6,1994,1.269,2080,2.419,2082,3.231,2268,1.377,2286,1.409,2318,3.154,2443,6.797,2541,1.504,2552,2.293,2553,2.293,2554,2.293,2555,1.628,2556,4.771,2557,2.495,2558,2.495,2559,1.767,2560,2.161,2561,2.495,2562,2.495,2563,4.231,2564,2.495,2565,2.161]],["t/711",[6,0.077,83,3.259,110,1.672,167,3.981,168,2.808,207,1.766,208,1.656,256,4.194,305,4.332,420,2.041,708,5.419,727,4.031,751,5.121,988,2.859,1564,3.435,2093,3.105]],["t/713",[6,0.078,110,1.572,149,3.017,155,1.998,167,2.634,198,3.961,207,1.736,208,1.485,286,4.174,316,3.473,374,1.352,392,5.598,486,3.107,1602,6.373,2443,5.925,2566,7.714]],["t/715",[6,0.074,2567,10.331]],["t/717",[6,0.077,155,2.653,158,3.316,159,3.701,160,1.783,168,1.876,170,2.185,185,2.045,191,2.915,193,1.261,204,1.85,207,2.036,208,1.354,236,2.279,334,5.151,374,0.826,431,1.876,480,2.469,522,4.999,589,2.072,959,2.956,967,4.125,989,2.072,1086,4.546,1132,3.38,1534,4.416,1551,5.307,2036,4.645,2189,5.25,2205,4.999,2568,3.932,2569,5.541,2570,6.706]],["t/719",[6,0.078,83,1.658,153,1.008,155,2.548,158,1.876,160,2.023,168,1.736,191,1.736,193,1.431,204,1.268,207,1.396,208,1.139,214,1.319,236,2.586,286,2.61,316,1.798,374,1.265,401,1.363,423,2.518,431,2.129,480,1.47,567,2.827,575,1.344,581,4.766,597,1.995,639,1.798,944,3.458,959,3.782,963,1.824,967,1.608,990,2.827,998,2.441,1041,1.553,1101,2.56,1117,1.425,1118,1.838,1132,2.013,1178,2.013,1225,3.768,1398,1.535,1534,1.608,1551,2.341,1731,2.479,1825,3.458,1908,2.764,1939,2.406,2036,4.462,2188,4.766,2189,4.916,2205,2.976,2318,2.976,2568,2.341,2571,3.993,2572,2.897,2573,3.067,2574,3.993]],["t/721",[6,0.076,102,3.921,155,2.051,167,2.704,168,2.215,170,3.62,176,2.73,193,1.489,231,3.268,236,2.691,377,3.565,420,2.059,431,2.215,434,4.472,484,5.746,520,2.812,639,3.565,749,4.544,849,4.611,853,5.606,1178,5.087,1287,4.772,2050,3.791,2189,3.791,2229,7.278,2575,7.918,2576,7.918,2577,5.746,2578,6.291,2579,6.081,2580,9.276,2581,5.902,2582,5.902,2583,7.918,2584,7.918]],["t/723",[6,0.077,160,1.497,190,3.697,193,1.848,200,3.115,204,2.134,207,2.014,208,1.339,236,1.775,374,1.103,398,1.439,401,1.784,431,2.504,476,1.775,480,2.796,575,1.758,631,4.342,639,2.352,815,2.302,883,4.524,988,2.767,989,2.347,998,2.055,1118,2.405,1178,2.633,1534,2.104,1590,1.965,1619,4.15,1627,5.556,1738,4.524,2097,4.801,2189,2.501,2332,3.616,2585,5.223,2586,5.223,2587,5.223,2588,4.316,2589,5.223,2590,5.223,2591,4.801,2592,5.223,2593,5.223,2594,5.223,2595,8.379,2596,5.223,2597,5.223,2598,7.595,2599,7.595,2600,7.595,2601,5.223,2602,7.595,2603,5.223,2604,7.391,2605,5.223,2606,5.223,2607,5.223,2608,5.223,2609,5.223,2610,5.223,2611,5.223]],["t/725",[6,0.077,155,2.425,168,3.132,344,3.359,420,2.434,2049,4.482,2205,6.979,2612,8.606]],["t/727",[6,0.078,98,2.628,153,2.278,155,3.053,160,1.316,168,3.298,170,2.941,203,4.529,204,2.09,214,2.982,373,2.945,383,3.395,437,5.131,512,2.303,532,2.249,589,2.064,1131,4.359,1178,3.368,1590,3.395,2062,4.213,2205,6.729,2613,5.785,2614,6.681,2615,5.785]],["t/729",[6,0.078,155,2.282,208,1.319,401,3.684,480,3.244,1041,3.426]],["t/731",[6,0.076,170,3.291]],["t/733",[6,0.078,102,2.36,149,1.864,155,1.235,168,1.334,193,1.768,204,0.974,208,0.713,219,3.377,231,3.502,236,2.413,237,6.008,261,3.875,374,0.587,420,1.239,422,1.992,431,1.987,520,1.693,522,3.553,575,1.604,581,3.661,639,2.146,670,4.381,842,3.11,849,2.178,959,3.129,967,1.919,989,1.473,998,1.875,1069,3.168,1080,3.938,1132,2.403,1170,2.833,1178,2.403,1211,3.553,1225,2.36,1287,5.113,1327,3.938,1491,3.794,1908,4.915,1994,2.425,2036,3.848,2050,2.282,2332,3.299,2433,3.661,2568,2.795,2572,5.152,2581,3.553,2582,3.553,2595,5.293,2616,4.766,2617,4.766,2618,5.866,2619,4.766,2620,4.766,2621,4.766,2622,4.766,2623,4.766,2624,4.766,2625,4.766,2626,3.661,2627,4.766,2628,4.766,2629,4.766,2630,7.1,2631,6.526,2632,6.526,2633,4.766,2634,4.766,2635,4.766,2636,7.1,2637,4.766,2638,4.381,2639,4.766,2640,4.766,2641,5.641,2642,4.766]],["t/735",[2,5.388,6,0.077,208,1.319,236,2.994,380,4.289,401,3.009,420,2.291,434,4.977,697,5.973,998,3.466,1041,3.426,1225,4.363,2036,4.893,2189,4.218]],["t/737",[6,0.077,191,4.07,374,1.154,480,3.447,2205,6.979,2643,8.606,2644,8.606]],["t/739",[6,0.077,155,2.166,167,3.566,170,2.724,176,2.882,204,1.709,236,3.549,374,1.03,377,3.764,428,2.855,434,5.899,480,3.078,624,3.562,749,4.702,849,3.82,1132,4.214,1590,3.144,2577,6.066,2578,6.642,2579,6.421,2580,7.684,2645,8.36]],["t/741",[6,0.078,155,1.77,158,2.772,170,2.227,204,1.874,334,5.249,344,2.451,374,0.842,522,5.094,639,3.077,664,4.007,952,5.094,963,3.122,1101,4.381,1534,3.691,1551,5.375,2189,3.271,2332,4.73,2577,4.959,2579,5.249,2644,6.281,2646,6.833,2647,6.833,2648,6.281,2649,9.165,2650,6.833,2651,6.833,2652,5.918,2653,5.918,2654,6.833,2655,6.281]],["t/743",[6,0.074,98,3.664,185,2.841,374,1.148,505,4.695,589,2.878,727,4.783,960,5.084,961,4.459,1006,5.782,1086,6.313,1155,5.536,1534,3.751,1759,7.695,2189,4.459,2569,7.695,2656,9.314,2657,8.561,2658,9.314]],["t/745",[6,0.073]],["t/747",[6,0.076,168,2.794,1118,4.597,2659,9.987]],["t/749",[6,0.074,380,4.972,422,4.269,1132,5.149]],["t/751",[6,0.077,204,1.793,231,3.619,398,2.963,420,2.28,506,5.828,967,3.531,1041,4.183,2660,9.887,2661,8.768,2662,7.245,2663,8.06,2664,8.768,2665,8.768,2666,8.768]],["t/753",[6,0.077,168,3.207,170,3.433,204,1.733,208,1.269,231,4.348,321,5.263,384,6.062,399,3.284,635,4.679,967,3.414,1041,3.297,1312,3.874,1336,6.003,2662,7.005,2663,7.793,2667,8.478,2668,8.478]],["t/755",[6,0.077,155,3.06,167,2.298,168,3.305,185,2.767,231,4.732,377,3.031,380,3.276,434,3.802,437,6.968,439,3.49,440,4.952,697,6.15,749,3.031,750,4.563,967,2.711,1171,4.474,2168,5.561,2662,7.496,2669,6.731,2670,6.731,2671,6.731,2672,6.731,2673,6.731,2674,6.731,2675,6.731,2676,6.731,2677,6.731,2678,6.731]],["t/757",[6,0.076,185,2.598,204,1.742,231,4.741,236,3.591,718,4.6,967,4.256,1225,5.689,2036,3.864,2189,5.059,2568,4.996,2577,6.182,2579,6.543,2662,7.038,2679,8.518,2680,8.518,2681,8.518,2682,8.518]],["t/759",[6,0.076,155,2.166,160,2.058,170,2.724,193,1.964,344,2.999,374,1.287,401,2.855,431,2.922,486,3.367,513,2.775,659,5.038,665,6.421,1086,7.721,1897,6.642,1915,4.214,2189,4.002,2371,4.667,2683,8.36,2684,8.36,2685,6.066,2686,5.919]],["t/761",[6,0.077,193,1.779,1895,4.567,2093,3.743,2189,4.529,2245,5.873,2569,9.305]],["t/763",[6,0.076,185,2.932,207,2.163,208,1.439,344,3.449,961,4.602,998,3.781,1534,3.871,1811,6.654,2189,4.602]],["t/765",[6,0.077,158,3.177,168,2.361,176,2.909,185,2.574,204,1.725,208,1.572,398,2.324,399,2.63,506,5.609,512,2.909,905,4.509,1041,4.085,1117,3.012,1534,3.398,1551,4.949,1745,6.482,1928,4.293]],["t/768",[6,0.077,155,2.196,170,2.763,193,1.595,431,2.372,849,3.874,853,6.003,1287,5.11,2036,3.845,2189,5.044,2581,6.32,2582,6.32]],["t/770",[6,0.078,80,2.616,155,2.71,158,2.115,167,3.572,168,1.957,176,2.411,185,2.133,204,2.139,214,2.31,236,3.163,512,2.411,749,3.149,1534,2.816,1551,4.101,2036,3.172,2577,5.074,2579,5.371,2581,5.213,2582,5.213,2652,6.056,2653,6.056,2655,6.428,2687,6.428,2688,6.428,2689,6.993,2690,5.778,2691,6.056,2692,6.056,2693,6.993,2694,6.993]],["t/772",[6,0.077,849,4.046,1287,5.336,2036,4.016,2050,4.239,2188,6.801,2189,4.239,2577,6.425,2581,6.601,2582,6.601,2695,8.854,2696,8.854,2697,7.668,2698,8.854]],["t/774",[6,0.077,158,2.357,160,1.066,165,2.754,193,1.018,214,2.575,256,2.262,261,2.954,410,3.094,422,3.816,431,1.514,570,4.3,831,3.597,860,6.439,929,4.35,1036,4.483,1117,1.932,1178,2.728,1185,5.855,1211,7.892,1225,2.68,1432,4.687,1471,7.447,1534,2.18,1673,4.157,2273,4.3,2568,3.174,2604,5.518,2691,6.749,2692,6.749,2699,7.793,2700,7.793,2701,6.908,2702,3.928,2703,5.412,2704,9.131,2705,7.793,2706,5.412,2707,5.412,2708,5.412,2709,5.412,2710,6.439,2711,5.412,2712,5.412,2713,5.412,2714,5.412,2715,5.412,2716,5.412,2717,5.412,2718,5.412,2719,5.412,2720,5.412,2721,5.412,2722,7.163,2723,7.163,2724,5.412,2725,5.412,2726,5.412]],["t/776",[6,0.077,165,4.176,176,2.83,226,4.064,256,3.43,512,2.83,817,6.521,929,4.582,1117,2.929,1211,6.118,1562,5.262,2036,3.722,2061,6.118,2188,6.304,2691,8.94,2692,8.94,2701,5.355,2722,7.544,2723,7.544,2727,8.207,2728,8.207]],["t/778",[6,0.078,102,3.09,291,4.319,422,3.601,512,2.151,817,6.845,849,4.509,853,8.379,1036,4.229,1206,4.418,1211,4.651,1287,5.192,1491,4.603,2327,5.404,2581,8.607,2582,8.607,2652,5.404,2653,5.404,2701,6.438,2729,6.24,2730,6.24,2731,5.404,2732,8.615,2733,6.24,2734,6.24,2735,6.24,2736,6.24,2737,6.24,2738,6.24]],["t/780",[6,0.078,123,6.346,154,3.112,155,2.564,160,1.513,191,3.339,204,1.57,207,2.227,208,1.481,236,2.61,401,2.623,486,3.093,849,3.509,1398,2.953,2036,3.484,2189,5.537,2205,5.726,2581,5.726,2582,5.726,2739,6.651]],["t/782",[6,0.074,2740,10.331]],["t/784",[6,0.078,98,2.097,155,1.381,160,1.784,193,1.98,204,2.028,207,2.232,208,1.485,236,3.371,256,3.222,286,2.243,305,2.943,344,1.913,354,2.688,373,2.35,374,0.95,431,2.945,480,2.838,505,3.886,589,2.798,591,2.455,592,2.097,933,2.334,959,2.35,964,2.334,988,1.943,1118,2.455,1225,3.818,1564,2.334,1828,3.869,1939,3.213,2050,4.75,2268,2.943,2568,3.127,2701,5.03,2702,5.594,2741,6.268,2742,6.361,2743,5.896,2744,4.096,2745,5.332,2746,4.236]],["t/786",[6,0.078,7,1.49,41,0.961,79,2.352,110,0.233,143,1.796,144,1.085,149,0.673,150,0.71,153,0.434,155,1.652,158,0.52,160,1.534,167,0.588,168,1.61,193,1.2,196,1.283,204,1.932,207,2.17,208,1.516,214,1.012,231,1.708,232,0.71,236,2.645,237,1.218,256,1.729,279,2.53,305,2.284,316,0.775,319,0.792,344,1.485,347,1.763,359,1.491,369,2.433,373,1.35,374,0.959,377,0.775,382,1.249,387,2.7,398,0.474,420,0.447,422,1.28,424,0.769,431,1.158,433,1.009,480,0.633,487,1.088,494,1.558,513,1.666,528,1.068,575,1.031,581,1.322,639,0.775,730,0.804,749,3.322,761,1.218,849,3.556,853,1.218,942,1.191,959,2.213,961,0.824,964,2.197,967,2.569,971,1.191,988,0.627,989,0.532,992,0.811,998,2.509,1006,1.068,1036,0.845,1038,1.322,1041,1.191,1069,1.144,1117,1.477,1118,1.41,1132,0.867,1170,1.023,1174,1.123,1178,1.544,1192,2.352,1198,2.235,1206,1.218,1225,4.679,1242,0.984,1258,1.283,1287,1.846,1348,1.582,1394,1.422,1399,1.367,1534,0.693,1551,1.009,1565,1.068,1567,1.009,1590,1.152,1611,0.929,1643,0.651,1646,1.582,1673,1.322,1731,1.068,1832,4.573,1833,2.591,1891,0.867,1895,0.831,1901,0.996,1908,1.191,1920,1.103,1939,1.846,1983,1.166,2036,3.53,2049,0.824,2050,1.981,2052,1.283,2141,1.422,2154,2.433,2189,3.054,2268,2.771,2301,1.367,2332,1.191,2341,1.037,2352,1.582,2445,1.123,2493,2.076,2555,1.123,2572,1.249,2573,1.322,2595,6.07,2626,1.322,2687,1.582,2688,1.582,2701,3.275,2702,4.177,2731,1.49,2741,3.984,2742,4.433,2743,2.984,2746,2.433,2747,1.582,2748,1.322,2749,3.804,2750,1.721,2751,2.652,2752,1.721,2753,2.815,2754,1.582,2755,1.721,2756,1.582,2757,2.652,2758,1.582,2759,1.582,2760,1.582,2761,1.582,2762,1.582,2763,1.582,2764,1.49,2765,2.815,2766,1.582,2767,1.721,2768,1.721,2769,1.367,2770,1.582,2771,1.367,2772,1.49,2773,1.721,2774,1.721,2775,1.721,2776,1.582,2777,1.721,2778,1.582,2779,1.721,2780,1.721,2781,1.582,2782,2.433,2783,1.582,2784,1.49,2785,1.422,2786,1.218,2787,1.144,2788,1.283,2789,1.422,2790,1.582]],["t/789",[6,0.077,102,4.287,160,1.238,165,3.197,167,2.956,168,1.758,170,2.821,190,3.059,231,4.62,256,2.626,262,2.984,384,3.323,385,2.593,388,4.029,401,2.145,408,4.826,420,1.634,432,4.703,436,2.188,439,3.258,440,4.725,520,2.231,635,3.468,708,3.393,727,3.227,749,2.829,988,2.289,998,2.472,1067,4.992,1162,3.468,1169,4.826,1181,4.833,1185,4.029,1208,5.441,1215,5.776,2268,3.468,2517,5.776,2618,8.183,2748,4.826,2771,6.878,2791,4.35,2792,7.957,2793,6.283,2794,6.283,2795,6.283,2796,6.283,2797,6.283,2798,6.283,2799,6.283,2800,6.283,2801,6.283,2802,6.283,2803,6.283,2804,6.283,2805,6.283,2806,6.283,2807,6.283,2808,6.283,2809,6.283,2810,6.283,2811,6.283,2812,6.283,2813,6.283,2814,6.283,2815,6.283,2816,6.283]],["t/791",[6,0.077,12,4.713,102,2.825,153,1.44,155,1.478,190,2.777,193,1.522,204,1.166,208,1.407,231,3.88,236,2.75,256,2.384,261,3.114,347,2.431,383,2.146,431,1.596,565,2.646,599,4.532,727,2.93,849,2.607,1041,2.218,1048,4.532,1069,3.792,1080,4.713,1181,3.185,1185,6.029,1225,2.825,1429,6.029,1491,3.048,1567,3.345,1590,3.043,1908,5.601,2050,2.731,2189,4.502,2272,4.713,2273,4.532,2332,3.949,2433,4.382,2572,5.872,2595,4.253,2626,4.382,2638,5.244,2741,3.949,2749,5.244,2756,5.244,2757,7.007,2758,5.244,2759,5.244,2760,5.244,2761,5.244,2762,5.244,2763,5.244,2764,4.94,2765,5.244,2766,5.244,2771,4.532,2792,5.244,2817,5.705,2818,5.705,2819,5.705,2820,8.091,2821,5.705,2822,5.705,2823,5.705,2824,5.705,2825,5.705,2826,5.705,2827,5.705,2828,5.705,2829,5.705,2830,4.94,2831,5.705,2832,5.705,2833,5.244]],["t/793",[6,0.076,155,2.328,220,6.522,256,4.564,513,2.983,1225,4.451,2011,5.668,2036,4.076,2268,6.027,2568,5.271,2702,6.522,2741,6.222,2744,6.903,2783,10.038,2834,8.987]],["t/795",[6,0.078,7,3.112,41,2.006,158,1.087,193,1.074,230,2.629,231,2.933,232,2.357,236,1.221,237,2.544,256,3.932,261,3.117,279,7.301,305,3.152,422,3.384,431,1.005,494,1.828,510,2.054,573,1.552,639,1.618,799,3.662,831,3.796,849,2.61,992,1.693,1170,2.136,1185,2.304,1192,4.387,1202,2.544,1206,2.544,1225,3.52,1327,2.969,1429,2.304,1471,4.258,1491,1.92,1567,2.107,1833,3.646,1908,2.487,1939,3.442,2036,3.224,2050,1.72,2126,2.08,2154,2.855,2189,2.734,2301,2.855,2332,2.487,2433,2.76,2479,3.112,2493,3.871,2568,2.107,2572,2.608,2573,2.76,2595,6.037,2626,4.387,2643,3.303,2701,6.68,2702,5.158,2731,3.112,2741,4.92,2743,2.136,2744,2.76,2753,5.25,2757,3.112,2764,4.946,2778,3.303,2781,5.25,2782,4.538,2830,8.148,2835,3.593,2836,3.593,2837,3.593,2838,3.593,2839,3.593,2840,3.593,2841,3.593,2842,3.593,2843,3.593,2844,3.593,2845,3.303,2846,3.593,2847,3.593,2848,3.593,2849,2.76,2850,3.593,2851,3.593,2852,3.593,2853,3.593,2854,3.593,2855,3.593,2856,3.593,2857,3.593,2858,3.593,2859,5.711,2860,3.593,2861,3.593,2862,3.593,2863,3.593,2864,3.593,2865,3.593,2866,3.303]],["t/797",[6,0.077,41,3.62,79,3.247,153,1.067,155,1.68,168,1.183,170,1.378,176,1.458,193,1.484,200,1.734,204,0.864,214,2.142,230,3.631,236,2.204,247,2.711,252,3.152,254,2.024,256,3.697,261,2.308,264,3.152,485,2.214,513,1.403,639,1.903,839,2.283,849,2.963,933,4.176,988,1.54,1036,3.873,1078,4.025,1162,2.333,1185,2.711,1225,3.211,1429,5.058,1471,6.594,1567,2.479,1833,1.903,2050,2.024,2053,2.388,2123,3.661,2126,2.447,2268,5.557,2357,3.493,2488,5.961,2697,3.661,2701,5.772,2702,3.068,2741,4.489,2742,5.058,2748,3.247,2833,3.886,2845,3.886,2849,4.981,2867,4.228,2868,3.661,2869,4.228,2870,4.228,2871,5.961,2872,4.228,2873,6.484,2874,4.228,2875,6.484,2876,4.228,2877,4.228,2878,4.228,2879,4.228,2880,4.228,2881,4.228,2882,4.228,2883,4.228,2884,4.228,2885,4.228,2886,4.228,2887,4.228,2888,4.228,2889,4.228,2890,4.228,2891,4.228,2892,7.251,2893,4.228,2894,4.228,2895,6.484,2896,4.228,2897,4.228,2898,4.228,2899,4.228,2900,4.228,2901,4.228,2902,3.661,2903,4.228,2904,4.228,2905,4.228,2906,3.068,2907,4.228,2908,4.228,2909,6.484,2910,4.228,2911,4.228,2912,4.228,2913,4.228,2914,4.228,2915,4.228,2916,4.228,2917,4.228,2918,4.228,2919,4.228,2920,4.228,2921,6.484,2922,4.228,2923,4.228,2924,4.228,2925,4.228,2926,4.228,2927,4.228,2928,4.228,2929,3.661,2930,4.228,2931,4.228,2932,4.228,2933,4.228,2934,4.228,2935,3.886,2936,3.661,2937,4.228,2938,4.228,2939,4.228,2940,4.228,2941,4.228,2942,3.359,2943,4.228]],["t/799",[6,0.078,160,1.533,193,1.463,204,1.591,256,3.252,337,5.509,849,4.56,992,3.666,1567,4.563,1901,4.504,2011,4.907,2036,3.529,2701,5.077,2849,5.976,2944,9.173,2945,7.78,2946,7.78,2947,7.78]],["t/801",[6,0.078,83,1.466,129,2.018,164,1.748,193,1.059,204,1.791,212,2.118,214,1.86,236,1.913,256,1.475,298,3.057,299,2.916,300,2.043,308,2.393,319,2.592,385,1.457,410,2.018,422,1.475,516,2.561,545,4.652,559,1.994,575,1.188,639,1.589,645,3.391,678,3.14,799,3.61,831,3.743,933,2.465,967,1.422,1126,2.098,1170,3.347,1319,6.457,1495,2.711,1746,3.057,1810,2.07,1833,1.589,1836,2.263,2011,5.056,2126,5.071,2154,5.581,2268,5.614,2565,3.057,2701,2.303,2751,3.057,2849,5.395,2866,3.245,2906,2.561,2944,7.369,2948,8.663,2949,3.53,2950,5.631,2951,3.53,2952,3.53,2953,3.53,2954,3.53,2955,3.53,2956,3.53,2957,3.53,2958,3.53,2959,3.53,2960,3.53,2961,3.53,2962,3.53,2963,3.53,2964,3.53,2965,3.53,2966,6.457,2967,3.53,2968,3.53,2969,3.53,2970,3.53,2971,2.804,2972,3.53,2973,3.53,2974,5.631,2975,3.53,2976,5.176,2977,3.53,2978,3.53,2979,7.024,2980,5.631,2981,3.53,2982,5.631,2983,3.53,2984,5.631,2985,3.53,2986,3.53,2987,3.53,2988,3.53,2989,3.53,2990,7.024,2991,5.631,2992,3.53,2993,3.245,2994,3.53,2995,3.53,2996,3.53,2997,3.245]],["t/803",[6,0.078,155,1.567,173,3.816,193,1.586,204,1.724,207,1.898,208,1.262,221,2.996,230,2.785,236,2.056,256,2.529,340,4.999,359,2.945,476,2.056,565,2.807,845,4.51,849,2.765,959,2.667,1225,2.996,1501,5.562,1567,3.548,1920,3.88,1995,6.287,2036,4.763,2341,5.082,2701,3.948,2741,5.838,2742,7.674,2743,3.596,2744,4.647,2942,9.085,2998,5.562,2999,6.05,3000,6.05,3001,6.05,3002,6.05,3003,5.562,3004,4.999,3005,6.05]],["t/805",[6,0.077,207,1.963,208,1.306,344,3.13,513,2.896,961,4.177,1006,5.416,1527,7.556,1611,4.712,1895,4.212,2743,5.186,2784,7.556,2785,7.209,2786,6.178,2787,5.8,2788,6.504,2789,7.209,3006,8.725,3007,8.725]],["t/807",[6,0.078,153,1.586,158,1.9,159,3.468,170,2.047,208,0.94,214,2.076,219,3.445,230,2.893,254,3.008,256,2.626,264,7.956,359,3.059,367,4.56,520,2.231,905,3.357,906,3.468,1107,4.826,1833,2.829,2126,3.638,2189,4.741,2545,5.441,2641,8.479,2701,4.1,2739,5.441,2849,4.826,3008,6.283,3009,6.283,3010,4.992,3011,6.283,3012,6.283,3013,6.283,3014,6.283,3015,6.283,3016,6.283,3017,5.441]],["t/809",[6,0.077,102,2.528,150,2.107,154,2.068,155,3.024,160,1.472,167,1.743,168,2.09,170,1.663,193,1.405,204,2.114,207,2.431,208,1.67,236,3.001,256,2.133,347,2.175,377,2.298,380,2.485,388,3.273,395,4.421,420,1.327,422,2.133,431,2.09,433,2.994,437,3.921,439,2.647,440,2.786,639,2.298,727,2.622,749,4.376,750,3.46,839,2.756,967,3.008,998,2.008,1118,2.35,1178,3.765,1181,4.169,1225,4.374,1287,3.076,1567,2.994,1590,2.809,1809,3.076,1831,3.805,1939,3.076,2036,2.315,2050,3.576,2189,4.653,2346,4.421,2697,4.421,2741,3.534,2743,3.034,2771,5.934,2868,4.421,3018,4.218,3019,5.105,3020,5.105,3021,5.105]],["t/812",[6,0.076,158,2.691,176,3.068,185,2.714,191,3.868,199,3.562,207,2.002,208,1.332,212,3.347,374,1.443,505,4.486,513,2.953,589,2.749,929,4.968,961,4.26,972,5.087,1895,4.295,2786,6.301,3022,5.806]],["t/814",[6,0.077,41,3.609,80,3.302,153,1.631,155,1.674,176,3.465,185,1.972,204,2.208,214,2.136,254,3.095,256,2.702,264,4.819,298,5.598,299,5.341,326,4.633,340,5.341,433,3.791,513,2.146,678,2.89,730,3.022,905,3.454,906,3.568,967,2.603,1287,3.896,1469,4.691,1535,4.218,1564,2.83,2036,2.932,2189,3.095,2742,6.925,2743,5.974,2786,4.577,2902,5.598,2942,7.013,2998,5.942,3023,6.464,3024,6.464,3025,6.464,3026,6.464,3027,6.464,3028,6.464,3029,6.464,3030,5.942,3031,6.464,3032,6.464,3033,5.136,3034,6.464,3035,6.464,3036,5.942,3037,6.464,3038,6.464,3039,6.464]],["t/816",[6,0.077,150,3.311,204,2.081,487,2.85,730,3.751,909,5.06,988,3.708,1564,4.455,1895,3.873,1915,4.045,2742,7.167,2743,6.987,3040,8.024,3041,8.024,3042,8.024]],["t/819",[6,0.077,207,1.973,208,1.312,317,3.228,342,5.443,374,1.081,398,2.415,401,2.994,513,2.91,592,3.449,1181,4.895,1451,5.943,1611,4.735,1718,5.443,2743,5.211,2784,7.593,2785,7.245,2786,6.208]],["t/821",[6,0.076,10,3.021,153,1.882,155,1.932,164,3.693,176,3.348,185,2.275,193,1.403,204,2.207,214,2.464,231,3.078,254,3.57,286,3.137,326,3.199,431,2.087,433,4.373,678,3.334,904,5.728,905,3.985,906,5.359,967,3.003,1178,3.759,1287,4.494,1535,4.866,1564,3.264,2036,4.404,2189,3.57,2261,4.782,2341,5.852,2742,6.226,2743,5.771,2942,5.925,3030,6.855,3043,7.457,3044,9.71,3045,7.457,3046,7.457,3047,9.71,3048,6.855,3049,6.162,3050,7.457,3051,7.457,3052,7.457]],["t/823",[6,0.077,155,2.651,176,2.791,193,1.523,204,2.093,207,1.822,208,1.212,431,2.265,513,2.687,730,3.785,942,5.605,988,2.95,1181,4.52,1831,6.035,1887,7.442,2011,5.106,2341,4.879,2742,7.197,2743,4.812,2786,5.733,3018,6.689,3053,8.096,3054,8.096,3055,8.096,3056,7.442]],["t/826",[6,0.077,150,3.824,207,2.085,208,1.387,344,3.324,374,1.142,1006,5.752,2743,5.507,2787,6.159,2788,6.907,2789,7.656]],["t/828",[6,0.075,10,4.307,155,2.228,164,5.264,168,2.406,176,2.965,179,4.858,198,4.417,236,2.922,428,2.937,486,3.464,513,3.528,624,3.665,646,7.924,678,3.844,849,3.929,905,4.595,933,3.764,959,3.791,1733,6.606,1902,5.339,2261,5.514,2786,6.09,2789,7.106,3057,8.6,3058,7.905,3059,8.6]],["t/830",[6,0.076,176,3.053,193,1.665,204,2.212,207,1.992,208,1.325,431,2.478,730,4.139,967,3.566,1564,3.876,2341,5.336,2742,6.939,2743,5.263,3060,8.854,3061,8.854,3062,8.854,3063,8.854]],["t/833",[6,0.077,185,2.184,207,1.611,208,1.072,257,4.957,374,1.165,487,2.543,494,4.81,513,2.377,730,4.948,942,6.545,959,3.156,1006,4.445,1117,2.556,1564,3.134,2120,6.582,2121,6.582,2371,5.278,2742,7.709,2743,5.619,2785,8.745,2786,5.07,2788,7.048,3064,7.16,3065,7.16,3066,7.16]],["t/835",[6,0.078,176,2.614,185,2.313,512,2.614,730,3.545,1015,5.14,1170,4.507,1833,4.901,1836,4.862,1915,3.823,2036,3.439,2189,5.211,2402,5.14,2742,4.862,2743,5.834,2830,9.425,3067,7.583,3068,7.583,3069,6.971]],["t/837",[6,0.077,176,2.742,287,5.928,512,2.742,559,5.716,933,4.872,1181,4.44,2126,5.859,2154,6.319,2268,6.144,2565,8.764,2743,4.727,2849,6.108,2948,8.362,2966,7.31,2976,7.31,3070,7.953,3071,7.953]],["t/839",[6,0.078,41,5.59,80,2.401,155,2.789,158,1.941,176,3.452,185,1.958,207,2.253,208,1.499,512,2.213,513,2.915,1015,4.351,1032,4.961,1181,3.583,1908,4.443,2126,5.797,2189,4.794,2371,3.583,2572,4.657,2702,8.184,2742,4.115,2743,5.952,2744,4.93,2782,7.956,3072,6.418,3073,6.418,3074,6.418,3075,6.418]],["t/841",[6,0.078,158,1.962,168,2.476,204,1.809,207,1.46,208,0.971,219,2.582,236,3.007,374,0.8,513,2.153,730,3.033,749,3.984,751,4.233,793,3.967,849,2.964,1036,4.344,1117,2.316,1209,5.36,1225,4.382,1920,4.16,2011,4.091,2036,4.013,2268,3.581,2741,4.491,2742,5.674,2743,6.429,2771,7.03,2786,4.594,2942,7.03,3069,5.963,3076,6.488,3077,5.774]],["t/843",[6,0.077,83,3.149,154,3.073,155,1.964,204,2.225,207,1.706,208,1.135,236,2.577,256,4.102,374,0.935,843,5.825,933,3.319,961,3.631,1006,4.708,1225,4.861,1590,2.852,1611,4.095,1939,4.57,2011,4.782,2050,3.631,2268,5.418,2568,4.447,2701,6.405,2702,5.503,2741,6.795,2742,6.294,2743,4.507,2744,7.539]],["t/845",[6,0.074,3078,10.272,3079,10.272]],["t/847",[6,0.078,83,2.188,124,7.992,154,2.135,155,1.365,160,1.506,193,1.438,200,2.161,204,1.077,207,2.22,208,1.477,236,2.597,374,0.942,385,2.175,431,1.474,476,1.791,480,2.814,494,2.681,573,2.275,589,1.628,595,3.194,730,3.573,840,3.572,959,2.323,964,4.585,1204,4.563,1242,3.013,1502,6.699,1590,1.982,1833,5.075,1956,4.354,2746,4.187,3077,3.438,3080,6.326,3081,3.928,3082,7.809,3083,5.269]],["t/849",[6,0.078,83,2.353,124,6.485,149,1.391,150,1.468,154,2.296,155,1.468,193,1.328,195,2.086,204,1.646,207,1.979,208,1.316,219,2.255,236,3.466,250,2.733,256,3.365,344,2.033,374,1.084,383,2.131,385,1.468,387,2.321,424,1.59,431,0.995,432,2.691,480,2.965,565,1.65,573,2.447,595,2.951,651,2.463,730,2.649,743,1.245,928,2.321,959,2.497,964,4.465,967,1.433,974,2.951,975,2.951,980,2.463,985,3.368,992,3.327,1242,3.239,1502,4.786,1771,2.94,1833,5.118,1944,2.733,1953,2.733,1957,2.582,1958,3.841,1959,2.582,1960,3.081,1961,3.081,1965,6.226,2445,2.321,2746,2.827,2747,3.27,3077,2.321,3080,5.163,3081,6.555,3084,4.502,3085,4.352,3086,2.827,3087,2.733,3088,3.558]],["t/851",[6,0.077,41,3.756,124,7.102,131,3.666,160,0.874,236,2.761,250,3.408,256,1.854,291,3.071,373,1.955,374,0.829,383,1.669,424,1.983,480,2.477,595,2.812,602,3.666,645,2.142,656,4.657,743,1.552,793,2.713,849,2.027,928,2.895,951,2.895,964,3.557,973,3.219,974,5.089,975,5.089,979,2.346,985,6.098,1017,3.666,1064,2.568,1242,2.536,1502,4.83,1735,3.525,1741,5.044,1752,3.141,1833,4.944,1944,5.167,1953,5.167,1954,4.078,1957,3.219,1958,6.608,1959,3.219,1960,3.842,1961,3.842,1965,3.141,2200,3.842,2450,3.007,2555,2.895,2568,2.602,2746,3.525,3077,2.895,3080,2.845,3081,3.307,3084,3.525,3085,3.408,3086,6.456,3087,6.966,3089,4.436,3090,4.436,3091,6.727,3092,6.184,3093,4.436,3094,4.436,3095,4.436,3096,4.436,3097,6.184,3098,4.078,3099,4.436,3100,4.078,3101,4.436]],["t/853",[6,0.077,124,2.473,131,2.951,153,1.787,168,0.999,193,1.518,200,1.465,207,1.593,208,1.06,214,1.18,230,3.259,236,2.994,250,6.199,254,2.721,256,3.682,351,3.283,420,0.929,431,1.59,440,1.95,476,1.932,494,2.892,520,1.268,565,1.657,573,1.542,639,3.188,651,2.473,730,1.67,799,5.175,831,5.364,839,1.929,849,1.632,913,2.743,933,3.857,959,1.574,964,2.488,974,2.959,975,2.959,985,3.378,1036,1.754,1048,2.838,1078,2.217,1171,2.374,1193,4.125,1242,2.042,1769,3.093,1833,5.123,1862,3.093,1944,2.743,1953,2.743,1995,2.663,2050,1.71,2056,3.25,2061,2.663,2200,3.093,2268,4.863,2324,3.283,2446,3.093,2595,2.663,2971,2.838,3004,2.951,3080,6.017,3081,5.278,3084,5.625,3085,4.366,3100,3.283,3102,3.572,3103,3.572,3104,3.572,3105,5.684,3106,3.572,3107,3.572,3108,3.572,3109,3.572,3110,3.572,3111,3.572,3112,3.572,3113,3.572,3114,3.572,3115,3.572,3116,3.572,3117,3.283,3118,3.283,3119,3.572,3120,3.572,3121,3.572,3122,3.572,3123,2.743,3124,5.225,3125,3.572,3126,6.508,3127,3.572,3128,5.225,3129,4.697,3130,2.838,3131,3.572,3132,3.572,3133,3.572,3134,3.572,3135,3.572,3136,3.283,3137,7.28,3138,3.093,3139,3.572,3140,3.283,3141,3.283,3142,3.572,3143,3.572,3144,3.572,3145,3.572,3146,3.283,3147,3.283,3148,3.572,3149,3.572,3150,3.572,3151,5.225,3152,3.572,3153,3.572,3154,3.572,3155,3.572,3156,3.283,3157,3.572,3158,3.572,3159,3.283]],["t/855",[6,0.077,124,4.459,160,1.269,236,2.992,256,2.692,261,3.516,364,5.578,383,2.423,573,2.781,651,4.459,799,4.13,831,4.281,840,4.366,933,2.819,964,2.819,1132,3.247,1502,3.828,1590,2.423,1810,3.777,1833,4.517,2056,3.683,2268,3.555,3077,4.203,3081,6.564,3082,4.802,3084,5.118,3124,5.921,3126,8.094,3128,5.921,3129,8.289,3136,9.222,3137,5.322,3140,5.921,3141,9.222,3159,5.921,3160,6.441,3161,6.441,3162,6.441,3163,6.441,3164,6.441,3165,5.921,3166,6.441,3167,6.441,3168,6.441,3169,6.441,3170,6.441,3171,8.805,3172,6.441,3173,6.441,3174,6.441,3175,6.441]],["t/857",[6,0.078,41,2.559,83,1.904,129,2.621,149,1.793,167,2.354,168,2.907,170,1.494,204,0.937,236,3.663,239,3.521,321,2.845,377,3.105,385,4.08,388,2.939,410,2.621,424,3.082,510,2.621,513,1.521,573,4.269,635,2.53,697,3.107,730,4.31,799,4.421,831,4.583,845,5.14,849,5.184,913,3.521,933,4.036,1069,4.583,1174,4.499,1810,2.688,1833,3.732,2036,3.127,2268,5.089,3080,5.912,3117,4.213,3118,4.213,3137,6.849,3138,3.969,3176,4.584,3177,4.213,3178,4.213,3179,6.895,3180,4.584,3181,4.584,3182,4.584,3183,4.584,3184,4.584,3185,4.584,3186,4.584,3187,4.584,3188,4.584,3189,4.584,3190,4.584,3191,4.584,3192,4.584,3193,4.584,3194,4.584,3195,4.584,3196,4.213,3197,4.213,3198,4.584,3199,4.584,3200,4.584]],["t/859",[6,0.077,110,1.025,208,1.13,317,3.604,374,1.206,398,3.279,399,3.582,424,4.376,432,5.158,433,4.428,435,3.586,481,4.265,506,5.019,575,3.295,933,3.305,1101,4.842,1132,3.807,1312,3.45,3201,8.998,3202,6.941,3203,7.551,3204,7.551,3205,7.551,3206,7.551,3207,7.551]],["t/861",[6,0.078,41,4.34,160,1.532,199,1.654,214,1.365,230,4.346,236,3.208,247,2.648,261,2.255,286,1.737,319,4.023,364,5.516,374,0.509,385,2.629,476,1.404,520,1.467,543,3.413,573,1.784,595,1.726,639,1.86,730,1.931,743,3.057,793,2.526,839,3.439,928,2.695,933,3.403,974,1.726,975,1.726,985,2.455,988,2.321,1048,3.282,1064,5.059,1078,2.564,1403,3.282,1502,2.455,1810,4.559,1833,1.86,1994,2.101,1995,3.079,2056,2.361,2195,3.282,2268,3.516,2929,3.577,2936,3.577,2971,3.282,3004,3.413,3077,4.156,3080,6.396,3085,3.173,3137,3.413,3138,3.577,3146,3.797,3147,3.797,3151,7.146,3156,7.146,3165,3.797,3197,3.797,3208,4.13,3209,7.146,3210,4.13,3211,4.13,3212,4.13,3213,4.13,3214,4.13,3215,4.13,3216,4.13,3217,4.13,3218,4.13,3219,4.13,3220,4.13,3221,4.13,3222,4.13,3223,4.13,3224,5.855,3225,4.13,3226,4.13,3227,4.13,3228,4.13,3229,4.13,3230,4.13,3231,4.13,3232,4.13,3233,3.577,3234,4.13,3235,4.13,3236,4.13,3237,4.13,3238,4.13,3239,4.13,3240,4.13,3241,3.577,3242,3.797,3243,4.13,3244,4.13,3245,3.282]],["t/864",[6,0.077,959,4.214,1895,4.615,1932,5.163,2371,5.338,3080,6.131,3246,9.561]],["t/866",[6,0.077,10,2.821,41,2.592,82,3.689,153,1.757,160,0.915,164,3.448,179,6.114,185,1.416,199,1.859,207,1.045,208,0.695,230,3.205,236,3.378,254,3.333,262,2.205,286,1.953,315,3.369,317,1.709,326,1.991,344,1.666,347,1.978,374,1.372,398,1.279,399,1.447,424,4.148,428,1.585,432,3.306,476,1.578,494,2.362,513,3.3,559,2.622,573,2.005,575,2.812,592,1.826,659,2.798,680,4.82,839,4.51,959,2.046,1086,4.719,1112,2.882,1132,2.341,1312,2.121,1494,3.029,1798,4.021,1810,2.723,1833,3.761,1895,2.241,1902,4.322,1915,2.341,1932,3.759,1994,2.362,1995,7.411,2261,2.977,2371,3.887,2402,3.147,2685,5.052,2686,3.288,2769,3.689,3004,3.836,3077,5.45,3080,6.693,3224,4.268,3247,8.353,3248,4.021,3249,4.268,3250,4.268,3251,4.82,3252,6.4,3253,4.268,3254,3.566,3255,4.268]],["t/868",[6,0.076,41,4.325,160,1.526,207,2.239,208,1.489,250,5.95,928,5.055,964,3.391,974,5.016,975,5.016,978,7.121,979,4.097,985,4.604,998,3.047,1741,4.809,1833,4.481,1895,3.74,1944,5.95,1953,5.95,1958,6.746,1965,5.485,2060,9.148,2450,5.251,3081,5.775,3085,5.95,3098,7.121,3256,7.747,3257,7.121]],["t/870",[1,2.017,6,0.078,51,1.654,83,1.881,124,5.267,129,2.59,153,1.143,154,1.096,158,2.301,160,1.347,185,0.825,195,1.587,198,1.389,200,1.858,204,1.683,207,1.315,208,0.875,214,2.258,228,7.138,236,3.514,250,3.48,321,6.106,326,2.507,374,0.938,385,2.412,424,1.209,428,1.547,432,1.285,494,2.973,512,2.356,573,3.285,575,0.911,595,1.131,651,3.136,677,3.341,678,1.209,686,2.305,730,3.557,743,2.879,747,2.235,838,2.017,942,1.873,952,2.017,966,2.613,967,1.09,998,2.299,1064,4.764,1117,1.617,1132,1.364,1345,2.343,1383,2.017,1494,3.813,1502,4.062,1590,1.018,1833,4.55,1895,1.306,1902,2.812,1932,2.446,1965,1.916,2236,2.343,2371,3.262,2438,2.487,2769,2.15,3077,6.594,3080,6.109,3081,6.515,3082,8.727,3245,2.15,3251,1.873,3257,2.487,3258,2.706,3259,2.706,3260,5.844,3261,2.706,3262,2.706,3263,2.706,3264,2.487,3265,4.53,3266,2.706]],["t/873",[6,0.078,129,1.868,158,2.017,167,1.115,168,2.357,185,0.996,193,1.254,214,2.533,230,1.504,231,1.348,236,3.927,309,2.829,315,3.839,326,2.269,362,2.699,385,4.215,387,2.131,424,1.46,428,1.115,432,4.694,512,1.824,567,2.313,573,4.41,635,5.239,680,2.261,743,1.143,793,3.235,845,3.944,849,2.417,864,7.293,913,4.064,928,2.131,974,1.365,975,1.365,985,1.941,1036,1.604,1064,1.891,1078,2.028,1117,2.38,1225,3.302,1403,2.595,1833,1.471,2258,8.725,2371,1.824,2577,5.563,2578,2.595,2579,6.469,3077,7.139,3080,4.915,3085,2.509,3177,3.003,3178,4.863,3267,7.666,3268,3.266,3269,3.266,3270,3.266,3271,3.266,3272,3.003]],["t/875",[6,0.077,80,2.837,153,1.914,154,3.073,158,2.293,176,2.614,207,1.706,208,1.135,236,2.577,254,3.631,321,4.708,326,3.253,374,1.21,432,5.169,512,2.614,565,3.518,575,3.304,1132,3.823,1494,4.948,1833,3.414,1932,4.095,2371,4.233,3077,4.948,3082,5.653,3273,6.025]],["t/877",[6,0.078,41,4.892,80,2.392,158,2.65,167,2.992,193,1.203,200,2.623,236,3.828,321,5.439,326,3.758,432,4.161,494,3.254,512,2.205,1117,2.283,1287,7.011,1810,5.139,1836,4.101,1932,3.453,2088,5.538,2268,3.53,2371,3.57,3077,7.35,3080,5.618,3082,6.532,3274,6.395,3275,6.395]],["t/879",[6,0.078,124,6.932,150,2.649,154,2.6,160,1.265,193,1.207,207,2.538,208,1.688,236,2.181,374,1.083,424,3.927,480,2.363,575,2.16,840,4.351,964,3.845,1494,4.188,1502,5.952,1833,5.078,1895,3.098,1957,4.657,1958,4.351,1959,4.657,1965,6.22,2339,5.9,3077,4.188,3080,5.632,3082,4.784]],["t/881",[6,0.078,10,2.555,158,1.907,207,1.953,208,1.299,236,2.949,287,4.7,319,2.903,326,2.705,385,2.602,494,3.208,510,3.605,730,2.948,1225,4.297,1833,4.812,2092,5.796,2371,3.52,2751,5.46,3077,5.662,3080,5.564,3082,7.396,3276,6.305,3277,6.305,3278,6.305,3279,6.305]],["t/883",[6,0.074,3280,10.331]],["t/885",[6,0.077,83,2.504,110,0.818,154,2.443,155,2.959,159,3.328,160,2.066,167,2.873,168,1.687,169,3.256,170,1.965,193,1.582,204,1.233,207,2.18,208,1.45,214,1.992,374,0.743,377,2.715,398,1.661,431,2.354,436,2.099,565,3.903,584,2.776,595,4.05,655,3.584,678,2.696,743,2.11,1086,4.088,1118,2.776,1129,4.405,1130,3.366,1132,3.04,1312,2.755,1521,3.013,1674,4.498,1793,4.495,2039,3.491,2053,3.406,2246,5.866,3281,4.791,3282,4.791,3283,4.632,3284,5.543,3285,4.495]],["t/887",[6,0.078,57,2.457,110,1.197,155,2.797,158,1.273,159,2.322,160,2.062,167,2.686,168,1.808,169,2.272,170,1.371,193,1.479,204,1.608,207,2.142,208,1.425,214,2.135,268,1.494,375,2.121,398,1.78,420,1.68,431,1.808,436,2.249,490,3.343,504,3.343,520,1.494,565,3.648,584,1.937,589,1.3,595,3.287,622,1.283,655,2.501,678,1.881,743,1.472,749,1.895,1027,2.297,1117,1.502,1118,1.937,1125,3.477,1129,3.383,1130,3.607,1132,3.257,1398,1.618,1521,2.102,1565,2.612,1590,2.43,1600,2.852,1674,4.75,1706,3.868,1793,3.137,1891,3.257,1932,2.272,2039,5.108,2246,5.546,2290,2.084,2416,3.644,3281,3.343,3282,5.133,3283,4.963,3285,3.137,3286,3.868,3287,6.249,3288,4.208,3289,4.208,3290,3.868]],["t/891",[6,0.077,32,2.716,110,1.453,155,2.063,167,1.905,168,3.117,170,3.491,193,1.05,207,1.256,208,1.192,231,3.834,268,1.982,388,3.578,398,2.194,411,3.641,415,4.286,420,1.451,431,1.561,485,2.922,486,3.208,520,1.982,534,2.362,589,1.724,635,5.127,676,3.115,730,2.609,743,1.952,839,3.013,1041,2.17,1129,4.171,1178,4.016,1183,4.286,1312,2.55,1429,3.578,1459,3.412,1471,5.938,1633,4.05,1674,4.345,2035,5.514,2039,3.231,2246,4.091,2357,4.611,3003,7.322,3281,4.434,3291,5.58,3292,6.898,3293,5.58,3294,5.58,3295,5.13,3296,5.58,3297,7.966,3298,7.966,3299,4.286,3300,5.58,3301,4.16,3302,5.58,3303,5.58,3304,5.13,3305,5.58,3306,5.58,3307,5.58]],["t/893",[6,0.078,32,1.573,83,1.342,102,2.597,110,1.217,155,2.169,167,3.474,168,2.131,170,1.709,193,1.245,207,0.727,208,0.484,223,2.148,226,1.6,231,2.732,256,1.35,261,1.764,262,2.491,318,4.582,365,2.072,385,2.732,398,2.307,410,1.847,411,2.108,420,0.84,431,1.467,432,1.535,436,1.125,485,1.692,520,1.148,565,2.433,595,2.766,635,3.653,676,1.804,708,1.745,727,1.659,743,1.835,851,5.732,933,2.296,993,2.038,1032,2.962,1129,2.746,1130,1.804,1297,2.567,1312,3.827,1429,4.884,1659,2.798,1674,2.249,2035,2.237,2126,1.871,2246,3.399,2251,2.798,2290,1.6,3123,2.482,3292,4.542,3299,2.482,3304,7.698,3308,3.231,3309,3.231,3310,3.231,3311,3.231,3312,3.231,3313,3.231,3314,3.231,3315,3.231,3316,5.244,3317,3.231,3318,5.244,3319,3.231,3320,5.244,3321,3.231,3322,3.231,3323,3.231,3324,5.244,3325,3.231,3326,3.231,3327,3.231,3328,5.244,3329,3.231,3330,3.231,3331,3.231,3332,3.231,3333,5.244,3334,3.231,3335,3.231,3336,3.231,3337,3.231,3338,6.619,3339,3.231,3340,3.231,3341,3.231,3342,3.231,3343,3.231,3344,3.231,3345,3.231,3346,3.231,3347,3.231,3348,3.231,3349,3.231,3350,3.231,3351,8.375,3352,3.231,3353,3.231,3354,3.231,3355,3.231,3356,3.231,3357,3.231,3358,3.231,3359,3.231,3360,3.231,3361,3.231,3362,3.231,3363,3.231,3364,3.231,3365,3.231,3366,3.231]],["t/895",[6,0.077,32,4.356,57,3.403,98,2.055,110,1.333,149,2.043,155,2.545,168,2.125,170,1.702,193,0.982,207,1.175,208,0.782,219,3.562,231,3.693,374,0.644,375,2.633,398,1.439,411,3.408,420,2.327,428,1.784,431,1.462,436,3.116,485,3.977,486,2.104,589,1.614,590,4.12,592,2.055,622,1.593,635,4.192,748,4.285,767,4.524,799,3.349,815,3.348,831,3.472,845,3.894,851,6.577,960,2.851,1055,2.986,1129,2.735,1178,3.829,1242,2.986,1336,3.699,1429,3.349,1459,4.644,1674,2.241,2035,3.616,2246,3.901,3292,4.524,3295,4.801,3299,4.012,3367,5.223,3368,4.801,3369,4.801,3370,5.223,3371,7.595,3372,5.223,3373,5.223,3374,5.223,3375,5.223,3376,5.223,3377,5.223,3378,5.223,3379,5.223,3380,5.223,3381,5.223,3382,5.223,3383,5.223,3384,5.223,3385,5.223,3386,5.223,3387,5.223,3388,5.223,3389,5.223]],["t/897",[6,0.076,110,1.251,155,2.388,160,2.185,167,3.148,344,3.307,374,1.136,375,4.647,565,4.276,589,2.848,595,3.852,1674,3.954]],["t/899",[6,0.077,110,1.14,155,2.176,167,2.868,168,2.931,169,5.656,170,2.737,193,1.58,204,1.717,207,1.89,208,1.257,431,2.35,490,6.673,504,6.673,565,3.896,595,3.51,635,4.636,998,3.304,1041,3.266,3299,6.451]],["t/901",[6,0.077,110,1.14,167,3.576,207,1.89,208,1.708,223,5.583,232,4.323,374,1.291,398,2.313,565,4.859,589,2.595,595,4.77,1086,5.693,1129,4.398,1130,4.689,1611,4.535,1932,4.535,2540,5.329]],["t/905",[6,0.077,10,2.707,80,2.499,98,2.628,110,1.225,153,1.686,155,2.338,159,3.687,160,1.316,164,3.308,168,2.526,170,2.177,176,2.303,179,5.099,185,2.038,193,1.257,204,1.366,207,1.503,208,1,232,2.757,236,2.27,288,4.085,365,4.284,431,1.869,486,2.691,520,2.373,528,4.147,624,2.847,678,2.986,718,3.607,1036,3.28,1439,5.131,1469,4.848,1494,4.359,1496,5.785,1534,2.691,1674,4.385,1793,4.98,2039,5.226,2195,5.308,2246,4.636,2261,4.284,3281,5.308,3282,5.308,3287,5.308,3390,6.681,3391,6.681,3392,6.681,3393,6.681,3394,6.681,3395,6.681,3396,6.141,3397,6.681,3398,6.681,3399,6.681,3400,6.141]],["t/907",[6,0.077,155,2.753,167,2.937,176,3.665,226,4.259,565,3.989,595,3.594,1117,3.794,1534,3.464,1891,4.335,2035,5.953,2246,5.459,3287,8.445,3400,7.905]],["t/909",[6,0.077,155,2.249,204,2.186,207,1.954,208,1.3,214,3.533,512,2.994,1129,4.547,1398,3.339,1674,3.725,2039,5.027,2246,5.491,3283,6.67,3401,8.683]],["t/912",[6,0.077,32,4.032,57,3.15,102,4.102,149,3.239,155,2.146,198,4.254,420,2.154,428,2.828,434,4.678,436,3.615,584,3.813,590,3.813,641,6.174,655,4.923,748,3.965,845,6.174,965,7.173,1055,4.735,1129,4.337,1994,4.214,2246,4.254,3285,6.174,3368,7.614,3369,7.614,3402,8.283]],["t/914",[6,0.077,102,3.921,149,3.097,154,3.208,155,2.614,160,1.56,185,2.415,204,1.619,436,2.757,584,4.646,589,2.446,655,4.706,748,3.791,1110,4.643,1612,8.018,1697,7.278,2246,5.705,3283,6.081,3285,5.902,3403,7.918,3404,7.918,3405,7.918,3406,7.918]],["t/917",[6,0.076,168,3.191,170,3.149,204,1.976,3285,7.204]],["t/919",[6,0.077,106,9.25,155,2.042,167,3.988,185,2.404,319,4.633,512,2.718,565,5.142,595,4.633,919,6.055,1491,4.212,1547,4.685,1906,9.25,2246,4.048,3407,7.883,3408,7.883]],["t/921",[6,0.077,155,2.659,179,4.594,193,1.53,204,1.663,207,1.83,208,1.217,268,2.888,315,5.902,431,2.276,990,7.268,991,8.481,1398,3.127,1733,6.247,1994,4.138,2246,4.177]],["t/924",[6,0.076,57,3.452,169,4.902,180,5.821,193,1.708,199,3.634,207,2.043,208,1.359,374,1.119,396,7.501,431,2.54,487,3.224,490,7.213,504,7.213,557,6.973,1091,7.501,1611,4.902,1932,4.902]],["t/926",[6,0.076,167,3.164,208,1.387,232,3.824,565,4.298,595,3.872,1118,4.265,1932,5.003,2416,8.024,2540,4.714,3290,8.517,3409,9.265,3410,8.517,3411,9.265,3412,9.265]],["t/928",[6,0.077,155,2.146,167,2.828,193,1.558,204,1.693,214,2.736,431,2.318,436,2.884,565,3.842,584,3.813,595,3.462,655,4.923,743,2.898,748,3.965,1130,4.624,1521,4.138,1674,3.553,1891,5.234,2246,5.332,3283,6.362,3285,6.174,3287,6.581,3413,8.283,3414,8.283]],["t/930",[6,0.074,3415,10.331]],["t/932",[6,0.078,57,3.721,134,5.225,155,2.904,160,1.755,168,1.449,176,1.785,191,2.251,193,1.42,204,2.001,219,2.061,268,1.839,291,3.585,348,4.839,359,2.521,380,2.521,381,4.484,398,1.426,420,1.346,436,2.628,487,1.839,589,1.6,590,4.789,622,2.716,718,2.796,729,3.667,743,1.812,748,3.613,750,3.51,879,3.667,960,2.827,1027,2.827,1112,4.685,1129,3.952,1159,3.078,1398,2.902,1521,2.587,1534,2.085,1590,1.948,1674,4.928,2039,6.022,2053,2.925,2246,5.9,2540,3.84,3416,4.76,3417,5.178]],["t/934",[6,0.077,32,2.376,57,3.461,98,1.164,102,1.466,110,1.167,113,2.721,134,2.049,153,0.747,154,1.199,155,2.927,160,2.134,165,1.506,167,1.011,168,2.408,170,0.964,176,1.02,193,1.359,200,1.214,201,1.52,204,2.015,207,1.098,208,1.288,219,1.178,247,1.898,262,1.406,268,3.232,348,3.13,357,2.563,365,1.898,374,0.602,375,2.461,380,2.376,436,2.996,485,1.55,494,1.506,565,1.373,584,3.961,589,2.659,590,4.895,595,1.237,622,2.439,635,1.634,655,1.759,718,2.636,743,2.179,748,4.12,750,3.309,791,3.309,839,1.598,840,2.006,843,3.749,879,4.41,963,2.23,969,1.931,1027,4.364,1040,2.445,1112,1.837,1118,1.362,1129,1.55,1159,4.295,1198,1.598,1336,2.096,1353,2.352,1398,1.877,1521,2.439,1538,1.417,1590,2.718,1600,2.006,1611,1.598,1674,5.108,1817,2.563,2039,5.707,2041,1.898,2246,5.561,2341,1.784,2540,3.169,2560,2.563,3286,2.721,3287,2.352,3418,2.563,3419,2.352,3420,2.96,3421,2.96,3422,2.96,3423,2.721,3424,2.96,3425,2.096]],["t/938",[6,0.078,83,2.785,110,1.228,155,2.966,167,2.29,168,2.532,170,2.185,204,1.371,207,1.509,208,1.004,223,4.457,261,3.66,398,2.492,565,3.111,595,2.802,743,2.346,749,3.019,966,2.564,988,2.443,1041,2.608,1130,5.052,1132,3.38,1312,4.135,1590,2.522,1674,3.882,2039,5.239,2246,6.059,3283,5.151,3426,6.706]],["t/940",[6,0.077,32,4.858,43,5.976,57,2.959,102,3.853,155,2.015,168,2.792,170,2.535,193,1.463,219,3.096,221,3.853,399,2.425,420,2.023,428,2.657,431,2.177,436,3.474,589,2.404,590,5.532,622,2.373,676,4.343,734,6.182,748,3.725,1055,4.448,1129,4.074,1159,4.624,1170,4.624,1521,3.887,1891,3.922,2035,5.386,2141,6.429,2246,3.996,3285,5.8]],["t/942",[6,0.077,32,4.088,102,4.159,110,1.14,155,3.096,168,2.35,207,1.89,208,1.257,436,2.924,487,2.983,584,3.866,590,4.822,655,4.992,748,4.021,749,3.782,1674,3.603,2039,4.862,2246,5.379,2540,4.273]],["t/945",[6,0.077,43,3.877,83,2.096,110,1.005,125,4.371,155,2.788,165,2.568,167,1.723,168,2.705,170,1.645,193,0.949,204,2.105,207,1.136,208,1.313,214,1.668,219,3.492,223,5.832,228,5.375,236,1.715,237,5.245,261,2.755,262,4.167,268,2.631,380,5.011,410,5.017,431,1.412,494,2.568,565,2.341,595,2.109,659,4.464,743,1.766,853,3.574,864,4.371,963,2.306,969,3.293,971,3.494,1118,2.324,1129,2.643,1130,2.818,1218,4.64,1398,1.941,1590,1.898,1674,3.764,1817,4.371,1908,3.494,2039,4.288,2050,2.416,2098,6.415,2100,4.17,2246,5.527,2540,3.769,3123,3.877,3130,4.01,3427,5.047,3428,5.047,3429,5.375,3430,4.17,3431,5.047,3432,5.047,3433,5.047,3434,5.047,3435,5.047,3436,4.64]],["t/947",[6,0.077,110,1.008,154,3.009,204,2.203,207,2.179,208,1.772,219,3.854,374,0.915,380,5.245,420,2.518,424,3.32,590,3.419,733,6.136,1118,3.419,1398,2.856,1590,2.793,1809,5.836,2036,3.368,2043,6.827,2189,3.556,2272,6.136,3437,9.683,3438,7.426,3439,7.426]],["t/949",[2,3.802,6,0.077,43,4.776,57,4.04,102,3.079,110,0.844,125,5.385,155,2.752,168,1.74,193,1.17,204,1.271,219,2.475,223,4.133,268,3.773,291,4.304,380,3.027,436,2.165,516,4.512,565,2.884,584,3.957,589,3.043,590,2.863,595,3.592,622,3.241,718,3.358,729,4.403,748,2.977,879,4.403,959,2.741,960,4.691,1130,4.798,1538,2.977,1674,4.783,1705,5.385,2035,4.304,2036,2.82,2039,4.975,2246,4.414,2540,4.373,3423,5.716,3440,6.218,3441,5.716,3442,6.218]],["t/951",[2,4.243,6,0.077,57,3.963,155,1.797,176,2.392,185,2.116,193,1.305,214,2.292,268,4.114,436,3.224,494,4.711,584,3.194,586,4.913,589,2.144,592,2.729,622,2.824,718,3.747,748,4.433,879,4.913,960,3.787,969,6.042,972,3.967,1117,3.305,1398,2.668,1521,3.467,1674,4.968,2039,5.36,2237,5.173,2246,3.564,2540,3.53,3418,6.009,3419,5.513]],["t/953",[6,0.077,102,3.006,110,1.593,155,3.042,167,2.073,168,3.093,170,2.754,174,4.526,193,1.142,207,1.902,208,1.265,348,5.42,359,2.955,365,3.893,375,3.061,398,2.328,420,2.198,428,3.321,436,2.114,476,2.063,487,2.156,565,2.816,589,1.876,590,5.27,595,2.537,597,3.033,635,3.351,747,5.016,748,2.907,750,5.73,879,4.299,963,2.774,1129,3.179,1312,2.774,1502,3.608,1521,3.033,2246,4.994,2540,3.089,3299,4.663,3396,5.58]],["t/955",[6,0.078,57,4.201,155,2.027,160,1.542,193,1.024,198,4.02,201,2.796,207,1.225,208,0.815,268,3.254,374,0.671,420,1.416,428,2.672,431,2.19,436,1.896,480,2.005,584,4.885,590,4.885,622,2.795,655,3.236,748,2.607,749,2.452,791,7.489,815,3.45,960,2.972,1027,6.031,1040,6.467,1118,2.507,1156,3.691,1198,2.94,1386,4.32,1398,2.094,1521,2.72,1590,2.048,1674,2.336,2039,3.152,2246,4.02,2540,2.77,3419,4.326,3443,5.445,3444,5.445,3445,5.445]],["t/959",[6,0.076,155,2.196,176,3.632,212,3.189,268,4.258,584,4.85,590,3.903,655,5.039,791,5.747,1398,3.26,1534,3.414,1674,4.519,1759,7.005,2246,4.354,2540,4.314,3281,6.736,3418,7.342,3419,6.736,3446,7.793,3447,8.478,3448,8.478,3449,7.793,3450,7.342]],["t/961",[6,0.077,110,1.52,155,2.088,160,1.588,165,4.101,168,3.399,170,2.626,193,1.516,204,2.087,262,3.828,365,5.168,380,3.923,486,3.246,590,3.71,686,4.101,840,5.463,843,6.191,905,4.307,1132,4.063,2050,3.859,2246,5.242,2612,7.409,3282,6.404,3451,7.409]],["t/963",[6,0.078,80,2.287,155,2.528,160,1.204,176,2.107,204,1.25,208,1.271,214,2.019,268,3.016,308,4.143,326,2.622,380,4.134,494,3.11,512,2.107,589,1.889,743,2.138,791,4.143,815,2.694,933,2.675,969,5.542,1117,3.484,1129,3.2,1534,2.462,1538,2.926,1674,3.643,1702,5.618,1759,5.05,2035,4.231,2039,3.538,2050,2.926,2246,5.417,2341,3.684,2540,4.966,3282,4.856,3449,5.618,3450,9.134,3452,6.112,3453,6.112,3454,5.05]],["t/965",[6,0.077,57,2.946,155,2.848,160,2.166,176,2.671,193,1.457,268,2.751,375,5.017,436,2.697,584,4.581,589,3.397,748,3.709,791,5.251,960,4.229,988,2.822,1027,4.229,1111,5.251,1534,3.12,1674,4.977,2039,4.485,2246,5.647,2540,5.063,3455,7.747]],["t/967",[6,0.078,32,2.795,57,4.276,98,2.258,110,1.103,155,2.913,160,1.601,193,1.08,207,1.292,208,0.859,222,3.621,348,3.681,359,2.795,420,1.493,436,1.999,487,2.039,505,2.894,584,4.985,589,1.774,590,3.742,622,2.479,655,3.412,663,2.245,748,2.749,750,3.892,879,4.065,1159,3.412,1398,2.208,1400,7.471,1612,4.561,1674,3.486,1891,2.894,2039,3.324,2237,4.28,2246,5.937,2540,4.8,3456,4.972,3457,4.166]],["t/969",[6,0.078,57,4.081,110,0.999,268,2.616,375,3.713,559,4.16,589,2.976,590,3.391,591,3.391,622,2.247,718,3.977,815,4.245,960,4.02,1117,2.629,1242,4.211,1521,3.68,1674,3.159,3458,5.852,3459,5.852]],["t/971",[6,0.078,57,3.753,155,1.981,160,1.507,191,3.325,584,3.521,590,5.031,622,2.333,678,3.419,687,4.485,815,3.371,960,4.175,1027,5.965,1040,6.319,1117,3.523,1156,5.184,2246,3.928,2540,3.891,3458,6.076,3460,7.648]],["t/973",[6,0.077,57,3.348,155,1.668,160,1.269,193,1.656,204,1.317,207,1.449,208,1.318,268,3.127,431,1.802,436,3.066,487,2.287,533,3.269,590,4.965,595,4.193,622,2.686,718,4.755,748,3.084,791,5.969,879,4.561,960,3.516,1027,5.476,1398,2.477,1590,2.423,1674,5.119,2039,6.537,2049,3.084,2246,3.308,2540,3.277,3419,5.118,3446,5.921,3450,5.578,3461,5.921]],["t/975",[6,0.074,3462,10.331]],["t/977",[6,0.078,110,1.63,153,1.362,160,1.063,167,3.113,193,1.715,204,1.864,207,1.214,208,1.493,219,2.148,236,2.642,263,3.916,306,3.207,344,1.936,347,2.299,373,2.378,374,1.481,383,2.925,399,1.682,422,2.255,428,1.843,431,2.176,436,2.707,476,2.642,487,1.916,494,2.745,582,2.649,589,1.667,743,3.189,749,2.43,966,2.973,989,1.667,992,2.542,998,2.123,1041,2.098,1308,4.506,1376,4.023,1590,2.925,1609,4.459,1717,4.392,2050,2.583,3463,5.346,3464,5.396]],["t/979",[6,0.078,11,2.689,83,2.191,110,1.339,149,1.273,150,1.343,153,1.93,154,1.319,155,0.843,167,2.87,176,1.122,193,0.992,201,1.671,204,1.564,207,1.497,208,1.347,212,1.224,214,1.075,219,1.295,236,1.106,306,1.934,316,2.995,344,1.168,359,1.584,373,1.435,374,1.535,383,2.877,392,2.362,399,1.014,431,1.861,436,2.927,476,2.857,487,1.873,494,1.656,520,1.156,532,1.096,533,1.719,588,2.5,742,2.612,743,2.676,749,1.465,793,3.226,905,1.739,929,2.945,966,2.925,967,1.311,989,1.63,993,2.053,994,2.124,998,2.075,999,3.506,1037,1.962,1082,2.5,1117,1.162,1126,1.934,1127,2.206,1308,3.835,1315,2.426,1376,2.426,1398,2.028,1567,1.909,1590,2.502,1609,5.496,1717,2.98,1731,2.02,1901,1.884,2049,3.185,2546,2.992,3022,2.124,3436,2.992,3463,5.278,3465,3.255,3466,4.052,3467,2.689,3468,5.275,3469,2.819]],["t/982",[6,0.078,110,1.665,167,3.456,185,1.477,191,2.106,193,0.911,204,1.937,208,1.515,236,1.646,263,3.515,316,2.181,347,2.064,374,1.419,399,1.509,410,2.769,420,2.227,430,2.736,431,1.355,476,3.73,575,1.63,582,4.205,597,2.42,634,3.922,730,2.264,743,1.694,749,2.181,938,6.385,963,2.213,966,1.852,989,1.496,994,3.16,1041,2.794,1117,1.729,1139,3.105,1170,2.879,1308,4.518,1535,3.16,1590,2.702,1627,3.007,3463,5.023,3470,4.843,3471,4.843,3472,4.843,3473,6.222,3474,4.843,3475,4.843,3476,4.843,3477,7.418,3478,4.843,3479,4.843]],["t/984",[6,0.077,110,1.616,190,3.113,208,0.957,231,2.639,232,2.639,306,3.801,374,1.08,383,2.405,399,2.731,401,2.992,420,2.278,423,4.033,430,3.612,476,2.978,486,2.576,487,2.271,494,3.254,634,3.491,963,2.922,989,2.707,994,4.173,1078,3.97,1162,4.836,1178,3.224,1308,4.582,1459,3.91,1627,3.97,1932,3.453,3301,4.767,3429,4.641,3480,6.395,3481,6.395,3482,6.395,3483,6.395,3484,5.538,3485,5.879,3486,6.395,3487,6.395,3488,6.395,3489,6.395,3490,5.879,3491,6.395,3492,6.395,3493,5.081,3494,6.395,3495,5.879,3496,6.395]],["t/986",[6,0.077,83,3.666,110,1.621,167,2.207,190,3.147,193,1.216,214,2.136,263,4.691,374,1.393,420,1.681,431,1.809,476,3.416,582,4.935,743,2.262,933,2.83,938,6.58,966,3.375,989,1.997,992,3.046,1170,5.246,1308,3.761,1627,4.013,2126,3.742,3429,4.691,3463,3.791,3473,5.598,3477,7.644,3490,5.942,3493,5.136,3495,5.942,3497,6.464,3498,6.464,3499,6.464,3500,6.464,3501,6.464,3502,6.464,3503,6.464,3504,6.464,3505,6.464,3506,6.464,3507,6.464]],["t/988",[6,0.078,83,1.772,102,3.929,110,1.588,158,1.291,167,3.272,168,2.487,173,2.691,204,0.873,216,2.471,221,3.235,227,3.278,231,3.669,236,1.45,262,2.027,291,4.522,318,4.522,398,1.175,399,2.036,401,1.457,420,2.063,476,1.45,486,1.719,582,2.095,634,3.565,639,1.922,697,5.379,749,2.941,759,3.181,842,2.785,933,1.868,938,5.915,966,2.498,974,1.784,975,1.784,988,1.555,990,3.022,1060,3.097,1078,2.649,1162,2.355,1170,2.537,1178,2.151,1188,3.022,1308,3.381,1369,3.278,1439,3.278,1624,3.278,1741,2.649,2126,2.471,2618,3.526,2626,3.278,3301,3.181,3463,2.503,3508,4.268,3509,4.268,3510,4.268,3511,4.268,3512,4.268,3513,4.268,3514,4.268,3515,4.268,3516,4.268,3517,4.268,3518,5.656,3519,4.268,3520,4.268,3521,3.923,3522,4.268,3523,4.268,3524,4.268,3525,4.268,3526,4.268,3527,4.268,3528,4.268,3529,4.268,3530,4.268,3531,4.268,3532,4.268,3533,4.268,3534,4.268,3535,6.532,3536,4.268,3537,4.268,3538,4.268,3539,4.268,3540,3.923,3541,4.268,3542,4.268,3543,4.268,3544,4.268,3545,3.391]],["t/990",[6,0.078,110,1.53,158,1.941,167,2.999,176,2.213,214,2.12,236,2.985,374,1.39,476,2.181,575,2.957,582,4.312,634,4.795,743,3.073,966,2.454,1060,4.657,1130,3.583,1186,5.099,1308,3.743,1535,4.188,1601,5.303,2126,5.085,3463,3.764,3473,7.607,3540,5.9,3546,6.418,3547,6.418,3548,6.418,3549,6.418,3550,6.418,3551,6.418,3552,6.418,3553,6.418,3554,6.418]],["t/992",[6,0.078,110,1.615,153,1.16,155,1.19,160,0.905,167,3.152,176,1.584,191,3.609,193,1.299,204,0.939,207,1.034,208,1.034,231,1.896,236,1.562,268,1.632,316,3.111,319,2.115,374,1.51,399,1.432,420,1.195,436,2.405,476,3.992,582,4.532,749,3.738,938,6.188,945,5.708,956,3.98,988,1.674,998,1.808,1170,2.731,1308,1.958,1423,4.224,1836,2.947,2126,2.66,2573,3.53,3017,3.98,3272,4.224,3463,4.868,3467,3.797,3477,5.983,3555,4.595,3556,4.595]],["t/994",[6,0.078,83,2.392,102,4.034,110,1.394,155,2.11,167,1.967,168,2.645,204,2.217,207,1.296,208,1.219,231,4.241,257,3.987,291,3.987,374,1.266,402,4.424,423,3.632,476,1.957,486,2.32,559,3.253,697,5.522,749,2.593,839,3.11,842,3.758,966,3.115,967,2.32,989,2.92,1117,2.056,1178,4.107,1225,2.852,1287,3.471,1459,3.522,1643,2.178,1809,3.471,2026,3.632,2357,4.759,2408,5.294,3463,5.543,3557,5.759,3558,5.759,3559,5.759,3560,5.759,3561,5.759,3562,5.759,3563,5.759,3564,5.759,3565,5.759,3566,5.759,3567,5.759]],["t/997",[6,0.077,49,3.157,80,1.96,110,0.711,176,3.091,185,3.001,201,3.909,219,2.085,226,2.594,268,1.86,344,1.879,374,1.471,476,3.046,487,3.184,505,2.641,591,4.127,592,2.994,597,2.617,638,2.771,678,2.342,961,2.508,1015,6.077,1082,4.024,1308,4.453,1376,3.905,1521,2.617,1525,3.627,1611,2.829,1617,4.328,1647,3.551,1895,5.045,1915,2.641,1932,2.829,2049,2.508,2080,2.995,2082,3.072,2083,3.905,2086,3.252,2093,3.547,2286,2.959,2287,3.551,2371,5.004,2402,3.551,2685,3.802,3022,4.966,3251,6.206,3254,6.886,3568,3.627,3569,3.627,3570,5.523,3571,3.905,3572,5.239,3573,4.328,3574,4.328,3575,4.537,3576,4.537,3577,3.802,3578,5.674,3579,4.162,3580,4.328]],["t/999",[6,0.078,80,1.635,110,1.549,150,1.804,153,1.679,155,1.723,160,0.861,167,2.272,168,1.223,179,4.549,185,1.333,212,1.644,216,2.531,226,2.165,236,1.486,254,2.093,257,5.575,326,1.875,369,3.473,374,1.407,383,2.502,399,2.073,436,2.804,476,3.059,513,1.451,565,2.028,575,1.472,597,2.184,623,4.259,645,2.11,663,1.71,686,2.224,743,1.529,889,5.286,908,2.564,910,4.018,938,6.003,1036,3.266,1308,4.347,1538,2.093,1564,2.912,1611,3.592,1643,1.653,1809,2.635,1895,2.11,1928,3.385,1932,2.361,1936,3.473,2073,3.473,2237,3.259,2371,2.44,3463,6.219,3570,3.172,3571,3.259,3578,3.259,3581,2.361,3582,2.469,3583,3.786,3584,3.473,3585,3.786,3586,4.372,3587,3.786]],["t/1002",[6,0.078,110,1.373,155,1.861,185,2.613,195,2.84,204,1.937,208,1.282,214,2.374,257,5.929,300,4.159,344,1.738,358,3.848,374,1.307,436,1.686,476,1.646,512,3.267,659,2.919,712,2.704,942,3.353,974,3.58,975,3.58,989,1.496,1308,2.064,1564,2.12,1590,1.822,1809,5.162,1826,3.72,1895,3.468,1901,2.804,1928,2.464,1994,2.464,2080,2.769,2083,3.61,2086,3.007,2093,2.843,2184,3.848,2256,4.194,2286,2.736,2402,3.283,2436,4.452,2449,2.588,3463,5.935,3570,5.214,3577,3.515,3578,3.61,3579,3.848,3581,2.615,3582,4.058,3584,3.848,3585,4.194,3588,4.843,3589,4.843,3590,4.843,3591,4.843,3592,4.194,3593,4.002,3594,4.843,3595,4.843,3596,4.843,3597,4.843]],["t/1004",[6,0.078,83,2.795,155,2.35,158,2.036,185,2.053,216,3.897,316,3.031,374,1.118,383,3.412,512,3.128,532,3.054,533,2.956,742,3.333,743,2.355,906,3.715,974,2.813,975,2.813,1308,2.868,1895,3.249,1915,3.393,1928,3.424,2080,3.848,2082,3.947,2184,5.348,2286,3.802,3463,6.44,3577,4.884,3582,3.802,3584,5.348,3592,5.829,3598,6.731,3599,6.731,3600,6.731,3601,6.187]],["t/1006",[6,0.078,33,1.878,80,0.884,83,1.678,85,2.173,110,1.579,155,1.371,158,0.715,160,0.466,167,3.376,176,1.825,185,0.721,193,0.445,204,0.826,208,0.792,212,1.991,214,0.781,216,1.368,219,0.941,226,1.171,236,1.373,263,2.932,316,2.383,344,0.848,349,1.816,359,1.151,374,1.434,383,2.356,399,0.737,411,1.542,420,0.615,431,0.661,436,0.823,476,3.36,512,0.815,513,0.785,575,0.796,659,1.425,742,2.001,743,1.414,849,1.08,933,1.035,938,3.945,966,1.545,967,0.952,974,0.988,975,0.988,989,1.935,998,0.93,1015,1.602,1032,1.335,1037,3.19,1117,2.235,1126,2.402,1127,1.602,1275,1.762,1308,4.604,1564,1.035,1609,1.953,1611,2.182,1643,2.002,1647,1.602,1682,1.878,1896,2.047,1915,3.157,1928,2.056,1932,1.276,2025,1.571,2064,2.047,2083,1.762,2093,0.935,2126,2.339,2286,3.537,2287,1.602,2371,2.256,2429,2.047,2449,1.263,3022,1.542,3251,2.797,3430,3.339,3463,6.154,3469,2.047,3569,1.636,3574,1.953,3577,1.715,3578,1.762,3579,1.878,3580,1.953,3581,1.276,3582,1.335,3601,2.173,3602,3.714,3603,2.364,3604,2.364,3605,2.364,3606,2.364,3607,2.364,3608,2.364]],["t/1008",[2,3.434,6,0.078,9,3.732,83,3.323,98,2.209,110,1.593,199,2.248,204,1.148,208,1.197,219,2.235,263,4.075,316,2.528,344,2.015,359,2.733,374,1.416,383,3.506,398,2.204,401,1.917,420,1.46,436,1.955,486,3.222,575,1.89,582,2.757,589,1.735,743,1.965,818,3.065,966,3.059,974,2.347,975,2.347,989,1.735,992,2.646,1037,3.384,1155,3.338,1158,3.099,1170,3.338,1308,2.393,1398,2.159,1459,3.434,1590,2.112,1611,3.032,2049,2.688,2449,3.001,3463,5.466]],["t/1010",[6,0.074,3609,10.331]],["t/1012",[6,0.078,110,1.583,155,1.536,158,1.794,160,1.639,193,1.564,204,1.212,207,1.871,208,1.855,232,3.432,286,2.494,317,2.183,374,1.025,401,2.025,431,1.659,505,2.99,528,3.682,589,2.569,960,3.237,961,4.598,966,2.268,971,4.106,989,1.832,995,2.67,1041,2.306,1132,2.99,1564,2.596,1752,4.199,2540,4.231]],["t/1014",[6,0.078,46,2.212,59,2.4,110,1.564,158,1.025,160,1.347,168,1.525,191,1.474,193,1.885,204,2.049,207,2.063,208,1.654,212,1.275,232,1.399,286,1.426,317,2.007,359,1.65,374,1.337,382,2.46,398,0.934,399,1.699,401,2.335,420,1.417,431,2.192,476,1.152,505,1.709,528,2.104,573,2.354,585,2.913,589,1.047,591,1.561,592,1.333,639,1.526,645,1.636,725,2.073,727,1.741,961,3.273,966,1.296,967,1.365,971,3.774,989,2.833,992,1.597,995,3.527,1028,2.212,1041,1.318,1101,2.174,1132,1.709,1312,1.549,1752,4.841,1891,1.709,1928,2.773,1936,2.693,2050,2.61,2445,3.557,2540,1.725,3568,2.347,3569,2.347,3581,3.692,3610,2.936,3611,2.801,3612,3.116,3613,4.187,3614,4.721,3615,1.938]],["t/1017",[6,0.076,46,5.721,199,3.51,221,4.342,317,3.96,337,6.208,374,1.434,398,2.415,401,3.673,591,4.036,592,3.449,725,5.361,961,4.198,1028,5.721,1752,6.208,1895,4.232,2093,3.469,3615,5.013]],["t/1019",[6,0.077,110,1.582,160,1.269,168,1.802,185,1.965,193,1.212,199,2.579,208,1.502,232,2.658,374,0.794,398,1.774,399,3.361,401,3.007,420,2.609,431,1.802,478,4.674,505,3.247,573,2.781,585,3.442,589,1.99,622,1.965,623,3.407,712,3.596,961,3.084,963,2.943,967,3.546,989,3.1,995,3.965,1162,4.86,1891,3.247,1928,3.277,2100,5.322,2449,3.442,3610,5.578,3611,5.322,3613,4.947,3616,7.275,3617,5.921,3618,6.441,3619,6.441,3620,6.441,3621,6.441,3622,6.441,3623,6.441,3624,6.441,3625,6.441,3626,6.441,3627,5.921,3628,5.118,3629,6.441]],["t/1022",[6,0.076,110,1.29,208,1.691,232,3.925,373,4.192,1928,4.839,2231,7.858,2449,5.082]],["t/1024",[6,0.076,10,3.623,110,1.213,160,2.145,204,1.828,208,1.338,219,3.559,1399,7.105,1811,6.191,1891,4.508,1928,5.539,2449,4.778,3581,5.879,3613,6.869,3630,8.22]],["t/1026",[6,0.077,59,7.422,110,1.422,158,2.123,208,1.789,219,2.794,232,4.326,317,2.585,374,1.377,398,1.934,401,3.814,420,1.825,512,2.42,961,4.467,971,4.86,1512,6.453,1836,4.501,1928,3.572,2449,4.986,2540,3.572,3581,3.791]],["t/1028",[6,0.077,110,1.536,158,1.962,160,1.744,168,2.476,185,2.699,204,2.059,208,1.694,232,4.156,374,1.091,398,1.787,399,2.758,401,3.021,420,2.301,481,4.998,486,2.613,575,2.184,693,4.836,712,3.622,971,4.491,995,2.921,1041,2.523,1117,2.316,1353,5.155,1360,4.594,1590,2.44,2072,4.708,2449,3.467,2540,4.502,3425,6.266,3631,6.488]],["t/1031",[6,0.077,359,5.025,374,1.011,399,2.558,428,2.802,434,5.831,487,4.011,961,3.929,967,3.305,1915,4.137,2286,4.636,3632,4.692,3633,8.207,3634,8.207]],["t/1033",[6,0.077,110,1.627,199,3.394,208,1.269,232,3.499,317,3.121,327,4.093,374,1.413,401,2.895,486,4.243,686,4.314,961,4.059,1355,4.354,1752,6.003,2540,4.314]],["t/1035",[6,0.077,110,1.184,153,2.202,208,1.306,232,3.601,374,1.493,436,3.734,597,4.359,995,3.929,1928,4.439,2540,4.439]],["t/1037",[6,0.077,199,3.347,208,1.563,214,2.762,232,4.31,317,3.078,398,2.303,401,2.855,424,3.737,432,4.96,487,2.969,512,2.882,565,3.878,989,2.583,998,3.288,1970,7.684,2540,5.313,3614,7.24,3635,6.066]],["t/1039",[6,0.077,110,1.31,160,1.903,170,2.41,193,1.391,204,2.198,208,1.706,232,3.986,374,1.19,431,2.069,528,4.591,532,2.49,533,2.41,541,3.763,575,2.49,589,2.285,961,3.541,963,3.379,995,3.33,1037,4.457,1171,4.916,1928,3.763,2449,3.952,2540,3.763]],["t/1041",[6,0.075,46,6.109,208,1.401,232,3.864,317,3.447,591,4.31,592,3.683,676,5.226,725,5.725,961,4.482,1028,6.109,2093,3.704,2540,4.763,3615,5.353,3636,8.108]],["t/1043",[6,0.077,160,1.78,344,3.929,374,1.113,382,6.555,424,4.038,961,4.324,1086,6.123,1743,6.253,2569,7.463,3613,6.938,3637,9.032,3638,8.303,3639,9.032]],["t/1045",[6,0.076,109,5.12,110,1.244,193,1.725,199,3.671,262,4.355,317,3.376,359,4.464,374,1.362,436,3.193,676,5.12,988,3.341,995,4.129,3636,7.942,3640,9.171]],["t/1047",[6,0.077,110,1.392,160,1.326,185,2.053,204,1.376,208,1.837,219,4.701,232,4.732,374,1.118,512,2.321,528,4.178,575,2.266,1202,4.766,1554,5.348,1731,5.632,1891,4.573,1928,5.833,2093,2.663,2449,5.483,2540,5.221,3581,3.635,3613,6.968,3638,6.187]],["t/1049",[6,0.077,110,1.43,153,1.793,158,2.148,168,1.988,208,1.831,212,2.672,232,4.631,374,1.439,436,2.473,512,2.449,591,3.27,1345,8.144,1611,5.693,1928,3.614,1932,5.078,2449,5.025,2540,4.785,3641,7.103]],["t/1052",[6,0.078,64,8.6,153,1.779,185,2.15,204,1.441,208,1.4,232,2.909,262,4.443,317,2.595,432,5.313,541,3.586,989,2.891,1015,4.777,1118,3.244,1395,6.476,1915,3.553,1994,3.586,2080,4.029,2286,3.981,2540,3.586,3581,3.806,3635,6.789,3642,8.102,3643,6.478]],["t/1054",[6,0.078,110,1.631,168,3.43,170,2.333,204,1.464,208,1.415,232,2.955,436,2.493,485,3.749,995,3.224,1915,3.61,2337,4.957,2362,6.582,2449,3.826,2540,3.643]],["t/1056",[6,0.077,204,2.141,208,1.568,232,4.323,374,1.035,1564,3.676,1590,3.159,1891,4.234,1928,4.273,2540,5.329,3613,6.451,3614,7.273,3644,8.399]],["t/1058",[6,0.074,3645,10.331]],["t/1060",[6,0.078,110,1.384,150,1.804,153,2.032,160,1.587,167,1.493,170,2.168,190,2.128,204,1.84,207,1.497,208,1.347,231,2.746,247,5.771,254,2.093,344,1.568,373,1.927,374,0.82,375,2.204,377,1.968,383,1.644,398,1.204,401,3.073,420,2.518,422,1.827,486,3.243,505,2.204,532,1.472,533,1.425,589,2.781,686,2.224,718,2.361,929,2.44,959,1.927,966,3.442,967,2.679,989,1.351,995,1.968,998,1.72,999,2.906,1158,3.672,1225,2.165,1398,1.681,1523,4.828,1590,2.502,1693,3.473,1828,3.172,1900,2.803,2007,3.095,2036,1.983,2049,3.856,2053,2.469,2119,3.473,2206,3.786,2290,2.165,2559,3.095,3466,3.358,3581,4.349,3646,5.761,3647,3.786,3648,4.372,3649,3.259,3650,3.095,3651,4.372]],["t/1062",[6,0.078,110,1.413,150,2.142,153,1.656,155,0.827,160,0.629,170,1.04,185,0.973,191,2.257,193,1.565,204,1.701,208,0.478,230,2.39,231,2.708,254,1.528,286,2.183,316,1.437,373,2.892,374,1.207,399,1.618,401,2.241,420,1.706,422,1.334,431,0.893,436,1.111,476,1.084,480,1.175,486,2.091,532,1.074,533,1.04,686,2.641,849,1.458,959,2.288,963,1.458,966,3.182,967,3.045,989,0.986,995,1.437,998,1.255,1117,2.97,1158,3.622,1170,1.897,1225,2.571,1308,2.212,1312,2.372,1386,1.761,1394,2.637,1398,2.523,1399,2.535,1402,2.933,1406,2.379,1523,2.316,1554,2.535,1567,1.871,1693,4.125,1900,2.046,1928,1.624,2007,3.676,2036,2.355,2042,2.763,2049,4.27,2050,1.528,2053,3.707,2119,4.125,2141,2.637,2189,1.528,2290,1.58,2782,2.535,3466,5.041,3467,2.637,3581,4.493,3646,2.763,3649,2.379,3650,3.676,3652,5.422,3653,2.933,3654,3.191,3655,3.191]],["t/1065",[6,0.077,110,1.339,160,1.698,193,1.174,204,1.276,231,4.072,232,3.555,247,4.001,268,2.216,286,2.624,317,2.297,319,3.966,374,0.769,385,3.555,398,1.719,399,3.075,401,2.131,420,2.24,476,2.928,622,1.903,623,3.3,631,3.567,635,3.444,759,4.651,849,4.862,963,2.851,966,3.294,967,2.513,1036,3.063,1037,3.761,1312,4.509,1619,6.845,1627,5.348,2457,4.319,2493,5.84,2588,5.156,2591,5.736,3581,3.369,3656,6.24,3657,6.24,3658,6.24,3659,5.156,3660,6.24,3661,5.404,3662,6.24,3663,5.404,3664,5.404,3665,5.736,3666,4.793,3667,6.24,3668,6.24,3669,6.24,3670,6.24,3671,6.24,3672,6.24,3673,5.404,3674,5.736,3675,6.24]],["t/1067",[6,0.077,110,1.334,153,2.076,170,1.475,193,0.851,204,0.925,228,4.956,231,4.559,237,3.205,254,3.938,257,3.133,261,2.47,319,2.083,321,2.81,385,1.868,399,2.129,401,1.545,420,1.177,631,2.588,635,2.498,718,3.688,759,3.374,842,5.978,849,4.493,959,3.625,963,2.068,966,1.731,967,4.164,1032,2.556,1117,1.615,1158,2.498,1170,2.69,1181,3.813,1186,3.596,1225,4.073,1287,2.728,1312,3.121,1459,4.176,1491,2.418,1523,3.284,1554,3.596,1567,2.654,1627,2.81,1731,2.81,1908,4.728,2036,4.155,2119,6.535,2189,2.167,2290,2.241,2332,3.133,2433,3.476,2568,2.654,2572,4.956,2595,3.374,2626,3.476,2631,4.16,2632,4.16,2754,4.16,3301,3.374,3581,2.444,3646,3.919,3661,5.915,3663,3.919,3664,3.919,3665,4.16,3673,3.919,3674,7.561,3676,4.526,3677,4.526,3678,4.526,3679,4.526,3680,4.526,3681,4.526,3682,4.526,3683,4.526,3684,4.526,3685,4.526,3686,6.83,3687,4.526,3688,4.526,3689,4.526,3690,4.16,3691,3.919,3692,4.526,3693,4.526,3694,4.526,3695,4.526,3696,4.526,3697,4.526,3698,4.526,3699,4.526,3700,6.83,3701,6.83]],["t/1070",[6,0.077,10,1.4,49,2.082,57,1.314,80,2.071,98,1.359,110,0.94,150,1.426,153,1.748,155,1.434,158,1.045,160,0.681,168,0.967,185,2.416,193,0.65,204,2.063,207,0.777,208,1.185,228,2.507,231,2.858,232,1.426,327,1.668,344,1.986,347,2.359,369,2.745,373,2.44,374,1.41,383,2.082,398,1.525,399,1.725,422,1.444,423,2.179,433,2.026,436,1.927,476,1.174,480,1.272,485,2.898,487,1.966,505,1.742,513,2.629,517,2.026,532,1.163,533,1.804,534,2.343,584,1.591,590,3.646,591,2.548,592,1.359,597,1.726,622,1.688,623,1.827,635,1.907,659,2.082,718,1.866,842,3.612,849,1.579,951,2.254,959,2.44,963,1.579,966,2.117,967,3.49,988,1.259,1015,3.752,1036,1.696,1055,4.528,1110,2.026,1158,1.907,1159,2.053,1225,1.711,1287,2.082,1308,2.951,1376,2.576,1459,2.113,1495,2.654,1516,3.176,1538,1.654,1564,2.423,1590,1.3,1643,3.497,1647,2.342,1693,4.398,1784,2.654,1785,2.745,1799,3.176,1809,2.082,1811,2.392,1895,1.668,1915,1.742,1928,1.758,1932,1.866,2011,2.179,2036,2.511,2049,1.654,2056,1.975,2080,1.975,2082,2.026,2083,2.576,2086,2.145,2093,1.367,2189,1.654,2237,2.576,2247,4.904,2286,1.952,2287,2.342,2290,2.741,2297,2.992,2298,2.855,2371,3.09,2402,2.342,2457,3.832,2685,2.507,2686,2.446,3251,3.832,3254,2.654,3463,2.026,3570,2.507,3573,2.855,3574,2.855,3575,2.992,3576,2.992,3577,2.507,3578,2.576,3579,2.745,3580,2.855,3581,2.989,3582,1.952,3583,2.992,3584,2.745,3585,2.992,3593,4.573,3630,3.176,3650,4.904,3652,2.855,3666,2.654,3702,3.176,3703,3.455,3704,3.455,3705,3.455,3706,3.176,3707,3.176,3708,2.992,3709,3.455,3710,3.455,3711,3.455,3712,2.855,3713,3.455,3714,3.176,3715,3.455]],["t/1073",[6,0.077,79,6.002,150,3.225,153,2.525,155,2.024,193,1.47,204,1.598,231,3.225,306,4.644,374,0.963,383,2.939,436,2.721,967,3.147,1158,4.313,1895,3.772,1900,5.011,2049,3.741,2093,3.092,2189,3.741,2290,3.87,2782,6.209,3466,6.002,3581,5.404,3593,6.457,3650,7.086,3652,6.457]],["t/1075",[6,0.077,49,5.31,153,2.224,204,1.801,374,1.33,383,3.314,436,3.068,597,4.402,967,3.548,1198,4.758,1564,3.857,2049,4.218,2290,4.363,3466,6.768,3570,6.394,3581,6.297]],["t/1077",[6,0.076,150,3.747,208,1.359,232,3.747,374,1.119,487,3.224,654,8.345,655,5.396,1110,6.443,1693,7.213,1809,5.471,2049,4.346,3466,6.973,3650,6.428]],["t/1080",[6,0.078,110,1.53,160,1.265,185,2.679,193,1.207,306,3.815,347,2.735,374,0.791,428,2.191,486,3.537,624,3.743,678,2.869,686,3.265,718,3.466,959,3.872,966,4.312,1158,4.848,1225,4.35,1459,3.924,1534,3.537,1643,3.322,1895,4.24,2036,3.984,2053,3.625,2290,3.178,3581,3.466,3650,4.545,3716,6.418,3717,6.418,3718,6.418,3719,6.418,3720,6.418]],["t/1082",[6,0.078,145,6.176,159,3.936,191,4.099,212,2.682,344,2.559,347,3.039,425,3.308,645,3.443,1398,2.742,1643,3.566,1895,3.443,1897,5.666,2290,4.669,3581,5.092,3650,7.48,3721,6.176,3722,7.132,3723,6.555,3724,7.132,3725,9.429,3726,9.429,3727,7.132,3728,7.132,3729,7.132,3730,7.132,3731,7.132]],["t/1084",[6,0.077,43,3.255,80,2.43,110,0.881,150,1.749,153,2.858,155,1.098,193,1.222,207,0.954,208,0.634,254,5.182,373,2.863,374,1.334,383,2.443,431,1.186,476,1.44,512,1.461,532,3.531,533,3.418,554,5.368,637,2.765,718,3.508,959,2.863,966,2.484,973,3.075,974,3.302,975,3.302,979,2.241,998,1.667,1117,2.82,1118,1.951,1202,3.001,1308,1.806,1393,2.765,1394,3.501,1741,2.631,1834,3.367,1895,2.046,1928,2.156,2036,2.946,2049,3.782,2052,3.159,2080,2.423,2093,1.677,2268,2.339,2286,2.394,2290,4.386,2686,3.001,2701,4.239,3463,2.485,3577,3.075,3581,5.441,3582,2.394,3584,3.367,3592,3.67,3650,7.663,3652,7.318,3653,3.895,3732,4.238,3733,3.895,3734,4.238,3735,4.238,3736,4.238,3737,4.238,3738,4.238,3739,4.695,3740,4.238,3741,4.238,3742,4.238,3743,4.238]],["t/1087",[6,0.078,9,4.856,110,0.991,150,3.015,153,1.844,160,2.106,173,4.607,191,3.176,193,1.802,204,1.494,231,3.015,254,3.498,286,3.073,359,3.556,686,3.717,959,3.22,989,2.257,1158,4.032,1994,3.717,2036,3.314,2049,3.498,2290,3.618,2556,6.327,3581,3.945,3650,6.784,3666,5.611,3744,7.306,3745,7.306]],["t/1089",[6,0.074,3746,10.331]],["t/1091",[6,0.077,110,1.253,150,2.853,153,1.744,160,1.362,207,1.555,208,1.661,232,4.292,374,0.852,399,2.154,424,4.128,505,3.485,532,2.327,533,2.252,541,3.517,589,2.136,622,2.108,686,3.517,743,2.418,960,3.773,961,3.309,967,2.784,995,3.112,1198,3.732,1355,3.55,1386,3.815,1534,4.189,2093,3.654,2261,4.432,3747,5.016,3748,4.785,3749,6.354]],["t/1093",[6,0.078,98,1.306,110,1.491,143,1.947,149,1.299,150,2.213,160,1.674,193,1.798,198,2.754,200,1.362,204,0.679,207,1.742,208,1.645,221,1.645,232,4.105,286,1.397,344,1.191,354,1.674,359,3.282,374,0.661,392,2.41,424,3.797,431,2.542,477,2.41,480,1.223,505,2.703,532,2.859,533,2.522,585,3.603,589,2.953,622,1.013,639,1.495,729,2.351,743,1.876,960,1.813,961,4.349,989,2.624,995,3.485,1006,2.061,1181,1.854,1355,1.705,1386,1.833,1502,1.974,1534,4.006,1743,2.299,1891,1.674,1901,1.922,2071,3.564,2093,2.668,2252,2.129,2555,2.167,3747,3.891,3748,3.712,3750,4.26,3751,3.053,3752,3.321,3753,3.321,3754,2.876,3755,3.053,3756,3.321,3757,3.053,3758,3.053]],["t/1095",[6,0.078,110,1.483,158,2.723,160,2.011,193,1.252,198,5.24,207,2.46,208,1.636,219,2.649,249,6.712,374,0.82,383,2.503,480,3.315,533,2.169,585,3.557,639,2.997,645,3.213,980,4.608,995,2.997,1297,5.288,1356,4.608,1398,2.559,1534,3.626,1753,5.499,2071,5.985,3759,9.004,3760,6.656]],["t/1097",[6,0.076,110,1.27,193,1.761,208,1.401,232,3.864,399,3.488,420,2.91,431,2.62,520,3.325,585,5.003,3761,9.362,3762,8.606]],["t/1099",[6,0.077,100,4.233,110,1.414,168,1.164,193,1.469,199,1.665,208,0.622,232,1.716,261,3.495,319,1.915,385,1.716,398,2.755,399,2.733,401,1.42,420,1.665,431,2.185,476,2.98,480,2.358,520,1.477,573,3.372,585,3.422,623,3.387,815,3.866,967,1.675,972,3.661,977,2.764,989,1.979,992,1.959,995,2.883,1047,3.823,1078,4.847,1162,4.84,1327,3.436,1395,2.879,1471,6.538,2098,3.602,2100,7.246,2123,3.602,2467,3.436,2971,3.304,3233,3.602,3616,6.452,3617,5.886,3627,3.823,3628,3.304,3748,2.879,3763,4.159,3764,4.159,3765,3.602,3766,4.159,3767,4.159,3768,4.159,3769,4.159,3770,4.159,3771,4.159,3772,4.159,3773,4.159,3774,4.159,3775,8.77,3776,4.159,3777,4.159,3778,3.823,3779,4.159,3780,6.404,3781,6.404,3782,4.159,3783,6.404,3784,4.159,3785,4.159,3786,4.159,3787,4.159,3788,4.159,3789,4.159,3790,4.159,3791,4.159,3792,6.404,3793,4.159,3794,6.404,3795,4.159,3796,4.159,3797,4.159,3798,4.159,3799,4.159,3800,6.404,3801,6.404,3802,4.159,3803,4.159,3804,4.159,3805,4.159,3806,4.159,3807,4.159,3808,4.159]],["t/1101",[6,0.078,100,2.085,110,1.378,129,2.469,168,1.209,191,1.878,193,1.682,204,0.883,208,0.646,232,1.782,286,1.817,347,1.84,374,0.812,384,2.284,398,2.464,399,3.002,420,1.123,428,1.475,431,1.844,432,3.796,434,2.44,478,3.134,520,1.534,529,3.74,585,4.78,639,1.945,793,2.641,961,2.068,989,1.334,992,2.035,995,2.968,1067,3.432,1145,7.107,1181,2.411,1208,5.708,1312,1.973,1491,2.308,1915,2.177,2093,1.709,2906,3.134,3123,3.317,3130,3.432,3616,5.446,3628,3.432,3754,3.74,3809,4.319,3810,4.319,3811,3.97,3812,6.592,3813,5.237,3814,4.319,3815,4.319,3816,4.319,3817,4.319,3818,4.319,3819,4.319,3820,4.319,3821,4.319,3822,4.319,3823,4.319,3824,4.319,3825,6.922,3826,4.319,3827,4.319,3828,4.319,3829,4.319]],["t/1103",[6,0.077,208,1.394,232,3.844,424,4.163,743,3.259,961,5.342,1534,3.751,2093,3.685,3747,6.759,3748,6.447]],["t/1105",[6,0.077,110,1.07,160,1.553,193,2.085,204,1.612,431,3.102,487,2.8,513,2.616,573,3.404,728,4.685,743,2.758,908,4.623,989,3.109,2078,5.876,3747,5.72,3748,5.457,3830,7.246,3831,7.883,3832,8.715,3833,7.883,3834,7.246,3835,7.246]],["t/1107",[6,0.078,80,1.76,96,2.567,100,2.271,110,1.356,149,1.84,153,1.187,158,3.024,160,1.84,170,1.533,190,3.422,193,1.757,198,2.416,208,0.704,212,1.769,214,1.554,232,1.941,254,2.252,286,2.957,292,3.256,354,4.244,374,0.58,398,2.573,424,3.143,435,2.234,476,1.598,487,2.99,512,1.622,520,1.67,522,3.506,573,3.036,589,2.172,592,2.765,622,1.435,623,3.718,743,1.646,793,2.876,908,2.758,988,3.067,992,3.312,1118,2.165,1534,2.831,1545,2.966,1681,2.876,1743,4.867,2026,2.966,2207,3.613,3429,3.413,3615,2.689,3747,3.413,3748,7.526,3750,5.586,3778,4.324,3825,4.073,3832,6.088,3835,4.324,3836,4.704,3837,4.704,3838,4.324,3839,4.704,3840,4.704,3841,4.324,3842,3.737,3843,4.704,3844,3.886,3845,7.03]],["t/1109",[6,0.078,98,1.497,110,1.458,114,2.232,150,1.571,160,1.178,185,1.161,193,1.124,198,1.955,200,1.561,204,1.509,207,2.17,208,1.827,232,4.625,424,2.672,431,1.673,494,1.937,512,1.312,585,2.034,743,2.582,969,2.484,989,2.98,992,1.793,995,2.691,1038,2.924,1118,2.752,1132,1.919,1521,1.902,1534,2.972,1743,2.635,1752,2.695,1901,2.204,1928,5.466,1983,2.58,2071,5.558,3747,2.762,3748,5.788,3750,5.864,3755,3.499,3757,3.499,3838,3.499,3841,5.494,3842,3.024,3844,3.145,3846,3.806,3847,3.806,3848,3.806,3849,3.806,3850,7.38,3851,3.806,3852,3.499,3853,3.806]],["t/1111",[6,0.078,10,1.405,55,3.004,80,2.597,110,1.077,153,2.003,158,1.049,160,1.825,164,1.718,179,3.136,193,1.493,198,1.781,207,0.78,208,1.456,232,3.583,254,2.658,286,1.459,288,2.121,292,2.401,326,1.488,344,1.244,347,3.382,348,2.224,366,2.517,374,1.07,399,2.164,424,2.482,431,1.554,435,1.647,487,1.972,495,2.866,500,4.808,513,1.843,532,3.599,533,3.397,541,3.532,559,1.959,565,1.609,589,2.145,591,1.597,592,1.364,595,1.45,641,2.586,645,1.674,678,1.55,686,1.765,904,2.664,905,2.967,906,1.914,909,2.187,961,2.658,968,2.351,988,2.023,1082,2.664,1156,2.351,1171,4.615,1202,2.456,1209,2.866,1225,1.718,1312,1.585,1351,2.866,1395,2.401,1491,1.853,1521,1.733,1647,2.351,1681,2.121,1721,2.664,1743,2.401,1798,3.004,1811,2.401,1915,1.748,1928,4.038,1984,5.176,1994,4.038,2084,3.004,2085,3.004,2093,3.14,2247,3.932,2287,2.351,2540,1.765,2555,2.263,3252,3.188,3273,2.756,3750,2.756,3758,3.188,3854,3.468,3855,5.552,3856,3.468,3857,3.468,3858,3.468,3859,3.468,3860,6.382,3861,3.468,3862,3.004,3863,3.468]],["t/1113",[6,0.078,80,2.025,110,0.734,160,2.086,176,1.866,208,1.584,226,2.68,232,4.369,344,2.796,374,1.46,424,5.079,481,3.057,513,3.771,559,5.158,961,3.731,1312,2.473,1355,2.78,1534,2.18,1647,3.669,1743,3.747,1811,5.395,1891,4.603,1915,2.728,1928,3.965,2082,3.174,2084,4.687,2085,4.687,2086,6.201,2247,8.045,2453,4.687,3457,5.655,3750,4.3]],["t/1115",[6,0.078,80,1.589,110,1.665,150,3.265,153,1.997,193,0.799,207,0.956,208,1.662,226,3.223,232,4.333,286,3.328,354,3.281,374,1.093,431,1.189,500,6.851,512,2.728,532,3.534,533,3.421,961,2.034,989,2.011,1064,3.768,1355,3.342,1915,2.141,1994,2.161,2050,2.034,2071,7.662,2080,2.428,2082,2.491,2086,2.637,2093,3.13,2555,2.772,2948,3.51,3860,5.982,3864,4.248,3865,4.248]],["t/1117",[6,0.078,80,2.302,110,1.329,158,1.861,160,1.93,176,2.122,185,1.877,204,1.258,207,1.92,208,1.868,221,3.048,232,4.744,374,0.758,424,2.751,512,2.122,513,3.251,591,2.833,709,4.764,729,6.042,961,2.946,1355,3.161,1398,2.366,1534,2.479,1920,3.946,1928,3.131,2071,4.091,2078,4.588,2086,3.82,3852,9.004]],["t/1120",[6,0.078,110,1.269,150,2.909,160,1.843,193,1.76,208,1.055,221,3.49,232,2.909,424,3.151,431,2.618,622,2.15,908,4.133,961,4.479,989,2.178,995,3.173,1398,2.71,1534,2.838,1743,4.879,1891,3.553,2093,3.702,2261,4.519,2555,4.599,3749,6.478,3866,6.478]],["t/1122",[6,0.074,3867,10.331]],["t/1124",[6,0.078,10,2.387,110,1.58,130,4.525,153,2.089,158,2.503,160,2.045,204,1.205,208,1.553,317,2.169,374,0.726,383,2.216,480,3.048,532,1.983,533,1.92,585,3.148,589,1.82,597,2.944,742,2.918,963,4.372,966,3.659,989,1.82,993,3.716,1041,2.291,1106,4.681,1112,5.139,1142,3.994,1405,4.079,1534,3.334,1538,2.821,1565,3.657,1643,2.228,1891,2.97,3868,5.892]],["t/1126",[6,0.078,10,1.09,80,1.006,98,1.058,99,2.472,110,1.497,130,2.066,153,0.679,154,1.09,155,1.764,158,1.76,160,2.268,168,1.905,176,0.927,185,1.375,193,1.543,198,1.381,199,1.804,204,1.782,207,1.309,208,1.737,212,1.012,214,0.889,219,1.07,221,1.332,236,0.914,268,0.955,317,0.99,342,1.669,367,1.952,374,1.298,384,1.422,398,0.741,420,1.513,424,1.202,431,1.905,480,3.021,485,1.408,487,0.955,513,0.893,520,1.601,532,1.959,533,1.896,534,1.138,559,1.519,573,1.161,575,1.959,585,1.437,587,3.055,589,1.393,622,2.077,720,2.329,742,2.232,854,1.724,906,1.484,961,1.288,963,3.465,966,1.723,967,1.083,969,4.443,989,2.104,991,2.222,993,1.696,994,2.941,998,1.058,1038,2.066,1041,2.648,1079,1.788,1112,2.798,1117,1.609,1118,2.075,1126,1.598,1128,4.227,1132,1.356,1142,3.055,1198,1.452,1312,1.229,1353,2.137,1398,1.733,1405,1.862,1520,1.696,1534,2.343,1538,1.288,1547,1.598,1551,1.577,1578,2.222,1588,2.137,1590,1.012,1643,1.017,1765,3.271,1836,4.366,1891,2.272,1965,1.904,1984,2.005,2071,1.788,2072,1.952,2231,2.222,2245,1.669,2304,2.137,2316,2.329,2317,2.329,2445,1.755,2450,3.055,3425,1.904,3842,2.137,3869,2.689,3870,2.689,3871,2.689,3872,4.143,3873,4.507,3874,4.507,3875,2.689,3876,3.903,3877,2.689]],["t/1128",[6,0.078,98,3.244,110,1.595,154,1.504,158,1.123,160,1.155,170,1.21,198,3.01,199,1.486,204,1.686,208,0.877,212,2.204,216,2.149,221,1.838,231,2.997,236,1.261,247,2.38,317,2.158,333,3.437,374,0.457,398,2.935,399,2.974,401,1.267,408,2.851,420,1.888,425,3.368,428,2.001,430,5.071,478,2.694,486,1.495,506,3.895,512,1.28,520,1.318,534,1.571,622,2.215,623,1.963,624,2.497,628,3.824,634,3.199,639,1.671,839,2.004,849,1.696,963,2.678,966,1.419,994,2.422,1079,4.826,1106,2.949,1118,2.698,1128,2.304,1162,3.234,1178,1.871,1242,2.122,1451,3.973,1534,1.495,1627,5.119,1643,2.746,1939,4.376,1964,2.949,2050,3.948,2071,2.467,2447,2.949,2493,4.922,3484,3.215,3762,3.412,3878,3.712,3879,3.712,3880,3.412,3881,3.712,3882,3.712,3883,3.712,3884,3.712,3885,3.712,3886,3.215,3887,3.712,3888,3.712,3889,5.075,3890,3.712,3891,3.712,3892,3.215,3893,3.712,3894,3.412,3895,3.412,3896,3.712,3897,3.712,3898,3.712,3899,3.712,3900,3.412,3901,3.712,3902,3.712,3903,3.412]],["t/1130",[6,0.078,83,2.377,110,1.601,149,2.238,160,1.128,191,2.488,193,1.076,199,3.247,204,1.658,208,0.856,374,0.705,398,2.822,399,3.193,420,1.488,425,3.762,476,1.945,478,4.153,486,3.266,505,2.885,520,3.639,532,1.926,533,1.865,534,3.433,565,4.753,589,1.768,591,2.635,622,2.474,623,3.027,963,2.615,966,2.188,1128,3.553,1178,2.885,1312,2.615,1491,3.058,2053,3.232,2078,4.266,2493,3.879,2553,5.26,2554,5.26,3582,3.232,3635,4.153,3904,4.956,3905,4.956,3906,5.26,3907,5.26,3908,5.723]],["t/1132",[6,0.078,9,2.319,110,1.08,153,0.88,155,2.063,158,1.687,160,1.569,170,1.818,190,2.715,193,1.964,200,2.859,207,0.785,208,1.043,222,2.2,230,1.606,365,3.577,374,0.859,377,1.571,383,1.312,398,1.536,420,2.071,428,1.191,431,2.834,476,3.156,480,2.566,486,1.405,505,4.014,520,3.093,532,1.174,533,1.137,541,1.775,573,2.409,589,1.078,599,2.772,622,3.186,624,2.377,660,2.415,766,2.532,963,3.185,989,2.154,994,2.276,995,1.571,1041,1.357,1534,2.247,1535,2.276,1538,1.67,1643,3.83,1718,5.765,1984,2.601,2044,7.541,2237,2.601,2252,2.237,2454,2.601,2467,2.882,2613,3.021,3429,4.048,3441,3.207,3458,2.772,3571,2.601,3909,3.489,3910,9.31,3911,3.489,3912,5.578,3913,5.578,3914,5.578,3915,5.578,3916,5.578,3917,5.578,3918,5.578,3919,5.578,3920,3.489,3921,2.319,3922,3.489,3923,3.489,3924,3.489,3925,3.489,3926,3.021]],["t/1134",[6,0.077,10,3.064,80,1.943,89,3.769,110,1.329,153,1.311,155,1.345,160,1.49,164,2.572,168,1.453,176,1.79,193,0.977,204,1.546,208,1.132,219,2.067,230,3.482,231,2.143,236,1.765,254,2.486,286,2.184,288,4.625,292,3.595,317,1.912,319,2.391,326,2.228,327,2.507,347,2.213,348,3.33,374,1.34,398,2.083,420,1.35,425,2.409,431,1.453,436,1.808,486,2.092,487,1.844,513,1.724,517,3.046,575,1.748,622,2.307,637,3.389,664,5.231,678,2.322,725,3.176,818,2.835,905,2.775,909,3.275,961,2.486,963,2.373,988,1.892,989,1.605,1041,2.02,1113,3.871,1117,1.854,1351,4.291,1469,5.488,1538,2.486,1643,2.86,1996,3.871,2026,3.275,2073,4.126,2093,3.529,2245,3.224,3033,4.126,3036,4.774,3571,3.871,3927,5.193,3928,4.774,3929,4.774,3930,5.193,3931,5.193,3932,4.497,3933,5.193]],["t/1136",[6,0.077,10,2.275,110,1.559,153,1.417,158,3.073,160,2.116,185,1.713,204,1.148,208,1.87,214,2.643,219,2.235,254,2.688,286,2.362,331,4.863,344,2.015,347,2.393,357,4.863,374,1.416,436,3.245,517,3.293,532,1.89,533,1.83,575,1.89,622,1.713,725,3.434,906,3.099,909,3.541,988,2.046,999,3.732,1041,2.184,1117,2.856,1128,4.967,1469,4.075,1534,4.091,1551,3.293,1564,2.458,1643,3.842,1891,2.831,1983,3.807,1994,2.857,1996,4.186,2026,3.541,2093,2.222,2245,3.486,3934,8.001,3935,5.615]],["t/1139",[6,0.078,80,2.936,110,1.582,212,3.775,327,3.789,398,3.047,486,4.042,686,5.106,924,6.797,1117,2.801,2245,4.872,3936,7.848,3937,7.848,3938,7.848]],["t/1141",[6,0.078,10,2.226,110,1.504,153,1.387,160,1.083,193,1.034,256,2.297,317,3.921,332,3.804,374,0.677,398,3.144,399,2.87,425,5.295,431,1.538,436,1.913,480,2.023,486,2.213,513,1.824,534,2.326,565,5.416,570,4.366,623,4.871,628,3.586,645,3.803,980,3.804,1117,1.961,1126,3.266,1355,2.822,1469,3.988,1491,2.936,1565,3.411,1643,2.078,1673,4.221,1731,3.411,1994,2.796,2061,4.096,2090,4.54,2245,3.411,2559,3.891,3939,5.495,3940,5.495,3941,5.495,3942,5.051,3943,4.759,3944,5.495]],["t/1143",[2,2.706,6,0.078,110,1.101,155,2.655,158,1.338,160,1.323,193,1.704,200,3.715,208,1.005,216,3.887,230,3.091,261,2.416,286,1.861,306,2.63,317,1.629,326,1.898,344,1.588,347,1.886,374,0.545,398,1.219,420,1.151,425,2.053,431,2.534,476,1.504,480,1.629,513,1.469,842,2.888,933,1.937,959,1.951,969,2.888,989,2.799,992,2.085,1079,2.942,1117,2.896,1405,3.064,1491,2.365,1643,2.539,1718,6.044,1925,3.399,2026,2.791,2044,8.432,2061,3.299,2090,3.657,2245,4.168,3571,3.299,3907,4.068,3910,7.458,3945,6.715,3946,4.425,3947,4.425,3948,4.425,3949,4.425,3950,4.425,3951,4.425,3952,5.548]],["t/1145",[6,0.078,10,1.082,102,1.322,110,1.545,149,1.044,153,1.13,154,1.082,155,1.956,160,1.982,168,2.55,170,2.208,176,1.544,185,1.366,193,0.842,199,1.069,204,2.057,208,1.626,212,1.685,232,1.849,316,1.202,344,0.958,347,1.909,374,1.24,384,1.412,398,1.234,399,0.832,401,1.529,420,2.545,424,1.193,425,1.238,428,1.529,431,1.253,432,1.268,487,0.948,513,1.487,520,1.591,532,0.899,533,0.87,534,3.46,567,1.89,573,2.499,575,2.542,589,0.825,624,1.137,637,1.742,693,1.99,743,0.934,883,2.312,960,1.457,963,1.22,966,1.713,989,1.788,992,1.258,994,3.776,995,2.017,1041,3.378,1064,1.545,1117,0.953,1128,2.781,1129,3.954,1131,1.742,1132,1.346,1198,1.441,1312,1.22,1396,2.121,1399,2.121,1405,3.101,1520,1.683,1534,1.075,1538,2.144,1590,1.004,1633,1.937,1643,1.01,1895,1.289,2050,1.278,2053,1.508,2093,1.772,2787,2.977,3545,2.121,3632,2.561,3872,2.454,3953,2.669,3954,2.669,3955,2.669,3956,2.669,3957,2.669,3958,2.669,3959,4.479]],["t/1147",[6,0.078,49,2.566,110,1.37,160,1.561,185,1.299,193,0.801,201,3.348,208,1.573,214,1.407,374,1.295,383,2.98,420,1.107,487,3.153,512,2.248,533,2.125,534,2.76,595,2.725,742,5.712,817,3.383,942,4.513,963,1.945,989,1.316,998,1.675,1065,3.27,1118,1.96,1202,3.015,1244,6.287,1405,4.513,1611,4.278,1895,2.055,1932,2.299,1939,2.566,2555,2.778,2685,4.731,3022,4.254,3251,5.485,3570,3.09,3876,6.861,3943,3.687,3960,6.52,3961,4.258,3962,4.258,3963,4.258,3964,4.258,3965,4.258,3966,4.258,3967,4.258,3968,4.258]],["t/1149",[6,0.078,110,1.575,155,1.394,158,1.627,160,1.529,185,1.641,191,3.373,193,1.012,204,1.1,208,0.805,212,2.024,300,3.115,316,2.422,374,1.302,431,1.505,436,1.873,512,1.855,565,2.496,597,2.688,839,4.914,963,2.458,989,2.397,1069,3.576,1080,4.445,1117,1.92,1142,6.753,1355,2.763,1538,3.715,1643,2.035,2053,3.039,2093,2.129,2245,3.34,3969,4.945,3970,4.945]],["t/1151",[6,0.078,80,1.22,96,1.78,110,1.611,129,1.864,153,1.681,160,0.642,208,0.791,217,2.504,221,2.616,317,3.098,327,3.696,332,2.257,359,2.572,374,0.402,398,2.612,399,2.076,401,1.113,422,2.208,425,3.903,487,1.158,505,1.644,510,1.864,520,1.876,534,2.819,570,2.591,575,1.098,585,1.742,589,1.007,623,2.794,645,1.574,676,2.949,686,1.659,742,1.615,815,1.437,929,2.949,963,1.49,966,1.247,995,1.468,1036,1.601,1284,2.694,1312,1.49,1386,1.8,1491,2.823,1771,5.503,2011,2.056,2286,1.842,2304,5.291,2341,4.014,2559,2.309,2748,2.504,3926,2.824,3943,2.824,3971,8.414,3972,8.414,3973,3.261,3974,3.261,3975,7.287,3976,11.552,3977,6.66,3978,3.261,3979,3.261,3980,3.261,3981,3.261]],["t/1153",[6,0.077,98,3.56,110,1.39,130,6.951,153,1.692,155,1.737,160,2.018,193,1.702,204,1.85,208,1.533,219,2.669,299,7.477,374,1.351,383,2.522,431,2.532,436,2.335,480,3.332,494,3.412,533,2.185,575,2.257,589,2.072,595,2.802,742,4.481,854,4.3,960,3.66,963,4.135,969,4.375,989,2.072,1065,5.151,1142,4.546,1590,3.404,1891,3.38,1901,5.239,2011,4.229,2053,3.788,2069,5.541,2093,2.653,2467,5.541,2555,4.375,3982,6.706,3983,6.706,3984,6.706]],["t/1155",[6,0.073,3985,10.391]],["t/1157",[6,0.077,110,1.698,149,2.575,153,1.661,154,2.667,204,1.827,208,1.796,254,3.152,344,2.362,399,2.052,424,2.943,439,5.261,440,3.593,486,2.651,513,3.368,528,4.086,532,2.216,533,2.145,559,3.718,565,3.054,709,3.675,966,3.417,988,2.398,1405,4.557,1590,2.476,1643,3.837,1727,5.23,2049,4.279,2093,2.604,2341,3.967,3632,3.763,3666,5.056,3986,6.583,3987,6.583]],["t/1159",[2,2.012,6,0.078,102,1.629,110,1.655,149,2.621,153,1.343,158,0.995,160,2.017,173,2.075,193,1.448,204,1.37,207,1.732,208,1.641,219,2.118,286,1.384,327,1.588,344,2.404,359,2.591,368,2.388,374,1.042,398,1.466,399,2.635,420,1.384,424,1.471,425,1.526,431,0.921,439,4.383,440,1.796,486,1.325,505,1.659,513,2.224,520,1.169,528,2.043,532,1.791,533,1.734,534,1.393,559,1.859,565,1.526,589,2.07,597,1.644,639,2.396,709,1.837,815,1.45,961,1.575,963,2.432,964,1.44,966,2.562,988,1.199,989,1.017,990,2.33,992,1.55,995,2.396,998,2.093,1006,2.043,1101,2.11,1128,3.304,1131,2.147,1174,2.147,1534,1.325,1551,1.93,1643,2.534,1727,2.614,1731,2.043,1900,2.11,1983,2.23,1994,1.674,2093,1.302,2341,1.983,2445,2.147,3017,2.849,3632,3.831,3754,2.849,3988,3.29,3989,3.29,3990,3.29,3991,3.29,3992,3.29,3993,3.29,3994,3.29]],["t/1162",[6,0.077,155,2.051,160,1.988,199,3.17,204,2.063,207,1.782,208,1.185,236,2.691,317,2.915,374,1.244,420,2.059,425,3.673,430,4.472,480,2.915,520,3.584,622,2.415,631,4.527,634,4.322,964,3.466,998,3.114,1078,4.915,1118,3.645,1398,3.044,1939,4.772,2056,4.527,3691,6.857,3995,6.081,3996,7.918,3997,7.918,3998,7.918,3999,7.278,4000,7.918,4001,7.918]],["t/1164",[6,0.077,110,1.576,160,1.834,190,3.404,193,1.315,204,2.28,207,1.574,208,1.669,231,2.886,232,2.886,333,4.101,343,5.556,398,1.926,399,2.179,401,2.388,420,1.818,496,5.074,622,2.133,631,3.998,634,3.817,963,3.195,964,4.074,966,4,1198,3.776,1590,2.63,1994,3.558,2000,5.074,2056,3.998,2457,4.841,2493,4.74,3429,5.074,3691,6.056,3889,6.056,3999,6.428,4002,6.993,4003,6.993,4004,6.993,4005,6.993,4006,6.993]],["t/1167",[6,0.077,10,2.092,102,4.403,110,1.41,149,2.946,155,1.951,160,1.017,168,1.445,173,3.256,185,1.575,187,4.75,193,0.971,200,2.118,204,1.54,231,2.131,232,2.131,247,3.311,374,0.636,385,2.131,398,2.074,399,2.771,401,2.572,420,1.343,423,3.256,430,2.917,434,4.254,439,2.677,440,4.111,480,1.901,520,1.834,622,1.575,628,3.369,631,4.306,634,2.818,712,2.882,749,3.391,790,4.746,839,2.788,966,2.88,1060,3.747,1131,3.369,1132,2.603,1162,4.907,1459,3.157,1727,5.984,1964,4.102,2056,2.952,2344,4.102,2457,3.574,2493,3.5,3301,3.849,3429,3.747,3493,4.102,3632,5.94,3889,4.471,4007,5.163,4008,5.163,4009,6.223,4010,5.163,4011,5.163,4012,5.163,4013,5.163,4014,5.163,4015,5.163,4016,8.983,4017,5.163,4018,5.163,4019,7.531,4020,5.163,4021,5.163,4022,5.163,4023,5.163,4024,5.163,4025,5.163,4026,4.746,4027,5.163,4028,4.746,4029,5.163,4030,5.163,4031,5.163,4032,5.163,4033,4.746,4034,5.163,4035,5.163]],["t/1170",[6,0.078,110,1.369,149,3.097,153,1.998,398,2.181,399,2.468,439,6.065,440,5.508,534,3.352,597,3.956,1302,5.902,1836,5.077,3632,4.527,4036,7.918,4037,7.918,4038,7.278]],["t/1172",[6,0.076,102,4.239,110,1.161,168,2.965,173,5.398,204,2.167,398,2.357,433,5.019,434,4.835,967,3.447,1060,6.211,1181,4.778,1198,4.622,1225,4.239,1302,6.38,1459,5.234,1590,3.219,1604,6.8,1836,5.488,1956,7.072,4039,8.559,4040,8.559,4041,7.868]],["t/1174",[6,0.077,165,4.69,168,3.103,216,6.419,262,5.266,437,8.517,1067,7.324]],["t/1176",[6,0.077,110,1.145,149,4.108,204,1.725,398,2.324,399,3.274,434,4.766,597,5.715,743,2.952,1590,3.174,1604,6.704,1836,5.411,2457,5.842,2604,5.975,3632,4.824]],["t/1178",[6,0.077,102,5.121,110,1.644,149,4.044,153,1.724,191,2.971,193,1.285,204,1.397,374,0.842,399,3.777,420,2.689,575,2.3,622,2.795,963,3.122,964,2.991,989,2.111,992,3.219,1132,3.445,1174,5.98,2493,4.632,3632,6.588,4009,7.572,4016,8.424,4042,6.833,4043,6.833]],["t/1181",[6,0.073,374,1.191,487,3.432,678,4.32,961,4.627,1647,6.551,1915,4.872,2075,6.843,2080,5.525,2082,5.668,2086,5.999,2093,3.824,2286,5.459,2287,6.551]],["t/1183",[6,0.075,160,1.864,424,5.035,428,3.846,513,3.738,624,4.031,1643,4.548,1784,7.267,4044,9.461,4045,9.461]],["t/1185",[6,0.077,110,1.406,149,2.683,168,1.919,170,2.235,232,2.831,249,5.113,262,4.363,318,4.748,319,3.158,398,3.048,399,3.229,401,2.342,420,1.784,424,3.066,428,2.342,432,3.258,506,4.559,534,2.904,622,2.092,639,3.088,818,3.744,849,3.134,853,4.857,966,2.623,967,2.762,989,2.119,992,3.232,1113,5.113,1395,7.172,1750,5.667,2050,3.284,3518,7.957,3632,5.253,4009,5.667,4046,6.859,4047,6.859,4048,6.859,4049,6.859,4050,6.859,4051,6.859,4052,6.859,4053,6.859,4054,6.859,4055,6.859,4056,6.859]],["t/1187",[6,0.077,98,2.794,110,1.276,149,2.778,160,1.4,167,2.425,168,1.988,199,2.844,204,1.452,317,2.615,319,3.27,374,1.299,377,3.198,398,2.904,399,3.286,401,2.425,420,2.741,425,3.295,432,3.373,435,3.373,436,2.473,476,2.414,520,2.523,589,2.195,622,2.167,818,3.877,964,3.109,1069,4.722,1079,4.722,1113,5.295,1170,4.222,1174,4.635,1643,3.557,2341,4.281,3632,5.377,4009,5.869,4057,7.103,4058,7.103,4059,7.103]],["t/1189",[6,0.076,110,1.664,207,1.872,208,1.835,434,4.7,439,5.893,992,3.92,1145,6.611,2049,4.986,3463,4.88,3581,6.137,3582,4.7,3583,7.206,3632,6.498]],["t/1191",[6,0.077,110,1.519,208,1.675,513,3.107,2049,5.358]],["t/1195",[6,0.078,102,3.027,110,1.556,149,2.391,154,2.477,158,2.569,208,1.659,214,2.019,216,3.538,262,2.903,326,4.186,327,4.1,385,2.523,398,3.053,399,1.905,434,4.797,439,5.469,440,5.327,512,2.107,559,3.452,709,4.741,941,4.556,992,2.88,1036,3.001,1117,2.182,1145,4.856,1302,4.556,2344,6.748,3632,4.856,4038,5.618,4060,7.807,4061,6.112]],["t/1197",[6,0.078,80,2.481,110,1.548,149,2.594,153,1.674,155,1.718,204,1.356,208,1.634,326,2.844,327,3.201,374,1.107,383,2.494,398,1.826,439,4.657,512,3.096,513,2.981,709,3.702,952,4.943,992,3.124,1302,4.943,1308,2.826,1590,2.494,1643,2.508,2025,4.408,2049,4.3,2093,3.553,3463,3.889,3582,3.746,3632,3.791,4041,6.096,4062,6.631]],["t/1199",[6,0.077,110,1.654,153,2.815,176,2.411,185,2.133,208,1.824,254,5.339,326,3.992,327,3.376,331,6.056,344,2.509,398,1.926,439,5.424,693,6.938,709,3.904,1117,2.496,1643,2.645,2093,2.767,3033,5.556,3582,3.95,3632,3.998,4063,6.993,4064,6.993]],["t/1201",[6,0.078,110,1.588,204,1.464,208,1.584,217,7.262,326,4.055,398,1.972,399,2.232,439,4.902,565,4.385,623,3.787,645,5.109,709,3.997,1491,5.052,2080,4.094,2093,2.833,4060,6.582,4065,7.16,4066,7.16]],["t/1203",[6,0.078,80,3.786,110,1.373,185,2.426,208,1.19,327,4.885,344,2.853,374,0.98,398,2.19,439,4.124,559,4.492,686,5.149,709,4.44,1643,3.008]],["t/1205",[6,0.077,110,1.657,185,3.149,208,1.545,326,4.428,327,4.983,344,2.944,398,2.843,439,4.255,709,4.582,1643,3.104,3932,7.107,4067,7.544,4068,7.107]],["t/1208",[6,0.077,110,1.094,149,3.992,193,1.516,204,1.648,374,0.993,434,4.552,440,4.399,597,5.099,1126,4.79,1915,4.063,2075,5.707,2080,4.608,2086,5.003,2093,3.189,2344,6.404,3632,6.404]],["t/1210",[6,0.077,80,3.264,168,2.441,326,3.743,327,4.212,433,5.117,434,6.058,677,6.131,1050,8.02,1956,7.209,3250,8.02,4069,8.725,4070,8.725,4071,8.725]],["t/1212",[6,0.078,110,1.624,153,1.938,193,1.445,208,1.481,254,3.677,374,0.947,399,2.394,431,2.149,439,5.132,565,3.563,966,2.937,1308,3.273,2093,3.039,3632,4.391]],["t/1214",[6,0.077,110,1.434,149,3.332,207,1.917,208,1.581,321,5.288,327,4.112,398,2.346,428,3.608,709,4.755,1643,3.222,2093,3.37,3632,4.87,4072,8.518,4073,8.518,4074,8.518]],["t/1218",[6,0.077,10,2.707,102,4.47,110,1.552,149,3.998,168,2.526,173,4.213,204,2.338,208,1.351,231,4.72,374,0.823,398,1.84,399,2.813,402,6.933,423,4.213,434,3.774,437,5.131,439,4.68,575,2.249,839,3.607,842,5.89,967,4.117,1060,4.848,1131,4.359,1459,4.085,2341,4.026,2618,5.52,3301,4.98,3632,5.845,4026,6.141,4028,6.141,4075,6.681,4076,6.681,4077,6.681,4078,6.681,4079,6.681,4080,6.681,4081,6.681,4082,6.681,4083,6.681,4084,6.681,4085,6.681]],["t/1221",[6,0.078,102,4.781,110,1.62,149,2.343,187,3.778,208,1.646,399,3.009,434,4.73,439,5.421,440,5.707,513,1.988,559,4.73,1117,2.989,2093,2.37,2344,7.671,3632,5.977]],["t/1223",[6,0.074,4086,10.331]],["t/1225",[6,0.078,110,1.601,154,2.502,155,2.542,160,1.685,193,1.162,204,1.262,208,1.469,212,2.323,316,3.851,344,2.215,374,1.418,383,2.323,422,3.575,431,1.728,476,2.099,480,3.149,575,2.879,589,1.908,597,3.085,673,2.565,743,2.993,818,3.371,959,2.722,966,2.361,998,2.429,1064,3.575,1118,3.938,1308,2.631,1398,2.374,1564,2.703,2007,4.373,2036,2.801,2050,2.957,2062,5.394,3739,3.67,4087,5.676]],["t/1227",[6,0.078,83,1.507,110,1.643,150,1.498,153,1.453,160,0.715,176,1.251,193,0.683,204,1.463,208,1.071,212,1.365,214,1.199,221,1.797,268,1.289,316,2.592,317,1.336,374,1.457,383,3.554,422,2.99,431,1.016,476,2.431,480,1.336,513,1.205,532,1.222,533,1.183,575,2.741,589,1.121,597,4.069,663,1.42,673,4.113,743,1.27,849,4.057,905,1.939,929,2.026,959,2.537,964,3.565,966,2.736,995,1.634,998,3.493,1036,1.782,1064,2.101,1117,2.055,1118,2.65,1308,1.547,1564,1.589,1590,1.365,1643,1.373,1826,2.788,1928,1.847,2007,2.57,2036,2.611,2050,1.738,2062,4.512,2093,1.436,2290,1.797,2772,3.143,3425,4.076,3463,2.129,3581,3.864,3739,4.84,4087,3.336,4088,2.999,4089,3.63,4090,3.63,4091,3.63]],["t/1230",[6,0.078,98,2.162,110,1.689,149,2.149,155,2.041,167,1.876,168,1.538,193,1.034,204,1.611,208,1.659,212,2.067,374,1.312,380,2.675,383,2.963,387,3.586,420,1.429,422,2.297,476,2.677,505,2.77,575,1.85,585,2.936,589,1.698,597,2.745,743,1.923,929,3.068,964,2.405,966,2.101,967,2.213,992,2.589,995,2.474,1041,2.137,1064,3.181,1130,3.068,1158,3.033,1242,3.142,1308,3.357,1590,2.067,1809,3.312,1828,3.988,1832,4.366,1833,2.474,2050,2.631,2186,5.051,2297,4.759,2298,4.54,3582,4.45,3593,4.54,4088,4.54,4092,3.725,4093,5.051,4094,5.495,4095,5.495]],["t/1232",[6,0.077,96,4.175,110,1.038,153,2.758,155,1.981,160,1.945,204,2.018,212,2.877,316,4.444,374,1.347,383,3.712,476,2.599,532,2.574,533,3.216,575,2.574,595,3.196,597,3.821,673,3.176,989,3.049,1118,3.521,1308,3.259,1590,2.877,1978,7.03,2062,7.282]],["t/1234",[6,0.077,110,1.079,153,2.554,160,1.567,374,1.491,383,4.187,476,2.703,591,3.661,592,3.128,728,4.727,743,3.541,818,4.341,929,4.44,1064,4.604,1118,3.661,1308,3.389,1374,5.505,1420,6.571,1937,6.571,2062,5.015,3739,4.727,4088,6.571,4096,5.771,4097,7.953]],["t/1236",[6,0.077,35,6.118,110,1.384,153,1.68,155,1.724,212,3.838,286,2.8,354,3.355,374,1.451,383,2.503,476,2.262,575,2.24,597,3.325,673,3.739,743,3.15,849,3.041,966,3.443,1064,3.853,1162,4.969,1242,3.805,1308,3.837,2748,5.112,3739,3.956,4098,6.656,4099,6.656,4100,6.656,4101,6.656,4102,6.656,4103,6.118,4104,6.118,4105,6.118,4106,6.656,4107,6.118,4108,6.656,4109,5.288,4110,9.004,4111,6.656,4112,6.656,4113,6.118]],["t/1238",[6,0.078,110,1.418,153,1.175,160,0.917,193,1.574,204,2.136,208,0.697,231,3.453,232,2.879,268,1.653,316,3.141,319,2.143,374,1.288,383,2.624,385,1.921,398,1.282,399,2.607,401,1.589,408,3.575,420,2.416,422,1.945,423,2.936,431,1.302,476,3.158,480,1.714,516,3.378,517,2.73,631,2.661,635,2.569,673,1.933,743,1.629,759,3.47,849,2.127,929,2.599,964,3.053,966,1.78,989,2.155,1079,3.094,1118,3.211,1129,3.653,1162,2.569,1308,1.983,1393,3.037,1451,3.155,1565,2.89,1590,2.624,1619,3.698,1627,5.193,1994,2.368,2056,2.661,2290,2.305,2493,3.155,2588,5.764,2748,3.575,3581,3.767,3659,3.846,3663,4.031,3664,4.031,3673,4.031,3739,2.767,4088,3.846,4113,6.412,4114,4.655,4115,4.655,4116,4.655,4117,4.655,4118,4.655,4119,4.655,4120,4.655,4121,4.655,4122,4.655,4123,4.655,4124,4.655,4125,4.655,4126,4.655,4127,4.655,4128,4.655,4129,4.655]],["t/1240",[6,0.076,110,1.562,155,2.543,193,1.426,212,2.852,222,4.782,316,3.414,374,1.505,476,3.336,480,2.792,575,2.553,597,5.438,743,2.653,849,5.58,959,4.326,966,2.9,1064,4.39,1308,4.183,1393,4.948,1892,6.567,2036,4.452,2050,3.631,2568,4.447,3739,4.507,4130,7.583]],["t/1242",[6,0.077,110,1.507,154,2.24,158,1.672,204,1.13,231,2.282,232,3.266,236,2.689,345,5.082,374,1.522,422,3.307,485,4.839,575,3.396,597,4.617,743,3.233,759,4.122,849,2.526,959,3.488,966,2.114,988,2.014,1117,1.974,1188,3.915,1211,4.122,1308,3.938,1429,5.074,1565,3.432,1972,5.082,2036,4.191,2496,6.538,2568,4.641,2578,6.287,2868,4.788,3521,5.082,4109,4.393,4131,5.529,4132,5.529,4133,5.529,4134,5.529,4135,5.529,4136,5.529,4137,5.529,4138,5.529,4139,7.274,4140,6.853,4141,5.529,4142,5.529,4143,7.635,4144,5.529,4145,5.529,4146,4.788,4147,5.529]],["t/1244",[6,0.078,110,1.498,149,1.408,158,1.089,160,1.127,165,1.832,185,1.098,193,0.677,204,0.736,208,0.539,212,1.354,232,2.937,279,4.726,319,4.335,374,1.217,383,2.152,385,1.486,401,1.229,420,0.936,422,1.505,425,1.67,433,4.174,476,1.224,485,1.885,487,1.279,520,2.032,538,3.118,543,7.78,545,2.975,575,1.926,597,4.05,743,2.001,793,3.498,818,1.965,849,2.614,933,1.576,964,1.576,1032,2.034,1064,5.121,1077,2.765,1078,2.235,1101,4.564,1185,2.309,1308,3.454,1429,3.668,1433,3.118,1439,2.765,1451,2.441,1495,2.765,1502,2.14,1520,2.271,1619,6.441,1627,3.551,2062,2.271,2177,3.118,2341,2.17,2496,5.881,2568,2.111,2588,4.726,2710,2.975,2892,6.542,3241,4.954,3242,3.31,3245,7.028,3545,2.861,3649,2.684,4109,2.861,4139,3.31,4140,3.118,4143,2.975,4148,3.6,4149,3.6,4150,3.6,4151,3.6,4152,3.6,4153,3.6,4154,3.6,4155,3.6,4156,5.72,4157,3.6,4158,7.117,4159,5.72,4160,5.72,4161,3.6,4162,3.6,4163,3.6,4164,3.6,4165,3.6,4166,3.6,4167,3.6,4168,3.6,4169,3.31,4170,3.6,4171,3.6,4172,3.6,4173,3.6,4174,3.6,4175,3.6,4176,3.6,4177,3.6,4178,3.6,4179,3.6,4180,3.6,4181,3.6,4182,3.6,4183,3.6,4184,3.6,4185,3.6,4186,3.6]],["t/1246",[6,0.077,41,2.899,80,1.943,110,1.522,153,1.909,155,1.345,164,4.417,185,1.584,193,1.678,208,0.777,212,2.845,214,1.716,232,2.143,254,2.486,319,3.482,374,1.445,383,1.953,385,2.143,431,1.453,476,3.539,485,3.96,516,3.769,575,1.748,597,3.779,645,4.306,743,1.817,849,3.456,959,2.289,1064,3.006,1162,2.866,1188,3.677,1308,3.223,1567,3.046,1746,4.497,2036,2.355,2062,5.625,2126,4.378,2290,2.572,2496,7.37,2906,3.769,3209,6.952,3245,4.126,3659,4.291,3739,3.087,4103,4.774,4104,4.774,4105,4.774,4107,4.774,4109,4.126,4140,4.497,4143,4.291,4146,4.497,4187,5.193,4188,5.193,4189,5.193,4190,5.193,4191,5.193,4192,5.193,4193,5.193,4194,5.193,4195,5.193,4196,5.193,4197,7.563,4198,5.193]],["t/1248",[6,0.077,110,1.256,193,1.305,204,2.13,212,3.483,214,2.292,231,5.02,321,5.748,374,1.428,476,3.541,512,2.392,516,5.035,575,2.336,597,3.467,842,6.042,849,3.17,966,2.653,967,2.794,1336,7.379,1435,6.009,2177,6.009,2290,3.436,2341,5.58,3425,6.556,3706,6.378,3707,6.378,4199,6.939,4200,6.939,4201,6.939,4202,6.939,4203,6.939,4204,6.939,4205,6.939,4206,6.939]],["t/1250",[6,0.076,158,2.788,176,3.178,185,2.812,204,1.885,214,3.045,373,4.063,487,3.274,512,3.823,532,3.103,533,3.004,998,3.626,1564,4.035,1590,3.467,3739,5.479,4207,9.218]],["t/1253",[6,0.076,98,2.886,155,1.9,176,2.529,185,3.267,226,3.633,374,1.32,476,2.493,505,3.698,591,3.377,638,3.88,659,4.421,1015,6.511,1308,3.126,1647,4.973,1895,3.541,1915,3.698,1932,3.961,2007,5.194,2080,4.194,2082,4.302,2083,5.468,2086,4.554,2093,2.902,2286,4.143,2287,4.973,2371,5.362,2402,4.973,2685,5.323,2686,5.194,3251,6.65,3254,7.378,3570,5.323,3571,5.468,3573,6.061,3574,6.061,3575,6.353,3576,6.353,3577,5.323,3578,5.468,3579,5.828,3580,6.061,3739,4.36,4208,6.061,4209,6.061]],["t/1255",[6,0.076,110,1.434,204,1.742,208,1.275,231,3.516,327,4.112,344,3.056,347,3.63,422,3.56,517,4.996,663,3.332,1118,3.922,1126,5.063,1127,5.774,1643,4.344,1784,6.543,1785,6.768,3712,7.038,4210,8.518,4211,8.518,4212,8.518,4213,8.518]],["t/1257",[6,0.077,110,1.633,154,4.055,155,2.592,160,1.54,204,2.046,208,1.498,374,0.963,383,2.939,422,3.266,476,3.401,480,2.877,623,4.133,645,3.772,673,3.245,998,3.074,1036,3.836,1308,3.33,1564,3.42,1590,2.939,1809,4.709,1928,3.976,2290,3.87,3463,4.583,3581,4.22,3582,4.414,3739,4.644]],["t/1259",[6,0.078,80,2.518,110,1.231,155,1.744,179,3.802,193,1.706,319,3.099,326,2.887,374,1.353,422,2.813,428,2.298,433,3.947,476,3.083,485,3.524,532,2.266,533,2.956,575,3.054,597,3.363,624,2.868,637,4.392,645,3.249,988,2.452,1064,3.897,1101,4.316,1308,4.373,1538,3.222,1562,5.817,1643,2.545,1717,3.802,2906,4.884,3739,6.099,4214,5.829]],["t/1262",[6,0.077,150,3.45,155,2.166,185,2.55,204,2.329,214,3.45,327,4.035,512,3.927,673,3.472,1036,4.104,1375,7.24,1590,4.284,2772,7.24,3581,4.514,3739,4.969]],["t/1264",[6,0.077,83,3.149,153,1.914,154,3.073,158,2.293,176,3.384,193,1.426,374,1.341,476,2.577,485,3.971,487,2.693,512,3.384,532,3.664,533,3.199,905,4.052,906,4.185,1308,3.231,1538,3.631,2080,4.336,2286,4.283,2290,3.755,3577,5.503,3581,5.3,3582,4.283,3739,5.834]],["t/1266",[6,0.077,80,2.861,110,1.339,193,1.438,226,3.787,344,2.744,374,1.535,383,3.712,431,2.14,476,2.599,512,2.637,743,2.676,961,5.232,1006,7.168,1308,4.206,1643,2.892,2011,4.823,2568,4.485,3581,4.13,3739,4.546,4208,6.319,4209,6.319]],["t/1268",[6,0.077,150,3.372,155,2.116,158,2.471,160,2.221,176,2.817,193,1.537,204,2.105,219,3.251,374,1.007,431,2.286,673,3.393,712,4.561,998,3.214,1590,3.073,1643,3.09,1785,6.491,1928,4.157,2093,3.232,3463,4.791,3581,4.412,3712,6.75,3739,6.699]],["t/1270",[6,0.077,110,1.527,155,1.855,176,2.469,212,2.693,332,6.545,374,1.534,399,2.232,422,2.992,476,3.213,575,2.41,597,4.723,712,3.997,718,3.866,743,3.308,818,3.908,849,3.272,929,5.278,2011,4.516,3248,6.201,3582,4.044,3739,5.619]],["t/1273",[6,0.078,110,1.699,193,1.624,319,2.882,374,1.378,383,2.355,476,2.128,480,2.305,575,2.108,597,4.315,743,3.021,818,3.418,1032,4.878,1064,4.999,1308,4.541,1317,5.174,1994,3.186,2568,5.797,3649,6.438,3739,5.133,4068,5.422,4215,6.261]],["t/1275",[6,0.078,80,2.7,110,1.442,319,5.655,433,6.232,543,5.964,570,7.551,1032,4.077,1064,6.538,1101,6.814,2093,3.76,2126,4.178,3245,5.735,3545,7.551,4216,6.634,4217,7.218,4218,7.218]],["t/1277",[6,0.077,80,3.379,110,1.486,422,3.775,1117,3.224,4219,9.032,4220,8.303,4221,9.032,4222,9.032]],["t/1279",[6,0.077,110,1.103,155,2.107,374,1.501,383,3.059,422,4.29,476,3.488,575,3.455,597,5.619,1032,6.353,1132,4.1,1308,3.465,2093,3.218,4223,8.133,4224,8.133]],["t/1281",[6,0.076,193,1.828,374,1.198,645,4.69,2062,6.128,2093,3.844,2906,7.051,4216,8.932]],["t/1283",[6,0.077,155,2.088,199,3.227,226,5.054,373,3.552,374,1.497,436,2.806,476,2.739,512,2.779,559,4.552,680,7.065,1308,4.349,1521,4.027,1525,5.579,1547,4.79,1611,4.352,3739,6.066,3866,7.409,4225,6.404,4226,8.06,4227,8.06,4228,6.98]],["t/1285",[6,0.077,110,1.588,153,1.807,155,1.855,204,1.933,208,1.584,212,2.693,316,3.224,373,3.156,374,1.511,383,3.981,476,3.213,480,2.636,575,3.563,597,4.723,673,2.974,743,2.505,849,4.32,998,2.816,1032,4.044,1064,4.145,1188,5.07,1308,4.028,1565,4.445,1590,2.693,2036,3.247,2062,4.516,2568,5.544,4146,6.201]],["t/1287",[6,0.074,4229,10.272,4230,10.272]],["t/1289",[6,0.078,98,3.271,110,0.805,160,1.639,185,1.809,193,1.564,204,1.963,207,1.335,208,1.64,268,2.953,344,2.128,374,1.283,398,2.29,401,2.025,422,2.479,431,1.659,480,2.183,505,2.99,512,2.045,528,3.682,575,1.996,589,2.967,622,1.809,937,3.87,959,2.614,989,2.967,995,2.67,998,3.271,1006,3.682,1041,4.419,1132,2.99,1183,4.555,1534,2.388,1538,2.839,1928,5.296,2445,3.87,2457,4.106,2787,3.942,4225,4.712]],["t/1291",[6,0.078,109,2.026,110,0.781,130,2.788,153,2.055,155,1.491,158,2.164,160,1.134,168,1.611,170,1.183,176,1.251,185,1.756,193,1.346,204,2.262,207,1.295,208,1.538,214,1.902,262,1.724,344,1.302,359,3.483,374,1.387,398,1,401,1.966,420,1.86,422,1.517,431,2.002,505,1.83,512,1.985,520,2.045,575,2.741,587,2.46,589,1.779,622,1.756,712,3.214,725,2.219,815,3.589,961,1.738,988,1.322,989,3.269,995,1.634,1006,2.253,1041,3.995,1065,4.422,1132,1.83,1155,2.157,1198,3.109,1398,1.396,1534,3.28,1551,2.129,1674,1.557,1680,3.143,1731,2.253,1928,4.518,2050,2.756,2252,2.327,2445,4.669,2457,2.513,2573,2.788,3714,3.336,4231,3.336,4232,5.757,4233,5.757,4234,3.63,4235,3.63]],["t/1294",[0,7.14,6,0.077,185,2.515,262,3.915,268,2.928,398,2.271,401,2.815,420,2.144,430,6.393,512,3.569,520,2.928,587,5.589,622,3.158,634,6.178,712,4.603,815,3.634,1155,4.9,4236,7.579]],["t/1296",[6,0.077,143,4.745,160,1.124,168,2.631,185,2.468,190,3.939,230,4.328,231,3.88,359,2.777,365,3.658,384,5.411,385,2.354,398,1.571,401,1.948,410,3.261,422,3.382,430,4.57,589,1.763,623,3.017,634,4.417,660,5.601,712,3.185,722,3.867,793,3.488,799,3.658,815,2.514,989,1.763,1185,5.188,1279,4.94,1429,3.658,1534,2.297,1939,3.438,2604,4.039,2710,4.713,3545,4.532,3628,4.532,3813,6.429,4169,5.244,4237,5.244,4238,5.244,4239,5.244,4240,5.705,4241,5.705,4242,5.705,4243,5.244,4244,5.705,4245,5.705,4246,5.705,4247,5.705,4248,5.705,4249,5.705,4250,5.705,4251,5.705,4252,5.705,4253,5.705,4254,5.705,4255,4.94,4256,5.705,4257,5.705,4258,5.705,4259,5.705,4260,5.705,4261,5.705,4262,5.705,4263,5.705,4264,5.705]],["t/1298",[6,0.077,144,4.645,185,2.247,190,3.585,214,2.433,359,3.585,384,3.896,428,3.887,430,4.16,481,4.16,624,4.573,634,5.257,660,6.667,712,4.112,799,4.723,815,3.247,1743,6.667,2126,4.264,2151,6.771,2787,4.896,3813,5.852,4237,6.771,4238,6.771,4239,6.771,4265,6.379,4266,7.366,4267,7.366,4268,7.366,4269,7.366]],["t/1300",[6,0.076,190,3.959,193,1.53,200,3.336,204,1.663,431,2.276,628,5.307,631,6.43,639,3.662,793,4.973,967,3.275,989,2.513,998,3.199,1279,7.043,1624,6.247,1928,4.138,2050,3.894,2604,5.759,4255,7.043,4270,8.133,4271,8.133,4272,8.133,4273,8.133,4274,10.264,4275,8.133,4276,8.133,4277,8.133,4278,8.133,4279,8.133,4280,8.133,4281,8.133,4282,8.133]],["t/1303",[2,2.899,6,0.078,110,0.959,149,1.854,168,1.979,170,1.545,193,0.892,204,0.969,208,0.71,212,1.783,305,2.617,359,4.117,374,1.296,384,3.74,398,2.33,399,2.204,420,1.839,430,2.678,431,1.327,505,2.39,512,1.635,520,1.684,534,2.007,567,3.357,585,4.519,589,1.465,634,3.86,722,3.214,793,2.899,815,4.637,972,4.043,989,3.099,995,2.135,997,3.917,1006,2.943,1041,1.844,1155,2.818,1183,3.641,1282,3.641,1312,3.865,1360,3.357,1565,2.943,1587,4.358,1674,3.628,2039,2.745,4283,4.741,4284,4.741,4285,4.358,4286,4.358,4287,4.741]],["t/1305",[6,0.077,96,2.945,185,2.372,190,3.785,193,1.015,200,2.213,204,2.162,208,0.808,214,1.783,231,2.227,384,4.821,385,2.227,401,1.843,428,1.843,486,2.173,624,2.299,660,3.735,799,3.46,815,2.378,831,3.587,849,2.466,967,3.671,988,1.966,989,2.403,1041,4.518,1117,1.926,1160,4.023,1178,2.72,1627,4.827,1939,3.252,2126,4.502,2252,3.46,2445,3.521,2604,3.821,2929,4.673,2935,4.96,2936,4.673,3493,4.287,3628,4.287,3813,7.243,4243,7.148,4255,4.673,4288,5.396,4289,9.116,4290,5.396,4291,5.396,4292,5.396,4293,7.776,4294,5.396,4295,5.396,4296,5.396,4297,5.396,4298,5.396,4299,5.396,4300,5.396,4301,5.396,4302,7.894,4303,5.396,4304,5.396,4305,5.396,4306,5.396,4307,5.396,4308,5.396]],["t/1307",[6,0.077,143,4.428,149,2.953,193,1.42,196,5.629,204,2.221,344,2.709,484,5.48,849,4.473,967,3.041,1041,2.937,1731,4.688,2050,3.615,2272,6.239,2273,6,3632,5.597,4302,9.406,4309,9.789,4310,9.789,4311,7.551,4312,7.551,4313,7.551,4314,7.551,4315,7.551,4316,7.551]],["t/1310",[6,0.077,98,3.101,134,5.457,185,2.404,214,3.325,321,4.893,374,1.24,487,3.574,512,3.469,554,6.513,622,2.404,742,5.49,1155,4.685,1617,6.513,2788,5.876,3058,10.19,4208,8.315,4209,8.315,4317,9.25]],["t/1312",[6,0.074,98,3.626,155,2.872,168,2.579,185,2.812,207,2.495,208,1.847,374,1.136,512,3.178,622,2.812,998,4.362,1036,4.525,1041,3.585,1928,4.69,4318,9.218]],["t/1314",[6,0.077,10,3.906,51,3.069,80,2.76,153,2.207,159,4.071,160,1.453,164,5.087,165,2.554,170,1.636,179,5.802,185,2.25,190,2.443,193,0.944,198,2.578,207,1.968,208,1.607,214,1.658,226,2.486,254,4.187,262,2.384,286,2.111,326,4.406,344,2.646,374,1.078,410,2.87,486,3.522,487,1.782,512,3.015,622,2.668,646,5.499,677,2.87,904,3.855,1041,3.994,1155,5.73,1534,2.971,1538,2.403,1811,3.474,1897,3.988,1994,2.554,1995,3.742,2046,4.347,2545,4.347,2787,3.336,2788,3.742,2790,4.614,3033,3.988,3932,4.347,4067,4.614,4319,5.019,4320,5.019,4321,5.019,4322,5.019,4323,7.377,4324,5.019,4325,5.019,4326,5.019,4327,5.019,4328,5.019,4329,5.019]],["t/1317",[6,0.078,51,3.423,98,3.66,155,2.778,158,1.693,185,2.838,204,2.074,207,1.26,208,1.834,327,2.702,344,2.008,374,0.69,512,3.498,528,4.956,575,1.884,622,2.435,742,2.772,969,3.653,998,2.202,1041,4.463,1065,4.3,1144,4.3,1534,3.747,1564,2.45,1590,2.106,1891,4.025,1928,4.062,2050,3.822,2236,4.848,4317,5.146,4330,5.598,4331,5.598,4332,5.598]],["t/1319",[6,0.077,176,2.519,185,2.228,204,1.959,208,1.6,262,3.47,420,1.9,487,3.796,512,4.168,528,4.535,622,3.593,998,2.874,1041,4.157,1928,4.874,2337,5.057,2788,7.142]],["t/1321",[6,0.078,10,2.387,80,2.204,185,1.797,193,1.108,204,1.205,207,2.153,208,1.779,268,3.686,326,2.527,327,3.996,354,2.97,487,2.092,512,2.854,622,1.797,645,2.844,678,2.634,959,4.575,1041,4.252,1144,4.525,1155,3.502,1538,2.821,1731,3.657,3458,4.681,4333,5.892,4334,7.609]],["t/1323",[6,0.078,80,2.162,83,3.391,155,1.497,176,1.992,185,2.49,193,1.536,204,1.181,208,1.417,268,2.052,317,2.127,512,3.993,622,3.139,687,3.388,908,3.388,909,3.644,936,7.505,937,6.178,989,1.785,1041,3.175,1155,5.628,1574,5.311,1928,2.94,2000,4.193,4209,4.774,4225,7.523,4335,11.268,4336,5.778,4337,5.778,4338,5.778]],["t/1326",[6,0.078,193,1.936,204,1.67,268,2.901,319,3.761,326,3.504,512,2.817,622,2.492,967,3.29,1041,4.383,1155,4.856,2555,5.331,2559,5.785,4334,7.51]],["t/1328",[6,0.078,80,2.722,110,1.447,168,2.985,170,2.371,204,1.488,208,1.089,384,3.848,398,2.004,399,3.892,512,2.509,585,5.7,995,3.276,1041,2.829,1312,3.325,1518,5.424,2252,4.665,2457,5.037]],["t/1330",[6,0.077,80,2.722,190,3.542,208,1.761,384,6.222,401,2.484,430,6.026,512,2.509,634,5.215,967,4.297,1041,3.716,1567,4.267,2660,9.806,4339,7.276,4340,7.276,4341,7.276,4342,7.276,4343,7.276]],["t/1332",[6,0.078,98,2.638,193,1.261,208,1.004,268,2.381,374,0.826,384,4.786,431,1.876,494,3.412,565,5.311,622,2.76,959,2.956,989,2.072,1041,3.983,1155,3.986,1491,5.473,1901,3.882,3952,5.541,4344,6.706,4345,6.706,4346,6.164]],["t/1334",[6,0.077,80,2.689,207,2.386,208,1.801,226,3.56,268,3.366,315,5.217,326,4.066,374,0.886,565,4.919,686,4.823,712,4.013,951,4.691,959,3.169,998,2.828,1041,4.124,1491,5.065,1494,4.691,1590,2.704,4208,5.94,4346,6.608]],["t/1337",[6,0.078,208,1.494,214,2.57,374,1.23,1041,3.881,4347,7.152,4348,7.78]],["t/1339",[6,0.078,155,2.398,159,3.83,168,1.942,170,2.261,208,1.56,374,0.855,597,4.626,657,4.913,989,2.144,1041,4.504]],["t/1341",[6,0.078,10,1.754,155,2.632,167,1.478,168,1.848,170,1.411,191,1.882,193,1.685,195,2.539,204,2.228,207,1.801,208,1.842,236,1.471,347,1.845,374,0.534,384,4.234,388,2.776,422,1.809,431,2.24,439,2.245,480,1.594,663,2.583,742,2.144,749,1.949,937,2.825,959,1.908,967,2.66,988,1.577,989,3.14,1041,4.342,1178,2.183,1206,3.066,1371,3.44,1681,2.647,2050,3.162,2188,3.325,2318,3.227,3632,2.475,4349,4.329,4350,4.329]],["t/1343",[6,0.074,2239,8.896,4351,10.272]],["t/1345",[2,5.492,6,0.078,110,1.66,191,3.905,193,1.689,204,1.356,207,1.492,208,1.524,212,2.494,268,3.19,316,2.986,327,3.201,387,4.327,398,1.826,420,1.724,586,6.36,966,4.362,998,2.609,1130,3.702,1139,4.252,1564,2.903,1590,2.494,1681,4.055,1717,3.746,2304,5.269,2559,4.696,4352,6.088]],["t/1347",[6,0.078,110,1.68,149,1.22,152,2.159,154,1.264,160,1.004,168,0.873,191,3.243,193,1.66,204,1.042,207,1.147,208,1.584,214,1.03,226,2.523,268,1.108,316,2.294,327,1.506,344,1.828,354,1.572,374,0.628,384,2.695,387,5.365,398,0.859,399,1.588,401,1.74,420,2.138,486,2.052,513,1.691,534,2.157,575,1.05,582,2.502,586,6.876,656,2.159,966,4.462,967,1.256,974,3.891,975,3.891,979,2.695,998,2.004,1027,2.781,1117,1.113,1130,3.606,1139,3.267,1406,2.325,1564,1.365,1590,1.917,1643,2.821,1681,1.907,1717,3.649,1741,5.477,1765,2.263,1833,1.404,1891,1.572,1952,2.478,2049,1.493,2053,1.762,2093,2.016,2119,2.478,2450,2.114,2551,2.577,2559,4.574,3092,2.867,4352,5.981,4353,3.119,4354,2.867,4355,2.867,4356,2.263,4357,3.119,4358,3.119,4359,2.867,4360,2.867,4361,2.701,4362,3.119,4363,3.119]],["t/1350",[6,0.077,110,1.459,160,1.969,185,1.951,190,4.265,200,3.594,204,1.307,207,1.972,208,1.686,317,2.355,385,3.616,398,1.761,399,3.115,401,3.671,430,3.612,478,4.641,486,2.576,534,2.707,589,1.976,631,5.01,635,3.53,839,3.453,966,2.445,998,3.447,1117,2.283,1162,3.53,1178,3.224,1624,6.73,1939,5.281,2604,6.204,3429,6.359,3493,5.081,3765,5.538,3892,5.538,4302,5.538,4364,6.395,4365,6.395,4366,5.879,4367,5.879,4368,6.395,4369,6.395,4370,8.762,4371,8.762,4372,6.395,4373,6.395,4374,6.395,4375,6.395,4376,6.395,4377,6.395]],["t/1352",[6,0.077,110,1.667,160,1.475,190,2.492,200,2.1,231,3.089,256,3.128,262,2.431,268,1.818,316,2.305,347,2.181,385,2.113,399,2.757,410,2.927,415,3.932,420,2.692,485,2.68,486,3.014,534,2.167,582,2.513,586,3.625,635,2.825,759,3.816,966,4.271,1117,1.827,1130,2.858,1139,3.282,1162,2.825,1429,3.282,1451,7.019,1535,3.34,1681,3.13,1939,4.511,2341,3.085,2710,4.23,3661,4.433,3886,4.433,4265,4.433,4352,5.073,4378,5.119,4379,5.119,4380,5.119,4381,6.481,4382,5.119,4383,8.555,4384,5.119,4385,5.119,4386,5.119,4387,5.119,4388,5.119,4389,5.119,4390,5.119,4391,5.119,4392,5.119,4393,5.119,4394,4.706,4395,5.119,4396,5.119,4397,5.119,4398,7.484,4399,5.119,4400,5.119,4401,5.119,4402,5.119,4403,5.119,4404,5.119,4405,5.119,4406,5.119,4407,5.119,4408,5.119]],["t/1354",[6,0.077,110,1.29,158,2.183,160,1.422,193,1.999,219,2.872,256,3.016,420,1.877,520,2.563,966,2.76,974,3.972,975,3.972,1027,5.188,1125,5.964,1717,4.077,1741,4.48,1766,6.25,1962,5.544,2126,4.178,2433,5.544,2560,8.231,2613,6.25,3467,7.853,4143,5.964,4352,4.893,4361,6.25,4381,8.231,4394,6.634,4409,6.634,4410,7.218,4411,5.964,4412,7.218,4413,7.218,4414,7.218,4415,7.218,4416,7.218,4417,7.218,4418,7.218]],["t/1357",[6,0.078,110,1.414,160,1.172,176,2.051,191,2.587,193,1.568,203,4.033,207,1.339,208,1.56,219,2.368,226,2.947,232,2.456,326,2.552,344,2.135,368,4.318,373,2.623,374,1.186,398,1.639,431,1.665,486,2.396,513,1.975,664,3.49,677,3.402,686,3.027,908,4.888,909,3.753,966,2.275,974,2.487,975,2.487,988,3.998,992,2.803,998,2.341,1115,3.638,1545,3.753,1564,3.649,1643,2.25,1897,4.728,1902,5.174,1962,4.57,2093,2.354,4352,6.521,4419,5.95,4420,5.95,4421,5.95,4422,5.95,4423,5.95,4424,5.95,4425,5.95,4426,5.95]],["t/1360",[6,0.077,79,5.249,110,1.403,191,4.496,193,1.945,203,7.01,207,1.538,208,1.372,214,2.258,231,2.82,322,5.918,327,3.299,344,3.288,398,1.882,420,1.777,512,2.356,513,2.268,586,4.838,966,3.504,998,2.688,1158,3.771,1564,4.012,1643,3.911,2053,3.86,4352,7.49,4427,6.833,4428,6.833,4429,6.833,4430,6.833]],["t/1362",[6,0.078,80,2.271,110,1.651,176,2.093,185,1.852,208,0.909,286,3.555,374,1.199,398,1.672,486,3.917,487,2.156,512,2.093,575,2.044,677,3.471,686,4.301,966,4.491,973,4.406,974,4.064,975,4.064,979,4.471,1336,6.886,1741,5.247,1765,4.406,1902,3.769,2093,2.402,2449,3.244,2450,4.115,2551,5.016,4352,4.115,4431,6.071]],["t/1364",[6,0.078,80,2.302,110,1.507,154,2.493,158,1.861,185,1.877,208,1.277,212,2.315,214,2.819,236,2.091,262,4.053,318,4.26,374,0.758,512,2.122,966,3.263,973,4.466,974,3.566,975,3.566,988,2.242,992,2.899,1036,4.189,1130,3.436,1139,3.946,1186,4.89,1741,5.297,2093,2.435,2286,4.82,2906,4.466,4381,9.621,4383,9.18,4409,5.657,4432,6.154,4433,6.154,4434,5.657,4435,5.657,4436,9.795]],["t/1367",[2,3.412,5,3.641,6,0.077,110,1.619,156,4.286,158,1.688,160,1.1,193,1.05,204,1.141,207,2.09,208,1.716,373,2.46,374,0.688,383,2.099,398,1.537,399,2.483,420,1.451,575,1.878,582,2.74,964,3.487,966,3.874,973,4.05,974,4.987,975,4.987,979,4.913,994,3.641,998,2.195,1129,2.922,1534,2.247,1590,2.099,1594,4.434,1643,2.11,1741,6.915,1765,4.05,1828,4.05,1952,4.434,2449,2.982,2450,3.783,2551,4.611,3733,5.13,4352,3.783,4354,5.13,4355,5.13,4359,5.13,4437,5.13]],["t/1369",[6,0.077,49,3.586,110,0.807,149,2.327,155,2.159,160,1.172,164,2.947,168,1.665,170,1.939,204,1.967,207,1.876,208,1.247,316,3.753,354,3,384,3.147,387,3.883,398,1.639,401,2.032,520,2.113,575,2.003,586,4.213,749,2.679,944,5.153,973,4.318,974,4.357,975,4.357,1027,6.209,1130,4.653,1491,3.179,1590,3.135,1717,5.888,1741,5.972,1831,4.436,2906,6.049,4352,4.033,4361,5.153,4383,8.613,4434,7.662,4435,5.47,4438,5.95,4439,5.95]],["t/1371",[6,0.077,110,1.668,191,4.553,193,1.97,208,1.257,316,3.782,486,3.383,582,4.123,586,7.416,966,4.364,2053,4.744,4352,7.1,4383,6.94]],["t/1373",[6,0.077,80,2.801,110,1.681,176,2.582,204,2.342,208,1.619,486,3.016,513,2.486,686,4.953,966,3.723,967,3.016,1198,4.044,1564,3.278,1643,2.832,2341,4.513,4352,7.765,4440,7.488,4441,7.488]],["t/1375",[6,0.074,1807,8.896,4442,10.272]],["t/1377",[6,0.078,83,2.479,154,3.905,160,1.176,193,1.123,204,1.708,207,1.88,208,1.442,212,2.246,268,2.967,368,4.332,374,1.354,589,1.845,967,2.404,1130,3.333,1139,3.828,1355,3.066,1590,2.246,1717,3.372,1895,2.882,1901,3.456,2791,4.133,4092,5.663,4443,7.719,4444,5.97,4445,5.488]],["t/1379",[6,0.078,10,1.302,49,1.937,103,2.179,144,2.027,155,0.833,160,1.299,176,1.108,190,1.564,193,0.982,204,1.927,207,2.013,208,1.47,212,1.209,214,1.725,268,2.342,368,2.332,374,1.252,384,1.7,395,2.783,431,0.899,512,1.108,532,1.082,589,1.613,678,1.437,709,1.794,905,1.717,964,2.887,967,1.294,974,2.756,975,2.756,979,3.488,1041,1.25,1130,1.794,1139,2.061,1355,2.682,1406,2.396,1590,1.209,1717,1.815,1765,2.332,1809,1.937,1831,2.396,1891,1.62,1895,1.551,1900,2.061,1923,2.954,2189,1.539,2196,2.553,2341,1.937,2450,2.179,2555,2.097,2791,7.03,4092,5.147,4443,7.717,4445,2.954,4446,3.214,4447,2.655,4448,3.214,4449,2.783]],["t/1382",[6,0.078,9,5.083,168,2.14,193,1.438,204,2.018,207,2.459,208,1.789,268,2.716,374,0.943,380,3.723,432,3.632,481,4.32,964,4.32,1036,3.755,1198,4.13,4450,9.87]],["t/1384",[6,0.077,10,2.503,83,2.008,102,3.06,110,0.397,149,2.806,154,1.185,155,2.058,160,0.577,165,2.46,167,1.651,168,2.83,170,2.338,193,1.494,204,1.624,207,1.39,208,1.469,231,4.28,232,1.208,256,1.223,262,1.39,286,1.231,306,1.739,333,2.835,362,2.418,374,0.884,380,1.424,384,2.557,385,1.995,398,0.806,401,0.999,420,1.257,422,2.021,431,1.729,432,2.934,433,2.835,436,1.683,439,1.517,440,1.597,481,1.653,484,4.484,485,2.532,486,1.947,520,1.717,575,2.415,635,1.615,708,2.611,718,1.58,727,2.483,849,2.209,959,2.131,964,2.116,967,3.446,974,1.223,975,1.223,979,1.547,992,2.911,999,1.945,1006,1.816,1041,3.933,1101,1.876,1108,2.69,1131,4.682,1181,2.699,1192,2.247,1193,3.509,1198,2.611,1225,4.237,1336,2.072,1535,1.909,1567,1.716,1832,2.325,1833,1.317,1834,3.841,1901,1.694,1939,1.763,1994,1.489,2036,1.327,2168,2.418,2189,3.436,2298,2.418,2449,1.563,2479,2.534,2493,1.983,2494,2.418,2577,3.509,2578,2.325,2604,5.081,2641,3.841,3097,2.69,3632,1.673,3995,2.247,4092,1.983,4443,1.983,4451,2.926,4452,2.69,4453,2.926,4454,2.926,4455,2.69,4456,2.926,4457,2.69,4458,4.835,4459,2.926,4460,2.926,4461,2.926,4462,7.176,4463,4.835,4464,2.926,4465,4.835,4466,2.926,4467,2.926,4468,7.176,4469,2.926,4470,2.926,4471,2.926,4472,2.69,4473,2.926,4474,2.926,4475,2.926,4476,2.926,4477,2.926,4478,4.835,4479,2.926,4480,2.926,4481,2.926,4482,2.926,4483,2.926,4484,2.926,4485,2.926,4486,4.835,4487,4.835,4488,4.835,4489,2.926,4490,2.69,4491,2.926,4492,2.69,4493,2.69,4494,2.926,4495,2.926,4496,2.926,4497,2.926,4498,2.926,4499,2.926,4500,2.926,4501,2.926,4502,2.926,4503,2.926]],["t/1387",[6,0.078,10,3.112,154,3.112,190,4.818,207,1.728,208,1.149,268,2.728,374,0.947,964,3.362,1567,4.504,2332,5.317,2791,6.851,3616,6.346,4443,6.709,4504,7.681,4505,9.897,4506,7.681,4507,7.681,4508,7.681,4509,7.06]],["t/1389",[6,0.078,149,2.841,155,2.366,165,1.518,167,1.019,168,2.247,170,1.601,190,1.453,193,0.924,207,0.672,208,1.202,212,1.122,214,1.624,219,1.956,223,3.266,232,2.997,261,2.682,268,2.225,316,2.213,321,3.051,359,1.453,374,0.99,384,1.578,385,2.997,398,0.822,420,1.888,422,1.247,432,1.417,436,1.039,439,1.547,440,1.629,477,3.566,484,5.827,485,1.563,494,1.518,520,2.852,534,1.263,575,1.005,582,1.465,599,2.371,645,1.441,730,1.395,761,2.113,964,2.151,967,1.202,992,1.406,1006,1.853,1041,3.552,1117,1.754,1129,1.563,1130,5.099,1139,1.914,1182,2.743,1193,2.166,1258,2.225,1355,1.533,1393,1.947,1535,1.947,1614,2.166,1901,1.728,2189,2.353,2268,1.647,2327,2.584,2494,2.466,2495,2.584,2641,3.904,2791,7.049,3196,2.743,3602,2.743,4092,4.923,4285,2.743,4443,6.703,4452,2.743,4455,2.743,4457,4.517,4472,4.517,4490,2.743,4492,2.743,4493,2.743,4509,2.743,4510,2.984,4511,2.984,4512,2.984,4513,2.984,4514,2.984,4515,2.984,4516,2.984,4517,2.984,4518,2.984,4519,4.914,4520,2.984,4521,2.984,4522,2.984,4523,2.984,4524,2.984,4525,2.984,4526,2.984,4527,2.984,4528,2.984,4529,2.984,4530,2.984,4531,2.984,4532,2.984,4533,2.984,4534,2.984,4535,2.984,4536,2.984]],["t/1391",[6,0.071,10,3.958,80,3.655,103,6.622,154,3.958,176,3.368,190,5.933,268,3.47,374,1.204,559,5.518,678,4.367]],["t/1393",[6,0.077,10,2.995,80,1.883,118,7.238,154,3.549,155,1.915,158,1.522,160,0.992,185,2.255,193,1.816,207,1.133,208,1.106,268,2.625,282,4.159,306,4.393,327,2.43,347,2.145,368,5.364,369,3.999,374,1.19,424,2.25,486,2.027,487,1.787,494,2.561,513,1.671,645,3.568,664,2.952,679,3.652,908,2.952,929,2.81,959,2.218,961,2.41,988,3.917,992,2.371,1015,3.412,1041,2.875,1131,3.284,1355,3.796,1469,3.652,1491,2.689,1562,3.227,1681,3.078,1809,3.033,1884,3.866,1885,3.999,1891,2.537,1895,3.568,1896,4.359,1902,4.589,1915,2.537,1938,4.159,1994,2.561,2036,2.283,2189,3.539,2196,3.999,2237,3.752,2402,3.412,3022,3.284,3254,3.866,3568,3.484,3569,3.484,3952,4.159,4092,5.938,4443,5.011,4537,5.033,4538,5.033,4539,5.033,4540,4.359,4541,5.033,4542,5.033,4543,4.359,4544,4.627,4545,4.627,4546,4.627,4547,4.627,4548,5.033,4549,5.033]],["t/1395",[6,0.078,10,3.027,110,0.306,155,2.68,158,1.545,160,0.764,167,0.77,168,0.631,170,0.734,176,1.761,185,1.558,190,1.097,193,1.141,204,1.636,207,1.365,208,1.455,219,1.544,223,2.579,252,1.68,268,2.653,282,3.205,306,2.306,327,1.873,344,1.392,359,2.486,368,2.815,374,1.348,380,1.097,385,0.93,432,1.07,436,0.785,486,1.562,532,0.759,533,0.734,575,1.306,635,1.244,639,1.015,659,4.121,665,1.731,678,2.712,679,2.815,709,1.258,840,1.528,959,1.71,967,3.009,974,2.134,975,2.134,979,2.701,999,1.498,1015,1.528,1041,3.435,1117,1.385,1130,1.258,1131,3.332,1565,1.399,1745,1.731,1809,3.656,1891,1.136,1895,1.088,1900,3.275,1915,1.136,1940,1.731,1994,1.147,2050,1.079,2088,1.952,2189,3.274,2261,1.445,2292,2.072,2371,2.166,2402,2.63,2641,4.82,2686,4.842,2791,1.56,3018,1.862,3248,1.952,3251,3.535,3253,2.072,3457,1.636,3569,3.535,3647,1.952,3952,3.205,4092,4.113,4443,1.528,4543,1.952,4544,3.566,4545,3.566,4546,3.566,4547,3.566,4550,3.879,4551,3.879,4552,2.254,4553,3.879,4554,5.107,4555,2.254,4556,2.254,4557,3.879,4558,2.254,4559,2.254,4560,2.254,4561,3.879,4562,3.879,4563,3.879,4564,3.879,4565,2.072,4566,2.072,4567,2.254,4568,2.254]],["t/1397",[6,0.078,118,2.993,158,1.096,185,1.105,193,1.344,207,1.293,208,0.86,300,2.097,306,5.273,374,1.303,477,2.629,494,2.924,512,1.982,579,2.629,645,4.282,678,3.194,679,5.903,730,1.693,908,2.124,959,3.149,964,1.586,988,1.32,1130,2.022,1355,5.564,1826,4.415,1892,6.188,1900,2.323,1901,6.272,2072,2.629,2402,2.455,2791,4.946,3251,2.507,4092,8.257,4443,6.014,4449,3.137,4543,7.044,4565,3.33,4566,3.33,4569,5.748,4570,3.622,4571,3.622,4572,3.622,4573,3.622,4574,3.622,4575,3.622]],["t/1399",[6,0.078,51,3.319,176,2.693,191,4.349,193,1.021,203,3.68,204,2.325,207,2.058,208,1.369,231,3.775,290,4.99,308,3.68,359,2.643,512,1.872,532,1.827,677,3.104,967,3.684,974,3.264,975,3.264,979,4.13,1375,4.701,1590,3.763,1885,4.313,1940,4.17,2573,4.17,2791,3.758,3018,4.485,3647,4.701,4092,5.294,4443,6.2,4576,5.429]],["t/1401",[6,0.078,83,2.241,143,3.165,149,2.11,154,2.186,160,1.063,167,1.843,168,1.51,193,1.015,204,2.162,208,0.808,344,1.936,374,0.958,380,2.627,420,2.022,432,3.693,436,1.879,480,1.987,481,3.048,484,3.916,532,1.816,575,1.816,656,3.735,964,3.99,967,3.671,974,3.25,975,3.25,988,1.966,1027,5.772,1130,3.012,1567,4.56,1590,2.03,1681,3.3,1717,4.392,1810,3.165,2445,3.521,2791,3.735,4092,7.168,4360,4.96,4443,5.271,4577,10.574,4578,5.396,4579,5.396]],["t/1403",[6,0.078,160,1.494,204,1.55,207,1.706,208,1.469,268,2.693,374,0.935,589,2.343,599,6.025,1355,3.895,1393,4.948,1590,2.852,1901,4.39,2791,7.968,4092,6.654,4443,7.378]],["t/1405",[6,0.074,1807,8.896,4580,10.272]],["t/1407",[6,0.078,110,1.624,153,1.426,154,2.29,160,1.584,193,1.063,207,1.272,208,1.525,219,2.249,344,2.027,373,2.491,374,1.541,383,3.832,399,1.761,431,1.581,476,2.731,480,2.08,513,1.876,575,1.902,589,1.746,728,3.359,964,3.518,966,3.073,974,2.362,975,2.362,979,2.989,998,2.223,1118,2.601,1127,3.83,1308,3.425,2049,2.705,2067,3.912,2093,2.236,2305,4.49,2449,3.019,3582,4.54,4581,5.651,4582,5.194]],["t/1409",[6,0.078,10,2.125,110,1.608,150,1.334,153,1.323,154,1.309,155,0.837,158,0.977,160,1.94,195,1.895,204,0.661,207,1.18,208,1.523,212,1.215,219,1.286,221,2.597,297,2.97,300,1.871,344,1.881,347,1.377,367,2.345,373,2.312,374,1.539,383,3.703,399,2.374,435,1.535,476,2.588,480,1.931,513,1.741,532,1.088,533,1.053,575,1.088,589,0.998,622,0.986,676,2.928,728,3.117,854,2.072,963,3.024,964,2.296,966,2.531,974,2.192,975,2.192,979,1.709,985,1.92,1079,2.148,1127,2.19,1128,2.006,1129,1.692,1155,1.92,1198,1.745,1308,3.569,1355,1.659,1534,1.301,1578,2.67,1643,2.503,1784,2.482,1891,2.644,1983,3.555,2032,2.798,2067,3.63,2071,2.148,2093,1.278,2245,2.006,2251,4.542,2305,2.567,2449,1.727,3582,2.962,4583,3.231,4584,2.97,4585,3.231,4586,3.231,4587,3.231,4588,3.231]],["t/1411",[6,0.077,98,2.719,110,1.675,160,1.82,185,2.108,193,1.3,208,1.661,212,3.474,222,4.359,347,2.945,374,1.498,383,2.6,431,1.934,476,3.931,575,2.327,589,2.136,799,4.432,963,4.22,964,3.026,1117,2.467,1308,3.935,3582,5.217,4589,6.912]],["t/1413",[6,0.073,160,1.894,204,1.965,344,3.449,347,4.096,513,3.191,963,4.392,1643,3.635,1784,7.383,1785,7.637,1983,6.516,2025,6.389,2026,6.062,2245,5.967,3712,7.942]],["t/1415",[6,0.077,49,4.421,110,1.542,160,2.239,207,2.161,208,1.893,374,1.454,436,3.344,476,3.264,517,4.302,974,4.476,975,4.476,979,3.88,985,4.36,1308,3.126,1564,3.211,1717,4.143,2290,3.633,2358,6.353,2449,3.92,2454,5.468,3582,5.426]],["t/1417",[6,0.076,230,4.31,480,3.447,487,3.325,988,4.078,1115,5.725,1895,4.519,1901,5.42,1902,5.812,2093,3.704]],["t/1419",[6,0.077,9,3.254,10,1.984,98,1.926,110,1.292,153,1.828,160,0.965,191,2.128,193,1.621,199,1.96,212,3.242,268,2.572,317,1.803,374,1.469,383,1.842,431,1.37,436,1.705,487,3.383,505,3.651,541,3.685,589,2.238,591,2.254,592,1.926,637,4.726,730,2.289,929,2.733,963,2.237,972,2.799,974,3.027,975,3.027,980,3.389,985,4.305,988,1.784,989,1.513,1041,1.904,1155,2.91,1308,4.059,1374,3.389,1389,3.467,1420,4.045,1521,2.446,1525,3.389,1538,3.468,1611,3.911,1643,2.739,1717,4.869,1895,2.363,1932,3.911,2093,1.937,2371,4.043,2454,5.399,3568,3.389,3569,3.389,3570,3.553,4214,4.24,4228,4.24,4590,6.658,4591,4.896,4592,4.896,4593,4.896,4594,4.896,4595,4.896,4596,4.896,4597,4.5,4598,4.24,4599,4.896,4600,4.896,4601,4.896]],["t/1421",[6,0.077,10,2.638,83,2.704,110,1.538,204,1.331,208,1.51,230,4.084,231,2.687,344,2.336,398,2.779,399,3.144,401,2.223,420,1.693,476,2.213,486,2.622,487,2.312,597,3.253,623,3.444,645,3.143,664,5.202,974,4.216,975,4.216,979,4.691,985,3.87,994,4.249,1115,3.981,1308,3.78,1902,4.042,2449,4.74,2454,4.854,3942,5.985,4109,7.048,4220,5.985,4540,5.639,4602,6.511,4603,6.511,4604,6.511,4605,6.511,4606,6.511,4607,6.511,4608,6.511,4609,6.511,4610,6.511,4611,6.511]],["t/1423",[6,0.078,10,2.982,110,1.456,155,0.982,158,1.146,160,1.787,195,2.223,204,0.775,207,0.853,208,1.748,212,1.426,300,3.449,358,3.012,374,1.241,383,2.768,436,1.32,476,2.025,487,2.116,513,1.258,575,1.276,709,2.116,854,4.719,933,2.608,974,1.584,975,1.584,979,2.005,998,1.491,1111,2.569,1126,2.253,1127,2.569,1308,4.102,1355,4.284,1389,2.684,1534,1.527,1643,2.253,1717,3.365,1768,3.484,1895,4.027,1901,2.194,1932,2.047,2093,3.809,2245,5.179,2290,1.877,2371,2.116,2449,2.025,2559,4.218,2997,3.484,3582,5.688,4068,3.282,4582,5.476,4584,3.484,4590,3.484,4612,3.79,4613,3.79,4614,3.79,4615,3.79,4616,3.282,4617,3.79,4618,3.79,4619,3.79,4620,3.79,4621,3.79]],["t/1425",[6,0.078,110,1.298,198,3.026,208,0.882,221,4.099,306,3.502,367,4.275,373,2.597,374,1.58,383,3.904,392,4.275,399,2.58,476,2.813,676,3.289,728,3.502,929,4.621,969,3.844,988,2.147,1308,4.659,1355,3.026,1527,5.102,1735,4.681,1895,3.996,2067,5.73,2093,2.331,2305,4.681,2371,3.289,2430,5.416,3457,4.275,3975,5.102]],["t/1427",[6,0.077,110,1.433,158,1.306,193,0.812,208,0.987,230,3.034,268,1.534,300,3.816,306,2.567,326,2.827,344,2.365,359,3.891,374,1.526,383,3.972,435,3.13,476,3.933,487,2.839,494,2.197,513,1.434,588,3.317,659,2.603,664,2.533,676,2.411,686,2.197,718,2.332,730,2.019,906,2.384,933,2.885,959,1.904,972,2.469,1115,2.641,1117,1.542,1308,4.85,1355,2.218,1356,2.99,1491,2.308,1521,2.158,1538,2.068,1562,2.769,1603,3.97,1643,1.633,1932,2.332,2032,3.74,2075,3.058,2080,2.469,2082,3.866,2086,2.681,2089,3.317,2287,4.468,2371,4.462,2428,3.74,2615,3.74,2685,3.134,2686,3.058,3430,8.726,3457,3.134,3571,3.22,3905,3.74,4622,4.319,4623,4.319,4624,4.319,4625,4.319,4626,4.319,4627,4.319,4628,4.319,4629,3.569,4630,4.319,4631,4.319,4632,3.97,4633,6.059]],["t/1429",[6,0.077,109,2.195,110,1.472,153,1.547,176,1.355,185,1.87,193,0.739,196,2.931,204,0.804,208,0.588,221,1.947,227,3.02,230,1.81,300,5.341,332,7.067,348,2.521,374,1.537,383,1.479,398,2.692,399,3.382,476,1.336,487,1.396,494,3.119,534,1.664,575,2.064,659,2.369,664,3.595,676,3.422,718,2.123,742,1.947,743,1.375,774,2.479,889,3.124,929,6.497,1015,2.665,1038,5.788,1117,1.403,1258,2.931,1521,1.964,1525,2.722,1611,2.123,1647,2.665,1915,1.982,1932,4.069,2011,3.866,2067,2.722,2072,2.853,2080,2.248,2082,2.306,2083,2.931,2286,2.221,2287,4.156,2371,2.195,2428,3.405,2685,2.853,2686,2.784,3022,2.565,3251,2.722,3254,3.02,3568,2.722,3569,2.722,3578,2.931,3975,3.405,4228,5.309,4632,5.635,4633,3.614,4634,3.931,4635,3.931,4636,6.13,4637,6.13,4638,3.931,4639,6.13,4640,3.931,4641,3.931,4642,3.931,4643,3.931,4644,3.931,4645,3.931,4646,3.931,4647,3.931,4648,3.931,4649,3.931,4650,3.931,4651,3.931,4652,3.614,4653,3.931]],["t/1431",[6,0.078,10,0.99,11,2.019,80,0.914,103,1.657,110,1.599,158,1.257,176,0.843,185,0.746,198,1.255,208,1.168,214,0.807,236,2.176,252,3.099,268,0.868,300,4.519,326,1.048,332,2.878,359,1.19,374,1.512,383,2.408,398,0.673,399,2.733,435,1.161,436,1.448,476,3.791,485,5.549,487,1.477,512,0.843,637,1.595,659,1.473,664,1.433,687,1.433,728,1.453,742,1.21,929,5.105,933,1.07,974,1.021,975,1.021,985,1.453,988,0.89,1036,5.115,1078,3.368,1117,0.872,1162,1.349,1287,1.473,1308,4.801,1315,1.822,1355,4.503,1471,1.822,1494,1.595,1535,1.595,1538,1.17,1564,1.82,1717,3.065,1733,1.877,1735,1.942,1902,1.517,1915,1.232,1925,4.168,2036,1.886,2051,2.247,2062,1.541,2072,1.774,2080,1.397,2082,1.433,2260,4.483,2286,1.381,2371,1.364,2454,1.822,2615,2.117,2648,2.247,2686,1.731,3457,1.774,4214,2.117,4616,2.117,4629,4.483,4654,2.444,4655,2.444,4656,2.444,4657,2.444,4658,2.444,4659,2.444,4660,2.444,4661,2.444,4662,2.444,4663,2.444,4664,2.444,4665,2.444,4666,2.444,4667,2.444,4668,2.444,4669,2.444,4670,2.444,4671,2.444,4672,4.158,4673,3.822,4674,2.444,4675,2.117,4676,5.426,4677,5.426,4678,2.444,4679,2.444,4680,2.444,4681,2.247,4682,2.444,4683,2.444,4684,2.444,4685,2.444,4686,2.444,4687,2.247,4688,2.444,4689,2.444,4690,2.444,4691,2.444,4692,2.444]],["t/1434",[6,0.078,110,1.518,153,1.779,160,1.389,204,1.441,208,1.674,374,1.294,383,3.519,399,2.197,505,3.553,575,2.372,693,5.254,966,2.695,999,4.684,1398,2.71,1674,3.023,2049,3.374,3582,3.981]],["t/1436",[6,0.077,110,1.569,153,1.938,160,1.513,208,1.639,374,1.536,383,4.119,399,2.394,476,2.61,728,4.565,929,5.525,1308,3.273,2067,5.317]],["t/1438",[6,0.074,4693,10.331]],["t/1440",[6,0.078,109,3.215,114,4.777,150,2.377,153,1.454,176,1.986,207,1.296,208,0.862,236,1.957,256,2.407,374,0.71,589,3.175,622,1.757,993,5.961,1126,3.423,1158,3.179,1183,4.424,1284,4.759,1398,2.215,1494,3.758,1521,2.877,1534,2.32,1564,2.521,2040,6.965,2252,3.693,3416,5.294,3459,4.576,4694,5.759,4695,5.759,4696,8.614,4697,4.988,4698,7.26,4699,4.424,4700,5.294,4701,4.576,4702,5.759,4703,4.759,4704,4.293,4705,5.294,4706,5.759,4707,5.759,4708,5.759]],["t/1442",[2,1.766,6,0.078,98,1.882,114,1.694,121,2.501,150,1.192,153,0.729,158,0.874,199,1.156,204,0.59,212,1.086,214,0.954,230,1.33,233,2.096,256,1.207,308,1.958,337,2.045,358,2.295,374,1.161,377,4.054,422,1.207,428,0.986,431,0.808,476,0.982,503,2.501,513,0.959,622,0.881,639,1.3,651,4.238,673,1.199,676,1.612,686,1.469,712,1.612,743,1.011,815,1.273,908,2.805,951,1.885,986,3.8,993,3.017,1158,3.379,1198,1.56,1284,2.386,1373,2.655,1398,3.621,1406,2.153,1415,4.928,1521,3.059,1545,3.861,1547,1.717,1564,1.264,1588,5.656,1722,2.218,1810,1.694,1829,2.655,1925,2.218,1939,1.741,2040,5.764,2061,2.153,2301,2.295,3456,2.501,3457,2.096,3459,4.864,3469,2.501,3573,2.386,3635,3.471,3995,3.674,4696,6.756,4698,6.06,4699,6.06,4700,2.655,4701,2.295,4704,4.564,4705,2.655,4709,2.888,4710,2.218,4711,2.888,4712,2.655,4713,2.888,4714,2.888,4715,3.8,4716,2.888,4717,2.888,4718,2.888,4719,2.888,4720,2.888,4721,2.888,4722,2.295,4723,2.888]],["t/1445",[6,0.077,160,2.254,358,6.704,377,4.73,520,2.997,622,2.574,933,3.694,1415,5.842,1545,5.322,3635,6.123,4697,7.308,4699,6.482,4724,8.346,4725,10.505,4726,8.438,4727,8.438,4728,8.438]],["t/1447",[6,0.078,68,5.644,98,4.147,110,0.964,160,1.4,231,2.932,513,2.358,622,2.869,815,3.131,1032,4.012,1078,4.41,1101,4.555,1158,3.921,1393,4.635,1398,2.731,1415,7.298,1518,5.295,1519,5.456,1614,5.155,4696,5.644,4715,7.472,4722,5.644,4724,5.644,4729,7.103,4730,7.103,4731,7.103,4732,7.103,4733,6.53,4734,6.53,4735,6.152]],["t/1449",[6,0.078,160,1.217,221,3.058,233,7.687,256,2.581,343,4.906,374,1.371,385,4.05,431,1.728,436,2.15,520,3.485,676,3.447,705,4.186,815,2.722,933,3.744,986,4.906,1032,3.488,1159,3.67,1393,4.029,1398,2.374,1521,3.085,1545,6.681,1588,4.906,1782,5.102,3056,5.676,3459,6.796,3926,5.348,4698,4.743,4704,6.376,4712,5.676,4724,4.906,4736,5.102,4737,6.175,4738,6.175,4739,6.175]],["t/1451",[6,0.078,160,1.549,230,2.522,231,2.261,233,5.704,377,4.523,436,1.907,651,3.792,918,5.036,993,5.798,1078,3.401,1118,2.522,1158,5.074,1393,3.575,1398,2.107,1415,6.364,1614,3.976,1925,4.208,2040,6.809,2739,4.744,3456,4.744,3459,7.305,3635,3.976,3995,4.208,4696,8.451,4699,7.716,4701,7.305,4704,6.854,4734,5.036,4735,6.808,4736,4.527,4740,5.478,4741,5.478,4742,5.478,4743,7.861,4744,5.478,4745,7.861,4746,7.861,4747,5.478,4748,5.478]],["t/1453",[2,6.372,6,0.078,123,5.733,160,1.367,191,3.017,231,2.864,377,3.124,520,2.464,586,7.379,815,3.058,1032,3.919,1158,6.136,1398,2.668,1415,4.803,1547,4.124,1810,6.793,2002,6.378,4696,5.513,4698,7.112,4699,5.33,4701,5.513,4722,5.513,4724,5.513,4736,5.733,4749,6.939]],["t/1455",[0,5.153,6,0.078,158,1.8,160,1.642,214,1.966,233,4.318,374,0.733,377,3.753,575,2.003,815,2.623,933,2.605,1032,3.361,1078,5.972,1158,4.6,1398,3.205,1502,4.954,1545,6.067,1624,4.57,1835,5.47,1901,3.445,2040,5.65,3635,4.318,3995,4.57,4698,4.57,4699,6.402,4701,8.719,4724,6.622,4735,7.218,4736,4.916,4750,5.95,4751,5.95,4752,5.95,4753,8.335,4754,5.95,4755,5.95,4756,5.95,4757,5.95,4758,5.95,4759,5.95,4760,8.335,4761,5.95,4762,5.95,4763,5.95]],["t/1462",[2,4.1,6,0.078,98,3.56,114,3.932,129,3.834,216,5.239,286,4.308,385,4.227,399,2.09,420,1.744,422,2.802,520,3.214,700,5.541,1032,3.788,1158,4.995,1353,5.328,1415,4.642,1547,3.986,1810,3.932,2657,6.164,3702,6.164,3811,6.164,4698,5.151,4710,5.151,4715,7.19,4764,6.706,4765,6.706,4766,6.706,4767,9.049,4768,6.706,4769,6.706]],["t/1464",[6,0.074,4770,10.272,4771,10.272]],["t/1466",[6,0.078,110,1.607,160,1.948,193,1.624,204,1.28,207,1.409,208,1.595,219,3.934,347,3.68,374,1.064,398,2.379,431,1.752,480,2.305,510,3.58,589,1.935,730,2.927,774,3.949,854,5.537,963,2.861,964,2.741,966,2.394,999,4.162,1079,4.162,1204,5.422,1590,2.355,1731,3.887,1739,5.361,1833,2.819,1957,4.544,1958,4.244,1959,4.544,1983,4.244,2093,2.477,2541,5.205,4772,4.809,4773,5.756]],["t/1468",[6,0.078,110,1.593,149,3.128,155,0.911,160,0.693,168,0.984,170,1.146,185,1.072,204,1.787,207,1.967,208,1.567,214,1.854,219,3.479,236,1.195,286,1.479,306,3.336,344,1.261,347,1.498,354,2.83,374,0.986,398,2.798,420,0.914,435,2.666,494,1.789,512,1.212,639,1.583,663,1.375,673,1.46,730,3.275,854,3.599,959,1.55,964,2.457,966,2.679,967,1.416,974,1.469,975,1.469,979,1.859,988,1.281,990,2.49,992,1.656,999,2.337,1117,2.004,1158,1.941,1313,2.383,1567,2.062,1590,1.322,1739,5.427,1833,2.527,1891,1.772,1939,2.119,1957,4.073,1958,7.098,1959,2.551,2049,1.683,2093,1.391,2444,3.045,2449,1.879,2541,4.821,3086,6.355,3087,5.381,3425,2.49,4356,2.551,4772,2.701,4773,3.232,4774,7.006,4775,3.516,4776,3.516]],["t/1471",[6,0.077,158,2.323,160,1.95,163,7.06,185,2.343,204,2.023,207,2.227,208,1.481,344,2.755,373,3.385,374,1.22,424,3.433,534,3.251,573,3.317,589,2.373,815,3.385,964,4.332,1086,5.206,1534,3.986,1643,2.905,2444,6.651,2453,6.651,2787,5.105,3751,7.06,4286,7.06,4777,7.681]],["t/1473",[6,0.078,110,1.609,153,2.075,158,1.765,204,1.681,207,1.85,208,1.631,219,2.322,374,1.343,383,2.194,398,2.846,399,1.818,420,1.517,436,2.031,476,1.983,480,2.148,513,1.936,585,3.117,623,3.086,854,3.741,964,2.554,966,2.231,967,2.35,974,3.978,975,3.978,979,4.348,995,2.627,999,3.878,1079,3.878,1132,2.941,1308,2.486,1534,2.35,1741,3.622,2449,3.117,3582,3.295,3666,4.481,4093,5.363,4437,5.363,4772,4.481,4778,5.834]],["t/1475",[6,0.077,149,3.698,160,1.411,373,3.156,374,0.882,487,2.543,964,3.134,974,3.951,975,3.951,979,5,988,2.609,990,5.07,998,2.816,1939,4.315,1957,8.169,1958,8.31,1959,5.196,1962,5.5,1965,6.694,2450,4.854,3087,8.13,4779,6.582]],["t/1477",[6,0.077,98,1.915,110,1.615,160,0.959,204,0.996,207,1.096,208,1.422,219,2.871,221,2.411,231,3.546,286,3.034,317,1.793,347,2.075,374,1.059,398,2.926,399,2.678,401,1.663,408,3.74,420,2.234,430,2.75,476,1.655,478,3.534,486,1.961,510,2.784,622,2.621,628,3.177,631,2.784,635,2.688,774,3.071,839,2.629,854,3.122,966,4.317,1162,3.981,1178,2.455,1198,2.629,1459,2.977,1624,3.74,1643,2.728,1739,3.023,1833,2.192,1957,3.534,1958,3.301,1959,3.534,2541,2.935,2556,4.217,3299,3.74,3301,3.63,3425,3.448,3484,4.217,3485,4.476,3765,4.217,3886,4.217,3892,4.217,3894,4.476,3895,4.476,3900,6.631,3903,4.476,4366,4.476,4367,4.476,4772,3.74,4780,4.869,4781,4.869,4782,4.869,4783,4.869,4784,4.869,4785,4.869,4786,4.869,4787,4.869,4788,4.869]],["t/1479",[6,0.075,110,1.304,158,2.907,208,1.439,222,6.062,510,5.496,774,6.062,1117,3.431,1833,4.328,2441,7.942,2541,5.793,4356,6.976]],["t/1481",[6,0.077,110,1.676,193,1.489,208,1.751,333,4.643,374,1.244,398,2.78,399,2.468,420,2.059,476,2.691,480,2.915,510,4.527,774,4.993,964,3.466,966,4.473,974,3.309,975,3.309,979,4.187,1833,3.565,2450,5.367]],["t/1483",[6,0.077,110,1.668,176,2.498,193,1.363,207,1.631,286,3.048,398,3.322,510,4.143,730,4.455,761,5.131,774,4.57,966,2.771,988,2.64,1117,2.587,1313,7.217,1739,6.609,1833,5.093,4789,7.247]],["t/1485",[6,0.077,110,1.65,160,1.472,193,1.405,256,2.133,261,2.786,264,3.805,268,1.813,319,2.35,347,2.175,385,2.107,398,3.35,410,2.918,422,2.133,520,2.652,573,3.225,730,2.386,793,3.121,933,4.885,966,3.955,1162,2.817,1242,4.27,1275,5.568,1739,6.033,1833,2.298,1901,2.955,2268,5.708,2501,6.865,3129,4.218,3233,4.421,4411,4.218,4790,5.105,4791,5.105,4792,5.105,4793,5.105,4794,5.105,4795,5.105,4796,5.105,4797,5.105,4798,5.105,4799,5.105,4800,5.105,4801,5.105,4802,5.105,4803,5.105,4804,5.105,4805,4.692,4806,4.692,4807,4.692,4808,5.105,4809,5.105,4810,4.692,4811,5.105]],["t/1487",[6,0.077,110,1.598,256,2.069,261,2.702,286,2.082,347,2.109,354,2.495,374,0.61,398,3.29,399,2.985,410,2.83,422,2.069,480,1.822,485,2.592,573,2.137,639,2.229,730,4.774,933,3.196,959,2.182,966,3.905,1162,4.03,1275,3.69,1313,8.277,1739,5.945,1833,3.906,1937,4.09,2050,2.37,2268,4.03,3129,4.09,4411,4.09,4805,4.55,4806,4.55,4807,4.55,4810,4.55,4812,4.95,4813,4.95,4814,4.95,4815,4.95,4816,4.95,4817,4.95,4818,4.95,4819,4.95,4820,4.95,4821,4.95,4822,4.95,4823,4.95,4824,4.95,4825,4.95,4826,4.95,4827,4.95,4828,4.95,4829,4.95,4830,4.95,4831,4.95,4832,4.95,4833,4.95,4834,4.55]],["t/1489",[6,0.077,110,1.686,149,2.778,153,1.793,204,1.452,208,1.408,236,3.196,256,3.93,261,3.877,286,2.988,387,4.635,510,4.061,573,3.067,774,4.48,966,4.291,992,4.431,1833,4.747,1965,5.03,3086,7.472,4356,6.825,4835,7.103,4836,7.103]],["t/1492",[6,0.076,110,1.134,185,2.55,193,1.572,208,1.251,230,3.848,306,6.207,373,3.685,494,4.253,664,4.903,959,3.685,974,4.365,975,4.365,979,4.421,988,3.805,1002,7.24,1115,5.112,1355,4.293,1376,6.232,1902,5.19,2093,4.132,2449,4.467,4837,8.36]],["t/1494",[6,0.077,110,1.504,155,1.583,168,1.71,170,1.992,193,1.15,204,1.25,207,2.196,208,1.823,221,3.027,232,4.353,342,3.794,347,2.605,374,1.3,420,1.589,422,2.555,431,1.71,476,2.886,480,2.25,513,2.029,517,3.585,573,2.639,575,2.057,792,5.05,963,2.793,964,3.718,966,2.337,974,4.408,975,4.408,979,5.162,985,3.633,995,3.824,999,4.063,1041,3.795,1643,2.312,1765,4.436,1952,4.856,2078,4.556,2290,3.027,2449,3.266,2450,4.143,2454,4.556,4838,6.112,4839,6.112,4840,5.618]],["t/1496",[6,0.076,10,2.619,51,3.953,110,1.198,153,2.228,164,3.201,179,3.651,193,1.66,198,3.32,236,3,254,3.095,286,2.719,288,3.953,315,4.691,327,3.12,344,2.319,348,4.145,374,1.088,398,2.431,420,1.681,431,1.809,486,2.603,487,2.296,622,2.692,623,3.419,645,3.12,664,5.176,677,3.696,686,4.491,725,3.953,739,4.475,906,4.872,909,4.077,951,4.218,966,2.472,974,3.689,975,3.689,979,4.668,988,2.355,1002,5.598,1209,5.341,1313,4.382,1351,5.341,1355,3.32,1494,4.218,1643,2.445,1769,5.598,1833,3.974,1996,4.819,2026,4.077,2093,2.558,2245,4.013,2449,3.454,2541,3.896,2769,5.136,3033,5.136,4356,4.691,4841,6.464,4842,6.464,4843,6.464,4844,6.464,4845,6.464,4846,6.464]],["t/1499",[6,0.077,110,1.378,155,1.265,160,1.696,207,2.285,208,1.839,214,2.843,219,3.786,232,4.191,300,2.827,344,1.752,347,2.081,374,1.252,480,1.798,512,2.967,678,2.183,689,4.488,854,5.518,933,3.164,961,2.338,1006,3.031,1041,2.811,1117,1.743,1302,3.64,1355,2.508,1643,4.022,1647,3.31,1915,2.461,1920,3.131,2026,4.559,2080,2.792,2082,2.863,2093,1.932,2245,5.343,2286,2.758,2290,2.418,2441,4.034,2541,6.12,3410,4.488,4772,3.75,4840,7.911,4847,4.883,4848,4.883,4849,4.883,4850,4.883,4851,4.883,4852,4.883,4853,4.883,4854,4.883,4855,4.883,4856,4.883,4857,4.883]],["t/1501",[6,0.078,110,1.495,160,1.336,185,2.069,193,1.276,208,1.649,252,5.055,306,4.031,374,0.836,512,2.338,533,2.971,664,3.977,905,4.872,933,2.968,959,2.989,988,2.471,1355,4.683,1491,3.624,1538,3.247,1562,4.348,1564,2.968,1902,4.21,1915,3.419,2086,5.66,2286,3.831,2541,6.208,2552,6.234,2555,4.425,4858,6.782,4859,6.782]],["t/1503",[6,0.076,1126,5.936,2541,6.019]],["t/1505",[6,0.078,110,1.726,160,0.87,193,0.83,208,1.593,219,1.757,222,2.784,326,2.875,354,3.379,374,0.826,394,3.056,398,2.231,435,3.848,486,3.263,494,2.246,510,4.632,573,2.894,639,1.988,687,2.589,739,3.056,774,4.227,842,2.881,933,3.546,959,2.954,992,2.08,998,1.737,1117,2.892,1302,3.291,1313,5.492,1355,2.267,1491,4.329,1733,3.391,1739,5.616,1833,4.379,1901,2.556,1920,2.831,1958,2.993,2082,2.589,2268,3.699,2290,3.319,2541,6.767,3080,2.831,3087,3.391,4356,3.204,4860,4.058,4861,4.415,4862,6.702,4863,4.415,4864,4.415]],["t/1507",[6,0.077,110,1.579,158,2.363,160,1.54,204,2.517,207,1.758,208,1.873,510,4.468,512,2.694,774,4.928,998,3.074,1590,3.764,1733,6.002,1833,3.518,2541,6.654,3425,7.086,4865,7.814,4866,7.814]],["t/1509",[6,0.077,110,1.43,176,2.449,193,1.336,207,1.598,208,1.063,354,3.581,374,0.875,398,1.957,510,5.377,512,2.449,730,5.72,761,5.03,1181,5.886,1313,6.375,1833,5.593,2093,2.81,2290,3.518,2541,4.281,4867,7.103]],["t/1511",[6,0.078,80,2.756,110,1.603,208,1.102,398,2.653,486,4.584,512,2.539,686,5.791,974,3.078,975,3.078,979,3.896,1643,2.786,1902,4.572,2026,4.645,2449,3.936,2541,6.86,4868,7.366,4869,7.366]],["t/1513",[6,0.078,110,1.617,153,1.502,217,6.402,222,3.753,226,2.947,374,1.439,383,4.483,476,2.833,512,2.874,559,3.361,565,4.836,623,4.408,645,4.644,966,2.275,1181,3.322,1308,3.552,1491,4.454,1833,2.679,2541,7.183,3582,3.361,4356,6.049,4779,5.47]],["t/1515",[6,0.077,110,1.526,160,1.602,204,1.663,207,1.83,208,1.536,219,3.237,347,4.374,398,2.24,435,3.862,510,4.65,730,4.798,774,5.129,1313,5.513,1590,3.059,1739,5.049,1833,3.662,2067,5.63,2093,3.218,2541,4.901,3086,6.462,4772,6.247]],["t/1517",[6,0.077,110,1.358,153,1.972,160,1.54,193,1.882,286,3.287,398,2.152,510,4.468,742,4.956,774,4.928,1142,5.297,1244,5.533,1739,4.851,1828,5.671,1833,4.506,1937,6.457,2062,4.928,3876,6.767,4356,5.671,4834,7.183]],["t/1521",[6,0.077,110,1.662,374,1.021,398,3.275,933,4.965,1313,5.615,1739,5.142,2082,4.857,2268,6.26]],["t/1523",[6,0.077,110,1.665,153,1.814,226,3.56,374,1.512,383,3.565,476,3.832,512,3.268,559,4.061,565,3.335,678,3.214,818,3.924,1117,2.566,1242,4.11,1308,4.039,1940,5.522,2541,6.795,3582,4.061]],["t/1525",[6,0.076,110,1.178,326,4.586,374,1.07,394,6.011,398,2.392,639,3.91,687,5.092,933,4.68,992,4.091,1117,4.135,1313,5.886,1833,3.91,1958,5.886,2082,5.092,2268,5.901,3087,6.67,4860,7.982]],["t/1527",[6,0.076,374,1.397,559,5.401,591,4.402,592,3.761,1722,7.344,2093,3.783,2287,7.682]],["t/1529",[6,0.078,158,2.746,4870,9.078]],["t/1531",[6,0.078,214,3.107,300,4.112,839,3.836,1286,7.771,1344,7.465,1355,3.648,3457,7.651,4449,6.152,4871,7.103,4872,7.103,4873,7.103]],["t/1533",[6,0.078,1286,6.907,1344,5.919]],["t/1536",[6,0.078,67,4.959,110,1.564,204,1.397,420,2.996,1664,8.424,4874,9.165,4875,11.524,4876,11.05,4877,6.833]],["t/1538",[6,0.078,214,2.938,228,7.335,326,2.803,410,3.736,2199,5.192,3708,5.659,4629,5.399,4878,6.535,4879,10.108,4880,10.108,4881,6.535,4882,6.535,4883,6.535,4884,6.535,4885,6.007,4886,6.535,4887,6.535,4888,5.659,4889,6.007,4890,6.535,4891,6.535,4892,8.892,4893,6.535,4894,6.535,4895,6.535,4896,10.108,4897,10.108,4898,6.535,4899,8.892,4900,8.892,4901,8.892,4902,8.892,4903,6.535]],["t/1540",[6,0.078,185,2.133,247,7.151,631,3.998,839,5.026,1029,6.428,1186,9.488,1286,5.778,4904,6.993,4905,6.993,4906,6.993,4907,10.461,4908,11.613]],["t/1542",[3,7.383,6,0.075,160,1.894,193,1.808,589,2.97,596,6.062,1674,4.123,2039,5.565,2040,6.516,3454,7.942,4909,9.613,4910,9.613]],["t/1544",[6,0.078,110,1.269,158,2.83,207,2.105,208,1.4,327,3.402,520,2.503,541,3.586,589,2.178,596,4.445,1534,3.768,1549,6.103,1551,4.133,2040,4.777,2041,4.519,4710,5.413,4911,5.599,4912,6.478]],["t/1546",[6,0.078,158,3.315,160,1.517,196,3.03,204,0.831,207,2.109,208,1.403,233,2.95,286,1.71,344,1.458,380,1.979,425,1.886,520,2.234,541,2.068,589,1.944,596,2.564,628,4.105,631,3.597,663,1.59,685,3.23,951,2.652,952,3.03,989,1.256,1140,3.23,1159,3.739,1534,4.414,1549,3.52,1551,2.384,1674,1.744,1786,3.52,1932,2.195,1944,3.122,2040,2.755,2041,6.627,4652,3.736,4911,6.115,4913,4.065,4914,6.884,4915,3.359,4916,5.198,4917,4.999,4918,3.736,4919,4.065,4920,4.065]],["t/1550",[6,0.078,153,1.938,158,2.323,160,2.158,207,2.227,208,1.481,233,7.946,520,2.728,541,5.571,663,3.004,1534,3.093,4715,8.7,4916,6.346,4917,7.863]],["t/1552",[6,0.078,110,1.515,158,1.887,207,1.939,208,1.289,374,0.769,420,1.622,487,3.504,513,2.071,532,2.1,533,2.033,622,1.903,1674,3.695,2041,4.001,2231,5.156,4347,5.736,4710,4.793,4912,5.736,4914,4.958,4915,7.118,4916,7.118,4917,4.958,4921,6.24,4922,6.24,4923,6.24,4924,6.24,4925,6.24,4926,6.24,4927,6.24]],["t/1554",[6,0.076,46,5.835,98,3.518,110,1.477,374,1.342,487,3.866,505,4.508,589,2.763,591,4.117,592,3.518,1155,5.315,2041,5.734,3461,8.22,4710,6.869,4928,8.943]],["t/1556",[6,0.076,951,6.516,4929,9.987,4930,9.987]],["t/1558",[6,0.078,110,0.748,153,1.992,158,2.789,160,1.555,165,1.748,168,0.961,179,3.112,190,3.358,193,0.646,200,1.409,207,1.776,208,1.181,214,1.135,233,5.728,253,2.329,254,1.645,256,1.436,261,1.875,264,5.884,286,1.445,288,2.1,319,3.634,332,2.378,373,1.514,374,0.423,380,1.672,385,2.847,423,2.166,430,1.94,439,1.781,480,1.265,520,1.22,541,3.51,589,1.061,634,1.875,639,2.481,663,3.087,697,3.735,793,2.1,906,1.896,933,2.412,1496,2.975,1534,3.715,1551,3.231,1564,1.504,1627,2.132,1786,2.975,1976,2.283,2035,2.378,2041,3.533,2046,2.975,2555,3.595,3241,4.771,3721,5.974,3995,4.232,4411,5.7,4697,2.975,4715,2.729,4722,5.481,4915,8.006,4916,8.585,4917,7.699,4931,3.435,4932,3.435,4933,3.435,4934,3.435,4935,3.435,4936,3.435,4937,3.435,4938,3.435,4939,3.435,4940,3.435,4941,3.435,4942,3.435,4943,5.51,4944,3.435,4945,3.435,4946,3.435,4947,5.51,4948,3.435,4949,3.435,4950,3.435,4951,5.51,4952,3.435,4953,3.435,4954,3.435,4955,3.435,4956,3.435,4957,3.435,4958,3.435,4959,3.435,4960,3.435,4961,3.435,4962,3.435]],["t/1560",[6,0.078,380,3.048,580,4.162,815,2.76,1044,5.422,1159,6.334,1738,5.422,4616,8.561,4710,4.809,4911,4.975,4918,5.756,4963,8.636,4964,8.636,4965,6.261,4966,6.261,4967,6.261]],["t/1563",[6,0.077,158,2.788,373,4.063,1534,3.712,2041,7.11]],["t/1565",[6,0.077,158,3.313,207,2.032,208,1.352,373,3.981,380,4.397,1534,4.411,2041,7.023,4911,7.176,4914,7.176]],["t/1567",[6,0.078,207,1.899,208,1.263,2041,6.736,4914,6.704]],["t/1570",[6,0.078,123,5.733,128,5.33,158,2.099,207,1.561,388,4.449,663,2.714,1159,6.885,1534,2.794,1551,5.43,1812,6.378,1826,5.33,2040,6.276,2041,4.449,3721,6.009,4914,5.513,4915,5.733,4917,5.513,4968,9.259,4969,6.939,4970,9.259,4971,9.259,4972,6.939]],["t/1573",[6,0.078,110,0.995,158,2.219,173,4.626,256,3.066,380,3.571,596,4.626,1159,4.36,1534,2.954,2040,4.973,2041,7.287,3830,6.743,4704,5.468,4911,7.632,4973,7.335,4974,7.335]],["t/1575",[6,0.076,110,1.333,2041,6.299,3454,8.116]],["t/1577",[6,0.076,83,3.908,487,3.987,2041,7.199,3723,8.651,4975,9.411,4976,8.651,4977,11.227]],["t/1579",[6,0.078,110,0.975,596,4.534,2040,4.873,3454,5.94,4722,5.712]],["t/1581",[31,6.652,80,3.502,81,8.606,89,6.794,100,4.519,121,8.108,153,2.363,565,4.343,1675,8.606,1902,5.812,1940,8.597,4978,8.606,4979,8.606,4980,8.606,4981,9.362,4982,8.606,4983,9.362,4984,8.606,4985,9.362,4986,9.362,4987,9.362,4988,8.606]],["t/1583",[31,6.611,36,8.649,84,6.724,198,4.758,1039,7.656,1128,5.752,1656,7.362,2140,7.362,2315,7.656,3929,8.517,4096,6.724,4989,9.265,4990,7.656,4991,8.024,4992,9.265,4993,8.024,4994,8.517,4995,9.265,4996,9.265,4997,9.265,4998,9.265,4999,9.265,5000,9.265]],["t/1585",[3,8.902,4,7.891,31,5.903,59,7.032,69,6.48,136,8.41,791,6.732,1174,6.48,3905,8.601,4265,8.601,5001,9.932]],["t/1587",[3,6.163,4,8.881,31,6.049,38,5.236,42,7.375,55,6.949,59,5.681,69,5.236,83,3.332,137,6.949,214,2.651,725,6.223,1502,4.769,1601,6.63,2252,5.145,3010,6.375,4888,8.813,4979,7.375,4980,7.375,5002,10.177,5003,9.355,5004,10.177,5005,7.375,5006,11.177,5007,10.274,5008,8.024,5009,8.024,5010,8.024,5011,8.813,5012,8.024,5013,10.177,5014,8.024,5015,8.024,5016,8.024,5017,8.024,5018,8.024,5019,8.024,5020,8.024,5021,8.024,5022,8.024,5023,5.981,5024,8.024]],["t/1589",[6,0.077,45,6.431,80,3.623,176,2.56,239,5.704,342,4.61,367,5.389,928,4.846,1185,6.209,1821,6.431,1824,6.827,4681,6.827,4885,8.901,4888,9.888,5003,9.904,5025,7.426,5026,12.368,5027,11.418,5028,7.426,5029,7.426,5030,7.426,5031,7.426,5032,7.426,5033,7.426]],["t/1591",[89,7.37,127,8.392,131,8.392,136,7.37,440,5.544,516,7.37,4096,7.37,5034,9.336,5035,10.156]],["t/1593",[6,0.056,31,5.838,37,6.659,38,6.41,69,6.41,83,4.079,1502,5.838,3010,7.804,4096,8.356,5023,7.323,5036,9.972,5037,9.029,5038,9.029]],["t/1595",[6,0.073,31,6.207,36,6.066,39,6.232,69,6.815,101,6.642,109,4.667,158,2.528,317,3.845,435,3.97,724,5.919,1502,4.969,1656,6.642,2089,6.421,2315,6.907,4096,7.579,4988,9.6,5034,10.47,5036,7.24,5037,9.6,5039,6.421,5040,7.684,5041,8.36,5042,8.36,5043,8.36,5044,8.36,5045,10.444,5046,6.907,5047,8.36,5048,8.36,5049,8.36]],["t/1597",[31,5.87,38,6.445,84,8.383,98,3.885,128,7.586,337,6.994,792,8.161,840,7.831,1777,9.079,5050,9.877,5051,9.877,5052,9.877]],["t/1599",[38,6.553,39,7.486,84,7.288,98,3.95,103,6.808,105,7.486,128,9.469,840,6.808,1188,7.111]],["t/1600",[1,6.943,39,8.317,103,6.313,105,6.943,128,9.175,129,5.325,130,8.57,133,8.561,347,3.969,751,6.077,908,5.462,1039,7.695,1188,6.595,2053,5.261,2252,5.972,2770,10.256,5023,8.317,5053,9.314,5054,9.314]],["t/1602",[31,6.176,89,7.541,316,4.679,5039,7.981,5055,10.391]],["t/1604",[31,5.396,39,6.767,69,5.924,89,8.573,102,4.496,103,6.154,105,6.767,185,2.769,688,10.888,1614,6.588,2445,5.924,5023,6.767,5039,9.43,5056,9.078,5057,9.078,5058,8.345,5059,9.078,5060,9.078,5061,9.078,5062,9.078,5063,9.078]],["t/1606",[6,0.075,36,6.522,38,5.864,89,8.536,109,5.017,127,7.426,1656,7.141,2140,7.141,4990,9.023,4991,9.457,4993,7.783,5039,6.903,5046,7.426,5064,8.261,5065,10.038,5066,8.987,5067,8.261]],["t/1608",[39,7.404,89,7.207,137,8.601,2050,5.549,2089,7.628,5036,8.601,5038,9.129,5039,7.628,5058,9.129,5068,9.932,5069,9.932,5070,9.932]],["t/1610",[6,0.069,36,7.051,37,6.587,38,6.34,68,7.72,69,6.34,136,7.051,5071,9.717,5072,9.717,5073,9.717,5074,9.717,5075,9.717,5076,9.717,5077,9.717,5078,9.717]],["t/1612",[6,0.069,38,5.693,68,10.188,69,5.693,83,3.624,136,7.782,385,3.601,1469,6.332,2268,5.919,3010,6.932,4994,10.673,5023,6.504,5079,9.858,5080,10.724,5081,8.725,5082,8.02,5083,8.725,5084,8.02,5085,8.725,5086,8.725,5087,8.725,5088,8.725,5089,8.02]],["t/1614",[6,0.054,37,8.643,38,6.239,69,6.239,83,3.971,136,9.064,3010,7.597,5023,7.128,5079,10.418,5089,8.789,5090,10.418]],["t/1616",[31,6.141,32,5.029,37,7.003,58,7.702,532,3.478,1198,5.579]],["t/1618",[6,0.053,37,8.08,432,4.4,587,7.54,622,2.826,792,7.656,945,9.19,1036,4.549,2315,7.656,4096,8.649,5005,8.517,5007,10.224,5011,8.024,5039,7.117,5040,8.517,5091,9.265,5092,8.517,5093,9.265,5094,9.265]],["t/1620",[5,6.077,37,6.313,38,6.077,41,5.199,58,6.943,69,7.795,77,9.175,136,8.096,1282,8.57,1920,5.972,4675,8.066,5011,8.066,5090,8.561,5095,8.561,5096,11.945,5097,9.314,5098,9.314]],["t/1622",[5,7.709,31,6.53,37,7.447,38,7.169,40,7.862,41,5.068,57,4.669,58,6.767,60,8.345,366,7.973,840,6.154,1111,6.154,1282,6.973,1614,6.588,3084,7.213,4675,7.862,5099,9.078,5100,9.078,5101,9.078,5102,9.078,5103,9.078]],["t/1624",[6,0.074,37,6.281,58,6.907,114,5.434,385,4.59,388,5.941,5084,10.224,5104,8.517,5105,8.024,5106,9.265,5107,9.265,5108,11.123,5109,11.123,5110,11.123,5111,9.265]],["t/1626",[5,7.213,6,0.063,31,5.451,32,5.381,67,8.611,69,5.984,506,6.096,1415,7.652,2993,10.161,4982,10.161,5104,8.43,5112,9.171,5113,9.171,5114,11.054,5115,11.866,5116,11.054]],["t/1628",[5,5.166,6,0.074,31,4.706,37,5.367,66,7.278,68,6.291,70,5.746,72,7.278,76,7.278,317,2.915,1032,4.472,1718,6.265,1940,6.081,2257,7.278,3928,7.278,4096,5.746,4704,5.902,5082,7.278,5105,9.62,5117,7.918,5118,7.918,5119,7.918,5120,11.108,5121,12.082,5122,6.857,5123,7.918,5124,7.918,5125,7.918,5126,7.918,5127,7.918,5128,7.918,5129,7.918,5130,7.918,5131,7.918,5132,7.918,5133,7.918,5134,7.918,5135,7.918,5136,7.918]],["t/1630",[77,8.028,135,9.051,1309,7.791,1374,7.235]],["t/1632",[6,0.073,36,6.976,58,7.166,129,6.5,2140,7.637,4984,8.836,4990,9.394,5046,7.942,5137,9.846,5138,9.613,5139,11.369]],["t/1634",[34,11.029,38,6.141,39,7.016,135,9.723,232,3.884,1309,7.016,1374,6.515,2445,6.141,3458,9.533,5140,9.411,5141,9.411,5142,11.999,5143,9.411,5144,9.411,5145,11.227]],["t/1636",[5,6.109,82,9.512,84,8.122,103,6.346,105,6.979,118,7.735,129,7.092,136,6.794,231,3.864,1258,6.979,1309,6.979,1374,6.481,1565,5.812,1823,7.735,5137,8.108,5146,9.362,5147,9.362,5148,9.362]],["t/1638",[6,0.075,36,6.522,38,5.864,109,5.017,127,7.426,129,6.243,589,2.777,1656,7.141,2140,7.141,4990,9.023,4991,9.457,4993,7.783,5023,6.7,5046,7.426,5064,8.261,5065,10.038,5067,8.261,5149,8.987]],["t/1640",[84,8.303,103,7.756,105,8.529,128,9.644,129,6.953,521,8.932,575,3.271,5137,8.415,5150,9.717]],["t/1642",[6,0.073,5151,10.391]],["t/1644",[6,0.078,96,2.999,109,3.068,110,1.674,154,3.192,158,1.662,160,1.083,191,2.389,193,1.034,199,4.569,208,1.594,354,3.972,373,2.422,374,1.312,425,4.272,428,1.876,431,1.538,505,2.77,513,1.824,532,1.85,588,4.221,589,2.434,743,2.756,766,3.988,964,2.405,987,6.819,1356,5.454,1360,3.891,1564,2.405,2290,2.721,3568,3.804,3615,3.142,5152,5.808,5153,5.495,5154,3.988]],["t/1646",[6,0.078,96,4.386,98,2.022,100,3.624,109,3.407,110,1.531,134,1.574,153,0.574,155,0.589,158,0.688,168,0.636,185,0.694,191,0.989,193,0.735,199,4.078,200,2.82,204,0.465,207,1.547,208,1.421,214,0.751,219,0.905,257,4.225,262,1.08,268,0.808,317,2.959,337,1.61,344,0.816,349,1.747,354,4.051,359,1.107,373,1.723,374,1.402,383,0.855,398,0.626,420,0.591,425,3.935,428,1.755,431,1.094,432,1.08,435,1.856,480,1.439,481,2.208,505,1.146,532,1.316,573,0.982,575,2.314,585,1.215,588,1.747,589,0.703,596,1.434,622,0.694,676,3.407,743,3.103,766,5.448,854,3.296,964,3.009,966,2.334,972,1.3,987,4.66,988,2.224,1035,3.559,1038,1.747,1117,2.68,1128,1.412,1181,1.269,1312,3.43,1356,4.225,1360,1.61,1371,1.807,1393,1.484,1564,0.995,1590,0.855,1629,1.969,1631,1.969,1739,1.412,1938,1.879,2000,1.65,2078,2.914,2290,1.126,2776,2.09,3201,3.593,3202,3.593,3264,2.09,3615,4.292,3649,1.695,4687,2.09,4703,4.248,5122,1.969,5152,3.849,5154,2.837,5155,2.274,5156,2.274,5157,2.274,5158,2.274,5159,2.274,5160,2.274,5161,2.274,5162,1.969,5163,2.09,5164,2.274,5165,2.274,5166,2.274,5167,2.09,5168,2.274]],["t/1649",[6,0.077,110,1.552,199,3.378,337,5.975,354,5.766,374,1.475,425,3.914,987,5.72,1356,5.842,3649,6.291,5152,5.322]],["t/1651",[6,0.078,96,4.337,100,2.065,109,2.388,110,0.888,124,2.961,185,1.305,191,1.86,199,3.181,317,1.575,354,3.299,374,1.097,385,3.673,420,1.112,596,2.698,622,1.305,657,4.633,659,3.944,676,3.653,743,1.497,766,3.104,932,3.705,972,4.543,987,6.033,988,2.384,1079,4.349,1117,1.527,1181,4.969,1312,1.955,1502,2.543,1908,4.53,2572,5.766,3430,3.535,3615,6.017,3649,3.189,3659,3.535,3844,3.535,4978,3.932,5152,2.698,5162,7.708,5163,6.015,5167,3.932,5169,8.759,5170,4.278,5171,3.932,5172,3.932,5173,4.278,5174,6.015,5175,6.015,5176,4.278,5177,4.278,5178,4.278,5179,4.278,5180,4.278,5181,3.286,5182,4.278,5183,4.278,5184,4.278,5185,5.667,5186,6.544,5187,3.932,5188,4.278,5189,4.278,5190,4.278,5191,4.278,5192,4.278,5193,4.278,5194,4.278,5195,4.278,5196,4.278]],["t/1653",[6,0.078,59,5.017,96,2.595,109,2.654,110,1.149,134,3.291,158,1.438,199,4.367,208,0.711,226,2.354,317,3.697,326,2.039,342,2.951,354,4.27,374,1.298,384,2.514,425,2.205,510,5.368,512,1.639,513,1.578,563,4.369,774,2.998,986,3.777,987,7.6,1242,4.843,1356,3.291,1393,3.102,1523,3.449,2071,3.16,2188,3.651,3615,2.718,4673,4.369,5095,4.369,5154,5.142,5197,4.753,5198,4.753,5199,7.086,5200,4.753,5201,4.753]],["t/1655",[6,0.078,96,3.021,100,3.823,109,3.866,110,1.318,190,3.371,191,1.502,199,3.17,200,2.27,214,1.141,257,2.392,317,3.191,354,4.662,374,0.682,385,3.816,410,1.975,435,1.641,436,1.203,505,1.742,589,1.068,651,5.482,657,4.904,676,1.929,972,3.165,987,2.342,988,2.885,1082,2.654,1162,5.36,1275,2.576,1312,3.618,1523,2.507,1739,2.145,2126,2,3123,4.252,3130,4.398,3568,2.392,3615,5.287,3643,3.176,3834,8.5,3844,2.855,3880,3.176,4225,4.398,4236,3.176,5169,5.997,5174,3.176,5175,3.176,5185,2.992,5187,5.088,5202,9.247,5203,3.455,5204,6.925,5205,7.28,5206,3.455,5207,3.455,5208,6.925,5209,3.455,5210,5.535,5211,5.535,5212,3.455,5213,3.455,5214,3.455,5215,5.535,5216,5.535,5217,3.176,5218,5.535,5219,3.455,5220,3.455,5221,3.455,5222,3.455,5223,3.455,5224,3.455,5225,6.925,5226,3.455,5227,5.535,5228,3.455,5229,3.455,5230,3.455,5231,3.455,5232,5.535,5233,3.455,5234,5.535,5235,3.455,5236,3.455,5237,3.455,5238,3.455]],["t/1657",[6,0.078,80,2.746,96,2.06,100,2.866,110,1.364,165,1.92,185,1.811,190,1.837,191,1.641,193,0.71,208,0.565,231,1.558,257,2.613,316,1.699,317,2.186,319,1.738,354,4.562,374,0.732,385,2.451,398,1.04,410,4.197,425,2.754,430,2.132,435,3.486,573,3.17,575,1.271,631,3.395,659,2.275,839,2.038,879,2.673,964,1.652,988,2.163,1117,1.347,1157,3.47,1312,2.713,1451,4.976,1535,2.463,1750,3.119,2126,4.249,2971,2.999,3123,5.638,3130,5.832,4033,3.47,4703,3.119,5152,2.38,5169,6.357,5171,3.47,5172,3.47,5185,7.208,5205,3.47,5217,3.47,5239,3.774,5240,3.774,5241,3.774,5242,5.938,5243,3.774,5244,3.774,5245,3.774,5246,3.774,5247,3.774,5248,3.774,5249,3.774,5250,3.774,5251,3.774,5252,3.774,5253,3.774,5254,3.774,5255,3.774,5256,3.774,5257,3.774,5258,3.774,5259,3.774,5260,3.774,5261,3.774,5262,3.774,5263,3.774,5264,3.774,5265,3.774,5266,3.774,5267,7.34,5268,3.774,5269,3.774,5270,5.938,5271,3.774,5272,5.938,5273,3.774,5274,3.774,5275,3.774,5276,3.774,5277,3.774,5278,3.774,5279,3.774,5280,3.774,5281,3.774,5282,3.774,5283,5.458,5284,3.774,5285,3.774,5286,3.774,5287,3.774,5288,3.774,5289,3.774,5290,3.47,5291,3.47,5292,3.774,5293,3.774,5294,3.774,5295,3.774,5296,5.938,5297,3.774,5298,3.774,5299,3.774,5300,3.774,5301,3.774,5302,3.774,5303,3.774]],["t/1659",[6,0.078,100,2.529,109,5.493,212,2.863,214,1.731,226,2.594,236,1.78,300,3.033,317,4.142,385,2.162,394,3.627,420,1.362,425,4.564,435,2.488,573,2.262,634,2.86,972,2.995,1312,5.141,1945,4.815,2126,3.033,2604,3.709,2871,4.815,2902,4.537,3284,4.815,3615,5.625,5283,4.815,5290,4.815,5291,4.815,5304,5.239,5305,7.611,5306,5.239,5307,5.239,5308,5.239,5309,5.239,5310,5.239,5311,5.239,5312,5.239,5313,5.239,5314,5.239,5315,5.239,5316,5.239,5317,5.239,5318,5.239,5319,5.239,5320,5.239,5321,5.239,5322,5.239,5323,5.239,5324,5.239,5325,5.239,5326,7.611]],["t/1663",[6,0.077,96,6.026,109,4.362,193,1.882,199,4.006,908,5.869,909,6.311,988,4.241,5327,10.7,5328,7.814,5329,7.814,5330,6.767]],["t/1665",[6,0.078,10,1.569,46,2.527,80,3.158,96,5.541,100,2.924,109,2.162,110,1.145,143,3.553,149,2.369,153,1.529,154,3.023,155,1.003,158,1.171,160,0.763,164,1.918,170,1.262,179,2.187,185,1.181,199,3.379,207,1.899,208,1.371,230,1.783,236,1.316,254,1.854,262,1.839,288,2.368,292,2.68,317,2.747,326,1.661,342,2.404,411,2.527,420,1.575,425,1.796,435,1.839,512,2.089,513,2.477,575,1.303,664,2.271,704,3.076,730,1.81,739,2.68,743,2.12,909,2.442,964,3.266,972,2.214,974,1.618,975,1.618,976,3.353,979,2.048,988,1.411,1000,3.559,1037,2.334,1091,5.005,1145,3.076,1160,2.887,1242,2.214,1312,2.768,1356,2.68,1491,2.069,1562,2.483,1564,2.652,1683,3.076,1962,4.653,1994,1.97,2195,3.076,2261,2.483,3273,3.076,3615,4.826,3904,3.353,5152,4.706,5331,3.872,5332,3.872,5333,3.872,5334,7.758,5335,3.559,5336,3.559,5337,3.559,5338,3.559,5339,3.559,5340,3.872,5341,3.872,5342,3.872,5343,3.872,5344,3.559,5345,3.559,5346,3.872,5347,3.559,5348,5.246,5349,3.559,5350,3.559,5351,3.559]],["t/1667",[6,0.078,143,4.794,153,1.131,160,0.883,167,1.53,168,2.288,176,1.545,193,1.275,204,1.386,207,2.051,208,1.364,219,1.783,246,2.663,268,2.407,344,1.607,374,1.318,431,1.897,480,2.496,512,1.545,575,3.295,588,3.442,704,3.56,743,4.189,964,4.821,968,3.037,1091,5.6,1160,3.34,1564,1.961,2290,3.357,2447,5.385,3904,3.88,4231,4.119,5152,5.156,5327,4.119,5335,7.515,5336,4.119,5337,4.119,5338,4.119,5339,4.119]],["t/1669",[6,0.078,80,2.536,96,2.446,109,5.089,110,1.237,153,1.131,160,1.336,176,1.545,185,1.367,191,2.947,193,1.937,231,1.849,317,1.65,354,3.417,431,1.254,485,4.281,487,1.591,512,2.337,532,3.068,533,2.97,582,3.328,589,1.384,596,5.748,623,2.37,638,5.178,678,2.003,684,3.442,685,3.56,743,2.371,905,2.394,906,2.473,908,3.975,909,2.826,964,1.961,974,1.873,975,1.873,988,3.321,998,1.763,1115,2.74,1491,2.394,1562,2.873,1905,3.702,1925,3.442,1984,3.34,2447,3.56,3615,5.211,4704,3.34,5152,6.495,5330,3.88,5334,8.999,5344,8.999,5345,4.119,5352,4.481,5353,6.778,5354,8.175]],["t/1672",[6,0.077,109,5.863,158,2.132,195,4.133,219,2.805,344,2.528,425,4.34,487,3.73,512,2.43,559,3.981,622,2.15,638,3.727,678,3.151,942,6.476,980,4.879,1362,6.478,1363,6.478,2011,4.445,2012,6.478,2071,4.684,2548,6.478,3615,6.004,4447,7.73,5355,7.048,5356,6.478,5357,9.356,5358,7.048,5359,7.048,5360,7.048,5361,7.048,5362,7.048,5363,7.048,5364,6.478,5365,9.356,5366,7.048,5367,7.048,5368,7.048]],["t/1674",[6,0.077,10,2.282,51,3.444,80,3.493,100,2.719,109,5.213,110,1.088,153,1.422,154,2.282,164,2.79,170,1.836,176,1.942,179,4.529,185,1.718,193,1.06,207,1.268,208,1.2,214,1.861,226,2.79,230,2.593,236,1.914,254,2.697,262,2.675,288,3.444,292,3.899,317,2.074,326,2.416,435,2.675,485,4.199,512,1.942,513,1.87,532,1.896,533,3.747,541,4.08,573,2.432,575,1.896,678,2.518,906,4.426,1037,3.395,1171,3.744,1312,2.574,1491,3.01,1538,2.697,1562,3.612,1564,3.51,2195,4.476,2543,5.178,3273,4.476,3615,4.585,4447,8.406,4540,4.878,5152,5.057,5347,5.178,5348,6.944,5349,5.178,5350,5.178,5351,5.178,5369,5.633,5370,5.633]],["t/1676",[6,0.078,46,3.819,80,2.19,96,3.195,109,5.778,110,1.118,176,2.018,193,1.101,207,1.854,208,1.233,435,2.78,510,3.346,512,2.841,573,2.528,645,2.826,678,2.617,743,2.883,766,4.248,964,4.174,988,2.133,1242,5.452,1564,2.562,2290,4.08,3615,6.469,4447,7.879,5152,6.527,5371,5.853,5372,5.853]],["t/1678",[6,0.075,199,4.043,374,1.245,5154,7.329]],["t/1680",[6,0.078,195,4.355,201,3.814,207,2.425,326,3.186,512,2.56,596,4.684,687,4.355,742,5.336,761,7.63,924,6.431,1376,5.536,2011,4.684,2261,4.762,5154,7.819,5373,7.426,5374,7.426,5375,7.426,5376,7.426,5377,7.426]],["t/1682",[5,3.379,6,0.077,10,2.098,51,3.166,80,4.062,110,0.703,134,3.585,153,1.307,155,1.341,160,1.755,164,2.564,179,2.925,193,1.957,199,4.165,207,2.004,208,1.557,219,2.061,247,3.32,254,2.479,292,3.585,326,2.221,344,1.858,374,0.93,377,2.332,424,2.315,431,2.738,513,1.719,533,2.459,541,2.635,573,2.236,728,3.078,742,2.564,906,4.166,974,2.164,975,2.164,976,4.484,980,3.585,1037,3.121,1383,5.626,1562,3.32,1565,3.215,1683,4.114,2035,3.585,2290,2.564,3273,4.114,4976,4.76,5152,5.616,5154,7.549,5348,6.536,5378,5.178,5379,5.178,5380,7.547,5381,5.178,5382,5.178,5383,5.178,5384,5.178,5385,7.547,5386,5.178,5387,4.76]],["t/1684",[6,0.078,96,4.713,109,5.325,110,1.446,154,1.989,158,1.485,193,1.624,199,2.905,207,1.105,208,1.523,219,1.954,268,1.744,308,3.328,344,1.761,374,0.894,431,2.416,510,2.807,512,1.693,513,1.629,575,2.906,743,3.337,964,3.779,986,3.901,987,4.92,1564,2.149,2290,2.431,3615,4.149,5152,6.016,5154,6.922,5387,7.936]],["t/1686",[6,0.078,100,3.166,110,1.474,153,1.655,197,6.029,208,1.516,374,0.808,743,3.119,766,4.759,964,3.902,987,4.446,5152,7.166,5330,5.68,5388,6.559,5389,6.559]],["t/1689",[6,0.077,96,3.847,100,3.402,109,3.934,110,1.624,160,1.389,168,1.972,199,4.204,207,1.586,208,1.674,246,4.189,268,2.503,317,2.595,354,4.716,374,1.294,575,2.372,622,2.15,638,3.727,743,2.466,766,5.114,987,6.342,988,2.568,1312,3.22,1356,4.879,1564,3.085,1891,3.553,2071,4.684,2290,3.49,3615,4.029,5152,5.9,5154,5.114,5390,7.048]],["t/1691",[6,0.074,5391,10.331]],["t/1693",[6,0.078,110,1.56,153,2.67,193,1.158,268,2.186,317,2.266,373,2.713,420,2.219,430,4.82,431,1.722,513,2.832,520,3.031,533,2.005,541,3.131,622,1.877,634,4.658,663,3.337,989,2.637,3518,5.329,5392,6.154,5393,6.154,5394,5.329,5395,5.329,5396,5.657,5397,6.154,5398,6.154,5399,6.154]],["t/1695",[6,0.078,32,3.903,110,1.48,143,2.545,144,4.172,149,2.587,153,1.095,160,1.58,193,2.102,200,3.678,207,2.172,208,1.445,268,1.541,319,1.998,373,2.916,374,1.304,379,3.149,380,3.22,385,2.73,431,3.051,476,1.475,480,2.952,481,3.737,541,2.208,575,2.699,589,1.341,622,1.324,729,3.073,979,2.295,989,3.143,1155,2.579,1156,2.942,1171,4.397,1309,3.235,1386,5.328,1389,3.073,5396,3.989,5400,4.34,5401,4.34,5402,6.616,5403,4.34,5404,4.34,5405,4.34,5406,4.34]],["t/1698",[6,0.078,98,2.543,153,1.631,199,2.588,204,1.322,317,4.163,373,2.849,420,2.808,430,6.386,435,3.07,520,3.836,541,3.289,622,3.449,634,5.895,988,3.216,1079,4.297,1627,4.013,1739,4.013,1936,5.136,3568,4.475,3569,4.475,3611,5.341,5181,6.78,5407,6.464,5408,5.942,5409,6.464,5410,6.464,5411,6.464]],["t/1700",[6,0.077,110,1.509,153,2.807,158,2.802,268,3.291,513,3.075,541,4.714,638,4.9,1440,8.024]],["t/1702",[6,0.078,100,4.43,110,1.441,158,1.652,190,5.171,221,2.705,374,0.673,385,2.254,398,1.504,399,1.702,420,2.608,422,2.283,430,3.085,505,2.753,512,1.883,589,1.688,592,2.148,622,2.393,634,5.476,913,6.025,995,3.532,1041,2.124,1077,4.195,1111,3.702,1112,4.869,1156,3.702,1304,4.195,1374,3.781,1816,6.793,2090,4.513,3568,3.781,3569,3.781,3611,8.288,3921,7.573,5394,8.687,5395,6.793,5408,7.21,5412,4.73,5413,5.462,5414,5.462]],["t/1704",[6,0.078,110,1.558,185,1.871,198,4.372,512,2.115,520,3.023,592,4.155,622,1.871,645,2.961,663,2.399,933,4.28,989,3.021,1077,7.51,1627,3.807,1686,5.068,1936,4.873,3612,5.638,3642,5.311,3862,7.372,3921,5.658,5181,4.711,5395,5.311,5415,5.638,5416,4.572,5417,5.638,5418,6.133,5419,6.133,5420,6.133,5421,6.133,5422,6.133,5423,6.133,5424,6.133,5425,6.133,5426,6.133,5427,6.133,5428,6.133,5429,6.133,5430,6.133]],["t/1706",[6,0.078,198,4.084,212,2.991,316,3.581,425,3.689,520,4.161,592,4.609,933,3.481,1440,6.887,5415,7.31,5417,7.31,5431,7.953,5432,7.953]],["t/1708",[6,0.078,80,2.499,100,4.357,110,1.599,158,2.021,160,1.316,176,2.303,193,1.698,204,1.366,226,3.308,374,1.112,431,1.869,513,2.217,592,2.628,663,2.613,729,4.73,989,3.159,1385,5.308,1386,4.982,1547,3.971,1836,7.02,4597,6.141,5412,5.785,5416,4.98,5433,6.681,5434,6.681]],["t/1710",[6,0.077,100,5.177,110,1.575,214,2.883,374,1.322,385,3.601,480,3.212,712,4.871,1386,4.816,5412,7.556,5435,7.209]],["t/1712",[6,0.078,100,3.429,110,1.66,160,1.4,193,1.336,199,2.844,316,3.198,374,1.299,420,2.445,431,1.988,539,5.155,573,3.067,622,2.167,718,3.836,799,4.555,831,4.722,989,2.906,1035,4.917,1041,4.1,1111,7.147,5436,7.103,5437,7.103]],["t/1714",[6,0.077,10,2.717,98,3.56,100,4.944,110,1.228,153,1.692,160,1.783,191,2.915,199,3.623,347,2.857,374,1.262,505,4.562,532,3.854,533,3.731,589,3.388,591,4.166,592,2.638,622,3.345,743,2.346,988,2.443,989,2.072,1041,2.608,1111,4.546,1374,4.642,1674,2.876,1984,6.746,2078,4.999,3747,4.866,3748,4.642,3906,6.164,5092,6.164,5438,6.706]],["t/1716",[6,0.078,100,4.725,110,1.655,374,1.206,585,4.035,989,2.333,995,3.4]],["t/1718",[6,0.078,32,2.011,80,1.545,96,2.255,97,3.282,98,1.625,100,5.316,110,1.614,143,2.422,190,2.011,193,1.462,198,3.271,344,1.482,374,0.785,398,1.754,420,2.455,430,3.598,480,2.345,503,3.577,513,2.58,520,2.262,585,2.207,622,1.26,634,4.244,639,2.868,645,3.075,742,2.045,743,1.445,905,2.207,933,1.808,980,2.859,989,1.968,1282,3.173,1312,2.91,1562,2.648,1643,2.94,1655,3.797,1753,3.413,1816,5.516,3022,5.702,3862,3.577,3921,2.745,5394,3.577,5439,4.13,5440,4.13,5441,4.13,5442,4.13,5443,4.13,5444,4.13,5445,5.855,5446,4.13,5447,4.13,5448,4.13]],["t/1720",[6,0.078,57,1.097,82,2.291,96,1.574,100,5.482,110,1.541,143,1.691,149,1.128,153,1.206,193,1.338,199,1.154,204,0.59,208,1.346,232,1.19,354,1.454,374,1.047,398,2.171,399,1.906,420,2.05,422,1.205,428,0.985,431,1.337,477,2.093,480,1.062,513,0.957,532,0.971,533,0.94,534,1.221,565,1.338,575,0.971,585,3.8,589,0.891,590,2.199,628,1.882,631,2.731,645,2.306,663,1.868,673,1.198,709,1.61,849,1.318,951,1.882,963,2.183,966,1.827,987,1.955,989,2.908,995,3.825,1041,3.065,1129,1.51,1185,1.849,1627,1.79,1752,3.383,1753,2.383,2207,2.215,2208,2.215,2337,1.996,2457,1.996,3425,3.383,3690,2.651,3813,2.291,3825,2.497,3842,2.291,5152,3.013,5435,2.383,5449,2.884,5450,2.884,5451,2.884,5452,2.884,5453,2.884,5454,4.777,5455,2.884,5456,2.884,5457,2.884,5458,2.884,5459,4.777,5460,2.884,5461,4.137,5462,2.497,5463,2.651,5464,2.884,5465,2.651,5466,2.884,5467,2.651,5468,2.884,5469,2.884,5470,2.884]],["t/1722",[6,0.076,221,4.612,520,3.308,592,4.871,1128,5.782,1386,5.14,5181,7.154,5416,6.943,5435,7.695,5471,9.314]],["t/1724",[6,0.077,46,4.493,96,3.758,110,1.25,193,1.295,199,2.757,221,4.562,327,3.324,374,1.135,398,2.859,431,1.927,436,2.397,591,3.17,592,4.545,623,4.872,956,5.963,972,3.937,989,2.127,1028,4.493,1041,2.678,1111,4.667,1547,4.092,1718,6.444,2337,4.767,2559,4.876,3049,5.689,3615,3.937,4598,5.963,5435,5.689,5472,6.886,5473,6.886,5474,5.963]],["t/1726",[6,0.076,221,5.595,520,4.012,592,4.444,5181,7.305,5416,7.09]],["t/1728",[6,0.078,56,5.294,199,2.306,221,5.088,316,3.668,327,2.78,333,3.378,374,1.165,394,3.987,398,1.586,401,1.967,420,1.498,425,2.672,430,3.253,486,2.32,520,2.045,591,3.75,592,4.428,622,2.485,657,4.078,677,3.293,725,3.522,941,4.293,989,1.78,1028,5.315,1077,4.424,1128,3.575,1547,4.842,1718,3.575,2337,3.987,2468,5.294,3049,4.759,3615,3.293,4225,4.576,5181,6.257,5416,7.046,5474,4.988,5475,5.759,5476,5.759,5477,5.759,5478,5.759,5479,5.759,5480,5.759,5481,5.759,5482,5.759,5483,5.759,5484,5.759,5485,4.988,5486,5.759]],["t/1730",[6,0.078,100,2.008,198,4.863,212,1.564,221,4.69,286,1.749,317,3.229,354,2.097,398,1.764,430,3.617,485,3.353,520,2.274,533,1.355,534,1.761,585,2.222,592,4.871,595,1.738,623,2.2,628,2.714,673,1.727,744,4.919,905,2.222,988,1.515,989,1.285,996,3.436,1036,3.144,1077,4.919,1312,1.9,1374,2.879,1633,3.018,1718,2.582,1833,3.949,2199,3.304,2568,2.439,3022,5.095,3635,3.018,3842,3.304,3921,4.256,5487,8.77,5488,4.159,5489,4.159,5490,4.159,5491,4.159,5492,4.159,5493,4.159,5494,4.159,5495,4.159,5496,3.602,5497,3.195,5498,3.823,5499,4.159,5500,6.404,5501,4.159,5502,4.159]],["t/1732",[6,0.078,110,1.098,317,2.981,398,3.248,399,3.19,425,3.756,592,4.026,951,5.283,966,3.096,989,2.501]],["t/1734",[6,0.074,110,1.577,153,2.934,212,3.756,436,3.477]],["t/1736",[6,0.078,98,2.919,100,2.905,110,1.669,199,1.537,212,1.444,217,2.949,236,3.289,300,4.296,316,1.729,374,1.035,398,1.057,401,1.311,476,1.305,480,1.413,485,2.01,520,2.137,585,2.051,592,2.367,622,1.835,638,3.183,673,1.594,743,2.105,905,2.051,951,2.505,968,4.079,989,1.186,995,1.729,1064,3.484,1118,1.767,1142,5.695,1386,2.119,2208,2.949,2396,4.781,3921,2.552,3969,3.529,3970,3.529,5462,3.325,5497,5.7,5503,3.839,5504,3.839,5505,6.017,5506,6.017,5507,3.839,5508,3.839,5509,3.839,5510,3.839,5511,3.839,5512,3.839,5513,5.211,5514,4.972,5515,3.839,5516,3.839,5517,3.839,5518,3.839,5519,3.839,5520,3.839,5521,3.839,5522,3.839,5523,3.839,5524,3.839]],["t/1738",[6,0.078,100,2.247,110,1.619,124,3.222,153,1.76,246,5.523,304,4.279,398,1.282,420,1.814,435,2.211,532,2.348,533,2.273,592,3.915,634,2.541,645,4.038,815,3.075,905,2.487,989,2.155,1113,3.47,1156,3.155,1202,3.296,1297,3.698,1494,3.037,1674,1.997,1683,3.698,1739,2.89,2429,7.245,3921,4.637,5525,6.041,5526,4.655,5527,4.031,5528,4.655,5529,4.279,5530,4.279]],["t/1740",[6,0.078,46,5.033,96,4.21,110,1.572,354,3.889,374,0.951,2207,5.925,3587,8.594]],["t/1742",[6,0.078,110,1.687,354,4.754,420,2.452,592,2.805,622,2.175,634,3.893,1718,6.977,2337,4.937,2568,5.53,3615,4.077,5531,9.429]],["t/1744",[6,0.075,110,1.394]],["t/1746",[6,0.078,110,1.25,153,2.916,268,2.445,374,1.366,480,3.822,532,2.318,533,3.612,595,4.338,622,2.1,638,3.642,988,2.509,998,2.709,1041,2.678,1111,4.667,2690,5.689,5532,6.886]],["t/1748",[6,0.077,80,3.042,110,1.603,153,2.052,193,1.53,204,2.299,208,1.683,374,1.002,431,2.276,480,2.994,989,3.171]],["t/1750",[6,0.078,110,1.25,204,1.883,207,1.549,208,1.379,374,0.849,424,3.078,480,2.535,639,3.1,663,3.603,673,3.826,989,3.425,991,5.689,1086,4.667,1630,5.689,2209,5.471,5364,6.329,5533,6.886,5534,6.886,5535,6.329,5536,5.471,5537,5.471]],["t/1752",[6,0.078,110,1.657,153,2.361,158,2.132,193,1.326,208,1.572,246,5.561,431,1.972,533,2.297,592,4.131,595,2.945,815,4.124,989,2.178,1386,3.89,1534,2.838,1630,5.823,2252,6.734,3748,4.879,5535,6.478,5536,5.599,5537,5.599,5538,7.048]],["t/1754",[6,0.078,110,1.686,208,1.747,333,4.166,374,0.875,480,2.615,532,2.391,533,3.065,534,3.007,541,3.614,595,2.969,663,2.778,743,2.485,989,3.258,1041,2.762,1386,3.921,1562,4.555,1994,3.614,2252,6.03,5536,5.644,5537,5.644]],["t/1756",[6,0.078,100,5.025,110,1.542,208,1.245,333,3.478,374,1.184,420,1.542,480,3.062,532,2.799,533,2.71,573,2.561,585,3.169,592,3.778,663,2.319,673,3.988,905,3.169,989,3.216,1156,4.02,1312,2.71,1386,5.745,4629,4.9,5497,4.555,5514,4.9,5536,4.712,5537,4.712,5539,5.451,5540,5.931]],["t/1758",[6,0.078,110,1.369,208,1.51,232,3.268,663,3.947,673,4.191,989,2.446,5536,6.291,5537,6.291,5541,6.857,5542,7.918]],["t/1760",[6,0.075]],["t/1762",[6,0.077,100,4.72,110,1.327,153,2.148,154,2.485,190,2.985,198,3.15,204,1.254,327,2.961,420,1.595,534,2.596,585,3.277,592,2.413,663,2.399,676,4.752,677,3.506,687,3.597,929,3.424,952,6.346,960,4.647,989,3.264,992,2.89,995,2.761,1111,4.157,1142,4.157,1312,2.802,1938,5.068,2208,6.539,2396,6.764,2690,5.068,2948,5.068,3255,5.638,3636,5.311,3747,7.095,3748,4.246,5465,5.638,5467,5.638,5530,5.638,5543,6.133,5544,6.133,5545,5.638,5546,6.133,5547,6.133,5548,8.513,5549,6.133,5550,6.133,5551,6.133]],["t/1764",[6,0.078,110,1.089,153,2.025,374,0.989,532,2.701,533,2.615,534,3.397,592,3.156,663,3.138,676,5.682,815,3.537,989,3.145,1359,9.355,3022,6.641,5552,8.024]],["t/1766",[6,0.078,100,4.052,110,1.668,199,4.192,208,0.899,221,2.976,333,3.525,374,0.741,513,1.995,532,2.825,533,2.735,573,2.595,592,3.302,622,2.95,623,3.179,663,2.351,718,3.245,905,4.485,951,3.922,989,2.593,1111,5.69,1386,4.633,3022,3.922,3049,4.966,3921,3.995,5416,4.48,5462,5.205,5497,6.447,5498,5.524,5513,5.205]],["t/1768",[6,0.078,46,4.794,59,3.534,96,4.01,100,4.947,110,1.504,153,1.26,154,2.022,155,1.293,199,2.941,208,0.747,221,3.638,249,3.721,316,2.247,317,2.705,333,2.927,374,1.185,398,2.401,401,1.704,420,1.298,513,2.438,592,3.429,622,2.241,725,4.492,989,1.542,1028,3.257,1386,2.755,1494,3.257,1683,3.966,1718,4.561,1826,3.834,2199,3.966,2207,3.834,2337,3.455,2787,3.318,3615,4.984,3921,3.318,5416,3.721,5485,4.322,5553,4.991,5554,4.991]],["t/1770",[6,0.078,190,2.595,373,2.35,399,1.662,663,3.015,687,3.127,952,3.975,989,2.798,1455,4.618,1521,3.852,1525,3.691,2001,4.901,3048,4.901,3921,3.544,5555,5.332,5556,5.332,5557,5.332,5558,5.332,5559,5.332,5560,5.332,5561,5.332,5562,5.332,5563,5.332,5564,5.332,5565,5.332]],["t/1772",[6,0.078,46,4.129,98,2.489,110,0.859,316,2.849,374,1.072,420,1.645,591,4.576,592,4.211,622,1.93,663,3.402,673,2.628,815,4.381,989,1.955,1547,3.761,1611,6.533,1643,3.29,1734,6.484,1932,3.417,2247,4.48,2252,4.057,2787,4.206,4096,6.312,4598,5.48,4703,5.228,5496,5.48,5566,6.328,5567,6.328]],["t/1774",[6,0.078,98,2.388,100,2.931,110,1.625,153,1.532,190,2.955,208,1.455,246,3.608,268,2.156,316,2.733,333,4.957,374,0.748,398,1.672,420,1.579,532,2.845,533,2.754,592,2.388,622,2.578,660,4.203,663,3.803,687,3.56,815,2.676,989,3.416,1041,3.782,1129,4.426,2007,4.299,3921,4.035,5461,5.257,5474,5.257,5514,5.016,5541,5.257]],["t/1776",[6,0.078,48,7.14,110,1.405,153,2.081,374,1.016,663,4.049,1041,3.206,1734,6.146,5568,8.245]],["t/1778",[6,0.078,80,1.867,98,1.963,100,2.409,110,0.677,155,1.293,190,2.43,246,2.967,373,2.2,374,0.905,377,4.826,420,2.665,487,1.773,622,1.522,663,1.952,742,2.472,972,2.854,989,2.27,1181,2.786,1258,3.721,1495,3.834,1674,3.151,1734,3.721,2039,2.889,2346,4.322,3249,4.588,3921,3.318,5445,4.588,5497,3.834,5539,6.753,5569,8.718,5570,4.991,5571,9.615,5572,4.991,5573,4.991,5574,4.991,5575,4.991,5576,4.991,5577,4.991,5578,4.991,5579,4.991,5580,4.991,5581,4.991,5582,4.991]],["t/1780",[6,0.077,57,3.011,110,1.587,153,2.547,208,1.185,246,4.706,333,4.643,373,3.49,399,2.468,436,2.757,532,3.397,533,2.58,584,3.645,592,3.114,663,3.097,748,3.791,989,3.118,995,3.565,5463,7.278,5525,6.857]],["t/1782",[2,1.273,6,0.078,32,1.013,57,0.792,59,1.474,96,1.136,98,3.02,100,1.005,110,1.485,153,2.591,154,0.843,160,0.41,167,2.622,198,1.069,204,0.426,207,0.468,208,0.719,236,0.707,246,3.87,268,1.286,300,1.205,308,1.411,326,1.553,327,1.005,373,1.596,374,1.163,398,0.573,399,0.649,401,0.711,420,1.996,480,0.766,486,0.838,513,2.548,532,1.219,533,1.18,541,2.924,554,1.72,580,1.384,585,1.112,591,1.667,592,1.424,622,2.481,663,2.247,678,0.931,680,1.441,727,3.344,730,0.973,742,1.031,743,1.267,791,1.411,815,1.596,972,1.19,980,1.441,989,2.207,993,2.284,1044,1.803,1129,1.09,1142,1.411,1158,1.149,1198,1.124,1202,2.564,1386,1.149,1602,1.72,1611,3.103,1659,4.977,1734,1.552,1735,2.877,2007,2.564,2248,1.913,2305,1.654,2396,1.654,2769,1.654,2787,1.384,3022,1.358,3451,1.913,3832,1.803,4889,1.913,5105,1.803,5122,1.803,5461,1.803,5527,1.803,5529,1.913,5541,1.803,5583,2.082,5584,2.082,5585,2.082,5586,6.511,5587,2.082,5588,2.082,5589,2.082,5590,2.082,5591,2.082,5592,2.082,5593,3.621,5594,2.082,5595,2.082,5596,2.082,5597,2.082,5598,2.082,5599,2.082,5600,2.082,5601,2.082,5602,2.082,5603,2.082,5604,2.082,5605,2.082,5606,2.082,5607,2.082,5608,2.082,5609,2.082,5610,1.913,5611,2.082,5612,2.082,5613,2.082,5614,1.913]],["t/1784",[6,0.076,110,1.326,153,2.466,374,1.204,513,3.243]],["t/1786",[6,0.077,110,1.491,153,2.773,513,3.647,663,3.55,989,3.395]],["t/1788",[6,0.078,46,3.369,96,2.818,98,2.963,100,5.016,110,1.472,153,1.303,199,3.015,207,1.162,214,1.706,373,2.276,374,1.204,420,1.343,510,4.306,512,1.78,513,2.5,589,1.595,592,4.267,622,2.981,704,4.102,761,3.656,905,2.759,951,3.369,1031,4.266,1242,4.306,1386,4.157,2199,4.102,3569,3.574,3615,2.952,3666,3.966,5162,6.522,5545,4.746,5615,5.163,5616,5.163,5617,5.163,5618,5.163]],["t/1790",[2,4.116,6,0.078,98,4.037,110,0.913,153,1.699,199,3.632,212,2.532,221,3.333,316,3.031,374,1.265,398,1.854,425,4.208,436,2.343,592,4.646,622,2.767,677,3.848,989,2.08,1356,4.659,2396,5.348]],["t/1792",[6,0.078,110,1.156,663,3.332,673,3.538,989,2.632,2209,6.768]],["t/1794",[6,0.078,51,2.76,96,2.464,100,2.179,110,1.682,143,2.647,153,2.073,154,1.829,158,1.365,212,1.698,246,4.052,316,3.069,354,2.276,374,1.273,398,1.243,420,1.772,589,1.395,597,3.406,638,2.388,742,2.236,743,2.385,1117,1.611,1142,6.202,1546,4.15,1718,4.232,2568,3.998,3587,5.903,5356,4.15,5485,3.91,5497,3.468,5513,3.91,5514,3.73,5525,5.903,5527,3.91,5619,4.514,5620,4.514]],["t/1796",[6,0.078,110,1.408,153,1.738,208,1.031,216,3.986,317,2.535,374,1.135,480,3.391,513,2.285,575,2.318,663,2.693,684,5.289,685,5.471,966,2.633,5614,6.329,5621,6.886,5622,6.886,5623,6.886,5624,6.886,5625,6.886]],["t/1798",[6,0.078,110,1.617,153,1.914,208,1.135,532,3.304,533,3.199,2690,6.266,3642,6.567]],["t/1800",[6,0.078,110,1.405,153,2.081,424,3.686,513,2.737,663,4.427,673,3.424,989,2.547,1036,4.048]],["t/1802",[6,0.078,110,1.29,212,1.579,317,2.375,374,0.517,380,3.823,398,1.156,420,2.937,435,3.063,496,3.046,592,4.244,663,3.447,815,3.462,988,1.529,989,2.723,1312,1.918,1611,2.267,1643,1.588,2061,3.129,2158,3.859,2247,2.972,2252,4.136,2354,5.928,2787,4.287,3022,2.739,3568,6.95,3610,3.635,3708,3.635,4733,5.928,5496,3.635,5610,7.219,5626,4.198,5627,4.198,5628,4.198,5629,6.45,5630,6.45,5631,6.45,5632,6.45,5633,6.45,5634,4.198,5635,4.198,5636,4.198,5637,4.198,5638,4.198,5639,4.198,5640,4.198]]],"invertedIndex":[["",{"_index":6,"t":{"3":{"position":[[52,2],[68,1]]},"9":{"position":[[143,2]]},"21":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"23":{"position":[[48,1],[60,2],[63,2],[66,3],[70,2],[73,1],[75,3],[79,2],[82,4],[87,3],[111,2],[119,4],[124,1],[126,4],[136,2],[139,2],[142,3],[146,2],[170,1],[172,5],[178,2],[181,4],[186,5],[192,3],[237,1],[239,2]]},"25":{"position":[[7,2],[10,2],[13,1],[15,3],[19,5],[25,2],[28,3],[32,2],[35,3],[39,6],[46,1],[48,3],[57,1],[59,2],[62,5],[68,3],[72,1],[74,3],[78,3],[82,3],[86,2],[89,4],[94,2],[97,4],[102,4],[107,3],[158,2],[185,3],[189,2],[192,2],[195,2],[214,4],[219,1],[221,5],[227,2],[230,3],[234,2],[237,2],[240,3],[257,2],[260,2],[263,4],[268,5],[274,2],[277,1],[279,3],[283,5],[289,3],[293,2],[318,1],[320,2],[323,5],[329,2],[332,1],[334,4],[339,2],[342,3],[359,6],[366,2],[382,1],[384,5],[394,1],[405,2],[408,4],[413,3],[417,4],[422,4],[427,6],[434,6],[446,4],[451,3],[458,4],[463,2],[510,2],[513,3],[517,4],[522,2],[525,4],[530,4],[535,2],[538,5],[544,4],[549,3],[574,2],[577,2],[587,2],[590,4],[595,2],[598,5],[604,3],[608,3],[612,4],[617,4],[622,1],[624,4],[629,2],[632,3],[636,4],[641,2],[644,1],[646,4],[651,4],[656,5],[662,3],[666,3],[670,4],[684,2],[692,3],[696,2],[699,4],[709,5],[722,4],[727,2],[730,2],[742,2],[751,4],[759,1],[761,2],[764,4],[769,4]]},"27":{"position":[[0,2],[3,1],[5,4],[10,3],[47,2],[50,5],[56,2],[59,4],[64,2],[119,3],[123,2],[140,2],[143,2],[146,2],[149,3],[153,4],[167,2],[180,3],[184,5],[190,1],[192,2],[195,5],[201,5],[228,2],[231,3],[256,1],[268,1],[270,4],[275,2],[292,1],[294,5],[320,1],[322,3],[326,3],[330,2],[333,4],[338,6],[345,3],[349,3],[353,3],[357,3],[447,3],[457,1],[469,2],[472,4],[477,2],[480,6],[487,1],[489,5],[504,1],[516,2],[519,4],[524,2]]},"31":{"position":[[13,2],[16,1],[18,4],[23,2],[26,3],[30,4],[35,3],[39,3],[43,4],[56,1],[58,2],[61,1],[63,1],[65,4],[70,2],[73,2],[76,3],[80,5],[86,2],[89,3],[93,5],[99,2],[102,3],[106,5],[112,2],[115,3],[119,4],[131,1],[133,4],[138,4],[143,1],[145,2],[148,2],[151,2],[154,4],[159,3],[163,2],[171,3],[175,4],[180,3],[184,2],[187,4],[192,4],[197,4],[214,1],[216,4],[221,4]]},"33":{"position":[[13,2],[16,3],[42,1],[64,2],[67,2],[70,5],[82,1],[84,4],[101,1],[103,3],[107,1],[109,2],[112,3],[116,3],[120,3],[131,1],[151,1],[161,1],[186,2],[189,3],[206,1],[208,6],[215,1],[217,3],[221,4],[226,2],[236,1],[238,4],[259,3],[263,3],[280,1],[282,7],[290,2],[293,3],[310,1],[312,3],[316,3],[324,2],[327,3],[331,4],[343,1],[351,1],[353,5],[359,4],[364,4]]},"35":{"position":[[13,2],[16,1],[18,2],[21,4],[38,2],[41,2],[44,7],[52,2],[55,2],[58,2],[61,1],[63,4],[68,4],[73,3],[77,2],[80,4],[85,1],[87,5],[115,4],[120,2],[123,3],[127,3],[131,4],[136,2],[139,2],[142,3],[159,2],[162,4],[176,1],[178,2],[181,1],[183,3],[187,3],[191,2],[194,2],[197,3],[201,4],[206,1],[208,2],[211,3],[215,3],[228,3],[232,2],[235,5],[241,2],[244,3],[248,3],[252,1],[254,1],[256,2],[259,3],[263,3]]},"38":{"position":[[12,1],[14,4],[19,4],[24,4],[29,3],[33,2],[36,4],[41,5],[47,2],[69,1],[71,2],[87,1],[89,4],[107,1],[115,3],[136,1],[138,5],[167,1],[181,1],[194,1],[196,2],[199,4],[204,2],[207,2],[220,1],[222,5],[228,4],[233,4],[238,3],[250,1],[252,2],[268,2],[271,2],[274,3],[278,2],[281,3],[285,3],[289,2],[305,4],[310,2],[384,1],[386,3],[390,2],[393,4],[412,1],[414,2],[417,3],[421,4],[426,4],[433,1],[438,1],[454,1],[465,1]]},"40":{"position":[[0,2],[20,1],[22,6],[29,2],[45,2],[48,4],[53,3],[57,3],[68,1],[70,2],[73,3],[90,2],[100,1],[102,2],[105,3],[109,2],[123,4],[128,2],[144,1],[146,3],[150,4],[164,1],[166,2],[169,1],[171,5],[177,5],[183,5],[189,2]]},"42":{"position":[[0,1],[2,2],[5,4],[10,4],[32,1],[43,2],[65,1],[67,4],[72,2],[75,1],[77,4],[82,1],[84,3],[88,2],[91,1],[93,2],[96,2],[99,5],[105,5],[111,2],[118,2],[121,2],[141,2],[152,3],[156,4],[161,1],[163,2]]},"44":{"position":[[0,2],[3,3],[28,1],[30,2],[33,2],[36,3],[40,3],[44,4],[49,3],[53,3],[76,1],[87,1],[89,3],[108,1],[110,2],[113,3],[117,2],[120,2],[123,2],[126,2],[129,5]]},"47":{"position":[[0,3],[4,4],[9,2],[12,4],[17,1],[19,3],[23,3],[27,4],[32,2],[35,4],[40,6],[47,3],[51,4],[56,2],[59,2],[62,4],[67,4],[87,4],[92,2],[95,3],[99,3],[103,5],[109,2],[138,2],[141,2],[144,5],[150,3],[154,4],[185,3],[189,4],[194,2],[197,2],[200,2],[203,3],[207,4],[212,3],[232,2],[235,4],[240,2],[257,1],[259,4],[264,2],[281,3],[285,2],[288,4],[293,4],[298,3],[302,1],[304,5],[310,2],[313,5],[319,2],[337,2],[340,1],[342,5],[348,2],[366,2],[369,4],[374,4],[379,2],[382,5],[388,5],[394,1],[396,3],[400,3],[425,1],[427,3],[438,1],[473,1],[475,5]]},"49":{"position":[[0,2],[3,2],[6,2],[9,5],[15,3],[40,1],[42,5],[48,2],[51,3],[55,2],[58,4],[63,2],[66,4],[71,4],[76,3],[80,4],[85,3],[89,3],[93,3],[97,3],[101,3],[105,2],[108,4],[113,2],[116,4],[121,4],[126,3],[130,3],[134,3],[142,2],[156,2],[159,3],[163,3],[172,3],[186,3],[190,1],[215,2],[236,1],[238,2],[241,3],[245,2],[252,1],[254,3],[266,1],[268,2],[271,1],[279,1],[283,2],[288,2],[293,3],[297,3],[304,3],[308,4],[316,1],[324,1],[326,4],[331,5],[337,3],[344,1],[349,1],[351,6],[358,1],[360,3],[364,2],[367,4],[372,2],[396,1],[398,5],[404,5],[410,3],[414,3],[418,1],[420,5],[426,2],[431,3],[435,4],[440,4],[455,4],[460,3],[473,2],[511,1],[513,5],[519,3],[523,3],[576,1],[578,6],[585,3],[589,2],[592,1],[594,3],[625,1],[654,1],[656,4],[661,2],[664,1],[666,3],[670,2],[673,5],[706,1],[721,1],[787,1],[802,1]]},"53":{"position":[[6,4],[18,4],[28,4],[33,3],[57,2],[60,5],[66,4],[71,5],[84,4],[89,2],[92,2],[95,3],[112,1],[114,4],[137,1],[163,1],[369,1],[377,1],[382,2],[385,1],[387,5],[393,3]]},"55":{"position":[[0,2],[3,5],[9,3],[13,2],[35,2],[55,1],[73,2],[80,3],[84,3],[97,1],[99,4],[121,1],[128,1],[130,5],[141,1],[143,4],[148,4]]},"58":{"position":[[12,1],[21,4],[30,4],[35,4],[40,4],[45,4],[50,4],[55,4],[69,4],[74,6],[81,4],[86,6],[93,5],[119,1],[121,3],[125,6],[132,2],[135,3],[139,4],[144,2],[147,3],[151,3],[155,2],[158,4],[166,2],[174,2],[177,1],[179,4],[200,1],[202,5],[221,2],[224,2],[230,3],[234,3],[238,2]]},"60":{"position":[[0,1],[2,5],[8,3],[29,1],[37,2],[45,1],[47,2],[50,5],[61,1],[63,2],[73,3],[82,3],[86,2],[89,3],[93,4]]},"63":{"position":[[20,1],[22,4],[62,5],[80,3],[84,2],[87,3],[100,1],[102,5],[108,3],[112,3],[116,3]]},"65":{"position":[[0,2],[3,5],[9,4],[24,2],[44,1],[46,2],[49,2],[72,2],[90,2],[98,1],[100,2],[103,4],[108,4]]},"68":{"position":[[15,1],[31,1],[33,6]]},"72":{"position":[[21,1],[23,2],[26,4],[31,4],[36,5]]},"74":{"position":[[0,3],[4,3],[8,2],[35,4],[40,4],[45,3],[49,5]]},"76":{"position":[[19,1],[36,2],[39,3],[43,3],[69,1],[98,2],[101,3],[105,3],[109,3],[113,5],[119,2],[122,4],[127,2],[130,3],[147,1],[149,4],[154,2],[157,3],[174,1],[176,2],[179,1],[181,4],[186,2],[189,2],[205,4],[215,5],[225,5]]},"82":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"84":{"position":[[9,2],[37,1],[39,4],[44,2],[47,3],[51,1],[53,5],[66,1],[72,3],[76,5],[94,1],[96,3],[100,3],[104,3],[113,1],[115,6],[122,2],[150,1],[152,5]]},"86":{"position":[[0,2],[3,5],[18,4],[23,1],[40,1],[42,4],[47,2],[50,3],[54,4],[59,5],[69,1],[71,2],[74,2],[77,2],[80,3],[84,6],[91,6],[102,2],[105,5],[111,4],[116,3],[120,1],[122,4],[127,3],[138,1],[140,2],[143,5],[149,3],[158,1],[160,2],[163,1],[165,4],[170,2],[173,3],[177,1],[179,2],[182,4],[187,2],[202,1],[204,2],[207,4],[212,4],[217,2],[220,3],[224,2],[227,4],[232,2],[235,3],[239,2],[242,3],[246,3],[250,2],[253,3],[257,4],[266,1],[268,4],[273,4],[290,1],[292,4],[297,2],[300,2],[303,2],[323,4],[328,2],[338,2],[341,4],[346,4],[363,1],[378,1],[389,2],[407,1],[409,4],[414,4],[419,1],[421,2],[424,2],[427,4],[432,4],[437,1],[439,3],[457,6],[464,5],[470,1],[472,3],[476,4],[481,2],[484,5],[508,1],[510,1],[512,2],[515,3],[519,4],[524,4],[559,1],[561,2],[564,3],[568,3],[572,2],[575,2],[578,4],[583,3],[587,3],[591,2],[594,3],[598,4],[603,2],[606,3],[610,6],[617,4],[622,2],[625,1],[627,3],[631,2],[634,1],[636,4],[656,1],[658,2],[667,1],[669,2],[672,1],[680,1],[682,2],[685,2],[708,2],[711,3],[715,3],[719,3],[723,3],[742,1],[744,3],[748,3],[752,2],[755,1],[757,4],[762,5],[768,4],[773,5],[791,2],[794,3],[813,1],[815,3],[819,3],[823,3],[827,3],[831,3],[835,4]]},"88":{"position":[[12,1],[14,3],[18,3],[22,5],[28,1],[30,3],[34,2],[37,2],[40,3],[44,2],[62,1],[64,4],[69,2],[72,3],[76,5],[82,4],[102,3],[106,1],[108,2],[111,3],[115,2],[118,3],[122,3],[141,1],[143,6],[176,2],[179,3],[183,2],[186,1],[188,3],[192,4],[212,1],[214,6],[225,2],[228,5],[234,5],[246,3],[261,3],[269,2],[272,3],[291,1],[293,7],[305,1],[307,6],[314,3],[318,2],[321,2],[324,6],[331,3],[335,4],[340,1],[342,3],[346,2],[349,5],[355,3],[359,5],[407,2],[422,1],[439,1],[441,3],[448,2],[455,1],[457,2],[460,3],[479,2],[482,2],[485,4],[490,4],[499,1],[516,1],[518,3],[522,3],[526,5],[532,3],[536,1],[538,5],[553,2],[556,1],[571,1],[582,1],[584,2],[587,3],[591,7],[599,4],[604,3],[608,2],[615,3],[619,3],[623,4],[628,1],[630,4],[647,1],[649,6]]},"91":{"position":[[0,2],[21,3],[41,1],[55,1],[57,4],[65,1],[67,4],[72,3],[76,3],[80,4],[85,3],[89,2],[92,5],[98,3],[102,2],[115,3],[174,1],[195,1],[206,1],[249,1],[279,1],[281,6],[305,1],[307,2],[310,3],[314,3],[322,1],[324,2],[327,1],[346,1],[348,1],[350,3],[354,3],[358,3],[371,1],[387,1],[389,3],[393,3],[397,2],[412,1],[414,4],[434,2],[449,1],[451,2],[454,5],[460,3],[478,3],[486,1],[488,6],[495,3],[507,2],[528,4],[533,1],[538,2],[545,4],[550,5],[556,1],[569,1],[571,3],[591,2],[594,4],[613,2],[630,1],[632,4],[637,4],[642,4],[647,3],[651,4],[656,1],[658,4],[663,5],[669,5],[675,2],[678,4],[683,3],[687,2],[690,4],[695,4],[700,3],[704,3],[708,5],[714,2],[717,3],[721,4],[726,3],[730,4],[735,4],[740,1],[742,5],[759,1],[761,1],[769,1],[777,1],[779,5],[801,1],[803,2],[806,3],[820,1],[842,1],[875,1],[877,1],[879,2],[902,1],[904,2],[907,2],[910,1],[929,1],[931,1],[933,3],[937,2],[944,1],[946,2],[949,4],[954,1],[972,1],[986,1],[988,3],[992,1],[1014,1],[1033,1],[1035,2],[1071,1],[1088,1],[1106,1],[1151,2],[1154,3],[1158,3],[1181,1],[1199,1],[1201,2],[1232,1],[1234,2],[1237,3],[1241,4],[1246,2],[1249,1],[1273,2],[1293,1],[1304,1],[1314,1],[1316,2],[1365,1],[1377,1],[1379,4],[1390,1],[1392,2],[1410,1],[1412,2],[1421,3],[1425,2],[1448,1],[1450,2],[1453,2],[1456,2],[1459,2],[1466,1],[1487,1],[1489,2],[1492,1],[1494,2],[1497,4],[1502,2],[1535,4],[1582,1],[1642,5],[1665,1],[1704,1],[1718,4],[1750,1],[1794,4],[1841,3],[1845,4],[1850,5],[1862,1],[1864,2],[1867,1],[1869,3],[1873,5],[1879,3],[1900,1],[1902,1],[1904,4],[1909,3],[1913,4],[1938,3],[1974,3],[1990,1],[2033,1],[2059,1],[2063,1],[2065,4],[2102,3],[2128,1],[2130,5],[2161,2],[2191,1],[2193,2],[2196,3],[2209,1],[2236,1],[2238,3],[2270,3],[2285,1],[2325,1],[2353,1],[2357,1],[2359,4],[2392,3],[2407,1],[2409,5],[2415,2],[2418,5],[2439,1],[2470,6],[2492,2],[2502,2],[2505,4]]},"93":{"position":[[4,1],[19,2],[22,4],[27,2],[30,3],[38,1],[44,4],[49,4],[54,4],[74,4],[79,5],[85,3],[94,2],[112,1],[114,3],[130,3],[134,1],[139,2],[142,4],[147,2],[150,3],[154,5],[160,2],[163,2],[166,4],[171,4],[176,3],[180,3],[184,1],[198,1],[200,4],[224,2],[246,1],[248,3],[252,1],[254,4],[271,3],[275,4],[280,2],[283,2],[286,2],[289,3],[293,4],[298,2],[301,3]]},"95":{"position":[[0,4],[17,5],[32,1],[38,1],[52,2],[55,4],[60,2],[63,4],[81,1],[83,4],[119,2],[125,1],[143,2],[146,3],[156,1],[158,5],[164,3],[168,3],[178,1],[184,4],[189,2],[192,3],[196,2],[208,1],[222,1],[224,3],[236,2],[250,2],[265,4],[270,2],[273,1],[275,3],[279,2],[282,5],[304,2],[313,2],[316,1],[326,1],[353,2]]},"97":{"position":[[0,5],[10,1],[12,1],[14,5],[33,2],[52,1],[66,2],[69,2],[72,2],[75,4],[80,5],[102,2],[107,2],[110,4],[132,1],[152,1],[154,2],[157,4],[166,1],[185,2],[201,2],[204,2],[207,4],[222,2],[225,2],[228,2],[231,2],[234,4],[239,1],[241,2],[255,1],[257,4],[262,3],[266,1],[268,1],[270,1],[298,1],[300,2],[313,2],[328,1],[349,1],[351,3],[355,2],[358,3],[374,1],[395,1],[400,2],[419,2],[422,1],[424,2],[427,3],[431,2],[434,1],[436,2],[439,3],[447,1],[449,2],[452,3],[456,3],[475,1],[477,4],[482,2]]},"99":{"position":[[20,1],[22,2],[25,5]]},"102":{"position":[[151,2],[224,2],[240,2],[243,3],[247,2],[250,3],[254,2],[257,4],[271,2],[282,1],[308,1],[348,1]]},"104":{"position":[[8,1],[28,1],[35,1],[37,5],[47,1],[49,5],[55,3],[59,5],[65,2],[68,3],[72,1],[86,4],[91,3],[95,2],[98,5],[113,1],[133,1],[143,2],[162,1],[170,2],[173,3],[177,3],[181,1],[189,1],[191,4],[196,3],[200,2],[207,6],[221,3],[225,3],[229,2],[232,3],[236,5],[262,1],[284,1],[311,3],[315,3],[326,1],[332,1],[334,2],[355,1],[357,2],[360,2],[370,3],[374,3],[378,2],[393,2],[400,1],[402,1],[404,2],[413,1],[421,3],[425,2],[428,2],[431,2],[450,1],[452,2],[493,3],[503,1],[505,3],[509,1],[514,1],[516,1],[543,1],[552,1],[554,6]]},"106":{"position":[[32,1],[48,1],[61,1],[79,1],[96,1],[160,4],[165,2],[168,1]]},"108":{"position":[[9,4],[14,3],[18,2],[21,4],[26,3],[30,2],[33,4],[53,2],[97,1],[99,2],[102,1],[104,4],[146,3],[150,4],[155,2],[158,2],[173,3],[177,3],[181,4],[186,3],[190,2],[193,2],[212,4],[217,3],[221,2]]},"110":{"position":[[9,1],[20,1],[31,4],[36,2],[39,3],[66,2],[85,3],[103,2],[106,3],[116,1],[118,3],[122,6],[129,3],[133,1],[141,2],[144,5],[150,1],[152,3],[156,1],[163,2],[166,3],[170,2],[173,2],[176,5]]},"112":{"position":[[0,2],[36,6],[53,1],[55,2],[67,1],[69,2],[72,4],[77,2],[87,2],[105,1],[107,2],[110,3],[114,2],[117,4],[122,3],[126,2],[129,5],[135,1],[147,1],[149,2],[152,6],[159,3],[163,3],[167,3],[171,1],[173,2],[191,1],[193,5],[236,1],[238,4],[252,1],[254,6],[274,1],[276,3],[280,4],[285,5],[291,2],[294,4],[299,4],[304,4],[309,4],[314,2],[317,2],[320,8],[329,4],[334,5],[340,3],[356,3],[360,2],[379,4],[384,5],[390,1],[392,5],[398,3],[402,2],[405,6],[419,2],[422,4],[427,5],[433,1],[435,3],[439,3],[443,1],[445,1],[447,3],[469,1],[471,2],[474,6],[508,1],[510,2],[531,1],[537,1],[539,1],[541,5],[547,2]]},"114":{"position":[[0,1],[27,1],[29,3],[33,2],[36,2],[39,3],[43,3],[47,2],[334,1],[336,4],[341,3],[345,3],[349,1],[351,3],[359,1],[361,5],[367,3],[375,2],[378,3],[382,2],[385,4],[397,1],[403,2],[406,2],[409,1],[411,2],[418,1],[420,4],[425,3],[429,3],[433,1],[435,3],[439,2],[442,3]]},"116":{"position":[[4,1],[6,4],[11,4],[16,2],[19,4],[24,2],[51,1],[53,5],[83,3],[87,2],[90,3],[94,3],[98,2],[101,4],[106,3],[110,3],[114,5],[120,3],[124,3],[128,2],[131,3],[135,4],[140,2],[158,2],[161,5],[179,3],[183,3],[187,3],[204,6],[224,2],[227,5],[233,1],[245,1],[259,1],[285,3],[289,2],[292,1],[303,1],[309,1],[336,1],[345,1],[354,1],[356,4],[372,1],[374,2],[377,2],[380,1],[391,1],[412,3],[427,1],[448,1],[471,1],[473,2],[476,2],[479,1],[481,3],[485,2],[488,3],[492,3],[496,3],[500,1],[502,3],[525,1],[527,2],[530,1],[538,2],[541,5],[547,1],[549,2],[552,3],[556,1],[563,1],[579,1],[581,2],[597,3],[616,2],[619,2],[622,3],[626,3],[630,2],[633,4],[638,2],[658,1],[660,4],[677,1],[679,2],[682,2],[685,2],[688,1],[709,1],[715,1],[733,1],[735,2],[738,2],[747,1],[769,3],[792,3],[796,1],[802,1],[804,2],[827,1],[829,3],[833,3],[837,2],[840,1],[855,2],[858,3],[862,3],[866,3],[870,4],[875,3],[889,2],[892,1],[894,2],[929,1],[931,3],[935,4],[940,2],[943,4],[948,3],[952,5],[958,4],[963,2]]},"118":{"position":[[9,2],[29,1],[31,2],[34,3],[43,3],[59,2],[75,1],[77,5],[104,2],[124,1],[126,2],[138,3],[151,2],[160,3],[164,2],[187,3],[194,3]]},"120":{"position":[[6,2],[9,4],[44,1],[46,4],[51,2],[54,3],[58,4],[72,2],[75,4],[80,2],[103,1],[105,2],[108,1],[110,6],[127,2],[130,1],[132,2],[135,2],[138,3],[152,2],[155,2],[182,3],[190,1],[192,3],[196,3],[200,3],[220,1],[222,1],[224,3],[252,2],[255,1],[261,1],[272,2],[275,2],[278,2],[281,2]]},"122":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"124":{"position":[[4,3],[8,2],[11,2],[14,3],[18,6],[25,3],[29,1],[31,3],[51,4],[56,2],[59,3],[63,4],[68,2],[71,2],[86,1],[88,2],[91,5],[111,1],[113,4],[118,3],[122,2],[125,3],[145,1],[147,3],[151,2],[159,2],[162,3],[194,3],[198,5],[204,3],[208,1],[210,3],[214,3],[218,3],[235,1],[248,1],[250,2],[253,3],[257,3],[261,3],[265,2],[273,1],[335,1],[354,1],[356,2],[359,1],[361,2],[369,1],[371,3],[375,3],[379,1],[381,3],[385,3],[399,1],[416,1],[418,5],[424,2],[432,1],[434,6],[441,2],[444,2],[447,2],[450,5],[456,2],[464,1],[466,2],[483,2],[486,3],[490,6],[497,2],[505,1],[507,2],[510,3],[527,1],[546,2],[549,4],[554,3],[558,3],[569,1],[571,4],[576,2],[584,1],[593,1],[595,5],[601,3],[605,3],[614,2],[617,1],[619,3],[623,4],[628,3],[632,2],[635,3],[639,4]]},"126":{"position":[[0,3],[9,1],[11,3],[15,1],[17,2],[20,2],[23,4],[28,4],[33,2],[36,2],[39,5],[45,3],[49,5],[55,2],[58,4],[75,1],[77,3],[81,1],[83,2],[86,3],[90,5],[96,2],[99,2],[102,2],[105,1],[107,2],[115,2],[118,2],[121,5],[127,6],[134,3],[138,2],[141,3],[145,3],[166,2],[169,4],[174,5],[180,5],[186,3],[190,3],[194,3],[198,3],[207,2],[210,3],[238,2],[241,3],[245,1],[247,2],[250,5],[256,2],[276,2],[305,2],[324,3],[328,2],[331,5],[337,4],[363,2],[366,4],[371,2],[374,3],[378,1],[380,3],[384,4],[406,1],[458,1],[512,1],[524,3],[528,3],[538,2],[541,2],[544,2],[547,3],[551,5],[571,1],[573,5],[579,2],[582,2],[592,1],[594,4],[599,3],[603,2],[606,4],[611,1],[627,3],[631,5],[642,2],[668,3],[672,5],[683,2],[686,3],[702,1],[704,3],[708,2],[711,3],[715,2],[718,4],[723,2],[726,2],[729,3],[733,1],[740,1],[742,5],[748,2],[751,7],[769,1],[771,3],[775,3],[779,5],[785,1],[787,1],[789,3],[793,4],[798,3],[802,1],[804,2],[807,2],[810,2],[818,1],[820,2],[851,1],[853,4],[858,3],[862,5],[868,1],[870,2],[970,3],[974,2],[977,1],[984,2],[1011,1],[1013,4],[1018,3],[1022,5],[1028,3],[1052,1],[1070,1],[1072,2],[1075,2],[1078,5],[1084,5],[1090,2],[1098,1],[1100,4],[1105,4],[1124,4],[1136,1],[1138,4],[1148,1],[1150,5],[1172,1],[1181,1],[1183,6],[1190,4],[1195,3],[1216,2],[1219,2],[1227,1],[1236,1],[1238,5]]},"128":{"position":[[0,3],[25,1],[45,1],[59,1],[61,3],[65,1],[67,3],[85,1],[87,4],[97,1],[99,3],[103,6],[110,3],[114,2],[119,2],[127,1],[129,3],[133,3]]},"130":{"position":[[0,2],[3,2],[11,1],[13,2],[16,2],[26,1],[28,4],[50,1],[102,1],[156,1],[185,1],[226,2],[229,2],[232,3],[241,1],[243,2],[246,3],[250,3],[254,3],[258,2],[261,2],[264,5],[284,1],[286,5],[292,2],[295,2],[298,3],[302,4],[307,3],[311,3],[326,1],[335,1],[355,1],[385,2],[388,2],[391,5],[397,1],[399,5],[424,1],[426,5],[449,1],[458,1],[460,3],[464,3],[468,4],[473,5],[511,1],[532,1],[534,4],[539,3],[543,3],[558,2],[561,3],[565,2],[568,1],[570,3],[574,1],[576,2],[586,1],[686,1],[688,2],[693,2],[711,1],[713,3],[717,1],[719,2],[738,1],[740,2],[743,4],[748,4],[753,3],[757,4],[762,4],[767,3],[771,3],[775,1],[777,3],[803,2],[806,3],[810,3],[814,3],[818,2],[835,1],[837,4],[850,1],[852,2],[855,2],[858,5],[864,4],[869,3],[873,3],[877,4],[882,4],[887,3],[899,1],[901,4],[906,3],[910,3],[914,3],[918,4],[923,4],[928,3],[932,2],[935,3],[939,2],[942,4],[947,4],[952,2],[955,3],[959,5],[965,2],[976,1],[978,4],[983,1],[993,1],[995,4],[1000,4],[1005,2],[1008,5],[1014,2],[1017,3],[1021,4],[1026,4],[1031,3],[1035,3],[1059,3],[1063,2],[1066,5],[1072,4],[1077,4],[1082,3],[1086,3],[1090,4],[1104,1],[1106,2],[1118,1],[1120,4],[1345,1],[1347,3],[1351,1],[1370,3],[1389,3],[1393,2],[1396,2],[1399,2],[1402,3],[1406,3],[1410,3],[1414,1],[1416,4],[1421,4],[1426,2],[1429,3],[1433,3],[1437,4],[1442,2],[1445,2],[1457,1],[1459,3],[1463,2],[1466,3],[1470,2],[1473,3],[1477,3],[1481,2],[1484,2],[1505,2],[1508,2],[1537,1],[1539,4],[1544,3],[1556,1],[1569,1],[1571,2],[1574,2],[1577,1],[1579,2],[1587,1],[1589,2],[1592,3],[1596,2],[1610,1],[1612,4]]},"132":{"position":[[0,3],[4,3],[20,1],[38,1],[40,4],[45,3],[49,2],[52,5],[58,5],[64,3],[82,1],[101,1],[103,2],[122,5],[128,5],[148,1],[150,2],[153,2],[156,1],[180,2],[183,2],[186,3],[211,1],[233,2],[236,3],[240,4],[245,2],[248,2],[280,2],[283,4],[288,3],[292,3],[296,5],[302,2],[305,3],[309,4],[335,1],[337,4],[342,2],[345,2],[360,1],[362,2],[365,2],[368,2],[371,5],[377,5],[383,2],[386,4],[391,7],[399,6],[406,2],[431,2],[434,4],[452,1],[454,5],[460,4],[465,2],[468,3],[472,3],[488,1],[490,4],[495,3],[499,2],[507,1],[509,3],[520,1],[522,5],[528,3],[532,2],[535,3],[546,1],[548,3],[559,1],[561,3],[565,4],[570,6],[593,3],[597,4],[602,4],[607,3],[618,2],[621,3],[638,1],[640,5],[646,5],[652,2],[655,3],[666,1],[668,4],[673,6],[680,4],[685,3],[689,4],[694,4],[699,3],[703,2],[706,3],[710,4],[715,2],[718,3],[722,4],[727,3],[742,1],[744,5],[750,4],[903,1],[921,1],[927,1],[929,3],[933,3],[937,2],[945,5],[951,3],[959,1],[961,2],[964,3],[975,3],[988,1],[992,2],[995,4],[1005,1],[1007,4],[1012,3],[1016,3]]},"134":{"position":[[0,1],[7,1],[24,2],[27,2],[30,4],[35,4],[40,1],[42,2],[45,4],[55,1],[57,4],[62,4],[67,3],[71,3],[75,1],[77,3]]},"136":{"position":[[0,2],[3,2],[11,2],[14,3],[39,3],[51,1],[53,2],[56,1],[58,4],[63,2],[66,2],[77,3],[86,4],[91,2],[94,3],[98,2],[101,1],[103,3],[107,1],[109,3],[113,5],[119,2],[122,6],[148,1],[150,3],[154,4],[159,2],[162,2],[165,4],[170,5],[176,1],[178,2],[181,4],[186,3],[190,1],[192,3]]},"138":{"position":[[0,1],[2,5],[8,2],[16,1],[18,2],[32,1],[34,2],[37,4],[42,6],[49,1],[56,1],[58,3],[81,1],[83,5],[89,3],[93,4],[113,3],[117,5],[123,1],[125,3],[129,1],[136,1],[138,2],[146,1],[157,1],[159,3],[163,1],[165,3],[169,2],[183,1],[194,1],[196,3],[210,1],[212,3],[216,1],[218,3],[234,1],[238,2],[241,2],[244,1],[246,3],[250,5],[256,1],[258,4],[282,1],[284,4],[289,4],[294,2],[310,3],[314,5],[332,1],[347,1],[349,1],[356,1],[358,2],[361,2],[364,2],[377,1],[379,4],[384,3],[388,2],[391,4],[396,5],[402,3],[406,1],[408,2],[411,3],[420,1],[422,4],[434,3],[438,5],[449,3],[453,6],[460,3],[464,2],[472,1],[474,2],[477,4],[492,1],[494,5],[509,1],[521,1],[523,5],[529,2],[537,1],[539,2],[549,1],[551,2],[554,3],[558,5]]},"140":{"position":[[0,3],[4,2],[7,3],[11,2],[14,1],[23,1],[25,3],[29,3],[44,3],[97,1],[99,3],[103,3],[107,6],[131,1],[133,4],[138,3],[154,1],[156,2],[159,2],[162,2],[165,2],[168,5],[174,3],[178,5],[184,1],[191,1],[193,2],[196,3],[200,4],[205,1],[207,3],[211,2],[214,2],[222,1],[224,2],[227,4],[232,4],[237,2],[240,2],[263,1],[265,3],[269,2],[272,2],[275,5],[281,3],[303,4],[308,2],[311,1],[318,1],[320,5],[326,1],[333,1],[335,2],[338,4],[343,2],[346,3],[350,3],[354,3],[358,3],[377,1],[379,3],[383,4],[390,1],[392,3],[402,1],[404,4],[409,2],[412,3],[416,3],[420,3],[424,3],[428,2],[431,3],[448,2],[464,1],[466,4],[493,1],[495,1],[505,1],[507,4],[512,2],[515,3],[530,1],[532,3],[547,1],[549,5],[555,3],[559,4],[564,4],[569,3],[595,1],[597,2],[600,4],[605,2],[608,1],[610,3],[614,4],[619,3],[623,3],[645,1],[647,5],[658,1],[660,4],[665,3],[688,1],[690,2],[693,2],[696,4],[701,5],[707,4],[731,1],[742,1],[744,3],[748,2],[751,3],[755,5],[774,2],[788,1],[790,3],[809,1],[811,2],[819,1],[821,4]]},"143":{"position":[[5,3],[9,4],[17,3],[21,4],[26,4],[52,2],[55,3],[59,2],[62,1],[64,6],[80,1],[82,5],[88,2],[91,5],[97,4],[122,1],[124,2],[155,1],[157,2],[195,1],[197,2],[210,3],[227,1],[229,5],[235,2],[238,2],[249,1],[251,3],[290,1],[328,5],[334,1],[336,3],[340,1],[347,5],[353,3],[357,3],[361,4],[366,3],[388,2],[408,1],[410,3],[436,1],[438,5],[449,1],[451,5],[457,3],[466,1],[468,1],[470,3],[474,2],[477,3],[481,3],[485,2],[493,3],[497,2],[504,3],[508,2],[511,3],[531,1],[569,1],[619,1],[643,2],[646,3],[650,3],[658,3],[670,3],[674,3],[687,1],[700,1],[710,2],[723,3]]},"145":{"position":[[8,1],[10,2],[13,2],[16,1],[40,1],[42,5],[48,2],[51,1],[65,3],[69,4],[74,3],[78,4],[83,2],[94,3],[98,2],[101,3],[105,3],[109,2],[112,4],[117,2],[120,5],[126,3],[130,2],[133,3],[137,4],[142,2],[145,2],[148,2],[151,3],[155,3],[159,2],[178,1],[180,5]]},"147":{"position":[[8,1],[10,2],[13,3],[21,1],[23,5],[29,4],[34,2],[37,1],[39,2],[42,3],[46,5],[52,5],[58,3],[62,4],[67,4],[72,2],[75,5],[81,2],[84,5],[90,6],[97,1],[99,3],[103,5],[109,4],[114,2],[124,1],[126,3],[144,1],[146,5],[152,1],[154,2],[161,4],[166,4],[171,4],[176,5],[186,3],[190,3],[194,2],[197,5],[203,2],[206,5],[212,3],[220,3],[224,3],[228,2],[231,3],[235,4],[240,3],[244,2],[247,2],[250,3],[254,1],[261,4],[270,3],[274,5],[280,2],[283,3],[287,3],[291,2],[294,2],[297,2],[300,5],[306,2],[309,2],[312,4],[324,1],[342,1],[344,4],[349,4],[369,3],[373,3],[377,3],[381,1],[383,4],[388,2],[391,4],[411,1],[413,4],[418,1],[420,4],[425,5],[439,3],[443,2],[446,6],[460,1],[462,3],[466,7],[484,3],[488,1],[490,6],[497,1],[499,3],[503,4]]},"149":{"position":[[0,3],[20,1],[22,4],[27,4],[46,2],[49,2],[52,1],[54,5],[60,2],[63,3],[67,1],[76,2],[103,1],[105,2],[108,4],[113,2],[116,3],[120,1],[129,2],[155,1],[157,2],[160,5],[166,1],[175,1],[177,3],[194,1],[196,1],[198,1],[200,3],[204,5],[210,2],[213,3],[222,1],[224,5],[230,2],[233,1],[254,3],[258,1],[265,2],[268,3],[272,3],[276,3],[280,3],[284,4],[289,4],[294,3],[298,1],[305,3],[309,4],[314,3],[337,2],[340,3],[344,2],[347,2],[350,3],[354,4],[359,2],[362,3],[366,5],[372,2],[375,2],[378,2],[381,3],[385,2],[388,2],[407,1],[409,5],[415,1],[417,1],[419,4],[424,6],[434,1],[436,1],[438,3],[442,3],[446,7],[458,2],[463,5],[469,3],[477,1],[479,4],[484,2],[487,2],[490,3],[494,3],[505,4],[510,2],[513,3],[517,3],[521,2],[524,3],[528,3],[541,3],[545,3],[549,5],[555,5]]},"151":{"position":[[58,1],[79,2],[110,1],[128,1],[130,5],[136,3],[147,1],[149,2],[152,1],[154,2],[157,3],[166,1],[168,4],[180,3],[184,3]]},"153":{"position":[[17,1],[19,2],[46,1],[61,1],[63,2],[66,3],[97,1],[104,1],[106,5],[125,1],[132,1],[134,2],[150,1],[176,1],[183,1],[185,4],[194,2],[221,2],[224,4],[234,1],[236,2],[239,3],[243,5],[249,7],[257,4],[262,1],[278,4],[283,2],[286,3],[295,1],[297,4],[302,2],[305,4],[310,3],[314,3],[318,3],[322,3],[326,3],[330,3],[344,1],[359,1],[361,4],[379,1],[390,1],[392,4],[397,3],[401,5],[417,1],[419,1],[421,2],[424,2],[427,1],[429,1],[431,3],[435,3],[439,1],[441,4],[446,3],[463,1],[465,3],[474,2],[477,3],[481,5],[487,2],[502,1],[504,3],[518,5],[524,4],[539,5],[545,2],[559,1],[561,3],[565,3],[569,5],[575,1],[577,4],[599,1],[601,1],[603,1],[605,5],[616,1],[618,3],[634,3],[652,1],[654,5],[660,1],[662,3],[686,1],[688,2],[691,3],[695,4],[700,3],[704,2],[707,6],[714,2],[730,1],[732,2],[735,2],[738,3],[757,1],[759,4],[764,3]]},"155":{"position":[[0,1],[2,3],[8,1],[10,3],[14,2],[17,5],[23,2],[26,6],[33,1],[35,3],[39,3],[43,2],[46,3],[62,1],[64,2],[67,3],[89,4],[94,3],[98,4],[103,1],[126,3],[130,1],[137,1],[139,3],[158,1],[160,4],[186,1],[188,2],[193,2],[201,1],[203,2],[206,3],[227,2],[235,1],[237,2],[240,5],[260,1],[262,2],[265,2],[268,5],[274,3],[278,3],[282,3],[286,1],[288,4],[298,1],[300,2],[303,3],[307,3],[311,3],[315,2],[318,4],[323,3],[327,4],[332,2],[335,4],[340,2],[348,1],[350,2],[366,1],[368,4],[373,2],[376,2],[379,4],[384,4],[389,2],[392,4],[397,3],[406,1],[408,3],[412,1],[414,4],[419,3],[423,3],[427,4],[432,2],[435,2],[438,2],[441,3],[445,5],[451,1],[453,4],[477,3],[481,3],[495,1],[497,2],[524,1],[526,2],[529,5],[535,3],[539,4],[544,3],[548,2],[551,3],[555,3],[559,2],[562,3],[578,1],[580,3],[584,2],[587,5],[593,3],[597,1],[599,3],[610,1],[612,1],[619,1],[621,4],[626,3],[645,1],[647,3],[651,2],[661,2],[664,1],[666,1],[668,3],[682,2],[702,1],[726,2],[736,3],[740,5],[746,4],[758,3],[762,2],[765,1],[767,3],[771,3],[775,2],[778,3],[782,4],[787,1],[789,3],[793,2],[807,3],[811,5],[817,3],[843,1],[845,5],[867,1],[869,2],[872,2],[885,3],[889,3],[903,2],[906,3],[910,1],[912,4],[917,3],[921,2],[929,1],[953,1],[955,2],[972,3],[976,5],[982,2],[985,1],[987,1],[989,3],[993,6],[1024,1],[1026,5],[1042,3],[1046,1],[1055,1],[1057,5],[1063,2],[1066,3],[1070,1],[1072,3],[1081,1],[1083,5],[1089,5]]},"157":{"position":[[0,2],[3,5],[9,4],[14,4],[19,3],[23,3],[27,3],[31,4],[36,3],[100,1],[119,1],[121,2],[124,1],[126,2],[129,1],[136,1],[138,2],[146,7],[154,3],[158,4],[163,2],[177,3],[181,3],[185,5],[200,2],[225,3],[229,2],[232,3],[236,1],[238,3],[242,4],[247,5],[253,3],[257,2],[260,4],[265,5],[271,5],[299,1],[320,1],[322,2],[325,3],[329,3],[345,2],[348,5],[354,1],[361,2],[375,3],[389,1],[391,3],[395,3],[399,5],[405,2],[416,2],[419,3],[423,1],[425,2],[436,1],[438,5],[444,3],[448,4],[453,3],[457,3],[461,3],[465,3],[469,3],[473,5],[479,4],[484,2],[487,4],[492,4],[497,2],[500,5],[506,2],[509,3],[524,3],[528,2],[531,3],[535,3],[539,5]]},"159":{"position":[[0,1],[2,5],[34,1],[48,2],[51,3],[73,1],[75,4],[80,3],[84,4],[101,1],[103,3],[107,2],[110,4],[115,2],[118,2],[121,3],[125,6],[132,5],[138,2],[141,4],[146,1],[162,1],[169,2],[172,5],[178,3],[206,1],[208,2],[211,4],[216,2],[219,5],[225,4],[230,3],[234,3],[238,1],[240,3],[264,1],[266,2],[269,3],[273,2],[276,3],[280,2],[283,1],[285,1],[287,3],[291,5],[297,1],[299,4],[304,3],[308,4],[313,2],[316,5],[322,2],[325,4],[330,3],[334,1],[336,5],[342,2],[345,3],[349,3],[353,3],[357,4],[367,1],[369,1],[371,5],[377,4],[382,2],[385,1],[387,1],[389,7],[415,1],[417,2],[432,2],[435,1],[437,1],[439,2],[442,4],[447,4],[452,1],[454,4],[459,3],[463,3],[467,2],[470,2],[473,1],[475,3],[479,4],[484,2],[487,3],[491,4],[511,4],[516,4],[521,3],[525,4],[530,2],[533,2],[536,3],[540,5],[546,2],[549,1],[551,3],[555,4],[560,5],[566,1],[568,2],[571,3],[575,4],[580,3],[612,3],[616,3],[620,5],[626,1],[628,5],[634,2],[637,2],[640,3],[644,3],[648,2],[651,2],[654,3],[658,5],[664,3],[668,2],[671,3],[675,3],[679,4],[684,2],[687,4],[692,3],[696,3],[700,5],[706,2],[709,4],[727,1],[729,3],[740,1],[742,4],[747,5],[753,3],[757,1],[759,3],[763,3],[767,3],[771,3],[775,1],[777,2],[789,1],[791,2],[808,2],[811,5],[839,2],[842,3],[846,3],[850,3],[854,1],[856,3],[860,2],[863,6],[870,2],[873,4],[878,3],[882,1],[884,2],[887,3],[891,4],[896,1],[903,2],[906,3],[910,3],[914,6],[921,4],[926,2],[929,1],[931,3],[935,6],[942,3],[946,3],[955,2],[958,4],[963,3],[967,6],[974,2],[977,2],[980,4],[985,5],[991,2],[994,3],[998,3],[1002,1],[1004,3],[1008,2],[1011,3]]},"161":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"163":{"position":[[0,1],[2,4],[43,1],[45,2],[64,1],[74,1],[76,5],[82,3],[86,2],[114,1],[174,1],[176,2],[185,2],[188,3],[192,2],[195,2],[198,4],[203,3],[207,2],[210,4],[215,2],[223,1],[225,4],[230,4],[235,2],[238,5],[244,3],[248,1],[250,2],[253,3],[257,3],[261,4],[266,4],[271,3],[300,1],[302,3],[306,2],[309,2],[312,1],[333,2],[336,6],[356,1],[358,5],[364,3],[368,4],[373,5],[379,3],[383,4],[388,2],[391,3],[395,2],[398,1],[400,3],[404,2],[407,2],[416,1],[437,2],[440,3],[444,4],[449,4],[454,4],[459,4],[479,1],[481,3],[485,4],[490,1],[492,2],[495,3],[499,2],[502,2],[505,4],[510,3],[514,3],[518,3],[522,2],[525,2],[528,3],[532,2],[535,2],[538,6],[545,2],[548,3],[552,3],[556,3],[560,1],[562,2],[565,3],[569,2],[572,1],[574,2],[585,1],[587,4],[724,1],[728,2],[764,1],[766,4],[774,2],[797,3],[801,1],[806,2],[809,3],[813,5],[819,2],[822,3],[826,3],[830,5]]},"165":{"position":[[0,1],[2,5],[8,2],[11,4],[16,4],[21,3],[40,1],[42,2],[45,5],[51,2],[54,4],[64,1],[106,1],[112,1],[119,1],[121,2],[135,1],[137,2],[140,3],[144,3],[148,3],[152,2],[155,4],[160,2],[163,4],[168,3],[172,3],[176,3],[293,1],[295,5],[301,2],[313,1],[315,2],[318,2],[321,3],[325,3],[329,3],[333,2],[336,2],[359,2],[362,2],[370,1],[372,2],[375,2],[378,3],[382,5],[515,1],[517,5],[523,1],[525,2],[528,3],[532,1],[534,2],[558,1],[560,4],[565,3],[569,3],[573,3],[639,1],[641,1],[643,2],[646,5],[652,3],[689,1],[691,4],[696,2],[699,5],[705,3],[709,3],[713,4],[718,3],[722,3],[726,3],[730,2],[739,1],[741,2],[744,3],[757,1],[759,5],[765,3],[769,4],[774,2],[797,2],[800,4],[805,3],[809,4],[834,2],[847,1],[849,3],[853,2],[856,3],[860,4],[865,5],[871,2],[881,2],[884,4],[889,6],[896,2],[899,3],[903,2],[906,3],[910,4],[915,1],[917,4],[922,3],[926,2],[929,2],[937,1],[946,2],[959,3],[963,4],[968,2],[971,4],[976,2],[979,5],[985,2],[988,2],[991,2],[999,2],[1002,2],[1005,3],[1009,4],[1014,5],[1020,2],[1023,3],[1038,1],[1040,3],[1044,4],[1065,1],[1067,3],[1090,1],[1092,2],[1095,2],[1098,5],[1104,4],[1109,4],[1114,2],[1117,2],[1120,2],[1123,3],[1145,1],[1147,4],[1152,4],[1157,2],[1160,3],[1164,4],[1169,6],[1176,2],[1205,1],[1207,2],[1218,1],[1220,2],[1223,2],[1226,3],[1230,2],[1233,2],[1236,3],[1240,3],[1244,2],[1247,2],[1250,2],[1279,1],[1281,1],[1283,2],[1286,3],[1290,1],[1292,2],[1295,2],[1298,3],[1302,3],[1306,1],[1308,4],[1313,1],[1315,3],[1319,2],[1322,4],[1335,1],[1337,2],[1340,2],[1346,3],[1370,2],[1379,1],[1394,1],[1396,2],[1401,2],[1404,4],[1409,3],[1428,1],[1516,1],[1565,1],[1585,2],[1588,3],[1592,1],[1600,1],[1602,4],[1607,2],[1610,3],[1629,2],[1632,3],[1658,1],[1660,2],[1663,3],[1674,1],[1676,3],[1680,2],[1685,2],[1705,1],[1707,2],[1710,3],[1730,2],[1733,3],[1737,2],[1750,3],[1754,2],[1766,1],[1768,2],[1771,1],[1773,3],[1789,1],[1791,5],[1804,1],[1806,4],[1811,3],[1815,3],[1828,1],[1830,4],[1835,2],[1838,1],[1840,2],[1843,3],[1847,2],[1850,3],[1872,1],[1874,3],[1878,2],[1881,3],[1885,2],[1911,1],[1938,1],[1940,3],[1969,1],[1971,2],[1994,1],[1996,2],[1999,4],[2004,2],[2007,3],[2011,3],[2032,1],[2034,2],[2037,3],[2041,2],[2044,2],[2047,1],[2049,4],[2054,2],[2057,2],[2060,3],[2064,4],[2069,2],[2081,2],[2084,3],[2088,2],[2091,2],[2094,4],[2099,5],[2105,3],[2127,3],[2131,4],[2136,2],[2139,3],[2143,2],[2158,3],[2178,1],[2197,1],[2199,2],[2202,3],[2206,1],[2216,1],[2218,2],[2223,2],[2245,1],[2247,2],[2250,3],[2261,1],[2263,4],[2268,2],[2290,3],[2294,4],[2306,1],[2308,4],[2313,1],[2315,2],[2318,5],[2324,5],[2330,5],[2336,3],[2340,3],[2355,1],[2357,4],[2362,2],[2365,2],[2373,1],[2382,1],[2384,4],[2389,4],[2394,3],[2398,1],[2400,3],[2404,3],[2408,3],[2412,2],[2415,5],[2429,1],[2431,3],[2440,1],[2442,3],[2446,4],[2451,3],[2479,1],[2481,4],[2486,3],[2490,2],[2493,5],[2502,3],[2538,1],[2540,3],[2544,1],[2546,3],[2550,2],[2553,2],[2559,3],[2563,6],[2570,3],[2574,3],[2578,5],[2584,3],[2588,3],[2592,3],[2596,2],[2599,5],[2635,1],[2637,2],[2640,3],[2670,1],[2672,5],[2678,3],[2697,1],[2709,1],[2711,3],[2715,2],[2718,3],[2722,2],[2725,3],[2729,2],[2732,5],[2738,3],[2742,2],[2753,1],[2755,2],[2763,3],[2767,4],[2772,4],[2777,2],[2780,2],[2789,1],[2799,1],[2801,3],[2805,1],[2807,3],[2811,3],[2831,1],[2836,3],[2866,1],[2871,2],[2874,5],[2880,2],[2883,3],[2887,2],[2890,2]]},"168":{"position":[[13,2],[16,3],[20,2],[23,3],[53,1],[57,3],[67,1],[69,5],[126,1],[132,1],[149,1],[158,1],[160,4],[165,2],[174,1],[176,2],[188,1],[190,4],[204,1],[212,1],[225,1],[234,1],[236,4],[241,2],[244,3],[259,3],[267,1],[273,1],[275,1],[277,4],[282,3],[297,1],[306,1],[308,4],[313,4],[318,3],[322,3],[326,5],[332,1],[340,1],[349,1],[351,2],[354,3],[358,2],[361,2],[364,3],[368,3],[372,3],[376,1],[378,3],[382,2],[411,1],[427,2],[430,3],[452,2],[455,5],[461,3],[465,2],[468,2],[471,2],[474,5],[480,2],[483,6],[490,5],[496,2],[499,4],[504,3],[508,1],[510,3],[522,1],[524,2],[527,1],[529,3],[533,2],[536,5],[542,5]]},"170":{"position":[[0,3],[29,1],[31,3],[35,3],[46,3],[50,3],[54,3],[58,4],[63,2],[66,5],[72,2],[75,1],[77,4],[82,3],[97,1],[99,2],[102,2],[105,3],[109,5],[115,4],[127,1],[129,4],[134,2],[154,1],[180,1],[182,5],[188,5],[216,1],[218,3],[222,2],[225,6],[232,3],[248,1],[250,2],[253,4],[258,5],[269,1],[271,3],[275,4],[297,2],[300,1],[314,1],[316,2],[319,3],[323,1],[325,3],[329,2],[348,1],[374,2],[377,2],[380,4],[409,1],[411,5],[417,3],[421,2],[428,1],[494,1],[496,5],[526,1],[528,4],[553,3],[557,4],[581,1],[583,3],[587,4],[592,3],[596,4],[626,1],[684,1],[686,5],[692,6],[699,4],[704,6],[711,2],[714,2],[717,4],[722,3],[734,2],[737,2],[740,2],[743,2],[746,4],[751,4],[756,3],[760,1],[762,4],[796,1],[798,3],[802,4],[807,5],[813,1],[815,3],[819,3],[823,4],[828,3],[845,3],[849,3],[861,1],[863,3],[867,4],[872,4],[887,3],[891,5],[897,3],[901,3],[918,1],[920,1],[936,3],[942,3],[946,1],[948,3],[954,3],[958,3],[975,1],[977,3],[981,1],[983,3],[987,4],[1073,1],[1075,5],[1165,1],[1167,4],[1172,1],[1174,3],[1178,4],[1266,3],[1270,2],[1273,3],[1277,4],[1282,2],[1285,3],[1289,3],[1293,3],[1314,1],[1316,2],[1319,2],[1322,3],[1326,3],[1330,5],[1336,5],[1342,3],[1346,2],[1355,1],[1357,2],[1383,2],[1386,6],[1393,1],[1395,2],[1398,5],[1404,6],[1467,1],[1486,2],[1497,3],[1514,1],[1544,3],[1548,3],[1552,2],[1555,3],[1559,5],[1565,2],[1568,2],[1571,3],[1575,3],[1579,3],[1583,2],[1586,3],[1590,5],[1596,2],[1599,2],[1602,3],[1611,2],[1614,3],[1618,3],[1622,2],[1625,3],[1653,1],[1655,3],[1659,2],[1662,3],[1666,5],[1672,2],[1675,4],[1680,3],[1702,3],[1706,4],[1711,2],[1714,1],[1716,2],[1734,3],[1738,3],[1742,1],[1744,3],[1748,5],[1754,2],[1757,2],[1774,1],[1776,3],[1780,2],[1783,3],[1787,5],[1793,2],[1796,2],[1799,3],[1808,2],[1811,3],[1815,3],[1819,4],[1829,1],[1831,3],[1835,2],[1838,3],[1842,5],[1848,2],[1851,4],[1877,3],[1881,4],[1886,2],[1889,1],[1891,2],[1894,2],[1904,2],[1907,3],[1911,3],[1915,2],[1918,4],[1923,3],[1927,1],[1929,3],[2038,1],[2046,2],[2097,1],[2127,2],[2160,1],[2188,2],[2272,2],[2275,1]]},"172":{"position":[[7,3],[11,4],[16,3],[20,3],[24,3],[28,2],[81,1],[83,5],[127,1],[129,4],[149,1],[151,2],[171,1],[173,5],[179,2],[198,1],[213,2],[216,3],[220,4],[245,1],[247,5],[253,6],[260,3],[264,3],[268,3],[272,4],[325,1],[327,5],[333,3],[363,1],[365,2],[377,1],[379,5],[385,2],[395,2],[398,3],[402,3],[406,2],[409,4],[414,3],[418,1],[420,3],[517,1],[546,2],[554,1],[560,1],[571,1],[578,1],[584,1],[594,2],[691,3],[695,2],[700,2],[732,1],[736,2],[739,2],[753,1],[755,4],[765,1],[767,3],[791,1],[793,2],[796,1],[798,6]]},"174":{"position":[[0,4],[12,1],[37,1],[39,3],[43,2],[46,3],[50,3],[54,3],[58,2],[67,1],[69,2],[87,1],[98,1],[100,4],[105,4],[118,1],[136,2],[139,3],[159,5],[165,4],[170,3],[189,3],[193,5],[219,1],[262,1],[270,2],[273,5],[279,4],[322,1],[324,5],[330,2],[333,2],[336,4],[341,2],[344,3],[348,3],[352,1],[354,4],[359,2],[380,1],[382,2],[385,3],[406,1],[408,6],[415,3],[435,1],[437,1],[439,4],[444,5],[476,1],[486,1],[488,2],[491,5],[497,2],[500,2],[503,3],[507,2],[514,2],[517,4],[539,1],[541,4],[554,1],[562,2],[565,5],[591,1],[593,3],[618,2],[629,1],[633,2],[653,1],[657,2],[675,1],[683,2],[686,5],[692,2],[695,5],[716,1],[744,2],[747,3],[751,3],[755,3],[759,1],[761,3],[765,1],[767,3],[777,2],[780,3],[784,5],[790,3],[794,2],[797,5],[803,4],[808,3],[812,2],[849,1],[851,2],[854,2],[857,2],[860,5],[866,4],[887,2],[890,3],[922,1],[932,2],[957,1],[959,2],[962,3],[970,1],[972,4],[977,3],[981,1],[983,2],[986,1],[988,1],[990,4],[995,2],[998,3],[1002,2],[1005,5],[1011,2],[1014,3],[1018,2],[1021,3],[1025,2],[1028,5],[1034,3],[1038,2],[1041,3],[1045,2],[1048,4],[1053,1],[1055,2],[1058,3],[1062,4],[1067,1],[1069,2],[1072,2],[1075,4],[1080,4],[1085,5],[1112,1],[1114,5],[1135,1],[1137,5],[1166,1],[1168,4],[1173,3],[1251,1],[1253,3],[1257,1],[1259,3],[1271,1],[1273,1],[1275,5],[1281,4],[1307,1],[1309,2],[1312,2],[1332,3],[1336,5],[1342,6],[1363,1],[1365,3],[1375,1],[1383,1],[1385,5],[1391,3],[1410,1],[1412,2],[1415,3],[1419,3],[1433,1],[1439,1],[1441,2],[1444,3],[1448,5],[1454,2],[1457,5],[1463,5],[1469,1],[1471,4],[1476,2],[1479,4],[1484,3],[1492,2],[1495,4],[1519,1],[1521,6],[1528,2],[1541,1],[1550,1],[1552,3],[1556,4],[1561,3],[1565,4],[1570,2],[1573,5],[1579,4],[1584,3],[1588,5],[1611,1],[1613,2],[1616,3],[1630,3],[1634,3],[1638,4],[1643,3],[1647,1],[1649,4],[1654,3],[1658,6],[1678,2],[1710,1],[1712,5],[1740,1],[1742,2],[1745,1],[1761,1],[1773,1],[1831,1],[1833,5],[1839,3],[1861,1],[1887,1],[1889,2],[1910,1],[1921,3],[1925,2],[1957,1],[1959,4],[1993,1],[1995,4],[2000,4],[2077,1],[2085,2],[2115,1],[2131,4],[2144,1],[2164,2],[2167,2],[2209,1],[2341,6],[2364,2],[2367,2],[2374,1],[2376,2],[2388,1],[2390,3],[2394,3],[2398,3],[2402,2],[2405,3],[2409,3],[2413,1],[2415,3],[2419,3],[2433,1],[2465,1],[2467,5],[2473,2],[2476,3],[2480,4],[2485,2],[2488,4],[2504,1],[2516,1],[2518,1],[2520,3],[2524,3],[2528,3],[2532,3],[2548,1],[2550,3],[2578,1],[2596,2],[2599,6],[2606,3],[2610,5],[2616,1],[2618,3],[2622,3],[2626,2],[2629,2],[2638,1],[2640,3],[2663,1],[2665,2],[2668,3],[2672,5],[2678,4],[2683,5],[2695,1],[2697,3],[2701,3]]},"177":{"position":[[0,2],[3,2],[6,5],[12,1],[14,3],[18,5],[63,1],[65,3],[69,2],[72,4],[77,3],[81,5],[87,2],[107,5],[123,1],[144,1],[163,1],[165,2],[168,4],[184,1],[186,4],[191,3],[203,2],[206,3],[227,1],[229,5],[235,1],[251,1],[253,3],[257,3],[319,1],[343,1],[362,1],[483,3],[505,1],[507,4],[527,1],[529,5],[543,1],[556,3],[560,2],[568,1],[588,1],[599,1],[601,2],[604,7],[612,4],[617,4],[639,1],[641,5],[657,1],[670,1],[672,2],[675,4],[694,1],[701,3],[705,3],[709,1],[711,3],[715,1],[717,3],[721,4],[734,1],[781,1],[787,1],[789,3],[793,3],[797,1],[799,1],[801,3],[856,1],[880,1],[899,1],[992,3],[1029,1],[1031,5],[1037,2],[1052,5],[1066,1],[1079,3],[1083,2],[1086,5],[1092,4],[1097,3],[1101,1],[1103,4],[1108,5],[1132,2],[1135,3],[1139,3],[1143,2],[1146,2],[1149,4],[1154,3],[1170,5],[1176,2],[1179,4],[1184,4],[1189,4],[1194,2],[1197,2],[1200,3],[1260,1],[1306,1],[1332,1],[1334,4],[1347,1],[1349,2],[1377,1],[1379,4],[1384,2],[1387,4],[1407,1],[1409,4],[1414,6],[1479,1],[1503,1],[1522,1],[1542,1]]},"179":{"position":[[22,1],[24,3],[36,1],[38,4],[54,1],[65,1],[67,4],[72,2],[75,3],[79,6],[86,1],[88,3],[92,2],[95,3],[99,3],[103,4],[108,6],[115,2],[118,4],[123,3],[146,2],[149,4],[154,3],[176,1],[196,1],[198,3],[202,3],[213,1],[215,2],[218,2],[221,2],[224,3],[228,2],[231,3],[235,2],[238,4],[243,5],[249,4],[254,3],[258,3],[262,3],[266,3],[270,2],[273,4],[278,2],[281,3],[285,3],[289,1],[291,3],[295,5],[301,3],[305,5],[311,4],[316,4],[321,3]]},"182":{"position":[[0,1],[2,3],[6,1],[8,3],[12,2],[15,2],[44,1],[55,1],[72,1],[74,5],[80,2],[88,1],[103,1],[105,4],[110,5],[121,2],[124,2],[127,4],[132,5],[138,3],[142,2],[145,4],[150,2],[153,4],[186,5],[197,3],[201,2],[220,1],[238,1],[240,5],[261,1],[267,1],[331,1],[333,2],[354,2]]},"185":{"position":[[8,1],[35,1],[65,2],[90,1],[117,2],[120,2]]},"187":{"position":[[4,1],[10,1],[30,1],[41,1],[43,5],[53,1],[59,5],[79,1],[100,1],[102,5]]},"189":{"position":[[0,1],[2,2],[17,5],[53,1],[62,1],[69,1],[75,1],[77,5],[83,1],[85,6],[156,1],[172,1],[174,6],[181,2],[198,1],[204,2],[207,3],[211,1],[213,4],[218,5]]},"191":{"position":[[4,1],[17,1],[36,6],[43,5],[60,1],[157,2],[175,1],[177,5],[200,1],[216,1],[232,1],[239,1],[259,2],[285,1],[301,1],[303,5]]},"193":{"position":[[4,2],[7,4],[12,1],[16,2],[34,1],[36,3],[40,4],[53,2],[61,1],[71,1],[73,5],[79,4],[84,4],[156,1],[182,1],[184,6],[191,3],[195,3],[205,1],[213,2],[216,2],[219,3],[223,3]]},"195":{"position":[[4,1],[6,5],[25,5],[53,1],[61,1],[75,3],[79,5]]},"197":{"position":[[12,1],[19,5],[30,1],[40,1],[42,5],[48,2],[51,1],[53,4],[58,2],[64,1],[87,1],[93,1],[99,1],[101,3],[105,4],[110,5],[116,1],[118,5],[124,2],[130,1],[132,5]]},"199":{"position":[[16,1],[30,1],[38,4],[43,2],[46,2],[49,7],[64,1],[66,2],[69,5],[75,5],[85,1],[87,4],[187,2],[205,1],[207,5],[213,5]]},"201":{"position":[[0,2],[3,3],[17,3],[21,4],[26,2],[29,2],[32,4],[82,1],[102,1],[104,2],[107,3],[111,5]]},"203":{"position":[[16,1],[35,3],[46,1],[48,2],[51,4],[56,4],[61,3],[78,2],[81,3],[85,5],[91,2],[94,2],[110,3],[114,2],[117,3],[121,5],[127,2],[130,2],[133,1],[135,2],[138,3],[142,3],[163,1],[165,3],[169,2],[172,5],[178,3],[182,3],[186,2],[189,3],[193,3],[197,3],[201,4],[219,2],[222,5],[228,1],[230,2],[233,5],[260,1],[262,3],[266,3],[270,1],[272,2],[280,3],[284,5],[290,2],[308,1],[310,4],[315,2],[318,3],[322,5],[343,1],[362,1],[368,1],[370,4],[375,3],[379,5],[392,2],[395,4],[400,2],[403,2],[406,3],[410,2],[413,2],[416,3],[420,3],[424,2],[434,1],[436,2],[439,2],[442,3],[446,2],[449,4],[454,3],[458,1],[460,3]]},"205":{"position":[[0,1],[2,3],[6,1],[8,3],[29,3],[33,5],[73,1],[75,3],[79,2],[82,2],[94,2],[104,1],[122,4],[127,1],[129,2],[132,3],[136,1],[138,4],[143,3],[149,2],[152,2],[170,1],[172,3],[178,2],[187,1],[194,1],[203,1],[205,4],[210,3],[214,2],[217,2],[220,4],[225,3],[229,3],[233,4],[238,1],[240,2],[243,2],[279,1],[281,2],[284,3],[290,2],[299,1],[301,3],[320,2],[323,3],[327,2],[330,4]]},"207":{"position":[[0,2],[20,1],[22,3],[26,3],[32,2],[41,1],[43,3],[62,3],[66,6],[73,2],[76,3],[97,4],[102,3],[106,2],[109,1],[111,4],[116,6],[123,2],[126,3],[130,2],[133,5],[139,4],[144,5],[150,1],[152,7]]},"209":{"position":[[8,1],[24,2],[27,3],[31,2],[34,6],[44,2],[73,1],[75,5],[89,1],[91,3],[95,2],[98,5],[104,2],[107,2],[110,3],[117,3],[121,6],[128,3],[132,3],[136,5]]},"211":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"213":{"position":[[0,1],[2,3],[61,1],[63,3],[67,2],[118,1],[120,2],[164,1],[190,3],[212,1],[214,2],[217,3],[246,1],[248,4],[253,3],[257,2],[260,3],[264,2],[267,4],[272,2],[275,2],[287,1],[289,1],[291,2],[294,4],[299,2],[302,3],[306,4],[315,3],[336,3],[340,1],[342,2],[345,6],[352,5],[383,1],[385,4],[417,1],[419,3],[433,2],[445,1],[447,3],[451,2],[454,4],[459,2],[462,2],[474,1],[476,2],[479,4],[509,2],[512,8],[521,5],[531,3],[535,2],[538,4],[543,4],[548,2],[551,6]]},"215":{"position":[[21,1],[28,2],[31,3],[35,3],[86,1],[88,6],[95,2],[98,4],[116,3],[120,4],[125,1],[127,3],[155,1],[181,1],[183,3],[209,1],[211,2],[214,2],[217,4],[232,3],[236,2],[239,4],[259,1],[261,2],[264,5],[289,1],[316,3],[350,3],[354,2],[387,1],[404,3],[439,2],[482,1],[484,2],[487,3],[491,2],[494,2],[523,1],[525,4],[550,2],[553,3],[557,1],[559,3],[563,5],[569,5],[575,3],[579,4],[584,4],[589,4],[594,3],[598,1],[600,3],[604,1],[606,4],[611,4],[616,3],[641,2],[662,1],[664,2],[670,1],[677,1],[679,4],[684,2],[687,3],[691,3],[708,1],[710,5],[716,3],[720,2],[723,2],[731,1],[745,2],[748,3],[752,2],[755,4],[760,3],[764,1],[766,4],[771,3],[807,5],[813,2],[856,1],[858,3],[862,1],[864,4],[869,3],[882,1],[884,3],[888,1],[890,3],[894,3],[898,5],[904,2],[907,4],[930,1],[932,3],[936,1],[938,3],[952,1],[974,1],[976,3],[980,1],[982,3],[986,2],[1003,1],[1005,5],[1011,2],[1014,2],[1017,2],[1032,3],[1047,1],[1079,2],[1097,3],[1101,2],[1122,1],[1136,4],[1151,1],[1153,3],[1157,2],[1160,1],[1162,3],[1166,4],[1185,1],[1223,1],[1238,3],[1242,4],[1247,5],[1253,2],[1256,3],[1260,2],[1263,3],[1315,2],[1323,3],[1327,3],[1331,2],[1362,1],[1376,1],[1378,1],[1380,4],[1398,1],[1434,1],[1448,1],[1450,3],[1454,3],[1458,2],[1461,2],[1464,3],[1468,2],[1517,1],[1519,2],[1539,1],[1541,1],[1543,1],[1545,5],[1551,3],[1560,1],[1582,3],[1586,2],[1589,3],[1593,2],[1596,4],[1601,5],[1607,1],[1609,1],[1611,5],[1617,3],[1621,3],[1631,2],[1634,2],[1637,5],[1643,4],[1648,5],[1654,2],[1657,2],[1660,4],[1665,3],[1669,2],[1672,2],[1675,4],[1680,3],[1684,5],[1690,2],[1693,2],[1696,2],[1699,3],[1703,6],[1710,1],[1712,3],[1716,2],[1719,2],[1722,5],[1728,6],[1735,2],[1738,2],[1741,3],[1745,4],[1750,3],[1754,6],[1761,2],[1832,5],[1838,3],[1842,2],[1845,3],[1849,3],[1853,2],[1856,3],[1860,2],[1863,4],[1868,5],[1880,2],[1883,3],[1887,1],[1889,5],[1895,2],[1898,2],[1901,1],[1933,4],[1938,3],[1942,3],[1946,4],[1951,5],[1957,3],[1961,3],[1965,2],[1968,1],[1999,1],[2001,2],[2004,2],[2007,2],[2010,2],[2013,3],[2017,6],[2024,1],[2026,3],[2030,4],[2035,3],[2039,4],[2044,5],[2050,3],[2054,4],[2059,5],[2065,2],[2068,2],[2071,6],[2078,3],[2086,3],[2090,3],[2094,2],[2097,3],[2101,3],[2105,3],[2109,1],[2111,2],[2114,4],[2119,5],[2125,3],[2129,3],[2133,5],[2139,2],[2146,3],[2181,6],[2188,3],[2192,1],[2194,2],[2197,6],[2204,3],[2208,7],[2216,3],[2220,3],[2224,2],[2273,1],[2303,2],[2306,2],[2309,2],[2340,1],[2367,2],[2370,3],[2384,3],[2388,4],[2393,3],[2401,3],[2405,3],[2409,3],[2413,2],[2416,2],[2419,3],[2423,4],[2428,5],[2434,2],[2437,6],[2444,2],[2447,3],[2451,3],[2455,4],[2460,3],[2464,4],[2473,2],[2505,6],[2512,4],[2528,2],[2531,4],[2536,4],[2541,2],[2544,3],[2548,5],[2554,2],[2557,5],[2563,7],[2571,1],[2573,2],[2576,4],[2581,4],[2590,3],[2594,3],[2598,2],[2601,4],[2606,1],[2608,5],[2614,6],[2621,3],[2625,2],[2628,1],[2630,2],[2633,3],[2637,4],[2653,2],[2656,3],[2660,3],[2664,1],[2666,6],[2673,3],[2677,2],[2680,3],[2720,2],[2723,4],[2728,1],[2730,5]]},"217":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"219":{"position":[[0,2],[19,3],[35,3],[39,3],[43,2],[46,3],[50,3],[54,5],[60,2],[71,1],[73,3],[77,1],[79,5],[85,4],[106,1],[108,2],[119,1],[121,2],[124,2],[127,5],[133,5],[139,4],[144,4],[149,2],[152,3],[171,3],[175,4],[180,2],[183,1],[185,2],[188,3],[192,5],[198,2],[201,3],[220,1],[222,3],[234,1],[236,5],[259,1],[261,5],[267,3],[287,2],[290,3],[294,3],[298,1],[300,3],[304,5],[310,2],[316,2],[319,5],[333,1],[340,1],[342,3],[346,4],[351,3],[355,2],[370,1],[390,3],[394,2],[397,3]]},"221":{"position":[[12,1],[14,3],[18,3],[22,3],[26,3],[30,2],[33,3],[37,3],[41,4],[46,3],[50,2],[53,3],[57,1],[59,2],[62,3],[66,3],[70,3],[90,1],[136,2],[139,2],[154,3],[158,5],[212,2],[215,2],[218,3],[222,5],[228,5],[234,3],[238,3],[242,4],[247,3],[251,3],[255,5],[261,4],[266,4],[271,5],[285,2],[288,2],[291,2],[294,3],[310,1],[312,3],[316,4],[338,1],[340,5],[346,4],[351,1],[353,3],[357,2],[360,2],[363,2],[366,4],[371,4],[376,2],[379,3],[400,1],[402,5],[408,3],[412,3],[416,1],[418,3],[434,3],[438,5],[444,4],[449,5],[463,1],[465,2],[468,3],[472,2],[475,3],[479,5],[505,1],[507,2],[510,3],[531,2],[534,2],[557,3],[599,1],[660,1],[662,3],[666,3],[677,3],[681,4],[701,2],[717,1],[719,2],[722,2],[737,2],[740,4],[745,2],[766,1],[768,1],[774,1],[776,4],[781,5],[798,1],[800,5],[814,1],[820,2],[823,4],[894,2],[909,1],[911,2],[914,2],[917,3],[921,4],[926,6],[941,1],[943,2],[946,2],[949,3],[953,5],[973,1],[975,2],[978,2],[981,4],[986,2],[989,2],[992,2],[995,2],[1006,2],[1009,4],[1014,2],[1017,5],[1023,2]]},"225":{"position":[[8,1],[26,1],[46,3],[57,1],[72,1],[84,1],[147,3],[158,1],[164,1],[187,1],[206,1],[249,1],[251,2],[275,1],[277,2],[287,1],[289,3],[299,1],[310,1],[320,1],[322,2],[330,3],[334,3],[338,5],[344,3],[352,3],[356,4],[371,1],[373,3],[395,1],[406,1],[421,3],[425,3],[429,3],[433,2],[456,1],[458,5],[464,2],[482,1],[484,7],[492,2],[537,1],[556,1],[558,3],[562,3],[566,2],[569,3],[588,1],[611,1],[613,2],[637,1],[656,2],[659,2],[662,2],[686,1],[696,1],[698,5],[712,1],[714,2],[717,4],[740,2],[768,2],[787,2],[790,3],[794,2],[797,5]]},"227":{"position":[[8,1],[10,1],[12,3],[36,1],[38,5],[68,1],[79,2],[82,2],[97,5],[103,4],[108,2],[111,5],[128,1],[130,2],[133,2],[136,2],[149,1],[160,1],[179,1],[181,4],[186,2],[201,2],[204,4],[216,1],[218,2],[362,1],[364,4],[387,2],[390,1],[408,1],[420,3],[441,1],[450,1],[452,4],[457,2],[460,3],[464,5],[470,1],[472,1],[491,1],[502,2],[505,1],[507,2],[510,1],[564,1],[579,2],[591,1],[616,2],[630,1],[637,1],[653,1],[660,1],[696,1],[698,4],[703,2],[714,1],[716,3],[720,1],[722,3],[726,2],[729,4],[756,1],[773,1],[775,2],[785,3],[789,2],[792,4],[797,3],[801,3],[809,1],[811,4],[816,4],[827,1],[836,2],[853,3],[857,2],[877,1],[879,2],[882,3],[886,3],[890,2],[893,4],[898,3]]},"230":{"position":[[0,2],[18,1],[20,3],[24,4],[29,4],[52,1],[54,4],[59,2],[62,4],[67,4],[72,2],[96,1],[98,2],[101,3],[113,1],[115,2],[118,3],[122,2],[125,2],[132,1],[134,1],[136,3],[140,1],[169,2],[172,3],[176,2],[210,4],[215,4],[220,4],[225,2],[228,4],[237,2],[240,3],[260,2],[263,3],[267,4],[272,2],[275,2],[278,3],[282,4],[287,4],[302,1],[304,2],[307,1],[333,1],[335,2],[353,4],[376,4],[400,2],[403,2],[432,1],[438,1],[440,5],[464,1],[466,3],[470,3],[506,1],[508,5]]},"232":{"position":[[15,1],[17,2],[20,4],[31,2],[34,6],[58,1],[60,2],[63,2],[66,2],[69,2],[72,4],[77,3],[81,2],[84,3],[88,1],[90,3],[94,4],[99,2],[120,1],[122,5],[150,3],[162,1],[170,2],[173,2],[176,3],[180,2],[193,1],[195,2],[215,1],[232,1],[234,4],[254,3],[258,2],[261,3],[265,4],[270,2],[273,2],[297,2],[300,3],[324,1],[339,2],[342,2],[369,1],[371,2],[374,2],[398,1],[433,4],[451,1],[453,2],[456,3],[460,2],[463,2],[466,4],[471,5],[477,3],[481,1],[483,2],[486,3],[490,2],[514,1],[539,1],[541,4],[546,2],[553,1],[561,1],[563,2]]},"234":{"position":[[21,1],[23,4],[28,4],[33,2],[36,3],[40,2],[50,1],[61,2],[64,3],[68,1],[88,1],[110,1],[112,2],[139,3],[157,1],[173,4],[178,2],[181,4],[202,3],[206,2],[209,4],[214,2],[230,1],[232,5],[238,3],[248,1],[250,2],[253,4],[258,4],[263,2],[280,3],[304,1],[306,5],[330,1],[332,5],[338,2],[359,1],[361,2],[372,1],[374,3],[378,3],[382,1],[392,1],[394,4],[416,2],[441,1],[443,4],[455,1],[464,1],[475,3],[495,1],[497,5],[503,6]]},"236":{"position":[[0,3],[12,1],[25,1],[42,2],[45,4],[50,2],[53,1],[55,2],[58,3],[62,2],[65,4],[70,2],[89,5],[95,2],[98,3],[139,2],[168,1],[250,1],[272,3],[297,1],[303,4],[325,1],[327,3],[331,2],[360,6],[367,2],[370,1],[372,3],[385,3],[389,2],[392,1],[394,2],[410,1],[412,5],[418,2],[426,2],[429,5],[435,6],[442,3],[446,3],[482,1],[484,3],[488,2],[491,4],[517,2],[538,1],[540,2],[575,2],[578,4],[583,4]]},"239":{"position":[[8,4],[31,2],[38,3],[42,3],[46,3],[50,3],[63,1],[65,3],[69,1],[71,3],[90,1],[126,1],[136,1],[138,5],[144,2],[147,3],[151,2],[154,2],[157,3],[165,1],[173,1],[175,5],[181,2],[184,3],[188,2],[191,4],[196,2],[199,4],[216,1],[218,3],[222,3],[226,3],[235,1],[280,1]]},"242":{"position":[[10,4],[38,4],[95,5],[117,1],[130,1],[143,1],[145,4],[150,5],[166,2],[175,1],[188,2],[191,4],[196,3]]},"244":{"position":[[67,1],[69,3],[73,3],[77,4],[82,4],[99,1],[101,2],[104,2],[107,2],[114,1],[116,4],[138,1],[159,1],[161,3],[178,3],[182,2],[196,2],[199,2],[202,1],[204,3],[208,6],[215,5],[221,3],[225,3],[229,3],[233,5],[255,2],[258,2],[261,3],[265,2],[300,2],[318,2],[325,5],[331,2],[334,2],[337,1],[344,6],[351,4],[363,1],[365,6],[372,3],[376,3],[380,2],[388,1],[390,4],[400,1],[402,4],[407,3],[411,4],[416,2],[419,3],[423,2],[442,1],[444,5],[450,3],[454,2],[457,2],[460,3],[464,5],[470,2],[480,3],[484,2],[487,5],[493,3],[497,2],[510,3],[514,3],[518,3],[522,3],[526,1],[528,2],[531,2],[534,3],[538,3],[542,3]]},"246":{"position":[[17,3],[21,2],[24,3],[28,3],[44,2],[59,1],[61,5],[79,1],[98,1],[115,2],[118,3],[129,1],[142,1],[144,4],[149,2],[152,3],[156,3],[160,2],[163,2],[166,5],[176,1],[199,3],[203,4],[208,2],[211,3],[215,2],[218,4],[229,3],[248,1],[250,3],[254,3],[271,4],[276,5],[298,3],[310,4],[315,2],[318,2],[321,3],[325,4],[330,1],[332,1],[334,2],[337,4],[342,2],[345,3],[349,6],[356,2],[359,2],[362,2],[365,2],[368,5],[386,1],[388,5],[394,2],[407,1],[409,3],[413,5],[430,1],[454,1],[456,3],[460,2],[463,2],[466,3],[470,3],[474,4],[479,3],[483,3],[487,3],[491,3],[495,3],[499,3],[503,2],[506,2],[509,3],[513,3],[517,4],[522,4],[527,2],[530,4],[535,4],[540,2],[555,1],[557,2],[560,3],[564,4],[569,3],[573,1],[575,2],[578,3],[582,3],[586,3],[590,3],[594,2],[597,2],[600,2],[603,2],[606,4],[611,4],[616,1],[618,2],[621,3],[625,4],[630,3],[634,4],[639,2],[642,3],[646,1]]},"249":{"position":[[0,2],[22,1],[37,1],[51,2],[54,3],[76,1],[111,1],[144,1],[146,2],[149,2],[157,4],[162,3],[166,2],[169,3],[173,4]]},"251":{"position":[[23,1],[35,3],[39,5],[45,4],[62,2],[82,1],[84,5],[90,3],[94,5],[100,1],[102,2],[105,4],[110,5],[123,7],[136,3],[140,5],[153,1],[155,4],[160,3],[164,3],[168,2],[179,1],[181,3],[193,2],[196,3],[200,5]]},"253":{"position":[[9,2],[21,5],[27,2],[30,3],[34,2],[65,1],[67,2],[70,2],[81,2],[84,1],[86,5],[92,4],[117,1],[119,7],[142,1],[144,4],[149,2],[160,1],[162,3],[166,4],[180,1],[191,4],[196,2],[210,4],[215,6],[222,1],[224,2],[236,3],[240,3],[252,1],[254,3],[270,2],[282,4],[293,1],[295,4],[300,5],[310,2],[322,3],[326,2],[329,3],[333,2],[336,3],[349,2],[352,2],[355,3],[365,1],[373,1],[375,1],[377,3],[381,3],[385,2],[388,1],[390,4],[395,1],[397,2],[414,2],[433,2],[436,3],[440,1],[442,4],[447,1],[449,3],[453,2],[456,2]]},"255":{"position":[[0,3],[12,1],[14,2],[17,4],[22,3],[26,3],[30,2],[33,2],[36,3],[40,3],[44,2],[57,4],[62,1],[64,2],[67,2],[70,3],[79,3],[83,7],[91,1],[101,1],[123,1],[129,1],[131,4],[136,2],[139,5],[145,3],[161,4],[172,1],[174,5]]},"258":{"position":[[0,1],[2,3],[10,1],[12,2],[15,1],[17,2],[37,1],[39,4],[44,2],[47,3],[51,3],[55,3],[59,3],[63,1],[65,2],[85,1],[87,3],[91,1],[93,2],[96,2],[99,3],[103,2],[106,3],[110,5],[116,2],[119,4],[141,1],[143,3],[147,3],[151,4],[156,2]]},"260":{"position":[[0,1],[2,2],[9,1],[11,2],[21,1],[23,4],[28,2],[31,3],[35,2],[38,2],[41,2],[44,3],[61,1],[63,3],[73,1],[75,2],[78,5],[84,3],[88,3],[98,1],[100,4],[105,1],[107,4],[112,2],[131,1],[133,1],[135,3],[156,1],[158,5],[164,3],[168,2]]},"262":{"position":[[0,1],[2,2],[9,1],[21,1],[29,1],[31,4],[43,1],[45,4],[50,3],[54,4],[59,2],[62,2],[69,4],[74,3],[78,1],[80,2],[89,1],[91,3],[95,2],[98,4],[103,3],[107,1],[109,3],[113,5],[119,4],[124,3],[128,1],[130,4],[143,1],[145,6],[159,1],[161,4],[166,4],[171,4],[176,2],[179,3],[183,4],[188,2],[191,2],[194,3],[198,4],[214,1],[235,2],[238,1],[240,4],[245,2],[248,5],[254,2],[257,2]]},"265":{"position":[[8,3],[12,2],[30,1],[32,1],[34,3],[38,3],[42,1],[44,3],[48,2],[71,1],[89,3],[93,4],[98,3],[117,1],[119,2],[122,3],[126,4],[131,1],[151,3],[163,1],[165,5],[188,5],[194,3],[198,3],[202,3],[206,4],[211,3],[215,2],[218,4],[223,4],[228,2],[239,1],[241,1],[266,1],[268,2],[271,3],[275,3],[279,4]]},"267":{"position":[[10,3],[14,2],[32,1],[34,1],[36,3],[40,3],[44,1],[46,3],[50,3],[54,3],[58,3],[62,2],[65,5],[71,4],[90,4],[95,4],[120,2],[123,3],[127,4],[142,1],[148,1],[150,4],[155,2],[171,1],[173,2],[176,3],[196,1],[202,1],[204,3],[208,2],[211,3],[215,2],[218,3],[222,5],[228,5],[244,3],[248,3],[252,3],[256,2],[259,5]]},"269":{"position":[[0,3],[13,1],[15,3],[32,1],[46,1],[48,3],[52,3],[56,2],[80,5],[86,2],[89,3],[93,6],[100,3],[104,1],[106,4],[111,2],[124,1],[126,2],[129,2],[132,5],[138,2],[141,1],[143,6],[159,1],[161,2],[168,4],[173,2],[176,2],[179,2],[187,4],[192,3],[196,2],[215,1],[229,1],[231,2],[234,3],[238,4]]},"271":{"position":[[0,1],[2,3],[6,4],[19,1],[21,2],[24,2],[48,1],[50,5],[100,2],[103,2],[106,3],[110,4],[115,2],[118,4]]},"273":{"position":[[36,1],[38,1],[40,2],[43,4],[48,4],[53,4],[58,2],[69,1],[71,4],[76,3],[80,4],[85,3],[89,2],[92,4],[127,2],[130,3],[134,2]]},"275":{"position":[[0,2],[3,6],[20,1],[42,1],[54,1],[64,1],[66,3],[70,2],[73,3],[77,2],[80,3],[99,1],[101,7],[109,2],[112,2],[124,3],[128,2],[139,1],[141,2],[144,3],[148,4],[153,3],[157,2],[160,3],[164,3]]},"277":{"position":[[0,1],[2,3],[6,5],[20,1],[34,1],[36,1],[38,4],[43,2],[54,1],[77,1],[79,4],[84,2],[87,2],[90,3],[94,2],[97,1],[99,2],[110,1],[112,3],[116,2],[119,3],[123,3],[127,4],[146,2],[149,2],[152,2],[155,4],[168,1],[170,3],[174,2],[185,1],[187,4],[192,4],[197,2],[200,3],[204,3]]},"279":{"position":[[8,1],[10,2],[21,1],[23,2],[26,1],[28,2],[31,1],[33,4],[38,3],[46,3],[50,6],[81,1],[83,3],[87,2],[90,4],[95,3],[99,2],[119,1],[121,4],[126,4],[131,3],[135,4],[140,2],[143,4],[148,4],[153,1],[155,2],[158,3],[162,4],[167,3],[171,3],[175,3],[179,3]]},"281":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"283":{"position":[[0,3],[26,1],[36,1],[46,1],[48,3],[61,4],[66,3],[70,2],[93,1],[95,4],[112,1],[114,2],[117,1],[119,4],[129,2],[132,3],[136,4],[141,6],[148,2],[151,7],[159,2],[162,3],[166,2],[169,2],[181,2],[200,2],[212,2],[225,2],[255,1],[257,2],[265,3],[269,1],[271,5],[277,2],[280,3]]},"285":{"position":[[4,1],[11,1],[23,1],[25,2],[28,4],[49,5],[55,3],[59,2],[62,3],[66,3],[70,5],[82,1],[101,1],[120,1],[122,2],[125,3],[129,2],[154,1],[156,2],[176,1],[191,1],[199,2],[202,2],[205,4],[210,4],[215,2],[218,3],[222,3],[235,3],[239,5],[245,3],[249,4],[254,2],[257,2],[280,1],[288,1],[297,3],[301,4],[306,2],[309,4],[314,4],[319,1],[321,2],[324,3],[328,3],[337,2],[340,5],[346,5],[352,3],[360,1],[362,2],[365,5],[371,1],[373,5],[383,1],[385,4],[390,3],[414,2],[417,4],[428,1],[437,3],[461,1],[463,4],[480,2],[483,4],[488,2],[503,2],[511,5]]},"287":{"position":[[0,2],[3,3],[7,3],[11,2],[18,1],[20,3],[24,2],[68,5],[80,1],[98,1],[100,2],[103,3],[129,1],[131,6],[138,3],[142,2],[145,2],[148,2],[151,2],[154,3],[158,2],[161,5],[175,1],[177,2],[180,6],[195,1],[197,2],[200,7],[208,2],[223,1],[225,2],[228,2],[231,1],[233,7],[280,1],[282,2],[296,1],[298,4],[303,3],[307,4],[312,2],[336,2],[339,6],[361,1],[363,2],[366,2],[369,3],[373,4],[387,1],[404,1],[406,4],[500,1],[543,1],[545,3],[554,2],[557,2],[587,1],[617,2],[650,1],[652,7],[695,1],[720,2],[723,1],[725,5],[731,3],[747,1],[770,1],[776,1],[778,4],[783,2],[792,1],[816,3],[820,3],[839,2],[842,4],[847,3]]},"289":{"position":[[0,3],[4,2],[35,1],[53,3],[57,2],[60,3],[72,1],[150,1],[201,1],[234,1],[236,2],[247,1],[249,1],[251,3],[255,3],[320,2],[323,1],[325,4],[336,1],[354,3],[358,2],[361,2],[364,1],[366,3],[370,3],[382,1],[384,2],[387,4],[392,2],[407,1],[409,1],[411,5],[417,4],[430,1],[440,1],[465,1],[501,1],[503,2]]},"292":{"position":[[8,1],[15,1],[22,1],[24,3],[40,2],[43,5],[49,1],[57,1],[59,1],[61,2],[75,1],[77,2],[157,1],[169,1],[191,5],[197,1],[199,2],[222,2],[225,1],[237,1],[239,3],[286,1],[373,1],[405,1],[407,4],[412,2],[415,2],[418,2],[421,2],[439,1],[458,1],[504,1],[521,2]]},"294":{"position":[[8,2],[16,1],[23,1],[25,3],[41,2],[44,5],[64,1],[66,2],[84,1],[86,2],[105,2],[108,2],[125,1],[134,1],[136,2],[160,2],[171,1],[173,5],[179,1],[191,1],[213,1],[235,2],[252,1],[269,1],[271,4],[285,1],[307,1],[319,2],[322,2],[325,2],[328,1],[338,1],[357,1],[359,1],[361,2],[364,3],[375,3],[392,1],[394,2],[397,3],[405,2],[408,2],[411,2],[423,3],[427,3],[431,1],[433,3],[437,2]]},"296":{"position":[[19,1],[27,1],[39,3],[50,2],[61,2],[64,4],[87,1],[89,2],[106,1],[131,1],[139,1],[141,3],[152,1],[154,4],[163,2],[166,3],[170,2],[199,2],[202,3]]},"298":{"position":[[0,3],[4,1],[6,2],[19,1],[50,2],[53,3],[72,1],[93,1],[103,1],[130,1],[139,1],[141,4],[155,1],[163,1],[177,1],[179,5],[185,2],[205,1],[207,3],[219,3],[223,4],[235,1],[237,2],[247,1],[249,4],[254,3],[266,1],[268,3],[283,1],[285,2],[307,5],[318,1],[327,2],[341,1],[347,1],[349,3],[353,5],[359,2],[376,1],[378,5],[459,1],[554,5],[560,4],[585,1],[606,1],[648,3],[674,1],[676,3],[680,5],[686,6],[702,2],[735,1],[737,3],[760,1],[782,1],[805,1],[807,4],[835,2],[838,1],[840,1],[842,5],[848,3],[852,4],[857,6],[886,1],[888,3],[892,4],[925,1],[927,4],[932,4],[937,3],[941,2],[944,1],[946,3],[950,2],[953,6],[982,1],[984,2],[987,1],[989,5],[995,3],[999,3],[1003,6],[1034,1],[1036,2],[1047,2],[1050,4],[1074,1],[1088,2],[1091,5],[1097,3],[1123,1],[1125,2],[1140,1],[1142,2],[1145,3],[1149,5],[1172,1],[1200,1],[1202,3],[1206,2],[1209,2],[1224,1],[1256,1],[1266,3]]},"300":{"position":[[64,1],[92,1],[94,4],[99,3],[103,3],[134,1],[136,4],[160,1],[182,2],[199,1],[208,1],[214,1],[233,2],[236,2],[239,3],[243,2],[246,2],[249,3],[277,1],[286,3],[290,2],[293,3],[316,1],[318,4],[358,1],[360,4],[365,2],[368,3],[391,2],[394,1],[396,1],[406,2],[416,2],[419,4],[424,4],[450,1],[452,2],[455,2],[483,2],[486,2],[489,2],[501,2],[504,3],[508,4],[520,3],[524,3],[550,1],[552,3],[556,4],[561,2],[564,5],[686,2],[744,2],[760,1],[776,2],[930,1],[1197,1],[1199,4],[1229,2],[1238,1],[1245,1],[1252,1],[1254,2],[1257,1],[1264,1],[1287,1],[1293,1],[1314,1],[1339,1],[1341,2],[1344,1],[1351,1],[1353,3],[1357,5],[1363,4],[1368,1],[1370,2],[1373,3],[1377,2],[1380,3],[1406,1],[1408,2]]},"302":{"position":[[12,1],[35,1],[37,1],[39,3],[43,2],[46,3],[50,2],[86,3],[96,1],[121,2],[124,5],[141,1],[157,1],[166,2],[169,5],[175,2],[178,2],[189,1],[191,1],[202,1],[219,1],[235,1],[244,1],[246,1],[248,1],[250,3],[254,2],[278,1],[280,4],[321,1],[323,5],[337,1],[360,1],[362,5],[389,2],[392,2],[408,1],[418,1],[420,3],[424,3],[428,5],[434,1],[436,3],[440,2],[457,1],[466,3],[478,1],[480,1],[482,3],[486,2],[503,1],[505,2],[508,3],[519,1],[521,1],[523,3],[535,1],[558,1],[568,1],[570,1],[572,3],[576,2],[579,3],[583,3],[595,1],[597,2],[600,3],[611,1],[613,1],[615,3],[634,1],[662,1],[664,4],[685,3],[689,4],[694,3],[698,3],[731,4],[744,1],[746,3],[750,2],[753,2],[756,1],[758,1],[760,3],[764,3],[768,4],[773,2],[788,3],[801,1],[803,5],[809,2],[812,3]]},"304":{"position":[[21,3],[33,1],[43,1],[45,1],[47,4],[52,1],[54,3],[58,2],[61,3],[65,4],[70,4],[112,1],[114,2],[117,2],[147,2],[150,3],[170,1],[172,5],[235,1],[250,1],[260,1],[335,1],[337,2],[349,2],[352,5],[364,2],[367,2],[370,2],[384,1],[386,2],[389,2],[392,3],[396,5],[416,1],[434,2],[437,3],[441,1],[443,3],[453,1],[462,3],[491,1],[508,3],[524,1],[526,3],[545,1]]},"306":{"position":[[0,2],[31,1],[33,5],[52,1],[54,2],[85,1],[94,1],[96,4],[101,2],[122,2],[125,2],[143,1],[166,3],[170,4],[175,2],[208,1],[227,2],[230,1],[232,5],[259,1],[295,3],[318,1],[320,5],[343,3],[347,2],[358,1],[396,1],[398,4]]},"308":{"position":[[0,1],[2,4],[18,1],[32,1],[34,2],[37,3],[50,1],[52,3],[56,4],[61,2],[73,2],[76,3],[80,3],[84,2],[87,3],[91,3],[95,2],[98,3],[102,4],[107,3],[111,2],[114,2],[125,1],[142,1],[144,4],[170,1],[172,5],[199,1],[201,3],[243,1],[245,5],[251,1],[253,2],[256,2],[259,1],[261,3],[273,1],[281,2],[305,4],[310,3],[411,2],[422,1],[434,1],[453,2],[467,1],[472,2],[483,1],[495,1],[611,1],[627,1],[639,1],[661,1],[663,1],[665,3],[669,2],[672,3],[676,2],[679,3],[692,2],[728,2],[731,5],[737,3],[741,2],[761,1],[763,2],[781,1],[794,1],[816,1],[834,2],[837,3],[841,1],[843,2],[846,3],[850,3],[854,3],[858,3],[862,2],[875,1],[877,1],[879,3],[883,3],[887,2],[890,2],[921,1],[923,4],[928,6],[935,1],[937,3],[941,2],[944,3],[948,3],[952,2],[955,2],[958,2],[974,3],[978,2],[981,2],[984,3],[988,5],[994,2],[997,3],[1001,2],[1004,1],[1020,1],[1022,3],[1026,1],[1028,2],[1031,1]]},"310":{"position":[[23,1],[25,1],[90,1],[92,2],[95,2],[98,3],[149,1],[151,5],[157,4],[172,1],[195,1],[219,1],[221,3],[225,4],[230,2],[233,3],[246,1],[278,2],[289,1],[304,2],[307,4],[371,1],[373,2],[376,1],[378,2],[381,2],[384,3],[388,2],[397,1],[399,1],[401,2],[404,3],[408,4],[413,1],[415,2],[418,2],[421,1],[431,2],[458,3],[498,1],[500,4],[505,2],[536,2],[539,3],[543,4],[548,3],[565,1],[567,3],[571,1],[573,2],[576,3],[580,3],[584,2],[587,1],[589,3],[601,1],[611,1],[630,1],[632,4],[649,3],[659,1],[678,1],[680,2],[705,2],[708,3],[717,1],[719,4],[748,1],[750,5],[756,3],[760,3],[764,3],[768,2],[771,2],[780,4],[785,3],[797,2],[810,1],[828,2],[851,1],[853,5],[867,1],[869,3],[894,1],[896,2],[908,1],[910,3],[914,2],[939,1],[941,4],[946,3],[966,1],[981,1],[1005,1],[1007,2],[1010,2],[1013,3],[1017,5],[1043,1],[1074,2],[1077,2],[1080,2],[1100,2],[1103,4],[1127,1],[1129,4],[1140,1],[1142,2],[1145,3],[1149,5],[1155,2],[1173,1],[1190,1],[1192,2],[1211,1],[1213,4],[1227,1],[1229,3],[1233,5],[1239,2],[1242,2],[1245,3],[1249,2],[1291,1],[1293,2],[1308,1],[1315,1],[1344,1],[1352,1],[1361,1],[1373,1],[1375,4],[1380,4],[1404,1],[1406,2],[1428,1],[1469,1],[1471,2],[1507,1],[1509,2],[1512,2],[1515,2],[1526,2],[1543,2],[1559,1],[1561,4],[1587,1],[1589,5],[1611,2],[1614,3],[1618,3],[1626,1],[1628,2],[1653,1],[1655,4],[1693,1],[1721,2],[1724,3],[1728,5],[1739,1],[1746,1],[1748,3],[1752,4],[1772,1],[1805,1],[1807,4],[1812,2],[1815,4],[1835,1],[1837,2],[1840,3],[1844,3],[1848,5],[1877,1],[1891,5],[1897,2],[1916,1],[1918,3],[1922,2],[1925,2],[1928,3],[1932,4],[1937,3],[1941,4],[1946,2],[1964,1],[1966,3],[1970,2],[1973,1],[1975,3],[1979,3],[1983,3],[1987,3],[1991,4]]},"313":{"position":[[0,1],[7,1],[24,1],[26,2],[61,2],[64,2],[67,3],[90,1],[92,4],[97,5],[103,4],[108,1],[123,1],[150,1],[152,4],[172,1],[174,3],[182,3],[186,1],[188,1],[218,3],[250,1],[258,2],[261,2],[279,1],[297,2],[300,3],[304,1],[321,2],[324,1],[346,1],[368,1],[370,2]]},"315":{"position":[[19,1],[21,2],[24,2],[27,1],[29,2],[32,3],[36,1],[43,2],[60,2],[66,2],[69,2],[72,2],[75,3],[79,3],[88,1],[94,1],[96,5],[123,2]]},"317":{"position":[[15,1],[17,6],[46,1],[61,1],[84,1],[101,1],[117,2],[120,2],[123,2],[140,1],[142,6],[149,2],[152,3],[156,2],[159,2],[246,1],[418,1],[474,1],[476,2],[493,1],[502,2],[505,6],[524,1],[526,1],[528,4],[533,4],[538,6],[577,1]]},"319":{"position":[[9,1],[11,1],[13,2],[31,2],[52,1],[64,1],[73,1],[83,2],[92,1],[94,4],[99,2],[112,2],[115,2],[141,1],[153,1],[176,1],[178,3],[190,2],[204,1],[224,1],[240,2],[269,1],[314,1],[328,2],[331,2],[334,1],[336,7],[344,4],[349,3],[364,1],[366,2],[369,4],[374,3],[387,1],[400,1],[402,6]]},"322":{"position":[[32,1],[34,2],[69,1],[71,3],[75,2],[78,2],[81,4],[86,5],[101,3],[105,2],[108,1],[115,3],[129,2],[132,3],[148,2],[155,1],[157,2],[171,1],[173,2],[176,2],[179,2],[182,1],[184,4],[189,5],[195,2],[198,2],[201,1],[203,2],[206,3],[210,2],[213,2],[216,3],[220,2],[255,1],[257,2],[270,1],[282,1],[284,4],[289,2],[305,2],[308,3],[312,3],[316,3],[320,2],[328,1],[330,2],[333,2],[340,1],[342,2],[345,2],[353,1],[355,2],[358,3],[380,1],[413,1],[429,2],[443,1],[445,2],[448,3],[467,1],[469,5],[488,1],[490,6],[501,4],[506,3],[520,1],[522,2],[525,3],[545,1],[547,3],[590,1],[601,2],[604,1],[619,1],[624,1],[626,6],[633,3],[637,2],[659,2],[662,3],[666,5],[672,2],[675,2],[678,1],[680,2],[683,3],[687,2],[690,3],[694,3],[698,2],[701,3],[705,2],[712,1],[714,1],[716,1],[722,1],[748,1],[750,4],[755,3],[759,2]]},"324":{"position":[[12,1],[14,3],[29,1],[31,4],[36,4],[41,3],[45,3],[49,4],[54,5],[72,1],[100,2],[103,2],[106,2],[109,2],[124,1],[126,5],[143,4],[148,4],[153,2],[160,3],[179,2],[196,1],[215,1],[217,5],[223,2],[226,2],[229,4],[234,5],[262,1],[277,2],[289,1],[291,5],[307,2],[310,3],[314,6],[325,2],[342,3],[346,3],[350,2],[353,3],[357,5],[363,2],[366,4],[371,4],[376,2],[379,2],[382,4],[399,2],[402,1],[404,3],[408,3],[412,3],[416,3],[420,1],[422,3],[426,2],[433,1],[439,3],[443,1],[445,3],[449,1],[451,4],[464,1],[466,4],[471,4],[476,3],[480,2],[483,2],[490,3],[494,3],[518,1],[549,2],[552,4],[568,1],[570,2],[573,3],[577,3],[581,2]]},"326":{"position":[[12,1],[14,2],[23,1],[25,2],[28,4],[33,1],[35,3],[39,4],[44,2],[47,3],[51,3],[69,1],[71,2],[74,2],[77,1],[84,1],[105,1],[107,3],[118,1],[149,1],[151,3],[161,2],[164,2],[167,3],[171,3],[206,1],[219,4],[229,1],[231,2],[234,2],[251,1],[257,4],[285,1],[287,4],[313,1],[332,1],[354,1],[356,2],[359,1],[375,1],[377,2],[403,1],[427,1],[429,3],[457,1],[459,2],[466,1],[468,4],[473,2],[476,4],[492,1],[505,1],[507,6],[538,3],[553,1],[566,2],[569,3],[584,2],[606,1],[632,1],[646,1],[648,4],[653,2],[656,2],[659,3],[663,2],[666,2],[669,2],[672,5],[719,1],[721,4],[726,2],[739,1],[763,1],[769,2],[772,6],[783,1],[785,4],[790,2],[793,3],[822,2],[825,2],[843,1],[857,1],[868,2],[892,2],[895,4],[900,1],[902,5],[908,3],[912,2],[915,4],[920,3],[924,3],[928,4],[964,1],[966,3],[982,1],[997,1],[999,5],[1005,2],[1023,1],[1025,2]]},"328":{"position":[[0,1],[2,4],[19,2],[22,3],[36,1],[38,3],[70,2],[89,6],[96,2],[99,4],[121,1],[144,2],[147,2],[168,2],[183,1],[195,2],[219,6],[226,2],[229,3],[233,3],[237,1],[239,3],[270,1],[313,2],[321,3],[325,4],[330,4],[335,2]]},"332":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"334":{"position":[[5,2],[8,3],[19,1],[30,2],[54,1],[56,2],[59,3],[82,1],[84,4],[89,2],[92,3],[129,3],[133,6],[140,5],[146,2],[168,1],[170,3],[174,2],[196,1],[210,2],[213,4],[252,1],[282,2],[285,1],[287,6],[294,3],[327,6],[334,1],[336,3],[340,2],[343,5],[349,2],[352,5],[365,4],[370,4],[375,3],[393,1],[404,3],[408,4],[413,3],[436,1],[438,3],[451,1],[488,1],[490,5],[518,1],[536,1],[538,3],[542,2],[545,1],[547,3],[551,5],[557,6],[568,1],[575,1],[596,4],[610,2],[613,2],[616,6],[623,2],[626,3],[630,4],[635,3],[639,3],[647,1],[661,2],[683,1],[685,3],[689,4],[694,3],[735,2],[738,5]]},"336":{"position":[[0,3],[9,1],[16,1],[18,2],[38,1],[40,3],[44,4],[65,4],[70,1],[72,2],[75,4],[94,1],[109,1],[111,3],[115,3],[119,4],[130,3],[134,5],[156,1],[158,6],[174,2],[177,3],[181,3],[185,3],[189,3],[200,1],[202,5],[218,2],[226,3],[251,3],[262,4],[267,5],[273,3],[291,1],[293,4],[298,2],[301,2],[304,3],[325,1],[327,2],[349,1],[351,5],[377,1],[379,3],[392,3],[396,3],[400,3],[415,5],[440,1],[454,1],[456,3],[494,1],[496,2],[503,1],[505,4],[525,1],[527,2],[530,2],[533,4],[556,1],[578,1],[613,2],[616,2],[632,1],[634,3],[646,1],[648,4],[653,2],[656,4],[661,4],[666,2],[681,1],[704,2],[723,3],[727,4],[745,2],[748,1],[750,4],[772,1],[774,5],[780,2],[783,3],[787,3],[791,3],[795,3],[799,2],[802,3],[806,5],[812,2],[830,1],[832,4],[837,2],[844,2],[881,1],[883,2],[890,1],[892,5],[898,6],[924,1],[926,3],[930,3],[951,1],[958,1],[960,4],[978,1],[980,2],[996,1],[998,5],[1004,3],[1021,2],[1056,1],[1058,5],[1064,3],[1082,3],[1086,5],[1092,3],[1116,1],[1118,4],[1145,2],[1148,3],[1152,3],[1161,1],[1163,3],[1167,4],[1172,1],[1174,3],[1188,2],[1205,1],[1207,6],[1214,3],[1218,3],[1222,3],[1226,4],[1231,2],[1248,1],[1250,2],[1253,1],[1261,2],[1264,4],[1269,2],[1280,1],[1282,4],[1291,1],[1293,2],[1296,2],[1299,4],[1304,3],[1308,3],[1312,4],[1317,4],[1322,4],[1327,4],[1332,2],[1345,1],[1347,4],[1352,2],[1355,4],[1373,3],[1377,3],[1381,3],[1402,1],[1417,3],[1421,2],[1424,5],[1430,3],[1453,1],[1455,3],[1459,3],[1463,1],[1465,4],[1470,5],[1476,2],[1479,4],[1484,3],[1510,1],[1512,4],[1517,3],[1528,1],[1537,3],[1541,2],[1544,4],[1554,2],[1557,3],[1568,3],[1572,3],[1576,3],[1580,3],[1597,4],[1624,4],[1629,4],[1634,3],[1638,4],[1643,1],[1645,6],[1652,2],[1655,1],[1657,2],[1673,2],[1676,3],[1680,1],[1682,3],[1705,1],[1707,3],[1715,3],[1719,2],[1726,1],[1728,5],[1738,1],[1762,1],[1780,1],[1782,3],[1786,1],[1788,2],[1807,1],[1809,2],[1817,1],[1819,3],[1823,5],[1837,3],[1841,5],[1856,2],[1859,3],[1863,2],[1888,4],[1893,2],[1899,2],[1928,6],[1940,1],[1962,2],[1965,3],[1969,4],[1986,1],[2007,2],[2010,4],[2015,6],[2022,3],[2026,4]]},"339":{"position":[[4,1],[6,4],[22,2],[25,4],[61,1],[63,2],[66,1],[68,4],[73,5],[84,1],[88,2],[91,4],[96,2],[105,1],[129,1],[131,2],[139,1],[169,1],[184,1],[186,2],[191,3],[195,2],[205,1],[207,2],[210,2],[238,1],[240,5],[246,2],[251,2],[254,3],[258,2],[270,1],[281,2],[286,3],[301,1],[303,4],[308,2],[311,1],[317,1],[348,1],[350,5],[356,3],[360,2],[378,1],[392,2],[425,1],[455,1],[462,1],[480,2],[489,2],[492,2],[516,1],[518,4],[553,1],[630,1],[648,2],[651,4],[656,3]]},"341":{"position":[[31,3],[35,2],[45,3],[71,1],[73,5],[93,2],[96,1],[117,1],[119,4],[128,1],[146,1],[148,3],[152,3],[161,1],[194,3],[198,4],[217,1],[219,4],[237,1],[239,4],[260,1],[262,4],[280,1],[296,1],[298,3],[312,4],[317,5],[323,1],[325,2],[343,1],[345,4],[350,3],[366,1],[384,3],[395,1],[397,3],[414,1],[416,5],[422,3],[426,1],[428,4],[455,1],[457,5],[463,2],[466,3],[470,7],[478,3],[482,2],[485,3],[493,1],[499,1],[510,3],[514,7],[548,1],[550,3],[554,2],[557,4]]},"343":{"position":[[14,1],[16,3],[45,6],[52,1],[54,3],[58,3],[80,2],[96,1],[98,3],[102,1],[117,1],[138,1],[140,4],[156,3],[160,3],[178,1],[282,1],[303,3],[307,4],[312,1],[314,3],[318,4],[323,3],[331,3],[335,3],[350,2],[365,2],[378,2],[381,2],[384,3],[388,5],[394,3],[402,1],[404,4],[424,1],[426,2],[442,1],[444,4],[463,2],[499,1],[501,6],[508,3],[526,1],[528,5],[534,2],[543,1],[556,2],[559,3],[567,1],[569,5],[575,4],[580,6],[642,1],[644,3],[648,3]]},"345":{"position":[[4,1],[6,4],[20,3],[24,5],[49,1],[51,4],[56,2],[70,3],[74,3],[93,1],[106,1],[108,4],[113,4],[122,1],[146,1],[148,2],[164,2],[181,1],[183,2],[208,3]]},"347":{"position":[[9,2],[12,2],[15,3],[19,2],[22,3],[30,1],[56,1],[93,1],[95,3],[99,5],[120,3],[130,1],[132,4],[152,2],[171,1],[186,1],[188,5],[194,2],[197,3],[201,1],[203,2],[206,3],[210,4],[215,3],[232,4],[254,2],[257,5],[263,2],[270,1],[272,3],[276,4],[281,3],[285,4],[290,5],[296,1],[298,4],[303,3],[307,4],[312,2],[323,1],[325,4],[330,2],[343,2],[363,1],[365,1],[367,3],[376,2],[379,3],[383,2],[418,1],[420,2],[445,1],[447,2],[450,5],[456,3],[460,4],[465,3],[482,1],[484,3],[505,1],[507,6],[514,2],[517,5],[543,1],[545,4],[572,2],[575,4],[585,1],[606,1],[608,2]]},"350":{"position":[[0,3],[9,1],[21,1],[23,2],[26,2],[29,6],[46,1],[48,3],[67,1],[69,5],[80,1],[103,1],[105,2],[115,1],[117,4],[162,2],[165,5],[171,3],[175,1],[177,5],[183,2],[202,1],[204,5],[210,2],[218,1],[233,1],[235,4],[240,3],[244,3],[248,4],[253,3],[308,1],[310,5],[316,3],[344,1],[353,5],[359,3],[363,4],[368,5],[374,3],[382,1],[384,3],[393,1],[409,1],[411,3],[430,1],[454,1],[456,5],[462,3],[470,1],[472,1],[474,3],[478,3],[482,2],[485,5],[552,1],[566,2],[580,1],[592,1],[594,1],[601,1],[603,2],[624,2],[649,1],[651,1],[658,1],[660,1],[730,3],[741,1],[748,2],[751,3],[777,3],[781,6],[801,6],[808,1],[828,3],[832,2],[859,1],[861,2],[864,2],[867,1],[869,3],[899,1],[923,1]]},"352":{"position":[[16,2],[19,1],[24,1],[28,1],[30,4],[50,4],[72,1],[74,2],[84,1],[86,3],[90,1],[92,3],[110,1],[137,1],[149,2],[158,1],[160,2],[180,1],[182,6],[189,2],[197,1],[199,2],[202,5],[208,4],[213,2],[216,1],[218,2],[221,3],[225,3],[234,1],[270,1],[281,1],[283,1],[285,2],[288,2],[291,4],[296,2],[299,3],[303,3],[307,4],[312,2],[335,1],[352,2],[362,2],[365,5],[371,1],[373,3],[386,2],[389,3],[393,1],[395,3],[419,1],[421,4],[426,4],[450,1],[452,5],[458,2],[461,3],[475,1],[477,4],[482,4],[487,5],[507,1],[534,1],[549,1],[551,4],[556,1],[558,3],[562,3],[566,5],[572,3],[586,3],[595,1],[597,2],[600,3],[604,3],[608,4],[613,2],[616,3],[620,1],[622,4],[632,2],[652,1],[667,3],[671,2],[674,5],[680,3],[684,4],[689,2],[692,6],[699,2],[711,2],[714,3],[718,1],[720,3],[724,4],[729,3],[733,4],[738,2],[741,1],[748,1],[750,4],[772,1],[782,3],[786,5],[792,2],[795,4],[800,4],[805,2],[808,1],[820,2],[823,2],[826,5],[832,2],[835,4],[840,4],[845,2],[848,2],[861,2],[864,2],[867,5],[873,3],[883,1],[892,2],[895,5]]},"354":{"position":[[5,1],[7,3],[24,1],[26,5],[123,3],[132,1],[134,2],[137,5],[152,2],[155,4],[160,3],[164,4],[169,3],[173,2],[176,5],[182,1],[184,3],[188,5],[207,1],[209,4],[214,5],[220,2],[223,3],[249,3],[253,5],[259,3],[263,3],[267,5],[288,1],[290,5],[296,1],[300,1],[302,4],[325,1],[327,3],[344,3],[348,4],[353,3],[357,4],[386,1],[406,1],[428,2],[431,5],[455,3],[459,2],[462,1],[464,3],[468,1],[470,2],[473,3],[490,1],[492,4],[497,2],[518,1],[520,1],[524,1],[526,5],[532,1],[534,3],[538,4],[578,4],[583,2],[606,1],[608,5]]},"356":{"position":[[0,3],[9,2],[30,1],[32,2],[56,2],[59,3],[70,4],[75,6],[96,1],[98,4],[103,2],[123,1],[144,1],[146,4],[151,2],[154,5],[160,3],[171,1],[173,3],[177,3],[181,3],[185,3],[189,2],[192,4],[202,1],[224,1],[226,3],[230,2],[233,2],[249,2],[285,1],[287,7],[299,1],[306,1],[308,6],[330,2],[333,3],[348,1],[350,4],[355,4]]},"358":{"position":[[0,3],[9,1],[20,2],[23,3],[27,2],[50,1],[74,1],[76,4],[81,4],[118,1],[163,1],[165,5],[175,1],[192,1],[194,2],[203,1],[205,2],[218,1],[237,1],[239,4],[244,3],[256,1],[261,3],[277,1],[279,4],[299,1],[301,5],[345,1],[347,2],[412,1],[430,1],[432,5],[455,1],[523,1],[535,1],[558,3],[598,1],[600,2],[603,4],[608,5],[614,2],[617,3],[643,2],[646,5],[652,3],[677,1],[679,3],[683,3],[693,1],[700,1],[717,1],[719,2],[759,1],[761,5],[803,1],[810,1],[844,1],[846,2],[865,1],[867,4],[885,1],[887,3],[891,3],[895,2],[898,3],[902,1],[904,3],[967,1],[981,2],[1002,1],[1004,1],[1012,2],[1033,2],[1054,1],[1056,1],[1064,1],[1132,3],[1143,1],[1167,3],[1186,1],[1188,3],[1192,1],[1196,1],[1198,4],[1203,2],[1206,4],[1211,3],[1215,4],[1233,1],[1254,1],[1256,6],[1272,1],[1306,1],[1308,2],[1326,2],[1342,1],[1344,3],[1358,1],[1360,5],[1366,6],[1409,1],[1411,4],[1416,3],[1420,3],[1438,1],[1453,1],[1455,2],[1458,3],[1469,1],[1471,3],[1475,4],[1480,2],[1483,3],[1487,3]]},"360":{"position":[[26,1],[28,4],[33,4],[53,1],[55,5],[97,1],[104,1],[119,1],[121,2],[124,2],[127,4],[132,2],[151,1],[153,4],[169,1],[171,3],[175,4],[185,1],[201,1],[203,2],[221,1],[223,4],[228,1],[233,4],[257,1],[259,2],[262,4],[267,5]]},"362":{"position":[[0,2],[8,1],[19,2],[22,3],[26,2],[29,3],[40,1],[42,7],[50,2],[53,3],[66,2],[69,3],[73,4],[106,3],[110,3],[114,4],[119,5],[129,2],[139,2],[142,4],[169,1],[171,2],[174,5],[180,6],[197,5],[203,2],[228,1],[230,2],[233,2],[236,2],[239,4],[244,5],[250,2],[253,2],[256,4],[261,4]]},"366":{"position":[[10,1],[12,2],[20,1],[22,7],[34,1],[36,5],[42,3],[55,2],[58,1],[60,1],[62,3],[71,1],[73,2],[91,1],[93,3],[97,5],[103,2],[106,3],[110,3],[114,3],[131,1],[133,4],[138,5],[144,2],[147,3],[220,1],[231,1],[233,4],[238,3],[249,5],[255,4],[265,3],[269,3],[278,3],[282,3],[286,3],[290,5],[309,2],[312,3],[316,2],[319,5],[325,4],[330,3],[339,1],[341,3],[349,1],[351,2],[354,4],[382,5]]},"368":{"position":[[5,2],[17,1],[19,2],[25,2],[48,1],[60,1],[62,5],[73,2],[89,3],[93,2],[103,1],[105,4],[129,1],[131,3],[135,2],[138,6],[145,4],[150,2],[153,3],[164,1],[166,4],[184,1],[186,5],[192,3],[205,2],[236,1],[238,5],[244,3],[248,3],[252,1],[278,1],[280,2],[305,1],[307,6]]},"370":{"position":[[22,1],[34,7],[47,2],[50,3],[54,3],[58,6],[65,1],[69,2],[85,1],[94,1],[96,5],[102,3],[109,1],[133,1],[135,6]]},"374":{"position":[[3,2]]},"376":{"position":[[3,5],[9,2],[12,3],[16,1],[18,3],[24,2],[27,3],[31,1],[33,3],[37,3],[50,1],[52,2],[55,4],[60,5],[66,2],[74,1],[137,1],[158,1],[160,2],[163,2],[166,3],[175,2],[188,3],[192,1],[194,4],[209,1],[223,1],[225,5],[247,2],[250,2],[258,3],[262,4],[267,4],[278,1],[286,4],[291,2],[301,1],[308,2],[323,1],[325,5],[331,3],[335,4]]},"378":{"position":[[0,4],[38,1],[40,4],[64,1],[66,3],[75,1],[86,3],[90,6],[116,1],[130,2],[153,2],[156,2],[159,3],[163,4]]},"380":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"382":{"position":[[17,1],[47,1],[56,1],[58,4],[67,1],[87,3],[91,2],[94,4],[99,2],[102,2],[132,2],[135,3],[139,3],[143,2],[156,3],[160,5],[166,4],[171,2],[174,2],[185,1],[187,2],[214,1],[240,1],[242,2],[245,2],[263,1],[265,3],[269,1],[271,2],[291,1],[303,1],[315,1],[317,3],[339,1],[347,6],[359,2],[363,1],[381,2]]},"384":{"position":[[0,3],[7,1],[9,2],[12,3],[16,2],[19,1],[21,2],[24,4],[29,4],[34,2],[37,3],[41,3],[45,3],[49,2],[52,4],[57,2],[60,5],[90,1],[111,2],[114,3],[123,2],[126,2],[129,3],[133,2],[136,1],[138,3],[142,1],[144,2],[147,5],[153,3],[157,4],[166,1],[178,3],[182,2],[206,3],[223,1],[225,4],[230,3],[234,4],[239,3],[243,2],[246,1],[248,2],[251,4],[256,2],[259,2],[279,1],[292,2],[314,1],[316,3],[320,2],[323,2],[326,2],[329,2],[332,2],[350,3],[354,2],[361,1],[373,1],[375,2],[407,1],[409,4],[414,3],[418,2],[430,2],[433,3],[451,1],[464,2],[467,3],[497,1],[499,4],[504,3],[517,2],[520,1],[522,1],[524,5],[530,2],[533,2],[536,2],[539,2],[542,2],[574,1],[587,1],[589,2],[592,4],[597,4],[602,4],[607,2],[610,3],[627,2],[630,2],[633,4],[638,3],[642,1],[663,1],[665,3],[669,2],[672,3],[676,5],[682,3],[686,2],[689,3],[693,3],[697,2],[700,3],[704,4],[709,2],[712,2],[715,4],[720,2],[723,5],[763,1],[765,3],[769,3],[792,1],[809,1],[811,2],[814,3],[818,2],[830,1],[859,3],[863,4],[892,1],[913,5],[919,4],[943,1],[945,2],[966,1],[974,1],[976,3],[984,1],[986,3],[1000,1],[1021,1],[1023,1],[1025,3],[1029,4],[1039,2],[1063,1],[1065,3],[1069,4],[1074,3],[1078,2],[1081,3],[1109,1],[1111,4],[1116,2],[1119,2],[1122,2],[1130,1],[1132,5],[1138,1],[1140,2],[1143,3],[1147,5],[1153,1],[1155,3],[1159,3],[1167,1],[1182,1],[1189,1],[1191,3],[1195,1],[1197,3],[1201,2],[1204,4],[1209,5]]},"386":{"position":[[0,3],[4,2],[12,1],[43,1],[45,6],[52,5],[58,3],[81,1],[83,4],[88,2],[91,2],[94,1],[109,1],[111,5],[117,3],[121,3],[125,1],[127,2],[130,3],[138,1],[168,1],[170,4],[179,1],[181,3],[185,1],[187,3],[191,2],[194,5],[207,3],[215,1],[228,1],[248,2],[251,3],[255,1],[257,4],[262,1],[264,2],[267,2],[270,3],[274,3],[278,3],[282,4],[287,2],[290,2],[297,1],[299,3],[303,3],[307,2],[310,4],[315,2],[318,3],[322,4],[327,3],[331,2],[334,1],[336,3],[340,2],[343,3],[347,2],[350,2],[353,2],[360,3],[388,1],[409,2],[417,1],[419,2],[422,2],[429,3],[437,1],[458,3],[462,3],[466,4],[488,1],[490,2],[493,2],[496,2]]},"388":{"position":[[3,1],[26,3],[30,2],[51,1],[67,1],[69,4],[74,2],[82,3],[111,4],[116,2],[126,2]]},"391":{"position":[[6,1],[33,1],[35,3],[39,3],[68,1],[70,3],[98,1],[130,1]]},"393":{"position":[[6,1],[8,3],[30,1],[43,3],[47,2]]},"395":{"position":[[0,3],[13,1],[34,1],[36,1],[48,1],[50,3],[54,3],[62,1],[64,4],[69,1],[71,2],[74,5],[91,3],[95,5],[101,3],[128,1],[130,2],[133,2],[142,4],[166,1],[168,3],[172,5],[178,2],[188,1],[190,3],[199,1],[216,5],[235,1],[246,1],[248,2]]},"397":{"position":[[8,2],[111,1],[113,3],[133,2],[136,3],[146,1],[148,3],[152,1],[159,1],[161,2],[164,2],[167,4],[172,2],[184,3],[188,2],[200,2],[203,2],[206,1],[208,2],[216,2],[219,1],[221,3],[225,3],[229,2],[232,4],[237,3],[241,2],[260,2]]},"399":{"position":[[14,1],[28,1],[30,3],[34,2],[37,2],[40,2],[43,3],[47,1],[54,3],[58,3],[62,2],[65,3],[69,2],[72,2],[75,2],[78,2],[81,4],[86,5],[92,5],[98,4],[107,2],[124,1],[126,1],[128,3],[132,4],[137,1],[139,1],[141,2],[144,2],[163,3],[167,2],[170,2],[173,8],[186,1],[193,2],[200,2],[203,3],[207,1],[209,1],[211,2],[214,2],[217,3],[221,2],[224,3],[228,3],[232,3],[242,1],[244,3],[248,2],[251,3],[255,6],[262,2],[265,2],[272,1],[274,2],[291,1],[313,1],[326,1],[328,2],[331,2],[344,1],[350,1],[352,4],[357,2],[365,1],[372,2],[389,1],[391,3],[395,1],[397,1],[399,4],[404,2],[413,1],[415,2],[429,2],[432,3],[440,1],[442,4],[447,2],[454,3],[458,3],[462,3],[470,1],[476,4],[481,2],[484,3],[488,1],[490,5],[496,3],[500,2],[503,3],[507,2],[510,3],[514,3],[518,3],[522,3],[531,3],[535,3],[539,2],[551,2],[554,3],[558,3],[572,3],[576,4],[581,1],[583,3],[591,1],[602,2],[605,1],[607,2],[610,2],[613,3],[617,1],[619,3],[623,2]]},"401":{"position":[[14,1],[16,3],[20,2],[23,3],[37,3],[41,2],[44,1],[46,4],[60,2],[63,2]]},"403":{"position":[[14,1],[16,4],[21,2],[24,1],[26,3],[30,3],[34,3],[38,3],[42,4],[47,3],[51,3],[55,2],[58,2],[61,1],[63,3],[67,3],[71,4],[76,4],[87,1],[89,2],[116,1],[124,1],[126,1],[128,3],[132,2],[135,2],[138,2],[141,2],[144,4],[153,1],[155,2],[158,3],[162,2],[165,4],[170,4],[175,3],[179,2],[191,1],[218,1],[220,3],[224,4],[229,3],[233,3],[237,1],[239,2],[266,1],[268,3],[272,1]]},"405":{"position":[[10,1],[12,3],[16,3],[20,1],[22,2],[25,2],[56,5],[62,4],[67,1],[69,1],[71,2],[74,3],[78,3],[86,1],[88,3],[92,3],[96,5],[102,2],[105,3],[109,3],[113,3],[117,2],[120,2],[123,3],[127,4],[132,4],[137,5],[143,2],[155,1],[157,3],[161,3],[165,4],[192,4],[201,1],[203,2],[206,3],[210,4],[234,1],[236,4],[241,1],[243,4],[248,2],[251,3],[255,2]]},"407":{"position":[[14,1],[16,2],[19,3],[23,3],[40,1],[42,2],[45,3],[49,1],[51,1],[53,5],[59,2],[62,1],[64,2],[67,4],[86,1],[88,4],[93,4],[98,3],[102,1],[104,4],[109,3],[113,2],[116,3],[120,2],[123,2],[130,1],[132,4],[137,2],[140,3],[144,2],[156,1],[158,3],[162,3],[166,4],[175,2],[178,3],[182,3],[196,3],[200,4],[205,5],[211,1],[213,2]]},"409":{"position":[[0,2],[3,2],[17,1],[19,3],[27,1],[29,2],[43,1],[45,2],[62,1],[64,2],[67,3],[90,1],[107,1],[111,1],[113,5],[123,3],[129,1],[131,2],[138,2],[141,1],[143,3],[151,1],[153,2],[206,1],[208,3],[212,2],[215,2],[224,1],[237,1],[245,1],[253,2],[256,3],[275,3],[279,3],[283,4],[297,2],[300,2],[303,2],[310,1],[312,4],[317,3],[321,2],[324,4],[329,4],[334,3],[338,2],[355,1],[357,3],[371,2],[374,1],[376,5],[382,3],[386,2],[395,4],[403,2],[408,2],[411,2],[420,1],[436,1],[438,4],[443,3],[456,1],[458,3],[462,3],[466,3],[489,2],[492,2],[495,2],[498,2],[512,5],[518,3],[527,3],[534,1],[536,2],[550,4],[576,1],[578,2],[595,1],[597,2],[610,1],[612,4],[624,3],[628,2],[631,2]]},"412":{"position":[[5,2],[8,3],[12,3],[16,3],[20,3],[24,2],[27,3],[31,2],[55,2],[58,3],[62,2],[75,1],[77,1],[79,2],[82,2],[85,3],[108,1],[110,3],[114,4],[119,2],[122,2],[146,1],[148,3],[152,2],[155,3],[159,4],[164,5],[170,2],[180,2],[183,2],[186,3],[190,2]]},"414":{"position":[[5,1],[18,2],[21,3],[25,3],[29,4],[55,1],[57,4],[62,2],[65,4],[70,2],[88,1],[90,2],[93,2],[96,4],[101,3],[109,3],[134,1],[136,2],[146,2],[149,5],[166,1],[168,4],[173,4],[182,2]]},"416":{"position":[[0,2],[8,1],[10,3],[14,2],[17,3],[21,3],[25,3],[48,2],[51,5],[71,1],[73,1],[75,1],[77,3],[81,3],[85,1],[87,3],[102,1],[104,3],[122,1],[124,3],[128,2],[131,3],[135,3],[139,3],[143,3],[147,2],[155,1],[157,4],[162,2],[165,3],[169,2],[172,1],[174,3],[178,2]]},"418":{"position":[[14,1],[47,1],[49,3],[53,2],[56,4],[61,2],[64,1],[66,1],[68,2],[71,3],[75,2],[78,4],[83,6],[90,3],[94,2],[97,2],[100,3]]},"420":{"position":[[0,2],[3,1],[14,1],[16,2]]},"422":{"position":[[0,4],[5,4],[10,3],[14,3],[18,3],[22,5],[28,4],[57,1],[65,1],[67,2],[70,4],[75,3],[79,2],[82,2],[85,2],[88,3],[118,2],[121,2],[130,3],[134,3],[138,4],[143,2],[146,2],[149,2]]},"424":{"position":[[0,4],[5,3],[9,4],[14,3],[18,2],[21,3],[25,3],[29,3],[33,4],[38,3],[42,2],[45,3],[55,4],[60,6],[74,1],[76,3],[80,6],[95,1],[97,3],[101,3],[105,3],[109,6],[116,3],[120,3],[124,7],[132,1],[134,6],[167,1],[169,3],[173,3],[180,4],[185,3],[189,3],[196,1],[201,3],[205,3],[209,2],[212,5],[218,2],[231,3],[235,3],[239,3],[243,5],[256,3],[266,3],[280,1],[296,1],[298,2],[306,3],[310,2],[313,2],[329,1],[331,3],[354,1],[356,4],[372,1],[374,2],[397,3],[420,1],[422,1],[429,4],[434,3],[438,3],[446,1],[448,4],[460,1],[462,4],[467,3],[471,3],[478,3],[496,1],[498,4],[503,4],[508,2]]},"426":{"position":[[0,3],[15,1],[17,4],[22,3],[26,5],[46,1],[48,2],[72,2],[75,1],[77,2],[80,2],[83,2],[86,3],[115,1],[124,1],[126,2],[141,5],[161,1],[163,3],[167,5],[173,4],[178,1],[180,2],[192,5],[202,4],[207,1],[209,4],[214,4],[219,2],[222,1],[224,3],[242,2],[264,1],[286,1],[288,2],[306,3],[324,1],[362,1],[368,1],[370,1],[372,3],[376,1],[378,2],[386,3],[390,2],[393,3],[397,2],[400,4],[405,2],[412,1],[414,3],[430,1],[432,4],[455,1],[461,2],[464,3],[468,3],[472,6],[490,1],[492,3],[496,2],[499,1],[501,1],[503,2],[506,3],[525,1],[527,3],[531,1],[533,3],[537,3],[541,7],[549,2],[552,2],[555,2],[558,2],[565,3],[583,1],[585,5],[591,2],[594,5],[600,3],[604,1],[606,1],[608,2],[611,1],[613,2],[616,5],[626,1],[628,4],[633,2],[636,2]]},"428":{"position":[[0,1],[2,3],[6,2],[9,3],[13,2],[16,1],[18,2],[21,3],[25,4],[30,3],[34,2],[47,3],[51,2],[72,1],[74,2],[176,2],[179,4],[197,2],[200,4],[205,2],[208,3],[212,2],[284,1],[286,4],[291,5],[297,3],[301,4],[316,3],[320,5],[326,3],[330,3],[334,2],[337,3],[341,3],[349,1],[351,4],[356,3],[360,2]]},"430":{"position":[[14,1],[19,2],[32,3],[36,4],[41,5],[47,2],[50,3],[54,3],[58,2],[85,1],[96,3],[114,1],[116,2],[119,3],[123,3],[127,5],[147,1],[149,3],[153,1],[158,1],[175,3],[179,3],[203,1],[205,3],[209,2],[212,1],[214,5],[220,2],[223,3],[241,3],[245,3],[249,2],[252,2]]},"432":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"434":{"position":[[28,1],[30,3],[39,1],[41,2],[54,4],[59,5],[107,1],[109,6],[116,3],[120,3],[124,3],[132,1],[138,2],[161,1],[179,5],[201,1],[214,3],[218,2],[221,3],[225,1],[227,4],[232,4],[237,2],[240,2],[243,3],[247,3],[251,2],[254,4],[259,2],[262,3],[274,1],[276,5],[286,1],[299,2],[302,2],[324,1],[326,3],[330,1],[332,3],[357,1],[370,1],[372,5],[397,1],[399,4],[404,3],[408,3],[440,3],[444,3],[448,2],[451,4],[467,1],[469,5],[483,1],[485,2],[496,1],[498,5],[524,1],[526,3],[530,4],[535,5],[541,3],[545,3],[549,3],[559,2],[571,2],[579,3],[583,3],[595,2],[607,4],[612,2],[619,2],[622,3],[626,3],[634,3],[638,2],[645,1],[647,2],[650,3],[654,4],[669,1],[671,2],[696,2],[704,1],[717,1],[719,4],[724,4],[729,3],[750,1],[752,5],[758,5],[764,3],[768,4],[773,3],[844,2],[847,2],[850,5]]},"436":{"position":[[4,1],[6,3],[10,3],[14,3],[39,3],[43,3],[51,5],[57,6],[64,3],[68,3],[72,4],[77,3],[81,3],[85,3],[89,6],[96,3],[100,3],[104,2],[107,2],[110,5],[116,3],[120,3],[124,3],[128,3],[132,2],[135,3],[139,2],[146,4],[151,3],[155,2],[158,4],[163,2],[166,3],[170,4],[175,4],[180,1],[182,4],[187,2],[190,5],[239,1],[241,3],[245,2],[248,2],[265,3],[269,5],[275,1],[277,1],[279,4],[284,3],[292,4],[297,4],[302,5],[308,3],[317,1],[339,1],[341,4],[346,3],[350,2],[353,1],[364,1],[388,1],[390,5],[396,3],[400,3],[404,5],[410,1],[412,3],[416,2],[428,1],[444,2],[452,5],[458,4],[472,1],[479,1],[481,4],[486,1],[488,2],[491,4],[503,1],[514,3],[556,1],[577,3],[597,5],[603,4],[615,1],[647,2],[656,1],[658,2],[665,1],[682,1],[684,5],[701,4],[706,2],[709,2],[712,1],[714,3],[718,3],[722,3],[726,3],[739,1],[741,2],[744,2],[751,1],[753,3],[757,2],[771,2],[785,3],[789,3],[804,1],[817,2],[835,1],[841,3],[845,6],[852,4],[857,2],[864,1],[866,1],[868,4],[873,5],[879,4],[884,2],[887,3],[891,3],[895,1],[897,4],[902,4],[907,3],[915,1],[921,1],[923,4],[939,3],[943,1],[945,4],[975,2],[978,3],[994,1],[996,5],[1002,2],[1005,1],[1007,2],[1010,3],[1014,3],[1018,2],[1021,3],[1025,3],[1029,3],[1037,6],[1044,2],[1047,3],[1071,3],[1095,1],[1113,3],[1117,4],[1127,1],[1135,1],[1145,2],[1148,4],[1153,2],[1156,5],[1162,2],[1168,2],[1175,2],[1185,1],[1187,5],[1193,3],[1197,3],[1201,2],[1204,4],[1209,5],[1215,3],[1219,3],[1223,3],[1227,3],[1240,3],[1244,5],[1250,2],[1253,3],[1265,1],[1267,5],[1273,2],[1295,1],[1311,1],[1313,3],[1317,1],[1319,3],[1323,2],[1347,7],[1355,5],[1361,2],[1364,3],[1368,1],[1370,2],[1373,4],[1386,1],[1388,3],[1414,3],[1424,1],[1452,1],[1454,4],[1459,3],[1463,3],[1470,3],[1474,4],[1479,4],[1484,3],[1488,2],[1494,2],[1497,3],[1501,3],[1505,3],[1509,4],[1531,2],[1538,2],[1549,4],[1570,1],[1572,5],[1578,3],[1582,2],[1588,2],[1602,1],[1613,1],[1615,4],[1620,5],[1631,2],[1634,3],[1655,3],[1679,6],[1686,2],[1689,2],[1692,4],[1697,4],[1702,3],[1706,5],[1712,2],[1715,3],[1738,1],[1740,4],[1745,2],[1756,1],[1758,4],[1783,1],[1785,4],[1790,4],[1795,2],[1798,5],[1804,3],[1822,3],[1826,5],[1832,1],[1834,3],[1851,1],[1853,3],[1857,3],[1861,3],[1879,1],[1881,3],[1885,4],[1896,1],[1898,3],[1905,3],[1909,4],[1928,3],[1940,1],[1942,3],[1946,2],[1956,1],[1967,2],[1990,1],[2010,1],[2016,2],[2035,1],[2037,6],[2052,1],[2054,3],[2058,1],[2080,2],[2083,3],[2090,4],[2095,2],[2116,1],[2132,1],[2134,3],[2138,1],[2140,2],[2143,3],[2147,3],[2151,2],[2154,3],[2158,3],[2162,2],[2165,2],[2168,1],[2170,3],[2178,6],[2185,5],[2191,2],[2194,3],[2206,1],[2208,3],[2216,3],[2231,1],[2233,3],[2237,3],[2241,2],[2244,5],[2250,3],[2268,3],[2272,5],[2278,3],[2288,2],[2300,2],[2308,5],[2314,2],[2330,4],[2335,5]]},"439":{"position":[[4,1],[6,4],[11,2],[14,3],[27,1],[29,4],[34,3],[38,4],[54,2],[57,5],[63,3],[67,2],[70,3],[74,4],[79,3],[106,1],[112,5],[129,1],[131,2],[134,2],[137,3],[141,2],[144,2],[147,3],[151,6],[168,2],[175,3],[179,2],[182,2],[185,3],[200,2],[213,2],[216,2],[219,3],[223,6],[230,3],[234,4],[239,3],[243,3],[247,3],[251,2],[263,1],[265,2],[275,1],[277,3],[281,4],[286,5]]},"441":{"position":[[5,1],[7,1],[9,3],[13,4],[18,4],[23,3],[27,3],[31,3],[35,4],[50,3],[54,3],[63,1],[65,2],[85,2],[101,1],[103,5],[109,5],[126,1],[143,1],[145,5],[155,1],[170,1],[184,1],[186,2],[201,1],[218,1],[220,5],[226,3],[259,1],[286,1],[327,2],[339,1],[341,2],[344,6],[355,1],[357,3],[361,2],[368,3],[372,2],[375,1],[377,2],[380,3],[408,1],[432,1],[434,4]]},"443":{"position":[[0,1],[2,4],[19,2],[22,5],[28,4],[50,1],[52,4],[64,1],[85,1],[93,3],[102,1],[104,5],[121,3],[125,1],[127,2],[130,3],[134,2],[196,5],[217,2],[231,2],[234,2],[237,4],[251,1],[268,5],[274,5],[280,2],[283,4],[310,1],[312,5],[318,3],[322,1],[324,5],[330,1],[332,2],[335,3],[339,3],[343,2],[346,5],[368,1],[374,1],[376,3],[380,5],[386,2],[389,3],[393,2],[396,5],[402,4],[425,3],[434,1],[449,1],[451,2],[454,5],[465,1],[467,2],[470,3],[474,2],[477,1],[479,1],[481,3]]},"445":{"position":[[0,1],[2,5],[8,4],[28,3],[60,2],[63,4],[68,5],[74,2],[89,1],[91,3],[95,2],[98,4],[115,3],[119,2],[122,4],[127,2],[130,4],[135,3],[139,3],[143,3],[158,1],[160,5],[175,4],[185,1],[201,1],[203,5],[229,1],[231,2],[234,3],[238,3],[242,6],[258,1],[260,4],[265,3],[269,2],[272,5],[278,3],[282,4],[297,4],[311,1],[313,3],[325,1],[327,5],[343,4],[348,3],[372,1],[374,3],[378,1],[380,4],[396,3],[400,3],[404,2],[407,1],[409,3],[413,5],[419,1],[421,4],[426,3],[430,3],[434,2],[440,2],[447,1],[461,1],[463,5]]},"447":{"position":[[4,1],[20,1],[22,5],[28,5],[34,2],[37,1],[39,4],[44,3],[71,1],[78,1],[80,4],[85,4],[90,3],[101,3],[110,1],[112,3],[116,1],[118,3],[122,5],[128,2],[131,4],[155,1],[162,1],[164,2],[167,3],[176,2],[179,3],[183,2],[186,3],[190,2],[193,4],[210,3],[219,1],[224,2],[236,1],[238,3],[242,2],[245,3],[256,1],[258,3],[262,1],[275,3],[279,4],[284,3],[288,3],[292,3],[300,2],[323,1],[325,4],[343,2],[380,2],[383,5],[405,1],[436,1],[441,1],[443,2],[457,1],[463,1],[465,4],[470,7],[478,2],[491,3],[495,4],[504,2],[526,1],[528,3],[532,3],[536,4],[541,3],[545,2],[548,3],[552,3],[566,4],[571,4],[580,1],[598,1],[600,4],[605,2],[616,1],[618,5],[624,2],[633,2],[652,1],[654,5],[673,1],[681,1],[683,5],[689,3],[707,1],[729,2],[732,3],[739,2],[742,3],[746,1],[748,3],[752,3],[765,1],[775,1],[777,3],[781,2],[784,3],[788,3],[792,3],[800,1],[802,4],[820,1],[822,2],[835,4],[840,2],[843,5],[857,1],[872,3],[895,1],[897,3],[901,2],[904,3],[908,3],[926,1],[928,5],[934,3],[938,4],[943,5]]},"449":{"position":[[10,2],[33,1],[35,3],[39,3],[43,3],[56,1],[58,4],[63,4],[68,3],[72,2],[75,3],[88,1],[90,2],[103,2],[106,3],[110,1],[112,2],[115,3],[119,4],[133,2],[144,2],[147,3],[151,3],[155,2],[158,2],[169,1],[171,5],[177,2],[180,3],[184,3],[188,8],[197,4],[202,4],[207,5],[213,3],[217,3],[221,1],[223,5],[229,2],[232,2],[235,3],[239,3],[250,3],[254,5]]},"451":{"position":[[0,3],[11,2],[14,2],[56,2],[59,1],[68,4],[73,2],[76,2],[88,1],[90,4],[95,2],[126,1],[128,2],[131,3],[135,1],[137,3],[141,1],[143,5],[158,1],[167,3],[191,4],[196,5],[212,5],[218,4],[223,2],[226,3],[230,3],[238,4],[243,3],[247,2],[250,3],[262,4],[267,3]]},"453":{"position":[[21,1],[23,4],[28,1],[37,1],[39,3],[43,3],[47,1],[53,3],[57,2],[69,4],[74,5],[80,3],[96,1],[154,1]]},"455":{"position":[[46,3],[50,3],[54,3],[69,6],[92,2],[95,3],[99,6],[113,1],[124,1],[126,5],[152,3],[167,3],[171,3],[181,1],[274,1],[276,5],[282,3],[297,9],[341,1],[355,2],[395,1],[410,1],[412,5],[418,2],[421,4],[460,1],[462,3],[473,4],[515,1],[517,2],[520,3],[531,3],[535,3],[547,2],[550,5],[556,3],[562,2],[576,6],[594,3],[646,1],[657,2],[660,5],[666,3],[686,1],[753,1],[755,4],[760,1],[762,2],[789,1],[800,1],[802,5],[808,3],[812,3],[816,4],[829,1],[831,5],[837,5],[861,1],[867,2],[886,1],[888,6],[895,1],[897,4],[914,2],[917,3],[921,5],[927,3],[950,1],[967,2],[970,1],[972,4],[977,5],[983,2],[998,1],[1016,1],[1027,2],[1049,1],[1051,5],[1057,3],[1061,5],[1067,3],[1087,1],[1089,4],[1094,2],[1097,3],[1101,4],[1106,3],[1133,1],[1135,5],[1141,3],[1145,3],[1149,2],[1160,1],[1162,4],[1167,2],[1170,2],[1173,3],[1177,3],[1181,4],[1186,3],[1190,2],[1193,3],[1197,6]]},"457":{"position":[[0,3],[16,2],[19,6],[59,1],[65,1],[67,5],[73,3],[86,1],[88,4],[93,2],[96,3],[100,3],[104,3],[108,2],[111,5],[117,3],[121,4],[134,1],[136,2],[139,3],[143,4],[148,2],[151,1],[153,2],[156,2],[159,5],[165,1],[176,2],[179,1],[277,1],[292,2],[295,5],[301,3],[305,2],[308,5],[314,3],[326,1],[348,1],[350,3],[354,2],[357,4],[362,4],[371,1],[382,1],[384,2],[394,3],[398,2],[401,3],[405,1],[407,3],[411,4],[416,2],[428,2],[431,3],[435,3],[439,2],[450,1],[452,5],[462,2],[465,1],[474,1],[476,6],[483,2],[486,2],[489,3],[498,1],[534,1],[536,4],[550,3],[554,3],[558,3],[562,5],[572,1],[584,1],[607,2],[610,2],[613,3],[617,2],[655,1],[657,5],[667,1],[669,2],[680,3],[704,2],[707,3],[711,4],[716,3],[729,1],[731,2],[740,3],[744,4],[773,1],[775,5],[781,3],[785,3],[797,1],[811,1],[841,3],[845,3],[884,1],[886,2],[898,1],[900,4],[905,5],[917,3],[925,1],[927,2],[930,2],[933,2],[936,4],[941,3],[945,3],[949,3],[953,2],[956,3],[960,6],[967,1],[969,2],[978,5],[984,4],[1003,1],[1013,1],[1015,5],[1021,4],[1034,1],[1036,4],[1041,3],[1045,2],[1070,1],[1085,1],[1087,5],[1097,2],[1100,3],[1112,1],[1114,4],[1119,2],[1122,2],[1129,1],[1131,5],[1137,3],[1141,2],[1152,1],[1154,3],[1158,4],[1163,2],[1174,1],[1176,5],[1182,4],[1193,4],[1198,5],[1204,3],[1208,4],[1227,1],[1229,3],[1233,4],[1238,3],[1242,3],[1246,3],[1250,3],[1254,3],[1258,2],[1261,3],[1265,3],[1269,3],[1273,4],[1278,3],[1286,1],[1288,4],[1293,3],[1297,3],[1301,4],[1315,2],[1318,3],[1322,2],[1325,2],[1328,3],[1332,3],[1336,5],[1342,3],[1346,2],[1349,2],[1356,3],[1360,4],[1365,6],[1372,1],[1374,5],[1389,1],[1391,4],[1396,3],[1400,1],[1402,3],[1406,2],[1409,3],[1413,2],[1416,1],[1418,4],[1430,1],[1441,3],[1445,2],[1448,3],[1452,5]]},"459":{"position":[[0,2],[12,2],[15,3],[35,4],[40,3],[65,1],[79,1],[81,4],[90,1],[92,3],[103,1],[105,5],[128,1],[210,1],[276,2],[279,2],[294,1],[390,2],[393,2],[413,1],[422,3],[426,3],[430,2],[433,2],[436,1],[498,2],[508,1],[510,2],[513,3],[521,2],[540,1],[542,5],[557,1],[559,2],[562,4],[573,1],[575,5],[581,2],[594,2],[597,2],[600,2],[603,3],[607,2],[610,3],[624,2],[634,3],[645,3],[649,2],[661,2],[664,3],[684,2],[694,3],[698,6],[705,3],[709,3],[720,3],[724,3],[728,3],[736,2],[739,3],[743,4],[748,3],[759,3],[763,3],[767,5],[773,3],[777,3],[781,2],[784,2],[790,2],[800,3],[804,4],[809,3],[813,2],[816,1],[818,2],[830,1],[832,5],[838,4],[843,3],[847,2],[850,2],[856,2],[866,1],[868,3],[872,4],[877,2],[880,3],[884,6]]},"461":{"position":[[0,2],[13,1],[28,4],[33,5],[39,1],[41,3],[61,1],[81,3],[85,2],[88,2],[91,3],[95,2],[107,3],[111,5]]},"464":{"position":[[6,1],[50,1],[80,1],[129,1],[131,6],[147,1],[149,5]]},"466":{"position":[[9,2],[27,1],[29,2],[32,3],[41,1],[43,4],[56,5],[77,3],[81,5],[96,2],[99,3],[103,3],[107,4],[112,3],[149,1],[173,3],[185,1],[187,5],[193,2],[196,3],[208,1],[210,4],[223,1],[233,3],[237,3],[241,6],[248,2],[251,3],[259,2],[271,2],[282,1],[284,4],[294,1],[296,3],[300,2],[303,2],[306,3],[310,2],[313,2],[320,3],[324,2],[327,5],[348,1],[350,3],[354,2],[362,1],[364,4],[369,3],[373,3],[377,3],[381,3],[385,5],[391,3],[400,1],[402,4],[425,1],[434,1],[436,5],[454,1],[456,2],[459,3],[463,3],[467,2],[470,4],[489,1],[491,4],[496,3]]},"468":{"position":[[0,2],[7,1],[9,4],[14,1],[16,2],[19,5],[25,4],[35,1],[37,2],[51,1],[53,3],[107,1],[114,1],[116,2],[143,1],[145,4],[183,3],[187,5],[206,1],[216,3],[220,5],[226,1],[228,4],[233,4],[254,5],[260,4],[265,4],[270,3],[274,2],[277,3],[281,1],[283,5],[297,1],[305,1],[307,3],[311,6],[318,3],[329,3],[333,3],[337,1],[339,2],[342,3],[346,5],[352,4],[357,1],[359,3],[363,3],[367,4],[372,4],[377,3]]},"471":{"position":[[8,1],[37,1],[44,2],[47,2],[50,2],[61,2],[69,1],[77,2],[85,1],[98,1],[100,5],[113,3],[117,2],[120,2],[123,3],[127,5],[133,3],[137,3],[145,3],[149,4],[154,3],[174,1],[176,5],[192,5],[198,2]]},"473":{"position":[[15,1],[22,2],[30,1],[32,3],[36,2],[43,2],[57,1],[59,3],[63,5],[69,2],[72,3],[76,2],[79,3],[91,1],[93,1],[95,1],[97,5],[103,1],[105,3],[116,1],[118,3],[122,3],[126,3],[130,4],[135,1],[137,3],[148,1],[158,1],[160,4],[165,3],[169,4],[174,3],[178,5],[193,1],[199,1],[201,4],[206,3],[210,3],[214,2],[217,3],[221,4],[226,5],[232,2],[239,1],[245,1],[247,5],[253,2],[256,6],[263,2],[266,4],[271,2],[279,5],[285,3],[289,1],[291,1],[293,5],[299,4],[308,4],[313,3],[317,4],[322,2],[325,2],[342,3],[346,5]]},"475":{"position":[[8,1],[10,4],[35,3],[39,2],[51,4],[56,3],[60,4],[65,5],[77,2],[80,3],[84,3],[102,1],[104,2],[107,1],[109,2],[112,5],[118,3],[144,2],[157,2],[160,4],[173,2],[184,1],[186,3],[190,4],[204,1],[206,1],[208,1],[210,4],[223,1],[225,4],[247,2],[250,3],[254,4],[259,2],[267,2],[270,4],[275,4],[296,2],[299,7],[307,4],[312,5],[318,5]]},"477":{"position":[[8,1],[14,1],[16,2],[19,2],[22,2],[45,1],[54,2],[57,2],[60,3],[64,5],[70,2],[73,2],[84,1],[105,3],[109,2],[112,3],[121,1],[123,5],[144,1],[152,2],[155,2],[158,5],[164,2],[167,3],[171,3],[175,3],[179,3],[183,4],[188,2],[191,5]]},"479":{"position":[[14,1],[32,3],[36,2],[39,2],[42,2],[52,4],[66,1],[68,2],[71,3],[75,2],[78,1],[86,1],[88,2],[91,2],[94,2],[104,1],[106,2],[109,5],[115,2],[118,1],[120,4],[125,2],[128,4],[133,4],[138,3],[142,4],[147,4],[152,3],[156,3],[160,3],[173,1],[175,3],[188,2],[191,2],[194,4],[199,2],[239,3],[243,3],[247,4]]},"481":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"483":{"position":[[0,2],[13,1],[15,1],[17,2],[20,2],[23,3],[27,2],[81,2],[108,1],[110,2],[113,3],[117,5],[123,2],[140,3],[144,2],[152,1],[154,2],[171,1],[173,3],[184,1],[186,2],[200,3],[204,2],[207,4],[228,1],[254,1],[256,2],[259,2],[262,4],[267,3],[289,1],[291,4],[296,4],[301,2],[304,3],[329,1],[331,3],[356,1],[366,1],[368,2],[371,3],[375,4],[398,5],[404,4],[409,2],[435,1],[446,2],[449,1],[462,1],[464,2],[467,2],[470,3],[479,5],[541,1],[571,2],[574,2],[577,2],[580,3],[584,5],[599,2],[602,2],[613,1],[615,4],[620,4],[625,2],[654,2],[657,5],[663,2],[666,3],[689,1],[691,2],[694,3],[706,1],[737,1],[739,5],[745,3],[749,4],[796,1],[798,5],[849,1],[879,2],[882,3],[904,2],[912,1],[914,2]]},"485":{"position":[[5,1],[7,3],[11,2],[14,2],[17,3],[21,3],[32,2],[35,5],[50,2],[53,3],[57,2],[60,2],[79,1],[90,1],[92,1],[94,3],[98,3],[102,3],[106,2],[109,3],[113,2],[132,1],[134,1],[136,5],[142,3],[146,2],[149,3],[153,2],[156,2],[159,5],[182,2],[185,3],[189,2],[192,1],[194,4],[199,2],[202,3],[206,5],[225,3],[238,1],[254,1],[272,2],[275,1],[277,4],[295,1],[310,3],[314,5],[320,3],[347,2],[368,3],[403,2],[422,1],[424,2],[441,1],[443,3],[447,3],[451,4],[456,3],[460,3],[464,3],[468,3],[472,3],[476,2],[479,2],[482,1],[484,2],[487,4],[510,1],[512,5],[518,4],[523,2],[555,1],[557,2],[560,5],[580,1],[593,3],[597,6],[604,3],[608,3],[612,3],[616,2],[619,4],[634,1],[652,3],[656,2],[659,1],[661,2],[664,2],[667,4],[677,1],[687,1],[702,3],[706,4],[711,3],[715,2],[718,5],[724,1],[726,3],[730,2],[733,2],[736,3],[740,4],[745,2],[748,2],[751,5],[757,4],[762,6],[769,2],[772,5],[778,2],[781,2],[784,3],[788,2],[807,1],[809,1],[811,4],[816,1],[818,3],[822,4],[827,4],[832,2],[835,3],[839,5],[845,5],[870,3],[874,4],[879,2],[898,1],[900,2],[903,3],[907,4],[912,2],[918,2],[921,3],[925,2],[943,4],[948,5],[954,3],[958,2],[961,2],[964,2],[983,1],[985,3],[994,3],[998,4],[1003,3],[1007,3],[1037,2],[1040,2],[1043,3],[1047,4],[1052,4],[1066,3],[1070,2],[1073,3],[1077,1],[1079,2],[1082,3],[1086,2],[1110,1],[1112,6],[1124,1],[1146,3],[1160,1],[1162,5],[1168,3],[1180,1],[1182,2],[1185,3],[1189,4],[1194,2],[1197,2],[1200,4],[1214,3],[1218,4],[1231,1],[1233,2],[1236,3],[1240,6],[1247,4],[1262,1],[1264,5],[1292,1],[1311,1],[1313,5],[1341,1],[1343,4],[1393,1],[1395,5],[1418,1],[1420,5],[1442,1],[1466,1],[1468,4],[1473,4],[1478,3],[1482,2],[1485,2],[1488,3],[1492,2],[1495,3],[1499,2],[1502,2],[1505,4],[1510,6],[1521,3],[1525,2],[1528,4],[1552,2],[1555,5],[1565,3],[1574,2],[1577,6],[1592,1],[1594,5],[1600,5],[1628,1],[1649,1],[1651,5],[1657,3],[1668,1],[1670,2],[1684,4],[1703,1],[1705,2],[1708,3],[1712,2],[1715,3],[1719,5]]},"488":{"position":[[19,1],[37,1],[39,2],[42,3],[61,1],[71,1],[73,3],[93,1],[95,5],[109,1],[120,1],[130,4],[135,2],[138,3],[162,1],[164,2],[167,3],[171,4],[176,2],[179,3],[183,4],[188,3],[192,3],[217,1],[219,4],[224,2],[227,4],[232,4],[237,3],[241,2],[244,4],[278,1],[280,2],[283,4],[300,2],[303,4],[323,1],[339,3],[343,2],[355,1],[357,4],[362,2],[384,1],[386,3],[390,4],[395,2],[398,3],[402,1],[404,2],[407,3],[411,3],[415,3],[419,4],[424,4],[429,3],[456,1],[458,4],[463,1],[465,5],[471,2],[474,2]]},"490":{"position":[[0,3],[11,1],[13,3],[17,2],[34,1],[36,5],[49,1],[51,2],[54,4],[59,2],[62,1],[64,3],[68,4],[73,3],[77,1],[79,4],[94,2],[97,5],[118,1],[129,1],[131,7],[139,1],[141,3],[145,3],[149,3],[153,3],[170,1],[172,4],[177,3],[181,3],[185,1],[187,3],[191,3]]},"492":{"position":[[14,1],[20,3],[24,3],[33,1],[35,5],[49,1],[51,5],[57,3]]},"494":{"position":[[0,1],[2,2],[5,4],[37,1],[39,2],[42,4],[47,3],[51,2],[54,3],[58,5],[64,1],[66,3],[78,1],[96,2],[99,1],[101,2],[104,4],[123,2],[126,3],[130,2],[141,1],[143,2],[146,3],[150,4],[155,2],[158,2],[161,3],[165,2],[177,1],[189,4],[194,4],[199,6],[206,4],[227,1],[229,2],[232,2],[241,1],[243,2],[254,2],[273,2],[276,1],[278,2],[281,3],[285,4],[290,3],[300,3],[312,1],[314,4],[319,5],[333,2],[336,2],[339,2],[342,4],[347,5],[353,3]]},"496":{"position":[[0,1],[2,2],[5,4],[10,3],[37,1],[48,4],[53,3],[57,1],[69,2],[86,1],[88,4],[114,1],[116,5],[122,2],[138,1],[140,2],[143,3],[173,1],[186,1],[188,5],[194,3],[212,1],[257,1],[274,1],[276,5]]},"498":{"position":[[0,1],[8,1],[15,1],[38,1],[54,1],[56,4],[61,2],[89,1],[91,3],[120,1],[122,4],[127,2],[130,3],[134,3],[156,1],[182,2],[185,3],[189,5],[195,1],[202,1],[212,3],[216,6],[228,1],[243,1],[274,1],[276,2],[305,2],[308,6],[320,1],[322,5],[328,3],[338,2],[361,1],[363,4],[368,2],[389,1],[409,1],[411,2],[425,1],[438,1],[456,2],[459,5],[465,3],[482,1],[484,4],[506,1],[508,4],[513,3],[544,1],[546,5],[569,1],[571,4],[576,3],[597,1],[599,4],[604,2],[620,1],[622,4],[627,5],[633,6],[657,1],[659,2],[673,1],[675,3],[687,2],[690,2],[693,3],[708,1],[718,2],[729,4],[734,5],[740,3],[752,1],[771,1],[794,1],[796,2],[816,1],[818,6],[839,2],[857,4],[862,5]]},"500":{"position":[[0,1],[7,1],[17,1],[19,6],[31,1],[46,1],[48,3],[52,3],[56,4],[61,4],[66,2],[69,3],[73,2],[76,2],[84,1],[102,2],[128,1],[130,4],[135,1],[137,2],[164,1],[166,2],[169,3],[173,3],[177,3],[193,1],[195,4],[208,1],[226,1],[256,1],[258,4],[263,2],[296,1],[320,1],[322,4],[335,3],[339,2],[362,1],[364,3],[375,1],[383,3],[415,1],[437,1],[439,1],[441,2],[444,4],[457,1],[492,1],[494,6],[513,1],[526,2],[529,5],[543,1],[572,1],[574,4],[598,1],[600,2],[611,1],[613,3],[617,1],[619,3],[629,1],[648,1],[672,1],[699,2],[702,4],[707,6],[735,1],[737,2],[748,1],[767,2],[783,1],[785,4],[805,1],[824,2],[848,3],[852,5],[858,3],[862,2],[874,1],[876,2],[879,3],[883,3],[908,3],[912,5],[918,3],[922,2],[925,3],[946,1],[948,4],[959,2],[962,2],[965,2],[968,2],[1006,1],[1008,2],[1025,1],[1027,6],[1034,3],[1038,2],[1057,1],[1059,3],[1063,4],[1068,5],[1089,1],[1097,1],[1099,3],[1119,1],[1121,4],[1142,2],[1154,1],[1163,2],[1181,1],[1183,1],[1191,1],[1193,5]]},"502":{"position":[[0,1],[7,1],[17,1],[27,2],[30,7],[51,1],[66,4],[98,1],[100,2],[126,3],[130,3],[134,3],[138,6],[157,1],[165,1],[167,3],[179,1],[196,1],[211,1],[213,2],[216,5],[222,1],[224,3],[236,1],[267,1],[269,5],[275,4],[286,1],[300,1],[302,3],[314,1],[347,1],[349,2],[352,5],[366,1],[398,1],[400,5],[406,2],[409,3],[423,1],[444,2],[486,2],[511,1],[513,3],[517,2],[520,4],[544,1],[546,6]]},"504":{"position":[[0,3],[4,3],[20,2],[23,2],[26,5],[32,4],[37,3],[41,3],[53,1],[114,1],[116,5],[152,3],[156,5],[170,4],[175,1],[177,3],[181,3],[204,1],[206,3],[210,3],[214,2],[220,3],[224,3],[228,3],[240,1],[250,2],[301,1],[303,5],[328,1],[330,4],[350,1],[360,1],[362,2],[365,2],[368,4],[373,1],[375,2],[378,4],[383,4],[388,4],[393,1],[395,2],[416,1],[418,4],[423,3],[427,4],[441,1],[451,1],[461,1],[463,4],[468,3],[472,3],[497,2],[514,1],[516,4],[521,4],[548,1],[550,5],[573,1],[575,3],[601,1],[625,2],[640,5],[660,1],[684,1],[696,3],[700,6],[707,4],[730,1],[732,5],[738,3],[761,3],[765,2],[784,1],[786,5],[792,2],[805,1],[838,1],[840,4],[845,2],[848,3],[852,5],[858,4],[863,3],[867,2],[870,3],[874,4],[879,5],[885,1],[887,2],[890,2],[893,4],[898,2],[901,2],[904,3],[908,2],[911,3],[915,2],[918,2],[921,2],[924,3]]},"506":{"position":[[12,1],[14,1],[16,2],[19,2],[30,1],[32,3],[36,3],[40,4],[45,4],[94,1],[122,1],[124,3],[128,3],[137,1],[139,3],[143,1],[145,3]]},"508":{"position":[[22,1],[32,1],[50,1],[66,2],[93,1],[95,5],[101,3],[105,1],[107,3],[111,3],[123,1],[125,4],[144,1],[146,5],[152,2],[171,1],[173,2],[184,1],[194,2],[197,4],[239,1],[241,3],[245,1],[247,3]]},"510":{"position":[[0,1],[2,5],[22,1],[24,2],[33,3],[37,5],[59,1],[76,1],[86,1],[88,5],[102,1],[112,1],[137,1],[146,1],[148,5],[154,1],[156,3],[168,3],[172,5],[178,5],[184,2],[203,1],[205,1],[207,3],[211,4],[216,3],[251,1],[253,4],[266,1],[276,2],[290,3],[294,5]]},"512":{"position":[[8,1],[30,1],[32,1],[34,2],[37,4],[42,3],[46,1],[48,2],[59,1],[61,4],[86,1],[88,2],[91,2],[109,1],[126,1],[128,2],[149,1],[151,3],[155,1],[157,3],[169,1],[179,1],[181,4],[214,1],[216,2],[244,1],[246,3],[250,1],[252,3]]},"515":{"position":[[0,2],[3,3],[19,5],[25,4],[44,1],[66,1],[68,5],[76,2],[138,6],[145,2],[148,5],[154,2],[157,3],[164,1],[178,1],[180,2],[183,4],[188,3],[192,4],[197,3],[224,1],[226,4],[245,1],[247,2],[267,2],[270,4],[275,3],[279,6],[286,2],[289,4],[306,1],[308,4],[313,5],[319,4],[324,3],[328,2],[331,1],[333,4],[338,1],[340,3],[344,2],[347,3],[351,1],[353,3],[357,3],[361,2],[364,3],[368,5],[374,3],[395,1],[397,4],[402,3],[406,5],[412,7],[420,2],[423,2],[432,2],[435,3],[439,6],[446,2],[463,2],[466,1],[472,1],[474,5],[488,2],[505,1],[544,1],[546,5],[552,3],[556,4],[568,5],[574,3],[578,5],[611,1],[628,2],[631,2],[634,1],[636,3],[640,3],[644,3],[648,3],[652,3],[665,1],[667,1],[669,4],[674,3],[693,1],[695,3],[699,1],[701,2],[704,4],[716,1],[718,2],[721,3],[739,1],[749,5],[763,1],[765,1],[767,2],[770,2],[782,1],[784,5],[790,1],[792,5],[798,2],[811,2],[819,1],[844,1],[857,1],[859,3],[863,6]]},"517":{"position":[[0,3],[19,1],[21,1],[23,4],[37,3],[54,1],[61,1],[66,1],[68,5],[74,2],[77,4],[88,3],[112,1],[122,1],[155,2],[158,5],[172,1],[192,2],[195,6],[209,3],[213,5],[219,3],[231,3],[235,4],[240,3],[252,2],[255,3],[259,3],[263,2],[266,2],[269,3],[273,5],[297,3],[301,2],[309,4],[330,3],[334,3],[338,3],[342,4],[347,1],[349,1],[351,3],[355,4],[360,2],[370,6],[385,6],[392,6],[399,7],[426,3],[453,6],[469,4],[474,3],[478,5],[484,2],[487,2],[490,4],[495,5],[501,2],[504,4],[509,4],[514,8],[523,1],[525,2],[528,5],[543,2],[546,2],[549,2],[552,3],[556,2],[559,3],[563,2],[566,4],[571,3],[575,2],[578,1],[580,2],[587,3],[591,2],[594,4],[599,2],[602,3],[616,2],[619,2],[622,6],[629,2],[632,3],[636,2],[639,3],[643,2],[646,2],[649,2],[660,5],[666,5],[672,2],[675,4],[687,2],[690,3],[694,3],[698,4],[720,6],[727,2],[730,1],[732,2],[735,4],[740,4],[745,2],[748,2],[751,3],[755,2],[758,3],[762,2],[765,3],[774,5],[780,2],[783,2],[791,2],[794,1],[796,2],[799,4],[804,2],[807,3],[811,2],[826,5],[832,3],[836,2],[844,2],[847,3],[860,6],[867,1],[869,2],[872,5],[878,2],[881,3],[885,2],[888,1],[890,1],[892,2],[899,3],[903,3],[907,4],[915,2],[918,2],[921,4],[926,7],[934,2],[937,3],[947,2],[950,3],[954,3],[958,3],[962,3],[966,3],[970,2],[983,6],[990,2],[993,5],[1003,3],[1007,3],[1011,2],[1020,5],[1057,6],[1064,2],[1120,2],[1123,3],[1127,3],[1131,4],[1136,2],[1139,4],[1144,6],[1166,1],[1173,4],[1184,3],[1188,3],[1192,4],[1197,4],[1202,2],[1205,2],[1208,3],[1212,4],[1223,6],[1241,1],[1247,3],[1251,4],[1280,4],[1285,3],[1289,6]]},"519":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"521":{"position":[[0,3],[11,3],[33,2],[36,1],[38,3],[42,3],[57,1],[79,2],[112,3],[133,1],[142,1],[144,4],[166,1],[180,3],[184,1],[186,3],[201,3],[205,2],[236,1],[250,1],[252,3],[256,3],[260,4],[277,1],[307,3],[311,3],[342,1],[344,2],[347,3],[361,1],[363,5],[369,4],[374,3],[378,4],[383,3],[387,2],[390,3]]},"523":{"position":[[5,3],[45,1],[47,2],[59,2],[62,3],[66,5],[72,3],[76,2],[79,3],[83,5],[97,2],[113,1],[128,1],[130,1],[162,1],[176,3],[180,2],[183,3],[187,3],[191,4],[196,3],[200,2],[203,2],[206,1],[208,2],[211,3],[215,5],[233,1],[250,1],[252,3],[256,5],[262,4],[267,4],[272,2],[275,2],[278,2],[304,1],[306,4],[321,2],[324,3],[328,4],[333,4],[338,4],[343,3],[347,4],[352,3],[356,2],[359,3],[375,1],[377,2],[380,4],[385,4],[390,3],[394,3],[398,3],[402,3],[406,3],[426,1],[448,2],[451,2],[460,1],[462,2],[465,3],[483,2],[504,3],[518,1],[540,1],[542,2],[553,1],[594,1],[596,3],[600,3],[614,4],[631,1],[633,4],[638,5],[644,2],[647,2],[650,6],[657,4],[670,1],[681,2],[694,1],[708,2],[711,2],[714,5],[720,3],[724,3],[728,2],[731,4],[736,3],[769,1],[799,1],[813,1],[815,1],[817,4],[822,2],[840,1],[842,3],[846,5],[872,1],[880,1],[882,2],[885,1],[887,3],[891,3],[895,4],[900,4],[933,1],[935,4],[940,1],[942,4],[947,4],[952,4],[967,1],[973,1],[975,1],[977,3],[981,1],[983,2],[986,2],[989,3],[993,2],[1016,2],[1030,1],[1032,3],[1048,3],[1052,4],[1057,2],[1060,2],[1063,3],[1067,3]]},"525":{"position":[[12,1],[14,2],[35,3],[67,1],[75,1],[77,2],[111,1],[113,2],[116,2],[154,4],[177,4],[194,1],[196,4],[201,2],[221,1],[261,1],[263,5],[269,2],[283,2],[311,1],[325,1],[327,2],[330,7],[338,1],[357,2],[360,1],[362,3],[366,5],[393,2],[396,3],[400,5],[406,4],[411,4],[416,2],[424,2],[427,4],[432,2],[435,3],[439,4],[444,4],[461,1],[463,3],[467,3],[471,3],[502,1],[504,3],[508,2],[532,1],[548,1],[550,2],[571,1],[573,3],[584,2],[587,3],[596,1],[598,5],[604,2],[607,1],[614,4],[628,2],[631,3],[635,2],[638,3],[642,2],[659,1],[661,2],[669,1],[671,2],[674,4],[679,1],[704,1],[706,2],[709,3],[713,3],[717,4],[743,1],[765,1],[767,4],[772,3],[776,2],[779,1],[781,3],[805,1],[859,2],[862,3],[898,2],[901,3],[905,5],[932,1],[934,1],[936,3],[963,1],[965,4],[970,3],[984,1],[997,1],[999,4],[1004,3],[1038,1],[1065,3],[1111,2],[1134,1],[1141,2],[1144,3],[1179,1],[1201,1],[1235,2],[1256,1],[1265,2],[1268,3],[1272,1],[1274,1],[1276,2],[1279,2],[1287,1],[1315,1],[1317,2],[1320,4],[1331,1],[1338,1],[1340,2],[1348,1],[1350,4],[1355,2],[1358,2],[1367,2],[1374,1],[1376,5],[1382,6],[1406,1],[1408,4],[1413,3],[1417,2],[1420,2],[1431,1],[1446,2],[1470,1],[1472,5],[1478,3],[1496,4],[1501,4],[1517,1],[1519,1],[1521,2],[1524,2],[1547,2],[1563,1],[1573,1],[1575,4],[1585,1],[1587,6],[1594,2],[1602,2],[1605,3],[1609,2],[1612,3]]},"527":{"position":[[0,3],[35,1],[37,2],[40,4],[76,1],[87,2],[101,1],[138,1],[140,2],[143,2],[146,3],[150,3],[154,3],[185,3],[189,2],[202,1],[204,5],[210,2],[213,2],[216,5],[222,1],[224,3],[240,1],[242,3],[253,1],[255,3],[259,2],[262,2],[293,1],[307,1],[309,4],[334,1],[345,1],[376,1],[421,1],[423,4],[428,1],[430,3],[444,1],[446,1],[453,2],[456,3],[460,6],[480,1],[492,1],[494,2],[497,1],[512,1],[539,1],[541,2],[584,1],[597,1],[613,1],[615,2],[618,2],[634,3],[638,2],[731,1],[764,1],[795,2],[813,1],[846,1],[877,2],[895,1],[928,1],[1043,1],[1045,2],[1062,1],[1096,1],[1114,1],[1124,3],[1142,1],[1144,4],[1149,2],[1172,1],[1174,4],[1179,2],[1232,1],[1277,3],[1362,2],[1390,1],[1392,2],[1548,2],[1611,2],[1644,2],[1656,2],[1659,1],[1714,1],[1734,2],[1779,2],[1839,2],[1883,2],[1946,2],[1997,2],[2054,1],[2081,2],[2377,1],[2496,1],[2603,1],[2627,1],[2629,2],[2632,2],[2661,1],[2692,1],[2709,1],[2711,2],[2714,1],[2726,1],[2734,1],[2742,2],[2795,1],[2833,1],[2844,2],[2902,1],[2916,3],[2937,1],[2950,1],[2970,3],[2974,3],[2978,1],[2980,3],[2984,3],[2988,3],[2992,3],[2996,2],[3021,1],[3035,1],[3037,1],[3039,3],[3043,3],[3047,2],[3056,1],[3121,1],[3169,1],[3183,2],[3203,1],[3205,3],[3209,2]]},"529":{"position":[[17,1],[24,2],[27,2],[30,2],[33,2],[75,1],[77,3],[91,1],[93,4],[104,4],[109,4],[114,4],[144,3],[160,1],[162,4],[235,1],[266,2],[320,2],[330,1],[345,1],[355,1],[357,3],[361,2],[380,1],[382,2],[393,2],[409,1],[419,1],[421,3],[433,1],[463,1],[465,4],[499,2],[517,2],[527,1],[537,1],[541,3],[558,2],[581,1],[586,2],[589,2],[601,3],[618,1],[620,4],[628,2],[639,1],[641,4],[651,2],[654,1],[719,3],[770,1],[820,1],[851,3],[855,2],[866,3],[870,3],[874,3],[878,2],[911,2],[914,5],[920,6],[927,3],[931,3],[935,2],[938,4],[943,3],[947,4],[952,3],[966,3],[970,2],[973,5],[979,2],[982,4],[987,4],[992,4],[997,4],[1002,8],[1027,1],[1032,3],[1036,2],[1039,4],[1044,3],[1048,3],[1052,6],[1059,5],[1065,5],[1071,3],[1075,4],[1080,4],[1085,3],[1089,1],[1091,3],[1095,3],[1099,7],[1123,1],[1128,3],[1187,1],[1201,1],[1203,1],[1205,4],[1210,3],[1230,1],[1232,4],[1321,1],[1323,5],[1329,1],[1358,1],[1387,2],[1400,1],[1402,2],[1405,2],[1408,6],[1422,1],[1433,1],[1435,2],[1448,1],[1456,1],[1458,3],[1462,5],[1503,1],[1505,3],[1509,4],[1514,2],[1540,1],[1542,3],[1546,2],[1549,2],[1589,1],[1646,1],[1648,2],[1651,2],[1654,5],[1668,1],[1696,2],[1739,1],[1796,1],[1810,2],[1813,2],[1838,3],[1861,1],[1863,3],[1867,3],[1871,2],[1874,2],[1877,4],[1922,1],[1969,1],[1971,3],[1982,2],[1985,3],[1989,2],[1992,3],[1996,5],[2002,2],[2005,1],[2017,1],[2019,4],[2024,3],[2028,5],[2067,1],[2069,4],[2074,2],[2077,2],[2080,3],[2084,2],[2107,4],[2112,2],[2132,1],[2134,2],[2157,1],[2159,4],[2164,3],[2175,1],[2250,1],[2263,2],[2266,3],[2270,3],[2274,2],[2306,1],[2308,2],[2326,3],[2330,3],[2362,3],[2366,2],[2369,2],[2428,1],[2459,1],[2461,2],[2472,3],[2493,2],[2503,3],[2524,3],[2556,3],[2567,1],[2577,3],[2581,4],[2586,3],[2608,2],[2611,3],[2615,3],[2619,2],[2622,2],[2625,5],[2631,2],[2645,3],[2649,2],[2652,3],[2663,1],[2665,2],[2700,2],[2703,3],[2707,3],[2711,4],[2723,1],[2738,2],[2749,1],[2751,5],[2771,1],[2773,5],[2779,3],[2783,5],[2789,3],[2800,1],[2823,2],[2855,2],[2858,3],[2862,2]]},"531":{"position":[[17,1],[19,2],[34,4],[39,4],[58,1],[60,4],[65,3],[87,1],[89,4],[94,2],[110,1],[133,3],[137,3],[164,1],[183,1],[185,2],[188,3],[224,1],[245,2],[248,2],[261,1],[263,3],[267,3],[286,1],[288,4],[293,3],[297,3],[509,1],[532,1],[546,1],[548,3],[552,1],[554,3],[558,2],[561,2],[564,3],[583,1],[602,2],[605,1],[607,5],[613,2],[616,3],[620,3],[624,2],[627,3],[631,4],[636,2],[639,5],[645,6],[652,4],[657,4],[662,2],[665,2],[668,3],[765,1],[767,3],[771,3],[775,1],[777,3],[805,1],[807,3],[811,3],[815,3],[819,4],[847,1],[849,4],[865,1],[867,3],[871,4],[876,6],[883,2],[902,1],[904,2],[907,2],[915,1],[917,1],[928,2],[931,3],[935,2],[961,1],[963,1],[965,4],[970,2],[973,4],[978,2],[999,1],[1027,1],[1029,4],[1044,1],[1046,4],[1051,2],[1054,4],[1059,4],[1064,3],[1068,4],[1073,5],[1079,2],[1101,1],[1103,4],[1127,4],[1142,2],[1168,1],[1186,1],[1188,5],[1194,1],[1196,4],[1218,2],[1221,3],[1225,2],[1253,1],[1266,2],[1284,1],[1291,1],[1305,2],[1326,1],[1362,1],[1381,1],[1383,2],[1386,3],[1415,1],[1417,4],[1422,3],[1426,3],[1430,2],[1433,3],[1437,3],[1441,3],[1463,1],[1470,1],[1484,2],[1487,2],[1515,1],[1528,1],[1530,5],[1536,2],[1539,3],[1543,3],[1562,1],[1564,4],[1569,2],[1572,5],[1578,3]]},"533":{"position":[[0,3],[11,2],[25,1],[27,2],[30,3],[34,2],[37,2],[40,2],[68,1],[79,1],[81,2],[101,2],[116,2],[134,1],[136,2],[139,3],[148,1],[150,6],[162,2],[165,2],[168,2],[171,2],[196,1],[198,4],[203,1],[205,3],[209,3],[222,2],[225,2],[228,3],[242,1],[244,4],[249,3],[253,2],[275,1],[277,4],[302,1],[313,1],[315,5],[331,1],[333,2],[336,3],[340,2],[343,4],[353,1],[367,2],[370,3],[398,1],[420,1],[432,1],[437,1],[448,2],[460,1],[462,2],[465,3],[469,3]]},"535":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"537":{"position":[[12,2],[26,1],[28,3],[32,2],[35,4],[52,1],[54,2],[57,2],[60,3],[64,2],[67,4],[72,3],[76,2],[102,1],[104,2],[196,3],[200,3],[283,1],[285,3],[289,3],[293,2],[296,3],[300,3],[304,2],[307,2]]},"539":{"position":[[0,3],[27,1],[29,1],[31,3],[35,2],[61,1],[71,2],[79,2],[93,1],[95,2],[98,1],[100,2],[103,2],[106,1],[108,2],[134,1],[136,2],[139,2],[142,2],[145,2],[171,1],[173,4],[178,2],[204,1],[210,3],[214,3],[218,3],[238,1],[240,4],[245,2],[248,3],[252,2],[255,1],[257,2],[260,3],[264,2],[272,1],[284,1],[312,2],[364,1],[366,2],[375,2],[383,1],[385,4],[397,1],[408,2],[417,2],[451,3],[475,1],[481,3],[488,2],[491,3],[507,1],[516,2],[519,2],[522,2],[525,1],[527,4],[547,2],[559,2],[562,3],[566,5],[591,1],[622,4],[627,3],[631,2]]},"541":{"position":[[6,1],[8,2],[11,3],[15,3],[19,2],[28,1],[30,2],[33,2],[57,2],[83,1],[85,5],[96,2],[99,3],[103,4],[119,1],[121,2],[124,2],[134,1],[136,4]]},"544":{"position":[[51,1],[65,1],[67,2],[81,1],[88,2],[91,2],[106,1],[108,2],[111,4],[116,2],[119,4],[124,1],[126,5],[132,2],[135,3],[195,1],[201,1],[203,4],[219,1],[221,2]]},"546":{"position":[[15,1],[17,5],[27,1],[29,2],[43,1],[57,1],[59,2],[62,2],[65,2],[68,6],[75,2],[80,2],[83,5],[89,3],[93,4],[98,2],[171,2],[174,5]]},"548":{"position":[[14,1],[21,1],[23,3],[27,4],[32,4],[37,2],[63,1],[65,2],[72,1],[74,3],[80,2],[83,4],[88,3],[95,2],[119,2],[122,2],[143,5],[158,2],[161,3],[174,3],[178,5],[184,2],[187,3],[205,1],[207,2]]},"550":{"position":[[17,1],[19,3],[23,3],[50,1],[52,2],[55,1],[57,4],[62,2],[65,3],[121,1],[123,2],[141,1],[143,4],[148,4],[153,2],[156,3],[169,1],[191,2],[220,1],[238,1],[240,4],[245,2],[253,1],[263,1],[265,6],[278,1],[287,1],[308,1],[310,4],[315,5],[334,1],[351,1],[373,3],[377,3],[381,2],[387,1],[398,3],[402,1],[404,4],[409,4]]},"553":{"position":[[10,1],[28,1],[45,2],[48,3],[52,2],[66,1],[68,4],[73,2],[90,1],[92,2],[100,1],[133,1],[143,1],[159,2],[166,1],[178,3],[202,2],[212,1],[227,2],[255,2],[263,1],[270,2],[273,3],[290,2]]},"555":{"position":[[35,1],[54,1],[56,2],[66,2],[69,1],[85,1],[87,2],[90,2],[93,2],[96,2],[99,2],[120,1],[122,3],[126,3],[130,4],[135,3],[168,3],[172,2],[189,1],[208,3],[212,3],[230,4],[235,2],[238,2],[251,1],[253,2],[298,1],[300,3]]},"557":{"position":[[0,2],[3,3],[7,1],[25,2],[28,2],[39,2],[42,2],[50,2],[61,1],[68,1],[70,2],[73,2],[95,1],[102,1],[104,5],[110,4],[156,1],[172,1],[174,4],[184,1],[192,1],[194,2],[197,2],[216,1],[218,3],[222,2],[225,3],[229,4],[234,2],[247,2],[250,5],[256,3],[260,1],[262,2],[265,3],[269,2],[272,2],[280,1],[282,3],[286,4],[291,2],[294,3],[308,1],[310,3],[314,1],[316,2],[319,2],[334,2],[337,2],[340,2],[353,2],[356,1],[358,3],[362,2],[365,2],[368,2],[371,4],[376,1],[378,3],[382,4],[387,1],[393,1],[406,1],[426,1],[443,2],[446,2],[449,2]]},"559":{"position":[[31,1],[37,1],[39,3],[43,3],[47,2],[50,2],[53,6],[60,2],[63,3],[67,4],[82,1],[84,3],[88,2],[91,2],[114,1],[116,4],[125,2],[139,2],[142,1],[144,3],[148,2],[151,2],[154,2],[172,1],[174,3],[193,2],[223,2],[236,3],[240,3],[244,2],[247,3]]},"561":{"position":[[0,3],[19,1],[23,2],[26,4],[50,1],[52,5],[58,2],[61,2],[64,3],[68,4],[73,2],[76,2],[79,5],[99,1],[120,1],[122,4],[127,2],[130,6],[142,1],[144,2],[152,2],[170,1],[178,2],[181,3],[198,1],[205,2],[212,1],[217,1],[219,2],[222,4],[232,2],[241,2],[254,1],[260,1],[265,1],[273,1],[280,2],[283,3],[287,2],[290,3],[294,3],[298,4],[313,1],[320,1],[322,4],[327,2],[330,2],[333,2],[345,3],[349,4],[363,1],[365,3],[373,1],[378,2],[381,4],[386,2],[405,2],[413,2],[416,3],[420,3],[429,4],[434,3],[438,3],[442,2]]},"563":{"position":[[0,6],[30,1],[40,5],[46,3],[50,3],[58,1],[78,1],[80,3],[84,2],[87,1],[93,1],[106,1],[108,1],[110,2],[113,3],[117,4],[122,2],[125,2],[141,3],[145,3],[149,5],[155,3],[159,2],[168,2],[171,2],[174,3],[178,2],[185,1],[187,2],[201,1],[203,2],[206,2],[209,3],[213,4],[218,2],[221,5],[235,1],[248,2],[251,2],[258,3],[262,3],[266,2],[281,1],[299,1],[301,3],[345,2],[348,2],[370,1],[372,5],[378,2],[381,2],[384,2],[395,1],[401,3],[405,2],[408,2],[411,3],[415,2]]},"565":{"position":[[9,1],[11,5],[17,4],[22,2],[29,4],[34,2],[60,1],[62,2],[65,3],[69,3],[83,3],[87,2],[94,3],[98,4],[103,4],[114,2],[141,1],[147,6],[164,1],[193,3],[197,4],[206,2],[209,2],[212,3],[216,6],[229,2],[237,1],[249,1],[261,1],[263,5]]},"567":{"position":[[23,1],[25,4],[30,3],[34,4],[39,4],[44,1],[65,1],[67,2],[70,3],[74,4],[79,5],[98,5],[109,1],[111,4],[132,5],[141,1],[175,3],[190,1],[204,1],[216,1],[247,1],[263,1],[269,4],[279,2],[294,1],[326,1],[328,2],[337,1],[339,2],[342,1],[344,4],[368,1],[370,2],[396,2],[399,2],[405,1],[407,2],[427,1],[429,4],[471,1],[478,2],[481,4],[486,2],[492,1],[508,3],[512,4],[541,1],[543,3],[547,2],[550,1],[552,3],[556,3],[560,2],[566,1],[579,1],[621,1],[650,1],[652,3],[669,2],[684,1],[713,1],[727,1],[729,5],[735,2],[738,3],[742,5]]},"569":{"position":[[5,3],[9,3],[13,2],[16,2],[23,4],[94,1],[109,2],[125,2],[170,1],[185,2],[192,2],[229,4],[248,2],[251,2],[254,2],[278,1],[303,2],[306,1],[308,4],[326,1],[328,2],[352,1],[364,1],[375,1],[377,4],[395,1],[397,4],[402,2],[426,2],[451,1],[458,2],[467,2],[470,3],[474,4],[494,2],[508,2],[511,1],[513,4],[518,2],[521,2],[524,2],[527,3],[531,2],[534,2],[541,3],[561,1],[567,3],[574,1],[576,2],[579,3],[583,3],[587,2],[590,2],[593,3],[597,5],[608,1],[620,1],[636,1],[638,3],[651,3],[659,1],[661,4],[666,2],[669,2],[682,1],[684,3],[698,1],[700,1],[702,3],[706,4],[711,2],[718,3],[722,3],[726,3],[740,1],[746,2],[749,2],[761,1],[763,3],[767,5],[773,3],[777,4],[805,1],[807,3],[838,1],[840,1],[842,2],[845,3],[849,1],[851,1],[853,2],[856,3],[943,2],[960,1],[977,2],[980,6],[1004,1],[1006,5],[1012,2],[1015,3],[1019,3],[1023,2],[1031,1],[1033,3],[1037,3],[1088,3],[1092,3],[1096,3],[1100,4],[1105,2],[1118,1],[1120,3],[1124,4],[1129,3],[1133,1],[1135,1],[1137,3],[1146,2],[1149,4],[1154,4],[1159,3],[1163,3],[1167,5],[1173,3],[1177,4],[1182,2],[1185,3],[1189,3],[1193,2],[1196,2],[1199,2],[1202,3],[1206,2],[1209,4],[1214,2],[1217,3],[1221,3],[1225,3],[1229,3],[1233,2]]},"571":{"position":[[0,1],[2,3],[29,1],[31,2],[50,1],[52,2],[55,2],[58,3],[62,2],[69,4],[113,2],[136,1],[142,1],[144,3],[148,2],[151,2],[154,3],[158,2],[161,5]]},"573":{"position":[[23,1],[25,2],[28,2],[31,2],[34,3],[38,1],[56,1],[58,3],[62,2],[65,4],[70,5],[76,1],[78,3],[96,1],[98,3],[102,2],[105,2],[108,3],[112,1],[119,2],[122,2],[125,4],[130,2],[133,3],[137,3],[141,3],[145,2],[148,4],[153,2],[165,1],[178,1],[180,1],[182,3],[186,2],[189,3],[193,3],[197,2],[200,2],[203,2],[206,2],[209,3],[213,4],[218,3],[222,3],[249,1],[251,2],[254,2],[257,2],[260,4],[265,3],[269,3],[273,2],[276,2],[279,4],[284,2],[287,3],[291,2],[294,4],[299,3],[303,2],[306,1],[308,3],[312,3]]},"575":{"position":[[15,1],[17,2],[20,3],[24,5],[30,2],[33,4],[58,1],[60,2],[82,1],[84,2],[87,4],[92,2],[95,5],[101,1],[103,4],[108,2],[111,2],[123,1],[125,2],[128,3],[132,4],[137,2],[140,2],[143,5],[157,1],[163,4],[187,1],[189,2],[200,3],[204,4],[209,1],[211,2],[218,3],[222,3],[226,1],[228,1],[230,3],[234,2],[252,1],[268,3],[272,3],[276,4],[289,3],[293,2],[296,2],[299,2]]},"577":{"position":[[0,3],[4,2],[40,3],[52,1],[65,1],[119,1],[131,1],[174,1],[176,5],[182,4],[187,2],[190,2],[206,1],[224,1],[226,5],[232,4],[237,2],[263,1],[270,1],[272,4],[277,3],[281,2],[299,3],[303,1],[305,1],[307,4],[312,2],[315,3]]},"579":{"position":[[23,6],[42,1],[85,3],[89,2],[92,3],[96,3],[100,2],[103,3],[107,3],[111,2],[114,4],[119,3],[123,3],[137,3],[158,2],[161,3],[165,3],[169,2],[201,2],[210,3],[214,2],[217,3],[221,4],[226,7],[239,2],[242,3],[246,3],[250,2],[253,2],[256,2],[282,1],[284,3],[288,3],[292,4],[297,3],[301,4],[306,2],[309,2]]},"581":{"position":[[3,2],[6,3],[10,2],[13,3],[17,7],[25,3],[29,4],[34,2],[60,1],[62,5],[68,2],[71,2],[74,5],[80,3],[84,6],[101,1],[103,3],[130,1],[145,1],[152,1],[154,3],[158,3],[162,2],[165,2],[173,2],[199,1],[201,2],[204,4],[209,3],[213,3],[217,1]]},"583":{"position":[[23,2],[26,4],[41,1],[43,1],[45,2],[63,1],[65,2],[89,1],[91,2],[117,2],[120,2],[123,2],[126,2],[129,3],[133,2],[136,2],[139,2],[142,4],[170,1],[181,1],[183,2],[186,3],[190,6],[201,1],[203,4],[227,1],[229,2],[236,1],[238,2],[241,3],[245,2],[248,2]]},"585":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"587":{"position":[[68,1],[76,1],[78,3],[82,2],[85,2],[106,1],[116,2],[131,1],[157,2],[160,4],[165,3],[173,1],[197,1],[199,4],[204,2],[207,3],[211,3],[215,1],[217,2],[220,3],[224,1],[323,1],[325,3],[338,1],[340,5],[346,3],[370,1],[372,4],[386,1],[388,3],[405,1],[412,1],[414,4],[424,1],[442,1],[469,3],[473,5],[479,1],[481,3],[500,1],[514,1],[516,4],[530,1],[549,2],[571,1],[573,4],[578,1],[580,3],[584,2],[596,1],[598,4],[609,2],[622,1],[624,2],[648,2],[665,2],[668,3],[672,1],[674,2],[691,2],[700,1],[717,1],[719,6],[739,1],[741,2],[744,3],[748,2],[763,3],[767,3],[774,1],[776,4],[786,2]]},"589":{"position":[[15,1],[21,1],[23,3],[27,2],[30,3],[46,1],[48,2],[66,1],[68,2],[71,3],[75,2],[93,1],[95,4],[100,4],[123,1],[156,1],[173,1],[185,1],[187,4],[192,3],[196,3],[223,1],[252,2],[267,1],[274,1],[276,6],[301,2],[304,3],[320,1],[322,3],[326,3],[330,4],[335,2],[354,1],[368,1],[370,2],[373,5],[379,4],[477,2],[480,2],[483,2],[507,1],[535,3],[543,1],[545,3],[566,1],[578,2],[597,1],[599,5],[605,2],[627,1],[648,1],[650,3],[654,3],[683,1],[685,3],[723,1],[733,1],[735,2],[742,1],[768,1],[770,4],[775,3],[792,1],[794,2],[797,3],[806,1],[808,2],[811,2],[814,4],[823,1],[838,2],[841,3],[845,3],[849,4],[854,5],[860,1],[862,4],[867,2],[874,3],[878,3],[882,2],[889,1],[891,1],[893,4],[898,4],[903,2],[906,2],[909,2],[912,3],[916,3],[920,3],[952,1],[954,2],[957,4],[962,3],[966,2],[969,2],[972,2],[979,1],[981,5],[999,2],[1002,2],[1005,3],[1016,1],[1035,3],[1039,2],[1042,1],[1044,2],[1047,2],[1050,4],[1055,3],[1059,3],[1063,3],[1067,3],[1071,2],[1074,3],[1078,2],[1085,1],[1104,1],[1106,4],[1111,1],[1113,4],[1118,2],[1121,5],[1127,3],[1131,2],[1134,3],[1138,7],[1146,2],[1149,2],[1152,2],[1161,1],[1172,3],[1176,2],[1195,1],[1197,3],[1201,5],[1207,4],[1212,5],[1275,1],[1277,2],[1280,2],[1283,3],[1303,1],[1312,2],[1327,2],[1330,2],[1333,3],[1375,3],[1379,4],[1396,1],[1398,3],[1402,2],[1405,2],[1408,2],[1416,1],[1424,2],[1436,1],[1438,3],[1442,4],[1466,1],[1468,4],[1478,1],[1484,1],[1503,3],[1507,2],[1515,1],[1517,3],[1533,1],[1535,2],[1538,3],[1542,6],[1549,2],[1552,2],[1555,2],[1569,1],[1571,2],[1574,3],[1578,2],[1586,3],[1590,1],[1592,6],[1599,2],[1602,3],[1606,3],[1610,1],[1612,3],[1616,2],[1619,3],[1623,1],[1625,3],[1629,3],[1633,2],[1655,1],[1682,1],[1684,5],[1690,3],[1694,2],[1707,1],[1709,6],[1735,2],[1738,3],[1742,3],[1746,4],[1758,2],[1761,3],[1774,1],[1785,1],[1787,2],[1790,1],[1792,3],[1799,1],[1801,4],[1806,3],[1825,1],[1845,1],[1859,1],[1861,1],[1878,1],[1902,2],[1905,3],[1909,2],[1925,1],[1964,2],[1992,1],[2010,1],[2012,3],[2045,2],[2065,1],[2077,1],[2079,2],[2090,2],[2093,6],[2117,2],[2120,3],[2124,2],[2127,2],[2130,3],[2147,1],[2158,1],[2160,3],[2164,3],[2168,1],[2170,2],[2173,3],[2177,1],[2179,2],[2182,2],[2185,2],[2217,4],[2227,2],[2230,4],[2241,2],[2257,1],[2269,1],[2290,2]]},"592":{"position":[[5,1],[33,1],[54,1],[62,1],[73,1],[84,1],[86,4],[91,4],[100,1],[102,4],[107,3],[111,3],[115,3],[133,1],[148,1],[150,5],[166,1],[187,1],[189,4],[219,1],[230,1],[232,2],[235,4],[240,3],[244,1],[246,2],[256,3],[260,2],[263,3],[274,1],[285,2],[288,3],[292,3],[296,4],[307,1],[324,3],[328,5],[348,2],[372,2],[375,3],[379,3],[383,3],[387,1],[389,2],[392,4],[397,2],[400,4],[405,2],[429,1],[431,2],[434,3],[456,2],[468,1],[470,4],[475,4],[480,3],[484,1],[486,3]]},"594":{"position":[[25,1],[39,3],[43,3],[47,2],[50,4],[73,3],[77,3],[93,4],[103,3],[107,3],[114,3],[121,1],[126,5],[152,1],[167,1],[204,1],[219,1],[275,1],[277,4],[285,1],[299,2],[327,2],[371,2],[379,3],[395,1],[397,3],[418,1],[448,1],[467,1],[469,3],[482,3],[515,2],[518,2],[524,1],[529,1],[545,1],[547,4],[552,2],[563,1],[570,1],[572,2],[578,1],[605,1],[607,2],[610,7],[618,3],[642,3],[658,3],[662,3],[666,3],[670,4],[675,2],[678,2],[699,2],[702,4],[707,2],[737,2],[740,3],[749,2],[786,1],[847,1],[882,1],[928,2],[936,6],[949,1],[951,3],[968,2],[971,3],[980,1],[993,1],[1013,2],[1056,4],[1083,1],[1085,5],[1118,1],[1120,2],[1123,3],[1145,1],[1147,3],[1151,5],[1157,2],[1160,2],[1163,3],[1174,1],[1176,1],[1178,3],[1182,2],[1185,2],[1188,2],[1191,3],[1195,4],[1200,2],[1234,1],[1251,1],[1275,3],[1279,2],[1282,2],[1285,3],[1305,1],[1307,2],[1310,2],[1313,4],[1318,1],[1320,5],[1326,2],[1349,1],[1366,1],[1368,2],[1382,1],[1391,1],[1393,2],[1396,2],[1425,2],[1443,1],[1445,2],[1448,4],[1453,2],[1456,4],[1461,3],[1465,3],[1472,5],[1478,2],[1497,2]]},"596":{"position":[[5,2],[8,3],[12,3],[19,1],[42,1],[44,2],[47,3],[51,2],[54,1],[56,2],[81,2],[87,1],[89,2],[142,1],[176,1],[224,1],[226,5],[258,1],[260,2],[310,1],[352,1],[366,1],[368,5],[374,2],[377,3],[381,3],[385,3],[414,1],[428,1],[430,2],[433,2],[456,2],[544,1],[748,3],[778,1],[787,1],[789,4],[794,2],[797,5],[873,1],[951,1],[957,1],[985,1],[1015,1],[1017,4],[1042,3],[1046,3],[1050,3],[1054,2],[1057,2],[1060,3],[1081,1],[1083,1],[1085,2],[1088,3],[1092,5],[1098,5],[1119,1],[1121,2],[1124,2],[1127,3],[1139,1],[1141,4],[1146,3],[1150,3],[1154,2],[1174,1],[1176,2],[1204,1],[1206,3],[1210,5],[1216,2],[1241,2],[1244,1],[1246,4],[1251,1],[1260,1],[1273,1],[1275,2],[1286,3],[1290,3],[1294,1],[1311,1],[1313,5],[1319,2],[1322,1],[1330,1],[1332,3],[1336,3],[1351,2],[1354,5],[1360,2],[1363,4],[1368,2],[1391,2],[1394,2],[1418,3],[1422,5],[1449,1],[1451,3],[1455,1],[1480,1],[1482,2],[1491,1],[1506,2],[1509,3],[1513,4],[1518,2],[1528,2],[1531,4],[1547,1],[1570,1],[1572,3],[1576,2],[1588,1],[1619,1],[1621,1],[1623,3],[1627,4],[1648,2],[1651,3],[1655,3],[1675,1],[1767,1],[1855,1],[1857,2],[1860,1],[1862,2],[1871,1],[1900,1],[1902,7],[1932,1],[1968,3],[2058,1],[2138,1],[2313,1],[2336,1],[2338,4],[2343,3],[2356,1],[2358,1],[2360,1],[2367,2],[2370,3],[2374,4],[2379,2],[2399,1],[2408,2],[2411,3],[2430,3],[2434,3],[2438,2],[2462,3],[2466,4],[2477,1],[2486,2],[2489,2],[2492,4],[2503,1],[2505,1],[2507,2],[2510,3],[2519,2],[2548,1],[2550,4],[2555,3],[2559,3],[2563,6],[2570,3],[2581,1],[2583,4],[2588,2],[2591,2],[2594,4],[2599,2]]},"598":{"position":[[13,1],[15,3],[19,3],[23,2],[26,2],[34,3],[38,2],[49,1],[63,4],[68,2],[71,2],[74,3],[78,1],[94,1],[96,5],[102,4],[116,1],[118,2],[139,3],[143,3],[147,3],[151,2],[158,2],[161,1],[163,3],[186,3],[209,1],[211,5],[222,3],[226,4],[231,2],[234,3],[238,4],[243,4],[248,2],[251,5],[257,3],[267,1],[269,1],[280,1],[282,2],[285,2],[288,2],[311,1],[313,4],[318,3],[330,1],[332,2],[340,1],[342,6],[349,2],[358,1],[360,1],[371,1],[373,5],[379,3],[383,4],[388,2],[391,4],[396,3],[412,1],[414,2],[417,4],[422,3],[426,3],[430,1],[432,3],[450,1],[466,1],[484,1],[497,2],[519,1],[521,4],[526,5],[551,1],[553,4],[591,1],[593,4],[598,3],[602,4],[607,4],[612,2],[615,6],[622,3],[626,2],[629,2],[644,1],[665,1],[667,4],[672,2],[675,1],[677,4],[682,3],[686,3],[695,3],[699,2],[702,5],[708,3],[712,3],[728,1],[745,2],[793,1],[795,2],[798,3],[818,3],[833,2],[863,1],[902,1],[974,1],[988,1],[1034,1],[1036,4],[1057,1],[1091,1],[1119,3],[1123,2],[1126,5],[1144,3],[1148,1],[1165,1],[1167,2],[1195,1],[1197,3],[1201,3],[1205,3],[1209,2],[1212,3],[1231,1],[1259,6],[1277,1],[1296,2],[1334,1],[1360,2],[1380,1],[1382,2],[1385,6],[1392,3],[1396,2],[1409,4],[1414,2],[1444,5],[1450,2],[1453,5],[1459,3],[1463,3],[1467,4],[1472,2],[1475,5],[1481,2],[1484,7],[1492,6],[1520,4],[1525,4],[1530,3],[1534,3],[1538,2],[1551,5],[1557,6],[1626,1],[1671,1],[1734,2],[1772,3],[1840,3],[1844,2],[1856,1],[1892,1],[1918,2],[1921,3],[1944,1],[1971,1],[1973,2],[1976,2],[1979,2],[2018,1],[2038,1],[2044,1],[2083,2],[2110,2],[2135,1],[2142,1],[2187,1],[2215,3],[2219,2],[2231,3],[2235,1],[2237,2],[2259,1],[2275,1],[2277,2],[2283,5],[2289,4],[2294,3],[2306,1],[2308,2],[2311,2],[2314,3],[2318,4],[2323,4],[2328,3],[2332,4],[2337,4],[2342,3],[2346,2],[2349,2],[2352,3],[2373,2],[2376,4],[2446,1],[2448,4],[2470,1],[2478,2],[2481,1],[2504,1],[2526,1],[2528,2],[2531,3],[2535,1],[2537,4],[2551,3],[2574,1],[2576,4],[2581,1],[2583,2],[2586,3],[2602,2],[2605,3],[2609,5],[2632,1],[2634,4],[2639,2],[2642,3],[2662,1],[2664,5],[2670,4],[2702,1],[2704,4],[2709,2],[2731,1],[2733,4],[2738,3],[2742,1],[2744,1],[2746,3],[2750,2],[2770,2],[2773,3],[2805,1],[2807,2],[2832,1],[2834,3],[2838,4],[2843,5],[2872,1],[2899,1],[2901,3],[2920,1],[2922,4],[2944,1],[2976,1],[2978,4],[2983,4],[3005,3],[3009,3],[3027,1],[3046,2],[3067,1],[3069,2],[3072,3],[3076,4],[3081,3],[3104,1],[3106,2],[3111,2],[3114,3],[3123,4],[3128,5],[3141,1],[3158,1],[3176,1],[3193,1],[3231,1],[3253,2],[3266,1],[3280,1],[3300,1],[3330,1],[3332,4],[3345,2],[3362,1],[3376,1],[3378,4],[3415,2],[3428,1],[3449,1],[3451,4],[3456,5],[3479,1],[3481,2],[3499,1],[3526,2],[3542,2],[3559,1],[3567,1],[3581,1],[3583,4],[3610,2],[3618,1],[3639,1],[3650,1],[3652,2],[3655,5],[3661,3],[3691,1],[3723,1],[3725,6],[3732,1],[3734,2],[3737,3],[3748,2],[3751,2],[3754,2],[3774,1],[3802,2],[3805,2],[3808,3],[3812,2],[3815,2],[3823,1],[3842,2],[3871,3],[3892,1],[3894,2],[3897,3],[3901,2],[3904,2],[3917,1],[3931,1],[3950,2],[3970,2],[3973,4],[3978,3],[3996,1],[4015,1],[4017,3],[4021,1],[4023,3],[4027,2],[4030,4],[4035,1],[4037,3],[4041,3],[4068,2],[4071,1],[4073,3],[4077,2],[4080,2],[4083,1],[4085,2],[4088,6],[4095,5],[4101,3],[4105,3],[4118,2],[4121,1],[4123,4],[4128,3],[4132,1],[4134,2],[4137,3],[4141,2],[4144,3],[4148,2]]},"600":{"position":[[0,2],[17,2],[38,1],[53,2],[56,2],[85,1],[99,1],[101,1],[103,2],[106,5],[112,1],[114,3],[118,2],[121,4],[146,1],[148,4],[175,1],[177,5],[197,2],[218,4],[234,1],[236,4],[241,2],[244,5],[250,3],[254,3],[258,3],[279,1],[281,2],[284,3],[302,1],[307,3],[311,3],[315,3],[337,1],[339,3],[356,3],[374,1],[402,1],[431,1],[433,1],[435,2],[457,1],[459,2],[474,3],[491,1],[505,4],[515,2],[523,1],[525,4],[537,1],[539,2]]},"602":{"position":[[0,4],[18,1],[20,3],[24,2],[27,2],[33,3],[37,4],[42,2],[72,1],[74,2],[94,2],[100,1],[102,3],[124,2],[140,1],[159,2],[162,4],[187,2],[262,1],[264,3],[307,1],[353,2],[356,2],[374,1],[376,2],[475,1],[509,1],[521,1],[542,1],[560,1],[562,4],[567,1],[577,1],[604,3],[608,2],[611,3],[615,3],[619,1],[628,1],[630,1],[651,1],[653,3],[657,4],[662,4],[701,1],[717,2],[720,2],[723,2],[733,1],[751,1],[753,2],[782,2],[785,4],[790,4],[795,3],[799,1],[801,3]]},"604":{"position":[[13,1],[21,1],[23,2],[26,1],[28,2],[31,2],[43,1],[45,4],[79,1],[81,2],[84,2],[87,3],[91,2],[99,1],[101,2],[104,3],[115,1],[132,1],[134,2]]},"606":{"position":[[0,2],[6,1],[25,2],[28,3],[40,1],[42,2],[51,2],[54,2],[57,3],[64,1],[85,1],[87,5],[97,1],[99,2],[112,2],[128,1],[130,3],[134,4],[139,2],[142,5],[148,3],[158,2],[178,4],[183,2],[217,1],[227,1],[234,1],[255,1],[257,2],[260,4],[265,2],[268,1],[270,4],[275,2],[278,2],[281,2],[288,2],[291,4],[307,1],[322,2],[328,2],[331,3],[335,2],[352,2],[355,2],[358,1],[360,4],[365,2],[368,2],[377,1],[401,1],[409,1],[424,2],[427,2],[430,3],[434,2]]},"608":{"position":[[6,1],[25,1],[27,2],[30,2],[33,3],[37,6],[44,2],[47,1],[76,2],[79,4],[89,1],[91,5],[97,4],[102,3],[127,1],[129,2],[159,1],[161,5],[167,6],[188,1],[190,2],[240,2],[266,1],[268,4],[282,2],[308,1],[310,5],[316,2],[322,1],[327,2],[346,2],[358,1],[368,1],[370,3],[380,1],[382,1],[384,3],[388,3],[392,3],[396,1],[398,1],[406,1],[416,2],[427,1],[429,3],[433,5],[465,1],[477,1],[488,1],[490,2],[497,1],[506,1],[508,5],[520,1],[552,1],[554,4],[580,1],[594,2],[597,2],[600,3],[604,2],[607,2],[610,3],[614,3],[618,4],[623,3],[627,2],[630,2],[633,3],[637,5],[649,1],[651,3],[655,1],[662,1],[664,2],[667,3],[679,2],[682,2],[685,3],[697,1],[699,2],[702,2],[715,2],[734,1],[754,1],[756,3],[778,1],[780,2],[794,1],[796,2],[799,2],[802,2],[828,1],[830,4],[835,3],[845,1],[867,1],[869,2],[907,2],[910,2],[913,3],[917,3],[921,6],[932,2],[948,1],[950,3],[974,1],[976,2],[994,1],[996,6],[1026,1],[1031,3],[1039,1],[1056,1],[1058,5],[1064,3],[1068,2],[1093,1],[1114,3]]},"610":{"position":[[0,3],[4,3],[8,3],[25,1],[27,3],[31,2],[34,3],[54,1],[56,2],[59,4],[64,1],[72,1],[74,4],[92,1],[112,1],[114,5],[151,1],[181,1],[183,4],[199,1],[201,3],[218,1],[259,1],[264,1],[271,1],[312,1],[314,2],[329,2],[332,6],[368,1],[370,4],[375,1],[381,1],[397,1],[407,2],[414,1],[435,1],[437,2],[440,1],[442,3],[446,2],[449,1],[455,3],[459,7],[483,1],[491,2],[494,3],[498,3],[502,4]]},"612":{"position":[[6,1],[27,1],[29,3],[33,4],[38,3],[56,2],[85,1],[107,1],[122,1],[145,3],[149,1],[178,1],[185,1],[194,1],[198,1],[204,1],[244,1],[246,2],[262,1],[264,3],[279,1],[296,3],[300,3],[310,1],[312,1],[318,1],[320,3],[344,1],[357,1],[359,3],[376,1],[390,5],[396,2],[399,4],[404,2],[422,2],[431,1],[436,1],[450,3],[477,1],[479,1],[485,2],[488,3]]},"614":{"position":[[6,1],[8,2],[11,1],[26,2],[46,1],[48,2],[51,3],[65,1],[91,1],[93,3],[97,2],[117,1],[119,2],[122,3],[137,1],[168,1],[170,5],[176,6],[219,1],[224,1],[234,1],[267,2],[270,3],[280,1],[299,1],[301,4],[306,2],[316,1],[323,1],[325,2],[364,1],[366,4],[371,2],[397,3],[407,2],[410,3],[421,2],[424,5],[430,3],[434,3],[438,3],[442,4],[447,6],[463,3],[467,2],[476,2],[479,3],[483,4],[488,2],[494,7],[513,3],[517,6]]},"616":{"position":[[10,1],[25,1],[43,1],[45,2],[48,2],[57,1],[69,2],[72,1],[74,2],[90,2],[102,3],[122,1],[124,2],[152,1],[162,2],[175,1],[198,3],[202,2],[218,2],[221,3],[225,3],[229,5],[248,1],[271,1],[273,2],[276,2]]},"618":{"position":[[18,1],[20,2],[23,2],[26,3],[30,3],[45,3],[55,3],[59,1],[61,1],[63,4],[68,2],[76,2],[79,2],[87,1],[113,1],[115,4],[123,2],[131,2],[134,1],[150,1],[163,1],[174,3],[191,1],[193,2],[216,1],[218,3],[222,2],[262,2],[274,1],[283,2],[286,4],[291,1],[293,1],[295,3],[299,1],[307,1],[318,2],[321,2],[332,1],[334,2],[337,3],[357,2],[366,4],[379,1],[381,2],[390,1],[397,1],[404,3],[408,2],[411,2],[414,2],[425,2],[428,1],[430,3],[440,1],[442,3],[446,3],[450,4],[455,2],[478,1],[480,2],[483,2],[486,4],[491,2]]},"620":{"position":[[13,3],[23,2],[26,5],[35,2],[53,2],[56,2],[59,1],[61,2],[64,3],[68,6],[75,2],[78,3],[82,1],[84,2],[87,5],[93,4],[98,2],[101,5],[107,4],[112,4],[117,4],[122,2],[125,3],[129,4],[134,2],[150,1],[152,4],[157,4],[167,5],[195,1],[218,1],[220,4],[225,4],[235,5],[241,2],[244,4],[254,5]]},"622":{"position":[[0,3],[17,2],[38,1],[40,2],[62,1],[64,2],[107,2],[110,2],[113,3],[117,2],[126,1],[145,2],[148,3],[157,2],[160,2],[179,1],[199,1],[227,2],[230,2],[233,2],[257,1],[259,1],[261,2],[264,2],[273,1],[292,1],[294,2],[315,1],[328,2],[331,3],[350,1],[359,1],[361,4],[366,2],[369,1],[371,2],[379,2],[388,1],[390,3],[399,1],[401,3],[405,2],[414,3],[418,2],[421,2],[444,1],[472,1],[474,2],[483,1],[498,1],[500,5],[516,1],[525,2],[540,1],[542,2],[568,1],[573,1],[575,2],[578,2],[581,2],[584,2],[587,3],[612,2],[615,3],[633,1],[638,2],[657,1],[659,4],[670,2],[673,3],[677,3],[681,4],[690,1],[692,3],[714,1],[716,4],[721,4],[726,2],[729,2],[732,3],[736,3],[740,3],[744,2],[747,2],[750,2]]},"624":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"626":{"position":[[29,1],[43,1],[45,3],[49,3],[53,2],[56,3],[60,5],[66,2],[99,1],[106,2],[121,1],[123,3],[127,4],[141,1],[159,1],[161,3],[165,4],[170,1],[176,1],[178,2],[181,3],[185,3],[189,5],[195,1],[197,4],[212,3],[216,4],[221,3],[230,1],[232,5],[238,3],[247,2],[255,1],[262,1],[264,3],[280,1],[282,4],[287,5],[298,3],[302,4],[307,4],[324,1],[331,1],[346,2],[349,2],[352,4],[357,4],[381,1],[383,4],[388,3],[405,1],[407,4],[412,2],[415,2],[418,3],[422,5],[428,3],[432,5],[438,3],[442,4],[447,2],[453,1],[461,1],[473,1],[475,4],[480,4],[485,2],[516,2],[531,1],[538,1],[551,2],[559,1],[561,4],[566,1],[573,3],[577,2]]},"628":{"position":[[26,1],[33,1],[35,3],[39,3],[43,5],[49,4],[54,5],[72,3],[76,2],[79,4],[84,2],[87,2],[90,2],[93,5],[99,4],[104,3],[120,2],[136,1],[138,5],[159,1],[173,1],[182,1],[212,1],[214,4],[245,1],[247,2],[264,1],[304,1],[306,2],[327,1],[343,2],[346,2],[354,1],[356,1],[364,1],[381,1],[392,1],[413,1],[415,2],[428,2],[455,3],[475,4],[480,5],[490,1],[503,3],[507,5],[513,3],[545,1],[547,5],[553,2],[556,4],[561,3],[565,3],[579,3],[583,2],[586,2],[589,3],[598,1],[600,5],[611,1],[618,1],[634,3],[638,4],[643,2],[655,1],[669,1],[671,4],[676,1],[678,1],[680,3],[684,3],[688,1],[690,3],[714,1],[726,2],[741,1],[756,2],[759,4],[764,3],[768,2],[789,1],[795,1],[797,6],[804,1],[806,3],[810,5],[821,2],[824,3],[842,3],[851,1],[862,3],[866,2],[897,2],[904,1],[920,3],[924,2],[927,2],[930,1],[932,3],[936,2],[955,1],[962,3],[966,4],[971,2],[974,2],[982,1],[988,1],[990,5],[996,2],[1003,4],[1008,2],[1023,1],[1029,1],[1031,5],[1037,4],[1061,1],[1083,2],[1086,2],[1089,3],[1093,6],[1100,2],[1103,4],[1108,2],[1111,3],[1133,1],[1135,5],[1146,1],[1153,3],[1172,1],[1185,1],[1191,3],[1207,2],[1210,3],[1227,1],[1229,4],[1248,1],[1250,6],[1281,1],[1307,1],[1309,2],[1312,1],[1314,3],[1318,5],[1334,1],[1336,2],[1351,1],[1357,1],[1364,3],[1371,1],[1378,1],[1390,6],[1397,4],[1402,5],[1408,3],[1412,2],[1420,1],[1422,4],[1439,1],[1441,3],[1445,1],[1447,3],[1456,1],[1463,1],[1481,1],[1483,2],[1491,4],[1496,3],[1515,1],[1517,2],[1524,2],[1527,3],[1544,1],[1550,1],[1563,2],[1587,2],[1593,1],[1600,1],[1612,1],[1614,4],[1619,4],[1624,4],[1629,2],[1637,1],[1639,4],[1649,3],[1653,3],[1657,2]]},"630":{"position":[[0,2],[18,1],[32,1],[34,4],[43,1],[59,3],[63,5],[69,2],[85,1],[99,1],[113,2],[128,1],[140,1],[142,6],[149,6],[172,2],[187,1],[193,1],[200,3],[242,2],[249,1],[280,2],[288,1],[290,4],[311,3],[315,5],[321,2],[328,1],[330,2],[333,4],[338,1],[340,2],[343,3],[347,5],[372,2],[375,4],[380,2],[428,1],[444,1],[446,4],[463,1],[475,1],[487,1],[489,2],[496,2],[499,2],[509,1],[511,5],[529,1],[538,1],[552,2],[570,1],[572,2],[575,1],[589,1],[595,2],[614,1],[616,4],[621,1],[648,1],[654,1],[656,5],[671,3],[675,3],[679,5],[685,2],[700,3],[704,3],[721,1],[723,4],[742,1],[744,5],[762,1],[791,1],[831,1],[833,4],[851,1],[853,3],[865,1],[867,1],[875,1],[885,2],[888,3],[892,5],[898,3],[921,1],[923,4],[936,1],[938,1],[965,1],[983,1],[1020,1],[1056,1],[1072,1],[1074,2],[1081,1],[1083,2],[1086,3],[1090,4],[1095,2],[1117,1],[1119,4],[1128,1],[1130,5],[1144,2],[1172,1],[1174,4],[1198,1],[1214,1],[1216,4],[1221,5],[1227,3],[1231,1],[1233,3],[1254,1],[1308,1],[1331,1],[1352,1],[1354,4],[1359,3],[1363,2],[1366,2],[1369,2],[1372,1],[1399,1],[1401,5],[1440,1],[1570,1],[1581,1],[1595,1],[1602,1],[1612,1],[1614,4],[1641,1],[1683,1],[1685,4],[1702,1],[1710,1],[1712,1],[1714,3],[1718,5],[1827,1],[1829,4],[1851,1],[1863,1],[1875,1],[1877,5],[1883,2],[1899,1],[1901,5],[1907,2],[1910,3],[1918,2],[1921,3],[1969,1],[1984,1],[1986,7],[1994,2],[1997,2],[2045,1],[2052,1],[2054,4],[2076,1],[2078,2],[2093,1],[2107,3],[2111,1],[2125,4],[2130,1],[2132,3],[2136,3],[2140,1],[2142,3],[2217,1],[2236,1],[2238,1],[2240,2],[2243,4],[2248,5],[2258,1],[2270,1],[2272,3],[2288,1],[2294,1],[2296,6],[2303,1],[2305,4],[2314,1],[2326,1],[2356,2],[2364,1],[2373,1],[2399,1],[2401,3],[2405,1],[2407,2],[2410,3]]},"633":{"position":[[10,1],[24,2],[27,3],[31,2],[84,2],[96,1],[140,1],[172,3],[176,4],[181,5],[192,1],[194,2],[207,1],[221,2],[232,1],[246,1],[248,2],[254,1],[256,3],[268,1],[279,1],[293,2],[302,1],[311,1],[325,1],[327,2],[343,1],[345,2],[348,3],[375,1],[384,1],[386,2],[402,1],[418,2],[421,3],[425,3],[429,2],[432,1],[434,1],[436,3],[440,3],[444,3],[452,1],[454,3],[470,1],[500,2],[507,1],[509,5],[521,2],[541,1],[543,2],[551,1],[564,1],[566,3],[570,4],[575,2],[587,1],[589,3],[593,3],[658,1],[678,1],[719,1],[752,3],[783,1],[785,2],[803,1],[833,1],[839,1],[847,1],[885,2],[906,1],[930,1],[941,1],[962,1],[964,2],[1013,1],[1019,1],[1021,4],[1030,1],[1038,1],[1040,1],[1042,2],[1057,1],[1059,2]]},"635":{"position":[[21,1],[27,1],[29,4],[38,1],[46,1],[48,1],[50,2],[65,1],[67,2],[103,1],[109,1],[111,4],[120,1],[128,1],[130,1],[132,2],[147,1],[149,2]]},"638":{"position":[[10,1],[25,1],[31,2],[34,2],[61,1],[76,1],[102,1],[114,2],[138,1],[140,2],[143,3],[147,2],[150,3],[154,3],[158,3],[162,2]]},"640":{"position":[[8,1],[18,1],[31,1],[37,2],[40,2],[63,2],[85,2],[88,3],[115,2],[135,1],[137,3],[141,2],[144,2],[161,2],[164,5],[189,2],[192,2],[195,2],[206,1],[217,1],[231,1],[237,2],[240,2],[243,5],[268,2],[285,3],[307,2],[310,2],[313,2],[325,1],[327,5],[338,1],[340,3],[354,1],[356,6],[363,3],[367,3],[394,1],[396,4],[401,3],[413,1],[415,2],[422,1],[424,3],[428,4],[433,5],[439,1],[441,3],[449,1],[470,2],[483,1],[485,5],[491,5],[501,3],[505,2],[508,4],[513,3],[517,3]]},"642":{"position":[[21,1],[23,3],[27,5],[41,1],[47,2],[50,2],[53,3],[57,5],[67,1],[69,3],[73,2],[76,2],[79,3],[83,3],[87,3],[91,2],[94,2],[101,2],[108,2],[118,2],[131,3],[135,5],[141,2],[144,1],[146,3],[150,2],[166,1],[178,1],[184,2],[187,3],[191,2],[194,1],[196,1],[198,3],[215,1],[227,1],[233,1],[235,2],[238,3],[242,3],[246,3],[250,3],[254,3],[258,5],[264,2],[267,3],[271,2],[274,2],[277,3],[294,1],[306,3],[310,3],[314,3],[318,3],[328,1],[337,1],[339,4],[344,2],[347,3],[351,3]]},"644":{"position":[[0,3],[11,1],[32,2],[52,1],[59,1],[72,3],[76,3],[80,2],[83,3],[94,4],[99,3],[103,5],[117,2],[120,2],[123,1],[141,1],[158,1],[182,1],[184,4],[194,3],[198,2],[201,2],[209,1],[211,5],[228,1],[235,3],[239,3],[243,2],[252,2],[255,2],[258,1],[276,1],[293,1],[317,1],[319,4],[329,3],[333,2],[336,2],[344,1],[346,5],[363,1],[369,3],[373,3],[377,2],[380,3],[384,4],[393,1],[395,1],[397,5],[403,3],[407,1],[409,3],[423,2],[426,3],[435,3],[439,4],[452,1],[454,5],[464,1],[476,1],[478,5],[484,4],[499,2],[502,3],[506,3],[510,4]]},"646":{"position":[[0,2],[3,1],[5,1],[20,1],[22,5],[33,1],[35,4],[40,2],[47,1],[49,5],[67,1],[73,1],[75,4],[80,4],[85,7],[93,3],[101,1],[119,1],[121,2],[132,1],[151,1],[153,6],[177,1],[191,1],[193,1],[195,5],[206,1],[234,1],[236,2],[239,5],[258,1],[260,5],[279,3],[283,3],[287,1],[289,3],[293,5],[305,1],[307,5],[328,1],[339,1],[341,2],[344,2],[360,1],[362,3],[378,1],[384,1],[392,1],[403,2],[406,3],[410,2],[426,1],[428,5],[434,4],[439,5],[445,3],[449,2],[452,2],[455,2],[458,1],[460,3],[477,4],[482,3],[486,1],[488,3],[492,2],[495,2]]},"648":{"position":[[48,1],[66,1],[68,4],[88,1],[90,2],[103,1],[105,6],[112,8],[121,2],[124,4],[129,2],[132,4],[137,3],[158,2],[161,4],[166,2],[174,4],[183,1],[192,1],[194,1],[196,2],[199,5],[212,2],[235,1],[255,1],[257,2],[260,1],[262,2],[265,4],[285,1],[306,1],[341,1],[343,4],[374,3],[378,2],[395,1],[416,1],[439,2],[447,1],[461,1],[469,1],[485,1],[496,1],[517,2],[527,1],[546,3],[550,1],[552,3],[561,1],[563,5],[569,3],[573,2],[576,3],[580,4],[597,1],[599,5],[632,1],[634,4],[639,3],[643,3],[647,3],[651,2],[654,3],[658,3],[662,3],[666,4],[671,3],[675,5],[681,3],[685,2],[716,3],[758,1],[776,1],[791,1],[793,2],[796,4],[810,1],[812,5],[822,1],[834,1],[836,3],[840,4],[845,2],[848,3],[852,3],[890,1],[914,2],[921,1],[939,1],[950,1],[952,1],[954,2],[957,4],[990,1],[992,6],[1040,1],[1042,4],[1047,1],[1049,3],[1053,2],[1056,3],[1060,2],[1063,1],[1065,1],[1067,3],[1071,3],[1075,3],[1083,1],[1085,3],[1099,1],[1101,2],[1104,5],[1114,1],[1116,3],[1120,6],[1127,4],[1132,4],[1137,3],[1141,1],[1143,3]]},"650":{"position":[[9,2],[12,2],[19,1],[21,3],[25,3],[41,2],[48,1],[62,1],[64,3],[68,2],[83,1],[89,3],[112,1],[126,1],[128,4],[133,1],[148,1],[150,2],[157,1],[178,1],[180,2],[183,2],[203,1],[210,1],[212,4],[244,3],[266,2]]},"652":{"position":[[8,1],[10,2],[13,1],[15,2],[22,1],[24,2],[27,5],[33,3],[37,1],[39,4],[44,2],[47,5],[56,1],[58,3],[62,2],[65,3],[69,5],[75,2],[78,2],[81,4],[86,1],[88,2],[91,3],[95,5],[101,3],[105,4],[110,1],[112,2],[115,2],[118,3],[122,2],[125,3],[129,2],[132,2],[135,2]]},"654":{"position":[[0,2],[3,3],[7,1],[9,2],[12,1]]},"656":{"position":[[30,1],[36,2],[39,4],[63,3],[67,4],[88,1],[90,2],[93,3],[97,2],[105,2],[125,1],[127,4],[132,7],[140,1],[142,4],[147,3],[166,1],[168,3],[181,2],[184,3],[188,4],[193,2],[196,2],[204,1],[231,1],[233,2],[236,1],[238,2],[241,2],[244,2],[247,2],[259,1],[261,2],[264,2],[267,2],[270,3],[284,1],[286,5],[292,3],[314,1],[316,2],[327,3],[331,3],[335,2],[343,1],[353,1],[355,3],[364,2],[381,1],[397,4],[402,2],[410,1],[412,3],[416,3],[420,2],[428,2],[436,1],[453,1],[455,4],[477,2],[485,3],[489,3],[493,2],[513,1],[530,2]]},"658":{"position":[[27,1],[38,2],[41,3],[45,3],[49,3],[53,2],[74,1],[95,1],[97,3],[121,1],[128,1],[150,1],[182,2],[190,3],[194,5],[200,1],[202,3],[249,1],[251,2],[254,3],[258,2],[270,1],[289,1],[291,4],[296,2],[299,1],[301,4],[306,3],[310,2],[313,4],[318,5],[324,2],[327,4],[337,1],[339,3],[351,1],[353,5],[359,5],[365,2],[368,2],[376,2],[379,2],[382,2],[393,2],[407,1],[426,1],[428,4],[451,2],[454,2],[471,1],[478,1],[514,1],[516,4],[521,2],[529,2],[549,1],[551,2],[554,3],[558,2],[561,2],[573,1],[575,3],[579,1],[581,3],[585,5],[591,3],[595,1],[597,2],[600,3],[604,3],[608,3],[612,4],[617,2],[620,2],[623,2],[630,2],[633,4],[656,1],[681,1],[695,3],[699,3],[703,3],[715,1],[717,3],[721,3],[725,2],[773,1],[804,1],[819,2],[839,1],[913,1],[936,2],[939,4],[944,1],[946,2],[949,2],[962,1],[988,1],[990,2],[1005,1],[1027,1],[1036,1],[1038,4],[1043,2],[1053,1],[1071,1],[1073,2],[1083,2],[1086,3],[1090,3],[1106,1],[1108,2],[1134,2],[1137,2],[1140,2],[1151,1],[1189,1],[1203,2],[1206,1],[1213,1],[1215,2],[1233,2],[1256,1],[1263,2],[1266,4],[1283,1],[1305,4],[1310,3],[1329,1],[1331,2],[1361,2],[1374,1],[1376,3],[1389,1],[1396,1],[1416,1],[1418,3],[1443,1],[1457,1],[1459,2],[1479,1],[1481,1],[1483,3],[1487,1],[1489,2],[1492,4],[1497,3],[1501,2],[1504,2],[1515,1],[1537,3],[1541,3],[1578,1],[1602,2],[1605,3],[1609,2],[1612,3],[1616,3],[1634,1],[1636,2],[1686,1],[1688,5],[1717,1],[1740,1],[1774,1],[1776,4],[1781,1],[1828,2],[1831,2],[1867,1],[1869,2],[1884,1],[1886,1],[1897,1],[1899,2],[1925,1],[1927,4],[1932,3],[1936,2],[1939,4],[1944,3],[1963,1],[1965,3],[2011,2],[2028,1],[2043,2],[2046,2],[2076,1],[2091,1],[2102,1],[2104,5],[2110,3],[2180,2],[2183,2],[2190,1],[2212,1],[2214,3],[2238,1],[2240,5],[2275,1],[2287,1],[2289,4],[2294,2],[2297,2],[2326,1],[2328,4],[2333,2],[2341,1],[2376,1],[2378,3],[2382,3],[2386,3],[2394,1],[2396,4],[2401,3],[2411,1],[2413,2],[2421,1],[2423,3],[2427,3],[2431,2],[2434,3],[2438,4],[2443,2],[2446,2],[2470,1],[2483,1],[2504,1],[2506,2],[2509,3],[2533,2],[2550,3],[2554,3],[2558,3],[2562,2],[2570,1],[2572,2],[2575,4],[2580,4],[2600,3],[2604,3],[2627,1],[2649,3],[2653,2],[2656,2],[2667,1],[2681,1],[2683,2],[2691,1],[2700,2],[2703,3],[2707,4],[2712,2],[2723,1],[2730,1],[2732,6],[2739,2],[2759,1],[2770,2],[2773,2],[2776,4],[2781,2],[2814,1],[2816,4],[2821,2],[2829,1],[2831,2],[2834,3],[2838,3],[2842,2],[2845,2],[2848,3],[2852,3],[2856,3],[2868,1],[2874,1],[2903,3],[2907,2],[2910,3],[2939,2],[2942,2],[2945,3],[2974,1],[2987,1],[2989,4],[2994,5],[3005,2],[3030,3],[3034,5],[3064,1],[3069,1],[3071,2],[3087,1],[3106,1],[3142,2],[3145,3],[3149,2],[3152,3],[3156,5],[3177,1],[3204,1],[3206,2],[3209,4],[3234,2],[3242,2]]},"660":{"position":[[0,3],[4,2],[23,2],[50,2],[53,3],[57,3],[61,1],[63,2],[66,2],[69,3],[73,2],[76,2],[79,2],[82,2],[90,1],[92,5],[98,3],[102,2],[105,2],[108,5],[114,3],[118,4],[123,3],[127,2],[135,1],[137,2],[140,4],[145,2],[148,3],[152,3],[156,3],[160,4],[165,5],[171,5],[177,2],[196,1],[198,4],[203,3],[207,3],[211,3],[215,6],[222,1],[224,3],[228,4],[233,3],[237,3],[271,1],[273,2],[291,1],[293,3],[304,1],[320,1],[322,4],[327,3],[331,6],[354,1],[356,2],[374,1],[396,1],[414,3],[418,5],[424,2],[440,2],[443,3],[462,3],[466,2],[469,5],[485,3],[489,2],[509,1],[518,1],[520,4],[525,2],[528,3],[550,1],[582,2],[599,1],[617,1],[619,2],[622,2],[625,2],[643,1],[662,1],[673,3],[677,2],[685,2],[688,3],[692,1],[694,2],[712,1],[714,1],[716,3],[720,3],[755,1],[774,1],[782,1],[784,2],[787,3],[791,1],[793,2],[796,2],[804,1],[806,3],[810,1],[829,1],[831,5],[837,3],[841,4],[846,2],[892,1],[894,4],[899,3],[903,2],[906,2],[909,3],[913,5],[927,1],[952,2],[955,3],[959,1],[961,2],[964,2],[967,1],[986,1],[988,3],[992,2],[995,2],[998,2],[1001,2],[1012,1],[1022,1],[1024,2],[1051,1],[1053,3],[1057,2],[1060,4],[1065,1],[1067,2],[1085,1],[1087,4],[1092,2],[1095,2],[1098,3],[1102,1],[1104,2],[1107,2],[1118,1],[1120,2],[1123,3],[1127,4],[1132,5],[1138,4],[1165,2],[1168,3],[1172,3],[1176,1],[1178,3]]},"662":{"position":[[12,1],[14,2],[38,1],[40,5],[46,1],[48,3],[52,3],[61,1],[67,1],[74,3],[78,3],[116,5],[137,1],[139,2],[156,4],[161,5],[167,3],[171,2],[174,3],[178,4],[183,3],[187,3],[191,2],[194,3],[198,2],[201,2],[204,3],[208,8],[217,2],[220,3],[224,3],[236,2],[239,2],[242,4],[247,5],[253,1],[255,4],[260,2],[270,1],[293,1],[307,1],[309,3],[313,3],[329,1],[331,1],[339,1],[364,3],[384,1],[404,1],[412,2],[432,1],[434,4],[450,1],[462,1],[480,2],[483,1],[495,1],[504,1],[526,1],[528,2],[531,3],[535,1],[547,2],[550,2],[572,2],[583,1],[585,2],[604,3],[608,2],[611,2],[625,1],[627,2],[641,1],[643,3],[647,1],[649,5],[671,3],[675,2],[693,1],[695,1],[697,2],[720,1],[722,2],[725,2],[738,2],[741,4],[746,2],[773,2],[784,1],[786,2],[822,1],[846,2],[860,1],[862,2],[878,4],[883,2],[900,2],[920,1],[922,4],[927,5],[940,4],[945,1],[983,1],[985,5],[996,1],[998,4],[1013,2],[1016,2],[1019,3],[1039,1],[1041,1],[1065,2],[1093,1],[1095,3],[1119,1],[1131,2],[1134,3],[1138,2],[1156,3],[1160,5],[1198,1],[1200,5],[1233,1],[1245,1],[1247,4],[1252,2],[1262,1],[1294,2],[1297,6],[1319,1],[1327,1],[1329,2],[1332,1],[1339,1],[1341,2],[1378,1],[1380,2],[1383,2],[1467,1],[1504,1],[1506,2],[1515,1],[1535,1],[1537,4],[1550,1],[1583,2],[1586,3],[1620,2],[1623,4],[1628,2],[1631,2],[1634,3],[1638,3],[1642,3],[1646,1]]},"664":{"position":[[0,3],[12,1],[24,1],[26,2],[58,3],[62,3],[71,6],[83,1],[97,1],[104,3],[108,4],[125,1],[140,1],[142,2],[145,1],[147,3],[174,1],[201,1],[203,2],[206,2],[209,2],[212,2],[236,1],[259,1],[261,4],[266,4],[271,2],[274,3]]},"666":{"position":[[36,1],[49,1],[51,2],[59,4],[79,3],[83,2],[106,1],[108,4],[113,1],[124,1],[138,1],[171,2],[174,1],[182,1],[194,1],[209,1],[211,4],[228,1],[230,2],[233,2],[236,3],[260,1],[262,2],[280,2],[288,1],[304,1],[306,2],[320,1],[322,5],[328,3],[332,1],[334,1],[336,5],[342,4],[349,2],[352,1],[376,2],[414,2],[432,1],[434,4],[439,2],[453,2],[461,1],[475,1],[477,5],[487,1],[494,1],[496,2],[511,1],[541,1],[547,1],[549,2],[552,3],[568,2],[571,2],[584,1],[586,3],[590,2],[593,3],[597,3],[601,3],[605,6],[624,1],[626,3],[630,5]]},"668":{"position":[[5,2],[8,3],[12,2],[30,1],[42,1],[44,3],[91,2],[124,2],[299,2],[302,1],[337,1],[344,1],[356,2],[372,1],[381,1],[415,2],[418,5],[424,2],[427,2],[430,2],[455,1],[472,1],[474,2],[488,2],[499,1],[512,2],[520,3],[541,1],[569,1],[579,1],[581,3],[590,1],[592,2],[603,1],[605,2],[615,1],[620,1],[622,4],[627,2],[635,2],[638,2],[641,2],[656,1],[663,1],[686,1],[707,5]]},"670":{"position":[[8,1],[10,4],[15,3],[19,2],[22,3],[26,3],[30,1],[32,2],[35,3],[64,1],[66,2],[69,2],[80,1],[86,1],[93,3],[103,1],[107,1],[113,3],[117,2],[132,1],[137,1],[158,2],[161,5],[167,4],[186,3],[190,2],[318,3],[322,2],[325,2],[392,1],[402,1],[418,2],[490,2],[501,1],[503,5],[521,2],[524,2],[535,2],[538,2],[541,1],[543,5],[549,4],[565,2],[568,2],[571,2],[588,1],[602,2],[605,4],[689,1],[691,4],[728,1],[740,2],[753,1],[755,2],[758,3],[771,1],[773,3],[794,1],[796,6],[803,3],[807,2],[810,4],[815,2],[818,2],[821,2],[824,3],[855,2],[863,1],[894,1],[896,3],[936,2],[939,2],[957,1],[959,3],[997,2],[1000,2],[1015,1],[1045,2],[1055,1],[1062,1],[1064,2],[1080,1],[1086,2],[1089,4],[1101,2],[1104,5],[1115,1],[1121,1],[1123,3],[1127,2],[1130,2],[1133,4],[1138,4],[1143,2],[1157,2],[1165,4],[1170,1],[1172,2],[1225,1],[1235,1],[1237,2],[1256,1],[1263,1],[1265,3],[1269,3],[1273,2],[1276,2],[1285,1],[1287,5],[1298,1],[1300,5],[1306,2],[1309,2],[1312,2],[1320,1],[1322,3],[1326,2],[1329,2],[1332,2],[1350,1],[1352,3],[1368,1],[1370,2],[1373,2],[1395,1],[1425,1],[1431,2],[1455,1],[1457,2],[1460,1],[1462,2],[1465,2],[1468,5],[1486,1],[1488,3],[1513,1],[1527,1],[1529,2],[1536,3],[1540,1],[1547,2],[1558,1],[1560,2],[1563,1],[1565,5],[1576,1],[1598,1],[1600,4],[1605,2],[1617,1],[1619,2],[1638,2]]},"672":{"position":[[13,1],[35,1],[37,2],[56,1],[74,1],[76,5],[82,2],[85,2],[88,3],[92,1],[94,2],[97,3],[111,1],[113,4],[118,2],[121,3],[138,1],[140,4],[145,1],[147,2],[159,3],[181,1],[198,1],[243,1],[259,1],[261,1],[269,1],[271,2],[294,1],[296,3],[332,1],[334,3],[343,2],[359,1],[373,1],[375,1],[377,2],[380,3],[384,3],[404,1],[406,3],[423,3],[427,3],[431,2],[434,3],[450,1],[452,2],[455,3],[459,2],[462,2],[473,1],[475,1],[477,2],[480,3],[484,4],[489,2],[492,2],[495,2],[498,2],[508,1],[510,1],[533,1],[540,1],[542,2],[545,1],[547,3],[551,2],[565,1],[574,2],[586,1],[593,1],[595,2],[598,1],[600,2],[627,1],[629,2],[632,3],[636,2],[653,1],[655,4],[672,1],[674,1],[676,2],[679,2],[682,2],[685,1],[710,1],[722,1],[736,2],[749,1],[808,2],[811,2],[822,1],[839,1],[841,1],[866,2],[926,2],[946,1],[988,2],[996,3],[1000,3],[1004,2],[1007,2],[1010,3],[1014,3],[1018,3],[1042,1],[1054,1],[1063,1],[1071,1],[1093,1],[1110,1],[1112,5],[1118,2],[1121,2],[1144,2],[1173,1],[1175,2],[1182,3],[1186,2],[1189,2],[1192,2],[1200,2],[1203,1],[1221,2],[1224,1],[1229,2],[1232,2],[1235,4],[1255,1],[1277,1],[1279,2],[1282,3],[1286,3],[1290,2],[1307,2],[1327,1],[1329,4],[1334,3],[1346,3],[1350,2],[1368,1],[1401,1],[1411,1],[1413,6],[1449,1],[1451,3],[1455,2],[1458,3],[1462,2]]},"674":{"position":[[0,6],[15,1],[32,2],[40,3],[44,5],[50,3],[54,2],[68,2],[71,2],[81,1],[104,2],[119,1],[161,1],[163,3],[176,1],[198,1],[200,5],[206,2],[209,2],[224,1],[226,2],[241,1],[243,3],[262,2],[415,1],[608,3],[620,1],[638,1],[640,6],[664,1],[666,3],[670,2],[673,2],[707,1],[718,2],[733,1],[741,2],[750,1],[783,2],[786,1],[788,3],[801,2]]},"676":{"position":[[0,3],[12,1],[14,3],[18,4],[23,2],[35,2],[38,2],[41,2],[44,2],[47,2],[67,1],[69,4],[89,2],[98,3],[102,4],[107,3],[118,1],[125,1],[132,2],[151,1],[179,2],[208,2],[219,4],[224,2],[227,3],[231,3],[256,3],[260,2],[263,3],[267,2],[270,3],[274,2],[285,1],[287,3],[291,3],[308,2],[319,3],[323,2],[326,2],[329,1],[331,2],[334,3],[341,6],[360,4],[365,2],[368,2],[371,2],[389,1],[395,1],[397,2],[400,1],[402,3],[406,1],[416,1],[418,2],[429,1],[431,3],[435,3],[439,4],[444,4],[449,3],[453,2],[456,3],[467,1],[481,1],[493,2],[496,2],[499,3],[503,3],[507,2],[515,1],[527,2],[538,4],[543,2],[546,3],[550,2],[553,3],[557,2],[560,2],[571,1],[573,4],[588,1],[590,2],[593,4],[606,1],[608,1],[610,4],[615,2],[618,2],[631,1],[633,4],[638,2],[653,2],[656,2],[659,4],[664,2],[675,1],[700,1],[702,4],[727,1],[729,5],[745,1],[747,2],[755,1],[757,2],[768,1],[770,2],[773,2],[776,2],[784,3],[798,1],[812,2],[815,2],[835,2],[838,3],[842,3],[846,3],[850,2],[853,2],[865,3],[890,1],[892,2],[906,2],[909,2],[912,4],[939,1],[941,5],[963,1],[984,2],[987,2],[1011,1],[1013,2],[1016,3],[1020,2],[1023,2],[1026,3],[1059,4],[1064,3],[1068,1],[1070,4],[1075,2],[1086,3],[1106,3],[1110,2],[1113,3],[1145,1],[1147,2],[1150,2],[1153,2],[1156,3],[1160,2],[1183,1],[1185,2],[1188,2],[1191,2],[1205,2],[1217,1],[1219,2],[1222,3],[1239,1],[1241,3],[1245,1],[1247,2],[1250,3],[1254,5],[1260,2],[1263,1],[1278,1],[1280,2],[1283,3],[1287,4],[1292,3],[1296,4],[1323,2],[1326,2],[1329,2],[1332,3],[1336,2],[1339,3],[1343,2],[1352,1],[1358,1],[1360,2],[1363,2],[1366,2],[1369,4],[1374,2],[1390,1],[1398,2],[1411,1],[1413,4],[1418,3],[1422,4],[1427,2],[1430,6],[1458,1],[1460,2],[1463,3],[1467,3],[1471,2],[1474,3],[1478,2],[1489,1],[1517,2],[1528,1],[1536,1],[1538,2],[1546,2],[1549,3],[1589,4],[1602,2],[1616,1],[1618,3],[1630,2],[1660,1],[1662,2],[1665,3],[1669,2],[1672,2],[1675,3],[1691,1],[1704,1],[1706,3],[1710,2],[1713,3],[1717,4],[1722,3],[1726,3],[1730,3],[1734,2],[1737,3],[1762,2]]},"679":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1],[84,1],[86,5],[98,1],[109,1],[123,2],[126,3],[150,2],[153,4],[172,1],[209,1],[220,2],[223,5],[229,4],[243,1],[245,5],[251,3],[255,3],[271,2],[281,1],[283,4],[288,3],[292,5],[298,3],[302,3],[306,3],[310,1],[312,4],[322,1],[324,4],[338,1],[340,2],[373,1],[383,2],[386,2],[403,1],[429,1],[431,2],[434,3],[438,3],[442,1],[444,3],[448,2],[463,1],[487,1],[495,2],[498,2],[512,1],[528,1],[546,1],[548,2],[561,3],[565,2],[568,2],[585,1],[592,1],[594,3],[604,1],[618,2],[621,4],[626,3],[637,3],[641,3],[645,3],[649,3],[653,4],[658,2]]},"681":{"position":[[5,1],[16,2],[19,3],[23,3],[27,6],[34,2],[37,3],[41,4],[46,3],[50,5],[73,2],[81,1],[83,2],[86,4],[91,3],[95,3],[99,4],[104,4],[109,4],[119,1],[133,1],[149,1],[151,2],[163,1],[172,1],[174,2],[177,2],[202,3],[206,1],[213,1],[215,2],[234,1],[236,4],[241,6],[248,2],[251,3],[255,4],[275,1],[277,4],[282,3],[286,3],[307,3],[311,3],[342,1],[344,5],[350,2],[368,1],[383,3],[387,5],[447,2],[466,2],[478,1],[480,3],[509,1],[550,5],[556,2],[590,1],[592,2],[595,1],[597,4],[625,4],[630,3],[634,4],[659,2],[662,5],[668,4],[673,3],[677,1],[679,3],[700,1],[702,2],[705,3],[709,2],[712,5],[718,2],[821,6],[828,2],[854,1],[862,1],[872,3],[876,1],[885,1],[899,2],[902,1],[904,6],[932,2],[935,5],[955,1],[957,2],[992,1],[994,2],[997,1],[999,4],[1004,3],[1008,3],[1012,5],[1023,3],[1044,1],[1046,1],[1048,3],[1052,4],[1057,2],[1060,6],[1081,1],[1083,5],[1089,2],[1092,5],[1103,4],[1108,4],[1125,1],[1127,4],[1132,2],[1135,4],[1140,2],[1157,1],[1159,2],[1174,1],[1176,4],[1206,1],[1208,5],[1214,3],[1218,4],[1223,2],[1226,3],[1230,3],[1234,3],[1238,3],[1242,3],[1246,2],[1249,1],[1251,4],[1270,1],[1272,2],[1305,1],[1315,1],[1317,2],[1334,1],[1336,6],[1356,1],[1358,4],[1380,1],[1382,3],[1386,1],[1388,3],[1392,2],[1395,3],[1399,1],[1401,5],[1407,4],[1420,2],[1423,3],[1441,1],[1443,3],[1455,1],[1468,1],[1483,1],[1485,2],[1492,1],[1494,2],[1497,1],[1506,1],[1526,2],[1550,1],[1552,3],[1563,1],[1573,1],[1592,1],[1603,1],[1627,1],[1629,1],[1631,5],[1643,2],[1668,1],[1670,2],[1673,4],[1687,1],[1689,3],[1693,4],[1715,2],[1726,1],[1733,1],[1735,2],[1738,3],[1742,2],[1745,3],[1764,2],[1784,1],[1786,4],[1791,4],[1796,4],[1801,2],[1836,1],[1855,1],[1857,3],[1861,3],[1865,3],[1869,5],[1875,3],[1879,3],[1883,2],[1886,2],[1889,2],[1905,1],[1907,2],[1921,1],[1936,1],[1965,1],[1967,4],[1972,3],[1976,3],[1987,1],[1989,5],[1995,3],[2023,2],[2036,1],[2038,3],[2047,1],[2049,4],[2054,4],[2064,1],[2066,2],[2069,5],[2075,2]]},"683":{"position":[[61,2],[96,2],[106,3],[119,2],[122,3],[126,5],[158,1],[187,2],[190,4],[195,3],[227,1],[259,1],[261,2],[264,3],[268,5],[274,4],[331,1],[363,3],[367,3],[375,1],[377,3],[401,5],[407,3],[421,2],[424,3],[428,3],[432,2],[447,1],[449,4],[454,3],[458,1],[465,1],[467,2],[482,1],[494,1],[496,4],[501,4],[506,2],[514,1],[516,2],[519,3],[556,3],[560,3],[564,2],[572,1],[574,4],[579,6],[586,2],[589,2],[592,5],[598,3],[634,1],[640,1],[642,5],[663,1],[678,1],[680,2],[683,5],[689,4],[709,1],[722,1],[736,1],[738,2],[741,2],[744,4],[762,1],[775,1],[785,1],[787,3],[797,1],[799,3],[803,3],[831,4],[865,2],[868,3],[892,1],[906,1],[908,2],[911,2],[914,1],[922,1],[924,3],[928,1],[930,3],[934,2],[951,1],[953,3],[957,3],[961,3],[965,2],[988,1],[990,5],[1010,1],[1012,4],[1017,2],[1020,3],[1024,4],[1029,3],[1033,3],[1037,3],[1053,2],[1063,1],[1065,4],[1070,3],[1074,5],[1080,2],[1083,3],[1116,1],[1142,1],[1144,5],[1157,1],[1176,1],[1178,5],[1184,2],[1187,3],[1215,1],[1217,3],[1221,3],[1225,1],[1227,2]]},"686":{"position":[[14,1],[21,1],[39,1],[41,2],[44,3],[48,2],[93,2],[141,1],[143,2],[146,1],[155,1],[204,1],[214,2],[254,1],[305,2],[326,1],[352,1],[380,1],[409,1],[419,1],[430,1],[441,1],[443,1],[461,1]]},"688":{"position":[[14,1],[16,3],[20,2],[23,4],[53,1],[85,1],[87,4],[92,3],[110,2],[126,1],[134,1],[144,3],[148,2],[182,1],[202,1],[215,1],[228,1],[251,1],[253,4],[258,2],[287,1],[339,1],[452,1],[468,1],[490,1],[574,1],[591,1],[635,1],[645,1],[675,2],[695,1],[697,3],[725,1],[727,6],[745,2],[748,5],[754,2],[757,3],[761,3],[765,3],[769,3],[773,3],[777,3],[817,1],[830,1],[845,1],[887,5],[912,1],[936,1],[938,4],[943,3],[961,1],[981,1],[983,4],[988,2],[1012,1],[1037,1],[1039,2],[1055,1],[1072,1],[1082,2],[1085,2],[1088,5],[1094,1],[1096,1],[1098,3],[1111,3],[1133,1],[1153,1],[1155,2],[1158,5],[1164,5]]},"690":{"position":[[0,2],[3,4],[8,3],[22,1],[24,1],[31,2],[52,2],[111,1],[127,1],[146,1],[148,2],[174,1],[190,2],[193,3],[221,1],[233,1],[249,1],[251,2],[254,2],[257,3],[268,2],[282,1],[299,1],[312,1],[346,1],[360,1],[374,1],[382,1],[384,2],[401,1],[420,1],[434,1],[450,1],[470,2],[473,2],[476,3],[488,1],[490,4],[495,3],[522,1],[538,1],[540,3],[544,3],[548,2],[551,3],[555,3],[559,5],[579,1],[581,3],[603,3],[607,4],[612,2],[627,1],[647,1],[649,3],[653,2],[680,2],[683,2],[686,2],[689,3],[717,1],[719,2],[722,2],[743,1],[758,2],[761,3],[765,3],[769,1],[771,1],[773,2],[776,2],[791,1],[807,1],[827,3],[831,2],[834,2],[837,2],[840,2],[843,3],[847,3],[869,1],[885,1],[887,3],[891,3],[895,3],[899,1],[901,2],[904,4],[909,4],[914,4],[933,1],[947,4],[952,4],[957,3],[961,4],[966,2]]},"692":{"position":[[0,3],[28,1],[48,1],[50,4],[77,1],[79,4],[84,2],[87,3],[91,2],[94,3],[98,3],[102,2],[115,2],[118,3],[122,2],[125,2],[128,1],[130,2],[133,2],[136,3],[140,2],[167,1],[195,1],[212,1],[214,2],[217,3],[221,2],[241,1],[243,2],[257,1],[274,2],[277,3],[300,1],[311,3],[322,1],[341,3],[345,3],[367,2],[389,1],[405,1],[407,3],[430,2],[433,5],[439,2]]},"694":{"position":[[0,4],[19,1],[21,5],[41,1],[78,2],[81,5],[87,3],[102,1],[104,2],[107,2],[118,1],[120,1],[148,1],[165,2],[168,3],[172,4],[177,2],[191,1],[193,4],[198,2],[225,3],[229,4],[234,3],[247,1],[249,3],[253,5],[265,6],[272,1],[288,1],[312,1],[314,2],[369,1],[371,2],[387,1],[429,1],[458,1],[460,2],[463,3],[467,1],[483,1],[485,3],[489,2],[492,2],[511,1],[604,1],[669,1],[720,1],[750,1],[752,3],[768,1],[791,2],[794,2],[797,3],[853,1],[899,1],[901,5],[911,1],[922,4],[927,4]]},"696":{"position":[[14,1],[25,1],[27,2],[40,3],[44,7],[52,1],[68,2],[71,2],[74,5],[86,2],[89,3],[93,3],[106,1],[120,1],[140,1],[155,1],[157,1],[159,3],[163,2],[166,2],[169,1],[171,3],[175,3],[196,3],[200,3],[204,3],[208,4],[213,3],[217,5],[223,2],[226,5],[232,2],[248,3],[252,1],[254,2],[267,1],[269,4],[274,4],[301,2],[304,4],[321,1],[323,5],[329,4],[334,2],[337,5],[343,2],[346,3],[350,1],[366,2],[385,1],[387,3],[415,1],[417,2],[420,3],[442,1],[462,1],[482,1],[484,4],[489,3],[493,1],[495,3],[517,1],[537,1],[557,1],[559,5],[582,2],[600,1],[606,1],[615,2],[633,1],[635,2],[638,3],[660,1],[662,6],[675,2],[704,1],[706,6],[731,1],[751,1],[771,1],[773,5],[783,1],[800,1],[802,2],[805,3],[809,1],[811,2],[851,1],[853,2],[856,3],[878,1],[893,1],[905,1],[907,1],[909,2],[912,2],[915,3],[919,4],[942,1],[959,1],[961,2],[974,1],[994,2],[997,7],[1017,2],[1020,1],[1022,1],[1024,4],[1053,1],[1055,6],[1075,1],[1077,3],[1081,1],[1083,2],[1086,3],[1105,1],[1122,1],[1124,2],[1149,1],[1151,5],[1181,1],[1193,1],[1213,4],[1218,5],[1224,2],[1253,1],[1255,3],[1259,3],[1292,1],[1316,1],[1339,1],[1370,1],[1435,1],[1560,1],[1565,1],[1597,1],[1614,1],[1642,2],[1671,3],[1675,2],[1696,1],[1707,1],[1709,2],[1729,1],[1731,5]]},"698":{"position":[[0,1],[18,1],[20,3],[42,2],[59,1],[61,5],[86,1],[88,1],[102,2],[117,1],[119,2],[134,1],[181,1],[191,1],[203,1]]},"701":{"position":[[0,2],[17,3],[21,2],[33,1],[45,2],[48,2],[51,2],[90,1]]},"703":{"position":[[19,1],[21,5],[39,1],[84,1],[121,1],[137,2],[152,1],[154,1],[174,1],[176,4],[189,2],[200,1],[202,2],[205,2],[230,1],[252,1],[272,1],[288,1],[290,3],[294,1],[296,3],[300,2],[323,2]]},"705":{"position":[[8,1],[24,3],[28,2],[42,1],[44,4],[49,2],[78,2],[81,2],[84,1],[96,1],[98,2],[114,4],[119,2],[122,1],[124,2],[127,3],[136,3],[165,2],[168,3],[172,3],[193,1],[220,1],[222,4],[227,2],[247,2],[250,5],[266,1],[286,1],[288,2],[291,3],[340,2],[370,4],[393,2]]},"707":{"position":[[8,1],[10,3],[23,2],[26,4],[54,5],[77,1],[79,4],[84,3],[88,3],[101,1],[109,3],[121,1],[127,3],[139,1],[153,1],[155,4],[160,2],[169,1],[177,2],[180,2],[197,3],[201,2],[223,1],[225,5],[240,3],[244,2],[247,3],[251,4],[256,3],[260,2],[263,3],[267,3],[288,1],[290,3],[294,2],[297,2],[300,3],[304,3],[308,4],[321,1],[323,4],[328,2],[348,2],[351,3],[355,2],[358,5],[372,2],[390,2],[393,3],[397,2],[400,3],[404,2],[407,3],[411,1],[413,3],[417,3],[430,1],[432,5],[438,5],[453,1],[455,1],[462,1],[464,4],[469,7],[477,2],[500,3],[512,1],[514,4],[536,1],[538,6],[558,1],[560,3],[564,2],[567,4],[572,2],[575,2],[587,3],[603,1],[605,4],[630,1],[632,3],[645,2],[648,3],[652,4],[657,2],[672,1],[674,2],[698,2],[705,1],[707,3],[711,2],[714,3],[718,2],[721,2],[724,2],[727,2],[767,1],[769,5],[787,1],[789,2],[806,2],[809,2],[812,3],[816,2]]},"709":{"position":[[34,3],[46,1],[57,1],[80,3],[84,3],[88,2],[118,1],[120,3],[124,3],[146,1],[148,4],[153,1],[160,1],[162,2],[177,1],[179,4],[201,2],[204,2],[207,3],[232,1],[247,1],[249,4],[270,1],[280,1],[302,3],[306,2],[316,1],[318,3],[322,2],[325,3],[329,6],[344,1],[361,1],[367,2],[375,2],[387,1],[389,4],[394,2],[397,4],[416,1],[430,1],[432,4],[437,1],[439,2],[442,3],[446,2],[449,2],[465,1],[467,3],[471,1],[485,1],[487,5],[493,5],[513,1],[527,1],[529,2],[532,3],[536,3],[540,3],[544,3],[578,3],[589,1],[591,3],[595,4],[600,3],[604,3],[628,1],[630,4],[650,2],[653,6],[660,1],[662,2],[665,4],[670,3],[674,2],[677,2],[694,2],[715,2],[736,2],[749,1],[769,2],[772,2],[775,2],[778,3],[800,1],[802,3],[806,3],[810,1],[812,4],[817,2],[820,1],[822,1],[824,3],[842,2],[853,1],[855,2],[858,3],[879,2],[882,3],[886,4],[891,3],[895,3],[899,2],[902,2],[919,1],[921,4],[936,1],[956,1],[958,4],[963,3],[978,1],[980,4],[993,1],[995,2],[1006,3],[1010,3],[1014,2],[1050,2],[1063,1],[1082,1],[1091,1],[1093,6],[1115,2],[1118,3],[1136,1],[1138,2],[1141,3],[1145,3],[1149,3],[1153,4],[1158,3],[1162,3],[1180,1],[1231,2],[1234,4],[1239,2],[1242,2],[1245,3],[1249,2],[1252,3],[1260,1],[1266,1],[1268,2],[1278,1],[1280,2],[1283,3],[1287,2],[1295,1],[1297,2],[1300,4],[1305,3],[1309,3],[1313,4],[1340,1],[1342,3],[1346,2],[1349,1],[1351,1],[1353,3],[1357,3],[1365,2],[1388,1],[1395,3],[1399,2],[1402,2],[1405,2],[1413,1],[1423,1],[1425,2],[1428,2],[1431,3],[1435,3],[1439,4],[1456,1],[1458,4],[1471,1],[1483,1],[1485,5],[1491,4],[1496,2],[1514,1],[1516,4],[1521,2],[1524,2],[1527,3],[1531,2],[1554,2],[1557,4],[1562,3],[1566,4],[1571,4],[1576,2],[1579,2],[1582,4],[1587,3],[1591,3],[1595,4],[1628,2],[1631,2],[1634,3],[1638,2],[1657,1],[1659,3],[1663,2],[1674,1],[1684,1],[1686,3],[1697,3],[1701,4],[1706,2],[1709,2],[1712,2],[1715,2],[1718,2],[1790,1],[1806,1],[1815,1],[1817,4],[1822,2],[1830,2],[1833,2],[1836,4],[1841,2],[1844,3],[1848,2],[1863,2],[1879,2],[1889,2],[1892,2],[1895,2],[1898,3],[1902,4],[1907,2],[1910,2],[1913,2],[1916,2],[1933,5],[1939,3],[1943,3],[1994,1],[2006,1],[2025,1],[2027,2],[2030,2],[2033,3],[2037,2],[2040,3],[2044,1],[2046,2],[2049,3],[2053,3],[2057,2],[2060,4],[2065,3],[2089,2],[2092,4],[2114,3],[2118,4],[2123,2],[2126,2],[2129,3],[2197,1],[2199,2],[2207,2],[2210,2],[2213,2],[2216,2],[2223,1],[2230,3],[2234,1],[2236,2],[2242,1],[2244,3],[2252,1],[2254,1],[2256,2],[2259,3],[2263,3],[2269,2],[2274,1],[2276,2],[2279,2],[2282,3],[2286,2],[2338,3],[2342,2],[2353,1],[2355,1],[2357,2],[2360,2],[2363,2],[2379,1],[2381,4],[2403,1],[2405,3],[2409,2],[2420,1],[2430,1],[2432,4],[2447,1],[2449,2],[2459,1],[2461,3],[2465,2],[2476,2],[2492,1],[2494,3],[2498,2],[2501,3],[2505,2],[2508,2],[2511,2],[2524,3],[2528,2],[2546,2],[2549,2],[2572,2],[2575,6],[2582,3],[2591,2],[2594,4],[2599,6],[2613,2],[2616,2],[2619,2],[2622,3],[2636,1],[2638,3],[2642,2],[2645,3],[2649,3],[2653,2],[2656,2]]},"711":{"position":[[0,1],[2,3],[20,1],[46,1],[48,4],[53,5],[72,1],[90,1],[109,1],[111,3],[115,3],[119,2],[122,3],[126,1],[128,4],[144,1],[159,1],[161,1],[163,2],[182,1],[184,5],[190,2],[209,1],[211,4],[228,1],[252,2],[271,4],[276,2],[288,1],[290,2],[293,3],[297,3],[301,5]]},"713":{"position":[[0,3],[12,4],[17,1],[19,2],[22,3],[26,2],[29,2],[46,1],[60,3],[64,6],[88,1],[110,1],[112,4],[117,3],[121,4],[126,2],[151,1],[153,4],[168,1],[170,5],[176,4],[181,3],[185,2],[188,2],[191,3],[195,3],[199,2],[207,1],[209,2],[234,1],[236,2],[239,2],[242,4],[247,2],[269,1],[271,4],[276,3],[280,4],[299,1],[301,2],[317,1],[319,4],[324,2]]},"715":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"717":{"position":[[11,1],[13,5],[31,4],[36,2],[39,3],[43,2],[46,3],[76,2],[105,1],[132,1],[163,1],[165,2],[184,1],[186,2],[209,1],[211,2],[214,2],[217,2],[225,2],[240,1],[253,1],[255,5],[266,1],[288,2],[299,3],[307,3],[311,4],[319,2],[346,1],[354,3],[358,1],[360,2],[363,2],[371,1],[381,1],[383,3],[387,4],[410,2],[433,1],[446,2],[465,1],[467,2],[470,3],[474,2],[477,4],[487,1],[489,2],[492,2]]},"719":{"position":[[0,2],[23,1],[25,4],[30,2],[33,3],[41,1],[43,5],[54,1],[67,1],[69,1],[71,5],[89,1],[91,4],[96,2],[99,5],[105,4],[110,2],[113,1],[115,5],[121,3],[125,2],[128,5],[143,3],[156,1],[158,2],[161,2],[164,3],[168,4],[173,3],[177,3],[186,2],[207,1],[209,2],[212,2],[239,1],[241,4],[246,5],[252,2],[255,2],[258,1],[260,3],[264,5],[270,4],[281,4],[295,3],[299,3],[303,1],[305,2],[308,3],[312,5],[328,3],[332,4],[337,3],[341,2],[344,4],[383,1],[385,3],[413,1],[415,5],[421,2],[424,2],[427,3],[431,4],[453,1],[462,1],[464,3],[468,2],[488,1],[490,2],[493,4],[498,3],[502,4],[543,1],[545,2],[568,1],[570,3],[574,2],[594,1],[608,1],[610,3],[614,2],[645,1],[647,5],[653,4],[658,2],[673,1],[675,5],[681,4],[686,1],[688,3],[703,2],[706,2],[714,1],[716,4],[730,1],[748,1],[757,1],[759,3],[763,2],[766,3],[775,1],[777,2],[780,1],[782,2],[785,3],[794,2],[797,2],[818,1],[820,2],[828,1],[830,3],[834,2],[837,2],[845,3],[849,4],[854,2],[857,1],[859,2],[862,2],[878,1],[887,2],[896,1],[898,2],[905,1],[911,1],[913,4],[923,1],[925,5],[931,2],[934,2],[937,4],[942,1],[968,2],[971,2],[979,1],[1000,1],[1002,3],[1006,1],[1008,1],[1010,4],[1015,2],[1018,2],[1021,1],[1043,2],[1046,4],[1061,1],[1063,2],[1083,1],[1085,5],[1100,2],[1103,3],[1107,3],[1137,1],[1139,3],[1143,1],[1145,3],[1149,2],[1152,2],[1174,1],[1191,1],[1193,3],[1197,1],[1199,2],[1202,1],[1226,1],[1228,5],[1252,1],[1254,2],[1262,1],[1264,2],[1267,5],[1273,3],[1277,3],[1295,2],[1298,3],[1302,3],[1306,2],[1309,2]]},"721":{"position":[[12,5],[18,3],[22,5],[28,1],[30,3],[34,2],[37,2],[40,2],[61,1],[69,1],[89,1],[177,1],[244,1],[250,1],[272,2],[303,1],[333,1],[377,1],[400,1]]},"723":{"position":[[5,1],[26,1],[28,4],[33,2],[36,8],[45,1],[47,3],[54,1],[62,2],[65,2],[72,2],[128,1],[130,2],[133,2],[152,1],[175,5],[181,4],[217,1],[219,2],[274,1],[276,2],[288,1],[299,1],[316,2],[331,2],[365,1],[367,3],[371,1],[383,4],[388,2],[400,1],[402,5],[408,6],[427,1],[578,1],[662,1],[664,3],[668,1],[686,2],[689,3],[693,2],[729,1],[731,5],[737,1],[739,1],[751,1],[788,1],[808,1],[810,2],[813,3],[835,1],[837,2],[857,1],[859,4],[864,5],[870,3],[874,2],[877,1],[879,3],[912,1],[914,2],[941,1],[943,2],[969,1],[1003,1],[1005,1],[1007,2],[1010,3],[1037,1],[1039,3],[1043,3],[1088,3],[1111,1],[1113,2],[1116,2],[1128,1],[1130,3],[1268,1],[1299,1]]},"725":{"position":[[0,2],[3,5],[14,1],[16,5],[36,2],[39,1],[53,2],[56,3],[60,5],[66,2],[69,4],[74,3],[91,1],[101,1],[103,5],[109,4]]},"727":{"position":[[0,2],[11,1],[13,3],[17,2],[20,1],[22,3],[26,3],[30,1],[81,1],[95,3],[99,1],[101,2],[209,1],[211,3],[215,3],[233,1],[235,4],[256,1],[268,1],[270,4],[275,2],[286,1],[288,4],[307,1],[309,2],[312,3],[316,4],[335,1],[337,2],[361,1],[363,3],[367,2],[384,4],[389,1],[395,1],[397,4],[402,4],[407,2],[416,1],[418,3],[422,3],[438,1],[448,1],[450,3],[454,2],[457,4],[462,5],[468,5],[488,1],[490,6],[497,2],[508,1],[510,2],[513,2],[516,3],[520,3],[524,2],[527,1],[529,1],[531,3]]},"729":{"position":[[0,1],[2,3],[6,5],[26,1],[28,4],[33,4],[38,3],[42,3],[46,5],[52,4],[57,2],[60,4],[65,3],[69,4],[74,5],[80,5],[95,1],[97,3],[112,1],[114,2],[117,4],[122,2],[136,2],[139,1],[150,3],[154,4],[159,3],[163,4],[168,2],[171,2]]},"731":{"position":[[0,1],[2,3],[18,1],[20,3],[24,4],[29,2],[32,5],[38,2],[41,2]]},"733":{"position":[[0,2],[11,1],[26,1],[28,5],[34,4],[39,3],[43,3],[47,1],[65,1],[67,2],[80,1],[82,4],[87,2],[90,5],[110,1],[121,2],[139,1],[167,1],[169,3],[173,1],[175,2],[187,3],[209,2],[212,3],[216,4],[221,3],[225,2],[228,2],[231,5],[310,1],[312,2],[315,2],[356,1],[370,1],[376,1],[394,1],[396,2],[399,3],[497,1],[547,1],[558,1],[567,1],[585,2],[588,2],[595,1],[601,1],[623,1],[625,2],[637,1],[656,1],[666,1],[668,3],[678,1],[680,5],[686,1],[703,1],[721,1],[723,2],[733,1],[746,1],[748,2],[764,1],[766,3],[770,3],[796,1],[803,1],[818,1],[825,1],[865,1],[883,1],[889,1],[893,2],[896,5],[919,1],[929,1],[940,1],[944,2],[947,2],[950,2],[975,2],[994,1],[1013,1],[1019,1],[1021,2],[1024,2],[1032,2],[1035,3],[1039,2],[1051,1],[1060,2],[1063,2],[1066,4],[1071,3],[1083,2],[1086,2],[1089,2],[1092,1],[1102,1],[1108,1],[1110,4],[1115,1],[1132,1],[1143,1],[1145,3],[1149,4],[1154,2]]},"735":{"position":[[0,2],[19,1],[26,1],[33,4],[38,2],[41,2],[54,1],[63,1],[65,2],[68,4],[73,3],[77,5],[83,3],[87,6],[98,1],[100,4],[119,2],[122,3],[126,2],[149,1],[151,3],[155,3]]},"737":{"position":[[0,2],[19,1],[21,3],[25,2],[35,2],[51,1],[53,4],[58,2],[61,2],[64,1],[66,2],[69,4],[74,2],[77,2],[80,4],[103,1],[105,3],[109,2]]},"739":{"position":[[12,2],[17,2],[34,1],[36,3],[111,1],[121,3],[147,1],[170,1],[172,4],[177,1],[179,1],[181,1],[200,1],[211,1],[213,4],[218,3],[222,4],[231,1],[240,3],[261,2],[264,4],[269,4]]},"741":{"position":[[0,2],[3,1],[5,3],[9,3],[13,1],[15,2],[18,2],[21,3],[25,2],[46,1],[53,2],[56,4],[61,2],[81,1],[83,2],[93,1],[95,3],[99,3],[103,3],[140,1],[142,2],[145,2],[157,3],[161,2],[175,1],[182,3],[192,2],[200,1],[202,2],[210,1],[217,2],[229,1],[240,1],[251,2],[254,2],[268,3],[280,2],[290,1],[298,4],[313,1],[324,3],[328,2],[331,3],[346,2],[349,1],[355,2],[358,2],[366,1],[368,3],[372,2],[375,2],[378,2],[381,2],[389,1],[391,2],[394,2],[410,1],[412,4],[417,4],[422,1]]},"743":{"position":[[17,1],[25,2],[33,2],[41,2],[159,1],[161,4],[166,2]]},"745":{"position":[[0,2],[3,3],[7,3],[11,3]]},"747":{"position":[[0,4],[14,3],[18,3],[22,1],[30,1],[32,3],[36,2],[68,1],[70,2]]},"749":{"position":[[13,1],[15,4],[20,3],[24,2],[27,3]]},"751":{"position":[[12,3],[30,1],[32,4],[37,4],[42,3],[46,5],[52,2],[55,3],[59,5],[65,3],[81,1],[94,1],[96,3],[100,2],[103,2],[126,1],[155,1],[179,1],[216,1],[234,1]]},"753":{"position":[[24,1],[26,5],[47,4],[52,2],[73,3],[88,1],[90,2],[93,2],[102,4],[107,3],[122,1],[124,2],[127,3],[142,2],[145,2],[168,1],[200,1],[228,1],[235,1],[270,1]]},"755":{"position":[[15,1],[37,3],[55,2],[72,1],[74,1],[98,1],[105,3],[122,1],[124,4],[129,3],[133,1],[135,4],[173,1],[175,4],[194,1],[207,3],[221,4],[226,3],[230,4],[235,4],[273,1],[275,4],[280,2],[283,3],[302,1],[304,3],[308,2],[344,1],[346,4],[351,1],[353,1],[355,4],[360,2],[363,2],[380,1],[382,3],[419,1],[421,3],[425,1],[427,2],[430,6],[437,4],[497,1],[550,1],[554,1],[567,1],[659,1],[661,2],[692,1],[708,1],[732,1],[755,1]]},"757":{"position":[[0,2],[19,1],[49,1],[67,1],[69,2],[72,3],[76,6],[83,4],[88,2],[100,1],[111,2],[119,1],[121,2],[144,1],[176,1],[279,1],[286,1],[288,3],[308,1]]},"759":{"position":[[8,2],[16,1],[23,3],[27,2],[30,2],[58,1],[92,1],[115,2],[118,2],[126,1],[128,3],[132,2],[135,2],[138,1],[170,1],[178,1],[180,2],[188,1],[204,1],[206,2]]},"761":{"position":[[8,1],[10,2],[13,1],[15,3],[28,2],[36,1],[48,1],[50,1],[52,2],[55,2],[63,1],[77,3],[81,3],[85,2],[88,2]]},"763":{"position":[[5,1],[11,2],[31,1],[33,5],[39,4],[44,3],[61,1],[69,3],[73,4],[78,2]]},"765":{"position":[[21,1],[23,2],[34,2],[37,4],[46,4],[51,2],[57,1],[59,5],[65,2],[74,2],[77,4],[82,2],[85,3],[89,1],[91,2],[133,1],[140,2],[143,2],[166,1],[168,2],[175,4],[180,2],[183,1],[185,2],[188,2]]},"768":{"position":[[5,1],[7,2],[10,1],[12,1],[14,3],[18,1],[20,3],[24,3],[28,4],[33,3],[37,2],[40,2],[43,1],[45,2],[48,3],[52,3],[80,1],[82,3],[86,3],[90,3],[99,1],[101,4],[106,2],[109,2],[112,3],[116,4],[121,3],[134,1],[136,5],[176,1],[182,2],[185,4]]},"770":{"position":[[0,4],[22,2],[25,5],[31,5],[48,1],[50,3],[75,1],[86,2],[94,1],[101,1],[103,4],[112,2],[120,4],[135,1],[137,5],[164,1],[175,2],[183,1],[190,1],[192,4],[207,1],[209,2],[222,1],[224,4],[229,3],[243,2],[256,1],[279,2],[303,1],[305,2],[308,3],[312,2],[315,6],[331,1],[342,1],[344,1],[355,2],[358,3],[362,3],[366,4],[371,2],[374,2],[382,1],[386,1],[388,2],[391,3],[411,1],[413,3],[417,2],[420,1],[422,3],[426,5]]},"772":{"position":[[0,4],[5,2],[8,2],[15,3],[24,1],[26,5],[32,3],[36,5],[74,2],[86,1],[88,1],[90,2],[93,3],[97,2],[130,1],[132,2],[135,2],[155,1],[157,2],[160,1],[162,3],[166,2]]},"774":{"position":[[17,1],[39,1],[41,4],[46,2],[49,3],[71,1],[73,4],[113,4],[174,1],[203,1],[205,2],[208,2],[263,1],[290,1],[292,3],[305,2],[366,1],[393,1],[404,1],[406,3],[410,5],[416,2],[419,2],[441,4],[446,4],[471,1],[473,2],[563,1],[749,1],[776,1],[778,4],[807,1],[826,1],[834,5],[840,1],[858,2],[863,1],[874,1],[876,3],[880,2],[885,1],[887,3],[891,2],[898,1],[904,1],[906,5],[919,1],[921,3],[925,3],[929,2],[938,2],[941,2],[944,2],[947,2],[950,2],[953,3],[957,1],[959,1],[961,3],[982,1],[1005,3],[1031,1],[1053,1],[1076,3],[1102,1],[1116,1],[1127,1],[1129,4],[1170,3],[1174,3],[1184,1],[1191,1],[1198,1],[1200,4],[1205,2]]},"776":{"position":[[6,1],[15,1],[17,3],[26,1],[28,3],[32,1],[65,1],[73,2],[76,2],[100,1],[123,2],[126,2],[146,1],[148,2],[151,3],[155,4],[181,1],[183,2],[186,1],[188,2],[191,2],[194,3],[230,1],[232,1],[234,2],[237,3],[249,1],[251,3],[255,2]]},"778":{"position":[[0,3],[20,1],[26,2],[29,5],[35,2],[38,3],[46,1],[64,1],[91,1],[121,1],[123,4],[136,3],[150,1],[168,1],[204,3],[208,3],[257,1],[275,2],[293,2],[296,3],[300,2],[314,1],[320,1],[347,2],[364,1],[366,4],[416,2],[419,1],[427,2],[430,2],[433,3],[437,2],[440,1],[442,2],[461,1],[477,1],[479,5],[489,1],[491,1],[493,2],[496,5],[502,4],[523,1],[525,2],[532,1],[534,2],[537,2],[540,3],[544,2],[551,1],[576,1],[578,4],[583,3],[603,1],[609,1],[611,4],[616,2],[629,2],[632,2],[635,2],[638,3],[642,2],[645,2],[653,1],[660,1],[662,3]]},"780":{"position":[[4,1],[18,2],[21,2],[24,2],[27,2],[30,1],[32,3],[36,1],[38,1],[40,3],[49,2],[52,3],[56,2],[77,1],[79,3],[99,1],[101,3],[105,2],[108,2],[111,4],[132,1],[134,4],[139,3],[143,2],[163,1],[165,2],[186,1],[188,4],[193,2],[196,2],[211,2],[219,1],[221,3],[225,4],[235,1],[246,1],[262,2],[281,1],[288,2],[291,4],[296,2]]},"782":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"784":{"position":[[41,1],[60,1],[74,2],[77,2],[84,1],[86,2],[89,4],[94,2],[115,1],[131,1],[145,4],[150,2],[170,1],[172,3],[176,7],[184,2],[199,3],[203,7],[235,1],[256,1],[258,4],[263,4],[268,3],[272,3],[276,2],[279,1],[281,4],[286,2],[321,1],[323,2],[353,1],[355,4],[360,5],[366,2],[386,1],[388,4],[393,3],[397,5],[415,3],[431,1],[433,3],[437,4],[442,2],[445,3],[457,2],[476,1],[495,1],[497,2],[517,1],[547,1],[584,4],[609,1],[624,1],[641,1],[662,1],[679,1],[681,5],[687,2],[690,5],[713,1],[715,3],[719,4],[724,4],[746,1],[748,3],[752,4],[757,3],[809,1],[839,1],[841,2],[862,1],[864,5],[870,4],[883,1],[885,3],[889,2],[892,2],[903,1],[914,2],[917,5],[923,5],[929,2],[951,2],[954,2],[957,3],[961,5]]},"786":{"position":[[16,1],[18,3],[26,1],[28,3],[32,3],[36,5],[42,1],[44,3],[48,3],[52,3],[56,3],[65,1],[76,1],[94,1],[96,2],[99,1],[111,1],[113,4],[118,3],[122,3],[131,1],[137,4],[142,3],[146,2],[149,5],[170,1],[172,3],[176,4],[181,4],[186,3],[207,1],[209,2],[212,3],[233,1],[235,1],[242,1],[244,3],[256,1],[258,7],[266,3],[270,3],[274,4],[279,5],[285,2],[288,4],[293,2],[300,1],[324,2],[327,3],[331,3],[335,5],[341,3],[345,2],[348,1],[350,2],[353,2],[356,2],[359,3],[363,5],[373,1],[396,1],[398,4],[403,1],[410,1],[412,2],[415,1],[425,1],[450,1],[461,2],[470,2],[473,2],[476,2],[479,2],[505,1],[507,4],[512,7],[532,1],[534,3],[538,2],[541,3],[560,1],[573,3],[586,2],[610,2],[627,1],[643,1],[656,1],[664,2],[680,1],[717,2],[720,1],[722,4],[744,1],[757,1],[759,2],[762,4],[777,1],[782,3],[786,6],[793,3],[797,3],[801,3],[805,4],[829,2],[832,3],[855,1],[876,1],[898,4],[903,3],[907,3],[972,1],[1005,1],[1021,1],[1023,3],[1040,1],[1054,1],[1072,1],[1089,2],[1092,5],[1104,3],[1108,4],[1125,1],[1140,2],[1156,1],[1176,1],[1199,1],[1213,2],[1216,4],[1241,3],[1245,2],[1248,2],[1251,3],[1268,2],[1271,2],[1274,2],[1277,2],[1280,2],[1312,1],[1326,1],[1328,5],[1334,2],[1362,1],[1364,5],[1370,2],[1387,2],[1390,3],[1394,4],[1399,2],[1402,3],[1415,1],[1429,1],[1444,1],[1446,4],[1451,1],[1465,1],[1467,1],[1475,1],[1477,2],[1489,1],[1491,6],[1498,5],[1504,2],[1507,2],[1527,1],[1529,3],[1533,2],[1536,2],[1539,2],[1542,1],[1544,3],[1548,4],[1553,3],[1562,2],[1565,4],[1570,7],[1578,2],[1593,1],[1595,1],[1597,2],[1617,1],[1619,3],[1639,1],[1690,1],[1700,1],[1712,1],[1722,1],[1951,2],[1989,2],[2001,1],[2003,4],[2017,1],[2033,2],[2036,2],[2039,2],[2062,1],[2068,1],[2087,1],[2089,1],[2096,1],[2135,1],[2142,3],[2146,5],[2170,1],[2189,2],[2192,2],[2199,2],[2202,2],[2210,1],[2229,1],[2231,5],[2237,1],[2239,2],[2242,2],[2245,2],[2248,3],[2252,1],[2269,1],[2271,3],[2288,1],[2319,2],[2332,1],[2341,1],[2343,1],[2345,2],[2353,1],[2355,3],[2359,2],[2362,2],[2365,2],[2368,1],[2401,1],[2412,1],[2414,4],[2419,2],[2422,2],[2444,1],[2458,1],[2460,1],[2478,1],[2480,4],[2493,1],[2502,2],[2505,2],[2508,4],[2513,3],[2517,2],[2520,2],[2523,4],[2528,2],[2538,1],[2540,5],[2546,2],[2549,3],[2573,2],[2593,2],[2603,1],[2617,1],[2619,1],[2626,1],[2628,2],[2631,2],[2642,2],[2673,1],[2687,2],[2713,2],[2716,1],[2718,2],[2721,2],[2724,2],[2735,2],[2749,1],[2767,1],[2783,2],[2786,1],[2788,4],[2793,1],[2795,3],[2799,2],[2818,1],[2820,1],[2822,3],[2846,1],[2848,4],[2871,2],[2874,3],[2878,3],[2913,1],[2915,4],[2920,4],[2925,3],[2929,2],[2932,2],[2985,1],[2987,3],[2991,3],[2995,2],[3016,1],[3018,1],[3020,2],[3033,1],[3035,4],[3040,2],[3043,3],[3054,1],[3056,2],[3082,1],[3084,3],[3088,4],[3098,1],[3100,2],[3135,4],[3140,3],[3144,1],[3146,1],[3148,2],[3151,1],[3153,4],[3158,2],[3161,2],[3164,2],[3186,1],[3188,2],[3208,1],[3221,4],[3231,3],[3235,5],[3241,3],[3245,3],[3249,1],[3251,3],[3255,2],[3258,3],[3262,2],[3304,2],[3330,2],[3349,4],[3371,1],[3373,4],[3378,2],[3381,6],[3396,1],[3419,1],[3426,1],[3428,4],[3440,1],[3442,5],[3478,2],[3491,1],[3493,4],[3511,1],[3539,1],[3541,1],[3551,2],[3575,1],[3589,1],[3591,4],[3617,3],[3621,2],[3635,1],[3637,2],[3663,1],[3665,2],[3668,4],[3687,1],[3689,4],[3694,2],[3697,3],[3701,3],[3705,4],[3717,1],[3723,1],[3725,2],[3728,3],[3732,2],[3759,1],[3770,2],[3773,3],[3782,1],[3784,5],[3790,3],[3794,1],[3796,4],[3818,1],[3836,2],[3839,3],[3843,6],[3850,3],[3879,3],[3916,1],[3918,2],[3925,1],[3927,5],[3933,5],[3939,3],[3943,3],[3951,1],[3953,4],[3958,4],[3963,2],[3978,1],[3995,1],[4014,1],[4016,5],[4026,1],[4028,5],[4060,2],[4079,1],[4081,4],[4086,3],[4114,1],[4120,1],[4134,1],[4164,1],[4166,3],[4174,1],[4180,1],[4196,1],[4211,2],[4214,2],[4231,1],[4252,1],[4254,2],[4257,3],[4278,1],[4284,1],[4309,1],[4311,4],[4344,1],[4351,3],[4372,1],[4374,2],[4377,3],[4389,2],[4392,3],[4396,2],[4399,3],[4408,1],[4417,1],[4419,3],[4423,2],[4437,1],[4469,2],[4487,2],[4490,2],[4504,1],[4506,3],[4519,1],[4521,4],[4536,1],[4558,3],[4562,2],[4565,2],[4576,1],[4597,2],[4600,3],[4604,2],[4624,1],[4631,3],[4655,1],[4674,2],[4691,1],[4693,4],[4706,2]]},"789":{"position":[[0,4],[23,1],[44,1],[46,4],[51,3],[55,1],[57,3],[76,1],[78,4],[110,1],[199,1],[201,3],[214,2],[236,1],[238,2],[322,1],[399,1],[438,1],[581,1],[692,1],[705,1],[745,1],[747,5],[767,2],[787,1],[793,1],[822,1],[824,1],[826,3],[846,1],[848,2],[891,1],[913,1],[926,1],[1076,5],[1102,1],[1104,4],[1129,2]]},"791":{"position":[[5,1],[26,1],[28,3],[52,1],[73,3],[85,1],[101,1],[103,3],[107,3],[124,1],[126,3],[130,3],[174,1],[185,1],[199,1],[210,1],[444,2],[470,5],[480,1],[513,1],[515,5],[525,1],[536,3],[553,1],[560,1],[562,3],[568,2],[571,3],[589,1],[595,1],[623,1],[629,1],[672,1],[674,2],[710,1],[732,1],[734,2],[741,1],[749,1],[769,1],[771,2],[844,1],[850,1],[902,2],[905,4],[910,2],[913,3],[917,3],[951,1],[958,1],[960,3],[964,3],[985,1],[987,2],[990,3],[994,2],[997,2]]},"793":{"position":[[0,3],[4,1],[6,2],[9,2],[12,2],[15,2],[18,2],[64,1],[95,3],[99,2],[136,2],[139,4],[162,1],[164,4],[195,2]]},"795":{"position":[[28,1],[49,1],[80,4],[135,1],[145,1],[157,1],[167,1],[264,1],[313,1],[327,1],[421,1],[494,1],[545,1],[547,1],[549,2],[552,4],[579,1],[589,1],[591,4],[604,1],[632,1],[634,2],[685,1],[687,2],[690,4],[705,1],[716,3],[737,1],[746,2],[749,5],[765,1],[769,2],[772,5],[782,1],[788,1],[802,1],[813,3],[819,1],[821,3],[825,2],[828,2],[847,4],[852,2],[859,1],[865,1],[881,3],[885,2],[888,2],[903,2],[957,1],[965,2],[1002,1],[1010,2],[1101,3],[1105,5],[1111,1],[1134,2],[1142,3],[1146,2],[1159,1],[1161,5],[1167,3],[1171,2],[1186,1],[1188,2],[1191,2],[1198,1],[1200,4],[1221,1],[1223,3],[1227,1],[1229,3],[1233,3],[1237,2],[1240,4],[1309,1],[1311,3],[1315,1],[1317,2],[1358,1],[1360,2],[1363,5],[1373,1],[1375,4],[1380,2],[1383,3],[1387,2],[1390,3],[1394,3],[1415,1],[1443,1],[1445,4],[1473,1],[1475,2],[1478,4],[1488,1],[1509,1],[1511,4],[1521,1],[1523,3],[1527,1],[1529,3],[1566,3],[1570,2],[1573,3],[1577,3],[1589,1],[1591,4],[1596,2],[1599,4],[1604,2],[1607,2],[1610,2],[1621,3],[1625,2],[1628,3],[1646,1],[1648,2],[1651,6],[1658,2],[1661,3],[1681,1],[1683,2],[1686,4],[1691,4],[1696,4],[1701,2],[1704,3],[1716,1],[1718,6],[1725,4],[1730,4],[1735,2],[1738,3],[1750,1],[1758,1],[1760,4],[1781,1],[1791,2],[1811,1],[1813,2],[1816,2],[1824,1],[1830,1],[1836,1],[1849,1],[1851,5],[1866,2],[1869,4],[1874,2],[1877,1],[1879,2],[1891,1],[1893,3],[1922,1],[1935,2],[1938,3],[1958,2],[1978,2],[1981,2],[1984,3],[2004,1],[2006,1],[2013,1],[2036,1],[2038,3],[2042,4],[2047,2],[2050,5],[2056,4],[2061,5],[2067,2],[2070,2],[2073,1],[2075,3]]},"797":{"position":[[0,3],[25,1],[27,1],[47,1],[113,1],[129,1],[131,2],[141,3],[145,3],[158,1],[177,1],[179,4],[200,1],[202,5],[208,5],[218,1],[239,1],[241,4],[272,1],[318,1],[342,1],[368,1],[411,1],[413,2],[480,1],[499,1],[536,1],[591,1],[593,2],[646,1],[648,2],[707,1],[709,2],[950,1],[1003,1],[1082,1],[1089,1],[1130,3],[1134,3],[1147,1],[1168,1],[1170,2],[1222,1],[1252,1],[1279,2],[1282,2],[1312,1],[1314,2],[1393,1],[1578,1],[1585,1],[1662,1],[1664,3],[1668,2],[1679,1],[1812,1],[1929,1],[1980,1],[2043,2],[2048,1],[2240,1],[2242,2],[2322,1],[2337,1],[2356,2],[2375,1],[2389,3],[2393,3],[2413,1],[2453,1],[2455,6],[2499,1],[2501,1],[2503,2],[2513,1],[2515,2],[2518,3],[2539,1],[2541,4],[2546,2],[2549,3],[2553,2],[2556,2]]},"799":{"position":[[0,2],[11,1],[13,4],[27,2],[30,2],[33,4],[38,2],[41,1],[43,3],[69,1],[96,1],[98,4],[103,2],[106,4],[111,2],[130,1],[132,5],[138,2],[157,2],[160,3],[164,5],[179,1],[181,5],[187,4],[192,3],[196,2],[199,4],[204,3],[218,1],[220,4],[237,1],[239,5],[245,4],[250,3],[268,1],[280,1],[300,1],[302,3],[306,3],[310,4],[324,1],[326,1],[328,3],[332,1]]},"801":{"position":[[19,1],[21,2],[24,5],[44,1],[46,2],[72,1],[83,3],[87,2],[90,4],[107,1],[109,4],[129,1],[142,1],[153,2],[176,4],[202,2],[205,3],[209,4],[223,1],[236,1],[238,4],[243,4],[259,1],[261,5],[267,3],[271,1],[279,1],[293,1],[295,4],[309,1],[311,2],[314,3],[318,2],[321,3],[334,2],[337,2],[340,2],[343,3],[347,3],[387,2],[405,1],[415,1],[417,2],[420,3],[424,3],[446,2],[523,1],[543,1],[588,1],[712,3],[716,3],[741,1],[763,1],[781,1],[783,4],[805,1],[834,1],[846,2],[849,4],[854,5],[860,1],[879,1],[896,1],[898,2],[947,1],[961,1],[963,3],[967,1],[969,4],[974,2],[993,2],[996,3],[1000,2],[1048,1],[1056,1],[1107,2],[1167,1],[1199,1],[1211,1],[1213,4],[1218,2],[1226,1],[1228,3],[1232,5],[1238,1],[1250,1],[1252,3],[1256,1],[1258,3],[1262,5],[1268,3],[1272,2],[1275,4],[1280,4],[1285,3],[1289,4],[1303,1],[1311,1],[1325,1],[1327,2],[1330,3],[1334,1],[1336,2],[1350,3],[1354,4],[1359,3],[1363,2],[1366,1],[1374,1],[1394,2],[1404,2],[1407,2],[1410,3],[1414,5],[1440,1],[1463,1],[1471,1],[1473,4],[1490,1],[1492,3],[1496,1],[1498,2],[1501,4],[1506,1],[1508,5],[1514,2],[1517,3],[1530,1],[1554,1],[1583,2],[1723,2],[1763,1],[1792,2],[1822,2],[1862,1],[1882,1],[1936,2],[2072,1],[2091,1],[2136,1],[2165,1],[2167,3],[2220,1],[2238,1],[2268,3],[2288,1],[2290,2],[2302,1],[2332,1],[2362,1],[2392,2],[2395,3],[2399,2],[2402,2],[2422,1],[2424,2],[2427,2],[2437,1],[2439,1],[2441,1],[2443,3],[2512,1],[2625,3],[2648,3],[2652,2],[2655,4],[2669,1],[2683,2],[2686,2],[2689,3],[2722,1],[2724,3],[2744,3],[2748,3],[2752,2],[2755,2],[2758,3],[2762,3],[2766,3],[2770,2],[2773,4],[2778,2]]},"803":{"position":[[5,3],[29,1],[31,4],[53,1],[55,4],[60,4],[65,3],[69,3],[98,1],[139,2],[142,1],[167,1],[169,5],[193,1],[207,1],[209,5],[215,5],[230,1],[232,4],[237,2],[240,3],[244,3],[272,1],[274,5],[280,6],[318,1],[350,2],[353,2],[356,2],[359,2],[384,1],[386,1],[394,1],[415,1],[429,1],[441,1],[451,1],[463,2],[466,2],[469,3],[488,3],[509,3],[536,1],[554,1],[556,3],[560,3],[580,1],[582,5],[588,2],[606,2],[609,6],[633,1],[635,4],[640,3],[653,2],[656,2],[671,2],[682,1],[684,2],[703,1],[705,3],[709,2],[712,2],[715,3],[726,1],[728,3],[732,1],[734,3],[738,3]]},"805":{"position":[[8,1],[10,4],[30,1],[43,1],[57,3],[61,2],[64,3],[68,5],[74,3],[102,1],[113,1],[125,1],[142,2],[145,2],[157,1],[167,1],[180,1],[182,3],[186,2],[189,2]]},"807":{"position":[[0,3],[12,1],[14,2],[17,4],[22,2],[25,3],[72,2],[75,2],[78,2],[81,3],[102,1],[104,2],[112,1],[130,1],[142,1],[154,1],[164,3],[177,1],[188,1],[190,2],[193,2],[203,1],[205,3],[209,2],[212,2],[224,1],[226,2],[229,4],[234,3],[238,1],[240,4],[254,1],[256,3],[260,1],[276,1],[278,2],[281,3],[285,2],[297,1],[302,2],[308,1],[310,2],[313,2],[323,2],[326,2],[334,1],[336,4],[347,1],[349,3],[361,1],[363,4],[377,1],[384,1],[386,2],[389,3],[405,2],[408,3],[412,2],[462,1],[476,2],[495,1],[497,5],[519,1],[521,3],[525,2],[528,3],[532,5],[538,1],[540,3],[562,2],[565,2],[568,4],[573,1],[575,2]]},"809":{"position":[[8,1],[10,2],[13,4],[18,2],[38,1],[51,1],[53,2],[56,2],[59,4],[85,2],[88,3],[112,1],[121,1],[123,5],[129,2],[148,1],[174,1],[176,4],[231,2],[247,1],[276,1],[297,3],[320,2],[323,3],[327,1],[329,2],[332,3],[344,1],[346,2],[365,1],[389,1],[402,3],[406,4],[411,1],[413,1],[461,1],[471,1],[484,1],[503,4],[508,4],[513,4],[518,3],[522,2],[545,2],[554,2],[565,1],[584,1],[603,1],[605,2],[608,2],[616,1],[650,1],[683,1],[705,1],[720,2],[723,1],[725,1],[727,3],[763,1],[765,2],[777,1],[803,1],[805,1],[811,2],[814,2],[822,1],[829,1],[837,1],[856,2],[859,2],[862,3],[871,1],[971,1],[973,4],[978,2],[981,3],[985,2],[988,3],[992,3],[996,1],[998,4],[1008,1],[1010,4],[1015,2],[1018,3]]},"812":{"position":[[0,3],[4,3],[8,6],[30,1],[44,2],[47,2],[61,2],[64,2],[67,5],[73,1],[75,6],[135,1],[154,1],[191,2]]},"814":{"position":[[15,1],[32,2],[35,3],[39,2],[56,2],[67,1],[78,1],[80,2],[117,2],[137,1],[139,3],[143,3],[147,3],[159,1],[217,2],[220,5],[231,1],[242,1],[270,1],[272,5],[286,1],[317,1],[363,2],[366,2],[369,2],[380,1],[382,2],[401,1],[419,1],[427,3],[467,1],[513,2],[516,2],[562,1],[577,1],[598,1],[600,2],[617,1],[652,1],[665,1],[678,1],[691,1],[733,3],[737,2]]},"816":{"position":[[0,3],[19,2],[30,1],[41,1],[43,2],[59,2],[74,1],[96,2],[107,1],[109,2],[112,3],[116,4],[121,1],[123,2],[126,2],[129,3],[133,2],[136,2],[156,1],[163,1],[165,2],[176,1],[182,2],[192,4],[211,2],[219,2],[230,1],[232,2],[235,2],[245,3],[249,2],[252,1],[254,2],[257,2]]},"819":{"position":[[0,3],[4,5],[26,1],[37,2],[40,2],[43,2],[54,1],[83,1],[85,2],[88,1],[95,2],[124,1],[126,2],[129,1],[137,1],[151,1],[153,3],[157,2],[160,1],[174,2]]},"821":{"position":[[0,3],[21,2],[33,1],[43,2],[66,2],[121,2],[124,2],[134,5],[140,3],[144,3],[173,1],[226,2],[229,2],[237,1],[248,1],[284,2],[287,2],[298,1],[333,1],[391,2],[394,2]]},"823":{"position":[[2,2],[77,2],[107,2],[110,2],[121,1],[140,2],[143,2],[146,3],[150,2],[169,1],[174,2],[177,1],[179,3],[183,2],[186,2],[205,1],[224,1],[226,3],[247,1],[249,3],[253,4],[258,3],[262,3],[266,3],[270,3],[274,2]]},"826":{"position":[[10,1],[17,1],[19,3],[23,3],[27,3],[39,1],[52,3],[68,3],[72,3],[76,3],[80,1],[82,2],[85,6],[92,2],[95,2],[98,2]]},"828":{"position":[[15,1],[17,5],[23,3],[57,1],[67,1],[83,1],[85,2],[102,1],[104,2],[185,1],[187,2]]},"830":{"position":[[2,2],[12,2],[27,2],[30,2],[53,2],[84,1],[106,1],[132,2],[135,1],[137,5],[152,1],[154,4],[167,1],[169,1],[171,2],[174,2],[177,2]]},"833":{"position":[[7,2],[10,2],[27,2],[45,1],[59,1],[61,2],[64,2],[67,1],[69,4],[98,2],[110,1],[112,4],[125,1],[127,2],[143,2],[146,3],[150,2],[153,2],[166,1],[168,2],[178,1],[180,4],[185,2],[188,3],[192,6],[199,2],[214,1],[225,1],[227,3],[231,2],[234,2],[237,2],[245,1],[263,2],[298,2],[309,1],[319,2],[332,3],[336,2],[358,1],[360,2],[375,1],[377,2]]},"835":{"position":[[12,2],[15,5],[26,1],[49,2],[68,1],[70,2],[82,1],[84,3],[88,6],[95,2],[98,5],[104,3],[108,4],[130,1],[132,3],[136,3],[140,1],[142,2],[145,5],[151,4],[156,4],[161,2],[164,2],[167,1],[169,3],[173,2],[176,4],[181,2],[192,2],[195,1],[197,2],[200,4],[217,1],[225,2],[236,1],[243,1],[253,1],[255,2],[276,2],[287,1],[289,2],[292,6],[312,1],[314,2]]},"837":{"position":[[8,2],[28,1],[36,1],[46,2],[61,1],[75,1],[89,1],[91,2],[102,2],[122,1],[124,1],[135,2],[144,1],[163,1],[177,3],[181,4],[186,2],[198,1],[200,2],[224,1],[226,4],[231,2],[234,5],[240,3],[261,1],[263,5],[269,1],[271,2],[287,1],[289,3],[293,2],[301,2],[304,2]]},"839":{"position":[[0,3],[4,3],[23,1],[40,1],[69,1],[71,2],[74,3],[78,3],[82,2],[85,2],[88,2],[91,2],[94,2],[97,4],[102,2],[105,3],[109,2],[112,3],[116,2],[128,1],[139,1],[162,3],[206,1],[213,1],[219,1],[225,1],[261,2],[283,1],[292,1],[302,1],[338,2],[349,3],[359,1],[366,1],[383,1],[397,1],[399,2],[417,1],[419,3],[435,1],[442,2],[445,3],[449,4],[462,1],[464,3],[468,3],[472,2],[505,2],[516,1],[518,3],[522,3],[526,1],[528,3],[532,1],[544,1],[546,2],[549,3],[553,4],[558,1],[560,2]]},"841":{"position":[[7,1],[17,1],[31,1],[48,1],[50,1],[71,1],[96,1],[98,2],[105,1],[118,1],[120,1],[122,2],[132,1],[134,4],[139,3],[143,3],[147,2],[150,2],[153,3],[157,3],[172,1],[190,1],[203,1],[221,1],[223,2],[226,3],[230,1],[232,5],[238,3],[242,3],[246,3],[250,2],[253,3],[257,2],[260,3],[264,3],[286,3],[298,1],[315,1],[317,5],[329,3],[333,1],[335,2],[338,3],[350,1],[352,2],[355,3],[377,1],[399,1],[407,2],[410,2],[413,2],[436,2],[455,1],[474,3],[498,1],[500,4],[505,2],[524,1],[526,3],[530,1],[532,3],[536,2],[539,2]]},"843":{"position":[[0,3],[51,2],[73,1],[75,2],[95,1],[133,1],[154,1],[191,4],[209,2],[234,1],[236,4],[257,1],[259,4],[281,1],[304,2],[328,1],[330,3],[334,5],[340,2],[343,2],[346,1],[348,4],[353,3],[357,2],[368,1],[379,1],[381,5],[387,4],[392,2],[395,4],[400,3],[404,2],[407,2]]},"845":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"847":{"position":[[35,1],[54,3],[58,4],[63,3],[75,1],[97,1],[99,5],[105,4],[110,4],[115,4],[120,2],[123,4],[128,2],[131,5],[137,3],[160,1],[166,1],[192,1],[194,5],[200,5],[206,3],[210,2],[213,3],[217,5],[223,2],[226,4],[248,2],[275,1],[277,4],[286,1],[296,2],[317,1],[331,2],[334,4],[339,5],[345,1],[347,5],[373,1],[375,2],[390,1],[392,5],[398,5],[424,4],[445,2],[464,1],[466,3],[470,1],[472,2],[475,2],[478,1],[480,3],[484,3],[515,2],[540,1],[542,4],[547,2],[554,1],[572,1],[583,2],[586,2],[609,2],[612,4],[621,1],[623,1],[625,4],[630,2],[654,1],[675,2],[678,3],[698,2],[701,4],[706,2],[709,3],[717,1],[731,1],[744,2],[747,3],[751,2],[754,3],[770,1],[772,2],[779,1],[794,3],[798,2],[801,4],[816,2],[819,3],[823,2],[830,1],[844,1],[846,4],[851,2],[854,2],[857,4]]},"849":{"position":[[5,2],[13,1],[34,3],[60,2],[79,1],[81,3],[85,3],[89,6],[118,1],[120,5],[126,3],[140,1],[142,4],[163,2],[166,2],[169,4],[183,1],[190,1],[192,3],[196,3],[204,1],[206,4],[219,1],[221,2],[224,5],[250,1],[252,4],[257,2],[265,1],[267,6],[274,6],[281,3],[293,1],[321,2],[342,1],[344,6],[351,4],[363,1],[365,4],[388,1],[390,3],[394,1],[396,3],[436,1],[461,1],[463,4],[475,1],[492,1],[494,4],[507,2],[535,3],[543,1],[558,1],[560,2],[578,1],[580,3],[584,1],[586,3],[590,4],[595,2],[634,1],[643,1],[660,1],[662,2],[674,1],[676,3],[680,5],[686,2],[689,4],[718,2],[721,2],[724,2],[727,3],[748,1],[750,2],[765,1],[767,2],[770,4],[784,1],[795,1],[797,5],[803,6],[869,1],[871,3],[875,3],[879,3],[891,1],[893,2],[900,1],[902,2],[916,1],[918,2],[921,2],[943,2],[946,1],[959,1],[973,2],[998,1],[1000,2],[1007,1],[1009,3],[1013,4],[1018,3],[1022,1],[1035,1],[1052,2],[1055,1],[1057,1],[1059,5],[1065,5],[1071,4],[1095,2],[1098,3],[1110,1],[1112,2],[1127,2],[1138,2],[1141,2],[1157,1],[1159,3],[1180,1],[1182,4],[1195,3],[1199,4],[1221,3],[1234,2],[1237,4],[1242,3],[1246,3],[1250,2],[1253,3],[1257,2],[1277,1],[1283,1],[1285,1],[1287,2],[1290,2],[1293,2],[1317,1],[1319,2],[1322,2],[1343,2],[1353,1],[1367,2],[1370,2],[1373,3],[1404,1],[1406,4],[1411,2],[1414,3],[1422,7],[1430,2],[1445,1],[1447,4],[1472,2],[1475,4],[1480,3],[1500,2],[1503,1],[1521,1],[1523,2],[1540,1],[1554,1],[1556,2],[1559,3],[1578,2],[1581,4],[1586,4],[1604,1],[1606,2],[1609,3],[1658,2],[1661,3],[1665,2],[1668,2],[1671,3],[1675,3],[1692,3],[1696,2],[1699,4],[1715,2],[1718,3],[1722,2],[1725,2]]},"851":{"position":[[4,1],[18,3],[22,2],[25,2],[28,2],[31,3],[35,6],[42,3],[278,1],[320,2],[323,3],[335,1],[337,3],[361,1],[363,4],[368,4],[373,1],[375,3],[379,3],[394,1],[408,1],[422,1],[424,2],[427,5],[444,1],[483,3],[494,1],[511,1],[513,4],[526,2],[540,1],[550,3],[554,2],[586,1],[588,4],[593,3],[643,1],[674,1],[676,4],[708,2],[720,2],[741,1],[743,4],[784,1],[834,4],[863,2],[874,1],[876,5],[908,1],[942,2],[945,3],[949,4],[954,1],[956,2],[959,3],[963,3],[967,4],[1000,2],[1003,2],[1010,3],[1014,3],[1022,1],[1024,3],[1028,1],[1030,2],[1033,2],[1041,1],[1046,1],[1052,1],[1063,1],[1065,2],[1084,1],[1086,5],[1096,2],[1114,1],[1132,1],[1143,4],[1148,2],[1171,1],[1189,1],[1191,3],[1195,3],[1199,3],[1203,2],[1206,4],[1211,4],[1216,3],[1220,5],[1230,1],[1248,3],[1252,4],[1257,3],[1261,2],[1264,2],[1267,3]]},"853":{"position":[[13,1],[29,1],[35,1],[59,1],[61,3],[113,1],[163,1],[199,1],[207,1],[224,1],[243,1],[287,2],[290,2],[346,1],[365,2],[368,1],[370,2],[388,1],[390,2],[393,4],[467,1],[502,1],[504,2],[522,1],[524,4],[529,4],[559,1],[561,2],[629,1],[631,3],[635,3],[728,2],[737,1],[760,1],[762,2],[765,2],[774,1],[812,1],[883,1],[998,1],[1017,2],[1049,1],[1051,4],[1089,1],[1105,1],[1124,1],[1142,1],[1170,1],[1193,1],[1202,2],[1250,1],[1252,4],[1286,1],[1288,4],[1293,2],[1296,2],[1310,1],[1321,1],[1349,1],[1351,4],[1356,5],[1362,2],[1376,2],[1379,5],[1394,2],[1426,1],[1428,3],[1432,3],[1501,1],[1677,1],[1690,1],[1724,1],[1726,5],[1749,1],[1766,1],[1768,5],[1781,1],[1783,2],[1802,3],[1806,2],[1809,1],[1811,2],[1814,3],[1818,3],[1889,1],[1942,1],[1948,1],[2030,2],[2033,4],[2063,1],[2065,4],[2070,5],[2076,5],[2091,1],[2102,1],[2112,1],[2134,1],[2174,1],[2203,2],[2206,2],[2209,4],[2222,1],[2236,1],[2238,3],[2242,4],[2247,2],[2261,1],[2274,2],[2277,6],[2284,3],[2306,1],[2326,1],[2328,3],[2332,5],[2376,1],[2396,1],[2416,1],[2418,3],[2422,2],[2439,3],[2443,3],[2447,5],[2453,3],[2475,1],[2477,3],[2494,2],[2514,2],[2517,3],[2521,3],[2525,4]]},"855":{"position":[[0,1],[2,4],[7,3],[31,1],[60,2],[63,2],[70,1],[80,1],[82,1],[94,1],[109,2],[112,2],[126,1],[128,2],[131,3],[164,1],[166,3],[170,3],[237,1],[412,1],[464,1],[475,2],[478,3],[519,1],[521,2],[541,1],[612,1],[633,1],[635,1],[637,2],[676,1],[698,1],[700,3],[790,1],[809,1],[826,1],[828,5],[834,2],[837,2],[871,1],[883,1],[885,3],[907,1],[911,1],[930,1],[932,4],[937,2],[940,2],[943,2]]},"857":{"position":[[11,1],[13,4],[35,1],[37,2],[40,3],[62,1],[64,2],[67,1],[69,2],[90,2],[116,1],[118,3],[122,1],[150,1],[185,1],[187,3],[222,1],[224,2],[227,2],[248,1],[250,2],[261,1],[281,1],[290,2],[293,2],[320,1],[322,3],[344,1],[346,2],[357,2],[360,1],[362,2],[369,1],[383,5],[389,6],[396,2],[399,4],[404,2],[407,2],[410,2],[413,4],[418,2],[421,1],[437,1],[453,1],[455,4],[475,1],[477,4],[510,2],[518,1],[520,5],[526,1],[534,2],[560,1],[562,4],[567,1],[575,2],[599,1],[614,1],[616,2],[687,1],[702,1],[712,3],[730,6],[750,1],[765,1],[792,2],[803,3],[829,1],[845,1],[855,2],[858,2],[861,1],[877,1],[894,2],[897,2],[900,1],[941,1],[958,1],[960,3],[964,2],[967,2],[1032,1],[1048,1],[1071,1],[1099,1],[1203,1],[1249,1],[1268,1],[1270,2],[1284,1],[1338,1],[1372,1],[1406,1],[1450,1],[1452,3],[1456,1],[1458,2],[1476,1],[1478,3],[1489,2],[1492,3],[1496,3],[1507,1],[1527,3],[1531,2],[1534,5]]},"859":{"position":[[19,1],[21,4],[26,4],[31,3],[35,3],[39,2],[47,1],[70,2],[73,5],[79,2],[82,1],[93,1],[95,5],[101,2],[118,1],[120,3],[124,3],[147,1],[170,1],[172,2],[186,1],[188,3],[192,3],[196,3],[208,1],[237,1],[239,5],[276,1],[342,3],[376,1],[415,1],[460,1]]},"861":{"position":[[6,1],[16,2],[19,3],[23,3],[39,1],[41,2],[93,1],[95,5],[110,3],[131,1],[133,3],[137,3],[187,1],[239,1],[243,1],[247,2],[254,1],[353,2],[358,2],[386,2],[398,1],[400,5],[406,2],[419,3],[441,1],[454,1],[456,2],[459,1],[466,3],[488,2],[491,6],[498,1],[508,1],[528,1],[530,2],[549,1],[551,3],[555,2],[558,3],[562,3],[589,1],[591,5],[597,4],[602,2],[605,4],[610,2],[636,1],[638,2],[649,3],[653,3],[657,2],[674,1],[732,1],[758,1],[866,1],[873,1],[875,4],[920,1],[952,1],[954,2],[1009,2],[1012,3],[1016,3],[1050,1],[1052,4],[1066,1],[1068,5],[1074,2],[1088,1],[1090,5],[1116,1],[1118,2],[1121,3],[1145,1],[1147,5],[1153,2],[1156,2],[1159,3],[1163,4],[1183,1],[1185,3],[1189,2],[1192,3],[1220,1],[1231,1],[1233,3],[1237,1],[1262,1],[1269,2],[1272,3],[1290,1],[1301,1],[1303,1],[1322,1],[1324,3],[1328,2],[1490,1],[1492,4],[1515,1],[1517,4],[1529,1],[1546,2],[1549,1],[1551,1],[1553,4],[1558,4],[1563,2],[1575,1],[1586,1],[1588,2],[1591,5],[1597,4],[1602,1],[1615,1],[1617,5],[1623,3],[1650,1],[1652,2],[1663,3],[1667,3],[1671,2],[1693,1],[1754,1],[1756,5],[1818,1],[1916,1],[1948,1],[1966,1],[1982,1],[1998,1]]},"864":{"position":[[0,3],[4,3],[8,4],[13,4],[18,3],[39,2],[42,2],[45,2],[48,2],[56,5],[62,4],[80,1],[82,2],[85,2]]},"866":{"position":[[0,2],[17,1],[19,2],[40,1],[42,4],[69,1],[71,4],[83,1],[102,3],[132,1],[134,3],[138,1],[145,1],[159,1],[161,2],[164,3],[174,1],[176,3],[186,1],[209,1],[218,1],[229,1],[253,1],[255,2],[265,1],[267,2],[289,1],[291,3],[300,1],[314,1],[325,2],[333,1],[357,1],[398,1],[430,1],[441,1],[447,1],[465,1],[477,1],[531,1],[539,3],[569,1],[575,1],[586,1],[588,2],[611,1],[613,3],[621,1],[634,2],[637,2],[640,2],[648,2],[661,1],[663,2],[684,1],[699,1],[723,1],[725,3],[747,1],[763,1],[765,2],[768,2],[791,1],[793,3],[815,1],[817,3],[832,1],[834,5],[853,1],[855,3],[877,2],[900,1],[906,1],[942,1],[949,1],[951,3],[995,1],[1002,1],[1004,3],[1018,1],[1027,2],[1044,1],[1046,4],[1051,3],[1055,3],[1064,2],[1083,3],[1087,2],[1090,1],[1102,1],[1104,2]]},"868":{"position":[[0,3],[122,1],[145,1],[147,2],[150,2],[158,2],[161,2],[176,1],[211,1],[213,2],[229,1],[231,3],[239,1],[241,2],[256,1],[258,4],[263,3],[267,5],[273,2],[288,2],[302,1],[304,3],[308,1],[310,3]]},"870":{"position":[[8,1],[24,2],[31,1],[33,2],[51,1],[53,3],[57,5],[63,3],[98,1],[134,1],[136,4],[145,2],[154,1],[162,1],[187,2],[190,2],[201,2],[204,3],[208,3],[212,2],[232,1],[240,1],[242,3],[269,1],[271,7],[285,1],[295,1],[297,2],[305,1],[322,2],[329,3],[333,2],[336,2],[339,3],[343,3],[368,3],[372,4],[383,1],[385,4],[408,1],[410,5],[416,4],[443,1],[451,2],[454,3],[458,3],[462,2],[465,3],[469,3],[473,3],[485,1],[510,3],[544,2],[547,2],[550,3],[560,1],[568,3],[572,3],[582,1],[587,1],[589,4],[594,2],[603,1],[611,2],[618,1],[624,2],[648,4],[659,1],[666,1],[672,2],[697,1],[703,2],[720,3],[755,1],[757,4],[766,1],[768,5],[774,3],[778,3],[811,3],[815,3],[819,3],[823,3],[849,3],[858,1],[866,1],[882,1],[907,1],[909,4],[919,2],[922,3],[926,3],[930,2],[953,2],[968,1],[970,5],[981,1],[1002,1],[1013,1],[1015,3],[1019,1],[1041,2],[1044,2],[1047,3],[1051,1],[1058,1],[1060,2],[1063,3],[1082,2],[1100,1],[1128,1],[1130,6],[1137,2],[1140,4],[1159,1],[1173,2],[1176,4],[1181,1],[1201,1],[1212,1],[1217,1],[1219,3],[1223,2],[1234,1],[1236,4],[1241,2],[1256,1],[1263,1],[1275,2],[1285,1],[1313,1],[1315,4],[1323,1],[1329,2],[1349,1],[1351,2],[1354,2],[1357,2],[1360,3],[1364,3],[1386,1],[1410,2],[1413,2],[1416,2],[1424,1],[1432,2],[1439,3],[1461,2],[1464,3],[1468,3],[1489,2],[1504,1],[1506,3],[1510,3],[1514,2],[1517,1],[1519,1],[1521,3],[1546,1],[1548,2],[1565,4],[1588,1],[1590,3],[1603,1],[1627,1],[1629,3],[1633,2],[1649,2],[1664,1],[1677,1],[1679,2],[1701,3],[1705,5],[1711,4],[1716,3],[1720,4],[1725,3],[1735,1],[1743,2],[1758,1],[1760,1],[1771,3],[1793,2],[1796,2],[1799,3],[1803,2],[1829,2],[1832,3],[1836,3],[1846,1],[1854,1],[1856,2],[1859,2],[1880,1],[1904,3],[1908,2],[1934,4],[1945,1],[1953,1],[1974,2],[2000,1],[2002,3],[2006,2],[2017,2],[2028,1],[2034,2],[2037,3],[2041,4],[2046,3],[2073,1],[2075,2],[2078,2],[2086,2],[2089,3],[2093,3],[2097,4],[2110,2],[2135,1],[2152,1],[2164,1],[2170,1],[2172,4],[2200,1],[2202,2],[2205,2],[2208,2],[2211,2],[2214,1],[2221,1],[2223,2],[2230,2],[2233,2],[2251,1],[2263,2],[2273,1],[2275,5],[2281,3],[2285,3],[2289,3],[2308,1],[2310,4],[2315,2],[2318,2],[2321,2],[2324,3],[2328,3],[2339,1],[2341,4],[2346,1],[2353,1],[2359,3],[2377,2]]},"873":{"position":[[8,2],[34,2],[37,3],[41,4],[46,3],[67,1],[69,3],[73,3],[77,2],[88,1],[90,3],[128,1],[139,1],[150,1],[152,4],[157,5],[163,2],[166,4],[171,4],[204,1],[206,3],[238,1],[240,4],[245,1],[261,2],[276,1],[285,1],[287,2],[317,1],[319,2],[326,1],[339,1],[341,4],[346,2],[349,4],[354,2],[372,1],[374,1],[376,1],[378,2],[381,2],[384,2],[387,5],[393,3],[401,1],[423,2],[430,2],[433,3],[437,2],[444,1],[446,3],[450,3],[475,1],[477,1],[486,1],[506,1],[508,2],[511,4],[516,3],[520,2],[523,2],[526,3],[534,1],[536,2],[560,1],[566,1],[568,2],[571,3],[583,1],[592,3],[596,2],[599,2],[609,1],[632,1],[634,2],[642,1],[644,3],[654,2],[687,1],[689,5],[695,3],[703,1],[714,1],[725,1],[727,2],[730,2],[751,1],[753,5],[759,2],[762,6],[769,2],[772,2],[784,2],[787,1],[789,1],[791,3],[795,2],[798,2],[810,2],[839,1],[845,1],[851,2],[854,1],[863,3],[867,2],[870,3],[941,1],[955,1],[957,2],[960,4],[965,3],[969,3],[973,4],[987,1],[998,2],[1001,2],[1023,2],[1026,3],[1030,3],[1034,4],[1048,1],[1059,1],[1061,1],[1069,1],[1078,1],[1084,2],[1087,4],[1092,4],[1103,1],[1126,1],[1128,3],[1132,3],[1136,3],[1140,3],[1159,1],[1161,3],[1165,4],[1170,3],[1174,3],[1178,1],[1185,1],[1205,3],[1216,1],[1218,2],[1221,1],[1223,2],[1235,1],[1237,4],[1258,1],[1269,2],[1272,3],[1276,3],[1280,3],[1284,3],[1297,1],[1308,1],[1310,2],[1313,1],[1320,1],[1331,1],[1333,4],[1338,4],[1343,3],[1347,1],[1349,2],[1369,2],[1372,1],[1379,1],[1390,1],[1392,4],[1397,2],[1400,4],[1410,1],[1415,2],[1418,2],[1438,1],[1443,3],[1447,3],[1451,2],[1454,1],[1456,1],[1458,3],[1466,1],[1472,1],[1474,3],[1482,1],[1488,2],[1491,3],[1500,1],[1502,1],[1504,2],[1524,1],[1526,3],[1530,1],[1532,4],[1547,1],[1549,2],[1557,1],[1563,3],[1584,1],[1586,2],[1617,1],[1619,3],[1623,4],[1645,1],[1656,1],[1667,1],[1669,4],[1674,4],[1683,2],[1695,1],[1706,1],[1708,2],[1728,3],[1732,2],[1740,1],[1747,2],[1754,1],[1756,2],[1776,2],[1779,3],[1783,4],[1788,3],[1792,3]]},"875":{"position":[[0,3],[38,1],[40,4],[45,3],[49,4],[54,4],[59,3],[63,2],[74,1],[82,1],[84,3],[88,5],[99,1],[107,2],[123,1],[142,1],[144,2],[147,3],[151,5],[157,4],[162,4],[167,3],[171,2],[189,1],[191,2],[213,1],[215,4],[225,1],[227,5],[245,2],[248,3],[252,3],[275,1],[286,1],[288,4],[293,1],[295,2],[298,3],[302,4],[307,2],[310,3]]},"877":{"position":[[19,1],[41,1],[43,3],[47,3],[51,2],[54,2],[65,2],[92,3],[110,2],[113,4],[118,3],[122,2],[125,2],[137,1],[139,4],[144,2],[151,1],[153,2],[156,3],[160,2],[163,3],[167,2],[170,3],[174,4],[179,5],[191,2],[198,3],[208,1],[214,1],[237,2],[240,4],[245,2],[248,2],[263,1],[265,5],[275,3],[294,1],[314,1],[316,1],[318,2],[321,3],[329,1],[348,1],[350,2],[358,1],[366,2],[373,1],[375,2],[378,3],[382,4],[387,1],[404,1],[424,1],[426,2],[429,3],[438,2],[445,3],[456,1],[458,2],[476,1],[478,1],[480,2],[500,1],[502,3],[506,1],[508,3]]},"879":{"position":[[0,1],[2,4],[34,2],[37,5],[43,4],[70,1],[72,2],[75,2],[78,4],[87,1],[116,1],[118,2],[129,1],[143,2],[146,4],[151,3],[155,3],[171,1],[173,2],[180,1],[182,5],[200,1],[210,2],[213,4],[218,2],[221,2],[224,4],[241,2],[264,1],[266,5],[272,3],[276,2],[291,3],[295,3],[299,3],[303,2],[325,1],[327,2],[330,2],[333,3],[337,3],[350,2],[358,2],[366,1],[394,1],[396,3],[400,3],[413,2],[416,2],[419,3],[423,4],[449,1],[451,5],[457,2],[460,2],[463,3],[467,2],[482,1],[505,2],[513,2],[528,1],[535,2],[538,3],[542,2],[545,2]]},"881":{"position":[[21,3],[25,5],[35,1],[56,1],[58,4],[63,2],[66,2],[69,3],[73,4],[82,1],[96,2],[99,3],[111,2],[114,4],[119,4],[124,2],[127,5],[133,3],[141,1],[161,1],[163,3],[167,2],[190,2],[193,3],[205,2],[208,3],[212,2],[215,2],[232,1],[234,2],[237,4],[242,1],[244,2],[247,3],[251,2],[254,3],[263,1],[286,1],[300,2],[303,2],[306,2],[309,2],[312,2],[315,2],[318,3],[329,3],[333,1],[335,2],[345,2],[348,2],[351,3],[373,1],[378,3],[382,2],[385,5],[391,2],[394,3],[405,2],[408,2],[424,3],[434,2],[437,2],[440,3],[444,2],[447,1],[449,3],[453,3],[471,1],[473,1],[475,2],[478,2],[481,2],[484,3],[488,1],[490,2],[493,2],[496,2],[499,3],[503,3],[507,1],[509,3],[513,2]]},"883":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"885":{"position":[[14,1],[22,1],[52,1],[54,5],[72,2],[75,2],[78,2],[120,2],[138,1],[149,1],[151,2],[168,1],[170,4],[200,1],[202,3],[219,2],[226,3],[247,2],[250,6],[286,1],[288,3],[292,2],[295,3],[317,1],[330,2],[333,2],[363,4],[368,1],[382,2],[401,1],[409,1],[430,2],[433,3],[459,1],[461,5],[467,2],[484,1],[510,2],[513,2],[516,2],[529,1],[544,5],[550,3],[564,2],[567,2],[570,4],[575,2],[578,1],[580,2],[588,2],[637,2],[640,2],[670,5],[676,4],[681,3],[694,1],[696,3],[700,3],[704,2],[707,3]]},"887":{"position":[[4,1],[6,2],[9,5],[15,2],[36,1],[38,2],[41,2],[44,1],[46,3],[50,3],[54,2],[57,5],[79,1],[87,1],[117,1],[131,2],[134,3],[138,4],[143,4],[148,2],[151,3],[155,3],[159,5],[165,3],[169,3],[173,2],[176,5],[182,1],[184,3],[202,4],[213,1],[243,1],[245,5],[263,2],[266,2],[269,2],[281,1],[283,4],[316,2],[325,1],[336,2],[350,2],[359,3],[381,1],[412,1],[438,2],[441,2],[444,2],[447,2],[450,4],[473,1],[481,1],[483,3],[487,3],[497,1],[517,5],[550,2],[553,4],[575,2],[578,2],[595,1],[603,2],[606,1],[608,2],[611,2],[614,2],[654,1],[665,2],[683,1],[703,1],[705,2],[718,1],[798,1],[800,3],[804,2],[825,2],[841,2],[848,4],[860,2],[866,2],[889,2],[892,5],[898,2],[901,2],[912,1],[914,4],[925,1],[927,3],[948,1],[950,4],[955,3],[959,2],[1003,1],[1005,3],[1021,2],[1046,2],[1049,2],[1065,1],[1086,1],[1088,6],[1105,1],[1120,6],[1138,1],[1140,2],[1171,1],[1173,4],[1185,1],[1203,1],[1205,4],[1237,1],[1271,2],[1274,3],[1278,2],[1297,1],[1311,3],[1315,3],[1328,1],[1338,6],[1345,3],[1349,2],[1352,2],[1363,1],[1365,2],[1379,1],[1386,2],[1389,4],[1394,2],[1397,2]]},"891":{"position":[[28,1],[52,1],[54,4],[77,1],[79,4],[84,2],[87,3],[125,1],[127,2],[159,1],[161,2],[200,1],[224,1],[226,2],[288,1],[290,1],[298,1],[300,2],[321,1],[341,1],[368,1],[382,1],[384,2],[387,2],[421,1],[423,3],[427,2],[430,5],[436,2],[462,1],[464,2],[491,1],[493,1],[495,1],[504,3],[508,2],[511,2],[557,1],[559,3],[610,1],[653,1],[655,2],[658,3],[671,2],[702,1],[720,1],[722,2],[734,1],[743,1],[745,2],[868,2],[871,3],[897,1],[917,1],[936,1],[938,2],[972,1],[974,5],[989,2],[992,5],[998,4]]},"893":{"position":[[19,1],[21,4],[26,6],[42,3],[57,1],[59,3],[63,3],[67,1],[69,3],[85,1],[87,4],[92,3],[96,2],[99,1],[101,2],[104,2],[107,2],[110,3],[142,2],[163,5],[169,4],[201,2],[204,2],[229,1],[258,3],[270,1],[288,1],[290,4],[295,3],[299,2],[349,1],[351,2],[394,5],[413,1],[429,1],[438,1],[440,4],[445,2],[466,1],[468,2],[552,1],[558,1],[576,2],[584,2],[587,2],[590,1],[596,1],[614,2],[633,1],[635,2],[638,2],[641,1],[647,1],[665,2],[684,1],[686,2],[779,4],[784,2],[804,2],[816,1],[827,1],[846,1],[848,2],[893,1],[905,1],[992,2],[1013,1],[1015,2],[1041,2],[1064,1],[1066,4],[1071,2],[1074,2],[1086,1],[1088,1],[1100,1],[1102,5],[1108,3],[1148,1],[1250,1],[1275,1],[1310,1],[1321,1],[1323,5],[1329,3],[1333,2],[1336,3],[1340,5],[1346,2],[1349,2],[1352,2],[1355,3],[1359,3],[1363,3],[1367,1],[1369,2],[1442,1],[1499,1],[1501,4],[1516,1],[1531,1],[1557,1],[1559,3],[1572,1],[1574,4],[1586,1],[1588,3],[1592,3],[1596,1],[1604,1],[1606,1],[1608,2],[1633,3],[1637,2],[1640,3],[1644,4],[1649,1],[1651,2],[1654,3],[1663,1],[1665,1],[1677,1],[1679,5],[1702,1],[1704,5],[1710,1],[1712,2],[1715,2],[1727,1],[1729,2],[1793,1],[1828,1],[1830,1],[1946,1],[1948,1],[1950,2],[1953,2],[1974,1],[1976,2],[1979,3],[1983,2],[1995,1],[1997,2],[2003,3],[2007,2],[2010,2],[2041,1],[2043,2],[2055,1],[2057,4],[2062,2],[2065,2],[2078,2],[2081,5],[2087,4],[2092,2],[2104,1],[2106,4],[2122,5],[2128,2],[2131,4],[2136,2],[2139,3],[2143,3],[2147,2],[2150,5],[2156,4],[2161,2],[2168,4],[2173,2],[2176,2],[2179,5],[2185,2],[2188,4],[2193,6],[2200,6],[2230,1],[2239,1],[2265,1],[2267,4],[2272,2],[2321,1],[2423,2],[2453,1],[2455,5],[2480,1],[2482,5],[2500,1],[2502,2],[2505,3],[2531,1],[2533,4],[2538,3],[2548,1],[2572,1],[2574,4],[2579,3],[2592,2],[2595,2]]},"895":{"position":[[17,4],[36,1],[38,2],[58,1],[60,2],[73,3],[77,2],[91,1],[93,2],[96,3],[158,1],[172,1],[174,3],[178,2],[213,1],[215,5],[248,2],[338,1],[353,2],[374,1],[376,2],[398,1],[400,4],[434,2],[489,1],[530,1],[532,2],[550,1],[658,2],[680,1],[682,3],[704,1],[706,2],[709,2],[724,2],[727,2],[739,1],[745,1],[747,5],[753,2],[756,2],[790,1],[803,1],[823,1],[825,4],[830,2],[846,1],[848,2],[851,3],[874,1],[876,3],[880,2],[883,3],[932,1],[938,1],[1042,1],[1058,4],[1082,1],[1084,3],[1106,1],[1108,3],[1112,2],[1121,1],[1145,1],[1147,2],[1159,1],[1161,5],[1179,3],[1209,2],[1212,3],[1232,1],[1234,2],[1237,2]]},"897":{"position":[[27,1],[29,3],[51,1],[71,2],[74,4],[79,3],[90,1],[106,1],[120,2],[123,2],[126,1],[128,3],[132,2],[135,2],[138,2]]},"899":{"position":[[16,1],[18,4],[23,3],[49,2],[70,1],[79,1],[81,2],[84,2],[87,2],[105,1],[117,3],[138,1],[140,2],[147,1],[149,3],[153,1],[155,3],[159,2],[172,1],[174,4],[187,6],[211,1],[213,3],[217,2],[220,2]]},"901":{"position":[[8,1],[10,4],[29,1],[58,1],[60,2],[75,2],[105,1],[107,2],[110,5],[128,1],[142,1],[157,1],[159,3],[182,1],[194,2],[197,2],[200,2],[218,2],[221,4],[226,2]]},"905":{"position":[[16,1],[18,2],[47,3],[80,1],[82,2],[85,2],[102,1],[116,2],[214,1],[222,1],[249,1],[251,2],[272,2],[320,1],[346,1],[348,2],[362,2],[404,1],[421,1],[423,3],[427,4],[449,1],[451,2],[467,2],[476,2],[483,3],[487,2],[518,1],[520,4],[525,5],[531,2],[534,3],[538,1],[540,2],[543,3],[547,2],[550,2],[553,2]]},"907":{"position":[[6,2],[23,1],[32,1],[43,2],[53,1],[66,1],[68,4],[73,2],[76,2],[85,2],[101,2],[104,2],[113,4],[132,1],[134,3],[138,2],[141,3],[145,2],[148,2],[151,2],[181,5],[187,2],[190,2]]},"909":{"position":[[8,2],[11,3],[37,1],[60,2],[63,2],[66,1],[68,2],[71,2],[74,2],[91,1],[114,2],[117,2],[120,1],[124,2],[127,4],[132,3],[136,2],[139,3],[143,2],[146,6],[159,2],[166,1],[180,2]]},"912":{"position":[[12,1],[14,2],[29,1],[58,3],[62,2],[70,1],[87,1],[89,4],[123,1],[125,3],[129,2],[136,2],[139,3],[143,2],[154,2],[171,2],[174,2],[192,1],[208,1],[210,2],[223,1],[238,2],[241,2]]},"914":{"position":[[14,1],[28,1],[46,1],[58,2],[61,2],[83,1],[100,3],[111,2],[114,2],[122,1],[143,1],[145,2],[148,4],[165,1],[174,2],[177,2],[193,3],[202,1],[211,2],[214,3],[218,2],[221,2],[224,3],[228,2],[231,4],[236,4],[255,1],[265,3],[277,2],[280,2],[283,3],[287,2]]},"917":{"position":[[18,1],[20,3],[24,2],[27,3],[37,1],[39,4],[44,2],[57,1],[59,5],[75,2],[78,1],[80,2],[83,2]]},"919":{"position":[[17,5],[37,1],[39,2],[42,2],[45,1],[47,4],[52,2],[55,3],[59,2],[89,2],[100,2],[103,2],[106,2],[109,2],[132,1],[141,1],[143,2],[154,1],[156,2],[159,1],[161,2],[178,1],[180,3],[184,2],[187,2],[217,1],[231,2],[254,2],[257,1],[259,2],[262,4],[267,1],[269,2],[277,1],[279,2]]},"921":{"position":[[4,1],[23,1],[25,2],[40,2],[43,2],[46,4],[51,1],[53,3],[70,3],[74,2],[92,3],[96,4],[101,2],[104,2],[121,1],[136,1],[138,5],[144,4],[149,5],[169,2],[172,3],[176,4],[181,3],[185,4],[190,4],[195,2],[198,1],[200,1],[202,3],[206,2],[219,1],[221,3],[233,1],[235,4],[240,2]]},"924":{"position":[[21,1],[23,2],[47,2],[71,1],[93,4],[98,2],[101,2],[112,1],[114,3],[145,3],[155,1],[157,2],[160,2]]},"926":{"position":[[0,3],[13,1],[19,1],[21,2],[24,2],[50,1],[52,2],[66,1],[73,2],[103,1],[117,2],[120,2]]},"928":{"position":[[14,1],[31,1],[38,4],[50,1],[63,2],[66,3],[70,1],[72,2],[75,3],[79,2],[101,1],[103,2],[133,2],[155,1],[157,5],[163,2],[166,1],[174,1],[198,2],[223,1],[225,1],[227,5],[243,1],[258,1]]},"930":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"932":{"position":[[0,2],[17,1],[24,1],[39,1],[41,3],[45,4],[50,5],[56,3],[90,1],[92,1],[94,4],[99,3],[109,1],[111,4],[116,3],[120,1],[122,5],[173,1],[192,2],[209,1],[211,1],[213,2],[248,1],[256,2],[259,1],[261,4],[266,2],[277,2],[280,2],[295,1],[319,3],[323,2],[339,1],[357,2],[360,4],[378,3],[382,2],[416,2],[435,1],[464,1],[490,1],[492,2],[515,1],[517,3],[521,3],[525,3],[550,1],[574,1],[576,2],[579,2],[582,3],[586,5],[592,2],[595,3],[610,1],[642,3],[646,3],[672,2],[685,2],[702,1],[704,4],[745,1],[747,2],[764,4],[769,2],[792,2],[795,2],[798,2],[801,2],[818,1],[820,4],[842,1],[850,1],[866,5],[907,3],[911,2],[914,3],[918,1],[920,3],[960,1],[962,2],[965,5],[971,2],[974,6],[981,3],[985,3],[989,2]]},"934":{"position":[[0,2],[7,1],[37,1],[39,4],[44,3],[48,2],[67,1],[87,1],[89,3],[114,1],[116,4],[127,1],[157,1],[171,3],[189,1],[191,3],[203,1],[232,1],[234,4],[252,2],[287,2],[312,1],[314,5],[320,2],[323,3],[337,1],[345,2],[348,4],[385,1],[399,1],[401,4],[423,3],[427,4],[432,3],[436,2],[439,3],[443,5],[449,1],[451,3],[500,3],[504,3],[508,3],[526,3],[530,3],[541,1],[560,2],[577,1],[622,1],[643,1],[645,4],[675,1],[677,2],[716,1],[718,4],[723,4],[750,1],[752,3],[756,3],[773,2],[776,3],[794,1],[831,2],[841,1],[843,2],[846,2],[857,1],[859,2],[862,2],[865,3],[886,1],[896,2],[934,2],[948,1],[950,3],[975,1],[977,4],[999,2],[1026,1],[1028,5],[1060,1],[1062,5],[1068,2],[1086,1],[1107,1],[1109,5],[1137,3],[1141,3],[1145,4],[1150,1],[1152,2],[1155,2],[1158,4],[1163,2],[1187,1],[1217,1],[1219,2],[1227,2],[1230,3],[1234,4],[1239,3],[1276,2],[1293,1],[1318,1],[1335,1],[1363,1],[1365,2],[1385,3],[1411,1],[1413,2],[1426,2],[1429,2],[1439,1],[1456,1],[1493,2],[1496,2],[1520,1],[1528,1],[1552,2],[1555,4],[1560,2],[1602,4],[1636,3],[1654,1],[1683,1],[1685,3],[1699,1],[1716,2],[1719,3],[1751,2],[1797,1],[1825,1],[1833,2],[1856,1],[1868,2],[1871,2],[1891,1],[1893,4],[1930,1],[1936,3],[1940,2],[1943,3],[1957,1],[1959,2],[1962,3],[1966,1],[1974,1],[1976,2],[1979,2],[1982,2],[2014,2],[2065,1],[2092,1],[2094,4],[2116,1],[2118,3],[2138,3],[2142,3],[2153,1],[2164,4],[2169,3],[2173,2],[2176,3],[2180,2],[2183,2],[2186,2],[2252,1],[2293,4],[2312,2],[2371,1],[2402,2],[2405,2],[2408,3],[2412,2],[2428,2],[2431,2],[2472,2],[2491,1],[2520,1],[2522,3],[2536,1],[2583,3],[2600,2]]},"938":{"position":[[22,2],[25,3],[29,2],[78,1],[86,1],[97,2],[105,2],[123,1],[125,2],[142,1],[150,1],[170,3],[174,2],[202,1],[215,1],[224,1],[226,2],[252,1],[260,1],[262,4],[267,2],[297,2],[300,2],[303,2],[335,1],[337,2],[340,3],[344,2],[347,3],[355,4],[374,1],[376,4],[381,2],[384,2],[387,1],[396,3],[400,5],[406,3],[416,1],[418,2],[421,1],[423,3],[427,2],[430,3],[440,1],[442,2],[445,2],[448,3],[452,4],[457,3],[461,3],[465,5],[471,4],[476,3],[502,3],[506,4]]},"940":{"position":[[22,1],[24,2],[33,1],[41,2],[44,2],[74,1],[76,2],[84,2],[114,2],[144,1],[146,4],[168,1],[195,1],[207,2],[225,1],[245,4],[271,1],[273,4],[292,1],[299,1],[314,1],[316,4],[330,2],[333,4],[348,2]]},"942":{"position":[[14,1],[16,4],[42,2],[60,1],[86,1],[100,2],[103,2],[106,2],[109,3],[120,3],[142,1],[144,4],[149,3],[153,3],[187,1],[189,5],[195,3],[216,1],[218,5],[236,4],[241,3],[245,5],[251,1]]},"945":{"position":[[14,1],[43,2],[64,1],[79,1],[81,2],[84,2],[101,1],[103,5],[113,2],[126,1],[128,4],[133,3],[154,1],[174,1],[190,1],[192,3],[196,1],[198,3],[219,2],[222,3],[226,5],[232,2],[235,4],[240,2],[243,4],[248,3],[252,2],[267,2],[270,2],[300,1],[320,2],[323,2],[332,1],[334,2],[358,1],[383,1],[385,1],[400,1],[402,2],[425,1],[432,1],[447,2],[450,2],[466,1],[488,1],[501,1],[507,1],[509,2],[529,3],[542,1],[554,1],[556,4],[574,2],[593,1],[626,1],[654,1],[668,2],[684,1],[688,1],[709,1],[752,1],[767,1],[769,2],[774,1],[778,1],[780,5],[786,2],[789,3],[793,3],[809,1],[841,1],[843,4],[848,3],[874,3],[878,2],[881,3],[907,1],[909,2],[918,1],[926,2],[933,1],[935,2],[955,1],[957,3]]},"947":{"position":[[12,1],[14,2],[44,1],[46,2],[66,1],[68,2],[78,1],[101,1],[103,2],[110,1],[112,2],[122,1],[128,1],[150,1],[152,2],[174,1],[176,2],[179,2],[182,3],[195,1],[224,1],[230,2],[233,3],[237,3],[253,1],[261,1],[263,6],[279,1],[281,4],[292,1],[294,4],[304,1],[306,4],[316,2],[319,3],[335,3],[339,1],[341,2]]},"949":{"position":[[0,3],[4,3],[25,2],[51,1],[53,4],[58,3],[88,1],[90,3],[94,4],[99,1],[101,3],[122,1],[124,2],[154,1],[191,1],[193,4],[198,2],[225,2],[250,1],[273,3],[277,4],[282,3],[286,3],[312,3],[316,3],[320,1],[322,1],[324,2],[327,3],[331,4],[364,1],[366,3],[397,1],[423,1],[425,2],[452,1],[454,3],[458,3],[462,2],[491,1],[517,1],[546,1],[565,1],[580,6],[608,1],[610,2],[613,2],[616,2],[644,1],[668,2],[671,2],[674,3],[678,5],[684,2]]},"951":{"position":[[15,2],[18,2],[31,1],[39,2],[84,1],[86,3],[90,2],[110,1],[134,4],[139,2],[150,2],[153,3],[173,1],[182,2],[185,2],[202,1],[204,4],[229,1],[231,2],[238,1],[240,4],[245,3],[249,4],[254,2],[288,1],[314,1],[316,3],[320,3],[324,4],[329,2],[332,5],[338,2],[341,2],[344,7],[352,4],[374,1],[406,2],[409,4],[425,1],[454,3],[458,3],[484,1],[486,2]]},"953":{"position":[[7,1],[30,2],[33,3],[37,3],[41,3],[60,1],[81,2],[84,4],[89,4],[94,3],[98,2],[114,2],[131,2],[154,1],[178,1],[180,2],[183,5],[198,2],[235,1],[237,2],[240,4],[245,1],[262,1],[282,2],[302,1],[326,1],[346,1],[348,4],[371,1],[380,2],[383,2],[386,2],[423,1],[439,1],[441,3],[481,1],[483,2],[507,1],[565,3],[580,1],[582,2],[585,2],[588,1],[603,2],[606,1],[608,2],[630,2],[633,3],[637,5],[643,5],[649,5],[679,1],[681,2],[684,4],[689,3],[715,3],[719,2]]},"955":{"position":[[9,1],[17,4],[35,1],[41,3],[45,2],[48,3],[63,3],[67,2],[70,2],[73,3],[94,1],[96,2],[99,3],[125,1],[139,2],[142,2],[160,3],[164,1],[166,3],[190,3],[194,3],[198,3],[202,2],[205,6],[212,2],[215,2],[218,3],[222,2],[225,1],[227,2],[246,2],[249,1],[251,3],[274,2],[277,3],[294,1],[311,2],[328,1],[330,4],[375,1],[377,4],[382,2],[385,2],[388,3],[411,1],[417,2],[434,2],[466,2],[469,2],[484,1],[486,4],[518,1],[520,4],[540,1],[551,2],[568,2],[587,1],[597,1],[599,5],[605,2],[621,1],[635,1],[651,1],[667,2],[670,2],[673,3],[683,1],[696,2],[713,1],[715,1],[731,2],[734,3],[738,1],[740,3],[744,2],[747,1],[758,1],[760,2],[779,1],[781,2],[784,3],[802,2],[805,2],[808,2],[811,2]]},"959":{"position":[[17,1],[67,1],[108,1],[110,2],[123,1],[131,1],[133,2],[136,3],[164,1],[166,4],[171,2],[174,2],[186,1],[210,1],[212,4],[232,2]]},"961":{"position":[[22,1],[24,3],[43,1],[45,2],[74,1],[91,1],[93,2],[119,1],[135,1],[142,5],[148,1],[150,2],[159,1],[161,2],[204,1],[213,1],[215,2],[228,1],[239,1],[248,3],[258,1],[260,3],[274,1],[285,2]]},"963":{"position":[[12,1],[44,1],[46,3],[67,1],[75,1],[99,3],[103,2],[114,1],[116,4],[121,3],[142,1],[144,3],[148,3],[152,4],[157,3],[161,3],[165,2],[168,2],[190,1],[192,2],[207,1],[209,1],[211,2],[234,1],[236,4],[241,2],[261,1],[263,2],[266,2],[269,3],[273,3],[292,1],[294,3],[298,5],[326,1],[328,6],[335,1],[337,3],[355,2],[366,1],[371,1],[390,3],[394,4],[399,3],[403,5],[409,2],[412,3],[416,2],[419,4],[424,3],[428,3],[436,2],[439,4],[463,1],[465,2],[468,4],[473,3],[477,1],[479,3],[490,3],[500,1],[502,4],[524,3],[545,1],[559,1],[576,1],[578,2],[589,1],[591,3],[595,2],[598,2]]},"965":{"position":[[14,1],[16,2],[46,1],[80,1],[82,3],[103,1],[113,1],[146,1],[164,1],[166,3],[196,2],[199,4],[221,1],[240,2],[243,1],[245,3],[255,2],[258,4],[263,3],[293,5],[299,5],[305,4],[310,2],[327,1],[329,4],[356,3],[360,2],[363,2]]},"967":{"position":[[14,1],[16,3],[39,1],[56,1],[58,4],[81,1],[83,3],[108,1],[122,2],[125,3],[152,1],[154,4],[159,1],[161,4],[180,1],[182,3],[209,2],[217,1],[230,2],[233,4],[238,1],[240,3],[244,3],[252,3],[256,3],[260,3],[264,1],[266,2],[315,2],[318,4],[323,3],[340,1],[357,5],[380,1],[413,1],[432,1],[434,3],[438,2],[441,3],[445,3],[474,1],[476,3],[480,3],[498,1],[517,1],[536,3],[540,5],[560,1],[562,3],[566,2],[569,2],[589,1],[599,2],[609,1],[611,3],[615,5],[634,1],[636,3],[640,5],[646,2],[649,2],[652,2],[655,6],[662,4],[667,1],[669,2],[672,3],[676,3],[680,3],[684,4],[689,3],[693,1],[695,1],[697,3],[701,2],[731,1],[733,3],[737,2],[740,1],[742,3]]},"969":{"position":[[7,2],[10,4],[29,1],[31,2],[41,1],[51,4],[56,1],[71,4],[76,2],[79,3],[83,4],[88,3],[92,3],[115,1],[134,1],[136,4],[141,1],[143,3],[157,1],[168,1],[170,2],[173,2],[176,1],[178,1],[180,3],[190,2],[202,1],[204,4],[209,3],[213,3],[217,4],[222,5],[236,4],[241,2],[244,3],[248,3],[252,4],[257,2],[277,1],[296,2],[299,3],[303,4],[308,3],[312,5],[327,1],[350,1],[352,2],[355,3],[359,2],[362,2],[365,3],[369,2],[372,4],[377,5]]},"971":{"position":[[21,3],[25,3],[39,1],[62,1],[64,4],[69,4],[91,1],[93,2],[103,2],[121,1],[123,3],[144,1],[146,5],[158,1],[176,1],[178,2],[181,4],[186,3],[190,3],[194,5],[207,2],[217,1],[230,1],[232,3],[236,3],[240,1],[242,1],[244,3],[254,2],[257,3],[266,1],[268,4],[273,3],[277,2],[280,2],[283,4],[288,3],[292,3],[296,2],[299,3],[303,3],[307,3]]},"973":{"position":[[0,1],[2,3],[60,1],[79,2],[117,1],[146,2],[149,3],[169,1],[206,1],[208,2],[250,1],[269,1],[298,2],[301,3],[305,2],[308,2],[311,2],[322,1],[324,2],[327,3],[349,3],[353,2],[356,4],[361,3],[365,2],[368,2],[371,3],[375,2],[392,1],[394,2],[404,4],[441,1],[443,2],[460,1],[468,2],[471,5],[484,4],[489,4],[494,2],[497,3],[501,2],[504,1],[506,2],[509,2],[529,3],[533,2],[568,2],[571,2],[579,3],[583,2],[598,2],[601,2]]},"975":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"977":{"position":[[0,1],[2,3],[59,3],[63,2],[66,3],[76,1],[78,2],[139,1],[149,1],[151,2],[154,3],[164,3],[178,1],[198,2],[248,2],[276,1],[287,1],[289,3],[293,5],[299,2],[302,1],[313,2],[328,1],[330,2],[333,4],[345,1],[361,1],[375,2],[378,2],[398,1],[400,4],[419,1],[421,2],[424,2],[427,3],[450,1],[470,1],[472,7],[480,1],[490,1],[512,2],[515,2],[524,2],[527,2],[542,1],[559,1],[561,3],[565,2],[576,1],[578,2],[601,3],[622,2],[632,2],[674,1],[676,4],[686,1],[688,2],[701,1],[703,4],[708,2],[711,2],[714,2],[741,1],[743,4],[756,3],[760,4],[784,1],[786,2],[803,1],[805,4],[810,2],[813,1],[815,2],[818,2],[839,2],[842,3],[854,1],[870,1],[872,2],[875,2]]},"979":{"position":[[5,1],[24,1],[38,3],[42,3],[46,4],[51,5],[57,2],[65,1],[67,5],[73,4],[78,3],[87,3],[91,4],[96,3],[100,3],[104,2],[107,4],[112,4],[117,2],[130,1],[132,2],[135,3],[139,3],[143,3],[160,1],[182,1],[199,1],[201,4],[206,2],[209,3],[213,1],[220,2],[223,2],[226,4],[231,1],[233,2],[236,5],[242,1],[244,3],[248,3],[298,1],[355,1],[357,5],[363,2],[369,1],[371,3],[375,2],[411,1],[421,1],[423,2],[440,1],[452,1],[454,5],[460,2],[463,3],[492,1],[523,1],[535,1],[552,1],[567,1],[569,2],[578,1],[580,3],[584,3],[588,3],[592,4],[597,3],[601,3],[613,1],[627,1],[629,2],[650,1],[652,5],[673,1],[689,1],[722,1],[724,2],[744,1],[746,2],[755,1],[757,2],[760,2],[763,1],[765,2],[768,3],[772,3],[792,1],[794,3],[821,1],[828,2],[831,1],[833,2],[836,2],[839,2],[865,1],[882,1],[884,7],[919,1],[945,2],[973,1],[975,4],[1008,5],[1014,3],[1024,1],[1036,1],[1038,4],[1043,3],[1047,3],[1051,2],[1054,3],[1058,4],[1073,1],[1082,2],[1102,1],[1104,3],[1108,1],[1110,3],[1114,2],[1122,1],[1124,5],[1130,2],[1133,4],[1138,2],[1141,4],[1146,2],[1149,3],[1153,3],[1165,1],[1167,2],[1182,2],[1185,3],[1194,1],[1196,3],[1200,3],[1204,3],[1208,3],[1212,2],[1215,2],[1228,1],[1230,2],[1257,1],[1259,4],[1278,2],[1281,2],[1292,1],[1318,1],[1320,6],[1347,2],[1379,1],[1381,2],[1401,1],[1403,2],[1406,3],[1425,1],[1434,3],[1438,2],[1453,2],[1456,2],[1468,2],[1485,2],[1488,5],[1494,1],[1496,3],[1500,2],[1503,2],[1506,2],[1526,3],[1544,2],[1551,1],[1553,5],[1559,2],[1608,1],[1610,3],[1614,3],[1626,1],[1648,2],[1664,1],[1678,1],[1680,3],[1684,5],[1690,3],[1694,3],[1715,1],[1717,2],[1760,1],[1777,3],[1798,1],[1800,2],[1803,3],[1807,4],[1812,2],[1815,5],[1821,3],[1849,1],[1851,3],[1855,3],[1859,2],[1868,3],[1913,1],[1937,1],[1939,5],[1950,2],[1953,4],[1977,1],[1979,4],[1991,1],[1993,5]]},"982":{"position":[[8,1],[23,1],[35,1],[53,1],[55,4],[75,1],[77,2],[80,2],[117,1],[119,5],[125,3],[129,2],[153,1],[155,2],[178,1],[180,2],[195,1],[197,3],[201,4],[220,1],[236,1],[238,6],[268,1],[285,1],[300,1],[302,2],[362,4],[392,1],[394,2],[437,1],[439,3],[443,2],[477,1],[479,4],[484,1],[512,1],[514,2],[536,1],[551,2],[564,2],[567,1],[569,3],[581,1],[583,3],[598,1],[600,4],[620,1],[641,1],[657,4],[714,1],[716,2],[751,1],[772,1],[786,3],[790,2],[793,2],[802,1],[812,3],[816,2],[819,3],[823,3],[859,1],[865,2],[872,1],[874,3],[878,3],[882,5],[914,1],[930,1],[940,1],[942,4],[947,3],[951,3],[955,2],[958,3],[968,1],[1024,1],[1026,3],[1040,2],[1043,3],[1047,1],[1049,3],[1060,2],[1077,1],[1079,3],[1083,4],[1120,3],[1124,4],[1139,1],[1162,1],[1164,2],[1198,1],[1229,1],[1231,3],[1235,4],[1240,1],[1242,3]]},"984":{"position":[[0,2],[19,2],[26,2],[52,1],[68,1],[70,2],[127,1],[129,4],[134,1],[150,1],[152,2],[167,1],[169,2],[172,1],[174,5],[180,2],[196,1],[207,1],[209,1],[211,3],[215,5],[240,1],[242,2],[259,1],[279,1],[346,5],[356,1],[376,1],[398,1],[408,1],[443,1],[464,2],[467,5],[473,2],[476,2],[479,2],[482,5],[488,7],[516,1],[518,3],[522,3],[526,3],[530,3],[534,2],[555,1],[557,4],[562,3],[577,1],[636,2],[674,1]]},"986":{"position":[[16,1],[18,2],[88,1],[90,4],[95,2],[98,3],[116,1],[118,3],[139,1],[156,1],[177,2],[194,4],[211,1],[213,1],[224,1],[226,2],[288,1],[290,5],[302,1],[304,5],[310,3],[314,3],[339,1],[347,1],[349,4],[354,3],[358,5],[372,1],[374,5],[399,1],[488,2],[546,1],[567,2],[570,3],[616,1],[632,1],[666,1],[668,2],[671,8],[695,1],[718,1],[720,2],[729,1],[744,1],[746,3],[760,1],[762,4],[767,2],[770,4],[775,4]]},"988":{"position":[[8,1],[34,1],[36,6],[62,1],[85,1],[87,3],[91,3],[95,5],[101,6],[139,1],[151,2],[169,1],[189,1],[191,2],[194,4],[207,2],[268,1],[270,5],[324,1],[385,1],[387,2],[390,2],[410,1],[412,3],[416,4],[421,2],[428,1],[430,1],[456,1],[458,2],[461,1],[473,1],[475,2],[487,3],[491,4],[531,1],[573,1],[575,4],[580,2],[595,1],[611,1],[613,4],[631,1],[641,3],[688,1],[703,1],[721,2],[724,4],[736,1],[738,4],[743,2],[746,1],[748,2],[751,3],[767,1],[781,2],[784,4],[789,4],[794,4],[799,4],[810,1],[812,2],[815,1],[817,3],[821,5],[827,4],[832,3],[850,1],[852,3],[856,2],[864,1],[886,1],[888,5],[983,2],[1009,2],[1019,2],[1055,2],[1066,2],[1226,1],[1247,1],[1300,1],[1319,1],[1342,2],[1345,2],[1348,3],[1352,4],[1357,3],[1378,1],[1385,2],[1402,1],[1415,1],[1417,6],[1435,1],[1437,4],[1442,3],[1460,1],[1462,3],[1466,4],[1489,1],[1491,3],[1495,1],[1497,4],[1502,6],[1520,3],[1524,2],[1544,1],[1563,2],[1574,1],[1576,5],[1582,3],[1586,2],[1596,1],[1606,1],[1608,5],[1665,1],[1797,1],[1825,1],[1833,1],[1835,6],[1859,1],[1876,2],[1879,3],[1883,1]]},"990":{"position":[[13,1],[15,2],[36,1],[44,1],[46,2],[49,3],[63,1],[65,4],[77,1],[92,2],[95,5],[167,1],[180,1],[196,1],[265,4],[270,1],[272,2],[275,2],[278,2],[286,1],[288,6],[295,2],[298,3],[328,2],[345,3],[349,1],[362,1],[364,3],[376,1],[378,3],[382,4],[387,2],[396,1],[408,1],[410,4],[415,5],[421,2],[429,3],[433,3],[443,1],[445,4],[530,1],[563,3],[581,1],[583,3],[597,1],[612,1],[614,4],[619,2],[622,3],[634,2],[651,1],[653,3],[667,6],[674,6],[707,1],[709,3],[713,4],[718,2],[721,2],[724,3],[728,7],[736,3]]},"992":{"position":[[18,1],[51,1],[82,1],[84,3],[88,2],[91,5],[97,3],[101,3],[119,1],[121,4],[139,3],[143,2],[166,4],[171,5],[177,2],[180,1],[190,3],[194,4],[199,2],[202,5],[208,2],[211,2],[214,2],[225,1],[227,2],[239,1],[241,4],[265,1],[267,4],[283,1],[285,2],[298,1],[300,4],[317,2],[320,5],[347,1],[349,5],[355,1],[376,1],[378,2],[386,1],[395,1],[397,3],[401,2],[404,6],[428,1],[438,1],[440,1],[452,2],[455,7],[463,1],[465,4],[482,2],[485,4],[490,4],[495,3],[529,1],[531,5],[537,2],[566,1],[568,2],[571,2],[574,6],[581,4],[586,1],[593,1],[595,6],[602,2],[615,2],[618,5],[624,2],[627,3],[631,4],[636,6],[654,2],[657,4],[662,3],[681,2],[703,1],[705,3],[723,1],[725,2],[728,1],[730,5],[736,1],[747,1],[749,3],[761,1],[782,1],[784,4],[795,1],[797,2],[832,1],[834,3],[838,2],[873,1],[891,1],[893,5],[915,2],[918,2],[921,2],[924,5],[944,1],[946,5],[960,1],[985,1],[987,4],[1014,1],[1016,3],[1020,4],[1063,1],[1065,2],[1068,6],[1092,2],[1103,1],[1105,2],[1108,2],[1111,2],[1114,3],[1118,1],[1132,1],[1134,2],[1137,2],[1140,3],[1144,5],[1180,1],[1182,6]]},"994":{"position":[[0,1],[7,1],[9,3],[13,3],[60,1],[62,3],[66,4],[75,1],[95,1],[127,1],[129,1],[151,1],[164,2],[167,4],[200,1],[213,1],[218,1],[224,1],[256,1],[258,5],[268,1],[291,2],[298,2],[314,1],[316,3],[320,1],[322,4],[327,1],[334,1],[336,2],[349,1],[387,1],[406,1],[412,1],[450,3],[462,2],[479,1],[481,3],[494,2],[497,6],[504,4],[517,1],[531,1],[533,2],[544,1],[558,1],[560,6],[584,1],[586,4],[591,5],[597,2],[600,3],[604,4],[609,2],[612,3],[626,3],[630,5],[642,3],[646,3],[650,2],[661,1],[670,1],[675,1],[691,1],[693,6],[700,2],[711,1],[713,1],[720,1],[737,1],[739,4],[744,3]]},"997":{"position":[[0,3],[17,1],[44,1],[46,5],[148,2],[151,3],[160,3],[177,2],[180,2],[183,2],[216,1],[223,2],[243,1],[245,2],[248,5],[254,4],[273,1],[275,3],[341,2],[344,4],[349,2],[366,1],[387,1],[405,2],[408,3],[481,1],[506,1],[508,3],[517,4],[522,1],[545,1],[554,2],[562,2],[565,4],[570,4],[588,1],[590,2],[640,1],[642,4],[647,3],[654,4],[663,2],[666,3],[670,3],[710,1],[742,1],[744,3],[754,3],[758,4],[763,2],[770,2],[773,5],[779,2],[782,3],[786,2],[797,1],[799,3],[803,5],[816,1],[823,3],[827,2],[830,2],[833,2],[836,5],[853,1],[855,3],[859,3],[863,2],[866,2],[869,3],[883,1],[895,2],[927,3]]},"999":{"position":[[11,3],[23,1],[25,3],[29,2],[32,3],[68,1],[70,4],[75,4],[97,2],[100,5],[127,1],[129,2],[137,2],[140,3],[168,2],[171,3],[196,1],[205,1],[212,3],[216,2],[235,3],[247,1],[249,2],[252,1],[254,4],[259,2],[267,2],[283,1],[285,5],[343,1],[383,3],[395,1],[407,1],[409,3],[431,1],[433,7],[451,1],[473,1],[475,2],[478,2],[493,1],[495,2],[515,1],[517,4],[522,3],[534,1],[566,1],[568,3],[572,5],[578,3],[582,3],[586,3],[598,1],[600,2],[612,1],[614,2],[617,5],[631,1],[633,5],[639,5],[645,3],[649,2],[670,1],[672,4],[677,4],[682,6],[689,5],[695,4],[700,2],[703,1],[705,6],[712,5],[730,2],[733,2],[736,6],[753,1],[755,2],[762,3],[766,2],[769,3],[783,2],[791,5],[805,2],[815,1],[817,2],[820,2],[823,3],[827,2],[842,1],[844,2],[847,4],[871,1],[873,2],[890,1],[916,1],[918,5],[924,2],[927,2],[944,1],[946,2],[949,3],[967,1],[969,4],[974,2],[991,1],[1001,1],[1016,2],[1031,2],[1047,3],[1074,1],[1090,1],[1109,3],[1113,3],[1117,3],[1121,4],[1126,6],[1152,4],[1157,3],[1161,2],[1164,4],[1169,2],[1172,3],[1189,4],[1194,2],[1197,3],[1214,2],[1236,2],[1242,2],[1265,1],[1267,5]]},"1002":{"position":[[8,1],[12,2],[20,1],[32,1],[39,1],[41,3],[45,5],[91,2],[99,1],[111,3],[115,5],[131,2],[134,2],[137,3],[141,5],[157,1],[168,1],[177,1],[179,1],[181,3],[185,6],[197,1],[199,1],[201,2],[214,1],[219,1],[221,6],[236,2],[242,1],[244,5],[258,2],[273,2],[289,1],[291,3],[315,1],[317,3],[321,4],[326,5],[346,2],[349,3],[353,2],[356,3],[360,3],[372,2],[385,1],[392,2],[411,3],[425,1],[427,1],[429,1],[431,4],[443,1],[445,2],[448,4],[463,1],[491,1],[498,2],[508,1],[527,1],[529,4],[550,4],[565,1],[567,6],[590,1],[592,5],[638,2],[641,4],[646,3],[650,2],[742,1],[760,2],[763,4],[768,5],[802,2],[817,2],[820,6],[827,3],[831,2],[834,3],[843,1],[845,2],[848,2],[856,2],[859,3],[870,1],[891,4],[896,5],[902,3],[906,2],[909,4],[914,4],[919,2],[935,4],[940,3],[952,1],[962,1],[964,2],[967,2],[970,4],[985,1],[987,3],[996,6],[1003,3],[1007,3],[1011,2],[1014,5]]},"1004":{"position":[[8,1],[10,3],[14,1],[16,3],[28,1],[30,2],[33,2],[36,4],[52,2],[55,3],[59,3],[89,1],[91,2],[104,1],[114,2],[126,3],[130,4],[135,3],[139,3],[143,4],[156,1],[158,3],[162,1],[164,5],[170,3],[174,2],[177,2],[212,1],[224,2],[232,2],[235,4],[240,1],[242,2],[287,4],[292,3],[296,2],[299,4],[304,4],[319,1],[334,3],[346,1],[356,1],[358,2],[361,4],[366,2],[369,4],[374,2],[377,5],[383,2],[413,2],[438,3],[452,1],[470,2],[486,2],[489,4],[494,4],[499,5]]},"1006":{"position":[[16,3],[32,3],[36,5],[50,3],[54,3],[58,3],[62,3],[66,3],[70,3],[81,1],[83,1],[85,2],[98,6],[126,1],[131,3],[138,2],[141,3],[145,2],[156,1],[158,2],[161,3],[165,4],[170,3],[174,2],[177,2],[208,1],[210,3],[214,5],[234,1],[248,1],[250,1],[252,1],[254,5],[260,5],[274,1],[284,2],[296,2],[299,1],[304,3],[308,4],[313,3],[317,2],[334,1],[348,1],[350,2],[353,2],[356,3],[360,4],[365,3],[377,1],[379,3],[383,3],[387,2],[390,2],[401,1],[407,2],[420,1],[422,7],[436,2],[447,1],[449,4],[454,2],[475,3],[487,1],[489,3],[493,3],[497,4],[502,1],[504,2],[507,3],[511,3],[515,2],[532,1],[561,1],[577,2],[589,1],[591,2],[605,4],[610,4],[615,3],[625,1],[646,1],[648,6],[655,4],[660,2],[680,1],[688,1],[690,2],[707,1],[709,2],[737,1],[750,1],[752,5],[769,1],[771,3],[793,1],[810,1],[835,3],[839,4],[844,2],[868,2],[871,2],[879,1],[881,5],[887,3],[891,1],[893,2],[896,2],[923,1],[925,6],[932,2],[949,1],[951,4],[975,1],[977,6],[991,1],[1007,1],[1031,1],[1033,2],[1047,1],[1049,2],[1052,3],[1056,4],[1061,5],[1121,1],[1123,4],[1128,2],[1131,2],[1134,6],[1141,2],[1144,3],[1148,3],[1152,5],[1158,2],[1167,1],[1199,1],[1207,1],[1216,2],[1219,1],[1221,2],[1224,3],[1228,3],[1232,2],[1258,1],[1260,3],[1264,4],[1269,2],[1272,3],[1286,1],[1288,2],[1291,2],[1294,4],[1299,3],[1335,1],[1345,1],[1384,4],[1389,5],[1403,1],[1405,2],[1408,3],[1412,2],[1415,3],[1419,3],[1423,2],[1448,4],[1453,2],[1456,3],[1465,1],[1490,3],[1494,5],[1556,1],[1558,4],[1563,4],[1581,1],[1583,4],[1588,5],[1594,3],[1598,1],[1600,3],[1604,3],[1615,1],[1630,1],[1632,4],[1637,3],[1649,1],[1651,2],[1654,3],[1658,3],[1662,3],[1666,4],[1677,1],[1683,1],[1685,2],[1696,1],[1698,2],[1701,3],[1724,1],[1726,4],[1731,3],[1735,5],[1741,1],[1743,4],[1748,4],[1753,1],[1755,2],[1777,1],[1779,4],[1784,3],[1788,5],[1798,3],[1808,1],[1817,1],[1819,3],[1823,1],[1825,3],[1829,3],[1849,2],[1855,1],[1861,1],[1863,2],[1866,2],[1869,3],[1873,4],[1887,1],[1889,3],[1893,1],[1895,2],[1898,3],[1902,3],[1906,2],[1909,3],[1913,1],[1932,1],[1940,2],[1943,3],[1947,3],[1951,2],[1962,1],[1964,4],[1969,3],[1973,3],[1977,2],[1980,3],[2001,1],[2003,4],[2008,2],[2020,1],[2022,4],[2027,5],[2033,3],[2037,1],[2039,2],[2042,4],[2047,2],[2099,1],[2109,1],[2111,2],[2121,1],[2135,2],[2162,1],[2164,5],[2189,1],[2191,4],[2198,1],[2200,4],[2205,2],[2232,1],[2234,2],[2256,1],[2258,3],[2268,1],[2270,2],[2273,4],[2278,5],[2298,1],[2300,2],[2315,1],[2317,2],[2330,1],[2332,4],[2390,2],[2393,3],[2402,3],[2406,2],[2409,2],[2419,3],[2427,1],[2429,2],[2437,2],[2440,2],[2453,1],[2455,5],[2461,1],[2469,1],[2471,2],[2474,4],[2479,2],[2516,1],[2518,4],[2528,1],[2534,2],[2537,2],[2540,3],[2557,4],[2562,2],[2575,1],[2577,2],[2580,4],[2585,2],[2607,1],[2628,1],[2630,5],[2636,3],[2640,4],[2653,1],[2655,2],[2663,1],[2675,1],[2681,1],[2683,3],[2687,5],[2705,2],[2716,1],[2718,3],[2736,1],[2750,2],[2763,1],[2765,1],[2777,1],[2779,2],[2792,2],[2795,1],[2802,1],[2804,2],[2807,2],[2822,2],[2838,1],[2840,3],[2844,3],[2862,1],[2878,1],[2880,1],[2882,2],[2894,1],[2896,2],[2899,2],[2902,2],[2905,1],[2907,3]]},"1008":{"position":[[0,3],[13,1],[23,2],[39,2],[42,3],[46,3],[50,3],[75,1],[102,1],[118,2],[142,1],[144,4],[149,2],[164,1],[166,3],[170,2],[185,3],[197,1],[204,3],[208,3],[212,2],[215,3],[219,3],[223,4],[228,2],[231,4],[236,4],[255,1],[257,2],[294,1],[296,3],[300,4],[305,4],[310,1],[312,2],[315,2],[318,3],[322,3],[340,1],[346,1],[362,1],[383,1],[385,4],[397,2],[400,2],[403,1],[405,2],[408,2],[411,2],[442,1],[448,1],[459,3],[463,4],[482,1],[484,2],[487,1],[489,2],[492,2],[495,2],[510,1],[512,2],[545,1],[547,3],[551,3],[555,3],[574,1],[579,1],[581,3],[585,3],[636,3],[645,1],[647,4],[652,2],[663,1],[665,3],[669,2],[677,2],[680,5],[686,5],[692,3],[696,3],[700,2],[703,2],[706,1],[736,1],[738,3],[742,2],[745,2]]},"1010":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1012":{"position":[[14,1],[36,1],[47,1],[49,4],[72,1],[74,5],[89,1],[96,1],[98,2],[101,1],[103,3],[107,4],[112,2],[115,3],[119,1],[121,3],[162,2],[165,2],[168,4],[187,1],[189,4],[194,3],[216,1],[218,4],[223,1],[225,4],[230,2],[233,3],[251,3],[283,1],[285,3],[289,1],[291,3],[295,1],[297,2],[300,1],[302,3],[306,4],[311,2],[314,3],[318,4],[323,4],[342,1],[344,2],[347,3],[355,3],[359,2],[362,3],[366,2],[369,5],[375,4],[380,1],[382,2],[385,3],[389,4],[394,3],[398,2],[413,1],[415,3],[419,5],[441,1],[447,1],[452,1],[454,2],[469,1],[475,3],[489,1],[548,1],[550,2],[565,1],[567,4],[572,4],[577,5],[595,1],[597,5],[603,2],[606,3],[610,2],[613,3],[626,2],[629,2],[632,2]]},"1014":{"position":[[15,1],[17,2],[20,3],[34,1],[36,3],[40,6],[47,2],[50,4],[55,5],[61,3],[65,3],[86,1],[100,1],[102,3],[122,3],[133,2],[136,3],[140,2],[143,3],[162,1],[164,2],[176,1],[195,1],[197,4],[202,3],[215,1],[217,3],[221,3],[225,4],[240,1],[242,1],[249,1],[251,2],[270,1],[277,1],[279,4],[284,3],[288,2],[294,1],[296,2],[299,3],[303,2],[306,4],[321,1],[338,1],[354,1],[365,2],[392,1],[394,4],[402,1],[410,2],[413,2],[435,1],[437,3],[472,1],[483,2],[493,1],[495,4],[515,2],[531,1],[540,1],[548,1],[550,3],[554,5],[560,4],[571,2],[584,1],[595,1],[597,3],[601,2],[604,3],[624,1],[638,1],[640,2],[662,1],[676,1],[678,4],[683,3],[687,4],[692,3],[696,2],[718,1],[737,1],[746,2],[749,4],[785,1],[809,1],[829,1],[831,2],[843,1],[864,1],[877,1],[879,2],[887,2],[900,1],[902,6],[909,2],[912,3],[930,3],[934,2],[940,1],[942,4],[947,2],[978,2],[984,1],[996,1],[998,2],[1001,3],[1005,2],[1008,2],[1011,2],[1014,1],[1016,3],[1020,3],[1024,3],[1028,4],[1036,1],[1038,3],[1042,2],[1045,3],[1058,4],[1063,5],[1081,1],[1094,3],[1098,2],[1101,2],[1104,3],[1108,5],[1114,3],[1122,1],[1124,2],[1130,1],[1132,4],[1137,3],[1141,2],[1144,3],[1148,3],[1152,4],[1157,2],[1160,1],[1162,2],[1165,3],[1169,2],[1172,3],[1225,1],[1227,3],[1231,1],[1233,3],[1237,2],[1252,1],[1254,3],[1273,1],[1275,2],[1284,1],[1304,2],[1326,1],[1339,1],[1341,3],[1345,5],[1351,2],[1354,3],[1368,1],[1370,3],[1374,3],[1378,1],[1380,2],[1395,1],[1397,3],[1401,2],[1404,3],[1408,2],[1411,3],[1415,1],[1417,3],[1421,3],[1425,2],[1428,2],[1431,2],[1434,2],[1437,2],[1452,1],[1459,2],[1476,2],[1479,3],[1483,2],[1486,2],[1489,1],[1521,1],[1548,2],[1578,1],[1580,4],[1585,3],[1594,2],[1609,1],[1611,3],[1615,3],[1619,4],[1629,1],[1651,1],[1653,3],[1662,1],[1679,1],[1681,4],[1695,2],[1698,3],[1702,2],[1705,1],[1712,1],[1714,2],[1717,3],[1721,2],[1724,2]]},"1017":{"position":[[9,1],[11,1],[13,3],[17,2],[60,4],[65,2],[68,2],[71,2],[79,1],[91,2],[138,4],[143,2],[146,2],[149,2],[177,1],[209,2]]},"1019":{"position":[[17,1],[30,1],[63,1],[104,1],[106,3],[171,1],[173,2],[176,2],[179,3],[183,3],[187,1],[189,3],[193,3],[219,1],[238,1],[240,5],[271,1],[407,1],[409,3],[447,1],[471,1],[473,4],[482,1],[484,2],[512,2],[544,2],[617,1],[619,5],[650,1],[661,2],[769,1],[771,1],[773,1],[775,3],[793,1],[795,3],[819,1],[831,1],[836,1],[849,2],[852,1],[854,1],[856,3]]},"1022":{"position":[[34,1],[36,2],[55,2],[58,5],[64,6],[71,3],[75,4],[80,2],[86,1],[88,5],[94,3],[98,2],[101,2]]},"1024":{"position":[[24,1],[40,3],[56,1],[58,2],[64,1],[69,1],[82,3],[86,4],[116,1],[122,1],[124,5],[133,1],[138,2],[141,2],[144,3],[148,4]]},"1026":{"position":[[34,2],[41,4],[46,1],[48,3],[52,3],[56,5],[84,1],[86,2],[92,1],[94,3],[98,4],[103,4],[125,1],[127,1],[141,1],[143,2],[161,1],[163,4],[173,2],[176,4],[181,4],[186,4],[191,2],[194,1],[196,3],[200,3],[204,4],[222,1],[232,3],[270,2],[276,1],[278,4],[283,4],[310,2],[313,3],[317,2],[320,3],[324,5],[330,1],[332,4],[337,4],[349,1],[360,1],[362,2],[365,4],[370,5],[395,1],[397,3],[413,2]]},"1028":{"position":[[34,2],[55,1],[82,2],[85,5],[101,3],[105,2],[108,2],[111,1],[113,2],[126,2],[145,4],[150,2],[172,1],[174,2],[177,3],[198,1],[217,1],[219,5],[225,4],[230,3],[234,2],[237,1],[239,3],[243,4],[248,2],[263,1],[284,4],[289,2],[298,2],[301,5],[307,2],[317,1],[326,1],[342,1],[344,3],[360,1],[362,1],[364,2],[407,1],[412,3],[416,1],[418,3],[422,2],[425,2],[428,1],[448,1],[450,6],[477,1],[479,2],[496,1],[498,3],[509,1],[528,1],[530,1],[532,4],[537,3],[541,2]]},"1031":{"position":[[0,2],[3,4],[8,2],[32,1],[34,3],[38,2],[45,2],[75,1],[77,5],[83,3],[91,1],[93,3],[97,1],[99,4],[109,1],[119,1],[121,6],[128,2],[149,1],[160,1],[162,3],[170,1],[172,3],[176,2],[179,3],[183,6],[190,2],[213,1],[224,3],[228,3],[232,5],[238,2],[241,3],[245,4]]},"1033":{"position":[[14,1],[28,2],[31,3],[35,3],[39,3],[43,3],[56,1],[58,5],[64,2],[81,1],[88,3],[92,5],[98,5],[104,3],[128,1],[130,1],[132,2],[146,4],[151,5],[185,1],[187,1],[189,1],[198,2],[207,5]]},"1035":{"position":[[20,1],[22,2],[31,1],[33,2],[39,2],[68,1],[70,2],[78,1],[80,4],[85,6],[103,1],[117,1],[119,5],[125,2],[128,5],[134,1],[136,2],[139,4],[144,4],[149,3],[153,1],[155,4],[160,1],[162,3]]},"1037":{"position":[[12,3],[16,2],[27,1],[29,4],[34,2],[40,1],[42,6],[62,4],[67,5],[91,1],[93,4],[98,4],[103,2],[118,1],[125,1],[127,2],[136,2],[180,1],[182,5],[200,1],[202,2],[205,3],[209,2],[220,1],[222,5]]},"1039":{"position":[[12,2],[15,3],[19,2],[22,3],[44,1],[55,1],[57,2],[60,4],[65,2],[68,2],[71,1],[73,3],[80,1],[82,3],[86,2],[89,3],[125,2],[128,5],[134,2],[161,1],[163,3],[167,5],[184,1],[193,4],[198,4],[228,2],[238,1],[258,1],[270,1],[284,1],[296,1],[298,4],[303,2],[306,1],[308,3],[312,2],[315,3],[319,3],[323,2],[335,1],[337,2],[357,4],[362,2]]},"1041":{"position":[[12,1],[18,3],[22,5],[28,2],[41,1],[43,5],[49,2],[52,2],[111,1],[136,2]]},"1043":{"position":[[0,3],[4,2],[49,1],[70,2],[73,1],[75,4],[80,2],[92,1],[94,2],[97,3],[121,2],[124,1],[131,1],[137,2],[140,3],[144,3],[148,2]]},"1045":{"position":[[11,5],[17,1],[29,1],[31,5],[37,2],[99,1],[101,5],[107,2],[110,3],[136,1],[138,5],[162,1],[164,2]]},"1047":{"position":[[8,1],[22,1],[37,1],[39,5],[55,2],[92,1],[109,2],[112,3],[116,2],[119,3],[123,1],[125,3],[129,2],[144,1],[161,2],[164,2],[172,2],[178,3],[182,5],[206,1],[213,2],[220,1],[222,4],[227,2],[264,1],[269,2],[272,3],[276,2],[279,3],[293,3],[321,1],[323,3],[327,5],[336,1],[341,1],[354,2],[369,1],[371,2],[380,2],[386,1],[388,4],[398,1],[425,1],[427,3],[431,3],[435,2],[441,1]]},"1049":{"position":[[8,2],[11,3],[28,5],[34,2],[42,2],[48,1],[50,3],[54,1],[56,3],[60,2],[71,3],[75,2],[78,3],[90,1],[92,4],[131,2],[134,2],[137,3],[141,2],[178,1],[190,2],[193,2],[196,5],[202,2],[205,2],[208,3],[212,2],[225,2],[250,1],[252,4],[257,2],[287,1],[289,4],[294,4],[299,2],[302,2],[308,1],[310,3],[314,4],[324,2],[347,1],[361,1],[363,2],[366,3],[370,3],[374,1]]},"1052":{"position":[[0,2],[15,4],[44,1],[46,3],[50,2],[53,2],[56,3],[60,3],[84,4],[101,1],[103,3],[107,3],[111,1],[113,1],[115,3],[129,1],[131,2],[146,1],[155,2],[158,2],[161,5],[167,3],[171,2],[189,1],[191,4],[208,1],[222,2],[233,1],[235,4],[240,1],[242,2],[245,3],[249,3],[253,2],[256,4],[272,1],[280,1],[282,2],[292,1],[302,1],[304,5],[313,1],[315,2],[334,1],[346,1],[348,2],[351,2],[365,1],[373,1],[375,2],[378,2],[381,4],[386,3],[390,3]]},"1054":{"position":[[24,1],[38,3],[42,2],[45,4],[80,3],[84,3],[88,2],[91,3],[95,2],[105,1],[107,3],[122,1],[124,5],[130,2],[133,1],[135,6],[149,1],[151,5],[157,2],[160,2],[163,2],[172,1],[174,2],[177,3],[181,4],[186,3],[196,1],[198,4],[203,3],[207,3],[211,3],[225,1],[235,1],[237,3],[259,4],[264,6],[271,4],[276,2],[279,2],[282,4],[287,2],[290,2],[293,3],[297,3],[305,3],[322,2],[332,1],[334,4],[339,4],[344,2],[353,1],[355,4],[360,2],[363,2],[366,3],[370,2],[373,2]]},"1056":{"position":[[12,2],[15,5],[21,4],[26,4],[31,5],[40,1],[42,2],[45,2],[54,1],[77,1],[79,2],[85,1],[98,1],[100,3],[104,3],[108,2],[111,2],[114,4],[139,1],[141,4],[158,1],[160,2],[163,3],[167,3],[180,1],[182,1],[184,1],[186,2],[189,4],[194,2]]},"1058":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1060":{"position":[[0,2],[46,1],[69,1],[77,1],[79,3],[102,1],[143,2],[146,3],[156,1],[164,2],[167,3],[171,3],[175,4],[183,1],[185,2],[193,2],[196,5],[228,1],[242,3],[246,2],[249,3],[253,3],[257,2],[270,1],[272,4],[277,3],[281,3],[285,3],[289,4],[313,1],[315,5],[344,1],[346,4],[363,1],[386,1],[388,2],[415,1],[430,1],[432,3],[436,3],[440,1],[442,2],[445,2],[448,2],[451,3],[455,4],[489,2],[492,2],[495,3],[499,2],[559,1],[561,4],[566,2],[569,3],[573,4],[578,4],[583,2],[598,1],[615,7],[638,1],[647,1],[651,2],[654,3],[658,2],[661,2],[664,2],[667,2],[681,1],[683,6],[696,3],[700,3],[704,5],[710,2],[713,2],[716,4],[721,5],[727,3],[753,1],[758,2],[761,5],[767,2],[770,4],[775,4],[780,3],[784,1],[786,4],[791,2],[794,3],[830,1],[832,2],[847,1],[869,1],[897,1],[899,2],[902,2],[905,1],[907,2],[910,2],[927,1],[929,3],[933,2],[936,2],[946,1],[958,1],[971,1],[973,4],[982,2],[985,6],[992,3],[996,2],[1036,1],[1065,2],[1078,1],[1103,1],[1105,5],[1111,1],[1113,2],[1116,3],[1120,3],[1124,2],[1127,4],[1132,1],[1134,2],[1155,2],[1203,1],[1205,4],[1210,4],[1215,3],[1219,2],[1222,4],[1227,1],[1229,4],[1234,2],[1237,4],[1242,3]]},"1062":{"position":[[3,1],[15,2],[34,1],[36,2],[39,3],[43,3],[47,3],[55,1],[72,4],[77,1],[79,3],[83,2],[115,1],[127,1],[129,6],[136,3],[140,3],[144,3],[148,3],[152,3],[156,2],[175,1],[177,2],[180,2],[193,1],[195,5],[205,1],[207,3],[211,3],[215,4],[220,2],[223,4],[228,2],[231,2],[237,1],[244,2],[247,4],[287,1],[295,2],[298,3],[316,1],[344,1],[346,5],[352,3],[356,4],[361,2],[364,3],[368,3],[372,2],[395,1],[397,5],[403,3],[407,2],[410,2],[418,2],[421,3],[428,1],[430,3],[439,1],[447,2],[450,2],[453,3],[457,4],[464,2],[467,4],[472,2],[475,2],[478,2],[481,1],[483,4],[488,2],[491,1],[493,3],[497,4],[502,2],[510,2],[524,3],[541,2],[557,1],[572,2],[575,1],[585,1],[587,3],[591,2],[594,4],[612,2],[615,3],[627,1],[651,1],[670,2],[673,3],[677,2],[703,3],[723,3],[727,2],[735,3],[739,3],[743,3],[747,3],[751,2],[769,1],[771,3],[775,5],[793,1],[816,1],[818,2],[821,3],[825,2],[855,1],[875,1],[877,2],[880,3],[884,2],[902,1],[904,2],[907,1],[909,4],[932,3],[936,5],[942,3],[946,2],[949,3],[953,3],[957,2],[970,2],[973,2],[976,4],[981,4],[986,2],[989,2],[992,4],[997,2],[1005,5],[1011,1],[1013,5],[1051,1],[1053,5],[1081,1],[1103,1],[1133,1],[1135,2],[1156,1],[1158,2],[1184,1],[1199,1],[1201,2],[1234,1],[1266,1],[1268,1],[1270,2],[1273,2],[1290,1],[1292,4],[1310,2],[1313,3],[1317,2],[1320,3],[1324,2],[1334,1],[1345,2],[1358,1],[1360,2],[1368,3],[1372,5],[1378,3],[1382,2],[1385,4],[1390,1],[1392,4],[1397,2],[1400,4],[1405,2],[1408,6],[1426,1],[1428,4],[1447,1],[1462,1],[1468,2],[1471,3],[1475,2],[1478,2],[1481,4],[1486,4],[1491,4],[1496,3],[1500,2],[1508,1],[1510,4],[1515,3],[1519,4],[1537,2],[1545,1],[1569,1],[1571,3],[1575,2],[1590,1],[1592,6],[1602,1],[1604,3],[1608,3],[1612,3],[1625,1],[1637,4],[1642,5],[1653,1],[1672,2],[1675,2],[1685,1],[1690,2],[1697,1],[1699,4],[1714,3],[1723,1],[1725,4],[1730,4],[1753,2],[1756,3],[1760,1],[1762,2],[1765,3],[1769,3],[1773,2],[1776,4],[1781,4],[1786,2],[1794,1],[1796,1],[1798,2],[1801,3],[1805,3],[1830,1],[1843,6],[1850,2],[1853,5],[1859,2],[1862,3],[1866,1],[1868,3]]},"1065":{"position":[[61,2],[104,1],[132,1],[181,1],[183,2],[186,2],[189,1],[211,1],[276,1],[278,3],[291,1],[293,3],[300,1],[368,1],[408,2],[411,2],[418,1],[435,2],[438,2],[473,1],[475,2],[478,2],[498,2],[517,1],[519,5],[525,3],[535,1],[543,1],[545,3],[556,1],[601,1],[634,1],[636,1],[661,1],[663,3],[667,3],[731,1],[754,1],[821,3],[839,1],[864,1],[866,5]]},"1067":{"position":[[46,1],[48,3],[118,1],[135,1],[137,2],[254,1],[278,2],[281,2],[353,1],[457,1],[459,2],[482,2],[500,4],[549,1],[555,1],[571,1],[577,1],[663,1],[676,1],[682,1],[700,3],[704,3],[724,3],[728,2],[740,2],[743,1],[762,1],[772,1],[790,1],[792,3],[796,3],[865,1],[887,1],[960,3],[964,5],[991,4],[996,4],[1001,2],[1030,1],[1043,1],[1048,1],[1077,2],[1080,4],[1089,1],[1095,1],[1097,5],[1103,3],[1111,1],[1118,1],[1125,1],[1127,1],[1129,2],[1136,2],[1139,3],[1143,1],[1145,3],[1156,4],[1161,5],[1205,1],[1209,1],[1213,1],[1225,1],[1239,1],[1262,1],[1264,2],[1267,4],[1272,6],[1290,1],[1292,4],[1297,4],[1302,5],[1372,1],[1402,3],[1436,1],[1442,1],[1472,1],[1474,5],[1494,1],[1510,2],[1513,3],[1517,2],[1520,3],[1524,1],[1526,3],[1530,5],[1536,4],[1541,5]]},"1070":{"position":[[25,1],[34,1],[47,1],[49,2],[67,3],[87,1],[89,2],[329,1],[368,2],[382,3],[396,1],[398,2],[416,1],[418,1],[436,1],[447,2],[450,2],[485,1],[509,1],[528,2],[531,2],[534,5],[540,6],[547,4],[561,1],[583,2],[615,1],[708,3],[712,3],[716,2],[736,1],[746,1],[757,2],[800,1],[816,1],[818,2],[821,2],[824,2],[833,2],[855,1],[861,2],[864,4],[889,2],[892,4],[897,2],[905,1],[924,2],[927,3],[942,1],[982,3],[1002,1],[1013,1],[1034,1],[1039,3],[1065,1],[1070,1],[1072,3],[1076,6],[1126,1],[1131,1],[1156,1],[1158,3],[1162,2],[1165,5],[1199,1],[1201,3],[1214,1],[1216,3],[1234,1],[1244,1],[1246,3],[1257,4],[1262,2],[1265,2],[1268,2],[1351,1],[1353,3],[1362,1],[1386,1],[1396,1],[1413,1],[1415,2],[1441,1],[1458,1],[1460,3],[1464,3],[1490,1],[1498,2],[1501,2],[1509,1],[1514,3],[1518,5],[1524,4],[1600,1],[1620,1],[1622,4],[1627,2],[1639,5],[1649,1],[1660,1],[1675,2],[1681,4],[1686,4],[1700,1],[1702,2],[1710,1],[1732,3],[1741,1],[1743,2],[1746,3],[1750,3],[1778,1],[1787,1],[1802,1],[1804,3],[1820,1],[1844,1],[1859,1],[1861,5],[1880,1],[1882,3]]},"1073":{"position":[[5,1],[12,1],[24,2],[54,1],[56,6],[77,1],[83,2],[96,1],[98,3],[102,2],[109,1],[111,2],[125,1],[127,2],[148,1],[170,1],[172,2],[175,3],[182,1],[184,2],[187,1],[189,3],[212,1],[214,3],[235,1],[237,3],[246,1],[248,2],[256,1],[269,1],[271,2],[274,5],[280,3],[284,3]]},"1075":{"position":[[22,2],[30,1],[43,1],[65,1],[87,1],[89,3],[96,1],[98,4],[123,2],[126,2],[132,1],[134,6],[155,1],[157,4],[162,3],[166,3],[170,2],[173,3]]},"1077":{"position":[[0,1],[2,2],[19,1],[30,2],[38,1],[40,2],[53,3],[57,2],[72,2],[84,1],[93,2],[96,3],[100,6],[111,3],[115,4],[120,2]]},"1080":{"position":[[5,1],[15,2],[39,1],[62,1],[64,1],[66,2],[69,2],[72,4],[100,2],[112,1],[127,3],[131,2],[134,1],[136,4],[161,1],[173,1],[193,1],[212,1],[214,4],[219,3],[223,2],[226,4],[231,5],[253,1],[255,5],[261,5],[267,3],[271,5],[277,3],[290,2],[298,1],[322,1],[324,4],[334,2],[348,2],[351,2],[354,2],[357,1],[359,4],[364,3],[368,2],[371,4],[376,3],[385,1],[387,3],[391,1],[393,4],[398,3],[420,1],[428,1],[430,4],[444,1],[446,4],[477,1],[479,2],[482,1],[484,2],[487,3],[491,4],[496,2],[499,3],[503,1],[505,3]]},"1082":{"position":[[20,1],[22,4],[32,1],[50,6],[83,1],[85,4],[90,2],[93,2],[96,2],[99,3],[103,2],[124,2],[127,2],[130,2],[133,4],[138,3],[142,2],[145,3],[158,2],[172,1],[174,2],[197,1],[207,1],[215,2],[218,3],[222,2],[225,3],[229,1],[236,2],[248,3],[263,1],[265,2],[273,2],[288,1],[298,1],[305,2],[308,3],[312,2],[315,2],[318,1],[326,2],[329,1],[331,4],[341,1],[343,2],[351,1],[353,4],[358,3],[362,2],[365,3]]},"1084":{"position":[[30,1],[47,2],[50,2],[53,6],[65,1],[67,2],[70,1],[72,3],[76,3],[80,3],[84,3],[93,4],[98,3],[102,2],[123,1],[125,2],[153,3],[157,3],[173,2],[176,2],[191,1],[207,1],[222,1],[237,2],[240,2],[317,1],[334,1],[336,3],[340,3],[366,4],[376,1],[378,3],[382,2],[385,1],[387,4],[392,1],[394,2],[397,2],[400,2],[403,2],[411,1],[429,1],[431,5],[437,2],[454,2],[467,2],[470,2],[473,2],[578,1],[580,3],[589,1],[596,1],[617,2],[620,4],[625,2],[636,1],[643,1],[655,2],[663,1],[681,1],[683,2],[686,2],[700,1],[717,2],[720,4],[725,2],[728,2],[731,5],[737,2],[740,2],[743,4],[769,2],[777,1],[779,4],[784,2],[787,3],[796,1],[798,3],[817,2],[820,1],[822,3],[826,2],[829,2],[842,4],[865,1],[867,3],[876,1],[891,2],[898,1],[900,3],[904,3],[908,4],[913,2],[921,3],[925,4],[930,3],[934,2],[987,1],[989,1],[991,2],[994,2],[1011,2],[1014,3],[1018,5],[1172,1],[1174,3],[1183,1],[1185,1],[1187,2],[1190,2],[1216,1],[1218,4],[1223,5]]},"1087":{"position":[[17,1],[39,1],[51,2],[54,4],[59,5],[70,1],[79,1],[81,2],[89,1],[91,2],[94,3],[98,3],[102,2],[105,4],[110,2],[145,2],[198,1],[200,3],[204,2],[207,3],[226,1],[256,2],[259,1],[261,3],[265,2],[268,2],[271,3],[275,2],[278,1],[280,3],[284,3],[303,1],[305,6],[328,1],[330,3],[334,3],[338,4],[343,3],[347,3],[351,2],[354,6],[365,1],[367,2],[380,2],[383,3],[387,3],[391,3]]},"1089":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1091":{"position":[[0,4],[17,3],[31,1],[75,1],[77,2],[80,3],[84,4],[89,3],[93,3],[97,3],[140,1],[142,3],[155,1],[157,2],[160,2],[163,3],[167,2],[170,1],[172,4],[202,6],[209,3],[217,1],[219,4],[224,1],[242,2],[255,2],[258,3],[267,1],[285,6],[296,3],[320,3],[324,3],[328,3],[337,1],[339,5],[345,1],[347,2],[350,2],[353,2],[365,1],[386,1],[388,4],[393,3],[402,3],[406,3],[410,6],[417,1],[419,5],[434,1],[455,6],[467,2]]},"1093":{"position":[[0,2],[3,4],[21,3],[30,2],[33,1],[35,3],[39,3],[43,3],[47,2],[50,1],[52,2],[55,2],[58,2],[61,3],[65,5],[71,3],[75,5],[81,3],[105,1],[107,2],[142,1],[144,1],[146,2],[149,3],[153,2],[156,1],[158,3],[410,4],[415,3],[431,2],[443,1],[445,2],[448,3],[452,5],[481,1],[483,4],[488,3],[492,6],[499,3],[517,4],[522,4],[527,3],[531,3],[562,1],[578,1],[584,1],[586,4],[591,3],[595,1],[597,3],[601,2],[604,3],[631,1],[633,4],[638,4],[643,3],[647,5],[653,4],[658,2],[661,1],[663,2],[666,5],[672,5],[678,2],[681,7],[708,1],[710,5],[728,3],[732,1],[734,2],[737,3],[741,4],[753,1],[755,2],[758,4],[763,3],[767,3],[771,4],[776,2],[779,3],[800,1],[802,4],[807,5],[813,3],[817,5],[823,3],[827,3],[831,3],[851,1],[864,3],[885,1],[899,1],[901,1],[903,3],[907,1],[909,3],[922,2],[929,1],[935,2],[938,3],[942,3],[946,2],[966,2],[976,1],[978,4],[983,4],[988,3],[992,2],[1026,1],[1028,4],[1048,1],[1050,4],[1055,4],[1067,2],[1088,1],[1116,2],[1136,1],[1138,4],[1143,3],[1147,3],[1160,2],[1167,1],[1169,3],[1173,3],[1177,5],[1183,3],[1196,2],[1203,1],[1205,1],[1207,2],[1214,5],[1220,2],[1252,4],[1257,2],[1283,3],[1293,1],[1295,2],[1298,2],[1320,1],[1334,1],[1336,2],[1339,2],[1342,3],[1346,3],[1355,1],[1357,3],[1361,5],[1367,2],[1370,6],[1377,2],[1385,3],[1389,4],[1403,1],[1405,3],[1409,2],[1412,1],[1414,3],[1418,2],[1428,1],[1439,1],[1441,2],[1444,2],[1447,4],[1471,2],[1479,1],[1481,3],[1489,1],[1491,3],[1495,4],[1500,4],[1505,5],[1511,4],[1525,1],[1542,1],[1560,1],[1562,3],[1566,3],[1570,2],[1585,2],[1588,5],[1594,1],[1596,3],[1600,3],[1604,3],[1608,3],[1621,2],[1628,1],[1634,1],[1641,1],[1654,3],[1658,1],[1660,6],[1682,1],[1684,3],[1688,2],[1691,2],[1703,1],[1714,1],[1728,5],[1738,1],[1745,1],[1747,2],[1750,2],[1776,1],[1797,2],[1805,2],[1811,1],[1826,1],[1828,4],[1833,1],[1835,2],[1838,3],[1842,5],[1848,2]]},"1095":{"position":[[6,1],[15,1],[21,1],[23,7],[31,6],[54,1],[56,3],[60,2],[79,1],[93,1],[116,2],[119,2],[122,4],[127,4],[154,3],[158,3],[181,1],[183,4],[188,5],[194,2],[197,3],[201,4],[212,1],[221,1],[234,1],[236,2],[257,1],[259,2],[276,1],[278,4],[283,2],[286,2],[289,4],[294,3],[322,1],[324,1],[326,4],[331,4],[336,4],[341,3],[345,6],[352,2],[382,1],[384,4],[389,2],[392,2],[395,5],[417,1],[460,3],[464,3],[468,4],[473,4],[478,1],[480,2],[501,1],[503,2],[506,1]]},"1097":{"position":[[16,1],[18,4],[32,1],[40,1],[42,5],[62,3],[66,2],[98,1],[113,6],[138,1],[140,2]]},"1099":{"position":[[29,1],[31,4],[36,2],[60,1],[103,1],[105,2],[205,1],[207,2],[308,2],[311,2],[314,2],[317,6],[343,1],[345,3],[360,3],[364,2],[391,1],[411,3],[415,3],[432,3],[447,1],[465,1],[467,5],[484,1],[493,1],[495,3],[523,3],[538,1],[555,1],[557,5],[574,1],[582,1],[584,3],[606,1],[608,3],[650,1],[665,1],[667,4],[672,1],[674,3],[678,2],[681,3],[685,4],[690,2],[777,3],[784,3],[788,2],[832,1],[842,2],[852,1],[854,3],[858,1],[860,2],[863,4],[868,2],[871,1],[873,3],[894,1],[907,1],[937,1],[965,1],[989,1],[991,3],[995,5],[1026,1],[1028,2],[1115,1],[1117,5],[1123,3],[1156,1],[1158,5],[1164,2],[1209,1],[1211,5],[1221,1],[1223,3],[1227,2],[1230,2],[1283,2],[1355,2],[1410,3],[1423,1],[1447,1],[1463,1],[1465,4],[1479,1],[1481,3],[1485,2],[1488,2],[1535,2],[1599,2],[1691,1],[1721,2],[1724,2],[1741,1],[1777,1],[1779,2],[1782,1],[1784,2],[1806,1],[1808,2],[1811,1],[1813,2],[1816,1],[1857,1],[1859,4],[1923,1],[1925,4],[1930,4],[1935,1],[1937,3],[1996,1]]},"1101":{"position":[[19,1],[35,1],[37,5],[43,3],[47,1],[49,2],[52,3],[56,3],[60,2],[90,1],[120,1],[135,1],[137,2],[149,3],[153,2],[160,1],[182,1],[184,1],[220,1],[222,4],[227,3],[250,1],[262,1],[264,3],[268,1],[270,2],[273,1],[285,1],[287,2],[303,1],[305,2],[308,1],[310,2],[352,1],[354,2],[357,4],[362,2],[365,2],[368,5],[374,3],[378,2],[399,1],[401,2],[404,5],[410,2],[413,4],[418,2],[421,1],[423,4],[428,4],[442,2],[454,1],[456,2],[459,4],[464,4],[469,3],[473,2],[476,2],[479,2],[482,2],[485,2],[488,2],[491,3],[495,5],[501,3],[520,1],[522,4],[540,1],[554,2],[557,3],[566,1],[568,4],[602,1],[604,4],[622,2],[642,1],[644,2],[647,2],[679,1],[681,3],[685,2],[688,2],[703,1],[727,1],[777,1],[779,1],[814,1],[816,1],[818,1],[842,2],[845,1],[847,1],[882,1],[884,1],[886,1],[952,1],[977,1],[1006,3],[1029,1],[1040,1],[1042,2],[1045,5],[1051,6],[1068,1],[1083,2],[1086,2],[1089,4],[1104,3],[1129,1],[1131,5],[1147,1],[1149,3],[1153,1],[1155,3],[1159,2],[1162,1],[1164,2],[1181,4],[1186,2],[1199,1],[1201,2],[1213,1],[1215,4],[1220,2],[1223,2],[1235,1],[1237,3],[1307,2],[1310,3],[1320,1],[1335,2],[1338,3],[1342,4],[1347,3],[1351,1],[1353,3],[1357,4],[1362,3],[1380,1],[1382,1],[1384,2],[1387,3],[1391,5],[1397,1],[1399,2],[1402,3],[1406,1],[1416,1],[1418,3],[1422,4],[1427,2]]},"1103":{"position":[[4,5],[33,1],[45,1],[47,5],[53,2],[56,3],[69,1],[75,1],[81,3],[85,5],[96,3],[100,4],[105,3],[109,3],[113,3]]},"1105":{"position":[[18,2],[36,1],[41,1],[56,2],[59,3],[63,2],[66,3],[70,5],[76,2],[92,1],[108,2],[111,3],[122,2],[125,3],[140,1],[142,2],[145,2],[155,1],[185,2],[205,1],[207,3],[211,2],[217,2],[220,5],[226,2],[247,1],[259,1],[261,4],[266,5],[285,2],[288,2],[291,4],[296,2]]},"1107":{"position":[[15,1],[17,2],[28,1],[43,2],[46,3],[74,1],[101,3],[115,1],[117,3],[148,2],[151,3],[171,1],[173,3],[181,1],[188,1],[201,1],[203,2],[206,4],[211,4],[216,4],[221,2],[224,3],[233,1],[235,2],[238,1],[247,1],[249,1],[274,1],[276,5],[282,2],[294,2],[297,2],[309,1],[311,3],[347,1],[356,1],[358,5],[364,2],[367,2],[370,2],[373,2],[376,4],[381,3],[385,3],[400,3],[404,4],[432,1],[447,3],[451,1],[466,1],[477,1],[479,5],[485,2],[488,2],[511,1],[513,3],[517,3],[533,3],[542,1],[552,2],[555,1],[557,3],[561,2],[581,1],[583,5],[589,3],[600,1],[602,6],[621,3],[662,1],[664,3],[674,1],[691,2],[700,1],[715,2],[718,2],[725,2],[758,1],[760,3],[769,1],[771,2],[774,3],[778,2],[796,2],[815,2],[833,1],[835,2],[847,2],[850,2],[874,2],[906,1],[908,2],[933,2],[953,1],[955,2],[958,3],[976,2],[979,5],[985,1],[1010,3],[1014,3],[1031,1],[1033,4],[1038,4],[1052,1],[1073,1],[1090,2]]},"1109":{"position":[[30,1],[41,2],[50,1],[58,1],[60,2],[63,2],[75,2],[84,1],[92,2],[95,2],[109,1],[117,2],[155,2],[158,3],[162,1],[164,3],[175,1],[177,4],[194,2],[197,3],[201,1],[203,2],[213,1],[215,6],[225,1],[227,4],[232,2],[235,1],[237,2],[250,1],[260,3],[264,2],[267,2],[297,3],[314,1],[319,1],[321,3],[325,2],[328,3],[332,5],[338,2],[341,2],[344,3],[352,2],[376,2],[388,1],[402,1],[404,4],[409,1],[411,3],[415,2],[418,3],[422,3],[426,1],[428,3],[448,1],[470,1],[481,2],[484,3],[488,3],[492,5],[498,3],[509,3],[513,5],[519,5],[525,2],[537,2],[559,1],[566,1],[591,2],[611,1],[621,1],[623,4],[635,1],[637,4],[642,2],[645,3],[687,1],[693,1],[709,1],[714,1],[728,1],[748,1],[750,5],[787,2],[790,1],[792,2],[795,3],[799,2],[811,4],[816,3],[820,2],[826,1],[831,1],[847,1],[856,4],[870,1],[872,3],[876,3],[880,1],[882,4],[887,3],[891,2],[894,3],[907,1],[912,2],[915,3],[919,5],[925,1],[927,2],[930,2],[951,2],[964,3],[980,1],[982,4],[987,3],[991,3],[998,1],[1000,4],[1005,3],[1009,3],[1013,1],[1015,2],[1018,2],[1030,1],[1059,1],[1061,4],[1066,3],[1088,1],[1090,3],[1104,2],[1112,1],[1118,1],[1129,1],[1131,2],[1134,2],[1137,2],[1140,3],[1144,3],[1148,3],[1152,3],[1156,3],[1160,1],[1178,1],[1183,1],[1185,3],[1201,1],[1203,3],[1207,6],[1218,1],[1225,2],[1234,2],[1237,3],[1241,2],[1244,2],[1256,1],[1276,1],[1278,1],[1280,5],[1286,2],[1289,2],[1296,1],[1298,1],[1300,3],[1316,1],[1318,3],[1325,1],[1327,2],[1330,4],[1335,2],[1338,3],[1351,1],[1353,3],[1357,2],[1360,4],[1370,2]]},"1111":{"position":[[9,3],[13,2],[26,2],[29,2],[32,2],[45,1],[47,1],[62,1],[64,2],[74,1],[83,1],[85,4],[99,1],[101,5],[107,4],[112,2],[124,1],[126,2],[246,2],[249,4],[271,1],[282,2],[285,2],[305,2],[308,2],[311,3],[350,4],[355,2],[358,2],[361,1],[385,1],[387,2],[390,3],[423,2],[435,2],[448,1],[459,2],[472,2],[485,1],[495,1],[502,1],[509,2],[512,3],[557,1],[559,3],[573,2],[576,3],[590,2],[640,2],[643,4],[648,4],[653,2],[656,3],[675,1],[677,4],[682,5],[688,7],[696,3],[700,3],[751,3],[755,1],[757,1],[759,4],[764,4],[769,3],[773,5],[779,2],[782,5],[788,2],[824,1],[826,4],[831,2],[834,5],[854,1],[856,4],[861,5],[884,1],[886,4],[891,2],[894,3],[898,2],[952,1],[954,3],[965,2],[968,3],[981,1],[1002,1],[1004,4],[1060,1],[1062,2],[1074,1],[1102,1],[1104,2],[1107,2],[1110,2],[1122,1],[1124,3],[1128,1],[1148,1],[1150,2],[1170,1],[1192,2],[1226,1],[1228,4],[1249,2],[1267,1],[1269,2],[1286,1],[1288,4],[1320,2],[1356,2],[1359,3],[1363,2],[1366,2],[1369,5],[1406,4],[1444,1],[1446,2],[1467,1],[1506,1],[1508,3],[1512,3],[1516,2],[1519,3],[1523,2],[1541,1],[1546,2],[1549,3],[1565,3],[1569,2],[1583,2],[1604,1],[1606,2],[1609,3],[1646,1],[1651,1],[1653,1],[1655,2],[1658,3],[1662,4],[1672,2],[1675,2],[1687,1],[1703,1],[1726,1],[1728,2],[1731,2],[1734,3],[1738,3],[1742,2],[1745,4],[1750,3],[1766,1],[1790,1],[1804,2],[1825,1],[1827,2],[1848,3],[1852,2],[1855,1],[1857,2],[1860,2],[1863,3],[1867,2],[1870,3],[1874,2],[1880,3],[1890,4],[1895,3],[1899,4],[1977,1],[1989,3],[1993,2]]},"1113":{"position":[[16,1],[41,2],[53,2],[64,1],[74,1],[76,3],[80,2],[87,1],[97,1],[99,1],[101,4],[106,3],[113,1],[115,1],[117,1],[119,3],[123,2],[136,1],[156,1],[158,2],[170,1],[172,2],[185,1],[187,2],[190,3],[194,2],[197,1],[199,3],[208,1],[214,2],[217,3],[225,2],[228,5],[234,2],[261,1],[271,1],[288,1],[295,2],[298,4],[312,2],[337,1],[339,4],[353,1],[355,3],[371,1],[381,1],[388,3],[396,1],[407,2],[422,3],[426,3],[443,2],[449,1],[451,5],[457,2],[491,1],[521,1],[523,4],[528,3],[532,2],[535,2],[538,4],[552,1],[554,4],[564,1],[583,1],[596,3],[600,1],[602,2],[605,2],[608,2],[611,2],[619,2],[642,1],[653,2],[656,2],[664,1],[666,2],[690,2],[693,1],[695,5],[701,2],[704,3]]},"1115":{"position":[[52,1],[68,1],[103,1],[110,2],[113,1],[122,1],[124,6],[143,2],[146,3],[150,5],[170,1],[172,3],[176,3],[180,2],[183,2],[186,2],[189,2],[192,3],[210,1],[221,1],[223,3],[227,2],[240,3],[251,1],[253,3],[257,3],[261,3],[283,2],[286,2],[289,3],[293,2],[296,3],[300,2],[303,5],[309,3],[320,1],[325,1],[327,5],[333,2],[336,1],[338,2],[355,1],[357,2],[360,2],[363,3],[367,1],[369,2],[372,2],[375,3],[394,1],[403,3],[407,2],[410,2],[427,1],[429,4],[434,2],[445,2],[481,4],[505,2],[508,2],[511,3],[524,5],[552,3],[556,3],[560,2],[572,1],[574,2],[577,2],[580,2],[583,4],[588,1],[590,2],[600,1],[602,4],[607,4],[612,1],[614,2],[672,1],[674,2],[701,4],[706,3],[710,3],[714,2],[721,1],[749,3],[753,3],[757,3],[761,3],[765,1],[780,2],[783,2],[786,4],[791,4],[796,2],[799,2],[802,1],[826,1],[828,5],[846,2],[849,2],[852,4],[857,2],[893,2],[896,5],[902,2],[905,2],[908,2],[911,2],[922,1],[933,1],[935,2],[938,4],[957,1],[959,4],[968,1],[979,2],[982,3],[986,2],[998,1],[1014,2],[1017,2],[1020,3],[1031,2],[1034,1],[1050,2],[1053,2],[1056,4],[1061,2],[1077,1],[1083,2],[1091,2],[1103,1],[1105,3],[1109,3],[1113,3],[1117,1],[1132,1],[1134,2],[1137,3],[1150,2],[1153,3],[1157,2],[1160,1],[1162,3],[1175,1],[1195,1],[1197,2],[1200,2]]},"1117":{"position":[[11,1],[17,2],[20,3],[24,2],[27,1],[29,2],[54,2],[66,1],[85,2],[88,5],[94,1],[121,2],[133,2],[136,3],[140,2],[143,6],[159,1],[161,3],[170,2],[186,1],[188,7],[200,2],[219,1],[221,5],[227,4],[235,1],[237,3],[241,2],[244,2],[256,1],[264,1],[266,4],[280,1],[282,5],[294,2],[297,1],[299,3],[303,5],[309,2],[318,1],[320,2],[337,3],[341,3],[345,5],[351,2],[363,1],[365,4],[370,1],[372,2],[382,1],[384,2],[387,2],[399,1],[418,1],[430,1],[439,3],[443,4],[461,2],[464,4],[469,3],[489,3],[505,1],[507,3],[515,1],[517,4],[522,1],[524,3],[528,2],[531,3],[535,2]]},"1120":{"position":[[0,1],[2,4],[16,2],[36,2],[39,1],[41,2],[51,1],[53,4],[58,4],[81,1],[87,2],[90,2],[93,1],[95,4],[100,1],[102,6],[128,4],[133,3],[137,1],[139,3],[155,2],[163,2],[166,2],[174,1],[176,4],[181,3],[189,1],[191,2],[194,3],[208,2],[221,2],[228,3],[232,4],[241,3],[250,1],[263,1],[265,2],[268,2],[271,4],[276,5],[282,3],[306,1],[308,5],[324,2],[332,2],[335,2],[338,1],[340,3],[347,1],[362,1],[364,4],[369,1],[371,2],[374,2],[377,3],[381,3],[385,2],[388,2]]},"1122":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1124":{"position":[[0,1],[2,3],[20,2],[39,3],[43,2],[73,2],[88,1],[90,4],[95,2],[98,5],[104,4],[109,4],[120,1],[138,1],[140,3],[156,1],[174,2],[177,5],[183,2],[203,1],[213,1],[215,4],[220,2],[230,2],[233,3],[264,1],[272,1],[292,1],[294,1],[296,3],[300,2],[306,1],[319,1],[321,2],[324,5],[330,2],[333,1],[335,3],[349,1],[351,3],[369,1],[382,1],[384,2],[387,3],[391,1],[393,3],[397,1],[399,3],[411,1],[419,1],[421,3],[425,2],[428,5],[451,1],[453,2],[467,1],[469,3],[473,3],[477,3],[481,1],[483,3],[487,3],[491,3],[495,3],[513,1],[515,4],[520,4],[525,3],[529,2],[532,3],[536,5],[554,1],[556,3],[573,1],[575,4],[580,2],[599,1],[601,2],[615,1],[617,4],[622,4],[645,4],[650,1]]},"1126":{"position":[[4,1],[6,4],[27,1],[29,2],[39,2],[42,2],[45,3],[54,1],[81,1],[108,1],[131,1],[133,4],[138,1],[140,2],[147,1],[154,3],[158,3],[173,3],[204,2],[218,1],[240,1],[249,1],[329,1],[331,4],[349,4],[354,2],[404,2],[431,1],[446,1],[448,3],[464,1],[466,2],[469,4],[481,1],[483,4],[488,2],[491,3],[502,1],[504,5],[527,1],[529,2],[541,1],[543,5],[560,1],[562,4],[567,2],[588,1],[599,2],[602,2],[605,6],[628,2],[631,3],[646,1],[648,4],[653,3],[657,3],[661,3],[665,3],[669,2],[677,1],[679,3],[683,1],[685,3],[689,3],[717,2],[720,2],[723,3],[727,3],[748,1],[750,2],[753,3],[757,2],[760,2],[763,3],[767,2],[777,1],[779,3],[795,1],[797,3],[801,2],[822,1],[828,1],[830,1],[832,3],[836,2],[863,1],[865,3],[881,1],[891,1],[893,4],[898,1],[900,2],[914,1],[925,3],[947,2],[950,3],[965,1],[971,2],[974,3],[992,4],[997,2],[1000,2],[1003,3],[1007,5],[1032,1],[1079,1],[1081,2],[1084,5],[1110,3],[1131,2],[1155,1],[1157,5],[1176,1],[1178,4],[1183,3],[1187,3],[1221,1],[1239,1],[1241,3],[1245,3],[1249,3],[1276,1],[1285,1],[1287,1],[1295,1],[1319,1],[1328,2],[1353,1],[1365,1],[1373,1],[1393,1],[1395,3],[1419,2],[1437,1],[1439,4],[1444,2],[1447,3],[1451,1],[1453,3],[1469,1],[1471,2],[1474,1],[1476,3],[1494,2],[1526,2],[1529,1],[1547,2],[1561,1],[1593,1],[1603,1],[1617,1],[1630,1],[1641,2],[1665,1],[1675,4],[1696,1],[1698,4],[1716,2],[1731,2],[1734,1],[1736,2],[1748,3],[1777,1],[1799,1],[1801,6],[1821,1],[1841,2],[1844,2],[1856,3],[1867,1],[1920,1],[1922,3],[1940,4],[1958,1],[2008,2],[2052,3],[2056,3],[2060,4],[2077,1],[2079,3],[2092,1],[2094,2],[2097,4],[2102,3],[2106,4],[2111,2],[2124,3],[2128,3],[2141,1],[2143,2],[2171,1],[2177,1],[2179,3],[2207,3],[2211,5],[2217,4],[2222,4],[2227,3],[2231,2],[2234,1],[2236,2],[2249,3],[2260,3],[2280,1],[2290,3],[2316,1],[2318,6],[2339,1],[2341,2],[2355,5],[2361,5],[2392,2],[2395,5],[2401,3],[2415,2],[2438,1],[2440,2],[2443,2],[2446,2],[2449,3],[2453,3],[2457,3],[2475,2],[2478,1],[2484,5],[2503,1],[2516,2],[2543,1],[2553,1],[2577,1],[2579,2],[2582,3],[2600,1],[2624,1],[2626,2],[2642,1],[2644,2],[2665,4],[2670,5],[2676,3]]},"1128":{"position":[[3,1],[27,1],[29,2],[41,1],[59,2],[73,1],[75,2],[91,1],[105,2],[157,4],[162,3],[189,2],[192,3],[200,1],[202,3],[206,2],[213,1],[237,1],[253,1],[290,1],[292,6],[303,1],[317,1],[319,4],[355,1],[357,3],[373,1],[391,1],[416,1],[429,1],[441,1],[443,2],[464,1],[466,4],[480,3],[495,1],[507,1],[517,2],[520,2],[535,1],[595,1],[597,3],[620,1],[622,2],[631,3],[665,1],[667,2],[687,1],[714,1],[732,1],[740,1],[758,3],[762,2],[781,1],[796,3],[800,3],[811,1],[813,4],[831,1],[833,4],[838,3],[842,2],[859,2],[895,1],[897,6],[918,1],[931,1],[942,1],[957,3],[961,3],[965,3],[969,5],[975,2],[985,1],[987,4],[1017,1],[1019,3],[1030,1],[1032,1],[1034,2],[1037,5],[1057,1],[1077,1],[1096,2],[1113,1],[1115,4],[1120,2],[1123,3],[1127,3],[1145,1],[1162,1],[1177,1],[1179,4],[1184,3],[1188,3],[1192,1],[1194,4],[1199,2],[1217,1],[1230,1],[1239,2],[1242,3],[1269,1],[1335,3],[1343,1],[1356,1],[1358,5],[1364,2],[1383,2],[1386,5],[1392,3],[1410,2],[1429,1],[1431,5],[1441,2],[1481,1],[1504,1],[1506,5],[1515,1],[1517,2],[1520,3],[1530,1],[1542,2],[1561,1],[1573,1],[1579,1],[1581,2],[1631,1],[1633,5],[1639,3],[1655,1],[1714,1],[1716,3],[1724,1],[1740,2],[1750,1],[1767,1],[1769,4],[1834,1],[1867,1],[1869,4],[1890,1],[1892,5],[1898,3],[1902,3],[1910,1],[1924,1],[1926,5],[1932,2],[1935,6],[1969,1],[1978,3]]},"1130":{"position":[[22,1],[35,1],[37,2],[40,3],[44,3],[70,2],[108,1],[127,2],[130,3],[144,2],[162,5],[168,3],[184,1],[201,1],[203,3],[213,2],[221,1],[223,3],[227,4],[232,6],[264,1],[266,2],[289,2],[292,5],[318,1],[320,3],[437,1],[453,1],[455,5],[468,1],[485,1],[487,3],[501,2],[504,5],[510,1],[512,3],[516,3],[527,2],[530,3],[540,1],[542,5],[548,5],[561,1],[563,3],[581,1],[593,2],[596,6],[603,3],[614,1],[637,1],[639,5],[645,5],[651,1],[653,2],[663,2],[666,3],[684,2],[687,3],[691,3],[710,1],[719,3],[727,1],[759,1],[782,1],[784,4],[796,3],[815,1],[817,2],[820,3],[824,3],[828,3],[832,3],[836,4],[841,3],[845,3],[849,3]]},"1132":{"position":[[15,1],[23,1],[25,2],[28,3],[32,3],[39,3],[59,2],[88,1],[103,3],[110,1],[123,2],[149,1],[151,3],[167,1],[184,2],[192,2],[214,1],[216,3],[239,1],[250,1],[252,5],[273,1],[275,5],[281,3],[342,2],[366,2],[369,2],[378,1],[476,1],[661,1],[663,2],[666,5],[695,1],[727,2],[730,5],[736,6],[743,1],[745,3],[763,1],[765,2],[768,2],[771,2],[774,3],[791,1],[793,5],[799,4],[804,3],[808,2],[827,1],[842,1],[847,1],[849,3],[853,3],[857,2],[905,1],[907,1],[909,2],[912,2],[915,2],[933,1],[935,4],[940,4],[945,2],[951,1],[983,1],[993,4],[998,2],[1021,1],[1032,1],[1034,5],[1040,2],[1071,3],[1087,2],[1090,2],[1093,3],[1097,1],[1099,4],[1111,1],[1113,4],[1118,2],[1121,3],[1125,5],[1131,3],[1135,3],[1139,5],[1160,1],[1162,3],[1166,1],[1168,2],[1171,5],[1177,1],[1179,6],[1195,1],[1197,1],[1199,2],[1202,4],[1207,5],[1251,3],[1255,4],[1276,1],[1278,2],[1302,3],[1306,3],[1326,1],[1337,3],[1341,3],[1345,5],[1373,1],[1384,1],[1394,2],[1410,2],[1413,3],[1424,1],[1426,4],[1431,2],[1451,1],[1478,1],[1480,2],[1483,1],[1485,2],[1488,2],[1504,1],[1512,2],[1535,1],[1537,2],[1547,2],[1576,2],[1579,1],[1592,1],[1594,1],[1596,2],[1599,5],[1621,3],[1639,1],[1641,2],[1644,2],[1647,4],[1652,1],[1654,2],[1670,2],[1687,2],[1690,3],[1697,1],[1705,1],[1707,3],[1711,3],[1715,5],[1721,5],[1727,2],[1730,4],[1740,1],[1742,4],[1754,1],[1773,1],[1775,1],[1777,5],[1783,3],[1787,1],[1815,1],[1817,4],[1835,1],[1837,2],[1840,4],[1845,3],[1849,5],[1855,5],[1861,3],[1883,1],[1885,4],[1890,2],[1904,2],[1907,5]]},"1134":{"position":[[13,1],[42,2],[45,5],[51,2],[103,1],[105,2],[123,1],[125,3],[151,1],[156,1],[158,2],[172,1],[174,3],[210,3],[225,1],[255,2],[275,2],[278,3],[282,3],[286,3],[302,1],[311,2],[314,3],[318,3],[322,2],[325,2],[352,2],[355,3],[359,3],[363,2],[373,3],[377,2],[391,3],[395,2],[398,2],[401,2],[411,1],[413,2],[416,3],[420,2],[423,2],[426,2],[429,3],[443,2],[446,2],[449,2],[456,3],[469,1],[471,4],[476,1],[478,1],[480,5],[486,3],[498,2],[501,3],[505,2],[508,1],[517,1],[519,3],[538,1],[540,2],[543,2],[570,1],[590,1],[592,2],[608,4],[613,3],[630,1],[643,1],[645,4],[650,2],[681,1],[683,4],[701,2],[711,2],[761,2],[775,2],[778,2],[781,3],[789,1],[791,2],[877,3],[886,1],[888,2]]},"1136":{"position":[[22,3],[26,3],[33,2],[36,3],[106,2],[109,1],[111,2],[114,2],[117,2],[133,1],[152,3],[156,3],[160,1],[167,2],[203,1],[226,1],[228,2],[231,2],[237,1],[257,2],[260,3],[264,1],[266,2],[269,3],[282,1],[284,2],[294,2],[307,1],[309,4],[326,1],[328,2],[338,2],[347,1],[349,3],[353,2],[370,1],[385,1],[413,2],[430,1],[456,1],[461,1],[463,2],[466,4],[471,4],[509,1],[511,2],[528,3],[532,2],[553,1],[561,1],[572,2],[575,3],[586,2],[603,1],[625,1],[627,1],[629,3],[633,2],[658,1],[674,3],[678,3],[704,1],[723,3],[727,2]]},"1139":{"position":[[56,1],[58,3],[76,1],[78,2],[81,3],[85,3],[89,2],[92,1],[94,2],[97,3],[101,2],[111,1],[113,2],[126,2],[129,4],[134,2],[137,4],[156,1],[171,4],[176,3],[180,2],[183,2],[186,3],[190,2],[193,4],[198,3],[206,3],[230,1],[232,3],[236,3],[240,2],[243,2],[246,2],[249,4],[263,2],[266,2],[269,3],[273,3],[277,3],[281,2]]},"1141":{"position":[[0,2],[3,4],[8,2],[25,1],[42,1],[44,4],[71,1],[73,3],[108,1],[110,3],[146,2],[149,4],[154,3],[177,3],[194,2],[197,3],[204,1],[231,1],[254,2],[257,2],[260,1],[273,1],[295,1],[308,1],[310,2],[340,1],[342,3],[362,1],[364,1],[394,1],[396,2],[409,1],[411,3],[422,1],[434,1],[436,6],[443,2],[458,1],[472,1],[474,1],[492,1],[494,2],[519,3],[523,2],[539,5],[545,2],[560,1],[562,5],[575,1],[577,3],[581,2],[598,4],[603,3],[617,2],[620,2],[623,3],[642,3],[646,2],[649,2],[652,3],[683,1],[709,2],[727,2],[730,1],[732,3],[736,4],[745,4],[750,3],[754,4],[786,3],[802,1],[804,5],[825,1],[827,4],[832,2],[835,3],[877,4],[882,3],[892,1],[894,4],[899,3],[903,2]]},"1143":{"position":[[13,2],[36,1],[60,1],[62,3],[66,3],[70,2],[73,1],[75,1],[77,2],[83,1],[111,1],[130,1],[132,4],[137,2],[155,1],[157,2],[160,3],[175,1],[183,1],[194,1],[196,2],[199,2],[202,2],[205,4],[210,3],[224,2],[245,1],[256,1],[258,3],[275,2],[278,2],[281,3],[285,4],[304,1],[306,2],[309,2],[312,4],[317,3],[321,2],[328,3],[332,2],[335,5],[357,2],[360,3],[364,2],[367,2],[384,1],[386,3],[390,5],[396,3],[400,4],[414,1],[416,3],[420,3],[424,2],[437,2],[456,1],[458,2],[461,2],[464,2],[467,2],[481,2],[484,2],[503,2],[519,2],[522,3],[526,4],[531,4],[536,4],[541,4],[591,1],[605,5],[611,1],[613,2],[616,2],[619,3],[623,5],[633,3],[647,4],[659,2],[671,3],[675,2],[706,2],[709,2],[712,4],[717,4],[722,2],[737,1],[739,1],[741,1],[755,1],[760,3],[764,4],[769,3],[773,2],[776,2],[779,2],[782,2],[785,3],[789,2],[797,1],[799,2],[820,1],[822,4],[827,3],[831,4],[836,3],[849,1],[851,3],[855,1],[857,2],[873,1],[881,2],[892,1],[894,4],[899,2],[915,1],[917,4],[922,2],[925,3],[929,4],[934,3],[952,1],[970,3],[974,2],[977,1],[979,4],[987,4],[1005,1],[1007,4],[1012,4],[1017,1],[1019,1],[1021,3],[1051,1],[1066,1],[1068,3],[1072,4],[1077,2],[1080,6],[1101,1],[1103,3],[1107,2],[1110,5],[1116,1]]},"1145":{"position":[[28,2],[31,2],[34,1],[36,3],[40,3],[44,2],[47,3],[51,3],[55,2],[58,1],[60,3],[64,1],[66,3],[70,3],[74,2],[101,1],[103,1],[105,3],[116,2],[119,1],[121,1],[123,3],[154,1],[170,1],[172,2],[175,3],[182,3],[186,3],[196,3],[224,1],[226,3],[230,2],[233,2],[270,1],[294,2],[297,2],[337,2],[340,2],[349,2],[361,2],[364,3],[379,1],[381,4],[386,2],[389,2],[392,2],[409,1],[426,1],[436,1],[467,1],[469,4],[474,1],[476,2],[489,1],[491,2],[494,3],[498,3],[516,1],[532,1],[574,1],[583,1],[585,1],[587,3],[603,1],[605,2],[622,1],[630,1],[637,1],[639,2],[642,3],[649,1],[657,2],[671,3],[675,2],[678,2],[681,1],[694,1],[696,2],[706,2],[709,3],[713,2],[716,2],[724,4],[743,1],[769,1],[771,2],[781,1],[783,2],[800,1],[810,2],[820,2],[837,1],[839,2],[842,4],[847,2],[872,4],[877,2],[880,1],[882,2],[895,2],[898,3],[917,4],[922,3],[941,1],[943,2],[946,2],[949,3],[965,1],[984,1],[998,1],[1000,2],[1013,1],[1015,2],[1018,4],[1036,1],[1061,1],[1063,4],[1073,1],[1087,2],[1104,1],[1120,1],[1122,5],[1128,4],[1148,2],[1151,3],[1169,1],[1177,2],[1199,1],[1201,2],[1204,3],[1208,3],[1212,4],[1217,2],[1234,1],[1236,3],[1253,1],[1255,3],[1259,3],[1263,2],[1275,1],[1304,1],[1312,2],[1315,3],[1319,2],[1322,3],[1326,3],[1330,4],[1335,4],[1340,4],[1351,1],[1360,1],[1362,2],[1365,1],[1367,3],[1381,3],[1385,4],[1399,1],[1414,1],[1416,2],[1419,4],[1424,1],[1426,3],[1437,1],[1439,2],[1452,1],[1454,6],[1461,2],[1464,3],[1483,1],[1485,5],[1509,1],[1511,2],[1526,1],[1539,1],[1541,4],[1561,2],[1587,1],[1589,2],[1599,1],[1601,4],[1606,2],[1616,1],[1649,1],[1651,4],[1662,1],[1664,4],[1669,4],[1674,1],[1682,2],[1725,1],[1727,4],[1744,1],[1746,2],[1764,2],[1794,1],[1822,2],[1837,1],[1839,3],[1848,1],[1859,4],[1864,1],[1866,4],[1871,2],[1894,3],[1898,2],[1901,3],[1905,2],[1923,1],[1925,3],[1929,3],[1944,1],[1964,2],[1987,1],[1989,2],[1992,2],[1995,2],[1998,3],[2013,1],[2015,4],[2020,1],[2034,1],[2036,3],[2040,4],[2045,2],[2060,1],[2062,2],[2065,3],[2080,1],[2082,3],[2086,3],[2090,3],[2102,1],[2107,1],[2133,1],[2135,4],[2173,3],[2177,5],[2207,1],[2209,3],[2213,1],[2215,2],[2218,6],[2236,1],[2247,2],[2255,1],[2257,2],[2270,3],[2279,3],[2296,1],[2298,4],[2303,5],[2309,3],[2330,1],[2332,4],[2356,2],[2382,2],[2385,4],[2390,3],[2394,3],[2413,1],[2415,4],[2420,3],[2424,4],[2429,3],[2433,3],[2445,1],[2447,3],[2472,1],[2474,4],[2479,2],[2482,3],[2486,4],[2506,1],[2508,4],[2513,3],[2531,1],[2533,3],[2537,4],[2542,3],[2567,1],[2569,6],[2576,2],[2585,3],[2589,3],[2593,3],[2597,3]]},"1147":{"position":[[10,3],[28,1],[30,3],[34,3],[38,2],[41,4],[46,4],[51,4],[56,3],[60,3],[64,2],[89,1],[91,5],[118,1],[120,5],[126,2],[129,3],[133,2],[142,1],[144,3],[148,5],[154,4],[159,5],[177,2],[180,2],[183,2],[200,1],[215,1],[217,2],[231,1],[233,3],[237,2],[240,3],[244,1],[246,2],[258,1],[281,1],[283,2],[312,2],[318,1],[320,2],[333,2],[336,3],[340,3],[344,3],[359,1],[361,4],[384,2],[387,3],[391,3],[417,1],[419,3],[423,5],[429,3],[439,2],[442,4],[447,1],[463,1],[465,2],[476,1],[492,1],[508,4],[513,5],[532,2],[535,3],[539,2],[542,3],[557,1],[559,2],[562,1],[573,2],[585,3],[589,3],[613,1],[615,2],[626,1],[651,1],[680,1],[682,1],[684,1],[686,2],[689,2],[705,1],[707,2],[721,4],[726,2],[734,1],[736,1],[765,2],[777,2],[789,2],[796,5],[802,3],[806,1],[808,2],[811,3],[815,4],[820,2],[833,2],[836,2],[839,4],[844,3],[848,1],[850,3],[854,5],[860,4],[865,2],[890,1],[907,1],[909,5],[915,3],[919,2],[939,2],[942,4],[968,2],[981,2],[992,1],[1006,2],[1028,1],[1030,4],[1040,2],[1043,2],[1064,2],[1067,2],[1070,2],[1073,2],[1076,2],[1095,3],[1099,3],[1103,5],[1109,5],[1115,2],[1118,3],[1125,3],[1129,2],[1132,3],[1136,5],[1142,1],[1144,3],[1161,1],[1172,1],[1174,4],[1192,2],[1195,2],[1205,1],[1207,3],[1216,1],[1218,3],[1222,4],[1227,4],[1232,4],[1237,1],[1239,1],[1241,3]]},"1149":{"position":[[17,1],[19,3],[23,5],[29,2],[47,2],[50,3],[54,2],[57,3],[61,4],[71,3],[75,5],[81,1],[83,3],[87,2],[90,2],[93,3],[97,3],[101,4],[106,6],[113,2],[116,3],[120,3],[124,2],[127,3],[135,2],[138,3],[142,4],[147,1],[149,3],[168,1],[170,2],[173,5],[179,2],[182,4],[187,2],[204,1],[221,1],[243,1],[245,5],[251,1],[253,4],[258,2],[261,2],[264,2],[272,1],[278,2],[288,1],[290,4],[295,3],[307,1],[309,6],[329,1],[331,2],[360,1],[372,1],[374,1],[376,5],[382,4],[387,3],[391,1],[401,3],[405,2],[412,2],[415,2],[418,3],[435,1],[437,4],[450,1],[452,2],[455,3],[459,4],[471,1],[473,4],[478,2],[481,2],[484,1],[486,3],[497,1],[513,2],[516,1],[518,1],[520,2],[523,2],[526,2],[547,4],[552,4],[557,2],[560,1],[577,1],[579,2],[582,2],[585,2],[595,1],[611,4],[616,4],[621,2],[624,3],[639,2],[642,2],[645,3],[649,2],[652,3],[672,1],[674,2],[685,1],[696,2],[699,4],[726,1],[728,5],[734,2],[749,1],[751,5],[757,2]]},"1151":{"position":[[0,2],[3,3],[14,1],[21,1],[23,3],[27,4],[49,1],[51,4],[56,2],[59,3],[63,2],[66,2],[69,1],[71,3],[75,5],[81,5],[87,2],[90,3],[94,5],[100,4],[105,2],[108,4],[113,3],[131,1],[148,1],[150,2],[180,2],[183,4],[188,3],[192,1],[194,4],[199,3],[223,2],[226,4],[231,5],[237,2],[240,1],[255,1],[257,2],[278,1],[306,2],[309,5],[333,1],[363,1],[393,3],[413,1],[415,5],[421,2],[445,1],[447,2],[474,1],[500,1],[502,4],[507,2],[510,5],[516,3],[532,1],[545,1],[560,1],[576,1],[605,1],[607,2],[621,1],[623,2],[639,1],[641,2],[658,1],[660,2],[690,1],[703,1],[718,1],[734,1],[750,1],[752,2],[771,1],[773,2],[786,1],[799,1],[809,1],[822,1],[829,3],[842,1],[844,2],[858,1],[860,2],[871,1],[873,2],[887,1],[889,2],[898,1],[912,1],[925,1],[935,1],[948,1],[955,1],[957,1],[959,2],[962,1],[964,3],[984,1],[986,2],[989,2],[992,2],[1003,1],[1005,3],[1016,1],[1045,1],[1047,4],[1052,3],[1056,2],[1059,3],[1063,3],[1083,2],[1086,3],[1104,1],[1106,2],[1109,3],[1133,1],[1135,4],[1140,2],[1143,2],[1146,2],[1149,5],[1162,1],[1178,4],[1183,4],[1188,2],[1191,2],[1206,1],[1208,2],[1211,3],[1215,5],[1221,6],[1241,1],[1255,1],[1257,4],[1262,3],[1266,2],[1275,1],[1289,1],[1309,1],[1311,3],[1315,2],[1318,3],[1322,3],[1341,2],[1358,4],[1363,5],[1369,4],[1386,1],[1395,1],[1415,2],[1418,4],[1423,3],[1427,3],[1431,2],[1434,3],[1445,1],[1471,1],[1473,3],[1477,5],[1490,1],[1505,1],[1507,5],[1513,2],[1516,1],[1518,2],[1532,3],[1536,2],[1539,5],[1570,1],[1572,3],[1576,1],[1578,2],[1581,3],[1603,1],[1605,2],[1608,2],[1625,1],[1627,2],[1630,1],[1632,3],[1636,2],[1646,1],[1648,3],[1652,3],[1656,3],[1682,1],[1705,1],[1707,4],[1712,3],[1716,2],[1719,3],[1723,3],[1736,2],[1739,2],[1742,4],[1747,2],[1750,5],[1765,1],[1767,3],[1786,1],[1788,2],[1791,4],[1796,4],[1815,2],[1818,3],[1829,1],[1831,3],[1856,1],[1871,2],[1874,3],[1878,2],[1881,3],[1885,5],[1891,3],[1895,3],[1903,1],[1922,3],[1926,4],[1931,2],[1941,1],[1943,1],[1945,2],[1948,3],[1958,1],[1976,2],[2005,2],[2008,3],[2012,5],[2018,4],[2023,2],[2026,1],[2028,3],[2032,2]]},"1153":{"position":[[14,1],[38,1],[56,1],[67,2],[81,1],[83,4],[88,2],[101,2],[121,1],[148,1],[173,3],[177,2],[184,2],[213,2],[230,1],[247,2],[266,1],[301,1],[303,4],[328,1],[362,4],[383,1],[397,2],[400,1],[402,3],[406,2],[429,4],[442,1],[457,3],[493,1],[495,3],[499,2],[502,3],[506,1],[513,1],[544,1],[590,2],[593,4],[598,1]]},"1155":{"position":[[0,2],[3,1],[5,3],[9,3]]},"1157":{"position":[[14,1],[16,4],[26,3],[30,1],[32,4],[57,1],[85,1],[87,2],[90,2],[98,2],[101,3],[105,4],[126,1],[128,2],[131,1],[133,4],[138,3],[165,1],[167,2],[170,4],[175,2],[178,1],[194,1],[196,4],[201,2],[204,5],[270,1],[272,4],[300,1],[340,1],[360,1],[372,3],[386,2],[403,2],[423,2],[450,2],[453,2],[456,2],[459,2],[480,2],[483,3],[487,4],[506,1],[530,3],[534,2],[544,2],[565,1],[567,3]]},"1159":{"position":[[35,1],[46,1],[48,1],[50,3],[54,5],[71,2],[74,3],[78,2],[81,5],[87,3],[141,1],[143,3],[147,5],[153,3],[157,3],[161,3],[165,2],[168,3],[172,4],[189,1],[212,1],[224,1],[243,1],[245,4],[250,3],[254,3],[258,3],[262,3],[266,2],[269,1],[276,1],[278,2],[303,1],[305,3],[309,3],[338,1],[340,5],[346,4],[368,3],[372,2],[389,1],[391,3],[395,4],[400,3],[404,2],[420,1],[447,1],[449,5],[455,1],[457,4],[472,1],[498,1],[520,1],[537,1],[539,4],[544,1],[546,6],[553,3],[564,1],[566,5],[572,4],[577,3],[589,1],[604,1],[606,7],[623,3],[627,5],[633,3],[644,1],[646,4],[651,2],[654,2],[657,3],[661,5],[667,2],[670,2],[673,2],[684,1],[686,2],[689,3],[693,1],[695,3],[699,5],[705,2],[722,1],[724,7],[732,2],[752,2],[768,1],[787,1],[789,6],[809,1],[817,2],[820,4],[846,3],[859,2],[862,6],[869,5],[875,1],[901,1],[903,5],[923,1],[925,3],[929,3],[950,1],[952,3],[956,3],[960,3],[968,4],[973,3],[977,2],[980,3],[984,3],[1002,2],[1005,3],[1009,3],[1013,4],[1018,3],[1037,3],[1041,5],[1047,3],[1051,4],[1056,3],[1060,2],[1077,1],[1104,5],[1110,2],[1120,1],[1122,2],[1125,4],[1155,3],[1174,1],[1176,3],[1180,2],[1183,2],[1197,1],[1199,1],[1201,1],[1203,3],[1207,1],[1209,4],[1232,1],[1262,1],[1264,2],[1281,1],[1283,5],[1289,5],[1295,3],[1299,2],[1325,2],[1328,3],[1348,1],[1370,2],[1395,1],[1397,4],[1402,1],[1404,2],[1430,1],[1438,2],[1441,3],[1448,1],[1455,1],[1464,1],[1466,3],[1470,1],[1485,1],[1487,2],[1490,2],[1503,1],[1505,4],[1510,2],[1547,2],[1550,2],[1568,3],[1572,5],[1578,1],[1580,2],[1583,4],[1588,2],[1591,2],[1594,4],[1627,1],[1629,4],[1661,1],[1675,1],[1677,3],[1681,1],[1683,3],[1705,1],[1717,1],[1734,2],[1737,2],[1740,5],[1754,2],[1757,2],[1784,1],[1786,6],[1793,2],[1819,1],[1821,3],[1862,2],[1865,2],[1868,3],[1872,5],[1904,3],[1908,2],[1911,3],[1915,5],[1921,6],[1951,1],[1971,3],[1989,1],[1991,4]]},"1162":{"position":[[16,1],[23,1],[34,2],[37,4],[51,1],[68,1],[70,1],[122,1],[148,3],[161,1],[182,1],[184,1],[186,2],[202,1],[219,1],[221,2],[224,2],[380,5],[390,1],[392,2],[395,3],[399,2],[402,3]]},"1164":{"position":[[14,1],[28,1],[30,4],[35,4],[40,6],[47,2],[50,5],[81,1],[92,2],[111,1],[128,2],[131,3],[151,1],[157,2],[160,3],[164,5],[170,4],[192,1],[194,1],[208,1],[257,1],[259,4],[264,3],[439,1],[441,2],[455,3],[464,1],[495,1],[497,6],[526,1],[550,1],[552,3],[556,2],[559,3],[563,2],[585,1],[587,5]]},"1167":{"position":[[0,3],[43,2],[58,1],[88,3],[92,3],[96,2],[103,2],[142,1],[160,1],[162,3],[188,1],[199,1],[233,1],[294,1],[309,1],[317,1],[337,1],[423,1],[445,1],[483,1],[485,3],[537,1],[539,1],[554,1],[556,5],[562,3],[616,1],[628,1],[634,1],[636,1],[655,2],[701,3],[725,1],[727,5],[733,4],[745,1],[763,1],[765,2],[772,2],[855,1],[937,1],[939,2],[953,1],[955,3],[967,1],[986,2],[989,2],[992,3],[1000,1],[1019,1],[1021,2],[1028,1],[1034,1],[1068,1],[1102,1],[1153,1],[1155,4],[1160,2],[1174,1],[1204,1],[1241,1],[1243,3],[1262,1],[1264,2],[1286,1],[1303,3]]},"1170":{"position":[[0,3],[24,1],[50,1],[52,2],[55,2],[58,2],[61,1],[63,2],[66,2],[69,3],[73,2],[76,3],[80,3],[84,2],[87,2],[90,2],[107,3],[129,1],[131,4],[136,1],[151,1],[153,2],[156,2],[169,1],[171,4],[176,2],[213,2],[216,2],[234,3],[238,5],[244,1],[246,2],[249,4],[254,3],[258,5],[284,1],[286,3],[303,2],[306,4]]},"1172":{"position":[[19,1],[66,1],[95,1],[128,1],[130,5],[149,1],[151,2],[158,1],[160,3],[164,2],[167,3],[203,1],[226,1],[228,2],[231,3],[235,5],[241,3],[266,1]]},"1174":{"position":[[0,3],[24,1],[51,2],[59,1],[61,2],[74,1],[76,2],[79,4],[84,5],[107,1],[109,2],[112,3],[116,3],[120,1],[122,3],[126,2],[129,2]]},"1176":{"position":[[0,3],[4,1],[30,1],[73,1],[75,5],[81,2],[84,2],[87,3],[91,1],[110,1],[112,2],[123,1],[125,5],[131,1],[133,3],[137,3],[141,2],[170,1],[172,1],[194,1],[196,3],[200,4],[205,2],[226,1],[228,2],[231,3],[235,5]]},"1178":{"position":[[9,2],[12,2],[15,3],[28,2],[53,1],[102,1],[114,1],[116,4],[121,6],[151,1],[175,2],[178,4],[186,1],[193,3],[197,3],[223,1],[225,6],[232,2],[269,1],[277,1],[279,4],[284,4],[289,2],[292,5],[298,2],[301,2],[356,2],[377,1],[387,2],[417,1],[419,4],[446,1],[463,1],[465,5],[481,4],[513,1],[515,3],[554,1],[556,5],[584,2],[594,1],[596,4],[613,1],[615,2],[623,3]]},"1181":{"position":[[10,5],[26,1],[28,4],[46,1],[48,5]]},"1183":{"position":[[25,1],[45,5],[51,3],[55,5],[94,1],[111,1],[113,3],[117,3]]},"1185":{"position":[[9,2],[29,4],[34,1],[36,2],[51,2],[57,2],[72,1],[74,5],[120,1],[142,1],[194,1],[224,1],[256,1],[275,1],[290,1],[302,2],[328,1],[330,3],[334,3],[338,2],[355,3],[371,1],[419,1],[421,4],[430,1],[445,1],[469,1],[485,1],[487,5],[528,1],[535,1],[642,2],[703,1],[721,1],[723,2],[745,1],[747,4]]},"1187":{"position":[[3,2],[16,1],[41,1],[43,2],[46,1],[48,5],[74,1],[99,2],[102,6],[109,3],[120,1],[134,1],[136,4],[147,1],[158,3],[183,2],[226,1],[228,3],[270,1],[307,1],[313,1],[315,5],[324,1],[339,1],[369,2],[372,1],[408,1],[423,1],[425,2],[428,2],[431,5],[456,1],[476,1],[505,1],[517,1],[519,5]]},"1189":{"position":[[23,1],[25,1],[27,5],[59,1],[66,1],[68,2],[71,5],[105,1],[121,1],[123,3],[127,6],[134,4],[139,2],[142,3],[146,2],[256,1],[258,3],[262,2],[270,1],[272,2]]},"1191":{"position":[[0,2],[23,4],[42,1],[44,5],[50,2],[53,3],[57,3],[61,3],[65,2],[68,4],[73,5],[79,3],[88,5],[99,2],[102,5],[108,4],[113,3]]},"1195":{"position":[[23,1],[25,2],[42,1],[44,1],[46,2],[81,1],[89,5],[95,2],[98,1],[100,3],[114,1],[127,1],[129,3],[133,4],[161,1],[163,2],[166,4],[171,3],[175,3],[179,3],[193,2],[205,2],[218,3],[233,2],[240,1],[252,2],[255,2],[266,3],[286,1],[288,6],[295,4],[300,3],[304,3],[308,4],[320,2],[323,4],[351,1],[353,2],[356,4],[361,1],[363,2],[366,3],[370,4],[402,1],[424,1],[426,2],[429,3],[433,3],[437,3],[441,3],[470,1],[486,2],[489,3],[493,3],[497,3],[517,1],[549,1],[551,4],[556,2],[559,4],[583,1],[591,1],[601,1],[603,1],[605,2],[608,3],[612,3],[616,4]]},"1197":{"position":[[0,3],[14,2],[17,3],[26,2],[29,2],[32,2],[35,3],[53,1],[55,4],[79,2],[108,1],[110,6],[126,2],[152,1],[154,5],[171,1],[173,2],[176,2],[179,2],[182,3],[186,2],[189,1],[191,2],[194,3],[198,3],[202,3],[206,2],[239,1],[241,4],[246,3],[250,1],[252,2],[260,1],[270,1],[272,3],[285,2],[293,3],[297,2],[327,1],[329,2],[332,1],[334,4],[362,1],[364,2],[367,2],[370,3],[374,2],[391,4],[396,3],[404,2],[407,5],[413,2],[416,2],[419,3],[423,2],[426,2],[452,1],[474,1],[476,2],[479,3]]},"1199":{"position":[[0,2],[3,3],[21,2],[47,2],[50,2],[62,2],[65,4],[84,1],[100,1],[102,4],[107,7],[115,3],[119,4],[124,4],[152,3],[170,1],[215,2],[228,5],[234,3],[238,3],[242,2],[245,4],[259,1],[279,3],[311,1],[327,4],[346,3],[350,7],[358,2],[361,1],[363,2],[380,1],[382,3],[386,4],[414,1],[416,5],[427,1],[432,3],[436,3],[440,3],[444,5],[450,2],[462,3],[466,3],[470,5]]},"1201":{"position":[[14,4],[36,4],[41,2],[44,3],[48,3],[52,3],[56,2],[59,3],[63,6],[101,1],[103,5],[109,2],[142,1],[144,2],[147,2],[160,2],[174,2],[177,4],[182,2],[185,2],[211,4],[216,5],[239,1],[241,3],[249,3],[253,2],[279,1],[281,4],[286,3],[290,3],[294,3],[298,2],[301,1],[303,1],[305,2],[338,1],[359,1],[361,3],[365,3],[369,2],[372,2],[375,3],[379,2],[382,3],[386,3],[390,4],[395,3],[399,2],[419,2],[422,1],[424,6],[431,4]]},"1203":{"position":[[0,2],[3,2],[6,4],[11,3],[15,1],[17,5],[23,1],[25,3],[29,1],[43,2],[46,5],[52,3],[56,3],[60,2],[63,3],[67,3],[71,1],[73,1],[80,1],[82,2],[85,2],[88,4],[93,3],[97,2],[100,3],[104,4],[109,3],[122,1],[143,1],[145,5],[174,1],[176,2],[179,2],[182,6],[189,6],[198,1],[204,3],[208,2],[211,2],[217,1],[229,6]]},"1205":{"position":[[0,3],[4,1],[6,2],[16,1],[18,3],[22,5],[42,1],[44,2],[56,3],[60,3],[70,1],[83,1],[92,1],[94,3],[98,5],[127,1],[129,2],[139,4],[144,2],[147,3],[151,5],[157,2],[166,1],[179,1],[181,2],[184,5],[201,1],[215,2],[218,2]]},"1208":{"position":[[0,1],[9,1],[15,1],[33,1],[35,2],[57,1],[59,2],[62,3],[66,6],[108,1],[110,3],[123,3],[127,1],[129,2],[147,1],[149,2],[173,4],[178,2],[181,3],[185,4],[225,1],[227,3],[231,2],[234,5],[240,1],[242,1],[244,7],[252,1],[254,2],[276,1],[278,6],[285,1],[287,2],[290,3],[294,6]]},"1210":{"position":[[0,2],[3,3],[7,3],[32,2],[35,3],[39,2],[52,1],[63,2],[83,1],[85,2],[88,3],[92,5],[126,2],[129,3],[133,2],[136,2],[139,3],[143,4],[148,3],[160,4],[165,4],[170,3],[174,5]]},"1212":{"position":[[23,1],[25,5],[31,2],[51,1],[81,2],[96,1],[98,5],[104,2],[107,1],[109,3],[113,2],[116,2],[119,7],[127,3],[131,1],[133,2],[136,2],[139,1],[153,3],[167,2],[170,5],[176,3],[180,1],[182,2],[185,3],[189,1],[191,3],[205,2],[222,2],[225,3],[229,3],[233,3],[237,3],[241,2],[244,5],[250,2],[253,7],[261,2],[304,5],[310,3],[314,3],[318,2],[321,2],[324,2],[327,5],[333,6]]},"1214":{"position":[[0,3],[16,1],[18,4],[23,5],[29,3],[33,3],[65,2],[78,2],[81,4],[97,3],[128,3],[132,2],[149,2],[152,2],[155,1],[157,2],[160,4],[165,2],[168,1],[170,3],[194,1],[215,3],[219,3],[223,3],[227,3]]},"1218":{"position":[[23,1],[51,2],[54,3],[58,2],[61,5],[278,1],[290,2],[297,1],[323,1],[339,1],[391,1],[420,1],[449,1],[460,1],[465,1],[471,1],[502,1],[504,3],[508,4],[536,1],[551,1],[556,1],[590,1],[592,2],[595,4],[600,3],[604,2],[607,1],[609,1],[638,1],[640,2],[643,1],[645,4],[681,1],[683,4]]},"1221":{"position":[[0,3],[42,1],[67,1],[69,2],[86,1],[88,4],[93,5],[106,2],[109,1],[111,2],[124,4],[129,2],[132,2],[135,4],[140,3],[144,3],[148,5],[154,3],[181,1],[197,2],[200,3],[204,2],[207,6],[214,2],[217,5],[223,3],[254,2],[277,1],[279,2],[282,3],[286,2],[289,3],[293,3],[313,2],[345,1],[347,2],[350,2],[353,4],[358,4],[363,2],[366,3],[370,2],[383,2],[402,1],[421,1],[423,5],[429,2],[432,4],[437,3],[441,3],[445,2],[448,6],[471,1],[473,2],[476,3],[480,2],[483,2],[486,2],[489,3],[493,4],[498,2],[501,3],[505,2],[520,1],[522,4],[527,3],[531,4],[536,4],[541,4],[546,2],[549,4],[566,1],[568,5],[584,2],[587,3],[591,4],[596,3],[635,1],[637,2],[657,1],[681,1],[683,4],[688,4],[693,2],[696,3],[700,3],[704,3],[708,2]]},"1223":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1225":{"position":[[14,1],[34,1],[36,1],[43,1],[45,2],[54,2],[57,3],[61,3],[79,1],[81,4],[113,1],[115,3],[135,1],[137,5],[149,2],[161,1],[163,3],[167,2],[170,3],[174,4],[199,1],[201,2],[214,2],[217,3],[242,1],[244,3],[248,4],[253,3],[257,4],[262,2],[265,2],[268,3],[272,3],[276,2],[346,1],[369,1],[371,3],[402,1],[404,2],[407,1],[432,1],[434,5],[446,2],[449,2],[466,1],[500,1],[502,2],[509,5],[515,2],[518,3],[522,2],[534,1],[543,1],[545,4],[550,3],[554,2],[557,3],[561,2],[564,4],[593,1],[602,1],[611,3],[640,1],[642,2]]},"1227":{"position":[[45,1],[63,1],[65,1],[67,2],[70,3],[74,3],[78,1],[80,4],[120,1],[122,2],[129,1],[131,3],[135,2],[138,5],[144,2],[147,4],[152,5],[158,3],[162,4],[167,3],[171,3],[175,4],[180,3],[184,1],[186,3],[195,1],[197,2],[200,5],[206,2],[209,3],[213,4],[234,1],[236,3],[240,2],[243,3],[247,2],[269,1],[305,1],[307,2],[310,4],[319,1],[359,2],[371,1],[373,2],[379,1],[385,5],[391,4],[425,1],[427,2],[430,3],[450,1],[452,1],[454,3],[458,2],[461,4],[466,4],[471,3],[491,2],[494,2],[497,2],[500,2],[503,2],[506,2],[509,1],[511,3],[515,4],[520,2],[523,3],[533,1],[563,1],[565,2],[590,1],[604,2],[607,1],[628,1],[630,5],[655,1],[657,4],[674,1],[676,1],[678,2],[692,2],[695,2],[705,1],[707,3],[724,1],[726,4],[731,1],[733,2],[736,3],[740,4],[775,2],[793,1],[795,4],[812,1],[814,5],[829,1],[831,1],[833,2],[850,2],[873,3],[877,2],[880,2],[888,2],[891,4],[896,4],[901,2],[904,4],[909,4],[914,2],[917,3],[921,1],[928,1],[958,1],[974,1],[1006,1],[1008,3],[1012,2],[1015,1],[1017,3],[1042,2],[1045,5],[1051,2],[1054,1],[1056,3],[1060,4],[1079,2],[1082,2],[1097,1],[1099,2],[1125,1],[1127,2],[1130,2],[1142,1],[1153,2],[1156,3],[1181,1],[1215,2],[1240,1],[1242,2],[1245,3],[1249,3],[1262,1],[1285,2],[1288,5],[1294,2],[1307,1],[1317,1],[1319,3],[1327,1],[1340,1],[1348,2],[1396,2],[1399,2],[1402,2],[1452,1],[1454,1],[1456,2],[1459,2],[1462,2],[1465,5],[1475,1],[1493,1],[1495,4],[1500,2],[1503,5],[1514,1],[1523,1],[1543,1],[1545,2],[1552,1],[1554,1],[1568,1],[1581,1],[1583,4],[1606,1],[1608,5],[1614,2]]},"1230":{"position":[[8,1],[10,1],[12,4],[34,1],[36,2],[46,1],[63,1],[65,4],[83,1],[90,1],[105,1],[121,2],[124,2],[141,1],[149,2],[152,2],[175,1],[177,4],[198,1],[200,2],[222,4],[249,1],[258,6],[265,3],[276,3],[280,4],[285,2],[300,1],[328,1],[330,6],[344,2],[351,1],[373,1],[402,1],[420,1],[422,3],[442,1],[444,2],[447,5],[453,4],[458,3],[462,3],[473,1],[491,1],[493,1],[495,2],[589,4],[594,2],[602,1],[604,2],[621,1],[623,3],[627,6],[634,2],[637,1],[644,1],[665,1],[667,2],[670,3],[681,1],[683,2],[693,1],[707,1],[709,2],[719,4],[724,2],[741,1],[743,2],[756,4],[761,3],[765,2],[768,3],[786,1],[788,5],[817,2],[820,3],[836,1],[838,5],[855,2],[858,2],[882,2]]},"1232":{"position":[[19,1],[34,1],[59,1],[61,3],[65,5],[71,2],[74,1],[98,2],[117,1],[119,2],[134,1],[172,1],[174,2],[180,1],[192,1],[203,2],[206,3],[237,3],[241,4],[246,1],[248,2],[270,1],[272,2],[275,2],[278,3],[291,1],[296,1],[327,1],[329,2],[358,1],[360,2]]},"1234":{"position":[[23,1],[25,2],[33,2],[36,2],[39,1],[41,3],[45,3],[49,2],[130,1],[151,1],[153,2],[162,1],[183,1],[185,3],[201,2],[216,1],[227,3],[231,2],[234,3],[251,1],[269,1],[271,2],[293,1],[295,4],[305,2],[329,1],[331,2]]},"1236":{"position":[[52,1],[54,2],[174,1],[176,2],[261,3],[265,3],[269,1],[295,1],[303,1],[305,1],[307,2],[343,1],[345,4],[350,1],[381,2],[403,2],[406,1],[408,2],[411,1],[439,1],[452,3],[467,1],[481,3],[497,1],[499,4],[504,3],[508,4],[513,5],[519,3],[523,3],[527,5],[533,3],[537,2],[540,2],[543,3],[551,1],[576,1],[578,2],[602,1],[626,1],[680,1],[682,5],[709,1],[711,3],[715,5],[739,1],[741,1],[743,3],[773,3]]},"1238":{"position":[[125,1],[186,2],[199,1],[201,2],[215,2],[273,3],[317,1],[319,3],[323,2],[326,1],[328,3],[332,5],[338,2],[341,1],[343,2],[346,1],[368,1],[370,3],[413,1],[415,3],[419,2],[462,1],[464,3],[468,4],[473,5],[483,1],[502,2],[505,2],[508,6],[531,1],[537,3],[577,1],[652,1],[654,2],[660,1],[662,3],[666,3],[670,2],[744,1],[762,1],[781,1],[783,2],[786,1],[788,2],[791,3],[795,2],[812,2],[819,1],[821,3],[845,1],[872,1],[900,1],[902,1],[904,1],[947,1],[960,1],[968,1],[1038,1],[1049,1],[1051,2],[1059,1],[1061,3],[1065,7],[1084,1],[1086,2],[1089,2],[1092,2],[1095,3],[1099,2],[1107,2],[1110,3],[1114,3],[1128,4],[1133,2],[1136,3],[1140,2],[1143,2],[1146,2],[1149,4],[1154,2],[1179,1],[1188,1],[1199,3],[1222,1],[1236,1],[1245,1],[1247,5],[1253,3],[1257,3],[1261,3],[1265,2],[1268,4],[1304,2],[1345,2],[1366,1],[1368,1],[1370,5],[1396,1],[1398,3],[1402,2],[1419,2]]},"1240":{"position":[[14,1],[16,1],[18,3],[22,2],[54,1],[56,4],[87,1],[89,2],[92,6],[111,1],[113,2],[130,1],[177,1],[232,1],[234,2],[237,3],[269,1],[294,2],[297,2],[318,2],[321,2],[345,1],[378,1],[380,2],[406,1]]},"1242":{"position":[[21,2],[24,1],[52,2],[73,1],[75,5],[81,4],[86,4],[91,1],[98,1],[100,2],[114,1],[116,4],[145,1],[147,4],[152,1],[154,2],[157,2],[160,1],[174,1],[176,2],[202,1],[204,1],[206,4],[211,2],[221,3],[271,1],[371,1],[373,1],[384,1],[386,2],[433,1],[464,1],[499,2],[502,2],[514,1],[538,1],[540,3],[544,2],[566,1],[568,2],[595,1],[597,3],[601,2],[604,5],[610,1],[643,1],[659,1],[736,1],[755,2],[779,1],[781,6],[804,1],[806,3],[810,2],[829,1],[831,2],[856,1],[858,4],[863,3],[867,2],[893,1],[913,3],[936,1],[938,2],[965,1],[967,3]]},"1244":{"position":[[32,1],[34,2],[58,1],[60,4],[90,1],[92,1],[99,1],[101,5],[107,2],[110,2],[113,2],[116,2],[139,1],[141,4],[146,2],[149,4],[154,5],[160,3],[164,3],[182,1],[207,1],[209,2],[212,4],[231,2],[253,1],[255,2],[312,1],[314,2],[317,4],[362,1],[415,1],[417,4],[422,3],[426,2],[445,1],[455,1],[457,4],[462,3],[466,3],[470,2],[495,1],[497,2],[513,1],[515,4],[541,1],[564,1],[604,1],[640,1],[651,1],[653,2],[670,1],[672,5],[686,1],[696,1],[731,1],[733,5],[739,2],[753,2],[782,1],[792,1],[818,1],[851,1],[877,2],[919,1],[921,1],[923,1],[927,1],[933,1],[939,1],[941,1],[943,1],[970,2],[980,1],[986,1],[988,1],[990,1],[1011,1],[1013,1],[1054,1],[1066,1],[1095,1],[1118,1],[1134,1],[1156,1],[1169,1],[1171,4],[1176,2],[1195,2],[1217,1],[1270,1],[1282,1],[1284,2],[1303,1],[1319,2],[1322,2],[1339,1],[1355,1],[1375,2],[1403,1],[1450,1],[1476,2],[1515,1],[1517,1],[1519,1],[1551,1],[1595,1],[1671,1],[1690,1],[1692,2],[1703,1],[1722,1],[1751,1],[1753,2],[1770,1],[1781,1],[1783,2],[1806,3],[1810,4],[1833,1],[1840,1],[1853,1],[1855,3],[1859,3],[1863,2],[1866,3],[1877,4],[1891,1],[1914,1],[1916,2],[1919,2],[1945,1],[1956,2],[1959,1],[1961,4],[1986,1],[1988,3],[1992,3],[2049,1],[2069,1],[2079,1],[2102,1],[2125,1],[2206,1],[2274,1],[2293,1],[2295,2],[2298,3],[2324,1],[2344,1],[2346,3],[2350,4],[2355,2],[2358,3]]},"1246":{"position":[[13,2],[25,1],[48,1],[59,2],[64,2],[67,2],[87,1],[89,2],[108,1],[132,2],[135,3],[175,1],[210,2],[232,4],[242,1],[281,2],[305,1],[307,5],[313,2],[316,3],[346,3],[350,5],[362,1],[369,2],[372,4],[377,2],[398,1],[400,1],[408,1],[410,3],[414,2],[434,2],[441,2],[444,4],[449,2],[466,2],[473,2],[482,1],[484,4],[489,2],[492,2],[503,1],[518,1],[520,2],[541,1],[543,2],[577,1],[579,2],[596,1],[619,1],[658,1],[677,1],[679,3],[713,1],[794,1],[796,2],[804,1],[824,1],[826,3],[858,2],[861,3],[879,1],[881,2],[888,2],[936,1],[938,2],[1025,1],[1033,2],[1055,1],[1057,3],[1061,1],[1063,2],[1066,1],[1068,2],[1079,1],[1095,3],[1099,3]]},"1248":{"position":[[0,1],[7,2],[30,1],[32,3],[36,3],[40,3],[75,1],[77,1],[79,2],[82,2],[130,1],[132,2],[135,1],[156,1],[158,2],[180,1],[195,1],[221,1],[247,1],[258,2],[261,2],[285,4],[304,1],[306,2],[309,2],[330,1],[332,2],[353,1],[368,1],[395,1],[433,1],[463,2],[486,1],[488,2],[491,4],[496,2]]},"1250":{"position":[[0,3],[4,3],[20,2],[27,1],[29,3],[42,1],[44,3],[48,2],[51,3],[102,2],[105,5]]},"1253":{"position":[[4,3],[8,2],[16,1],[18,3],[34,1],[36,2],[42,5],[60,1],[62,2],[101,5],[111,5],[129,1],[131,2],[144,1],[171,1],[181,1],[223,1],[236,1],[274,1],[292,1],[322,1],[350,1],[361,1],[363,2],[370,1]]},"1255":{"position":[[14,1],[34,1],[36,3],[40,2],[59,1],[61,2],[64,3],[88,1],[90,3],[94,2],[97,5],[103,2],[127,2],[130,5],[198,3],[217,3],[236,1],[254,3],[258,2]]},"1257":{"position":[[4,1],[6,2],[19,1],[21,2],[45,1],[47,2],[67,1],[69,1],[87,1],[100,3],[138,1],[162,1],[181,1],[183,4],[195,2],[198,3],[207,1],[217,1],[219,4],[247,1],[264,2],[267,2],[270,4],[290,3],[303,1],[312,1],[314,4]]},"1259":{"position":[[16,1],[18,2],[50,2],[53,1],[80,1],[82,4],[96,2],[103,1],[118,1],[128,2],[131,2],[154,1],[156,2],[162,1],[172,1],[182,1],[198,1],[200,2],[208,2],[229,1],[231,2],[238,1],[254,1],[256,3],[288,1],[290,5],[296,2],[303,1],[326,3],[330,2],[333,2],[336,3],[340,2],[343,2],[351,1],[353,1],[355,1],[357,4],[362,3],[366,4],[371,2],[383,6],[390,1],[397,1],[403,1],[405,2],[408,2],[411,2],[414,3],[423,1],[438,1],[444,5],[450,2],[453,2],[456,2]]},"1262":{"position":[[18,1],[51,1],[53,2],[61,2],[64,3],[85,2],[108,4],[113,2],[116,1],[118,4],[123,2],[137,1],[139,2],[142,3],[146,2],[149,4],[154,2],[161,2],[168,2],[171,5],[186,2],[189,2],[192,3],[196,4],[221,3],[225,2]]},"1264":{"position":[[27,1],[40,1],[42,2],[45,3],[59,1],[61,3],[65,6],[72,4],[77,2],[90,1],[100,1],[111,2],[126,1],[131,1],[138,2],[141,2],[144,2],[154,2],[175,2],[178,4],[183,2],[186,2],[201,1],[203,4],[216,2],[230,1],[232,1],[234,3],[238,2],[241,1],[243,3],[259,2],[274,1],[276,5],[282,4],[287,3]]},"1266":{"position":[[9,2],[12,3],[37,1],[55,1],[57,6],[64,3],[85,1],[87,4],[120,1],[122,1],[124,2],[136,1],[142,1],[151,1],[174,1],[176,2],[186,2],[192,2],[195,1],[197,3],[201,3],[205,2],[212,1],[218,4],[223,4],[228,2],[243,1],[254,3],[267,2],[289,1],[291,5],[297,3]]},"1268":{"position":[[19,2],[40,3],[44,6],[55,2],[58,2],[70,4],[79,1],[115,1],[125,1],[127,3],[131,1],[133,2],[136,2],[139,2],[151,1],[153,3],[157,3],[165,1],[192,1],[194,2],[201,1],[218,1],[220,3],[238,2],[241,4]]},"1270":{"position":[[4,1],[6,4],[11,3],[22,1],[24,4],[50,1],[52,3],[75,1],[77,5],[95,1],[97,5],[109,4],[114,2],[127,1],[129,5],[135,2],[150,1],[152,2],[161,2],[182,1],[184,4],[189,2],[208,2],[211,1],[218,1],[232,1],[255,1],[257,4],[262,2],[280,1],[282,2],[285,2],[288,4],[302,5],[313,1],[319,1],[346,1],[348,3],[368,1],[370,3],[379,1],[381,5],[387,5],[393,2],[396,1],[398,2]]},"1273":{"position":[[0,2],[18,1],[20,4],[45,1],[47,5],[62,1],[71,1],[73,2],[76,3],[80,2],[104,2],[107,3],[111,2],[128,1],[142,1],[169,1],[171,3],[195,1],[197,4],[222,2],[225,2],[228,1],[230,2],[233,2],[236,2],[244,2],[247,2],[254,1],[277,1],[279,4],[284,3],[305,1],[330,1],[332,3],[357,1],[359,5],[365,4],[370,2],[373,3],[397,2],[400,3],[404,2],[407,2],[422,2],[425,3],[443,1],[445,2],[448,4],[460,1],[462,2],[465,1],[467,2],[470,2],[473,2],[481,2],[505,1],[507,4],[518,2],[521,2],[524,2],[527,3],[545,2],[558,1],[560,4],[565,2],[568,2],[591,1],[593,4],[598,2],[601,4],[606,4],[611,3]]},"1275":{"position":[[20,1],[22,2],[35,1],[37,4],[42,2],[45,3],[49,3],[53,2],[56,2],[64,1],[84,1],[86,4],[91,2],[94,2],[107,2],[116,3],[120,3],[124,2],[134,1],[136,2],[153,1],[155,5],[161,2],[164,3],[168,4],[173,2],[176,2],[187,1],[204,2],[216,4],[221,2],[229,1],[240,4],[245,1],[254,1],[256,5],[280,2],[301,1],[317,1],[319,4],[334,2],[343,2],[353,1],[368,3],[390,2],[393,3],[397,3]]},"1277":{"position":[[0,3],[4,4],[16,1],[42,1],[44,2],[53,2],[56,4],[61,1],[63,1],[72,1],[74,4],[86,1],[97,2],[100,2],[103,5],[109,1],[111,3],[115,4],[120,4],[125,2],[128,5],[134,2]]},"1279":{"position":[[7,2],[22,1],[38,1],[49,1],[51,2],[76,1],[78,6],[85,2],[88,3],[114,3],[118,2],[143,1],[145,6],[152,2],[155,3],[181,1],[193,3],[197,3],[212,1],[214,2],[223,1],[232,2],[253,1],[255,2],[258,1],[270,1],[272,4],[277,3]]},"1281":{"position":[[25,2],[28,2],[41,2],[50,2],[53,3],[57,3],[61,2],[83,4],[88,3],[92,2]]},"1283":{"position":[[0,2],[3,3],[9,2],[21,1],[23,4],[28,3],[44,1],[46,4],[51,1],[70,2],[145,1],[169,2],[183,2],[191,1],[193,4],[202,1],[204,3],[226,1],[228,3],[234,2],[242,1],[244,3],[252,2],[255,2],[258,3],[262,2]]},"1285":{"position":[[24,2],[27,2],[30,3],[34,3],[59,1],[89,2],[102,1],[118,2],[134,2],[164,1],[166,2],[181,1],[204,1],[236,1],[255,2],[289,1],[303,1],[314,1],[322,2],[332,2],[335,2],[338,3],[346,6],[376,2],[417,1],[419,2],[422,3],[426,2],[429,2],[432,2],[459,1],[468,2],[487,2]]},"1287":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1289":{"position":[[17,1],[53,1],[71,1],[73,4],[78,2],[81,5],[87,3],[94,1],[126,1],[128,4],[133,1],[140,1],[142,2],[155,1],[157,4],[162,3],[166,1],[168,4],[213,1],[215,2],[221,1],[223,3],[227,3],[245,1],[247,2],[264,1],[279,1],[290,2],[293,2],[329,1],[340,2],[350,1],[352,3],[369,2],[372,3],[376,2],[397,1],[399,1],[408,1],[427,2],[430,3],[434,1],[436,3],[440,3],[458,1],[485,1],[487,2],[496,1],[498,4],[503,3],[507,2],[515,1],[517,2],[535,1],[537,7],[559,1],[571,4],[576,3],[580,2],[583,1],[594,4],[602,1],[604,5],[619,1],[635,1],[637,2],[649,1],[651,1],[653,1],[655,2]]},"1291":{"position":[[17,1],[52,1],[54,4],[96,1],[98,4],[103,2],[106,5],[112,3],[119,1],[124,1],[126,2],[139,1],[148,2],[151,4],[156,3],[160,1],[167,2],[170,3],[174,2],[190,1],[197,1],[199,4],[204,3],[208,2],[214,3],[218,4],[223,3],[227,2],[230,2],[233,3],[237,3],[247,1],[271,1],[288,1],[290,3],[294,3],[298,1],[300,3],[328,3],[347,4],[362,1],[373,2],[398,1],[407,2],[410,4],[415,3],[434,1],[451,1],[460,3],[496,1],[498,5],[519,1],[525,1],[531,2],[534,3],[538,3],[542,3],[549,1],[551,3],[555,3],[559,4],[564,1],[571,3],[599,1],[601,5],[607,5],[619,1],[621,3],[638,1],[640,4],[645,2],[668,1],[670,4],[675,2],[678,5],[704,1],[716,1],[718,1],[720,4],[759,1],[761,1],[763,2],[766,3],[781,1],[783,2],[786,3],[790,2],[796,2],[811,3],[815,3],[831,1],[833,3],[837,3],[856,1],[858,2],[867,2],[870,3],[874,1],[876,3],[900,1],[902,2],[905,2],[908,5],[914,5],[920,1],[922,5],[938,1],[940,3],[944,2],[962,1],[978,1],[980,2],[994,1],[1036,1],[1058,2],[1068,1],[1087,3],[1132,1],[1140,1],[1184,1],[1193,1],[1195,2],[1198,2],[1201,1],[1210,1],[1221,4],[1226,1],[1228,2],[1231,4],[1236,2],[1239,1],[1241,2],[1244,2],[1247,2],[1253,1],[1262,1],[1264,3],[1268,1],[1270,4],[1282,1],[1309,2],[1312,5],[1325,1],[1327,2],[1330,3],[1334,4],[1339,2],[1357,2],[1360,2],[1363,2],[1375,3],[1379,1],[1384,1],[1386,2],[1402,1],[1411,2],[1414,1],[1421,2],[1436,1],[1443,1],[1445,4],[1450,1],[1452,6],[1459,3],[1467,1],[1498,1],[1505,1],[1507,4],[1512,3],[1516,1],[1534,1],[1536,2],[1539,2],[1542,2],[1554,2]]},"1294":{"position":[[10,1],[20,1],[33,1],[50,1],[52,3],[56,2],[59,3],[63,2],[75,6],[82,2],[85,2],[88,1],[90,2],[93,3],[97,3],[101,3],[119,3],[127,1],[151,1],[153,4],[162,1],[181,3],[199,3],[207,1],[217,2],[224,1],[234,3]]},"1296":{"position":[[20,1],[22,2],[81,1],[97,2],[108,1],[113,1],[115,3],[119,5],[134,4],[139,2],[142,1],[144,3],[157,1],[173,3],[181,1],[187,1],[189,2],[223,1],[229,1],[231,4],[253,1],[255,3],[290,1],[296,1],[298,2],[301,4],[306,2],[323,3],[345,1],[379,3],[406,1],[460,1],[462,1],[474,1],[498,1],[500,2],[524,1],[540,3],[557,1],[602,1],[604,3],[608,2],[624,2],[636,1],[655,1],[666,2],[678,2],[717,1],[796,1],[809,1],[831,1],[872,2],[887,1],[933,1],[960,1],[975,3],[979,2],[982,2],[999,1],[1022,1],[1042,2],[1045,4],[1050,2],[1053,2]]},"1298":{"position":[[5,1],[21,2],[32,1],[37,4],[42,2],[86,1],[88,3],[92,1],[94,3],[102,1],[126,1],[128,2],[131,4],[136,1],[146,1],[152,1],[192,1],[207,1],[209,3],[213,1],[215,3],[219,3],[232,1],[254,1],[265,4],[270,1],[272,2],[275,2],[319,1],[343,1],[345,2],[348,2],[392,1],[394,2],[397,1],[408,1],[416,1],[418,4],[446,1],[448,2]]},"1300":{"position":[[8,3],[12,3],[45,1],[47,6],[54,3],[72,1],[100,3],[104,2],[132,1],[134,2],[153,1],[155,5],[176,1],[203,1],[267,2],[273,1],[352,2],[393,1],[423,1]]},"1303":{"position":[[10,1],[22,1],[24,4],[29,2],[35,1],[37,3],[41,1],[43,2],[46,3],[58,1],[60,3],[64,3],[68,2],[74,1],[94,1],[96,4],[101,4],[106,2],[109,3],[113,4],[118,4],[131,1],[133,3],[137,1],[139,3],[161,1],[163,3],[167,3],[171,2],[174,1],[176,2],[179,3],[183,5],[201,1],[212,3],[216,3],[220,3],[234,1],[236,4],[244,1],[255,1],[257,5],[263,4],[276,1],[278,3],[282,4],[295,1],[312,2],[315,3],[319,3],[323,7],[346,1],[348,4],[353,3],[357,2],[360,1],[362,3],[390,1],[392,6],[415,1],[417,4],[422,3],[426,2],[429,1],[431,3],[435,3],[439,3],[451,1],[453,5],[459,4],[464,4],[558,1],[560,4],[573,1],[580,1],[582,5],[588,3],[592,4],[597,1],[599,4],[604,2],[607,3],[626,3],[630,5],[657,4],[662,2],[665,1],[667,1],[669,4],[717,3],[721,3],[737,1],[739,3],[770,1],[772,4],[777,1],[779,4],[784,1],[786,3],[824,1],[844,2],[864,2],[877,3],[881,2],[884,2],[887,3],[902,1],[904,4],[925,2],[928,4],[933,3],[951,1],[953,4],[958,5],[964,1],[966,3],[992,1],[994,7],[1002,5],[1008,2],[1011,5],[1031,1],[1033,2],[1059,1],[1061,3],[1065,2],[1084,1],[1086,2],[1089,3],[1093,1],[1095,3]]},"1305":{"position":[[14,1],[34,1],[43,1],[45,3],[65,1],[103,1],[105,3],[117,1],[127,3],[138,1],[140,3],[168,1],[230,1],[232,4],[244,3],[248,4],[284,1],[301,1],[349,1],[371,1],[393,1],[395,4],[415,1],[428,1],[445,3],[536,1],[586,1],[588,2],[606,1],[608,2],[611,5],[680,1],[717,3],[721,1],[761,2],[795,1],[921,1],[929,1],[931,4],[936,3],[965,1],[967,5],[994,1],[996,4],[1028,1],[1051,3],[1055,3],[1059,1],[1070,1],[1096,1],[1107,3],[1152,1],[1154,2],[1166,1],[1182,1],[1184,2],[1192,2],[1195,3],[1205,3],[1254,1],[1256,2],[1277,1],[1279,2],[1295,1],[1297,3],[1318,1],[1320,3],[1324,3],[1328,2],[1331,3],[1335,3],[1348,1],[1350,3],[1368,1],[1370,6]]},"1307":{"position":[[14,1],[16,5],[29,2],[32,2],[35,4],[40,4],[45,3],[49,2],[52,3],[56,2],[59,3],[63,3],[101,1],[163,1],[165,3],[229,1],[292,1],[294,4],[299,2],[323,1],[342,1],[371,1],[383,1],[385,5],[405,1],[424,1],[431,2],[434,3],[445,2],[448,4],[462,1],[464,5],[470,2],[503,1],[510,2],[536,1],[538,4],[543,3]]},"1310":{"position":[[19,1],[21,2],[24,1],[26,2],[48,1],[62,1],[69,2],[72,2],[83,1],[85,4],[90,3],[94,2],[97,3],[105,1],[107,4],[112,3],[132,1],[150,1],[162,1],[182,2],[204,1],[206,3],[210,2],[213,3],[217,2],[220,2],[223,4],[233,2],[253,1],[263,1],[265,2]]},"1312":{"position":[[30,2],[47,1],[49,2],[52,1],[54,2],[57,3],[61,2]]},"1314":{"position":[[14,1],[16,2],[32,1],[46,2],[68,1],[70,3],[85,2],[88,3],[92,3],[121,1],[123,2],[135,1],[153,1],[168,1],[170,2],[173,3],[177,2],[211,2],[229,1],[265,1],[281,2],[284,2],[375,1],[386,2],[409,2],[412,2],[429,1],[448,1],[450,2],[459,1],[465,2],[468,2],[483,1],[491,1],[497,2],[500,2],[523,1],[536,2],[539,2],[555,1],[563,1],[570,2],[573,2],[590,1],[604,2],[607,1],[613,2],[616,4],[621,2],[628,3],[632,6],[652,1],[654,2],[671,1],[673,1],[679,4],[688,2],[691,1],[705,1],[711,2],[714,3],[718,2],[740,1],[742,2],[757,4],[762,3],[787,2],[797,1],[824,2],[841,1],[843,3],[853,3],[857,2],[860,2],[863,2],[866,1],[888,1],[890,3],[908,1],[910,4],[915,3],[925,2]]},"1317":{"position":[[5,1],[31,1],[40,3],[58,1],[85,2],[88,3],[92,2],[125,1],[136,1],[138,4],[153,1],[159,2],[169,4],[184,1],[211,1],[228,1],[240,2],[248,1],[250,4],[263,2],[280,1],[290,2],[293,1],[295,3],[299,2],[302,5],[308,4],[313,1],[324,2],[346,1],[370,1],[372,4],[391,1],[393,1],[395,4],[411,2],[414,2],[417,2],[420,2],[437,1],[454,2],[474,3],[497,2],[500,1],[512,1],[514,2],[517,2],[525,2],[528,2],[531,3],[535,5],[555,1],[557,3],[568,1],[570,2],[579,1],[581,4],[586,1],[588,3],[592,2],[595,5],[615,1],[623,1],[650,1],[652,6],[659,5],[665,2],[668,4],[673,3],[677,2],[692,1],[694,4],[699,2],[702,3],[706,5],[718,2],[721,5],[727,1],[729,1],[731,4],[736,5],[742,4],[747,3],[751,2]]},"1319":{"position":[[0,3],[4,3],[21,1],[37,1],[42,2],[45,2],[48,3],[62,1],[69,1],[71,2],[88,1],[98,1],[100,5],[128,1],[135,3],[153,1],[169,2],[172,3],[176,3],[180,3],[184,2],[187,4],[192,3],[201,1],[203,5],[209,1],[211,2],[236,2],[242,2],[245,2],[248,2],[251,2],[254,4],[259,5],[287,1],[312,2],[319,1],[321,4],[326,5],[332,2],[335,3],[339,4],[344,3],[362,2],[365,2]]},"1321":{"position":[[14,1],[30,3],[34,5],[54,1],[73,2],[76,2],[79,1],[81,3],[85,3],[89,2],[101,3],[105,2],[108,5],[114,4],[119,2],[122,2],[125,5],[142,1],[144,2],[147,1],[149,3],[153,2],[160,2],[163,5],[169,5],[179,2],[182,2],[185,4],[190,3],[194,3],[198,3],[211,4],[221,3],[225,7],[233,2],[236,4],[254,1],[256,3],[260,2],[263,3],[267,6],[283,2],[300,1],[302,5],[317,1],[319,2],[322,3],[326,3],[348,1],[350,5],[356,2],[359,5],[365,4],[370,2],[373,3],[377,4],[382,3],[400,1],[414,3],[418,2],[421,3],[429,5],[435,1],[437,2],[440,2],[452,4],[471,1],[473,4],[478,3],[482,4],[501,1],[515,2],[518,3],[522,3],[526,3],[530,3],[534,2],[560,1],[562,2],[565,2],[568,2],[571,3],[575,2],[578,4],[583,3],[612,1],[614,4],[619,4],[624,3],[628,5]]},"1323":{"position":[[14,1],[30,1],[45,2],[62,2],[65,2],[82,3],[86,2],[89,2],[92,5],[98,4],[112,1],[119,1],[121,2],[130,1],[132,4],[137,1],[153,1],[155,2],[165,5],[183,2],[192,2],[204,1],[210,1],[212,4],[220,5],[237,2],[240,4],[249,5],[262,2],[265,2],[273,5],[279,4],[291,5],[297,3],[315,1],[317,2],[320,1],[322,2],[344,3],[348,2],[365,3],[369,2],[372,3],[376,4],[381,3],[385,3],[389,3],[404,3],[430,3],[434,4],[439,3],[443,2],[446,6],[453,3],[471,1],[487,4],[506,1],[516,1],[526,1],[528,3],[532,2],[535,2],[538,2],[541,5],[550,2],[567,3],[571,2],[574,2],[592,1],[608,1],[610,3],[628,2],[631,5],[645,2],[648,3],[652,1],[654,3],[658,3],[675,1],[677,4],[682,2],[699,1],[701,4],[706,3],[710,4],[715,2],[718,2]]},"1326":{"position":[[14,1],[16,1],[18,2],[41,1],[43,2],[46,1],[48,1],[50,4],[55,2],[65,3],[69,2],[72,3],[76,4],[81,4],[86,2],[104,1],[125,1],[131,1],[133,3],[137,2],[140,2],[143,5],[149,1],[158,1],[160,2],[177,1],[179,5],[185,2],[188,1],[190,2],[193,3],[197,3],[201,4],[220,1],[234,4],[239,2]]},"1328":{"position":[[16,1],[39,1],[41,5],[47,2],[65,1],[67,4],[87,1],[104,2],[107,3],[129,1],[143,1],[145,2],[148,5],[162,4],[167,2],[170,3],[174,5],[196,1],[198,4],[203,2],[206,3],[210,4],[215,4],[220,2],[223,2],[241,1],[259,4],[264,2],[267,4],[272,5],[278,3],[298,1],[316,1],[318,4],[323,2],[326,3],[340,1],[342,6],[349,4],[354,5],[360,3],[364,3],[368,2],[371,4],[376,3],[386,1],[388,3],[411,1],[428,1]]},"1330":{"position":[[9,3],[35,3],[39,2],[42,2],[45,2],[48,3],[73,1],[75,2],[78,2],[127,1],[129,5],[135,2],[159,1],[165,1],[171,2],[224,2],[227,4],[232,2],[248,2],[251,3],[263,4],[268,2],[284,1],[300,2],[303,2],[306,3],[310,3],[314,2],[317,5],[323,2],[340,1],[346,1],[352,1],[365,1],[367,3],[371,2],[374,1],[376,3],[393,1],[399,1],[412,2],[415,3],[419,2],[422,1],[424,2],[427,5]]},"1332":{"position":[[0,3],[11,1],[18,3],[22,3],[41,4],[46,3],[50,1],[52,3],[56,3],[60,2],[63,2],[88,1],[121,1],[123,2],[126,2],[129,3],[144,2],[147,5],[153,2],[167,1],[169,2],[172,4],[177,2],[194,1],[214,1],[216,2],[219,3],[223,3],[227,5],[244,1],[255,2],[258,2],[261,2],[264,4],[269,2],[272,1],[274,2],[277,3],[281,3],[307,1],[309,1],[311,2],[314,3],[318,2],[321,2],[324,2],[327,3],[331,4],[357,1],[359,3],[363,3],[367,3],[393,1],[395,3],[399,3],[403,2],[406,2],[416,1],[433,1],[435,2],[438,3],[442,2],[445,3],[460,2],[463,5],[469,3],[473,1],[475,3],[493,3],[497,2]]},"1334":{"position":[[16,5],[44,1],[46,3],[64,1],[66,2],[81,1],[83,3],[87,4],[101,1],[107,3],[111,2],[134,1],[141,2],[144,2],[147,2],[159,1],[165,3],[169,4],[174,3],[178,1],[194,1],[208,2],[211,3],[215,4],[220,4],[225,3],[229,3],[237,1],[239,2],[264,1],[266,3],[284,1],[303,1],[305,5],[311,2],[314,1],[316,2],[319,3],[323,4],[328,1],[339,4],[344,3],[348,5],[354,2],[378,1],[380,4],[385,2]]},"1337":{"position":[[2,2],[5,5],[25,1],[27,4],[32,3],[36,2],[44,1],[46,2],[49,1],[51,3],[68,3],[72,2],[75,1],[77,4],[82,4],[87,4],[92,1],[94,4],[99,2],[102,3],[106,4],[111,3],[115,5],[121,2],[124,2],[127,1],[129,4],[134,4],[144,1],[146,3],[150,1],[152,2],[155,3],[159,2],[162,4],[167,2],[170,2],[187,1],[189,1],[191,4],[196,2],[199,5],[205,3],[209,4],[214,4],[219,5],[225,3],[229,1],[231,2],[234,2],[237,4],[242,3],[246,1],[248,3]]},"1339":{"position":[[0,3],[20,5],[40,1],[42,2],[52,1],[54,3],[58,2],[61,4],[66,3],[70,3],[74,2],[77,2],[80,2],[83,4],[88,4],[93,4],[102,1],[104,4],[109,3],[113,3],[117,3],[121,2],[124,2],[127,5],[133,3],[151,1],[163,1],[165,3],[169,5],[175,3],[179,3],[183,2],[186,3],[190,4],[202,1],[204,4],[209,3],[213,3],[217,4],[222,3],[226,3],[230,4],[235,4],[240,3],[259,1],[286,3],[290,4],[303,1],[305,2],[308,2],[311,2],[314,2],[317,4],[322,3],[326,3],[330,1],[332,3],[336,3],[340,2],[343,3],[347,3],[356,1],[358,3],[362,2],[372,1],[374,4],[379,4],[384,4],[389,1],[391,3],[395,1],[397,2],[400,3]]},"1341":{"position":[[12,1],[39,1],[41,6],[48,3],[66,1],[83,1],[85,5],[94,1],[96,4],[101,3],[113,2],[128,5],[147,1],[149,4],[163,2],[180,1],[182,2],[185,4],[190,2],[193,2],[196,2],[199,2],[216,1],[233,1],[245,4],[250,1],[252,2],[255,3],[259,3],[263,2],[266,2],[276,3],[280,3],[284,3],[288,3],[292,3],[296,6],[303,3],[307,4],[312,2],[315,2],[332,1],[349,1],[351,1],[353,1],[377,1],[379,5],[397,1],[416,1],[418,3],[422,3],[426,2],[429,2],[468,1],[473,1],[475,3],[479,4],[491,1],[521,1],[523,4],[528,2],[542,1],[544,3],[548,4],[553,3],[572,1],[583,3],[604,1],[606,4],[622,1],[624,2],[644,3],[648,4],[667,1],[684,1],[686,2],[689,2],[692,2],[705,1],[707,3],[711,2],[714,2],[717,6],[724,2],[741,1],[758,1],[760,3],[764,1],[766,3],[770,5],[791,2],[798,1],[800,4],[805,5],[811,5],[817,2],[820,3],[844,1],[846,4],[863,1],[865,3],[869,3],[873,2],[911,2],[914,4],[919,4],[924,1],[942,2],[945,2],[948,2],[961,1],[970,2],[973,2],[976,4],[981,2],[984,1],[986,4],[991,5],[997,3],[1001,3],[1018,1],[1027,4],[1032,2],[1035,2],[1038,3],[1042,2],[1045,1],[1047,3],[1051,5],[1057,3],[1075,1],[1077,3],[1101,1],[1103,4],[1108,3],[1112,2],[1132,1],[1134,4],[1139,4],[1144,2],[1147,4],[1152,3],[1156,2],[1159,4],[1164,1],[1166,2],[1193,1],[1195,4],[1200,2],[1228,3],[1232,4],[1237,2],[1240,4],[1245,2]]},"1343":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1345":{"position":[[14,1],[33,1],[35,4],[40,4],[65,4],[70,2],[73,3],[77,2],[80,3],[84,2],[116,1],[118,4],[123,3],[134,2],[137,5],[143,5],[149,1],[151,4],[156,3],[160,3],[178,2],[181,4],[195,1],[207,1],[209,2],[231,1],[233,5],[259,5],[265,2],[268,3],[272,4],[310,2],[325,1],[327,5],[333,3],[365,1],[367,4],[372,2],[392,2],[407,1],[409,4],[414,2],[442,1],[444,4],[449,2],[452,2],[455,2],[458,2],[461,2],[469,1],[480,1],[482,4],[496,1],[508,3],[512,2],[515,1],[517,3],[521,3]]},"1347":{"position":[[14,1],[16,2],[36,1],[58,3],[62,6],[69,2],[84,1],[86,3],[103,1],[112,2],[135,1],[137,5],[160,1],[173,1],[175,3],[179,3],[183,3],[187,3],[191,2],[199,2],[202,4],[207,4],[212,2],[215,3],[219,4],[224,4],[243,2],[246,3],[250,2],[253,3],[257,1],[259,4],[264,2],[267,3],[271,3],[275,4],[280,3],[290,1],[292,1],[300,1],[315,2],[406,2],[457,1],[467,1],[517,1],[519,2],[522,2],[525,3],[529,2],[546,1],[567,1],[569,4],[598,3],[602,4],[621,1],[623,3],[627,6],[649,3],[653,3],[657,2],[660,5],[666,3],[670,1],[672,3],[695,2],[698,6],[716,3],[720,1],[722,2],[725,3],[729,3],[733,2],[736,3],[740,3],[744,4],[771,1],[782,1],[794,2],[797,3],[801,4],[806,5],[812,5],[826,3],[830,5],[836,3],[860,4],[865,2],[868,3],[872,5],[897,3],[901,5],[907,4],[912,3],[949,1],[951,2],[963,1],[975,1],[996,1],[998,4],[1003,3],[1046,3],[1069,1],[1071,2],[1074,3],[1078,6],[1085,3],[1094,1],[1096,3],[1107,1],[1109,4],[1114,3],[1146,1],[1148,2],[1151,2],[1154,3],[1179,1],[1181,5],[1187,5],[1193,4],[1198,5],[1204,5],[1210,2],[1213,2],[1216,3],[1220,5],[1301,2],[1304,3],[1308,2],[1311,3],[1315,1],[1317,3],[1326,1],[1345,1],[1347,4],[1366,1],[1368,5],[1374,1],[1391,1],[1418,1],[1420,4],[1444,1],[1446,3],[1450,3],[1454,2],[1475,1],[1477,2],[1480,3],[1484,1],[1486,3],[1490,2],[1493,2],[1496,2],[1517,1],[1519,5],[1525,2],[1533,2],[1536,1],[1538,3],[1542,3],[1546,2],[1559,1],[1568,1],[1570,2],[1573,2],[1590,1],[1592,4],[1606,1],[1623,1],[1625,4],[1640,1],[1650,2],[1661,1],[1679,2],[1688,2],[1705,1],[1707,2],[1710,2],[1713,2],[1748,1],[1760,1],[1762,2],[1783,1],[1785,4],[1823,3],[1846,1],[1848,4],[1853,2],[1856,3],[1860,2],[1868,1],[1870,1],[1881,1],[1908,1],[1910,3],[1936,1],[1938,3],[1942,4],[1964,1],[1966,2],[1988,1],[2013,1],[2036,1],[2038,4],[2051,1],[2062,2],[2074,1],[2076,2]]},"1350":{"position":[[73,1],[75,4],[87,1],[143,1],[187,1],[202,1],[204,4],[244,1],[246,4],[251,2],[289,1],[291,2],[313,1],[315,3],[319,3],[403,1],[485,1],[510,1],[526,1],[528,4],[533,2],[582,1],[597,4],[616,1],[634,1],[636,3],[640,3],[729,1],[741,1],[791,3],[827,1],[829,3],[833,6],[840,4],[845,2],[859,2],[876,1],[878,3],[882,5]]},"1352":{"position":[[5,3],[36,5],[42,1],[51,1],[65,1],[67,5],[73,2],[76,3],[95,1],[122,1],[124,3],[140,1],[142,3],[146,2],[149,2],[169,1],[171,5],[233,1],[248,1],[287,2],[290,2],[299,1],[301,2],[316,1],[326,2],[329,4],[334,2],[337,3],[341,3],[345,6],[457,3],[500,2],[581,1],[633,1],[641,3],[645,3],[649,2],[652,1],[666,1],[668,2],[735,1],[737,2],[754,1],[776,1],[778,3],[782,2],[785,2],[837,1],[931,1],[953,1],[967,1],[977,3],[999,1],[1015,1],[1035,1],[1037,3],[1041,5],[1047,4],[1057,1],[1078,1],[1080,3],[1084,2],[1087,5],[1113,1],[1190,2],[1258,1],[1285,1],[1313,1],[1348,1],[1366,4],[1371,4],[1390,1],[1396,1],[1398,4]]},"1354":{"position":[[58,1],[69,1],[79,2],[95,1],[97,3],[101,3],[105,3],[109,3],[113,2],[116,5],[122,3],[133,1],[135,2],[156,1],[158,4],[175,2],[191,1],[193,4],[198,3],[207,1],[218,2],[241,2],[244,6],[260,1],[275,1],[290,1],[359,2],[368,1],[370,3],[374,2],[377,2],[402,1],[438,1],[478,1],[540,1]]},"1357":{"position":[[7,3],[20,2],[28,1],[39,1],[51,1],[61,2],[64,2],[67,2],[79,1],[81,4],[86,3],[109,1],[111,2],[122,1],[133,2],[136,4],[160,1],[170,1],[178,1],[195,2],[198,2],[235,1],[260,2],[266,1],[268,1],[270,2],[286,1],[294,2],[302,3],[306,4],[311,3],[339,1],[358,1],[360,2],[395,1],[397,3],[465,1],[467,2],[470,5],[481,1],[483,3],[526,2],[576,1],[578,2],[581,3],[585,1],[587,1],[589,2],[592,1],[594,2],[597,4],[602,2],[605,3],[609,2],[612,3],[616,3],[620,2],[623,4],[635,2],[638,2],[641,1],[643,3],[647,4],[652,2],[655,5],[677,1],[679,2],[682,4]]},"1360":{"position":[[8,2],[16,1],[27,2],[30,2],[38,1],[40,2],[43,2],[46,1],[48,2],[51,4],[56,2],[59,2],[62,2],[65,2],[76,2],[79,2],[97,2],[105,2],[113,1],[129,1],[146,1],[157,1],[159,4],[164,3],[186,3],[190,4],[195,2],[198,3],[211,2],[230,1],[232,3],[250,1],[252,4],[284,1],[324,2],[344,1],[352,1],[354,4],[365,1],[367,3],[381,1],[383,2],[391,1],[393,3],[397,4],[407,1],[409,2],[412,2],[415,2],[423,2]]},"1362":{"position":[[12,1],[29,1],[38,3],[42,2],[53,2],[56,3],[74,1],[83,1],[85,3],[89,2],[92,2],[110,1],[115,4],[120,5],[135,2],[138,2],[141,2],[144,2],[147,2],[207,2],[210,2],[213,3],[217,3],[233,3],[237,4],[242,2],[245,3],[249,4],[254,2],[257,2],[275,3],[279,4],[284,2],[287,2],[290,2],[308,2],[311,2],[319,1],[321,2],[324,2],[327,4],[332,4],[349,3],[353,3],[357,1],[359,2],[362,4],[367,2],[389,1],[391,3],[395,4],[400,2],[403,1],[407,2],[416,2],[419,3],[425,2],[440,1],[442,3],[446,2],[461,1],[477,1],[479,6],[513,1],[522,1],[538,1],[548,1],[550,2],[553,2],[556,1],[558,3]]},"1364":{"position":[[17,2],[35,3],[39,4],[44,2],[47,2],[50,4],[55,2],[58,2],[68,2],[97,2],[100,2],[103,3],[107,1],[116,1],[131,1],[133,3],[150,2],[153,3],[159,1],[161,4],[203,1],[212,1],[214,3],[287,1],[289,3],[307,1],[309,3],[341,1],[343,3],[355,3],[359,2],[362,1],[364,2],[382,2],[385,2],[388,2],[408,1],[429,1],[431,2],[447,1],[449,2],[459,1],[461,2],[464,3],[474,2],[503,1],[505,4],[510,2],[513,2],[516,1],[518,2],[521,3],[525,4],[536,2],[539,3],[543,5],[549,1],[563,1],[565,3],[569,3],[573,2],[602,1],[604,5],[610,2],[613,1],[615,3]]},"1367":{"position":[[5,1],[16,2],[19,3],[23,3],[27,6],[37,1],[45,2],[48,1],[50,3],[54,4],[80,1],[82,2],[85,1],[87,2],[90,4],[95,6],[102,3],[106,2],[109,4],[114,3],[150,2],[153,1],[155,2],[158,1],[160,3],[199,1],[213,1],[255,1],[265,2],[268,1],[280,1],[294,2],[297,4],[302,4],[307,5],[313,4],[318,4],[335,3],[339,4],[344,3],[348,1],[350,2],[353,4],[358,6],[539,2],[556,1],[570,3],[574,4],[588,1],[590,5],[649,2],[666,1],[668,3],[672,7],[697,1],[699,5],[705,4],[710,4],[720,1],[722,2],[725,4],[730,2],[733,7],[741,2],[758,2],[761,6]]},"1369":{"position":[[19,1],[34,1],[43,5],[49,2],[84,1],[86,2],[112,2],[115,2],[118,4],[123,2],[126,2],[129,2],[132,2],[135,2],[138,2],[151,2],[154,4],[159,1],[161,3],[165,5],[179,5],[201,1],[203,4],[216,1],[218,5],[224,2],[236,1],[244,1],[254,1],[256,1],[258,3],[281,1],[323,1],[325,4],[350,2],[370,1],[400,1],[402,4],[412,2],[415,2],[436,1],[445,2],[480,1],[482,5],[488,2],[510,1],[512,3],[546,1],[548,4],[572,1],[598,1],[600,4],[605,5],[616,1],[625,1],[627,2],[662,3],[666,2],[688,2],[691,3],[695,4],[700,4],[718,4],[723,3],[727,4]]},"1371":{"position":[[18,4],[23,4],[37,1],[49,2],[66,3],[70,3],[74,2],[77,3],[81,4],[91,2],[94,1],[105,1],[128,1],[130,3],[142,2],[145,3],[149,4],[172,4],[186,1],[203,1],[205,5],[216,1],[232,4],[237,3]]},"1373":{"position":[[0,3],[24,1],[26,2],[29,2],[37,1],[39,4],[65,1],[81,1],[83,4],[88,4],[93,4],[98,2],[101,2],[104,3],[108,2],[119,2],[122,3],[129,1],[143,1],[145,4],[184,1],[186,3],[192,1],[208,2],[211,4],[241,1],[243,5],[254,1],[260,1],[282,5],[288,2],[298,5],[304,3],[308,2],[316,1],[318,3],[345,3],[349,4],[354,2]]},"1375":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1377":{"position":[[0,2],[52,2],[55,2],[78,1],[92,3],[96,4],[101,2],[118,2],[121,3],[125,2],[128,2],[131,2],[134,3],[138,3],[155,1],[157,3],[166,1],[168,3],[172,2],[175,3],[179,4],[184,2],[192,1],[194,2],[197,3],[208,1],[210,4],[215,2],[218,2],[221,3],[225,2],[245,1],[252,1],[254,4],[259,2],[262,3],[266,4],[271,1],[273,4],[278,3],[282,4],[287,3],[291,4],[296,5],[302,3],[314,1],[316,2],[319,3],[328,3],[343,1],[345,5],[351,2],[359,1],[372,1],[374,3],[378,4],[383,6],[390,2],[410,1],[412,2],[415,2],[423,2],[434,1],[436,3],[440,2],[443,2],[451,2],[459,2],[462,3],[466,3],[470,4],[487,2],[490,5],[507,1],[509,2],[512,4],[517,2],[520,1],[527,1],[529,2],[549,1],[551,3],[555,4],[560,4],[565,3],[569,3],[573,2],[589,1],[598,2],[601,5],[607,2]]},"1379":{"position":[[35,1],[37,4],[42,3],[51,1],[69,3],[73,3],[77,4],[94,1],[96,2],[99,6],[106,3],[110,2],[113,4],[118,3],[122,2],[174,3],[178,4],[183,3],[187,2],[195,1],[221,1],[235,1],[259,1],[261,3],[265,3],[269,2],[272,3],[286,1],[292,1],[310,1],[312,2],[315,3],[319,1],[321,2],[324,2],[327,2],[334,2],[337,4],[342,1],[344,4],[349,1],[351,3],[355,3],[375,1],[389,2],[392,2],[395,3],[399,5],[405,4],[410,3],[428,1],[430,3],[434,2],[442,1],[456,1],[458,3],[462,2],[465,2],[473,2],[488,2],[491,5],[497,5],[503,3],[507,3],[511,4],[516,3],[520,2],[523,2],[537,3],[546,1],[548,3],[557,1],[559,3],[563,3],[567,4],[572,2],[575,3],[584,1],[591,1],[593,4],[598,2],[601,2],[604,3],[608,3],[612,5],[618,4],[628,2],[631,2],[634,3],[638,3],[642,3],[646,4],[651,3],[655,5],[661,2],[669,1],[679,2],[682,3],[691,1],[703,1],[705,5],[724,1],[726,2],[729,3],[743,2],[746,1],[748,3],[752,4],[757,5],[763,2],[766,2],[769,3],[773,4],[778,4],[783,3],[787,4],[792,3],[796,2],[799,3],[803,3],[807,1],[819,1],[832,1],[851,2],[854,5],[860,3],[869,1],[871,5],[877,4],[892,1],[894,2],[897,5],[903,2],[906,3],[910,1],[922,1],[934,2],[937,5],[943,3],[947,2],[950,3],[954,4],[959,3],[963,2],[966,3],[970,1],[972,2],[980,1],[982,5],[1106,3],[1115,2],[1118,3],[1122,2],[1125,3],[1137,1],[1139,3],[1143,2],[1146,2],[1149,4],[1154,4],[1159,1],[1161,2],[1164,2],[1167,1],[1169,2],[1177,3],[1181,2],[1184,2],[1241,1],[1243,3],[1247,3],[1251,5],[1257,1],[1259,3],[1263,2],[1266,4],[1279,1],[1281,5],[1287,4],[1292,3],[1296,4],[1316,1],[1329,5],[1335,2],[1351,4],[1356,3],[1360,2],[1363,2],[1366,2],[1369,5],[1375,1],[1382,2],[1385,5],[1391,3],[1395,2],[1408,1],[1410,2],[1413,2],[1416,2],[1419,2],[1422,3],[1426,4],[1431,3],[1435,3],[1439,5],[1445,2],[1448,2],[1451,4],[1456,5],[1462,3],[1483,1],[1485,3],[1489,3],[1493,4],[1503,3],[1515,1],[1524,2],[1527,5],[1533,1],[1535,5],[1541,3],[1564,1],[1566,2],[1569,4],[1574,3],[1578,4],[1583,2],[1586,1],[1588,2],[1591,4],[1596,3],[1600,4],[1605,2],[1608,2],[1616,1],[1628,1],[1630,4],[1635,3],[1644,1],[1646,3],[1660,1],[1662,4],[1667,4],[1672,1],[1674,2],[1677,2],[1685,2],[1696,1],[1698,3],[1702,4],[1719,1],[1726,2],[1729,3],[1733,2],[1736,2],[1739,3],[1743,2],[1751,3],[1755,4],[1760,2],[1769,3],[1773,2],[1776,3],[1780,2],[1783,4],[1788,3]]},"1382":{"position":[[4,1],[17,2],[36,1],[59,2],[74,1],[76,1],[78,3],[82,3],[98,1],[100,5],[127,2],[130,2],[133,2],[136,3],[140,2],[143,3],[147,3],[151,2],[161,1],[167,1],[174,1],[183,3],[209,2],[212,2],[220,2],[235,1],[237,3],[241,3],[245,3],[249,1],[251,2],[254,2],[257,5],[263,5],[269,3],[273,3],[277,1],[279,5],[285,4],[290,3],[294,2],[304,1],[306,5]]},"1384":{"position":[[0,4],[13,1],[15,4],[44,1],[46,3],[50,1],[52,3],[56,1],[58,5],[64,3],[91,2],[94,3],[111,1],[113,1],[133,1],[155,2],[185,1],[187,2],[207,1],[234,1],[236,4],[241,4],[270,2],[273,5],[279,6],[306,1],[328,1],[350,1],[352,2],[362,1],[390,1],[441,1],[493,1],[502,1],[504,3],[508,3],[553,1],[873,1],[906,4],[911,2],[919,1],[921,2],[944,1],[978,1],[980,2],[991,1],[993,2],[1016,1],[1030,1],[1032,3],[1036,5],[1055,2],[1058,1],[1060,4],[1065,3],[1069,5],[1104,1],[1106,1],[1126,1],[1149,1],[1157,2],[1192,1],[1194,4],[1199,6],[1231,1],[1288,1],[1318,1],[1561,1],[1582,1],[1603,1],[1615,1],[1617,2],[1726,1],[1732,1],[1738,2],[1741,2],[1757,4],[1762,3],[1784,1],[1806,1],[1808,2],[1864,1],[2225,1],[2246,1],[2248,1],[2250,1],[2260,1],[2271,1],[2273,3],[2277,1],[2279,4],[2398,1],[2400,2],[2417,1],[2419,2],[2426,2],[2429,5],[2435,3],[2439,2],[2442,4],[2482,2],[2485,2],[2488,3],[2499,1],[2501,1],[2503,2],[2512,1],[2514,4],[2544,1],[2546,1],[2548,5],[2554,3],[2558,1],[2560,4],[2589,2],[2624,1],[2638,2],[2657,1],[2733,1],[2791,1],[2793,3],[2797,2],[2870,1],[2915,1],[2943,1],[2991,2],[3024,1],[3039,2],[3042,3],[3046,2],[3049,1],[3070,1],[3084,2],[3087,3],[3096,1],[3098,4],[3103,4],[3108,4],[3113,2],[3124,1],[3126,2],[3134,1],[3164,2],[3167,1],[3169,2],[3193,1],[3213,1],[3215,2],[3218,3],[3343,1],[3447,1],[3474,1],[3577,1],[3585,1],[3602,1],[3604,5],[3651,1],[3663,1],[3771,1],[3799,1],[3801,4],[3806,2],[3842,1],[3863,3],[3875,1],[3891,1],[3893,6],[3900,3],[3931,1],[3933,2]]},"1387":{"position":[[25,1],[45,1],[47,2],[50,2],[53,2],[56,3],[72,1],[74,3],[78,3],[87,2],[107,1],[109,2],[112,1],[175,3],[189,1],[191,4],[213,1],[215,4],[220,3],[237,3],[241,5],[247,2],[250,3],[265,1],[267,5],[273,2],[281,1],[283,4],[288,2],[291,3],[295,3],[299,2],[302,2],[326,3],[330,4],[335,4],[340,2],[343,4],[348,3],[352,3],[356,4],[361,1],[363,3]]},"1389":{"position":[[11,1],[24,5],[35,2],[38,1],[40,3],[44,3],[48,3],[62,1],[64,2],[67,2],[70,3],[74,2],[82,1],[84,2],[101,1],[117,1],[119,4],[133,1],[135,1],[137,2],[147,1],[149,3],[153,3],[162,4],[171,1],[173,2],[176,2],[179,3],[183,2],[206,1],[229,2],[232,1],[242,1],[262,3],[266,2],[269,2],[272,2],[275,4],[280,2],[283,2],[291,3],[295,4],[300,2],[303,2],[306,1],[308,1],[310,2],[313,3],[317,5],[328,3],[343,1],[345,4],[357,3],[361,3],[388,1],[398,2],[412,3],[424,1],[426,2],[429,3],[445,2],[448,2],[451,2],[462,1],[477,1],[500,1],[502,2],[505,3],[519,1],[521,3],[538,4],[543,4],[563,4],[568,2],[579,1],[581,5],[587,1],[594,1],[596,5],[602,3],[616,1],[635,2],[638,1],[640,2],[643,3],[647,3],[651,2],[654,2],[662,1],[664,2],[667,3],[671,5],[691,1],[693,4],[698,2],[701,4],[706,5],[712,2],[715,2],[718,3],[722,2],[725,1],[727,3],[731,2],[777,1],[792,3],[796,3],[800,3],[804,2],[825,1],[889,2],[933,2],[944,3],[956,1],[996,1],[1024,1],[1026,5],[1041,1],[1043,2],[1058,1],[1060,3],[1064,1],[1066,3],[1070,3],[1074,2],[1077,3],[1081,2],[1094,1],[1096,5],[1112,2],[1115,4],[1135,1],[1137,2],[1140,3],[1144,2],[1147,1],[1149,5],[1163,1],[1165,3],[1189,1],[1209,2],[1232,5],[1238,2],[1287,1],[1305,1],[1307,2],[1337,1],[1343,1],[1361,1],[1363,2],[1374,1],[1387,1],[1408,1],[1410,4],[1435,1],[1437,4],[1442,2],[1465,1],[1467,2],[1470,4],[1528,1],[1530,5],[1559,1],[1579,1],[1600,1],[1628,1],[1658,1],[1660,2],[1663,5],[1669,2],[1687,1],[1689,3],[1693,5],[1726,1],[1743,1],[1745,4],[1786,1],[1788,4],[1851,1],[1853,3],[1857,2],[1867,1],[1869,3],[1897,1],[1922,1],[1924,2],[1927,2],[1930,2],[1968,1],[1970,2],[1993,1],[1995,4],[2043,1],[2045,2],[2053,1],[2055,3],[2059,2],[2062,4],[2067,2],[2103,1],[2105,3],[2109,3],[2113,3],[2117,4],[2122,1],[2131,1],[2139,2],[2152,2],[2155,2],[2158,2],[2161,2],[2173,2],[2195,1],[2203,2],[2206,4],[2282,1],[2310,1],[2375,2],[2386,1],[2388,3],[2392,6],[2399,5],[2405,5],[2411,4],[2416,2],[2419,2],[2422,3],[2426,3],[2435,1],[2444,4],[2449,4],[2454,2],[2457,2],[2460,4],[2465,1],[2467,2],[2470,3],[2474,3],[2478,2],[2481,3]]},"1391":{"position":[[0,2],[3,1],[49,2],[52,2]]},"1393":{"position":[[126,1],[128,4],[142,1],[149,2],[152,2],[155,2],[166,1],[173,3],[177,2],[193,1],[195,2],[210,3],[214,2],[231,1],[233,5],[239,3],[243,3],[247,3],[251,2],[254,2],[270,2],[273,1],[303,1],[305,2],[342,1],[366,1],[390,1],[405,2],[408,4],[429,2],[448,4],[478,1],[489,2],[492,2],[504,1],[506,3],[510,2],[527,1],[529,2],[532,2],[535,3],[565,1],[567,4],[593,1],[600,3],[611,2],[628,1],[630,2],[651,2],[662,1],[676,1],[713,2],[718,1],[735,1],[737,3],[754,1],[770,1],[772,2],[825,1],[838,1],[840,3],[844,2],[847,3],[851,3],[855,2],[887,2],[890,3],[894,3],[898,2],[901,3],[905,4],[910,2],[913,3],[917,2],[920,1],[922,2],[933,1],[958,1],[960,2],[983,1],[1036,1],[1078,1]]},"1395":{"position":[[0,2],[22,2],[30,3],[34,5],[48,2],[51,2],[54,3],[58,2],[61,3],[65,2],[68,6],[80,2],[83,3],[87,2],[90,4],[95,3],[99,3],[103,2],[123,1],[138,1],[150,2],[164,1],[166,4],[200,1],[202,3],[206,3],[210,3],[214,3],[245,2],[260,2],[263,3],[267,2],[270,2],[273,2],[276,5],[282,3],[291,2],[306,2],[309,2],[312,3],[316,3],[337,2],[340,1],[347,1],[349,2],[373,1],[375,4],[380,2],[383,2],[399,4],[416,2],[419,4],[424,3],[428,2],[431,2],[434,4],[439,3],[443,2],[446,2],[454,1],[456,2],[459,2],[462,5],[468,4],[473,1],[475,2],[478,3],[525,2],[566,1],[568,3],[572,3],[576,3],[600,1],[613,1],[615,4],[620,2],[628,2],[631,2],[634,3],[661,1],[663,2],[666,1],[686,1],[700,1],[702,2],[705,1],[707,1],[709,3],[713,3],[717,3],[729,1],[748,2],[751,3],[763,2],[772,1],[796,1],[798,2],[809,1],[850,2],[853,1],[855,2],[880,1],[882,5],[896,1],[898,3],[902,2],[905,2],[938,1],[940,3],[951,1],[953,3],[965,3],[969,5],[975,2],[999,1],[1014,1],[1016,1],[1018,4],[1023,2],[1026,2],[1058,1],[1072,2],[1101,1],[1103,3],[1120,2],[1144,2],[1152,2],[1155,2],[1166,1],[1168,5],[1174,3],[1178,1],[1180,2],[1183,1],[1185,1],[1203,1],[1205,4],[1210,2],[1213,2],[1224,1],[1226,2],[1234,2],[1237,3],[1241,3],[1245,3],[1277,2],[1280,2],[1302,1],[1304,4],[1317,1],[1319,6],[1326,3],[1330,3],[1334,2],[1378,1],[1393,1],[1419,2],[1422,2],[1428,1],[1435,1],[1437,3],[1453,1],[1455,4],[1474,1],[1476,4],[1481,1],[1483,2],[1522,1],[1531,1],[1550,2],[1553,4],[1558,3],[1562,5],[1568,6],[1575,2],[1578,1],[1595,2],[1598,2],[1601,4],[1629,3],[1633,3],[1651,1],[1653,3],[1657,3],[1688,3],[1692,4],[1705,1],[1718,1],[1740,1],[1742,3],[1766,1],[1775,2],[1778,5],[1791,1],[1802,1],[1812,2],[1815,2],[1833,1],[1842,2],[1863,1],[1869,2],[1872,1],[1874,3],[1878,3],[1882,1],[1884,3],[1896,1],[1898,3],[1902,3],[1906,2],[1922,1],[1924,2],[1927,2],[1930,2],[1933,2],[1949,3],[1953,2],[1956,5],[1962,3],[1966,3],[1995,1],[1997,4],[2002,3],[2006,2],[2036,1],[2045,1],[2052,3],[2064,1],[2079,2],[2082,2],[2085,2],[2088,2],[2097,1],[2106,1],[2129,1],[2131,2],[2134,2],[2137,3],[2147,1],[2156,1],[2158,3],[2162,1],[2164,4],[2169,2],[2186,3],[2190,6],[2197,3],[2201,2],[2214,1],[2235,2],[2238,4],[2264,2],[2267,3],[2271,3],[2275,3],[2313,1],[2324,2],[2327,3],[2331,4],[2336,2],[2339,2],[2342,4],[2361,1],[2363,4],[2368,3],[2372,2],[2375,4],[2399,1],[2407,3],[2411,4],[2427,6],[2434,5],[2440,3],[2444,2],[2447,2],[2457,1],[2459,3],[2463,4],[2468,2],[2471,3],[2475,2],[2478,3],[2482,3],[2491,1],[2498,2],[2501,3],[2505,3],[2509,2],[2512,3],[2516,2],[2519,4],[2531,1],[2533,4],[2538,3],[2550,1],[2562,2],[2572,2],[2580,1],[2582,2],[2591,1],[2611,1],[2638,2],[2641,5],[2647,4],[2652,4],[2657,2],[2660,1],[2671,1],[2673,3],[2677,1],[2679,3],[2709,1],[2711,4],[2724,2],[2739,3],[2743,5],[2757,1],[2770,1],[2772,1],[2781,1],[2791,2],[2794,2],[2797,2],[2803,2],[2806,2],[2814,1],[2816,3],[2843,2],[2846,1],[2848,1],[2850,2],[2877,3],[2881,3],[2885,3],[2898,1],[2905,1],[2907,4],[2912,3],[2916,2],[2926,3],[2935,1],[2952,1],[2954,3],[2958,2],[2966,1],[2979,1],[2981,1],[2983,4],[2988,4],[2993,3],[2997,3],[3010,1],[3012,5],[3018,4],[3023,2],[3026,3],[3030,4],[3035,2],[3038,3],[3042,2],[3045,1],[3056,1],[3058,2],[3081,1],[3083,1],[3085,1],[3103,1],[3105,2],[3108,2]]},"1397":{"position":[[40,1],[55,1],[73,2],[76,4],[93,1],[104,2],[107,4],[117,1],[151,2],[154,1],[156,3],[167,3],[171,3],[175,3],[179,1],[181,4],[186,3],[190,1],[192,1],[209,2],[226,1],[241,1],[264,1],[266,5],[272,2],[283,1],[297,2],[305,1],[331,3],[335,2],[338,5],[362,1],[364,2],[367,2],[370,1],[372,2],[375,3],[379,3],[383,2],[400,1],[423,2],[434,1],[448,2],[464,2],[467,1],[469,3],[481,1],[483,4],[488,3],[492,4],[497,2],[500,3],[504,3],[508,4],[513,3],[525,1],[527,3],[531,5],[559,1],[561,1],[563,1],[565,3],[569,2],[580,1],[595,2],[598,2],[601,1],[603,4],[608,2],[611,3],[620,1],[639,1],[651,2],[654,2],[662,1],[664,5],[670,4],[675,2],[678,2],[689,1],[703,2],[706,3],[710,2],[713,2],[749,2],[760,1],[762,1],[769,3],[783,1],[802,1],[804,3],[808,2],[811,2],[828,1],[844,1],[846,3],[850,5],[856,2],[859,2],[862,2],[865,2],[876,1],[878,2],[881,2],[895,1],[897,4],[902,3],[906,4],[911,4],[933,1],[935,5],[941,4],[946,2],[957,1],[959,3],[963,3],[967,1],[969,2],[972,3],[981,1],[983,3],[987,5],[993,5],[999,2],[1011,3],[1015,3],[1019,1],[1021,2],[1024,3],[1033,3],[1045,5],[1051,3],[1055,3],[1059,2],[1062,2],[1065,5],[1071,5],[1077,4],[1082,1],[1084,3],[1088,4],[1093,6],[1135,2],[1159,1],[1161,4],[1166,2],[1169,3],[1173,2],[1184,1],[1186,2],[1206,2],[1209,3],[1213,3],[1230,3],[1234,1],[1236,5],[1242,5],[1248,2],[1256,3],[1260,5],[1266,3],[1270,4],[1275,2],[1278,1],[1292,1],[1294,3],[1298,3],[1302,4],[1307,2],[1310,4],[1315,2],[1318,2],[1321,2],[1324,2],[1327,4],[1340,1],[1349,4],[1359,2],[1369,3],[1373,3],[1404,1],[1406,3],[1410,2],[1413,2],[1421,1],[1423,4],[1428,4],[1433,2],[1443,3],[1461,2],[1464,1],[1466,4],[1471,4],[1491,1],[1493,1],[1500,2],[1520,1],[1522,3],[1526,4],[1531,1],[1533,2],[1536,3],[1540,5],[1546,3],[1550,1]]},"1399":{"position":[[8,1],[30,1],[56,1],[70,1],[72,2],[102,1],[124,1],[126,3],[130,3],[134,3],[138,2],[141,3],[145,4],[150,4],[155,3],[159,4],[164,4],[177,1],[191,1],[193,4],[198,3],[226,1],[228,4],[240,1],[249,2],[262,1],[264,1],[266,4],[271,3],[275,4],[280,2],[283,4],[288,2],[291,2],[294,2],[322,1],[324,2],[327,1],[329,2],[332,4],[337,4],[342,3],[346,2],[349,3],[353,3],[357,2],[360,2],[402,2],[405,4],[466,1],[468,2],[471,2],[479,1],[493,2],[500,1],[506,3],[510,5],[516,3],[520,5],[526,2],[529,2],[532,3],[536,4],[541,2],[544,3],[568,1],[570,1],[572,2],[575,3],[579,2],[582,1],[584,2],[593,1],[595,4],[600,2],[611,1],[613,2],[616,1],[618,1],[639,3],[643,2],[656,2],[662,1],[670,3],[674,2],[677,3],[681,3],[685,2],[688,2],[691,3],[695,3],[699,3],[703,3],[707,2],[710,3],[714,3],[718,1],[720,2],[723,1],[725,1],[727,2],[767,1],[774,1],[791,1],[793,4],[798,2]]},"1401":{"position":[[36,3],[56,1],[58,2],[71,3],[80,2],[83,2],[86,1],[88,4],[93,2],[96,5],[102,2],[105,5],[136,1],[138,4],[143,5],[149,4],[154,2],[157,4],[162,2],[170,1],[196,1],[198,2],[201,3],[205,2],[208,1],[210,3],[214,2],[217,1],[219,3],[294,1],[296,2],[299,3],[327,2],[357,3],[379,3],[396,2],[399,3],[411,1],[413,3],[417,3],[421,3],[425,3],[429,1],[431,4],[436,4],[441,1],[471,1],[473,3],[483,1],[485,2],[488,3],[492,3],[496,6],[503,3],[507,2],[510,3],[514,1],[516,1],[518,3],[589,3],[597,1],[629,1],[631,1],[639,1],[641,3],[653,1],[655,3],[659,5],[665,2],[668,3],[688,1],[690,2],[693,5],[699,5],[713,1],[719,1],[721,4],[734,1],[747,1],[753,2],[756,5],[762,4],[767,2],[770,5],[776,3],[780,2],[791,1],[803,1],[805,5],[815,1],[817,6],[824,3],[828,2],[831,2],[834,3]]},"1403":{"position":[[0,1],[2,4],[7,3],[60,1],[62,2],[65,4],[70,2],[73,1],[93,1],[95,2],[103,1],[116,1],[118,4],[128,1],[135,1],[137,2],[140,3],[155,1],[157,5],[163,4],[176,2],[187,1],[189,3],[193,4],[210,1],[223,2],[226,3],[230,3],[234,3],[238,2],[241,2],[255,1],[274,1],[276,3],[280,4],[285,5],[291,2],[294,2],[297,2],[305,3],[309,2],[312,4],[317,5],[323,3],[327,1],[329,3],[333,2]]},"1405":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1407":{"position":[[35,1],[53,1],[55,4],[60,2],[75,1],[77,3],[81,3],[85,3],[110,1],[126,1],[128,3],[137,3],[141,2],[155,1],[184,1],[186,2],[189,4],[194,3],[225,5],[231,3],[266,1],[268,5],[274,2],[277,2],[280,2],[283,1],[285,3],[301,1],[310,1],[312,2],[315,2],[330,1],[339,1],[341,5],[347,2],[350,2],[358,2],[375,1],[377,3],[381,2],[394,2],[397,2],[400,2],[403,5],[441,1],[443,5],[449,4],[462,2],[465,4],[470,2],[478,1],[480,2],[483,4],[488,3],[492,4],[497,3],[513,2],[534,5],[540,2],[548,1],[550,2],[569,1],[571,2],[574,3],[578,3],[582,5],[588,6],[608,1],[626,1],[628,4],[633,3],[643,1],[645,5],[669,1],[671,2],[674,2],[702,1],[704,4],[709,4],[733,1],[735,2]]},"1409":{"position":[[11,1],[13,4],[18,3],[22,4],[27,3],[31,2],[34,4],[57,1],[59,5],[65,2],[68,4],[73,3],[81,5],[87,2],[90,3],[94,3],[98,5],[104,6],[111,4],[116,3],[132,1],[134,4],[139,4],[144,3],[182,1],[184,5],[190,2],[209,1],[234,1],[236,5],[254,1],[256,2],[259,1],[261,3],[285,1],[287,3],[296,2],[319,2],[331,1],[333,4],[338,3],[342,6],[356,3],[360,4],[365,3],[386,1],[388,3],[392,2],[408,3],[412,5],[449,1],[451,3],[455,2],[493,1],[495,5],[501,1],[519,1],[521,2],[533,1],[555,1],[557,4],[575,1],[604,1],[619,1],[632,4],[637,2],[640,3],[644,2],[647,1],[649,2],[662,1],[664,2],[667,1],[669,5],[702,1],[704,2],[707,2],[710,2],[713,2],[716,1],[718,3],[734,1],[743,1],[745,2],[748,2],[763,1],[772,1],[774,5],[780,2],[783,4],[793,1],[806,4],[825,1],[827,3],[831,3],[835,2],[848,3],[867,1],[882,2],[891,1],[915,2],[929,4],[947,1],[960,3],[975,1],[977,3],[981,7],[1007,1],[1009,2],[1017,2],[1036,1],[1038,5],[1044,3],[1048,2],[1051,3],[1055,3],[1059,1],[1061,3],[1077,1],[1079,4],[1084,2],[1106,1],[1108,2],[1111,5],[1117,2],[1120,3],[1124,7],[1139,1],[1153,2],[1160,3],[1171,1],[1173,4],[1187,2],[1190,1],[1192,3],[1196,2],[1204,1],[1222,1],[1224,2],[1227,2],[1230,3],[1234,2],[1237,2],[1240,2],[1256,1],[1258,4],[1263,2],[1279,1],[1299,1],[1301,1],[1312,1],[1314,1],[1316,5],[1322,3],[1326,1],[1328,4],[1338,1],[1355,3],[1359,2],[1383,1],[1401,1],[1403,4],[1413,2],[1416,4],[1421,3],[1425,3],[1454,1],[1456,4],[1479,1],[1481,4],[1486,2],[1502,1],[1504,3],[1508,1],[1510,2],[1533,2],[1587,1],[1594,3],[1611,1],[1613,3],[1617,3],[1621,2],[1638,1],[1650,1],[1652,3],[1656,2],[1659,3],[1663,3],[1688,1],[1702,1],[1721,1],[1723,5],[1735,1],[1737,2],[1756,2],[1759,3],[1763,3],[1767,2],[1775,1],[1792,3],[1796,2],[1812,1],[1830,1],[1832,4],[1837,2],[1840,3],[1844,1],[1846,2],[1854,1],[1856,5],[1887,1],[1889,4],[1894,4],[1916,2]]},"1411":{"position":[[12,1],[14,2],[31,2],[34,3],[38,3],[47,1],[76,1],[99,3],[103,2],[121,1],[144,1],[146,2],[164,2],[167,2],[170,1],[172,3],[189,1],[198,2],[221,2],[224,2],[239,1],[241,2],[251,1],[253,5],[259,2],[276,1],[278,3],[282,3],[286,5],[304,1],[306,2],[336,3],[340,5],[346,2],[354,1],[375,1],[377,3],[381,2],[401,1],[403,2],[432,1],[434,5],[440,2],[456,1],[458,2]]},"1413":{"position":[[68,1],[70,2],[76,4],[94,1],[96,2]]},"1415":{"position":[[5,1],[7,2],[20,2],[59,1],[83,1],[85,5],[91,1],[105,1],[114,1],[116,5],[122,2],[125,2],[141,1],[182,1],[247,1],[262,1],[264,2],[267,3],[271,3],[275,3],[279,5],[297,1],[311,2],[314,2],[322,1],[324,3],[349,1],[351,3],[379,1],[381,4]]},"1417":{"position":[[5,1],[17,4],[22,3],[30,1],[55,2],[58,3],[62,2],[70,2],[73,4],[78,1],[88,1],[105,1],[107,2],[110,3]]},"1419":{"position":[[14,1],[16,3],[20,4],[41,1],[43,5],[70,1],[72,3],[76,4],[81,3],[85,3],[93,1],[108,2],[149,2],[195,1],[197,3],[208,1],[210,4],[215,2],[218,2],[221,1],[223,3],[248,1],[262,1],[264,4],[269,2],[272,2],[291,1],[303,1],[305,3],[314,4],[319,3],[323,4],[328,3],[339,1],[341,4],[346,1],[348,3],[352,1],[354,1],[356,3],[396,4],[417,1],[419,4],[431,1],[433,3],[437,2],[440,3],[449,2],[458,1],[479,1],[481,2],[489,1],[526,1],[528,3],[532,3],[542,1],[552,1],[554,1],[556,4],[561,1],[563,2],[592,1],[594,3],[598,2],[601,2],[612,1],[621,4],[626,3],[740,1],[775,1],[835,1],[841,1],[871,2],[874,5],[880,4],[885,1],[893,2],[916,1],[918,4],[944,1],[984,1],[986,4],[991,2],[994,4],[1003,1],[1025,2],[1028,3],[1040,1],[1042,4],[1094,1],[1117,2]]},"1421":{"position":[[0,3],[25,1],[27,2],[30,3],[34,4],[39,3],[50,1],[73,1],[75,4],[95,1],[97,1],[125,1],[135,1],[248,1],[264,1],[281,2],[284,5],[307,1],[325,2],[328,1],[330,3],[334,2],[384,2],[401,1],[407,4],[412,3],[430,3],[455,1],[457,2],[460,5],[491,1],[500,1],[523,2],[547,2],[574,1],[595,3],[614,2],[617,3],[631,2],[645,4],[661,2],[664,1],[666,3],[681,2],[684,3]]},"1423":{"position":[[80,1],[87,1],[99,5],[105,3],[125,1],[141,1],[143,2],[146,2],[149,3],[153,5],[159,2],[162,2],[170,1],[182,2],[190,1],[214,2],[222,1],[253,2],[271,2],[288,1],[295,3],[299,2],[302,3],[306,2],[309,3],[313,2],[332,1],[334,7],[342,3],[360,1],[362,5],[373,1],[375,2],[378,2],[381,4],[386,5],[392,1],[394,2],[402,2],[405,3],[424,1],[426,3],[430,2],[438,1],[461,1],[468,1],[480,4],[490,3],[494,3],[503,1],[510,2],[513,5],[522,3],[560,1],[562,3],[566,3],[570,5],[586,1],[588,3],[592,3],[611,2],[614,3],[618,2],[621,3],[630,2],[639,1],[663,2],[666,4],[671,2],[674,2],[689,1],[691,3],[695,1],[697,2],[715,1],[717,2],[725,1],[727,2],[730,3],[734,1],[736,2],[739,3],[743,3],[747,3],[751,3],[755,1],[757,3],[761,2],[772,1],[774,3],[783,3],[787,4],[792,2],[795,1],[797,4],[802,2],[836,3],[840,1],[842,3],[846,2],[849,2],[852,2],[855,3],[871,2],[874,2],[877,3],[881,4],[898,3],[902,2],[905,2],[908,1],[910,3],[1002,2],[1019,1],[1030,2],[1046,3],[1050,3],[1054,5],[1060,3],[1064,2],[1067,3],[1071,4],[1076,1],[1082,1],[1084,5],[1090,3],[1094,1],[1100,1],[1102,4],[1107,3],[1111,3],[1129,1],[1131,3],[1135,3],[1139,4],[1157,1],[1159,3],[1163,3],[1167,3],[1171,2],[1174,6],[1181,1],[1183,3],[1187,4],[1201,3],[1229,1],[1239,1],[1241,4],[1246,4],[1256,1],[1282,1],[1284,4],[1313,2],[1321,2],[1324,3],[1333,2],[1336,3],[1340,3],[1348,3],[1352,3],[1366,5],[1372,5],[1389,2],[1392,4],[1397,3],[1412,2],[1415,2],[1418,2],[1447,2],[1450,5],[1464,2],[1467,5],[1473,7],[1511,1],[1513,4]]},"1425":{"position":[[16,1],[32,2],[35,3],[39,6],[46,3],[62,3],[66,4],[71,2],[74,4],[79,3],[88,1],[95,1],[97,3],[106,1],[123,2],[135,1],[137,3],[153,1],[155,2],[158,2],[161,4],[182,1],[184,3],[188,1],[190,2],[193,3],[206,3],[210,6],[217,3],[221,5],[227,3],[231,2],[239,1],[259,1],[261,1],[272,2],[275,3],[279,1],[281,4],[286,2],[289,4],[294,2],[309,1],[311,3],[315,2],[318,3],[322,2],[325,2],[346,1],[364,2],[367,1],[369,2],[384,1],[401,2],[404,4],[431,1],[433,2],[456,2],[459,2],[462,1],[464,4],[495,1],[497,4],[520,1],[522,2],[525,2],[540,1],[542,3],[546,1],[548,4],[573,2],[576,3],[580,3],[609,1],[615,1],[617,5],[646,1],[652,2]]},"1427":{"position":[[18,1],[38,2],[74,1],[76,5],[82,1],[96,2],[99,1],[113,2],[125,2],[128,2],[144,1],[156,2],[159,2],[162,4],[185,1],[187,4],[192,4],[197,3],[201,7],[209,3],[225,1],[268,4],[273,2],[276,2],[279,3],[283,4],[288,3],[292,2],[316,3],[328,2],[343,1],[345,2],[375,2],[401,3],[405,2],[408,3],[430,1],[432,4],[449,1],[458,1],[460,3],[479,1],[481,2],[484,3],[488,1],[502,2],[530,2],[533,1],[535,3],[539,2],[542,2],[558,1],[560,1],[562,1],[564,2],[567,2],[570,2],[573,3],[583,1],[585,2],[644,2],[655,2],[658,4],[673,3],[693,1],[707,2],[710,3],[714,2],[717,2],[742,1],[750,1],[752,2],[755,3],[759,1],[761,2],[825,1],[858,1],[872,1],[874,3],[882,1],[903,1],[905,4],[926,1],[942,1],[958,4],[963,2],[966,5],[991,3],[995,4],[1009,1],[1011,5],[1017,2],[1030,2],[1056,1],[1058,2],[1082,1],[1084,3],[1118,3],[1129,1],[1143,1],[1145,3],[1149,1],[1151,2],[1185,4],[1190,2],[1198,3],[1220,1],[1222,2],[1225,2]]},"1429":{"position":[[14,1],[30,1],[49,1],[51,4],[56,3],[76,1],[102,1],[104,4],[109,4],[114,3],[118,2],[126,3],[130,3],[134,4],[139,1],[141,3],[145,1],[147,3],[151,5],[157,2],[160,4],[165,2],[181,1],[199,2],[202,4],[227,1],[229,2],[232,6],[244,1],[256,1],[277,2],[298,1],[300,2],[320,1],[322,4],[345,1],[347,2],[365,1],[367,3],[371,3],[375,1],[377,3],[381,1],[405,1],[418,3],[422,2],[425,2],[461,2],[475,1],[477,2],[488,1],[490,2],[543,1],[576,3],[598,2],[647,1],[776,1],[795,1],[823,1],[879,2],[929,2],[958,2],[1007,1],[1151,1],[1196,1],[1198,4],[1218,2],[1239,1],[1274,1],[1276,5],[1282,3],[1310,1],[1312,4],[1336,1],[1338,1],[1348,2],[1351,2],[1354,3],[1358,5],[1380,1],[1382,2],[1385,5],[1391,4],[1396,2],[1399,1],[1401,1],[1403,3],[1425,1],[1484,1],[1501,1],[1514,1],[1549,1],[1576,1],[1583,1],[1630,1],[1656,2],[1659,4],[1673,1],[1680,1],[1688,1],[1690,3],[1694,3],[1698,4],[1703,2],[1721,1],[1741,2],[1754,1],[1756,1],[1758,5],[1764,2],[1767,2],[1770,2],[1780,1],[1803,1],[1809,1],[1819,3],[1833,1],[1835,3],[1847,2],[1850,3],[1869,1],[1887,1],[1889,4]]},"1431":{"position":[[0,3],[19,1],[21,4],[47,1],[49,4],[54,3],[58,6],[77,1],[79,2],[82,2],[85,3],[101,1],[103,5],[121,2],[124,3],[128,2],[150,1],[152,4],[157,2],[160,2],[181,1],[183,4],[188,3],[192,1],[206,2],[209,1],[211,2],[232,1],[241,1],[243,4],[267,1],[269,2],[281,1],[306,1],[308,2],[311,2],[359,1],[361,2],[364,6],[401,1],[403,3],[426,1],[428,4],[453,1],[460,1],[480,1],[482,2],[489,1],[509,1],[538,3],[542,3],[560,1],[562,2],[565,1],[567,2],[570,2],[573,2],[614,1],[616,4],[635,1],[637,5],[643,5],[649,2],[652,1],[654,3],[674,1],[694,1],[696,2],[699,3],[703,3],[707,2],[715,2],[718,3],[722,2],[827,1],[846,1],[848,2],[865,1],[867,5],[889,1],[891,3],[909,2],[934,1],[936,3],[940,2],[983,1],[1095,1],[1112,1],[1114,4],[1177,1],[1179,3],[1195,1],[1197,5],[1224,1],[1254,3],[1258,4],[1263,3],[1275,1],[1292,1],[1294,4],[1299,1],[1301,2],[1304,1],[1325,1],[1327,2],[1351,1],[1353,4],[1382,1],[1384,4],[1403,1],[1405,3],[1409,1],[1411,3],[1415,3],[1435,1],[1458,3],[1462,2],[1465,1],[1479,1],[1512,1],[1514,2],[1517,3],[1521,2],[1524,4],[1529,1],[1543,1],[1545,2],[1567,1],[1574,1],[1576,4],[1581,2],[1603,1],[1605,2],[1615,1],[1617,2],[1689,1],[1698,1],[1722,2],[1736,1],[1738,2],[1753,3],[1782,4],[1787,4],[1792,5],[1824,1],[1847,3],[1872,2],[1891,1],[1912,1],[1942,1],[1972,1],[1986,1],[2002,1],[2018,2],[2021,3],[2025,2],[2033,1],[2035,5],[2041,5],[2047,4],[2076,2],[2079,2],[2106,2],[2109,4],[2119,1],[2135,1],[2137,2],[2146,1],[2148,1],[2166,1],[2168,2],[2171,2],[2190,2],[2193,2],[2266,5],[2272,3],[2276,1],[2278,1],[2280,3],[2284,1],[2286,2],[2362,1],[2376,1],[2378,2],[2381,2],[2398,1],[2400,4],[2405,4],[2410,3],[2414,3],[2418,2],[2421,3],[2441,1],[2443,5],[2449,3],[2489,1],[2491,5],[2509,1],[2542,1],[2544,2],[2561,1],[2563,4],[2568,4],[2582,2],[2585,1],[2587,3],[2591,2],[2609,4],[2649,1],[2651,2],[2664,1],[2666,2],[2683,1],[2685,4],[2690,2],[2693,3],[2706,1],[2708,1],[2710,3],[2738,1],[2747,3],[2751,5],[2760,1],[2764,1],[2766,1],[2772,3],[2778,1],[2783,1],[2785,1],[2817,1],[2823,3],[2827,1],[2829,3],[2858,1],[2865,1],[2872,2],[2891,1],[2893,3],[2897,2],[2900,3],[2904,3],[2908,2],[2911,3],[2915,3],[2919,3],[2935,1],[2937,2],[2940,1],[2956,1],[2958,4],[2963,2],[2966,5],[2972,3],[2992,1],[2994,4],[2999,2],[3002,2],[3031,1],[3033,2],[3036,3],[3045,1],[3047,3],[3051,2],[3054,3],[3073,1],[3075,2],[3094,1],[3096,2]]},"1434":{"position":[[0,2],[8,1],[10,2],[13,4],[32,1],[34,6],[46,1],[48,3],[52,2],[55,3],[59,5],[65,3],[69,1],[71,3],[75,3],[79,3],[83,4],[92,1],[94,2],[97,3],[115,1],[117,2],[120,3],[124,3],[128,3],[138,3],[166,1],[168,3],[172,4],[177,2],[194,1],[196,1],[198,4],[203,4],[208,4],[213,3],[222,1],[242,1],[244,4],[249,1],[251,2],[254,2],[257,3],[261,2],[277,1],[304,1],[326,2],[329,2],[332,2],[335,3],[354,1],[372,1],[374,3],[378,2],[381,3],[385,4],[390,4],[395,2],[398,4],[403,2],[406,2]]},"1436":{"position":[[0,1],[2,4],[21,1],[41,2],[58,1],[73,1],[75,5],[81,3],[85,5],[91,6],[119,1],[121,2],[124,3],[128,4],[149,1],[151,2],[154,2],[157,4],[162,2],[165,3],[181,1],[198,2],[201,4],[211,2],[225,1],[227,3],[231,5],[253,1],[255,4],[260,2],[275,1],[295,1],[297,3],[301,1],[303,1],[305,3],[309,4],[314,3],[328,3],[332,2]]},"1438":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1440":{"position":[[0,2],[8,1],[29,1],[31,4],[36,2],[39,4],[44,3],[48,4],[53,3],[80,1],[82,2],[85,3],[89,2],[92,4],[97,3],[113,2],[116,3],[120,2],[123,3],[127,3],[146,1],[148,7],[156,3],[160,5],[166,4],[171,2],[174,3],[178,4],[183,3],[197,1],[199,5],[212,6],[219,2],[222,3],[226,5],[247,1],[249,4],[254,4],[269,1],[287,1],[289,3],[293,2],[296,3],[316,1],[334,1],[336,4],[358,2],[361,1],[363,2],[366,5],[372,5],[388,1],[390,3],[394,2],[411,1],[433,1],[435,2],[438,7],[446,6],[453,1],[471,1],[473,4],[478,5],[484,3],[550,2],[568,1],[570,2],[573,3],[577,3],[581,4],[612,2],[626,4],[631,5],[637,2],[645,1],[653,1],[659,1],[661,2],[664,4],[669,3],[713,1],[726,1],[728,2],[731,2],[734,1],[745,4],[750,3],[754,5]]},"1442":{"position":[[0,2],[3,4],[17,1],[19,3],[23,2],[26,4],[37,1],[39,4],[44,5],[50,1],[52,3],[61,1],[63,4],[72,2],[75,1],[77,4],[82,3],[86,1],[88,2],[96,1],[107,1],[109,3],[113,1],[115,3],[119,3],[123,3],[127,4],[132,2],[135,2],[138,3],[142,3],[146,5],[152,3],[156,5],[162,5],[168,3],[172,3],[176,4],[181,4],[186,3],[190,4],[195,3],[199,2],[202,4],[207,2],[210,2],[213,3],[223,2],[226,4],[231,4],[236,4],[241,3],[245,1],[247,3],[257,1],[259,3],[263,5],[269,3],[273,2],[276,4],[281,3],[285,3],[289,4],[304,2],[307,3],[311,4],[316,5],[322,2],[325,6],[339,2],[358,1],[360,3],[364,2],[367,3],[387,2],[390,5],[396,2],[399,2],[402,6],[419,1],[421,2],[443,1],[445,5],[451,1],[478,1],[507,3],[511,3],[515,4],[520,2],[523,3],[527,4],[532,3],[536,1],[538,1],[540,5],[546,5],[552,2],[555,3],[559,1],[561,2],[564,3],[568,3],[572,4],[577,4],[582,3],[586,3],[590,4],[595,2],[598,5],[604,3],[617,2],[636,1],[668,1],[670,2],[702,1],[719,1],[721,4],[726,2],[729,3],[733,3],[737,5],[743,3],[747,3],[751,3],[755,3],[779,3],[783,3],[787,6],[794,1],[796,4],[801,3],[805,3],[809,2],[812,3],[816,2],[819,3],[823,4],[828,3],[832,5],[838,2],[841,3],[845,5],[851,3],[855,3],[859,3],[863,2],[868,2],[871,3],[875,5],[968,1],[970,3],[996,2],[1035,1],[1037,2],[1056,2],[1059,5],[1083,1],[1102,1],[1104,3],[1108,1],[1110,2],[1113,3],[1117,4],[1122,5],[1138,1],[1147,2],[1171,2],[1174,3],[1178,5],[1184,4],[1189,2],[1192,3],[1196,3],[1200,4],[1220,3],[1231,2],[1248,1],[1250,4],[1255,2],[1258,2],[1261,1],[1263,3],[1267,3],[1280,3],[1291,1],[1293,2],[1315,5],[1321,3],[1343,1],[1345,3],[1349,4],[1354,2],[1357,2],[1360,4],[1365,1],[1367,5],[1389,1],[1391,2],[1394,3],[1398,2],[1401,2],[1404,5],[1417,1],[1419,2],[1422,1],[1424,4],[1429,3],[1433,2],[1436,3],[1444,1],[1491,1],[1493,2],[1496,4],[1501,3],[1505,4],[1510,3],[1514,2],[1517,3],[1521,3],[1525,3],[1529,3],[1533,2],[1536,2],[1539,2],[1563,1],[1565,1],[1567,3],[1571,2],[1619,1],[1699,1],[1710,1],[1724,2],[1727,2],[1730,3],[1734,5],[1740,3],[1744,1],[1746,3],[1755,3],[1780,1],[1791,2],[1814,1],[1825,2],[1850,1],[1862,2],[1865,2],[1872,2],[1875,6],[1882,2],[1898,1],[1900,3],[1904,3],[1917,3],[1921,2],[1924,3],[1938,5],[1944,3],[1948,2],[1958,1],[1966,1],[1984,1],[2000,1],[2002,3],[2006,4],[2011,4],[2033,2],[2036,4],[2057,1],[2059,3],[2063,5],[2085,1],[2087,3],[2091,4],[2096,3],[2100,3],[2104,4],[2109,1],[2111,2],[2114,5],[2120,2],[2123,5],[2129,3],[2149,1],[2151,5],[2162,5],[2168,3],[2172,3],[2181,3],[2194,3],[2198,3],[2202,2],[2205,2],[2215,5],[2231,1],[2233,3],[2246,3],[2250,2],[2253,2],[2256,4],[2261,3],[2265,4],[2270,3],[2301,2],[2309,2]]},"1445":{"position":[[0,3],[4,1],[6,2],[9,3],[13,3],[17,2],[20,3],[36,1],[43,1],[52,1],[54,3],[83,1],[94,1],[96,3],[107,1],[115,1],[117,4],[153,1],[172,1],[180,1],[182,4],[187,2],[216,1],[218,3]]},"1447":{"position":[[6,1],[14,3],[18,3],[27,1],[36,3],[40,2],[43,3],[60,1],[62,4],[67,4],[72,3],[92,3],[96,5],[111,3],[146,4],[158,2],[181,1],[183,3],[187,3],[212,3],[216,3],[220,4],[242,1],[250,1],[252,3],[256,3],[264,3],[268,5],[274,3],[278,3],[299,1],[321,2],[329,1],[349,1],[351,2],[354,3],[358,4],[363,3],[367,3],[371,2],[374,3],[378,4],[383,2],[386,3],[396,2],[399,4],[412,1],[414,4],[446,1],[448,5]]},"1449":{"position":[[20,1],[42,1],[50,1],[52,3],[63,1],[65,4],[70,4],[75,1],[77,3],[81,3],[85,1],[87,3],[102,1],[104,4],[109,3],[113,3],[130,2],[133,3],[137,4],[155,1],[157,2],[175,1],[177,4],[182,4],[193,1],[211,3],[215,6],[222,3],[242,1],[244,5],[265,1],[267,3],[278,1],[298,1],[300,4],[311,3],[315,4],[345,1],[347,3],[367,2],[391,1],[413,1],[415,4],[420,2],[423,4],[459,2],[478,1],[497,1],[499,2],[509,4],[524,2],[531,1],[533,2],[536,5],[542,4],[547,2],[550,2],[567,5],[573,3],[584,1],[586,2],[589,3],[601,3],[605,5],[611,3],[620,1],[622,2],[625,4],[630,4],[635,2],[638,4],[643,5]]},"1451":{"position":[[4,1],[28,1],[44,1],[46,2],[67,1],[69,4],[74,2],[101,1],[103,5],[129,2],[132,3],[136,3],[140,3],[181,2],[218,1],[248,1],[250,5],[278,1],[280,5],[286,4],[300,1],[302,5],[308,1],[319,1],[336,2],[339,2],[342,3],[346,3],[350,2],[359,1],[371,1],[373,5],[379,2],[409,3],[419,1],[436,1],[438,3],[442,1],[444,2],[447,2],[459,1],[461,3],[465,3],[493,1],[512,2],[515,3],[519,1],[521,3],[525,2],[528,2],[537,1],[539,2],[561,1],[563,4],[568,3],[572,2],[595,1],[617,1],[619,3],[623,3],[627,2],[630,2],[633,3],[644,1],[646,2],[649,3],[659,2],[668,1],[670,2],[673,3],[677,2],[689,3],[718,3],[722,2],[744,1],[746,2],[749,2],[782,1],[802,3],[806,2],[815,1],[817,3],[821,2],[840,1],[842,4],[847,3],[851,4],[872,3],[876,3],[880,2]]},"1453":{"position":[[10,3],[14,2],[17,5],[34,1],[53,3],[72,2],[81,1],[89,1],[109,1],[111,4],[116,2],[119,4],[124,2],[127,3],[131,2],[134,5],[140,4],[145,2],[148,4],[153,3],[157,3],[161,4],[166,2],[169,5],[178,5],[203,1],[223,1],[225,5],[253,1],[262,1],[281,1],[283,5],[289,1],[291,1],[311,2],[322,3],[326,2],[329,2],[332,6],[339,2],[348,2],[351,2],[354,3],[358,3],[362,4],[367,2],[386,1],[388,2],[415,1],[417,2],[420,3],[424,3],[428,3],[432,3],[436,4]]},"1455":{"position":[[12,3],[22,1],[24,3],[28,6],[58,1],[60,2],[73,1],[88,1],[114,2],[117,4],[137,1],[139,2],[151,1],[163,1],[165,2],[182,3],[212,1],[214,4],[219,2],[222,3],[238,2],[245,2],[248,2],[251,3],[255,3],[259,1],[261,2],[273,4],[287,1],[289,4],[294,2],[319,1],[355,3],[359,4],[384,1],[386,4],[401,1],[403,2],[418,1],[430,1],[432,2],[479,1],[503,1],[505,3],[509,2],[512,4],[517,5],[551,1],[553,3],[557,3],[561,3],[565,3],[569,2],[579,4],[584,5],[600,1],[619,1],[621,4],[626,5],[632,1],[644,2],[659,1],[671,1],[673,5],[679,3],[683,2],[686,2],[689,2],[692,1],[703,3],[713,4],[734,3],[738,2]]},"1462":{"position":[[9,1],[14,1],[36,2],[39,3],[43,5],[69,1],[71,3],[75,2],[92,3],[96,6],[128,1],[130,2],[133,1],[135,3],[139,1],[141,3],[162,1],[181,2],[199,1],[201,6],[208,2],[211,4],[243,2],[246,4],[264,2],[267,2],[270,3],[284,1],[303,1],[305,4],[310,2],[313,5],[335,1],[337,5],[385,1],[387,6],[411,4],[416,3],[420,2],[430,1],[432,2],[445,2],[448,2],[451,2],[454,3],[458,4],[463,2],[466,2],[469,2],[472,3],[489,3],[493,4],[498,1],[500,2],[503,3],[507,2],[510,3],[514,2],[517,1],[519,3]]},"1464":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1466":{"position":[[14,1],[58,1],[73,2],[76,2],[92,1],[94,5],[100,2],[103,3],[107,3],[111,2],[128,1],[130,2],[145,3],[149,6],[165,1],[180,2],[188,2],[191,3],[195,2],[198,3],[202,5],[208,1],[210,4],[215,3],[241,1],[259,1],[270,3],[274,1],[276,1],[278,3],[282,2],[285,3],[289,3],[293,4],[298,2],[301,5],[307,5],[317,1],[319,3],[323,3],[327,3],[358,3],[422,1],[424,2],[427,6],[442,1],[476,1],[478,2],[481,3],[504,2],[530,1],[532,4],[537,2],[567,1],[569,4],[586,2],[589,2],[607,2],[610,3],[614,5],[641,2],[644,2],[651,1],[653,3]]},"1468":{"position":[[5,1],[30,1],[32,2],[35,2],[38,4],[43,1],[45,3],[49,5],[62,3],[75,1],[87,3],[91,2],[114,1],[116,2],[119,4],[124,2],[139,1],[163,3],[167,2],[205,2],[214,1],[228,1],[230,2],[233,3],[237,2],[240,1],[259,1],[261,6],[268,1],[270,3],[274,4],[279,2],[282,6],[301,5],[325,1],[327,3],[331,2],[334,1],[336,4],[341,2],[359,2],[362,4],[386,1],[388,5],[394,2],[397,2],[400,2],[421,1],[435,3],[451,1],[457,1],[459,3],[463,3],[467,1],[469,3],[506,4],[511,5],[517,2],[525,2],[546,1],[553,3],[557,4],[562,4],[567,2],[570,3],[574,3],[578,3],[582,2],[599,1],[601,2],[613,3],[617,2],[620,1],[622,3],[626,4],[638,2],[641,2],[644,3],[648,5],[677,1],[683,1],[685,2],[688,1],[690,3],[698,1],[712,1],[714,3],[745,1],[747,5],[753,2],[756,1],[758,5],[781,1],[783,4],[788,4],[793,2],[796,1],[810,1],[827,2],[830,3],[839,2],[842,3],[857,1],[875,2],[878,3],[896,2],[899,3],[903,2],[913,3],[917,3],[921,4],[926,3],[930,1],[932,2],[958,1],[976,3],[1003,1],[1020,1],[1022,2],[1025,3],[1029,3],[1049,1],[1051,4],[1071,1],[1073,4],[1078,1],[1109,1],[1111,2],[1129,1],[1131,4],[1136,1],[1138,2],[1153,2],[1172,1],[1174,4],[1216,2],[1219,2],[1222,3],[1238,1],[1240,6],[1247,3],[1273,1],[1275,5],[1281,2],[1301,2],[1304,1],[1306,4],[1334,1],[1336,4],[1390,1],[1392,2],[1395,1],[1397,3],[1409,1],[1411,3],[1415,3],[1419,3],[1437,1],[1452,3],[1466,2],[1469,2],[1472,2],[1482,1],[1493,2],[1496,2],[1504,1],[1518,2],[1535,1],[1537,3],[1541,1],[1543,1],[1545,3],[1564,1],[1566,3],[1570,3],[1582,1],[1596,1],[1609,1],[1611,2],[1614,2],[1617,1],[1623,2],[1638,1],[1640,3],[1644,3],[1656,1],[1672,1],[1674,2],[1677,3],[1681,4],[1686,4],[1696,2],[1711,1],[1713,5]]},"1471":{"position":[[5,1],[16,2],[19,1],[21,3],[25,5],[36,1],[46,1],[76,2],[102,1],[104,4],[109,2],[112,2],[128,1],[151,1],[156,2],[170,1],[172,3],[176,3],[190,2],[193,5],[199,4],[222,1],[246,1],[274,2],[277,1],[279,3],[283,3],[292,1],[294,2],[309,2],[312,2],[315,6],[322,2],[325,3]]},"1473":{"position":[[6,1],[8,3],[12,3],[22,1],[24,2],[41,1],[43,4],[48,4],[53,3],[57,2],[74,1],[76,3],[80,2],[83,3],[87,2],[90,3],[110,2],[113,5],[119,5],[125,2],[172,2],[215,2],[218,2],[221,2],[258,1],[267,2],[275,1],[286,2],[289,4],[308,2],[311,3],[315,3],[334,3],[350,2],[357,1],[359,2],[362,1],[364,2],[415,1],[422,1],[436,1],[445,1],[447,4],[471,1],[473,5],[479,3],[483,3],[487,4],[492,2],[495,2],[527,1],[543,1],[545,4],[550,2],[566,1],[568,4],[573,3],[577,2],[580,2],[583,2],[600,1],[602,4],[607,3],[638,1],[640,4],[645,2],[668,1],[670,2],[685,1],[699,3],[703,3],[707,3],[711,3],[715,2],[718,3]]},"1475":{"position":[[26,1],[55,2],[58,5],[64,5],[70,4],[75,2],[86,1],[88,4],[93,5],[99,3],[103,1],[105,2],[119,1],[121,2],[124,2],[127,2],[130,2],[133,1],[146,1],[163,2],[166,1],[172,3],[195,1],[212,2],[215,1],[217,3],[236,1],[243,1],[253,2],[271,1],[273,2],[276,2],[298,2],[305,1],[322,1],[324,3],[328,3],[352,2],[370,1],[372,3],[376,3],[391,1],[393,3],[397,1],[399,3],[403,2]]},"1477":{"position":[[3,1],[18,4],[23,1],[39,1],[50,1],[68,2],[71,4],[117,1],[125,1],[127,5],[160,1],[172,1],[174,4],[179,2],[182,6],[193,2],[224,1],[226,2],[269,1],[271,2],[274,2],[280,1],[282,2],[349,1],[351,5],[361,1],[435,1],[437,2],[461,2],[516,2],[523,1],[544,2],[560,1],[639,3],[658,2],[661,2],[678,3],[691,1],[704,2],[717,1],[730,1],[732,3],[736,2],[739,1],[887,1],[889,3],[893,2],[910,1],[912,2],[915,5],[921,5],[927,3],[937,1],[954,1],[956,4],[973,1],[975,2],[982,1],[984,5],[990,3],[994,3],[1010,1],[1012,2],[1015,1],[1040,1],[1042,4],[1047,3],[1051,4],[1056,2],[1059,4],[1064,4],[1069,2],[1091,1],[1098,1],[1117,1],[1119,1],[1121,1],[1123,3],[1127,3],[1157,1],[1159,5],[1165,4],[1170,3],[1182,1],[1184,5],[1190,2],[1225,1],[1227,4],[1253,1],[1255,4],[1260,2],[1263,3],[1267,4]]},"1479":{"position":[[7,1],[17,1],[19,2],[22,4],[27,1],[29,2],[44,1],[46,5]]},"1481":{"position":[[6,1],[27,1],[29,2],[36,1],[45,1],[47,1],[61,1],[84,1],[86,3],[106,1],[108,6],[115,3],[133,1],[155,1],[157,4],[185,1],[187,2],[201,1],[203,2],[206,2],[221,1],[223,3],[234,2],[258,1],[292,1],[294,5],[300,3]]},"1483":{"position":[[32,1],[56,2],[59,2],[85,1],[87,5],[93,4],[122,1],[124,5],[137,2],[140,4],[145,5],[171,1],[196,1],[198,4],[203,2],[206,2],[209,2],[212,4],[217,2],[234,1],[252,1],[254,3],[258,2],[261,2],[264,1],[266,3],[290,1],[292,4],[297,1],[312,1],[350,1],[352,4],[357,2],[360,2],[363,1],[373,1],[375,2],[378,4],[383,3],[387,2],[390,3],[394,2],[397,2],[400,3]]},"1485":{"position":[[22,1],[46,1],[48,4],[53,3],[91,1],[121,1],[123,2],[161,1],[228,1],[333,1],[353,1],[355,3],[359,2],[362,3],[366,3],[393,1],[395,4],[400,2],[403,1],[411,1],[430,2],[450,1],[467,1],[469,2],[485,1],[487,2],[490,4],[495,5],[501,3],[505,3],[536,1],[571,1],[573,3],[577,2],[580,5],[631,1],[657,1],[768,1],[793,1],[822,6],[829,1],[849,1],[868,1],[870,2],[879,1],[899,1],[901,5],[907,4],[912,3],[916,5],[922,2],[931,1],[933,3],[943,2],[955,3],[959,5],[965,2],[968,3],[972,2],[993,1],[1002,3],[1006,3],[1010,2],[1032,1],[1034,4],[1039,2],[1042,5],[1048,4],[1053,2],[1062,1],[1064,2],[1067,2],[1089,1],[1091,2],[1094,2],[1097,3],[1101,5],[1107,3],[1128,1],[1130,2],[1140,1],[1164,1],[1166,1],[1168,5],[1194,2],[1197,5]]},"1487":{"position":[[20,1],[40,1],[42,4],[47,1],[67,1],[79,1],[81,3],[108,1],[110,2],[113,4],[118,2],[121,1],[123,3],[144,1],[162,1],[164,2],[167,3],[171,2],[174,1],[176,5],[182,1],[190,2],[216,1],[218,4],[223,2],[246,1],[248,5],[254,3],[258,1],[278,1],[313,1],[326,1],[328,3],[354,1],[356,2],[419,1],[421,3],[425,1],[433,1],[452,1],[463,3],[467,4],[472,3],[476,2],[479,1],[499,1],[507,2],[533,3],[537,2],[567,1],[569,4],[592,1],[641,1],[742,1],[762,1],[764,3],[768,2],[771,3],[775,3],[800,3],[804,2],[807,2],[833,1],[835,1],[843,1],[878,1],[880,5],[931,1],[957,1],[1082,1],[1084,5],[1096,1],[1098,2],[1101,3],[1111,2],[1123,3],[1127,5],[1133,3],[1137,2],[1140,2],[1161,1],[1181,1],[1190,1],[1192,2],[1195,2],[1210,1],[1232,1],[1234,2],[1237,5]]},"1489":{"position":[[4,2],[45,1],[77,1],[79,3],[83,4],[88,5],[94,3],[98,1],[100,2],[103,3],[115,1],[134,1],[146,2],[149,2],[152,2],[159,1],[161,4],[166,1],[168,3],[204,1],[218,1],[220,5],[226,2],[246,1],[248,2],[251,6],[278,1],[290,1],[306,2],[315,1],[317,2],[320,2],[335,1],[337,2],[352,1],[356,2],[359,4],[372,3],[376,5],[396,2],[399,3],[421,3],[425,4],[442,1],[444,2],[447,2]]},"1492":{"position":[[0,3],[8,2],[25,1],[40,2],[53,1],[55,3],[59,6],[66,2],[69,3],[91,2],[94,2],[135,1],[137,3],[154,2],[157,3],[167,2],[184,1],[202,1],[204,4],[224,1]]},"1494":{"position":[[16,1],[82,1],[84,3],[114,1],[116,3],[132,1],[134,5],[188,1],[212,1],[226,1],[244,1],[255,2],[258,2],[273,2],[305,1],[316,1],[330,1],[346,2],[349,4],[354,2],[368,1],[370,4],[388,5],[394,2],[412,3],[433,2],[443,1],[445,4],[450,2],[462,1],[464,1],[466,2],[469,2],[483,2],[486,2],[525,1],[527,3],[531,2],[534,3],[538,2],[541,5],[601,1],[603,3],[614,1],[616,1],[636,1],[644,1],[646,5],[652,2]]},"1496":{"position":[[0,3],[21,2],[24,3],[46,1],[48,4],[53,2],[56,1],[76,1],[91,4],[96,2],[99,2],[102,2],[110,5],[116,4],[131,1],[147,1],[192,2],[195,2],[236,1],[238,2],[241,2],[244,2],[491,2],[527,1],[529,1],[531,6],[557,1],[584,1],[594,2],[612,2],[615,2],[638,1],[640,4],[671,1]]},"1499":{"position":[[8,1],[27,2],[44,3],[48,5],[66,2],[73,1],[75,4],[80,3],[84,2],[95,1],[116,1],[128,1],[151,1],[192,1],[205,1],[207,2],[232,1],[244,1],[259,2],[262,2],[281,1],[290,1],[306,2],[322,1],[330,1],[332,3],[336,2],[350,1],[366,1],[377,1],[379,6],[394,1],[407,2],[410,3],[414,3],[418,3],[422,5],[428,2],[445,1],[456,1],[458,2],[461,5],[467,4],[476,2],[479,3],[483,1],[485,2],[496,2],[499,4],[512,1],[520,1],[532,2],[547,1],[549,4],[561,3],[565,3],[574,2],[589,1],[591,2],[601,1],[603,2],[635,2],[638,2],[673,1],[682,1],[695,4],[712,2],[753,2],[770,1],[784,3],[794,1],[812,4],[817,2],[824,1],[826,2],[829,2],[832,1],[834,1],[836,3],[849,3],[861,1],[880,2],[883,1],[889,1],[891,4],[921,1],[923,3],[927,2],[930,4],[935,2],[938,1],[940,1],[942,3]]},"1501":{"position":[[8,1],[33,2],[36,1],[38,2],[41,3],[45,1],[52,1],[54,2],[57,3],[73,1],[75,4],[80,3],[97,2],[103,2],[114,1],[116,4],[121,2],[124,3],[136,2],[152,1],[161,2],[180,1],[182,4],[202,2],[205,4],[218,1],[234,1],[236,3],[240,2],[243,5],[260,1],[266,2],[269,3],[273,3],[286,1],[288,2],[295,2],[305,1],[318,4],[337,2],[347,2],[350,1],[359,3],[363,3],[367,4],[372,3],[376,1],[390,1],[392,6],[407,1],[409,4],[428,1],[430,3],[434,6],[441,2],[444,2]]},"1503":{"position":[[8,4],[13,4],[18,3],[22,3],[26,3],[30,4],[35,3],[48,2],[51,1],[53,2]]},"1505":{"position":[[32,1],[34,2],[46,1],[65,1],[67,3],[87,1],[89,2],[92,1],[94,2],[97,3],[109,1],[120,1],[135,2],[160,1],[162,2],[165,1],[167,2],[170,3],[174,4],[179,3],[183,2],[186,2],[189,3],[201,1],[231,1],[240,1],[250,2],[262,1],[264,2],[284,1],[295,1],[327,1],[329,5],[335,2],[346,1],[348,2],[351,3],[376,1],[378,2],[395,1],[404,1],[414,4],[419,2],[422,5],[428,2],[431,3],[450,2],[453,1],[455,1],[457,3],[485,1],[487,3],[499,1],[501,3],[524,2],[532,3],[553,1],[569,1],[579,2],[582,2],[585,3],[605,1],[607,3],[611,3],[615,1],[617,4],[622,2],[625,2],[628,4],[647,3],[651,2],[690,1],[700,3],[704,1],[706,2],[709,2],[712,2],[732,1],[742,1],[773,1],[775,4],[804,1],[813,1],[815,2],[832,1],[847,2],[857,1],[866,1],[868,4],[895,1],[913,1],[915,3],[933,1],[952,1],[971,3],[975,5],[998,1],[1014,1],[1030,1],[1032,3],[1054,4],[1059,3],[1063,2],[1066,3],[1070,3],[1074,2],[1077,3],[1081,3],[1085,4],[1106,1],[1108,3],[1112,2],[1115,2],[1132,1],[1134,5],[1154,1],[1170,2],[1173,3],[1177,3],[1181,2],[1184,3],[1220,3],[1224,3]]},"1507":{"position":[[8,1],[24,2],[56,2],[77,2],[80,5],[100,1],[102,2],[125,3],[152,1],[154,2],[165,1],[177,2],[195,1],[229,1],[231,2],[248,1],[268,2],[271,2],[274,2],[277,4],[282,3],[294,1],[310,1],[312,2],[325,1],[331,1],[340,1]]},"1509":{"position":[[20,1],[55,2],[58,3],[80,1],[82,2],[85,3],[89,2],[100,1],[102,1],[104,2],[122,2],[125,4],[138,2],[141,2],[154,1],[164,1],[188,2],[191,5],[208,1],[230,1],[232,2],[235,2],[238,2],[241,4],[246,1],[248,2],[267,1],[291,1],[293,3],[297,3],[309,1],[311,4],[324,2],[327,3],[331,3],[335,4],[340,2],[353,1],[374,1],[376,4],[381,2],[384,1],[386,2],[389,3],[393,3],[397,2],[400,2]]},"1511":{"position":[[18,3],[22,3],[34,4],[39,3],[43,5],[63,1],[73,1],[75,3],[79,3],[83,4],[88,2],[97,3],[101,3],[157,2],[168,2],[171,3],[183,2],[193,4],[198,1],[200,1],[202,3],[220,1],[230,1],[246,1],[248,3],[252,3],[256,3],[270,4],[275,3],[279,3],[283,4],[288,2],[291,1],[293,1],[295,3],[299,2],[321,1],[323,3],[327,5],[333,2],[336,2],[339,4],[354,2],[357,4],[362,2]]},"1513":{"position":[[21,4],[31,1],[33,3],[37,2],[54,1],[56,3],[82,3],[86,5],[108,1],[110,2],[113,2],[128,2],[139,1],[141,2],[151,2],[170,1],[184,1],[193,1],[195,3],[221,1],[231,2],[234,3],[238,3],[242,3],[263,1],[265,2],[268,3],[272,3],[276,2],[287,1],[315,1],[317,5],[323,2],[341,1],[362,1],[364,4],[377,1],[379,3],[383,3],[406,3],[410,2],[413,2],[416,2],[419,2],[430,1],[462,1],[464,2],[467,2],[470,3],[474,4],[493,1],[512,1],[514,5],[534,1],[555,3],[573,1],[575,5],[589,1],[591,3],[595,3],[616,1],[634,2],[651,2],[654,3],[658,2],[661,2],[672,1],[684,1],[686,2],[689,1],[691,2],[694,2],[697,4]]},"1515":{"position":[[0,1],[2,3],[35,1],[37,2],[54,1],[68,2],[71,1],[73,2],[76,3],[80,3],[84,2],[87,2],[94,3],[98,5],[142,3],[154,2],[157,1],[159,3],[175,1],[189,3],[209,1],[227,2],[240,4],[271,1],[273,4],[278,2],[281,2]]},"1517":{"position":[[0,3],[4,4],[31,3],[35,3],[72,2],[88,1],[90,3],[94,2],[97,3],[111,2],[114,3],[118,2],[121,4],[126,3],[130,2],[133,3],[137,3],[141,2],[144,3],[157,2],[186,2],[189,1],[208,1],[210,5],[216,3],[220,4],[225,1],[227,2],[230,3],[234,2],[237,3],[241,5],[247,4],[252,2],[255,2],[277,5],[312,5],[318,3],[340,4]]},"1521":{"position":[[0,2],[12,3],[30,1],[52,3],[74,1],[76,5],[82,4],[100,1],[119,1],[121,3],[125,4],[130,2],[146,2],[149,2],[169,1],[171,3],[175,2],[178,2],[181,5],[187,1],[189,3],[209,1],[211,3],[215,3],[219,4],[224,2],[227,3],[231,3],[235,2],[238,2]]},"1523":{"position":[[7,3],[23,1],[37,1],[39,4],[61,1],[63,2],[78,2],[89,1],[91,4],[103,2],[106,1],[108,2],[118,1],[132,1],[141,1],[143,5],[149,2],[152,5],[158,2],[173,2],[184,1],[186,2],[194,1],[196,3],[215,1],[229,1],[238,5],[244,1],[246,4],[251,3],[255,3],[259,3],[270,1],[301,1],[303,3],[307,1],[309,3],[313,3],[339,3],[351,1],[353,4],[375,3],[387,1],[389,3]]},"1525":{"position":[[7,1],[17,2],[29,3],[60,1],[92,1],[94,5],[108,2],[111,2],[114,2],[134,1],[136,2],[152,1],[160,1],[162,4],[167,4],[187,1],[189,5]]},"1527":{"position":[[21,2],[24,3],[28,2],[43,1],[45,4],[58,1],[60,3],[64,3],[75,1],[96,2],[99,5]]},"1529":{"position":[[0,2],[3,3],[7,2],[10,3],[14,2],[17,2],[20,1],[22,5],[28,3],[32,6],[39,2],[42,4],[47,3],[51,2],[54,2],[57,2],[60,5],[66,2],[69,2],[74,3],[78,2],[81,3],[85,2],[88,2],[91,2],[105,3],[109,5],[115,2]]},"1531":{"position":[[0,5],[6,2],[9,3],[13,3],[17,3],[21,1],[23,5],[29,2],[32,1],[38,1],[40,2],[43,4],[48,4],[53,3],[57,2],[60,4],[65,2],[90,2],[93,4],[98,1],[100,3],[104,1],[119,2],[122,2],[125,2],[150,2],[153,3],[157,1],[159,3],[163,1],[181,2],[184,2],[187,2],[207,2],[210,2],[213,1],[215,3],[219,1],[235,2],[238,2],[241,2],[244,2],[247,3],[251,3],[255,4],[260,2],[263,2],[266,3],[270,2],[273,1],[275,6],[282,2],[292,1],[297,2],[300,3],[308,2],[311,4],[316,2],[319,2],[322,5],[341,1],[343,2],[346,4],[351,4],[356,4],[361,2],[364,5],[370,4]]},"1533":{"position":[[0,5],[6,2],[9,2],[12,2],[15,1],[17,3],[21,3],[25,2],[28,2],[31,4],[36,2],[39,5],[45,2],[48,5],[71,1],[73,2],[76,2],[79,4],[84,3],[88,2],[91,3],[95,2],[98,3],[102,1],[104,6],[111,2],[114,4],[119,2],[122,5],[128,4],[133,5],[139,5],[145,3],[149,2],[152,4],[157,3],[161,2],[164,3],[168,4],[173,2],[176,3],[180,2],[183,4],[188,4],[193,5]]},"1536":{"position":[[34,2],[37,3],[51,1],[68,1],[70,2],[73,1],[75,3],[79,3],[83,4],[88,1],[105,1],[107,4],[112,3],[116,2],[135,2],[138,3],[142,4],[147,1],[149,3],[153,3],[157,3],[161,3],[165,1],[167,3],[171,4],[214,3],[218,2],[221,4],[226,3],[238,2],[241,3],[245,4],[250,2],[253,2],[256,3],[260,5],[266,5],[272,2],[275,4],[280,4],[294,3],[298,5],[304,5],[310,3],[336,2],[339,3],[343,3],[347,2],[350,5],[356,2],[367,2],[370,3],[395,1],[397,4],[417,1],[419,5],[425,2],[428,3],[432,3],[436,2],[439,4],[444,3],[448,4],[459,2],[462,3],[487,1],[489,5],[513,2],[533,2]]},"1538":{"position":[[0,2],[3,2],[6,1],[8,3],[12,2],[15,4],[20,1],[22,3],[26,4],[31,1],[33,2],[38,2],[73,1],[80,1],[87,1],[105,1],[139,3],[208,3],[277,1],[279,2],[284,1],[286,3],[290,2],[314,1],[325,1],[348,2],[351,2],[354,3],[358,4],[363,2],[366,2],[369,2],[372,2],[375,1],[377,3],[381,2],[384,1],[386,3],[390,2],[436,1],[443,2],[446,2],[449,3],[453,2],[554,3],[563,1],[570,1],[577,1],[584,1],[591,1],[598,2],[607,3],[616,1],[623,2],[639,3],[648,1],[655,1],[662,1]]},"1540":{"position":[[2,2],[5,4],[10,4],[15,2],[18,3],[22,2],[25,1],[27,4],[32,4],[37,3],[41,3],[49,1],[51,3],[55,4],[60,3],[64,3],[68,1],[70,2],[73,6],[82,1],[84,4],[89,4],[123,3],[127,3],[131,2],[134,5],[153,2],[156,4],[161,2],[164,1],[166,4],[171,4],[176,3],[180,2],[295,2],[298,1],[300,4],[305,2],[308,3],[312,3],[328,1],[340,1],[342,5],[348,3],[352,3],[356,4],[361,2],[368,1],[370,2],[373,3],[377,2],[380,3],[384,3],[388,1],[390,3],[394,2],[401,1],[411,1],[445,1],[467,2],[485,2],[508,2]]},"1542":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1],[83,2],[86,2],[89,1]]},"1544":{"position":[[0,1],[2,3],[15,3],[19,3],[29,1],[31,4],[36,3],[40,1],[42,3],[46,2],[49,3],[53,3],[57,4],[62,3],[66,2],[69,4],[74,3],[78,4],[83,1],[85,5],[91,2],[94,3],[98,5],[104,4],[109,1],[118,1],[131,1],[133,3],[144,1],[146,3],[150,3],[154,5],[160,2],[163,2],[166,4],[177,1],[200,3],[204,2],[214,1],[216,3],[220,2],[238,2],[241,2],[244,3],[248,4],[253,2],[256,3],[260,3],[274,1],[276,3],[280,2],[283,3],[287,2],[290,3],[306,1],[308,4],[313,1],[315,3],[330,2],[338,2],[346,5],[352,3],[356,3],[360,5],[366,6]]},"1546":{"position":[[0,3],[32,1],[34,4],[39,4],[44,4],[49,4],[54,3],[58,4],[63,3],[67,4],[72,2],[75,1],[77,3],[81,3],[85,2],[88,3],[92,3],[96,3],[100,6],[107,1],[109,1],[111,3],[115,3],[119,4],[124,3],[128,4],[133,3],[137,3],[141,3],[145,2],[157,1],[159,2],[162,3],[166,4],[171,3],[199,1],[201,2],[214,4],[219,3],[223,4],[228,3],[259,1],[267,1],[279,2],[282,2],[300,2],[303,5],[309,3],[313,1],[320,1],[322,1],[324,2],[341,3],[345,3],[349,3],[358,6],[365,3],[369,5],[375,2],[384,1],[413,4],[418,4],[430,2],[433,3],[437,1],[439,3],[461,2],[464,2],[467,1],[472,1],[491,2],[494,2],[497,2],[500,1],[502,3],[512,1],[514,6],[521,4],[551,1],[553,4],[558,2],[561,3],[565,3],[569,3],[573,4],[584,4],[601,3],[605,1],[607,2],[622,1],[630,1],[645,1],[647,2],[662,1],[670,1],[681,1],[683,2],[686,3],[690,3],[699,1],[701,3],[705,3],[709,2],[731,6],[747,1],[749,2],[758,2],[765,1],[767,2],[783,1],[785,2],[800,1],[813,5],[825,2],[828,2],[831,3],[835,3],[839,4],[849,1],[851,4],[856,2],[859,5],[865,2],[868,3],[872,3],[893,2],[896,2],[932,6],[945,1],[947,4],[952,2],[955,3],[959,5],[969,1],[983,3],[1002,1],[1004,3],[1008,4],[1013,2],[1016,3],[1020,2],[1023,4],[1028,4],[1033,2],[1036,4],[1041,4],[1046,4],[1051,3],[1055,2],[1058,6],[1077,1],[1079,3],[1083,3],[1087,4],[1092,2],[1107,1],[1126,1],[1128,3],[1132,4],[1137,2],[1140,4],[1145,2],[1160,1],[1162,3],[1166,3],[1170,3],[1174,2],[1192,2],[1195,2],[1198,4],[1203,3],[1207,4],[1212,3],[1216,4],[1221,4],[1226,1],[1228,4],[1233,3],[1237,4],[1242,2],[1245,3],[1249,3],[1253,1],[1255,2],[1258,2],[1261,4],[1266,2]]},"1550":{"position":[[0,4],[5,2],[8,1],[10,2],[13,3],[17,4],[22,3],[26,4],[31,3],[53,2],[56,6],[63,3],[67,3],[71,2],[91,1],[113,2],[128,2],[131,4],[136,3],[153,2],[156,2],[166,1],[168,5],[174,4],[179,2],[182,2],[185,5],[191,2],[194,2],[197,2],[213,1],[215,2],[222,1],[237,1],[239,2],[249,1],[251,3],[258,1],[264,5],[270,4],[293,1],[295,5]]},"1552":{"position":[[0,1],[2,3],[6,6],[24,1],[26,3],[42,1],[44,4],[49,3],[53,2],[68,1],[70,3],[74,2],[77,5],[83,3],[94,1],[96,5],[102,5],[108,1],[110,3],[114,3],[118,3],[122,4],[127,2],[151,2],[154,3],[158,5],[164,2],[167,5],[173,3],[181,3],[192,1],[194,4],[199,5],[211,1],[213,3],[232,1],[234,6],[241,4],[246,4],[251,1],[262,1],[276,1],[278,2],[281,4],[286,4],[291,2],[305,1],[319,1],[333,5],[339,3],[343,5],[349,5],[355,2],[358,3],[362,4],[374,1],[376,5],[382,2],[385,1],[387,3],[391,5],[397,4],[414,1],[416,5],[426,3],[430,4],[435,3],[460,3],[464,4],[469,4],[474,3],[478,3],[482,4],[487,3],[491,2],[511,3],[515,3],[536,1],[538,2],[547,2],[550,3]]},"1554":{"position":[[0,2],[8,1],[10,1],[12,3],[16,3],[20,4],[25,4],[30,3],[54,1],[68,1],[70,3],[89,2],[99,1],[194,1],[196,4],[201,3]]},"1556":{"position":[[7,1],[17,2],[25,2],[28,2],[31,2],[34,3],[38,2],[41,2],[44,2]]},"1558":{"position":[[0,3],[30,1],[38,1],[40,5],[52,1],[54,3],[58,4],[63,3],[67,4],[72,2],[75,4],[96,1],[98,5],[104,1],[106,5],[118,1],[120,1],[122,3],[126,3],[130,5],[185,2],[188,3],[192,4],[197,2],[206,1],[220,3],[224,2],[227,4],[232,3],[236,5],[300,4],[314,1],[316,4],[321,2],[328,3],[332,2],[339,3],[351,3],[355,2],[363,1],[373,2],[376,2],[379,2],[390,2],[393,5],[399,1],[401,2],[404,3],[408,4],[422,1],[424,4],[429,3],[433,3],[437,3],[441,2],[444,2],[447,2],[475,3],[479,3],[501,1],[503,4],[508,2],[518,1],[529,1],[531,4],[550,1],[552,5],[558,6],[573,1],[575,5],[587,1],[589,2],[592,1],[594,5],[613,1],[615,2],[632,1],[634,5],[717,1],[776,1],[790,1],[919,1],[932,1],[934,2],[940,1],[957,4],[971,1],[973,3],[990,1],[1001,1],[1012,1],[1014,1],[1016,3],[1020,4],[1025,3],[1033,1],[1035,3],[1039,3],[1043,4],[1056,1],[1058,3],[1062,3],[1071,1],[1076,1],[1092,3],[1124,3],[1141,1],[1143,2],[1146,2],[1153,5],[1159,2],[1162,1],[1167,4],[1172,2],[1175,1],[1192,1],[1197,2],[1200,3],[1204,3],[1208,3],[1212,3],[1220,1],[1222,4],[1231,1],[1237,3],[1253,3],[1257,2],[1264,5],[1270,2],[1273,3],[1277,3],[1281,3],[1298,1],[1321,1],[1323,5],[1329,2],[1340,1],[1342,4],[1359,1],[1380,1],[1382,4],[1396,3],[1446,1],[1458,1],[1517,1],[1595,2],[1601,1],[1615,1],[1617,1],[1619,1],[1626,1],[1733,1],[1745,1],[1806,1],[1808,3],[1840,1],[1899,1],[1934,1],[1946,3],[1964,1],[1983,2],[1990,2],[2002,1],[2015,2],[2027,1],[2034,1],[2036,4],[2053,1],[2063,3],[2067,2],[2084,3],[2094,1],[2100,2],[2103,3],[2107,2],[2110,2],[2125,1],[2136,6],[2154,1],[2168,1],[2170,2],[2173,2]]},"1560":{"position":[[8,3],[12,2],[15,2],[18,3],[30,2],[43,1],[45,3],[49,4],[54,3],[58,3],[62,3],[66,3],[80,1],[82,3],[86,6],[93,4],[98,5],[104,5],[110,3],[114,2],[117,3],[121,3],[125,3],[129,3],[133,3],[137,2],[140,2],[143,3],[147,4],[152,3],[156,3],[160,5],[166,3],[196,3],[208,1],[210,4],[215,5],[229,3],[241,2],[244,3],[248,3],[252,1],[254,3],[258,3],[262,1],[264,5],[270,3],[274,4],[279,3],[283,4],[288,5],[294,2],[297,3],[301,4],[306,4],[311,4],[323,4],[328,1],[340,2],[343,3],[347,3],[351,2],[354,3],[358,1],[360,1],[362,3],[366,2],[369,2],[372,1],[374,2],[377,4],[382,4],[387,5],[393,4],[398,3],[402,3],[406,2],[409,3],[413,2],[416,2],[430,4],[435,2],[447,4],[467,2],[470,3],[474,4],[479,3],[483,3],[487,2],[490,2],[525,2],[533,1],[544,1],[546,4],[551,2],[554,5],[560,4]]},"1563":{"position":[[0,4],[11,1],[13,4],[30,1],[32,3],[36,1],[38,2],[41,2],[44,4],[49,4],[54,2],[57,3],[61,3],[65,1],[67,4],[72,3],[76,2],[83,6],[102,1],[104,3],[108,4],[113,2]]},"1565":{"position":[[12,3],[22,2],[25,5],[31,3],[47,3],[57,2],[69,1],[71,2],[74,6],[86,2],[89,4],[94,2],[114,1],[116,4],[121,2],[128,5],[134,2],[137,3],[141,3]]},"1567":{"position":[[12,1],[31,4],[36,3],[40,3],[44,4],[49,4],[54,1],[56,1],[58,2],[61,2],[76,1],[78,3],[82,3],[86,3],[90,1],[92,3],[96,3],[100,4],[105,3],[109,2],[112,2],[115,3],[119,2],[122,3],[126,5],[132,4],[137,4],[142,3],[146,2],[149,2],[152,3],[156,3],[160,2],[163,3],[167,4],[172,2],[175,1],[177,2],[180,3],[184,3]]},"1570":{"position":[[0,2],[3,4],[8,3],[17,2],[20,3],[24,2],[27,4],[46,1],[48,5],[54,2],[57,5],[63,1],[79,1],[91,3],[95,4],[100,2],[103,6],[110,3],[124,3],[133,1],[135,4],[140,4],[151,2],[154,2],[157,2],[160,4],[165,3],[184,3],[188,3],[192,5],[198,3],[202,1],[204,5],[216,3],[220,4],[225,1],[227,3],[231,3],[235,2],[244,1],[246,5],[252,3],[268,2],[271,5],[277,3],[313,1],[375,2],[378,4],[383,2],[386,4],[391,3],[395,1],[397,2],[400,3],[417,2],[420,2],[423,2],[426,2],[429,4],[434,2]]},"1573":{"position":[[12,1],[14,3],[18,11],[30,2],[48,1],[50,2],[53,4],[58,1],[75,1],[77,4],[82,3],[86,3],[90,3],[94,3],[98,2],[101,2],[104,2],[107,3],[111,4],[116,2],[131,1],[133,3],[145,3],[149,3],[153,4],[158,2],[161,1],[163,3],[174,1],[176,3],[180,3],[213,1],[215,3],[231,1],[233,2],[236,3],[240,2],[243,3],[247,5],[253,3],[257,3],[261,4],[266,3],[270,1],[272,3],[276,3],[285,3],[289,4],[294,5],[300,3],[316,1],[318,3],[322,3],[332,2],[335,1],[343,1],[345,3],[349,4]]},"1575":{"position":[[8,1],[22,1],[24,3],[28,2],[31,5],[44,1],[46,3],[50,2],[53,3],[57,3],[61,4],[66,2]]},"1577":{"position":[[12,1],[14,3],[32,6],[39,3],[43,4],[48,2],[51,4],[76,1],[111,1],[116,1],[118,4],[123,3],[127,3]]},"1579":{"position":[[8,1],[10,3],[14,3],[18,6],[25,4],[30,2],[33,2],[39,2],[42,1],[44,3],[48,3],[52,2],[55,1],[57,5],[63,4],[68,4],[73,3],[77,1],[79,2],[82,3],[86,2],[89,4],[94,3],[98,3],[102,2],[105,2],[108,2],[111,3],[115,3],[119,3],[123,3],[127,1],[129,2],[132,3],[136,2],[139,3],[143,3],[154,1],[156,2],[159,3],[163,2],[166,1],[168,3],[172,2],[175,4],[180,3],[184,3],[188,3],[192,4],[197,4],[202,2],[205,2],[208,4],[213,3],[217,3],[221,3],[225,2],[228,3],[232,3],[236,5],[242,2],[245,3],[249,3],[253,2],[256,3],[260,4],[265,4],[270,5],[276,5],[282,5],[288,3],[292,3],[296,2],[299,4],[304,4],[324,1],[326,5]]},"1589":{"position":[[40,1],[42,4],[47,3],[54,4],[77,3],[81,1],[83,3],[90,6],[114,2],[117,3],[123,6],[148,2],[151,1],[153,3],[159,2],[166,2],[169,1],[189,2],[192,1],[194,3],[200,2],[205,2],[208,5],[214,5],[238,3],[242,1],[244,2],[251,2],[254,3],[275,3],[279,1],[283,2],[288,1],[290,5]]},"1593":{"position":[[55,1]]},"1595":{"position":[[186,1],[333,1],[335,1],[354,1],[374,1],[459,2],[462,2],[465,2]]},"1606":{"position":[[138,1],[140,1],[155,1],[165,1],[174,1],[176,1],[207,2],[210,2],[213,2],[216,2],[219,2]]},"1610":{"position":[[89,1],[124,1],[166,1]]},"1612":{"position":[[173,1],[182,1],[254,2],[257,1]]},"1614":{"position":[[78,1]]},"1618":{"position":[[180,2]]},"1624":{"position":[[137,1],[146,1],[176,1],[178,1],[180,3],[245,1],[283,1]]},"1626":{"position":[[114,3],[163,3]]},"1628":{"position":[[127,1],[149,2],[152,1],[266,2],[281,2],[284,1],[349,3],[372,2],[439,1],[502,1],[529,1],[553,1]]},"1632":{"position":[[98,1],[100,1],[108,1],[154,2],[157,2]]},"1638":{"position":[[138,1],[140,1],[155,1],[165,1],[174,1],[176,1],[202,2],[205,2],[208,2],[211,2],[214,2]]},"1642":{"position":[[0,2],[3,1],[5,3],[9,3]]},"1644":{"position":[[0,3],[39,1],[56,1],[67,1],[69,5],[75,2],[92,1],[94,2],[97,5],[117,1],[144,1],[173,2],[207,1],[209,2],[212,3],[216,6],[230,2],[233,3],[237,4],[242,3],[254,2],[257,2],[260,2],[263,3],[267,2],[270,3],[274,3],[278,4],[283,3],[313,1],[315,2],[318,4],[331,1],[333,3],[337,3],[351,1],[353,5],[359,1],[361,4],[366,3],[390,1],[408,1],[416,4],[430,3],[434,1],[436,1],[444,1],[446,2],[461,1],[463,5],[474,1],[476,4],[481,2],[496,1],[498,5],[504,3],[508,2],[552,1],[554,5],[560,4],[585,1],[587,5],[597,1],[607,3],[611,3],[615,1],[617,3],[621,2],[633,1],[635,1],[637,5],[682,1],[706,1],[708,3],[748,2],[751,3],[755,5],[761,3],[769,1],[779,1],[805,1],[807,4],[812,2],[815,5],[835,1],[843,3],[847,4],[852,5]]},"1646":{"position":[[5,1],[7,4],[16,4],[21,4],[46,1],[80,1],[98,1],[108,1],[110,1],[112,3],[135,1],[149,3],[158,1],[175,1],[177,3],[201,1],[203,5],[221,1],[223,4],[228,5],[234,2],[237,5],[262,1],[264,5],[283,1],[297,2],[328,2],[331,4],[341,1],[343,2],[363,1],[378,3],[394,2],[409,1],[432,1],[531,1],[533,3],[555,5],[561,1],[577,1],[596,1],[614,1],[627,2],[630,2],[633,3],[637,1],[639,3],[643,2],[646,2],[669,1],[671,4],[676,3],[694,1],[696,4],[701,4],[706,4],[718,1],[729,1],[746,2],[749,6],[766,2],[769,4],[802,1],[804,4],[809,4],[827,1],[844,1],[846,4],[851,2],[860,1],[871,1],[873,5],[899,1],[928,2],[931,3],[935,1],[937,3],[956,1],[981,1],[983,2],[1000,1],[1002,3],[1006,6],[1062,1],[1088,1],[1090,2],[1125,1],[1127,2],[1130,2],[1148,1],[1162,1],[1164,2],[1172,1],[1174,2],[1185,2],[1199,1],[1201,4],[1215,2],[1227,2],[1230,3],[1234,1],[1236,3],[1254,1],[1283,2],[1286,2],[1320,2],[1323,2],[1326,3],[1330,6],[1350,1],[1352,2],[1361,4],[1366,3],[1378,1],[1380,4],[1385,2],[1388,3],[1402,1],[1404,3],[1420,1],[1422,4],[1427,3],[1431,4],[1436,2],[1439,3],[1474,1],[1500,1],[1507,2],[1510,1],[1528,2],[1550,1],[1552,4],[1557,2],[1560,5],[1591,1],[1624,1],[1626,2],[1629,2],[1641,1],[1643,3],[1647,3],[1663,1],[1665,5],[1671,4],[1676,1],[1678,4],[1683,4],[1698,2],[1709,1],[1711,4],[1716,4],[1721,4],[1726,3],[1753,1],[1755,3],[1759,3],[1763,2],[1766,2],[1769,2],[1772,3],[1776,5],[1782,2],[1785,4],[1800,2],[1826,2],[1841,1],[1843,4],[1848,4],[1853,3],[1870,1],[1872,5],[1878,2],[1881,2],[1884,5],[1890,3],[1894,5],[1900,1],[1902,6],[1935,1],[1937,3],[1947,1],[1949,2],[1972,1],[1974,5],[1987,2],[2010,1],[2012,5],[2018,2],[2026,1],[2049,1],[2060,2],[2068,1],[2080,1],[2094,3],[2098,3],[2107,1],[2109,4],[2114,2],[2117,2],[2131,1],[2133,4],[2138,5],[2150,1],[2152,2],[2167,1],[2169,5],[2175,2],[2192,1],[2194,4],[2203,1],[2205,1],[2207,2],[2210,3],[2214,3],[2264,1],[2281,3],[2285,3],[2289,3],[2293,3],[2321,2],[2324,2],[2327,3],[2350,1],[2365,3],[2369,4],[2374,2],[2377,5],[2399,1],[2401,4],[2414,1],[2416,3],[2420,1],[2422,3],[2426,3],[2443,1],[2445,4],[2450,2],[2453,3],[2466,2],[2490,1],[2492,5],[2512,1],[2536,2],[2539,2],[2548,4],[2553,3],[2557,2],[2560,3],[2571,3],[2575,2],[2594,2],[2618,1],[2629,3],[2633,3],[2637,2],[2640,3],[2644,3],[2648,4],[2653,3],[2657,2],[2660,1],[2662,3],[2704,1],[2712,1],[2714,2],[2717,2],[2729,1],[2743,1],[2745,4],[2750,4],[2755,4],[2783,1],[2785,4],[2790,3],[2809,1],[2811,4],[2816,2],[2825,1],[2827,2],[2830,3],[2834,1],[2836,3],[2855,1],[2870,3],[2882,3],[2886,2],[2895,1],[2897,4],[2902,2],[2905,1],[2907,5],[2913,4],[2918,3],[2922,4],[2927,3],[2931,5],[2937,1],[2939,4],[2948,3],[2952,2],[2980,1],[2982,6],[3004,1],[3018,1],[3035,1],[3042,1],[3044,2],[3047,2],[3050,3],[3058,3],[3062,3],[3066,3],[3109,1],[3133,1],[3135,3],[3175,2],[3178,3],[3182,4],[3187,2],[3190,3],[3198,1],[3220,1],[3246,1],[3248,5],[3275,1],[3277,3],[3302,1],[3304,2],[3312,3],[3316,3],[3320,4],[3325,5],[3331,5]]},"1649":{"position":[[32,1],[34,2],[37,4],[50,3],[54,4],[59,5],[65,3],[69,3],[78,1],[80,2],[100,1],[114,2],[117,1],[131,1],[133,4],[142,1],[144,5],[150,3],[154,3],[163,1],[165,1],[167,2],[170,3],[174,2],[183,1],[185,2],[200,1],[202,5]]},"1651":{"position":[[4,1],[29,1],[31,3],[35,3],[63,1],[65,3],[78,2],[101,1],[119,4],[124,6],[147,1],[149,4],[163,1],[185,1],[187,2],[190,3],[194,5],[200,4],[205,3],[229,1],[231,5],[237,3],[250,1],[272,2],[294,1],[296,4],[301,1],[303,2],[306,3],[310,3],[314,2],[361,1],[363,2],[401,1],[403,3],[412,1],[414,3],[457,2],[472,1],[474,1],[476,3],[480,1],[515,1],[532,1],[534,2],[537,3],[541,5],[547,3],[551,5],[557,3],[584,1],[586,4],[595,1],[604,2],[607,5],[652,1],[654,4],[663,1],[669,1],[678,2],[681,3],[685,1],[687,3],[691,6],[698,3],[702,2],[705,3],[709,4],[732,5],[738,1],[740,2],[743,2],[770,1],[772,3],[780,1],[813,1],[849,1],[851,4],[867,1],[869,5],[889,1],[901,1],[903,3],[913,1],[915,4],[925,1],[927,3],[931,2],[934,2],[937,4],[942,3],[946,1],[948,3],[959,2],[962,4],[991,1],[993,3],[1010,1],[1016,1],[1034,3],[1038,4],[1043,3],[1047,4],[1052,2],[1055,3],[1059,2],[1062,4],[1067,1],[1069,3],[1157,1],[1265,2],[1268,1],[1436,1],[1459,1],[1461,4],[1466,2],[1469,2],[1512,1],[1523,2],[1526,3],[1530,3],[1534,4],[1539,2],[1542,2],[1545,3],[1549,3],[1559,1],[1561,2],[1564,3],[1568,5],[1593,1],[1595,4],[1600,2],[1638,1],[1652,1],[1654,5]]},"1653":{"position":[[6,1],[18,1],[20,4],[25,2],[33,1],[58,1],[60,4],[65,4],[87,1],[89,4],[100,2],[124,1],[132,1],[166,1],[168,2],[171,2],[174,4],[179,1],[181,3],[185,5],[201,2],[204,5],[210,4],[215,4],[220,5],[248,1],[250,3],[272,1],[289,1],[298,2],[301,3],[305,3],[309,2],[312,1],[314,1],[322,1],[324,4],[329,2],[339,1],[341,3],[345,4],[363,2],[376,1],[378,3],[382,3],[386,3],[390,2],[393,3],[419,1],[421,4],[432,2],[435,2],[449,1],[451,2],[454,4],[459,2],[462,1],[464,4],[476,1],[491,2],[494,3],[498,3],[502,3],[506,2],[509,1],[511,3],[515,1],[523,1],[525,3],[560,1],[590,3],[594,4],[599,1],[601,3],[605,2],[608,2],[611,3],[615,3],[619,1],[621,3],[625,1],[633,1],[635,2],[667,1],[669,4],[674,2],[677,2],[692,1],[694,2],[697,3],[701,1],[703,3],[722,2],[725,3],[729,5],[774,1],[798,1],[800,3],[804,5],[810,5],[816,1],[818,4],[842,1],[844,4],[849,1],[851,3],[855,3],[859,3],[863,3],[867,2],[870,1],[872,1],[874,3],[884,1],[886,3],[890,4],[901,1],[903,4],[908,2],[924,3],[951,3],[955,1],[957,3],[977,1],[979,4],[984,4],[989,2],[992,3],[996,1],[998,3],[1002,1],[1004,3],[1033,1],[1045,1],[1047,4],[1052,1],[1054,3],[1058,3]]},"1655":{"position":[[0,1],[2,2],[5,2],[32,1],[34,2],[48,1],[50,4],[55,5],[61,4],[73,3],[77,5],[94,2],[106,1],[123,2],[126,5],[132,4],[137,2],[140,3],[154,5],[192,1],[194,3],[214,1],[225,1],[236,2],[248,2],[251,3],[255,1],[257,3],[275,4],[296,1],[311,1],[313,3],[317,1],[319,3],[338,4],[359,1],[376,1],[378,4],[383,1],[385,3],[389,1],[391,3],[419,1],[421,2],[424,3],[451,1],[453,2],[498,1],[500,4],[505,2],[508,3],[526,1],[541,1],[543,1],[578,1],[593,1],[595,1],[603,2],[623,1],[638,1],[640,3],[644,1],[646,4],[660,1],[667,1],[669,3],[673,1],[675,3],[688,1],[714,1],[746,1],[768,1],[785,1],[787,3],[791,2],[794,4],[799,1],[801,3],[818,4],[895,1],[909,1],[911,2],[928,1],[930,4],[935,1],[943,2],[946,1],[970,1],[972,2],[1143,1],[1145,3],[1165,1],[1187,1],[1204,1],[1212,1],[1214,5],[1220,1],[1222,2],[1225,3],[1229,3],[1233,2],[1236,3],[1251,5],[1284,2],[1287,2],[1290,3],[1294,1],[1296,2],[1299,3],[1303,3],[1354,2],[1357,3],[1361,1],[1363,3],[1391,2],[1394,3],[1398,3],[1402,1],[1413,2],[1416,3],[1420,3],[1424,4],[1429,1],[1431,3],[1435,1],[1437,3],[1441,2],[1481,1],[1506,1],[1508,2],[1544,1],[1601,6],[1608,2],[1611,6],[1646,1],[1668,1],[1685,1],[1687,3],[1691,2],[1694,4],[1699,1],[1701,3],[1720,12],[1814,1],[1833,1],[1835,2],[1840,1],[1846,1],[1848,4],[1853,4],[1858,4],[1863,1],[1871,2],[1874,1],[1903,1],[1905,2],[2079,3],[2089,1],[2108,1],[2130,3],[2134,2],[2143,1],[2145,5],[2151,5],[2175,1],[2198,1],[2200,3],[2204,3],[2214,1],[2233,2],[2236,3],[2265,1],[2267,4],[2272,2],[2275,3],[2291,1],[2293,3],[2297,1],[2299,3]]},"1657":{"position":[[0,3],[4,2],[7,4],[12,2],[15,5],[21,1],[23,3],[27,3],[119,1],[170,1],[221,1],[259,1],[311,1],[351,1],[353,2],[356,3],[360,3],[364,2],[367,2],[370,2],[373,3],[377,5],[395,1],[397,2],[400,4],[405,3],[409,2],[412,2],[415,4],[432,1],[434,4],[439,3],[465,1],[467,4],[472,3],[476,1],[478,4],[483,3],[487,3],[491,5],[525,5],[531,4],[536,2],[561,1],[575,1],[577,2],[580,5],[586,3],[597,2],[605,1],[613,1],[627,1],[629,4],[634,3],[654,1],[656,3],[660,3],[772,1],[779,1],[834,1],[836,2],[839,1],[841,2],[846,1],[886,1],[899,1],[908,1],[914,2],[1072,1],[1086,1],[1135,1],[1137,3],[1141,3],[1357,1],[1405,4],[1410,2],[1432,1],[1467,4],[1472,2],[1494,1],[1538,2],[1560,1],[1595,4],[1600,2],[1622,1],[1670,4],[1888,1],[1918,1],[1920,3],[1924,3],[1943,1],[1945,2],[1965,1],[1967,4],[1972,4],[1977,3],[1981,2],[2067,1],[2098,1],[2170,1],[2281,1],[2296,1],[2315,1],[2338,1],[2350,1],[2391,1],[2437,1],[2439,4],[2444,4],[2455,1],[2462,1],[2471,2],[2482,1],[2484,5],[2490,3],[2494,1],[2496,3],[2500,2],[2503,4],[2508,1],[2510,2],[2513,3],[2541,1],[2543,2],[2551,1],[2553,2],[2574,1],[2576,5],[2582,1],[2584,3],[2588,3],[2596,1],[2618,1],[2620,3],[2624,3],[2770,2],[2843,1],[2877,2],[2910,2],[2955,1],[2978,2],[3011,2],[3211,1],[3219,1],[3221,4],[3226,2]]},"1659":{"position":[[0,2],[3,6],[44,1],[46,4],[51,1],[59,1],[79,1],[81,4],[86,4],[91,4],[96,2],[99,1],[101,3],[119,1],[121,3],[159,1],[161,4],[166,2],[169,2],[178,1],[198,2],[209,2],[219,2],[229,1],[231,2],[234,3],[238,2],[241,3],[245,4],[250,2],[253,5],[259,4],[290,1],[292,2],[295,3],[299,3],[310,2],[313,4],[318,2],[334,1],[336,5],[342,2],[351,1],[353,3],[375,1],[377,4],[382,2],[385,3],[389,1],[391,3],[395,3],[410,1],[412,4],[417,3],[421,1],[429,1],[431,2],[434,3],[450,1],[452,4],[457,2],[460,4],[465,6],[472,6],[498,1],[500,4],[505,2],[547,3],[551,2],[554,3],[567,1],[581,1],[604,1],[622,2],[662,1],[664,2],[685,2],[729,2],[732,5],[764,1],[766,3],[776,1],[778,2],[781,2],[813,1],[855,1],[857,3],[861,2],[864,3],[948,1],[959,1],[1039,1],[1041,1],[1054,1],[1056,4],[1061,4],[1095,4],[1100,2],[1118,1],[1122,1],[1124,2]]},"1663":{"position":[[0,1],[2,4],[31,1],[33,3],[37,4],[42,3],[46,2],[49,1],[51,2],[54,5],[60,2],[70,1],[72,2],[75,2],[78,2],[81,4],[129,1],[131,2],[141,1],[150,1],[152,4],[157,3],[161,5],[180,1],[182,5],[196,1],[207,1],[209,2],[212,3],[216,2],[228,1],[237,1],[239,2],[242,3],[246,2],[256,1],[258,2],[261,4],[290,3]]},"1665":{"position":[[24,1],[26,2],[29,4],[34,4],[43,2],[99,1],[101,2],[104,4],[109,4],[124,1],[134,1],[142,1],[144,3],[148,1],[150,1],[152,3],[182,1],[206,1],[208,4],[213,2],[216,1],[218,3],[239,3],[267,1],[274,1],[288,3],[292,3],[296,3],[300,2],[303,1],[305,2],[308,3],[312,3],[336,1],[338,2],[349,1],[357,1],[359,4],[364,2],[394,1],[396,2],[399,2],[409,3],[413,3],[417,3],[421,5],[427,4],[432,5],[462,1],[480,1],[487,1],[489,5],[495,2],[498,5],[504,4],[534,1],[540,1],[551,2],[554,3],[634,1],[650,1],[658,1],[660,4],[694,3],[698,1],[700,1],[713,1],[731,1],[733,4],[738,4],[743,2],[746,3],[750,4],[762,1],[764,4],[769,2],[783,1],[809,1],[811,2],[823,1],[825,3],[829,1],[856,1],[858,5],[864,2],[897,1],[910,1],[938,1],[940,4],[945,1],[962,1],[964,3],[980,1],[982,4],[987,3],[1010,1],[1012,3],[1016,1],[1018,3],[1030,2],[1033,3],[1069,1],[1071,1],[1073,2],[1085,3],[1089,5],[1099,1],[1101,4],[1114,2],[1143,1],[1145,5],[1155,1],[1170,1],[1188,1],[1190,4],[1195,2],[1198,4],[1218,1],[1220,2],[1223,4],[1228,4],[1260,1],[1271,3],[1275,4],[1348,1],[1350,3],[1354,3],[1358,4],[1373,1],[1375,2],[1392,1],[1394,2],[1410,1],[1427,2],[1430,6],[1451,1],[1462,2],[1465,2],[1468,2],[1479,1],[1481,3],[1485,4],[1490,3],[1494,2],[1508,2],[1511,1],[1513,3],[1517,4],[1522,2],[1538,1],[1540,4],[1548,5],[1554,2],[1557,3],[1561,4]]},"1667":{"position":[[4,1],[6,2],[9,2],[12,2],[15,3],[27,2],[30,5],[36,3],[40,4],[45,3],[98,1],[120,1],[122,3],[126,3],[130,3],[134,2],[137,1],[139,3],[143,3],[164,1],[166,8],[187,1],[216,1],[218,1],[220,4],[225,2],[228,5],[261,2],[264,2],[282,1],[295,1],[297,4],[302,3],[311,5],[341,1],[382,1],[384,2],[387,2],[390,3],[394,4],[399,2],[432,1],[434,4],[439,2],[442,5],[448,5],[454,4],[459,3],[467,1],[481,2],[484,5],[507,1],[509,3],[523,1],[525,3],[529,4],[534,4],[539,2],[542,5],[572,5],[583,1],[594,1],[596,2],[599,5],[605,1],[607,2],[610,3],[614,2],[617,1],[619,3],[623,2],[638,4],[643,3],[647,5],[663,1],[683,2],[686,4],[691,5],[697,3],[710,1],[716,1],[731,4],[760,1],[773,1],[775,4],[796,2],[809,1],[823,3],[827,1],[829,4],[858,1],[860,2],[867,1],[869,4],[874,5],[880,2],[883,4],[888,2],[891,4],[896,2],[899,5],[909,1],[911,2],[923,2],[926,4],[931,2],[934,2],[937,2],[966,1],[968,4],[980,2],[983,3],[987,2],[990,4],[995,2],[998,4],[1003,5],[1022,3],[1030,1],[1032,3],[1060,1],[1062,3],[1066,1],[1068,3],[1072,4],[1093,1],[1095,2],[1108,1],[1110,3],[1114,4],[1119,2],[1122,5],[1128,2],[1131,5],[1137,4],[1154,1],[1156,4],[1165,1],[1191,1],[1193,1],[1195,1],[1197,3],[1201,1],[1203,3]]},"1669":{"position":[[8,1],[12,3],[24,1],[31,1],[44,1],[46,4],[51,2],[54,2],[57,3],[61,4],[66,2],[69,5],[75,2],[90,1],[92,5],[102,1],[115,1],[117,3],[121,3],[125,3],[129,1],[131,3],[135,4],[144,1],[146,4],[169,2],[172,4],[177,3],[181,5],[191,1],[193,2],[222,2],[225,4],[237,1],[256,1],[258,5],[279,2],[294,1],[296,5],[302,3],[317,1],[343,1],[345,4],[350,4],[364,1],[376,4],[407,1],[409,3],[420,1],[422,4],[427,4],[432,4],[437,3],[459,5],[465,5],[544,1],[563,1],[565,3],[569,3],[586,1],[596,2],[599,1],[601,3],[605,1],[611,2],[633,1],[639,2],[663,1],[665,5],[671,3],[675,2],[687,2],[690,5],[700,1],[736,1],[738,5],[744,5],[750,5],[756,2],[759,3],[780,1],[782,5],[796,3],[804,1],[828,1],[830,4],[854,3],[858,3],[862,5],[868,3],[891,1],[902,1],[912,1],[946,1],[948,5],[958,1],[969,5],[975,5],[981,1],[983,2],[986,3],[990,5],[996,2],[999,4],[1021,1],[1023,2],[1035,2],[1042,1],[1044,1],[1046,2],[1049,3],[1053,4],[1077,1],[1089,1],[1091,5],[1113,1],[1131,3],[1135,3],[1139,1],[1141,3],[1145,1],[1147,1],[1149,3]]},"1672":{"position":[[8,3],[12,2],[17,2],[28,2],[31,3],[35,2],[46,1],[48,4],[53,1],[55,2],[58,2],[74,2],[116,3],[137,1],[143,2],[169,1],[193,2],[196,3],[200,4],[210,1],[212,3],[216,2],[230,3],[234,2],[241,1],[268,1],[291,2],[294,3],[298,5],[309,1],[311,3],[315,2],[329,3],[333,2],[336,1],[338,7],[383,1],[406,1],[415,2],[418,5]]},"1674":{"position":[[14,5],[39,1],[46,1],[57,2],[60,2],[68,1],[90,3],[94,3],[98,3],[102,3],[118,3],[122,2],[134,2],[137,3],[157,1],[159,5],[173,2],[180,1],[187,2],[212,3],[216,3],[220,2],[223,3],[227,5],[237,1],[252,1],[273,1],[275,4],[280,6],[287,3],[291,3],[303,1],[305,3],[309,3],[313,4],[337,1],[339,4],[412,1],[414,2],[427,1],[443,2],[446,3],[450,6],[508,5],[514,1],[516,3],[530,2],[533,2],[545,3],[559,2],[562,3],[606,1],[625,4],[630,3],[641,3],[654,1],[668,1],[674,2],[695,1],[697,2],[709,3],[713,2],[716,2],[731,1],[733,4],[738,4],[746,5],[752,2],[755,3],[759,2]]},"1676":{"position":[[8,1],[10,1],[12,6],[23,1],[34,1],[36,3],[40,5],[46,3],[50,3],[54,2],[57,3],[61,1],[63,1],[65,3],[74,1],[80,1],[82,2],[85,4],[110,2],[121,1],[125,1],[147,3],[151,3],[155,5],[161,3],[169,5],[175,3],[179,5],[201,2],[204,2],[207,1],[214,1],[220,1],[242,2],[245,6],[252,2],[269,3],[273,2],[276,2],[289,1],[295,1],[297,3],[308,1],[310,6],[321,1],[323,3],[346,1],[348,1],[350,1],[352,4],[357,1],[359,3],[363,2],[366,3],[370,4],[388,1],[423,1],[425,5],[431,3],[435,1],[437,3],[441,2],[460,1],[462,7],[474,1],[481,2],[484,2],[487,3],[491,3],[495,6],[521,1],[539,1],[541,5],[547,5],[553,3],[557,1],[559,2],[581,1],[583,4],[595,1],[597,6],[608,2],[623,1],[625,1],[627,1],[629,3],[633,1],[635,3],[639,1]]},"1678":{"position":[[0,1],[2,5],[35,1],[37,2],[40,2],[43,3],[47,2]]},"1680":{"position":[[8,3],[12,2],[15,1],[17,2],[20,6],[27,3],[31,3],[44,1],[46,3],[50,3],[54,3],[58,2],[61,1],[63,2],[66,2],[69,3],[73,2],[87,2],[107,2],[118,1],[120,3],[124,4],[139,1],[141,2],[151,2],[184,1],[186,2],[189,3],[193,4],[204,1],[216,2],[243,1],[245,3],[249,5],[255,1],[257,4],[262,2],[282,5],[288,2],[291,1],[293,1],[295,4],[300,2],[310,3],[323,3],[327,1],[329,5]]},"1682":{"position":[[22,5],[33,2],[59,3],[63,4],[68,3],[85,1],[96,2],[99,4],[118,2],[121,2],[131,1],[141,2],[144,3],[152,2],[155,3],[159,4],[164,2],[167,2],[239,1],[241,3],[245,3],[249,2],[259,4],[274,2],[277,4],[286,2],[295,1],[297,3],[301,5],[307,2],[310,2],[317,1],[319,3],[323,4],[328,2],[335,2],[366,1],[368,3],[385,1],[411,1],[417,3],[421,2],[437,1],[470,1],[494,1],[496,2],[499,2],[510,1],[512,2],[515,5],[561,1],[563,2],[593,1],[600,1],[602,4],[635,1],[637,2],[640,4],[657,1],[698,1],[700,3],[704,2],[712,1],[736,1],[738,2],[766,1],[780,1],[782,4],[787,2],[790,3],[819,2],[827,1],[833,1],[835,2],[852,1],[876,1],[878,2],[881,4],[886,3],[890,3],[898,1],[920,3],[932,1],[934,2]]},"1684":{"position":[[9,1],[13,2],[16,6],[27,1],[39,1],[41,3],[45,5],[51,2],[54,2],[57,3],[61,3],[65,1],[67,3],[77,1],[83,1],[85,2],[88,4],[113,2],[116,1],[118,2],[121,2],[128,1],[137,2],[140,2],[150,3],[154,5],[160,2],[177,4],[214,1],[216,4],[221,2],[246,1],[248,3],[252,2],[255,4],[260,1],[262,3],[266,6],[287,1],[294,1],[320,1],[322,4],[327,2],[330,6],[350,1],[352,4],[357,3],[365,1],[367,1],[369,2],[396,1],[398,4],[403,1],[405,3],[409,4],[414,4],[419,5],[446,1],[461,1],[463,4],[468,4],[473,1],[475,2],[478,3],[482,2],[485,2],[492,1],[494,2],[523,1],[525,4],[530,4],[535,3],[539,3],[553,1],[555,4],[560,3],[564,4],[569,4],[574,3],[578,3],[595,2],[598,1],[614,1],[616,3],[620,4],[625,2],[628,1],[630,2],[633,3],[637,3],[641,2],[644,3],[648,3],[652,3],[669,1],[684,1],[701,2],[704,1],[716,2],[719,4],[730,1],[732,1],[734,5],[744,2],[753,3],[757,4],[762,4],[767,3],[795,1],[811,1],[813,4],[818,4],[829,1],[831,3],[842,3],[846,5],[852,5],[858,1],[860,3],[870,1],[882,2],[885,4],[890,4],[895,2],[898,3],[902,6],[909,3],[913,2],[916,1],[918,3],[922,3],[926,3]]},"1686":{"position":[[0,3],[18,1],[20,2],[23,4],[28,4],[33,2],[45,1],[55,1],[57,5],[63,4],[68,1],[70,2],[73,3],[77,2],[80,3],[84,3],[94,2],[97,1],[99,1],[101,3],[109,1],[111,7],[119,2],[122,3],[126,4],[131,2],[148,1],[150,5],[156,2],[163,1],[174,1],[176,5],[182,1],[184,4],[189,3],[193,2],[196,4],[201,6],[212,1],[214,3],[218,4],[223,4],[228,3],[236,1],[245,1],[247,2],[250,5],[256,5],[267,1],[279,3],[283,2],[286,1],[288,2],[291,3],[295,3],[299,2],[302,3],[306,2],[314,2],[338,1],[340,5],[346,2],[369,1],[371,2],[374,5],[380,2],[387,1],[389,1],[391,2],[394,4],[399,4],[404,3],[408,3],[426,1],[434,1],[436,3],[440,2],[443,3],[447,4],[452,3],[456,5]]},"1689":{"position":[[0,1],[2,5],[8,3],[47,1],[49,2],[83,1],[85,3],[94,1],[96,2],[111,1],[135,1],[137,5],[164,1],[180,2],[183,4],[188,1],[190,3],[206,1],[208,3],[221,1],[238,3],[242,4],[247,3],[251,1],[253,3],[296,1],[320,1],[322,2],[325,2],[328,3],[336,1],[338,2],[373,1],[390,2],[393,3],[428,1],[454,1],[456,3],[460,1],[462,3],[466,5]]},"1691":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1693":{"position":[[4,1],[6,3],[10,6],[39,1],[41,2],[44,2],[47,2],[80,1],[82,4],[98,1],[100,5],[125,1],[127,2],[152,4],[157,2],[160,5],[166,3],[170,3],[184,1],[186,4],[191,2],[213,2],[216,3],[220,2],[237,1],[239,4],[244,2],[247,1],[249,2],[252,4],[257,3],[261,5],[267,2],[270,2],[273,3],[289,1],[291,3],[295,2],[298,2],[312,2],[315,3],[319,1],[321,3],[325,3],[329,2],[332,3],[336,3],[343,1],[345,3],[358,1],[372,1],[374,1],[376,2],[379,1],[381,3],[395,3],[399,5],[425,1],[450,2],[453,1],[455,3],[469,5],[475,4],[502,1],[504,2],[507,3],[511,3],[515,2],[518,3],[522,3],[526,3],[530,4],[535,1],[537,3],[558,4],[563,5],[569,5],[575,6],[582,2],[585,1],[587,2],[590,3],[594,5]]},"1695":{"position":[[26,1],[48,3],[64,1],[66,2],[69,5],[75,2],[98,1],[100,3],[104,2],[107,5],[122,2],[133,1],[135,4],[140,3],[144,4],[149,2],[152,3],[156,4],[161,4],[171,1],[173,2],[201,1],[207,1],[230,1],[232,5],[238,2],[249,1],[251,1],[253,4],[279,3],[283,3],[287,1],[289,3],[293,4],[298,3],[317,1],[319,2],[332,1],[338,1],[340,1],[342,3],[363,5],[369,3],[406,1],[428,1],[430,3],[434,6],[452,3],[489,2],[502,1],[504,5],[532,1],[547,1],[561,3],[575,2],[578,3],[582,2],[585,3],[589,2],[592,3],[610,1],[612,4],[632,1],[653,1],[655,2],[658,3],[662,5],[683,1],[685,3],[689,5],[711,1],[713,2],[716,5],[722,4],[739,3],[748,1],[750,2],[753,1],[755,3],[759,3],[789,2],[825,1],[827,3],[862,1],[867,1],[880,1],[901,2],[904,5],[910,2],[929,1],[931,4],[951,1],[953,3],[957,3],[961,3],[965,3],[969,2],[972,2],[975,2],[978,5],[984,3],[995,2],[998,3],[1005,2],[1008,4],[1016,2],[1019,3],[1023,4],[1028,2],[1075,2],[1078,3],[1082,5],[1088,3],[1092,3],[1096,2],[1099,3],[1103,3],[1114,1],[1116,4],[1144,2],[1147,3],[1151,3],[1155,3],[1159,1],[1161,2],[1164,4],[1169,3],[1180,1],[1195,2],[1201,1],[1203,2],[1206,2],[1214,2],[1217,2],[1220,3],[1231,1],[1233,2],[1255,1],[1257,2]]},"1698":{"position":[[4,1],[6,2],[29,1],[41,3],[51,2],[65,1],[67,5],[103,3],[107,5],[117,1],[131,2],[134,2],[137,3],[148,1],[150,1],[152,3],[175,1],[177,5],[183,3],[193,1],[202,2],[205,5],[211,5],[217,2],[220,2],[223,2],[226,4],[231,3],[235,6],[242,2],[265,2],[277,1],[303,3],[317,1],[319,4],[324,3],[347,2],[360,1],[382,1],[408,1],[410,4],[415,2],[418,2],[422,1],[426,1],[448,3],[452,1],[464,1],[466,2],[469,1],[471,5],[477,3],[509,2],[512,4],[527,1],[546,1],[548,2],[562,1],[579,1],[581,5]]},"1700":{"position":[[20,1],[22,4],[42,1],[44,5],[72,1],[74,1],[76,3],[80,4],[85,2],[90,3],[104,2],[107,2],[110,2],[113,3],[130,1],[132,5]]},"1702":{"position":[[10,1],[47,1],[121,1],[132,1],[134,4],[139,4],[144,1],[146,2],[154,1],[156,2],[184,1],[186,2],[208,1],[210,3],[223,1],[225,2],[259,2],[271,1],[273,2],[276,3],[299,1],[301,3],[305,2],[308,3],[312,3],[320,1],[352,1],[395,1],[447,2],[450,2],[453,4],[462,1],[464,5],[470,3],[486,1],[488,3],[492,3],[524,1],[526,1],[528,1],[530,4],[535,1],[537,2],[540,3],[552,2],[555,1],[557,1],[559,3],[563,1],[565,3],[569,3],[573,2],[576,3],[580,2],[583,2],[593,1],[597,1],[599,3],[603,2],[606,1],[608,3],[624,1],[626,4],[644,1],[667,1],[673,3],[686,1],[711,1],[713,2],[716,3],[720,2],[723,1],[725,3],[746,2],[759,1],[761,1],[763,2],[766,2],[769,2],[795,1],[801,3],[810,1],[812,2],[815,4],[820,3],[824,1],[826,2]]},"1704":{"position":[[3,1],[11,1],[13,6],[20,2],[23,2],[32,1],[51,1],[53,3],[57,3],[65,1],[67,2],[70,2],[73,3],[77,2],[80,2],[83,3],[87,1],[89,3],[93,3],[111,1],[160,1],[176,1],[178,4],[183,2],[186,2],[190,1],[194,1],[196,2],[199,3],[203,1],[205,3],[223,1],[229,1],[242,1],[244,2],[286,2],[289,2],[306,1],[308,1],[310,3],[314,3],[341,1],[355,1],[357,3],[368,3],[424,2],[441,1],[443,3],[447,4],[463,1],[465,2],[509,1],[557,1],[630,1],[639,3],[643,3],[647,2],[664,1],[666,2],[669,2],[678,1],[687,1],[689,2],[692,2],[704,1],[709,2],[712,3],[716,2],[719,3],[730,2]]},"1706":{"position":[[0,3],[4,4],[9,2],[18,1],[20,2],[42,2],[65,1],[67,3],[71,2],[74,2],[77,2],[80,4],[92,1],[94,2],[104,3],[108,4],[129,1],[131,2],[134,3],[145,1],[147,2],[150,3],[154,3],[158,3],[175,3],[179,4],[184,4],[189,2],[192,2],[195,2],[198,3],[241,3],[245,1],[247,3],[251,1],[253,3],[273,1],[282,2],[285,3],[289,5]]},"1708":{"position":[[0,3],[4,3],[8,5],[24,3],[28,2],[31,4],[36,2],[39,5],[45,3],[95,1],[97,3],[101,3],[152,1],[154,2],[171,2],[174,5],[180,3],[190,4],[195,2],[198,2],[211,2],[249,1],[260,3],[264,2],[298,1],[300,2],[317,2],[320,2],[323,3],[327,3],[331,2],[334,3],[338,2],[341,3],[345,1],[347,1],[349,2],[362,3],[366,3],[370,2],[406,2],[409,2],[412,5],[418,4],[423,2],[426,4],[431,2],[434,4],[439,3],[443,3],[447,2],[494,2],[507,1],[509,5],[515,3],[519,2],[532,2],[535,3],[539,3],[543,4],[548,3],[552,2]]},"1710":{"position":[[28,1],[46,1],[48,4],[53,3],[57,3],[115,1],[117,4],[122,2],[130,1],[132,2],[135,3],[148,1],[150,4],[164,1],[166,2],[169,1],[171,2],[174,5],[180,3],[190,1],[199,1],[201,2],[204,1],[206,3]]},"1712":{"position":[[0,2],[16,1],[32,1],[34,5],[40,2],[48,1],[56,1],[58,2],[61,3],[65,4],[70,2],[73,2],[81,1],[83,2],[105,1],[107,2],[110,1],[126,1],[128,1],[130,2],[147,3],[151,3],[155,3],[169,1],[171,2],[174,1],[189,1],[191,2],[212,3],[216,2],[219,3],[223,3],[227,3],[231,2],[234,1],[249,1],[265,2],[268,2],[271,2],[299,2],[317,1],[319,2],[322,1],[340,1],[353,1],[355,2],[364,2],[367,1],[369,3],[373,5]]},"1714":{"position":[[0,2],[3,5],[16,1],[18,3],[22,3],[26,3],[30,4],[44,1],[46,4],[51,4],[56,4],[61,3],[70,5],[79,1],[91,1],[93,4],[98,2],[101,4],[106,3],[125,1],[127,5],[171,4],[208,1],[223,1],[225,2],[228,4],[233,2],[241,1],[243,3],[247,3],[251,3],[255,4],[260,2],[277,1],[279,4],[284,3],[523,4],[548,1],[571,2],[600,2],[603,2],[606,3],[619,1],[621,2]]},"1716":{"position":[[0,2],[3,3],[16,1],[18,5],[24,3],[33,1],[35,2],[38,2],[41,3],[45,1],[47,3],[51,1],[53,2],[56,3],[60,3],[71,1],[73,4],[78,4],[83,2],[86,1],[88,3],[92,3],[96,2],[99,2],[102,4],[107,3],[116,1],[118,1],[120,2],[123,3],[127,2],[137,5],[143,3],[154,1],[156,5],[162,3],[166,1],[168,2],[171,1],[173,3],[177,4],[182,2],[194,1],[196,4],[201,4],[206,5],[212,3],[232,1],[234,2],[237,3],[241,3],[263,1],[268,1],[270,3],[274,3],[278,2],[281,4]]},"1718":{"position":[[16,3],[20,3],[24,3],[65,1],[78,2],[81,4],[95,1],[97,2],[100,3],[104,2],[125,3],[129,6],[136,3],[163,1],[165,2],[177,2],[184,1],[190,2],[206,2],[225,1],[227,2],[266,1],[268,2],[271,2],[281,2],[295,2],[298,2],[301,2],[304,4],[309,4],[314,2],[324,1],[326,2],[329,3],[333,3],[337,1],[339,5],[345,2],[348,4],[353,3],[357,3],[361,2],[364,3],[368,3],[372,3],[399,4],[404,2],[407,2],[410,1],[412,3],[420,1],[431,1],[433,3],[437,1],[450,2],[453,1],[455,3],[465,1],[467,2],[481,2],[484,2],[513,2],[516,3],[520,2],[545,1],[547,5],[553,2],[556,4],[561,2],[564,2],[567,2],[570,2],[573,1],[582,3],[586,2],[589,2],[603,1],[605,2],[624,1],[626,4],[631,3],[635,3],[639,3],[665,3],[669,2],[672,3],[683,1],[685,2],[688,3],[692,3],[696,4],[701,3],[708,1],[710,3],[717,1],[719,2],[731,2],[749,1],[751,3],[755,2],[758,2],[764,1],[781,1],[783,3],[787,3],[807,2],[813,1],[822,2],[825,3],[829,2],[832,2],[835,3],[839,5],[845,1],[849,1],[854,1],[856,1],[864,1],[897,1],[899,5],[905,4],[910,3],[914,2],[917,4],[922,2],[929,4],[934,3],[938,5],[944,3],[948,3],[952,1],[960,1],[962,4],[976,1],[978,4],[999,1],[1001,2],[1004,2],[1007,2],[1032,1],[1049,1],[1056,1],[1058,2],[1061,1],[1066,1],[1068,4],[1100,2],[1112,2],[1115,3],[1128,2],[1131,4],[1136,4],[1147,1],[1161,1],[1163,2],[1173,1],[1175,2],[1178,1],[1180,2],[1183,3],[1190,2],[1207,1],[1209,4],[1214,2],[1217,2],[1220,3],[1224,2]]},"1720":{"position":[[18,1],[23,1],[25,5],[36,1],[38,5],[44,3],[48,2],[51,3],[55,4],[60,3],[67,1],[69,3],[73,3],[77,2],[90,1],[92,5],[98,2],[101,5],[107,1],[109,3],[113,1],[115,2],[118,3],[122,4],[136,3],[140,4],[145,3],[149,3],[153,4],[158,4],[163,3],[167,2],[170,2],[182,1],[198,1],[200,5],[206,2],[209,3],[213,2],[216,2],[219,3],[239,1],[241,4],[246,2],[249,3],[253,1],[255,2],[258,2],[261,5],[267,2],[270,2],[273,4],[278,4],[283,3],[322,1],[330,1],[364,1],[366,4],[371,4],[376,4],[381,3],[385,3],[399,5],[405,2],[502,1],[624,6],[652,1],[669,1],[671,4],[685,1],[687,4],[692,1],[709,3],[713,2],[716,6],[752,1],[814,1],[829,1],[831,2],[834,2],[852,2],[855,5],[861,2],[873,1],[892,1],[920,2],[923,2],[926,3],[930,2],[947,2],[950,5],[956,3],[960,3],[979,2],[982,5],[991,1],[1026,1],[1028,2],[1031,4],[1052,2],[1055,4],[1060,4],[1065,4],[1070,1],[1072,4],[1077,2],[1080,2],[1086,1],[1094,4],[1099,2],[1102,3],[1106,4],[1120,1],[1122,2],[1125,2],[1128,3],[1132,4],[1137,2],[1150,1],[1152,5],[1158,1],[1160,3],[1164,2],[1167,5],[1173,4],[1178,3],[1182,1],[1184,2],[1187,5],[1193,2],[1200,1],[1202,2],[1205,3],[1209,3],[1223,1],[1225,4],[1230,4],[1235,3],[1239,4],[1244,5],[1265,1],[1267,2],[1291,1],[1293,2],[1314,1],[1316,3],[1320,2],[1323,3],[1327,1],[1329,1],[1331,3],[1335,3],[1346,1],[1348,3],[1352,2],[1355,4],[1375,1],[1377,2],[1392,1],[1409,3],[1473,2],[1476,4],[1481,3],[1492,1],[1512,1],[1514,5],[1520,2],[1527,1],[1540,1],[1542,2],[1554,2],[1557,4],[1571,1],[1573,2],[1576,1],[1585,1],[1587,4],[1592,2],[1595,3],[1599,3],[1603,1],[1605,3],[1609,3],[1613,2],[1616,4],[1632,2],[1644,1],[1646,5],[1652,2],[1655,4],[1660,1],[1662,2],[1680,1],[1682,3],[1686,2],[1689,1],[1691,2],[1698,1],[1700,1],[1708,1],[1710,2],[1727,1],[1729,3],[1733,5],[1739,1],[1750,1],[1752,4],[1757,5],[1779,1],[1781,2],[1784,5],[1790,2],[1802,2],[1805,4],[1810,4],[1829,4],[1834,4],[1842,1],[1844,2],[1863,1],[1871,1],[1873,3],[1897,1],[1899,5],[1940,3],[1970,2],[1973,3],[1998,1],[2008,4],[2013,4],[2018,2],[2024,1],[2035,1],[2037,2],[2058,1],[2060,2],[2063,3],[2067,3],[2086,1],[2088,4],[2093,3],[2110,2],[2113,5],[2119,3],[2140,1],[2149,1],[2151,4],[2156,3],[2160,2],[2163,3],[2167,2],[2179,1],[2181,3],[2198,1],[2200,2],[2206,1],[2239,2],[2242,2],[2245,4],[2250,3],[2263,1],[2265,3],[2269,2],[2272,2],[2275,3],[2293,1],[2295,2],[2315,3],[2319,2],[2338,1],[2340,3],[2368,1],[2370,2],[2381,2],[2384,3],[2388,2],[2395,1],[2412,1],[2427,1],[2443,2],[2475,1],[2477,3]]},"1722":{"position":[[25,1],[27,2],[30,4],[62,1],[64,4],[90,1],[92,4],[97,2],[100,2],[116,1],[132,3],[136,2],[139,5]]},"1724":{"position":[[7,1],[9,3],[13,4],[18,2],[21,4],[26,4],[31,3],[35,3],[39,3],[49,1],[66,1],[79,1],[81,2],[90,1],[92,2],[95,2],[109,1],[111,4],[121,1],[123,2],[144,2],[160,1],[162,3],[175,1],[177,2],[180,2],[183,3],[187,2],[204,1],[206,2],[222,1],[229,1],[231,2],[234,4],[255,1],[270,1],[287,3],[291,3],[325,2],[350,1],[352,2],[355,5],[387,1],[402,1],[404,2],[407,2],[414,2],[460,2],[463,2],[466,5]]},"1726":{"position":[[0,3],[31,1],[33,4],[38,3],[49,1],[51,2],[61,2],[64,4],[69,2],[72,2],[102,1],[104,4],[109,5]]},"1728":{"position":[[15,1],[44,1],[46,3],[64,1],[66,2],[69,4],[74,4],[79,3],[83,2],[107,1],[136,1],[138,2],[141,2],[144,2],[151,1],[175,1],[177,2],[199,3],[220,2],[234,1],[247,1],[249,2],[252,4],[257,2],[260,3],[283,1],[305,1],[327,1],[364,1],[366,2],[369,3],[373,2],[376,3],[380,2],[388,1],[390,3],[394,1],[396,4],[401,2],[408,1],[421,1],[423,3],[427,3],[431,2],[434,3],[438,2],[520,1],[522,4],[527,2],[533,1],[571,1],[573,2],[597,2],[600,3],[604,4],[609,2],[612,1],[614,1],[616,2],[619,2],[622,3],[647,1],[669,2],[672,3],[676,2],[683,1],[725,1],[727,3],[734,1],[736,4],[741,2],[744,2],[747,1],[749,3],[753,2],[756,2],[759,3],[763,3]]},"1730":{"position":[[0,2],[3,3],[14,2],[17,4],[22,2],[25,3],[29,2],[32,2],[35,2],[50,3],[77,1],[79,4],[118,2],[151,1],[153,5],[172,1],[174,4],[192,1],[194,2],[204,1],[233,5],[264,1],[281,1],[283,4],[288,2],[291,2],[294,2],[304,1],[306,2],[316,1],[318,2],[321,2],[324,3],[328,3],[363,1],[430,1],[449,3],[453,2],[456,2],[459,3],[463,3],[467,3],[471,2],[474,3],[478,2],[500,1],[502,4],[525,1],[527,4],[557,1],[559,2],[582,1],[584,3],[588,2],[591,6],[598,2],[608,2],[611,4],[616,2],[628,1],[640,2],[666,1],[668,4],[673,3],[677,3],[692,2],[695,1],[697,2],[700,1],[702,2],[705,3],[709,3],[713,3],[717,2],[720,2],[723,2],[726,5],[732,4],[748,1],[750,5],[766,1],[768,2],[782,2],[785,3],[789,2],[803,1],[815,1],[847,1],[849,4],[854,3],[878,1],[880,2],[883,2],[886,5],[892,3],[916,1],[932,1],[934,2],[937,3],[941,4],[953,2],[959,1],[961,2],[964,3],[968,3],[976,3],[980,4],[985,4],[1009,3],[1013,5],[1056,1],[1058,2],[1061,2],[1064,3],[1078,4],[1083,4],[1105,1],[1107,2],[1110,3],[1114,4],[1132,1],[1134,2],[1145,1],[1147,2],[1150,5],[1156,3],[1169,1],[1171,2],[1181,3],[1185,4],[1193,1],[1206,1],[1208,2],[1211,2],[1214,4],[1219,4],[1224,2],[1227,2],[1241,1],[1243,2],[1269,1],[1271,2],[1274,2],[1277,2],[1280,2],[1283,3],[1287,2],[1290,2],[1293,3],[1297,4],[1302,4],[1314,1],[1316,2],[1319,2],[1340,1],[1342,3],[1366,1],[1368,5],[1386,1],[1388,3],[1392,1],[1394,3],[1398,3],[1402,3],[1406,2]]},"1732":{"position":[[0,2],[3,3],[7,7],[15,4],[20,1],[22,2],[43,1],[45,4],[50,4],[55,5],[64,3],[68,1],[82,1],[84,2],[87,2],[90,3],[94,4],[122,1],[124,2],[127,1],[129,4],[134,2],[153,1],[155,6],[175,1],[177,3],[181,3],[185,2],[188,4],[193,1],[195,3],[202,2],[205,3],[209,4],[214,4],[219,2],[222,1],[224,3],[228,4],[233,5]]},"1734":{"position":[[22,1],[47,1],[49,4],[54,4],[59,3],[63,2]]},"1736":{"position":[[18,1],[20,2],[23,2],[26,2],[47,1],[49,3],[53,4],[74,1],[92,2],[113,1],[115,1],[117,3],[121,2],[124,4],[136,1],[138,3],[142,2],[164,2],[167,2],[186,1],[188,3],[192,3],[214,1],[216,2],[219,3],[223,1],[225,2],[228,1],[230,2],[233,4],[238,3],[242,3],[246,3],[250,3],[254,4],[259,2],[262,4],[267,3],[271,2],[292,1],[294,2],[304,1],[306,4],[311,2],[351,2],[476,1],[494,1],[496,2],[499,2],[502,4],[511,1],[520,2],[523,2],[526,2],[529,2],[532,3],[536,4],[545,3],[562,1],[564,2],[567,2],[570,2],[577,1],[589,5],[604,2],[607,2],[610,3],[614,3],[618,3],[622,1],[624,3],[628,3],[632,2],[645,1],[668,3],[672,3],[683,1],[685,4],[690,2],[693,2],[696,4],[701,3],[705,2],[727,1],[736,1],[738,2],[741,1],[750,1],[767,1],[769,4],[774,3],[785,1],[794,3],[798,2],[801,3],[805,5],[811,6],[821,1],[823,5],[843,4],[848,5],[854,1],[863,1],[872,2],[879,1],[881,2],[884,3],[897,3],[901,3],[905,3],[909,2],[912,2],[924,1],[926,5],[932,4],[937,4],[942,1],[951,1],[960,1],[962,2],[981,1],[1003,3],[1007,3],[1018,1],[1020,3],[1024,4],[1029,2],[1032,3],[1036,3],[1040,2],[1075,1],[1077,2],[1080,3],[1084,2],[1087,3],[1091,3],[1095,2],[1098,4],[1140,1],[1142,2],[1145,3],[1165,3],[1169,2],[1172,2],[1175,1],[1177,4],[1182,2],[1195,5],[1213,1],[1215,4],[1220,3],[1233,2],[1236,3],[1240,2],[1297,1],[1299,2],[1320,3],[1324,5],[1330,2],[1349,1],[1351,2],[1354,3],[1358,4],[1363,2],[1423,2],[1536,1],[1538,4],[1550,2],[1559,1],[1561,1],[1623,1],[1625,2],[1628,3],[1632,3],[1636,2],[1639,3],[1656,1],[1658,4],[1663,4],[1668,2],[1671,2],[1674,1],[1676,3],[1680,3],[1684,4],[1689,3],[1693,2],[1696,3],[1700,3],[1704,4],[1709,2]]},"1738":{"position":[[20,1],[45,1],[47,1],[52,2],[65,1],[67,6],[74,2],[77,5],[83,2],[93,1],[95,5],[101,3],[105,1],[107,2],[126,1],[128,3],[132,4],[137,1],[139,4],[144,3],[153,3],[157,4],[162,3],[166,3],[170,3],[174,3],[178,3],[182,3],[186,3],[195,1],[197,2],[207,1],[209,3],[213,1],[215,2],[241,2],[244,3],[248,2],[251,3],[255,2],[258,3],[262,4],[267,1],[269,5],[275,5],[281,5],[287,2],[290,4],[295,2],[315,1],[317,2],[320,4],[325,2],[328,3],[332,3],[345,5],[351,3],[355,2],[358,3],[362,4],[374,1],[376,2],[379,5],[391,1],[393,3],[397,3],[401,3],[408,1],[422,1],[424,3],[431,1],[433,4],[438,4],[443,3],[447,3],[451,3],[455,4],[486,1],[488,2],[491,2],[510,1],[512,3],[516,3],[520,4],[525,4],[530,3],[534,3],[541,1],[559,1],[561,3],[565,2],[568,3],[572,3],[576,4],[581,1],[583,2],[586,1],[588,3],[592,2],[595,3],[599,4],[604,2],[615,2],[618,2],[621,2],[627,1],[649,2],[652,2],[655,3],[659,2],[662,3],[666,3],[677,3],[697,1],[699,4],[704,2],[707,2],[714,1],[726,1],[728,2],[747,1],[749,4],[766,1],[768,4],[773,2],[776,2],[782,1],[804,1],[806,2],[825,1],[827,4],[832,3],[836,5],[842,2],[845,3],[849,2],[852,3],[856,2],[862,1],[867,3],[878,2],[881,4],[886,5],[892,2],[898,2],[901,4],[926,1],[937,1],[946,1],[948,4],[953,3],[981,1],[983,3],[987,3],[991,1]]},"1740":{"position":[[19,1],[21,2],[24,2],[27,5],[33,4],[38,1],[40,2],[43,3],[47,5],[53,2],[56,2],[59,5],[65,4],[87,1],[89,4],[94,2],[122,1],[124,3],[128,1],[130,2],[133,2],[136,3],[140,4],[145,4],[150,2],[153,2],[156,1],[158,2],[161,3],[165,3],[169,2],[172,4],[177,3],[181,1],[183,3],[190,1],[192,2],[195,2],[198,1],[200,2],[203,3],[207,2],[210,2],[213,3],[217,2],[231,1],[233,5],[239,2],[242,2],[245,3],[249,4],[254,3],[265,1],[267,2]]},"1742":{"position":[[0,1],[2,3],[6,2],[9,3],[13,4],[18,3],[22,2],[35,1],[37,2],[56,1],[58,2],[61,4],[66,3],[70,3],[95,1],[113,1],[115,2],[130,1],[132,4],[137,1],[151,1],[153,5],[166,2],[169,2],[172,2],[175,2],[178,5],[190,1],[202,3],[206,5],[212,3],[216,1],[223,1],[225,2],[228,2],[231,2],[251,4],[256,5],[269,1],[271,1],[273,3],[277,2],[285,2],[288,4],[293,1],[300,1],[302,2],[305,2],[315,1],[317,4],[322,5],[328,5],[337,1],[339,2],[342,3],[346,2],[370,1],[372,4],[377,2]]},"1744":{"position":[[7,1],[9,2],[12,3],[16,4],[21,3],[25,3]]},"1746":{"position":[[19,1],[39,3],[43,4],[48,3],[52,3],[56,4],[61,2],[70,1],[86,1],[88,3],[92,2],[95,3],[99,1],[101,3],[105,2],[108,2],[116,1],[118,2],[121,2],[124,4],[129,2],[159,2],[162,3],[185,1],[187,2],[190,2],[193,3],[197,3],[201,2],[222,1],[224,2],[227,2],[230,3],[234,2],[237,2],[240,2],[243,3],[247,4],[252,2],[255,3],[259,4],[264,5],[270,3],[284,2],[287,3],[307,2],[310,1],[312,4],[317,4],[338,1],[340,3],[351,4],[356,3],[360,5],[366,3],[373,1],[375,4],[396,1],[398,3],[421,1],[423,4],[428,3]]},"1748":{"position":[[7,2],[35,1],[37,1],[39,3],[43,5],[49,3],[77,3],[81,5],[87,2],[90,3],[94,3],[98,3],[102,4],[107,4],[112,3],[116,5],[122,2],[125,3],[129,2],[134,2],[144,3],[148,2],[164,1],[173,2],[183,2],[196,1],[198,2],[201,2],[204,2],[214,1],[216,2],[219,3],[223,2],[236,1],[245,2]]},"1750":{"position":[[23,1],[39,1],[41,2],[54,3],[58,2],[69,1],[87,2],[90,4],[102,2],[114,1],[116,2],[119,6],[126,2],[134,1],[144,1],[146,1],[148,4],[167,1],[180,1],[182,3],[186,4],[191,4],[196,2],[199,6],[206,2],[209,6],[216,3],[220,1],[222,4],[227,3],[231,2],[234,1],[236,2],[242,1],[244,3],[248,3],[276,1],[278,3],[282,2],[288,1],[301,2],[304,1],[306,2],[309,1],[311,1],[313,2],[316,2],[319,1],[332,1],[334,3],[345,2],[348,4],[356,1],[368,1],[377,2],[380,1],[382,5],[392,2],[409,1],[411,2],[414,6],[421,3],[425,1],[427,3]]},"1752":{"position":[[22,1],[31,3],[50,1],[52,5],[58,4],[63,2],[66,2],[76,1],[78,4],[83,2],[102,1],[104,5],[123,4],[148,2],[173,1],[195,1],[197,2],[200,2],[203,5],[231,1],[233,2],[241,1],[249,1],[251,2],[265,1],[267,4],[272,4],[277,4],[282,2],[285,3],[313,3],[327,2],[330,2],[333,2],[350,1],[352,2],[355,4],[360,3],[382,3],[406,3],[410,2],[429,1],[431,4],[436,3],[440,3],[444,3],[448,3],[452,4],[457,2],[460,2],[463,2]]},"1754":{"position":[[23,1],[32,2],[35,5],[41,4],[46,4],[67,2],[70,3],[74,2],[89,1],[91,4],[103,1],[105,4],[110,2],[113,8],[136,1],[138,3],[142,2],[145,2],[148,5],[168,1],[184,1],[186,2],[200,1],[224,1],[226,5],[235,1],[247,2],[250,1],[261,1],[263,3],[267,2],[292,2],[295,3],[299,2],[316,1],[328,4],[333,3],[337,6],[359,1],[361,4],[381,1],[396,3],[400,2],[422,3],[426,3],[430,2],[433,1],[435,3],[439,1],[441,2]]},"1756":{"position":[[23,1],[37,1],[50,2],[56,1],[65,4],[70,3],[74,5],[87,1],[89,4],[94,3],[98,3],[102,4],[107,2],[119,3],[123,4],[128,2],[131,3],[135,3],[139,5],[145,3],[149,2],[152,2],[155,1],[157,3],[161,3],[165,4],[196,1],[198,4],[203,1],[205,5],[220,1],[225,1],[227,2],[233,1],[249,3],[279,1],[281,4],[305,1],[307,2],[310,1],[312,3],[316,2],[325,1],[332,1],[348,2],[360,1],[362,2],[365,3],[369,3],[373,3],[389,1],[391,2],[394,3],[398,2],[401,4],[406,2],[420,1],[431,1],[452,1],[454,2],[462,1],[464,1],[466,3],[470,2],[473,1],[475,4],[480,3],[484,2],[487,2],[499,3],[503,3],[521,1],[530,1],[532,3],[545,1],[566,1],[568,3],[572,3],[576,1],[594,1],[607,1],[612,1],[614,2],[633,1],[635,4]]},"1758":{"position":[[17,1],[33,1],[35,5],[41,3],[45,3],[56,2],[59,5],[65,2],[79,2],[82,2],[85,5],[96,1],[107,1],[109,2],[112,2],[127,1],[140,5],[146,6],[160,3],[164,2],[167,2],[170,2],[173,1],[175,2],[178,4],[183,2],[197,1],[199,4],[204,2],[207,3],[211,3],[215,2],[218,3],[222,4],[227,2],[244,1],[246,2],[249,3],[253,5],[259,4],[264,3],[268,3],[272,2],[275,6],[282,3]]},"1760":{"position":[[0,2],[3,3],[7,6],[14,4],[19,2],[22,2]]},"1762":{"position":[[16,1],[35,1],[37,4],[42,3],[46,4],[51,2],[54,3],[58,6],[68,1],[85,1],[87,3],[91,3],[95,3],[99,2],[102,3],[106,5],[112,1],[127,1],[129,5],[135,2],[138,1],[140,4],[145,3],[149,1],[151,2],[167,1],[184,1],[186,4],[191,3],[195,2],[203,1],[213,1],[215,2],[218,4],[223,2],[233,1],[235,2],[238,5],[244,4],[258,1],[260,3],[264,3],[268,2],[271,3],[275,3],[377,1],[413,1],[415,3],[438,1],[440,3],[458,1],[560,1],[590,2],[593,1],[595,3],[602,1],[604,5],[610,3],[614,3],[618,3],[641,3],[645,4],[650,2]]},"1764":{"position":[[17,1],[19,4],[24,4],[29,4],[34,4],[54,1],[56,4],[61,2],[68,1],[73,2],[102,1],[104,2],[112,1],[114,2],[117,4],[122,2],[125,3],[142,4],[147,3],[151,3],[155,2],[158,3],[162,3],[166,4],[171,3],[195,2],[198,3],[202,3],[206,4],[211,3],[231,2],[248,2],[251,4],[256,3],[260,2],[276,4],[281,3],[285,2]]},"1766":{"position":[[27,1],[29,3],[33,3],[37,3],[41,3],[45,2],[48,4],[53,2],[56,3],[60,1],[62,3],[66,2],[79,1],[81,3],[92,1],[94,4],[99,4],[104,3],[112,3],[116,2],[119,3],[123,3],[133,2],[143,1],[145,5],[151,1],[160,1],[162,3],[166,3],[170,2],[194,1],[196,5],[222,2],[225,5],[231,3],[248,2],[292,1],[335,1],[337,5],[366,2],[378,2],[381,3],[385,3],[389,2],[399,4],[404,2],[432,1],[434,1],[436,2],[439,2],[442,2],[445,5],[451,2],[454,3],[458,4],[463,2],[477,3],[481,3],[485,3],[489,3],[493,3],[497,2],[500,2],[503,2],[506,2],[529,1],[531,5],[550,5],[556,2],[579,1],[590,1],[592,3],[596,3],[627,1],[640,2],[643,4],[648,4],[653,2],[656,2]]},"1768":{"position":[[7,1],[9,4],[14,2],[17,4],[42,2],[45,1],[47,2],[70,1],[72,2],[75,2],[78,1],[80,2],[83,2],[86,2],[89,2],[95,1],[117,2],[120,4],[148,2],[151,2],[154,1],[176,1],[178,3],[192,3],[196,4],[201,1],[203,3],[207,2],[210,1],[212,1],[226,3],[234,2],[237,2],[243,2],[246,2],[249,3],[253,1],[281,1],[283,1],[285,3],[289,2],[292,2],[295,4],[315,1],[317,2],[326,2],[329,4],[334,3],[338,1],[340,2],[343,3],[347,3],[384,2],[417,2],[429,2],[447,1],[449,4],[454,2],[457,2],[460,2],[463,3],[472,2],[478,1],[480,2],[483,5],[505,1],[507,2],[510,2],[513,2],[516,3],[520,2],[548,1],[550,2],[553,2],[569,2],[572,3],[576,2],[579,3],[583,3],[600,1],[624,3],[628,3],[632,2],[635,3],[644,1],[646,2],[655,2],[663,1],[677,2],[680,4],[685,3],[689,2],[695,1],[702,1],[723,2],[726,2],[739,2],[742,1],[744,2],[747,3],[760,3],[764,1],[766,3],[770,2],[773,2],[776,2],[779,5],[785,2],[788,3],[792,3],[796,1],[798,4],[803,5],[813,5],[819,2],[831,2],[834,2],[864,1],[866,5],[872,4],[877,1],[879,2],[882,3],[886,2]]},"1770":{"position":[[0,4],[5,4],[10,1],[12,3],[16,4],[21,1],[23,6],[30,3],[34,5],[40,2],[43,2],[46,3],[50,2],[53,3],[57,5],[63,4],[68,4],[73,3],[77,4],[82,3],[86,3],[112,1],[118,1],[120,2],[123,3],[127,3],[131,2],[134,2],[137,2],[140,4],[145,4],[150,2],[175,1],[177,3],[181,4],[186,2],[189,5],[195,2],[198,2],[201,1],[203,3],[207,5],[213,4],[218,4],[223,2],[226,3],[230,3],[234,5],[240,2],[243,3],[247,1],[249,4],[254,3],[258,2],[261,3],[265,2],[268,4],[273,1],[275,5],[281,4],[286,2],[289,3],[293,3],[306,1],[308,4],[313,3],[317,5],[323,3],[327,3],[335,1],[337,3],[341,5],[347,2],[350,4],[355,4],[360,5],[366,5],[372,3],[380,1],[382,3],[386,3],[390,3],[394,2],[397,3],[401,4],[420,2],[423,2],[426,2],[429,3],[433,3],[437,2],[440,2],[446,1],[448,1],[450,3],[454,2],[457,3],[461,4],[466,2],[469,2],[472,3],[476,4],[481,2],[484,2],[510,1],[512,3],[516,2],[519,2],[522,2],[525,2],[528,3],[532,4],[537,1],[560,1],[565,1],[567,2],[570,4],[575,3],[579,6],[586,3],[590,2],[593,4],[598,2],[601,2],[621,1],[623,3],[627,2],[630,2],[633,2],[636,2],[639,3],[656,1],[660,1],[695,3],[699,1],[701,3],[705,2],[708,3],[712,5],[721,2],[724,2]]},"1772":{"position":[[24,1],[43,1],[45,4],[65,1],[67,2],[77,3],[81,2],[87,1],[89,3],[93,2],[96,2],[121,1],[140,2],[150,1],[152,4],[157,2],[160,2],[189,1],[191,3],[195,2],[198,3],[202,2],[205,2],[235,1],[237,3],[241,3],[245,3],[249,4],[261,1],[263,2],[266,2],[269,3],[273,3],[277,2],[280,2],[283,3],[287,6],[294,6],[311,1],[313,3],[317,1],[319,6],[326,3],[330,1],[332,3],[336,3],[340,3],[347,1],[357,1],[368,2],[371,3],[375,4],[380,1],[404,1],[417,2],[428,1],[446,3],[450,3],[457,1],[499,2],[510,1],[512,5],[518,3],[522,4],[527,3],[534,3],[538,4],[543,3],[547,1],[549,2]]},"1774":{"position":[[16,1],[18,2],[21,3],[25,2],[28,4],[33,4],[38,4],[43,3],[57,3],[75,1],[77,2],[109,2],[112,2],[115,2],[118,2],[125,1],[127,5],[133,3],[148,2],[158,1],[160,4],[165,3],[169,2],[172,1],[174,3],[178,2],[181,3],[185,3],[189,2],[192,2],[197,1],[199,3],[203,3],[227,3],[256,1],[258,2],[261,3],[265,1],[278,1],[280,2],[290,2],[297,1],[299,2],[302,3],[315,1],[326,3],[330,3],[334,2],[360,2],[366,1],[377,2],[380,3],[384,2],[387,1],[402,3],[406,2],[432,1],[434,2],[460,1],[468,2],[471,2],[488,1],[490,5],[496,2],[502,1],[504,3],[508,2],[516,2],[536,2],[539,2],[566,2],[569,1],[585,1],[587,5],[593,2],[596,4]]},"1776":{"position":[[4,1],[6,3],[10,4],[15,2],[18,3],[38,2],[41,3],[45,1],[47,3],[51,2],[73,1],[75,4],[80,3],[84,4],[89,3],[93,3],[97,2],[100,3],[104,5],[127,1],[129,3],[133,5],[139,2],[156,2],[159,5],[165,3],[169,4],[184,3],[188,5],[194,3],[198,2],[201,2],[204,4],[209,3],[213,2],[216,3],[220,3],[224,1],[226,3],[230,2]]},"1778":{"position":[[10,3],[23,1],[25,3],[29,2],[37,2],[40,3],[44,4],[49,1],[51,3],[55,3],[59,2],[80,1],[82,1],[84,5],[90,2],[93,5],[99,2],[102,3],[106,1],[108,3],[112,2],[115,1],[117,2],[120,4],[127,1],[129,2],[132,3],[142,1],[157,2],[160,2],[183,2],[186,1],[196,3],[200,3],[204,2],[207,2],[224,1],[230,1],[239,1],[262,1],[264,2],[282,1],[299,1],[301,3],[305,1],[307,3],[311,2],[329,1],[331,2],[334,4],[339,3],[343,6],[365,2],[368,3],[419,2],[422,2],[430,1],[432,3],[440,1],[442,2],[445,3],[449,3],[459,1],[466,1],[468,3],[472,2],[475,3],[479,6],[486,3],[490,2],[503,1],[505,2],[514,1],[516,4],[521,2],[524,3],[528,2],[548,1],[579,2],[603,1],[605,2],[614,1],[616,4],[621,2],[624,3],[628,2],[661,1],[730,2],[733,2],[736,3],[740,2],[743,2],[746,1],[748,2],[751,3],[755,4],[760,3],[764,2],[767,3],[771,2],[799,1],[801,2],[816,1],[818,4],[823,5],[829,4],[834,2],[851,3],[855,2],[858,5],[864,3],[868,4],[873,4],[878,3],[882,3],[886,1],[894,3],[898,3],[902,2],[914,1],[916,3],[920,1],[922,3],[981,3],[985,2],[988,3],[992,4],[997,3],[1001,3],[1005,1],[1007,3]]},"1780":{"position":[[4,1],[10,1],[28,1],[42,2],[45,2],[74,1],[96,2],[99,1],[101,4],[127,1],[129,4],[134,4],[139,5],[145,3],[163,2],[166,7],[188,1],[190,2],[193,1],[195,3],[217,3],[221,3],[225,1],[263,1],[265,2],[268,4],[273,3],[277,3],[281,3],[285,5],[291,2],[294,3],[298,3],[302,2]]},"1782":{"position":[[22,1],[24,2],[27,1],[29,2],[48,2],[51,3],[55,5],[79,1],[81,2],[84,4],[110,1],[112,3],[116,4],[126,1],[128,2],[131,3],[135,2],[138,4],[143,2],[146,4],[151,5],[157,2],[160,3],[164,3],[168,2],[171,2],[174,3],[178,4],[183,2],[202,1],[204,2],[207,2],[210,2],[213,3],[217,4],[222,3],[226,2],[229,2],[232,1],[234,3],[238,3],[242,2],[245,2],[248,3],[268,2],[271,1],[273,2],[276,4],[281,3],[285,2],[288,2],[314,1],[316,2],[319,2],[322,3],[326,4],[331,2],[334,3],[338,4],[343,2],[346,3],[350,3],[354,2],[357,2],[394,1],[396,3],[405,1],[407,2],[410,4],[423,2],[449,1],[451,3],[455,3],[459,2],[462,4],[467,1],[469,3],[473,3],[477,3],[481,3],[512,1],[514,1],[516,3],[520,5],[526,3],[572,1],[583,1],[585,2],[588,4],[593,1],[595,1],[597,3],[601,4],[613,2],[630,2],[643,1],[645,4],[650,2],[653,3],[657,1],[659,2],[662,2],[689,1],[697,1],[699,2],[702,4],[712,2],[715,2],[718,3],[722,2],[730,2],[733,3],[737,4],[742,2],[745,3],[762,2],[765,3],[769,4],[774,2],[777,2],[800,1],[808,1],[810,2],[813,2],[816,3],[820,6],[851,2],[854,4],[859,2],[862,4],[867,3],[871,4],[876,3],[880,1],[902,1],[916,1],[918,3],[922,3],[926,5],[945,1],[947,4],[952,3],[956,2],[959,4],[964,4],[969,2],[972,2],[975,2],[978,2],[986,1],[1006,2],[1009,2],[1034,1],[1056,2],[1059,4],[1064,2],[1067,2],[1070,2],[1073,4],[1078,1],[1080,1],[1082,4],[1087,2],[1090,3],[1094,3],[1098,2],[1101,2],[1104,4],[1109,5],[1125,3],[1129,4],[1134,3],[1138,3],[1142,3],[1146,4],[1151,1],[1153,3],[1157,2],[1160,2],[1183,1],[1185,2],[1188,4],[1212,1],[1229,1],[1231,2],[1256,1],[1258,2],[1261,4],[1269,2],[1272,2],[1275,1],[1277,3],[1288,3],[1292,2],[1295,3],[1299,4],[1304,2],[1307,2],[1310,1],[1312,5],[1318,5],[1344,1],[1362,1],[1364,3],[1368,1],[1398,1],[1400,3],[1413,1],[1431,3],[1435,3],[1439,2],[1442,2],[1445,2],[1448,2],[1456,1],[1458,4],[1463,4],[1468,2],[1485,1],[1487,4],[1492,3],[1506,3],[1510,2],[1520,1],[1522,3],[1535,1],[1540,6],[1547,3],[1551,3],[1555,2],[1558,2],[1561,2],[1564,2],[1577,1],[1579,3],[1583,2],[1591,1],[1593,1],[1595,4],[1600,2],[1603,2],[1616,1],[1618,4],[1623,2],[1626,3],[1630,4],[1635,3],[1639,1],[1641,3],[1645,2],[1648,3],[1652,3],[1678,1],[1691,2],[1694,3],[1698,3],[1702,4],[1707,2],[1710,3],[1714,4],[1719,2],[1722,2],[1741,1],[1811,2],[1814,3],[1818,4],[1823,4],[1828,2],[1831,4],[1836,3],[1840,2],[1843,3],[1847,1],[1849,3],[1853,3],[1857,4],[1862,3],[1866,4],[1871,2],[1913,2],[1958,1],[1960,2],[1963,3],[1967,1],[1969,4],[1981,1],[1988,3],[1992,5],[1998,2],[2001,1],[2003,2],[2006,3],[2010,4],[2015,3],[2019,1],[2021,2],[2024,2],[2027,3],[2031,2],[2045,1],[2047,3],[2051,5],[2057,3],[2080,1],[2102,2],[2129,1],[2162,1],[2164,5],[2176,4],[2188,1],[2212,3],[2216,2],[2235,2],[2238,2],[2241,3],[2245,2],[2255,1],[2260,5],[2273,3],[2304,1],[2335,1],[2337,2],[2348,1],[2350,2],[2353,5],[2359,2],[2362,5],[2368,2],[2380,4],[2385,3],[2394,3],[2398,3],[2416,1],[2418,5],[2424,2],[2443,1],[2452,2],[2455,3],[2464,2],[2467,1],[2483,2],[2502,1],[2520,1],[2522,2],[2525,4],[2530,4],[2535,2],[2556,1],[2558,2],[2566,2],[2569,5],[2581,4],[2586,2],[2589,6],[2622,2],[2625,4],[2630,4],[2635,6],[2658,1],[2660,2],[2663,2],[2666,3],[2670,3],[2674,3],[2678,2],[2681,3],[2706,1],[2708,3],[2712,2],[2725,1],[2727,4],[2732,1],[2734,3],[2738,3],[2752,1],[2765,1],[2767,4],[2772,2],[2775,2],[2783,2],[2786,3],[2800,2],[2803,3],[2855,2],[2884,1],[2886,2],[2889,4],[2894,3],[2898,3],[2902,5],[2908,4],[2913,2],[2932,1],[2955,1],[2957,3],[2961,3],[2965,2],[2968,3],[2972,4],[2977,5],[2983,4],[2988,1],[2990,3],[2994,3],[2998,4],[3003,3],[3007,2],[3010,4],[3015,3],[3040,1],[3042,4],[3047,4],[3059,2],[3077,3],[3081,2],[3084,2],[3087,2],[3090,3],[3094,4],[3099,3],[3103,2],[3138,1],[3140,2],[3143,4],[3148,4],[3153,3],[3157,3],[3161,3],[3165,2],[3168,3],[3172,2],[3189,1],[3198,3],[3202,2],[3205,2],[3208,3],[3212,2],[3220,3],[3224,3],[3228,3],[3232,3],[3236,3],[3240,3],[3244,3],[3248,5],[3254,2],[3257,1],[3259,3],[3263,2],[3282,1],[3284,2],[3294,3],[3316,1],[3318,5],[3324,4],[3329,2],[3332,5],[3338,2],[3341,2]]},"1784":{"position":[[22,1],[24,3],[33,1],[35,3],[39,2],[42,3],[46,4],[51,6],[58,2],[61,2],[64,4],[69,3]]},"1786":{"position":[[0,3],[8,1],[10,3],[36,1],[38,1],[40,1],[42,4],[47,2],[50,4],[55,2],[58,5],[64,4],[69,3],[87,1],[89,2],[114,3],[118,4],[123,3],[127,2],[130,3],[134,5]]},"1788":{"position":[[43,1],[67,1],[89,1],[113,1],[115,2],[141,1],[162,1],[164,1],[166,6],[173,3],[184,3],[188,1],[190,5],[196,5],[202,3],[206,3],[210,3],[214,4],[219,4],[224,3],[228,4],[233,4],[264,3],[268,3],[272,2],[275,1],[277,2],[280,4],[285,4],[290,3],[294,3],[298,2],[339,1],[350,2],[359,1],[402,1],[404,4],[409,3],[413,1],[415,4],[429,1],[450,2],[453,3],[457,1],[459,5],[465,2],[471,1],[473,2],[476,3],[495,3],[499,2],[502,3],[506,5],[512,4],[523,1],[532,1],[534,4],[539,3],[543,5],[551,1],[575,3],[579,2],[609,1],[611,4],[616,4],[628,2],[631,3],[635,1],[637,3],[641,3],[645,3],[649,3],[653,3],[657,4],[662,2],[665,2],[668,4],[673,3],[677,4],[682,2],[685,3],[689,1],[691,3],[731,1],[733,2],[736,3],[740,2],[743,2],[755,1],[757,2],[760,2],[770,1],[772,2],[775,5],[790,1],[799,1],[801,3],[805,3],[809,3],[813,5],[819,4],[824,3],[828,3],[832,3],[836,2],[839,2],[851,2],[854,2],[864,1],[866,5],[882,1],[887,3],[891,1],[893,3],[897,2],[900,3],[904,4],[909,2]]},"1790":{"position":[[32,1],[40,1],[42,2],[45,2],[48,3],[52,3],[69,1],[71,4],[76,3],[80,3],[84,3],[88,2],[124,1],[145,1],[147,4],[152,3],[160,1],[162,4],[167,2],[170,3],[174,1],[176,5],[182,3],[186,2],[189,4],[194,5],[200,1],[202,2],[205,2],[208,2],[211,3],[215,3],[219,6],[232,3],[236,4],[241,2],[282,1],[300,1],[302,3],[306,3],[317,1],[319,3],[323,5],[329,6],[336,2],[339,2],[342,2],[345,3],[363,1],[365,4],[386,1],[404,1],[406,5],[412,4],[417,3],[421,2],[424,2],[432,2],[435,5],[441,2],[444,3],[448,1],[450,5],[456,3],[460,3],[464,2],[467,4],[472,2],[475,2]]},"1792":{"position":[[13,2],[16,1],[18,3],[22,4],[27,4],[32,3],[36,3],[40,3],[44,1],[46,2],[49,3],[53,2],[56,5],[62,3],[66,3],[70,3],[74,3],[78,2],[81,4],[86,3],[90,5],[96,3],[100,3],[104,2],[107,3],[111,2],[114,4],[119,3],[132,1],[143,5],[149,4],[154,2],[157,3],[161,3],[165,2],[168,1],[170,2],[173,3]]},"1794":{"position":[[18,1],[38,3],[49,1],[51,2],[54,5],[60,2],[63,1],[65,2],[68,4],[73,2],[76,3],[80,5],[96,1],[98,4],[103,3],[107,2],[110,3],[114,4],[119,2],[131,1],[137,1],[139,3],[143,3],[147,4],[152,3],[156,5],[172,3],[176,2],[179,3],[183,5],[200,1],[202,4],[207,3],[211,3],[215,5],[221,4],[226,3],[230,2],[233,3],[237,4],[242,2],[245,3],[249,2],[252,3],[256,3],[285,1],[287,3],[291,5],[297,5],[303,2],[306,3],[310,5],[316,3],[320,3],[324,3],[328,4],[333,2],[345,1],[347,1],[349,7],[382,2],[422,1],[424,2],[438,1],[440,4],[445,3],[460,1],[462,4],[467,4],[472,2],[475,3],[479,2],[482,3],[486,2],[489,2],[492,2],[495,2],[509,1],[521,2],[529,3],[538,1],[540,3],[565,1],[567,3],[571,1],[573,2],[595,2],[603,3],[607,2],[610,3],[614,1],[616,3],[640,1],[642,1],[644,2],[647,3],[651,2],[674,1],[676,3],[700,1],[702,2],[705,3],[709,3],[713,3],[717,3],[721,2],[724,2],[741,1],[749,2],[752,3],[756,2],[759,6],[766,3],[770,2],[787,1],[789,4],[794,4],[799,4],[804,3],[808,4],[813,4],[818,3],[842,1],[844,3],[848,2],[881,1],[883,2],[893,6],[909,1],[911,4],[932,1],[934,4],[954,1],[956,3],[960,1],[962,3],[966,3],[975,2],[978,2],[988,1],[990,2],[993,1],[995,3],[999,5],[1005,3],[1009,2],[1012,2],[1015,4],[1020,2],[1023,4],[1028,2],[1031,2],[1041,2],[1057,1],[1059,2],[1087,4],[1108,1],[1110,4],[1115,2],[1118,4]]},"1796":{"position":[[0,2],[3,4],[8,6],[37,1],[39,3],[43,3],[47,3],[51,5],[61,1],[82,1],[104,3],[124,1],[146,1],[148,4],[153,3],[157,2],[160,3],[191,2],[194,3],[198,2],[201,3],[205,5],[211,3],[215,1],[217,4],[222,1],[224,3],[228,2],[231,2],[248,3],[252,4],[257,2],[260,4],[269,1],[271,3],[275,2],[278,3],[282,2],[285,2],[288,4],[293,4],[298,1],[300,3],[304,5],[310,2],[313,4],[318,2],[321,2],[335,3],[339,1],[341,1],[343,3],[347,3],[355,1],[357,2],[360,2],[363,3],[367,2],[377,1],[379,2],[382,3],[386,3],[390,2],[393,2],[396,4],[401,3],[405,3],[409,2],[412,5],[418,3]]},"1798":{"position":[[7,1],[9,3],[13,3],[17,3],[21,4],[33,1],[35,4],[40,5],[46,1],[48,2],[51,3],[55,2],[61,2],[88,2],[99,1],[101,4],[106,2],[109,1],[111,1],[113,4],[118,2],[121,5],[127,3],[138,1],[140,3],[144,3],[148,3],[152,1],[154,5],[160,3],[178,2],[181,3],[185,3],[189,1],[191,1],[193,2],[196,5],[202,3],[213,1],[215,4],[220,5],[226,2],[229,2],[232,2],[235,4],[240,2],[243,3],[247,1],[249,2],[252,4],[257,3],[261,2],[264,1],[266,3],[270,4],[275,3]]},"1800":{"position":[[10,5],[16,3],[25,2],[37,1],[48,2],[51,3],[70,1],[76,2],[79,6],[86,4],[91,3],[95,2],[98,4],[115,3],[119,3],[123,3],[127,3],[131,1],[133,4],[138,2],[141,2],[144,4],[149,5],[177,1],[179,2],[182,4],[187,1],[189,3],[193,1],[195,3],[199,3],[203,2],[206,5],[212,2],[215,2],[218,3],[222,3],[226,4],[231,4]]},"1802":{"position":[[12,5],[18,3],[22,2],[25,3],[29,3],[33,1],[35,1],[37,2],[40,3],[44,3],[59,3],[63,2],[81,3],[91,1],[93,2],[96,2],[99,2],[102,2],[105,2],[108,3],[112,5],[118,1],[120,4],[125,2],[128,2],[131,3],[135,3],[139,3],[146,1],[156,3],[175,3],[195,1],[197,3],[201,1],[203,5],[209,1],[211,2],[218,1],[236,1],[238,4],[243,2],[261,1],[263,2],[273,1],[275,4],[280,4],[285,1],[287,2],[290,3],[294,4],[344,3],[348,3],[352,2],[371,1],[388,3],[392,3],[411,1],[413,5],[419,3],[423,2],[426,4],[431,2],[453,3],[464,1],[582,4],[587,2],[590,2],[593,2],[605,1],[607,3],[622,3],[633,1],[754,1],[756,4],[761,2],[764,2],[776,1],[778,4],[783,1],[785,1],[787,3],[791,4],[796,3],[800,2],[803,2],[806,3],[810,4],[815,1],[817,3],[821,1],[823,2],[826,3],[830,3],[834,3],[857,3],[867,1],[876,1],[878,4],[883,4],[888,2],[891,2],[894,2],[897,2],[915,1],[917,2],[920,3],[924,3],[928,4],[933,2],[936,3],[940,2],[943,3],[947,4],[958,1],[960,2],[982,3],[986,1],[988,3],[992,3],[996,3],[1000,3],[1004,3],[1008,2],[1011,3],[1015,3],[1019,2],[1022,3],[1026,5],[1032,2],[1035,2],[1041,3],[1062,1],[1076,4],[1081,2],[1084,2],[1087,3],[1091,5],[1097,2],[1100,4],[1105,3],[1119,3],[1123,3],[1127,3],[1131,4],[1136,1],[1138,1],[1140,2],[1143,3],[1147,4],[1152,5],[1158,2],[1161,4],[1166,2],[1182,1],[1184,4],[1205,1],[1207,5],[1213,4],[1244,1],[1246,2],[1249,2],[1252,3],[1264,2],[1267,2],[1270,3],[1274,4],[1279,2]]}}}],["0",{"_index":261,"t":{"49":{"position":[[346,2]]},"97":{"position":[[105,1]]},"132":{"position":[[990,1]]},"170":{"position":[[952,1]]},"174":{"position":[[2123,4]]},"666":{"position":[[347,1]]},"676":{"position":[[517,1]]},"709":{"position":[[2267,1]]},"733":{"position":[[891,1],[942,1]]},"774":{"position":[[883,1]]},"791":{"position":[[566,1]]},"795":{"position":[[767,1],[817,1]]},"797":{"position":[[2046,1]]},"855":{"position":[[909,1]]},"861":{"position":[[356,1]]},"893":{"position":[[2000,2]]},"938":{"position":[[351,3]]},"945":{"position":[[772,1]]},"1067":{"position":[[774,1]]},"1099":{"position":[[1663,2],[1895,2]]},"1143":{"position":[[840,2]]},"1389":{"position":[[1514,3],[1835,3]]},"1485":{"position":[[325,1]]},"1487":{"position":[[734,1]]},"1489":{"position":[[354,1]]},"1558":{"position":[[2004,2]]}}}],["0+△ϕ\\phi_0",{"_index":2594,"t":{"723":{"position":[[415,11]]}}}],["0,0.25,0.5,0.75,1}\\{0",{"_index":2561,"t":{"709":{"position":[[2133,23]]}}}],["0,1",{"_index":2718,"t":{"774":{"position":[[636,5]]}}}],["0,1\\}^{n\\time",{"_index":3115,"t":{"853":{"position":[[316,16]]}}}],["0,1\\}γi​∈{0,1",{"_index":4800,"t":{"1485":{"position":[[308,16]]}}}],["0,1\\}ζi​∈{0,1",{"_index":4826,"t":{"1487":{"position":[[717,16]]}}}],["0,1][0,1][0,1",{"_index":2721,"t":{"774":{"position":[[842,15]]}}}],["0,r0",{"_index":4755,"t":{"1455":{"position":[[321,9]]}}}],["0.0",{"_index":689,"t":{"149":{"position":[[473,3]]},"1499":{"position":[[723,6]]}}}],["0.001",{"_index":331,"t":{"63":{"position":[[135,5]]},"1136":{"position":[[78,6]]},"1199":{"position":[[186,7]]}}}],["0.0014",{"_index":4865,"t":{"1507":{"position":[[157,7]]}}}],["0.001p<0.001",{"_index":4677,"t":{"1431":{"position":[[1914,14],[1944,14],[2004,13]]}}}],["0.002",{"_index":1499,"t":{"372":{"position":[[7,5]]}}}],["0.007",{"_index":238,"t":{"38":{"position":[[457,5]]}}}],["0.009",{"_index":3392,"t":{"905":{"position":[[177,5]]}}}],["0.01",{"_index":693,"t":{"151":{"position":[[105,4]]},"155":{"position":[[1076,4]]},"589":{"position":[[1360,7]]},"1028":{"position":[[400,6]]},"1145":{"position":[[190,5]]},"1199":{"position":[[194,5],[422,4]]},"1434":{"position":[[132,5]]}}}],["0.01p<0.01",{"_index":4679,"t":{"1431":{"position":[[1974,11]]}}}],["0.02",{"_index":1496,"t":{"370":{"position":[[42,4]]},"905":{"position":[[196,4]]},"1558":{"position":[[1950,4]]}}}],["0.02\\%84.4%±0.02",{"_index":2412,"t":{"672":{"position":[[970,17]]}}}],["0.03",{"_index":4063,"t":{"1199":{"position":[[200,5]]}}}],["0.035",{"_index":4087,"t":{"1225":{"position":[[595,6]]},"1227":{"position":[[1516,6]]}}}],["0.04",{"_index":1817,"t":{"523":{"position":[[874,5]]},"934":{"position":[[1968,5]]},"945":{"position":[[920,5]]}}}],["0.05",{"_index":240,"t":{"38":{"position":[[468,4]]},"182":{"position":[[291,4]]},"244":{"position":[[30,4]]}}}],["0.05p<0.05",{"_index":3007,"t":{"805":{"position":[[169,10]]}}}],["0.08",{"_index":1887,"t":{"527":{"position":[[2736,5]]},"823":{"position":[[50,6]]}}}],["0.08%/0.16%/0.32%/0.65",{"_index":3043,"t":{"821":{"position":[[97,23]]}}}],["0.09",{"_index":1886,"t":{"527":{"position":[[2728,5]]}}}],["0.099",{"_index":692,"t":{"151":{"position":[[98,6]]}}}],["0.1",{"_index":528,"t":{"106":{"position":[[127,3]]},"149":{"position":[[403,3]]},"517":{"position":[[999,3]]},"527":{"position":[[448,4]]},"674":{"position":[[766,5]]},"786":{"position":[[4626,4]]},"905":{"position":[[377,3]]},"1012":{"position":[[443,3]]},"1014":{"position":[[1657,4]]},"1039":{"position":[[231,6]]},"1047":{"position":[[393,4]]},"1157":{"position":[[59,4]]},"1159":{"position":[[877,4]]},"1289":{"position":[[520,4]]},"1317":{"position":[[0,4],[243,4]]},"1319":{"position":[[64,4]]}}}],["0.1,0.3,0.5}\\{0.1",{"_index":3032,"t":{"814":{"position":[[469,19]]}}}],["0.13",{"_index":3060,"t":{"830":{"position":[[86,6]]}}}],["0.16",{"_index":3053,"t":{"823":{"position":[[57,6]]}}}],["0.1782",{"_index":690,"t":{"151":{"position":[[82,7]]}}}],["0.1\\%77.8%±0.1",{"_index":2407,"t":{"672":{"position":[[772,15]]}}}],["0.1\\%83.7%±0.1",{"_index":2410,"t":{"672":{"position":[[890,15]]}}}],["0.1pdrop​=0.1",{"_index":1340,"t":{"319":{"position":[[226,13]]},"322":{"position":[[415,13]]}}}],["0.1ϵls​=0.1",{"_index":1342,"t":{"319":{"position":[[316,11]]}}}],["0.2",{"_index":2046,"t":{"581":{"position":[[147,4]]},"1314":{"position":[[461,3]]},"1558":{"position":[[296,3]]}}}],["0.25",{"_index":2562,"t":{"709":{"position":[[2157,5]]}}}],["0.256",{"_index":294,"t":{"53":{"position":[[218,5]]}}}],["0.26",{"_index":3061,"t":{"830":{"position":[[93,6]]}}}],["0.3",{"_index":3033,"t":{"814":{"position":[[489,4]]},"1134":{"position":[[714,3]]},"1199":{"position":[[206,4]]},"1314":{"position":[[493,3]]},"1496":{"position":[[261,3]]}}}],["0.3/0.6/1.2m",{"_index":3024,"t":{"814":{"position":[[104,12]]}}}],["0.30",{"_index":4857,"t":{"1499":{"position":[[746,6]]}}}],["0.32",{"_index":3054,"t":{"823":{"position":[[64,6]]}}}],["0.3\\alpha",{"_index":1377,"t":{"326":{"position":[[845,11]]}}}],["0.3m",{"_index":3040,"t":{"816":{"position":[[158,4]]}}}],["0.3α=0.3",{"_index":1378,"t":{"326":{"position":[[859,8]]}}}],["0.4",{"_index":1315,"t":{"315":{"position":[[38,4]]},"656":{"position":[[480,4]]},"664":{"position":[[99,4]]},"670":{"position":[[1376,6]]},"707":{"position":[[457,4]]},"979":{"position":[[867,4]]},"1431":{"position":[[2100,5]]}}}],["0.47",{"_index":4856,"t":{"1499":{"position":[[738,7]]}}}],["0.5",{"_index":1673,"t":{"457":{"position":[[1352,3]]},"681":{"position":[[1098,4]]},"709":{"position":[[2163,4],[2248,3]]},"774":{"position":[[1156,5]]},"786":{"position":[[2137,4]]},"1141":{"position":[[126,4]]}}}],["0.5%−5%0.5",{"_index":2414,"t":{"672":{"position":[[1370,12]]}}}],["0.5,0.5",{"_index":3939,"t":{"1141":{"position":[[114,11]]}}}],["0.5>0.5",{"_index":2724,"t":{"774":{"position":[[1162,7]]}}}],["0.5\\}{0.1,0.3,0.5",{"_index":3034,"t":{"814":{"position":[[494,18]]}}}],["0.5][−0.5,0.5",{"_index":3940,"t":{"1141":{"position":[[131,14]]}}}],["0.5},step\\_",{"_index":1330,"t":{"317":{"position":[[296,11]]}}}],["0.5}\\cdot",{"_index":1326,"t":{"317":{"position":[[267,9]]}}}],["0.5−8%0.5",{"_index":2350,"t":{"662":{"position":[[1043,9]]}}}],["0.6",{"_index":310,"t":{"55":{"position":[[136,4]]},"65":{"position":[[75,5]]}}}],["0.65",{"_index":3055,"t":{"823":{"position":[[71,5]]}}}],["0.6\\alpha",{"_index":1349,"t":{"322":{"position":[[578,11]]}}}],["0.6m",{"_index":3405,"t":{"914":{"position":[[117,4]]}}}],["0.6α=0.6",{"_index":1350,"t":{"322":{"position":[[592,8]]}}}],["0.7128",{"_index":691,"t":{"151":{"position":[[90,7]]}}}],["0.75",{"_index":2563,"t":{"709":{"position":[[2168,5],[2225,4]]}}}],["0.75top",{"_index":3398,"t":{"905":{"position":[[406,7]]}}}],["0.7\\tau",{"_index":2033,"t":{"569":{"position":[[354,9]]}}}],["0.7τ=0.7",{"_index":2034,"t":{"569":{"position":[[366,8]]}}}],["0.8",{"_index":3932,"t":{"1134":{"position":[[832,3]]},"1205":{"position":[[203,4]]},"1314":{"position":[[799,3]]}}}],["0.85",{"_index":3037,"t":{"814":{"position":[[593,4]]}}}],["0.89",{"_index":4575,"t":{"1397":{"position":[[1552,4]]}}}],["0.9",{"_index":287,"t":{"53":{"position":[[139,3],[150,3]]},"80":{"position":[[44,3]]},"317":{"position":[[48,4]]},"324":{"position":[[285,3]]},"352":{"position":[[590,4]]},"837":{"position":[[296,4]]},"881":{"position":[[411,4]]}}}],["0.97",{"_index":296,"t":{"53":{"position":[[236,4]]}}}],["0.98β1​=0.9,β2​=0.98",{"_index":1320,"t":{"317":{"position":[[63,20]]}}}],["0.99",{"_index":290,"t":{"53":{"position":[[165,4]]},"1399":{"position":[[233,6]]}}}],["0.9999",{"_index":302,"t":{"53":{"position":[[290,6]]}}}],["0.999β2​=0.999",{"_index":526,"t":{"106":{"position":[[81,14]]}}}],["0.9β1​=0.9",{"_index":524,"t":{"106":{"position":[[50,10]]}}}],["0/1",{"_index":3991,"t":{"1159":{"position":[[508,3]]}}}],["000",{"_index":2219,"t":{"612":{"position":[[190,3]]}}}],["01",{"_index":5027,"t":{"1589":{"position":[[64,2],[102,2],[135,2],[176,2]]}}}],["02",{"_index":5003,"t":{"1587":{"position":[[27,2],[57,2]]},"1589":{"position":[[225,2],[263,2],[301,2]]}}}],["03",{"_index":4885,"t":{"1538":{"position":[[181,3]]},"1589":{"position":[[228,2],[266,2]]}}}],["04",{"_index":5033,"t":{"1589":{"position":[[304,2]]}}}],["05",{"_index":50,"t":{"7":{"position":[[239,2],[261,2]]}}}],["07",{"_index":4884,"t":{"1538":{"position":[[177,3]]}}}],["0<β1,β2<1.0",{"_index":2988,"t":{"801":{"position":[[2060,11]]}}}],["0\\eta",{"_index":2917,"t":{"797":{"position":[[1570,7]]}}}],["0\\gamma",{"_index":2900,"t":{"797":{"position":[[1072,9]]}}}],["0\\phi_0ϕ0",{"_index":2593,"t":{"723":{"position":[[353,11]]}}}],["0\\tau_0τ0",{"_index":4750,"t":{"1455":{"position":[[46,11]]}}}],["0\\triangl",{"_index":2822,"t":{"791":{"position":[[540,12]]}}}],["0g≈0",{"_index":4530,"t":{"1389":{"position":[[1653,4]]}}}],["0m=0",{"_index":3719,"t":{"1080":{"position":[[422,5]]}}}],["0r>0",{"_index":3696,"t":{"1067":{"position":[[1120,4]]}}}],["0si,j​<0",{"_index":3227,"t":{"861":{"position":[[1292,8]]}}}],["0wi,j​∂wi,j′​∂l​<0",{"_index":3168,"t":{"855":{"position":[[614,18]]}}}],["0wi,j′​=0",{"_index":3175,"t":{"855":{"position":[[873,9]]}}}],["0}γ=0",{"_index":3074,"t":{"839":{"position":[[285,6]]}}}],["0γ>0",{"_index":2901,"t":{"797":{"position":[[1084,4]]}}}],["0η>0",{"_index":2918,"t":{"797":{"position":[[1580,4]]}}}],["0​,r0",{"_index":4758,"t":{"1455":{"position":[[343,11]]}}}],["0∣|\\phi_0|∣ϕ0",{"_index":2605,"t":{"723":{"position":[[790,17]]}}}],["0∣|\\theta",{"_index":2606,"t":{"723":{"position":[[1047,17]]}}}],["0△=0",{"_index":2823,"t":{"791":{"position":[[555,4]]}}}],["1",{"_index":214,"t":{"33":{"position":[[320,1]]},"38":{"position":[[210,3]]},"40":{"position":[[162,1]]},"49":{"position":[[281,1],[723,2],[804,2]]},"58":{"position":[[227,2]]},"78":{"position":[[827,2],[881,1]]},"91":{"position":[[535,2],[1073,1],[1108,1],[1505,3],[1752,2],[1970,3],[2028,4],[2046,4],[2061,1],[2098,3],[2355,1]]},"95":{"position":[[122,2],[356,2]]},"104":{"position":[[6,1]]},"130":{"position":[[1199,4],[1225,4]]},"132":{"position":[[846,4]]},"138":{"position":[[232,1]]},"149":{"position":[[461,1]]},"155":{"position":[[6,1]]},"170":{"position":[[940,1]]},"174":{"position":[[2128,2],[2140,3]]},"177":{"position":[[481,1]]},"182":{"position":[[116,2]]},"304":{"position":[[414,1]]},"308":{"position":[[469,2]]},"310":{"position":[[865,1]]},"339":{"position":[[249,1]]},"352":{"position":[[21,2],[743,2]]},"354":{"position":[[298,1]]},"376":{"position":[[22,1]]},"386":{"position":[[205,1]]},"393":{"position":[[4,1]]},"395":{"position":[[140,1]]},"515":{"position":[[486,1]]},"517":{"position":[[851,2]]},"529":{"position":[[316,3],[391,1],[1420,1]]},"596":{"position":[[592,2]]},"598":{"position":[[2280,2]]},"608":{"position":[[677,1]]},"612":{"position":[[187,2]]},"644":{"position":[[295,1]]},"658":{"position":[[1359,1]]},"690":{"position":[[486,1]]},"694":{"position":[[657,3]]},"709":{"position":[[2272,1]]},"719":{"position":[[894,1]]},"727":{"position":[[391,3],[506,1]]},"770":{"position":[[54,3]]},"774":{"position":[[861,1],[1114,1]]},"786":{"position":[[779,2],[2536,1]]},"797":{"position":[[1149,2],[2280,1]]},"801":{"position":[[1765,2],[1864,2]]},"807":{"position":[[403,1]]},"814":{"position":[[676,1]]},"821":{"position":[[262,2]]},"853":{"position":[[1962,2]]},"861":{"position":[[221,2]]},"870":{"position":[[6,1],[293,1],[483,1],[1283,1]]},"873":{"position":[[581,1],[590,1],[1412,2],[1440,2]]},"885":{"position":[[222,3]]},"887":{"position":[[601,1],[844,3]]},"909":{"position":[[6,1],[122,1]]},"928":{"position":[[33,4]]},"945":{"position":[[776,1]]},"951":{"position":[[148,1]]},"963":{"position":[[112,1]]},"979":{"position":[[352,2]]},"986":{"position":[[300,1]]},"990":{"position":[[198,2]]},"1002":{"position":[[6,1],[256,1]]},"1006":{"position":[[2196,1]]},"1037":{"position":[[218,1]]},"1107":{"position":[[550,1]]},"1126":{"position":[[1745,2]]},"1136":{"position":[[336,1],[584,1]]},"1147":{"position":[[474,1]]},"1195":{"position":[[264,1]]},"1227":{"position":[[716,2]]},"1246":{"position":[[802,1]]},"1248":{"position":[[461,1]]},"1250":{"position":[[74,2]]},"1262":{"position":[[6,1],[74,1]]},"1291":{"position":[[1219,1],[1373,1]]},"1298":{"position":[[414,1]]},"1305":{"position":[[369,1]]},"1310":{"position":[[116,1],[242,2]]},"1314":{"position":[[639,1]]},"1337":{"position":[[0,1]]},"1347":{"position":[[824,1]]},"1360":{"position":[[6,1]]},"1364":{"position":[[157,1],[438,1]]},"1379":{"position":[[330,3],[533,3]]},"1389":{"position":[[145,1],[942,1]]},"1431":{"position":[[511,2]]},"1442":{"position":[[615,1]]},"1455":{"position":[[707,1]]},"1468":{"position":[[1480,1],[1491,1]]},"1499":{"position":[[93,1],[494,1],[846,2]]},"1531":{"position":[[294,2],[304,3]]},"1538":{"position":[[102,2],[322,2]]},"1558":{"position":[[343,1]]},"1587":{"position":[[175,1]]},"1646":{"position":[[386,2]]},"1655":{"position":[[1210,1]]},"1659":{"position":[[1120,1]]},"1674":{"position":[[566,1]]},"1710":{"position":[[162,1]]},"1788":{"position":[[549,1]]}}}],["1%1\\%1",{"_index":2413,"t":{"672":{"position":[[1338,7]]}}}],["1(a",{"_index":1629,"t":{"443":{"position":[[14,4]]},"628":{"position":[[423,4]]},"1646":{"position":[[323,4]]}}}],["1(b",{"_index":1631,"t":{"445":{"position":[[110,4]]},"628":{"position":[[700,5]]},"1646":{"position":[[389,4]]}}}],["1(c",{"_index":3264,"t":{"870":{"position":[[1642,6]]},"1646":{"position":[[761,4]]}}}],["1(d",{"_index":5165,"t":{"1646":{"position":[[1693,4]]}}}],["1(e",{"_index":5166,"t":{"1646":{"position":[[1795,4]]}}}],["1)(m+1",{"_index":3311,"t":{"893":{"position":[[272,7]]}}}],["1)fp2v​,fv2p​=bi",{"_index":832,"t":{"172":{"position":[[617,17]]}}}],["1)gp​∈(0,1",{"_index":4532,"t":{"1389":{"position":[[1839,11]]}}}],["1)g∈(0,1",{"_index":4525,"t":{"1389":{"position":[[1518,9]]}}}],["1)}(w_{ij",{"_index":2982,"t":{"801":{"position":[[1751,11],[1850,11]]}}}],["1)}vc​∈rd×(l+1",{"_index":1474,"t":{"358":{"position":[[414,15]]}}}],["1+at+11+a_{t+1}1+at+1",{"_index":3554,"t":{"990":{"position":[[532,22]]}}}],["1+δ))]j",{"_index":4418,"t":{"1354":{"position":[[542,12]]}}}],["1,000",{"_index":2196,"t":{"602":{"position":[[488,5]]},"612":{"position":[[124,5]]},"622":{"position":[[518,6]]},"1379":{"position":[[1223,6]]},"1393":{"position":[[377,5]]}}}],["1,1",{"_index":536,"t":{"108":{"position":[[67,3]]}}}],["1,100",{"_index":1688,"t":{"464":{"position":[[82,5]]}}}],["1,1}k",{"_index":535,"t":{"108":{"position":[[56,9]]}}}],["1,2,3,4,5,6,7,8,9,10,11,12,13,14,15][1,2,3,4,5,6,7,8,9,10,11,12,13,14,15][1,2,3,4,5,6,7,8,9,10,11,12,13,14,15",{"_index":4906,"t":{"1540":{"position":[[183,111]]}}}],["1,2,3,5,7,9,11,12\\}n∈{1,2,3,5,7,9,11,12",{"_index":2388,"t":{"670":{"position":[[646,42]]}}}],["1,2,4,8",{"_index":3045,"t":{"821":{"position":[[250,11]]}}}],["1,3,5,10}\\{1,3,5,10\\}{1,3,5,10",{"_index":4426,"t":{"1357":{"position":[[536,32]]}}}],["1,5,10,20,50}\\{1",{"_index":2557,"t":{"709":{"position":[[1182,18]]}}}],["1,5,10,20,50}\\{1,5,10,20,50\\}{1,5,10,20,50",{"_index":2547,"t":{"705":{"position":[[295,44]]}}}],["1,5,20,100,150",{"_index":3937,"t":{"1139":{"position":[[37,18]]}}}],["1,5,20,100,150}\\{1",{"_index":3936,"t":{"1139":{"position":[[0,20]]}}}],["1,836",{"_index":1991,"t":{"544":{"position":[[208,5]]},"573":{"position":[[167,5]]}}}],["1,\\dot",{"_index":2874,"t":{"797":{"position":[[320,8]]}}}],["1,xkeypoint",{"_index":610,"t":{"130":{"position":[[1136,11]]}}}],["1,ykeypoint",{"_index":611,"t":{"130":{"position":[[1148,11]]}}}],["1,γ2,…,γm}\\gamma",{"_index":4795,"t":{"1485":{"position":[[207,20]]}}}],["1,ζ2,…,ζk}\\zeta",{"_index":4821,"t":{"1487":{"position":[[621,19]]}}}],["1.0",{"_index":688,"t":{"149":{"position":[[454,3]]},"315":{"position":[[90,3]]},"1604":{"position":[[18,3],[71,3],[129,3],[194,3],[245,3]]}}}],["1.0/hello.md",{"_index":5069,"t":{"1608":{"position":[[89,12]]}}}],["1.0<β1​,β2​<1",{"_index":2989,"t":{"801":{"position":[[2093,14]]}}}],["1.1",{"_index":4068,"t":{"1205":{"position":[[196,4]]},"1273":{"position":[[476,4]]},"1423":{"position":[[1316,4]]}}}],["1.10",{"_index":3062,"t":{"830":{"position":[[100,5]]}}}],["1.14",{"_index":2398,"t":{"670":{"position":[[1578,5]]}}}],["1.19",{"_index":2399,"t":{"670":{"position":[[1622,5]]}}}],["1.1e1211e9×103=1.1e12",{"_index":2213,"t":{"610":{"position":[[153,21]]}}}],["1.2",{"_index":2790,"t":{"786":{"position":[[4698,4]]},"1314":{"position":[[868,5]]}}}],["1.25",{"_index":4329,"t":{"1314":{"position":[[565,4]]}}}],["1.26",{"_index":4576,"t":{"1399":{"position":[[242,6]]}}}],["1.28m",{"_index":280,"t":{"53":{"position":[[0,5]]}}}],["1.2m",{"_index":3283,"t":{"885":{"position":[[175,4]]},"887":{"position":[[617,4],[668,4]]},"909":{"position":[[93,4]]},"914":{"position":[[85,4]]},"928":{"position":[[16,4]]},"938":{"position":[[100,4]]}}}],["1.2tb",{"_index":2650,"t":{"741":{"position":[[186,5]]}}}],["1.3",{"_index":682,"t":{"147":{"position":[[453,3]]}}}],["1.37",{"_index":3277,"t":{"881":{"position":[[338,6]]}}}],["1.3b",{"_index":1549,"t":{"397":{"position":[[24,5]]},"1544":{"position":[[341,4]]},"1546":{"position":[[526,5]]}}}],["1.3m",{"_index":491,"t":{"102":{"position":[[38,5]]}}}],["1.3×1.3\\times1.3",{"_index":2374,"t":{"668":{"position":[[688,18]]}}}],["1.4e152×175e9×(41×98+103)=1.4e15",{"_index":2215,"t":{"610":{"position":[[273,32]]}}}],["1.5",{"_index":340,"t":{"65":{"position":[[93,4]]},"317":{"position":[[334,5]]},"803":{"position":[[388,5]]},"814":{"position":[[421,5]]}}}],["1.6",{"_index":2235,"t":{"620":{"position":[[162,4]]}}}],["1.76",{"_index":3279,"t":{"881":{"position":[[428,5]]}}}],["1.77",{"_index":3412,"t":{"926":{"position":[[43,6]]}}}],["1.8",{"_index":3042,"t":{"816":{"position":[[214,4]]}}}],["1.88",{"_index":4848,"t":{"1499":{"position":[[324,5]]}}}],["1.8k",{"_index":1977,"t":{"539":{"position":[[286,7]]},"583":{"position":[[68,4]]}}}],["1.91",{"_index":4854,"t":{"1499":{"position":[[715,7]]}}}],["1.9k",{"_index":2377,"t":{"670":{"position":[[139,4]]}}}],["1/2/l",{"_index":3059,"t":{"828":{"position":[[113,5]]}}}],["1/4",{"_index":1347,"t":{"322":{"position":[[336,3]]}}}],["1/r1/r1/r",{"_index":2280,"t":{"630":{"position":[[1853,9]]}}}],["1/taj​=1/t",{"_index":3604,"t":{"1006":{"position":[[739,10]]}}}],["10",{"_index":326,"t":{"63":{"position":[[33,3]]},"163":{"position":[[771,2]]},"165":{"position":[[25,4],[1343,2],[2499,2],[2833,2]]},"207":{"position":[[9,3]]},"209":{"position":[[41,2]]},"317":{"position":[[103,4]]},"322":{"position":[[497,3]]},"336":{"position":[[1896,2]]},"414":{"position":[[105,3]]},"473":{"position":[[48,2]]},"494":{"position":[[179,3]]},"517":{"position":[[912,2]]},"548":{"position":[[92,2]]},"553":{"position":[[277,2]]},"569":{"position":[[742,3]]},"668":{"position":[[173,4],[190,4],[207,4]]},"705":{"position":[[244,2]]},"707":{"position":[[583,3]]},"709":{"position":[[1204,3],[1368,2]]},"814":{"position":[[654,4],[667,4],[680,4],[693,4]]},"821":{"position":[[456,4]]},"866":{"position":[[467,2]]},"870":{"position":[[699,3],[1208,3],[1372,4]]},"873":{"position":[[397,3],[611,3]]},"875":{"position":[[115,4]]},"877":{"position":[[210,3],[325,3]]},"881":{"position":[[375,2]]},"963":{"position":[[450,4]]},"999":{"position":[[773,2]]},"1111":{"position":[[1543,2]]},"1134":{"position":[[266,2]]},"1143":{"position":[[593,3]]},"1195":{"position":[[104,2],[183,2],[270,2]]},"1197":{"position":[[160,3]]},"1199":{"position":[[211,3],[429,2]]},"1201":{"position":[[163,3],[222,2]]},"1205":{"position":[[67,2],[163,2]]},"1210":{"position":[[102,3]]},"1259":{"position":[[440,3]]},"1314":{"position":[[287,2],[324,4],[352,2],[684,3],[894,2]]},"1321":{"position":[[216,4]]},"1326":{"position":[[127,3]]},"1334":{"position":[[114,5],[233,3]]},"1357":{"position":[[506,3]]},"1427":{"position":[[20,2],[910,2]]},"1431":{"position":[[1875,3]]},"1505":{"position":[[247,2],[343,2]]},"1525":{"position":[[14,2],[105,2]]},"1538":{"position":[[173,3]]},"1653":{"position":[[719,2]]},"1665":{"position":[[1363,3]]},"1674":{"position":[[520,2]]},"1680":{"position":[[76,3]]},"1682":{"position":[[133,2]]},"1782":{"position":[[996,4],[1224,4]]}}}],["10%,20%,30%,40%,50%,60%,70%,80%,90%}\\{10",{"_index":4843,"t":{"1496":{"position":[[360,44]]}}}],["10%10\\%10",{"_index":2359,"t":{"666":{"position":[[309,10]]}}}],["10,000",{"_index":334,"t":{"63":{"position":[[164,6]]},"517":{"position":[[534,8]]},"589":{"position":[[2082,7]]},"614":{"position":[[309,6],[454,8]]},"717":{"position":[[291,7]]},"741":{"position":[[272,7]]}}}],["10,20,100}\\{10",{"_index":4868,"t":{"1511":{"position":[[119,16]]}}}],["10.1",{"_index":4584,"t":{"1409":{"position":[[885,5]]},"1423":{"position":[[224,5]]}}}],["10.2",{"_index":3594,"t":{"1002":{"position":[[779,8]]}}}],["10/100",{"_index":497,"t":{"102":{"position":[[183,6]]}}}],["100",{"_index":327,"t":{"63":{"position":[[43,4]]},"65":{"position":[[20,3]]},"143":{"position":[[536,3]]},"182":{"position":[[345,3]]},"215":{"position":[[795,4]]},"424":{"position":[[301,4]]},"459":{"position":[[732,3]]},"466":{"position":[[255,3]]},"529":{"position":[[2137,4]]},"656":{"position":[[525,4]]},"658":{"position":[[3089,5]]},"1033":{"position":[[201,5]]},"1070":{"position":[[857,3]]},"1134":{"position":[[214,3]]},"1139":{"position":[[28,4]]},"1151":{"position":[[824,4],[892,5],[950,4],[1565,4]]},"1159":{"position":[[1098,5]]},"1195":{"position":[[116,3],[222,3]]},"1197":{"position":[[90,3]]},"1199":{"position":[[261,3]]},"1203":{"position":[[38,4],[124,3]]},"1205":{"position":[[72,3],[168,3]]},"1210":{"position":[[110,4]]},"1214":{"position":[[47,3]]},"1255":{"position":[[106,5]]},"1262":{"position":[[157,3]]},"1317":{"position":[[339,6]]},"1321":{"position":[[549,5],[601,5]]},"1345":{"position":[[105,3]]},"1347":{"position":[[705,3]]},"1360":{"position":[[214,3]]},"1393":{"position":[[308,4]]},"1395":{"position":[[1395,6],[2613,6]]},"1496":{"position":[[285,3]]},"1544":{"position":[[333,4]]},"1724":{"position":[[321,3]]},"1728":{"position":[[147,3]]},"1762":{"position":[[325,4]]},"1782":{"position":[[3215,4]]}}}],["100,000",{"_index":314,"t":{"58":{"position":[[60,8]]},"315":{"position":[[46,7]]},"517":{"position":[[606,9]]},"600":{"position":[[376,7]]}}}],["100.00",{"_index":4850,"t":{"1499":{"position":[[649,8]]}}}],["100/500/1,000",{"_index":4569,"t":{"1397":{"position":[[243,13],[402,13]]}}}],["1000",{"_index":282,"t":{"53":{"position":[[23,4]]},"422":{"position":[[124,5]]},"1393":{"position":[[318,4]]},"1395":{"position":[[1430,4],[2749,7]]}}}],["10000^{2i",{"_index":1264,"t":{"308":{"position":[[424,9],[485,9]]}}}],["10000⋅2π10000",{"_index":1270,"t":{"308":{"position":[[695,13]]}}}],["1000ㅏ=1000",{"_index":4568,"t":{"1395":{"position":[[2759,10]]}}}],["100\\}{10,20,100",{"_index":4869,"t":{"1511":{"position":[[140,16]]}}}],["100\\}{20,50,100",{"_index":2384,"t":{"670":{"position":[[363,16]]}}}],["100\\}{5,20,50,100",{"_index":4423,"t":{"1357":{"position":[[427,18]]}}}],["100b",{"_index":1563,"t":{"399":{"position":[[49,4]]},"567":{"position":[[473,4]]}}}],["100k",{"_index":3571,"t":{"997":{"position":[[226,4]]},"999":{"position":[[830,4]]},"1132":{"position":[[1893,4]]},"1134":{"position":[[161,4]]},"1143":{"position":[[470,4]]},"1253":{"position":[[11,4]]},"1427":{"position":[[505,4]]}}}],["100k=100",{"_index":4566,"t":{"1395":{"position":[[1793,8]]},"1397":{"position":[[641,9]]}}}],["100l=100",{"_index":4220,"t":{"1277":{"position":[[18,8]]},"1421":{"position":[[309,8]]}}}],["100m",{"_index":3630,"t":{"1024":{"position":[[110,5]]},"1070":{"position":[[1573,7]]}}}],["100△t​=100",{"_index":3016,"t":{"807":{"position":[[464,11]]}}}],["101",{"_index":1455,"t":{"354":{"position":[[50,4]]},"366":{"position":[[158,4]]},"1770":{"position":[[162,4]]}}}],["102",{"_index":5612,"t":{"1782":{"position":[[3115,4]]}}}],["1024",{"_index":1801,"t":{"517":{"position":[[854,5]]}}}],["1024d1​=d2​=1024",{"_index":2768,"t":{"786":{"position":[[2070,16]]}}}],["1024dmodel​=1024",{"_index":1367,"t":{"326":{"position":[[315,16]]}}}],["1024x1024",{"_index":674,"t":{"143":{"position":[[713,9]]},"147":{"position":[[474,9]]}}}],["103",{"_index":2208,"t":{"608":{"position":[[928,3]]},"610":{"position":[[147,3],[266,4]]},"612":{"position":[[87,3],[200,3]]},"1720":{"position":[[1694,3]]},"1736":{"position":[[875,3]]},"1762":{"position":[[368,3],[408,4]]}}}],["10341×98+103",{"_index":2211,"t":{"608":{"position":[[1095,12]]}}}],["105",{"_index":5474,"t":{"1724":{"position":[[410,3]]},"1728":{"position":[[195,3]]},"1774":{"position":[[121,3]]}}}],["107",{"_index":5556,"t":{"1770":{"position":[[167,4]]}}}],["107,394",{"_index":1685,"t":{"464":{"position":[[26,7]]}}}],["109",{"_index":5613,"t":{"1782":{"position":[[3180,4]]}}}],["10986",{"_index":5032,"t":{"1589":{"position":[[231,6]]}}}],["10b",{"_index":3613,"t":{"1014":{"position":[[916,3],[1462,3]]},"1019":{"position":[[821,3]]},"1024":{"position":[[26,3]]},"1043":{"position":[[133,3]]},"1047":{"position":[[208,4],[283,3]]},"1056":{"position":[[56,3]]}}}],["10k",{"_index":889,"t":{"177":{"position":[[1236,4]]},"550":{"position":[[389,3]]},"670":{"position":[[1117,3]]},"999":{"position":[[718,3],[758,3]]},"1429":{"position":[[258,3]]}}}],["10l",{"_index":4622,"t":{"1427":{"position":[[246,4]]}}}],["10l=10",{"_index":4545,"t":{"1393":{"position":[[985,6]]},"1395":{"position":[[1835,6],[2149,6]]}}}],["10px",{"_index":5127,"t":{"1628":{"position":[[239,7]]}}}],["10−210",{"_index":2431,"t":{"676":{"position":[[947,8],[1090,8]]}}}],["10−7,1][10",{"_index":2434,"t":{"676":{"position":[[1030,13]]}}}],["10−9\\epsilon",{"_index":1321,"t":{"317":{"position":[[86,14]]}}}],["11",{"_index":308,"t":{"55":{"position":[[76,3]]},"76":{"position":[[221,3]]},"374":{"position":[[0,2]]},"376":{"position":[[0,2]]},"618":{"position":[[120,2]]},"801":{"position":[[2718,3]]},"963":{"position":[[363,2]]},"1399":{"position":[[664,5]]},"1442":{"position":[[1868,3]]},"1684":{"position":[[6,2]]},"1782":{"position":[[707,4]]}}}],["110",{"_index":5562,"t":{"1770":{"position":[[617,3]]}}}],["110m",{"_index":4044,"t":{"1183":{"position":[[71,7]]}}}],["112",{"_index":5598,"t":{"1782":{"position":[[1883,6]]}}}],["113",{"_index":5625,"t":{"1796":{"position":[[265,3]]}}}],["114",{"_index":5614,"t":{"1782":{"position":[[3185,3]]},"1796":{"position":[[351,3]]}}}],["115",{"_index":5498,"t":{"1730":{"position":[[624,3]]},"1766":{"position":[[325,4]]}}}],["116",{"_index":5550,"t":{"1762":{"position":[[586,3]]}}}],["11659",{"_index":5030,"t":{"1589":{"position":[[141,6]]}}}],["11660",{"_index":5031,"t":{"1589":{"position":[[182,6]]}}}],["117",{"_index":5497,"t":{"1730":{"position":[[619,4]]},"1736":{"position":[[573,3],[915,4],[1126,4]]},"1756":{"position":[[211,4]]},"1766":{"position":[[330,4],[559,5]]},"1778":{"position":[[795,3]]},"1794":{"position":[[133,3]]}}}],["11720",{"_index":5028,"t":{"1589":{"position":[[70,6]]}}}],["118",{"_index":5514,"t":{"1736":{"position":[[1131,4],[1553,5]]},"1756":{"position":[[216,3]]},"1774":{"position":[[293,3]]},"1794":{"position":[[122,4]]}}}],["118k",{"_index":652,"t":{"143":{"position":[[0,4]]}}}],["11b",{"_index":1983,"t":{"539":{"position":[[503,3],[512,3]]},"594":{"position":[[531,3]]},"604":{"position":[[37,5]]},"612":{"position":[[59,3]]},"786":{"position":[[78,4]]},"1109":{"position":[[1292,3]]},"1136":{"position":[[407,5]]},"1159":{"position":[[964,3]]},"1409":{"position":[[652,5],[876,5]]},"1413":{"position":[[54,3]]},"1466":{"position":[[183,4]]}}}],["11e9",{"_index":2218,"t":{"612":{"position":[[180,4]]}}}],["11e9×103=1.1e1211e9",{"_index":2212,"t":{"610":{"position":[[120,19]]}}}],["11m",{"_index":1096,"t":{"242":{"position":[[156,3]]}}}],["12",{"_index":680,"t":{"147":{"position":[[266,3]]},"149":{"position":[[498,3]]},"285":{"position":[[506,4]]},"315":{"position":[[63,2]]},"670":{"position":[[730,2]]},"709":{"position":[[1752,2],[1768,2]]},"866":{"position":[[449,2],[955,2]]},"873":{"position":[[1226,2]]},"1283":{"position":[[53,4],[180,2]]},"1782":{"position":[[1586,4]]}}}],["12,288",{"_index":2571,"t":{"719":{"position":[[750,6]]}}}],["12.1",{"_index":4684,"t":{"1431":{"position":[[2630,6]]}}}],["12.5",{"_index":3961,"t":{"1147":{"position":[[576,5]]}}}],["12.7m",{"_index":1097,"t":{"242":{"position":[[169,5]]}}}],["120",{"_index":5513,"t":{"1736":{"position":[[920,3],[1136,3]]},"1766":{"position":[[565,4]]},"1794":{"position":[[127,3]]}}}],["121",{"_index":5570,"t":{"1778":{"position":[[220,3]]}}}],["123",{"_index":5594,"t":{"1782":{"position":[[1760,5]]}}}],["124",{"_index":5552,"t":{"1764":{"position":[[64,3]]}}}],["125",{"_index":5545,"t":{"1762":{"position":[[330,4]]},"1788":{"position":[[877,4]]}}}],["125m",{"_index":2683,"t":{"759":{"position":[[85,6]]}}}],["128",{"_index":665,"t":{"143":{"position":[[500,3]]},"147":{"position":[[17,3]]},"230":{"position":[[329,3]]},"517":{"position":[[978,4]]},"759":{"position":[[140,3]]},"1395":{"position":[[501,4]]}}}],["129",{"_index":5606,"t":{"1782":{"position":[[2831,5]]}}}],["12][15,13,10,07,03,12",{"_index":4886,"t":{"1538":{"position":[[185,22]]}}}],["12m",{"_index":1095,"t":{"242":{"position":[[87,3]]}}}],["13",{"_index":2199,"t":{"606":{"position":[[224,2]]},"1538":{"position":[[169,3]]},"1730":{"position":[[1266,2]]},"1768":{"position":[[92,2]]},"1788":{"position":[[468,2]]}}}],["130",{"_index":5607,"t":{"1782":{"position":[[2844,5]]}}}],["131",{"_index":5548,"t":{"1762":{"position":[[537,4],[556,3]]}}}],["132m",{"_index":661,"t":{"143":{"position":[[342,4]]}}}],["134",{"_index":5559,"t":{"1770":{"position":[[376,3]]}}}],["135",{"_index":5463,"t":{"1720":{"position":[[1196,3]]},"1780":{"position":[[0,3]]}}}],["136",{"_index":5587,"t":{"1782":{"position":[[1001,4]]}}}],["137b",{"_index":1557,"t":{"397":{"position":[[68,5]]},"399":{"position":[[424,4]]},"409":{"position":[[232,4]]}}}],["139",{"_index":5561,"t":{"1770":{"position":[[612,4]]}}}],["13b",{"_index":1704,"t":{"473":{"position":[[335,6]]}}}],["13e−1",{"_index":3741,"t":{"1084":{"position":[[1054,5]]}}}],["13k",{"_index":4925,"t":{"1552":{"position":[[451,5]]}}}],["13m",{"_index":313,"t":{"58":{"position":[[26,3]]},"221":{"position":[[816,3]]}}}],["14",{"_index":554,"t":{"114":{"position":[[109,2],[148,2],[233,2],[324,2]]},"1084":{"position":[[344,2],[878,2]]},"1310":{"position":[[134,2]]},"1782":{"position":[[1806,4]]}}}],["14.6",{"_index":4428,"t":{"1360":{"position":[[257,5]]}}}],["14.9",{"_index":1982,"t":{"539":{"position":[[411,5]]}}}],["140",{"_index":954,"t":{"197":{"position":[[95,3]]},"251":{"position":[[131,4]]}}}],["141",{"_index":5621,"t":{"1796":{"position":[[57,3]]}}}],["142",{"_index":5590,"t":{"1782":{"position":[[1572,4]]}}}],["144",{"_index":3049,"t":{"821":{"position":[[358,4]]},"1724":{"position":[[295,5]]},"1728":{"position":[[404,3]]},"1766":{"position":[[108,3]]}}}],["144,288,576}\\{144",{"_index":3029,"t":{"814":{"position":[[319,19]]}}}],["145",{"_index":5528,"t":{"1738":{"position":[[710,3]]}}}],["146",{"_index":5609,"t":{"1782":{"position":[[2879,4]]}}}],["147",{"_index":5568,"t":{"1776":{"position":[[0,3]]}}}],["149",{"_index":5608,"t":{"1782":{"position":[[2850,4]]}}}],["14m",{"_index":381,"t":{"86":{"position":[[443,8]]},"102":{"position":[[65,4]]},"932":{"position":[[852,3]]}}}],["15",{"_index":1733,"t":{"492":{"position":[[16,3]]},"828":{"position":[[133,2]]},"921":{"position":[[155,2]]},"1431":{"position":[[2780,2]]},"1505":{"position":[[461,3]]},"1507":{"position":[[327,3]]}}}],["15,13,10,07,03,12][15",{"_index":4883,"t":{"1538":{"position":[[145,23]]}}}],["15,28,38,45,48,60][15",{"_index":4887,"t":{"1538":{"position":[[214,23]]}}}],["15.5",{"_index":2015,"t":{"557":{"position":[[186,5]]}}}],["150",{"_index":924,"t":{"189":{"position":[[189,4]]},"1139":{"position":[[33,3]]},"1680":{"position":[[103,3]]}}}],["1500",{"_index":4070,"t":{"1210":{"position":[[120,5]]}}}],["151",{"_index":5627,"t":{"1802":{"position":[[214,3]]}}}],["151m",{"_index":1792,"t":{"517":{"position":[[324,5]]}}}],["152",{"_index":5465,"t":{"1720":{"position":[[1523,3]]},"1762":{"position":[[372,4]]}}}],["154",{"_index":5599,"t":{"1782":{"position":[[1907,5]]}}}],["1546",{"_index":5029,"t":{"1589":{"position":[[108,5]]}}}],["155",{"_index":5486,"t":{"1728":{"position":[[679,3]]}}}],["1554",{"_index":1990,"t":{"544":{"position":[[182,5]]}}}],["157",{"_index":2376,"t":{"670":{"position":[[109,3]]}}}],["16",{"_index":906,"t":{"182":{"position":[[340,2]]},"358":{"position":[[258,2]]},"368":{"position":[[258,2]]},"370":{"position":[[106,2]]},"517":{"position":[[407,4]]},"589":{"position":[[2153,4]]},"600":{"position":[[360,2]]},"606":{"position":[[284,3]]},"630":{"position":[[1061,3]]},"670":{"position":[[461,3]]},"705":{"position":[[52,3]]},"807":{"position":[[299,2]]},"814":{"position":[[192,3]]},"821":{"position":[[198,3],[408,2]]},"1004":{"position":[[265,3]]},"1111":{"position":[[1422,3]]},"1126":{"position":[[967,3]]},"1136":{"position":[[669,4]]},"1264":{"position":[[32,3]]},"1427":{"position":[[0,2]]},"1496":{"position":[[276,2],[337,2]]},"1558":{"position":[[242,2]]},"1669":{"position":[[717,3]]},"1674":{"position":[[457,2],[598,2]]},"1682":{"position":[[115,2],[413,3]]}}}],["16.14",{"_index":90,"t":{"15":{"position":[[16,5]]}}}],["16.3",{"_index":4089,"t":{"1227":{"position":[[1342,5]]}}}],["160",{"_index":2032,"t":{"569":{"position":[[257,4]]},"1409":{"position":[[1156,3]]},"1427":{"position":[[41,3]]}}}],["1616×16",{"_index":779,"t":{"170":{"position":[[1222,8]]}}}],["1641×98×32bits=16kb",{"_index":2225,"t":{"614":{"position":[[236,19]]}}}],["167.3",{"_index":3724,"t":{"1082":{"position":[[177,7]]}}}],["16b",{"_index":1787,"t":{"517":{"position":[[108,3],[145,3],[293,3],[1168,4],[1243,3]]}}}],["16k",{"_index":1372,"t":{"326":{"position":[[481,3]]}}}],["16k=16",{"_index":1454,"t":{"352":{"position":[[885,6]]}}}],["16l=16",{"_index":1498,"t":{"370":{"position":[[87,6]]}}}],["16r=16",{"_index":2289,"t":{"633":{"position":[[377,6]]},"642":{"position":[[330,6]]}}}],["16x16",{"_index":515,"t":{"104":{"position":[[115,5]]}}}],["16×1616",{"_index":778,"t":{"170":{"position":[[1207,7]]}}}],["17",{"_index":2337,"t":{"658":{"position":[[3095,2]]},"664":{"position":[[151,2]]},"670":{"position":[[1427,3],[1608,3]]},"1054":{"position":[[316,2]]},"1319":{"position":[[315,3]]},"1720":{"position":[[319,2]]},"1724":{"position":[[347,2]]},"1728":{"position":[[530,2]]},"1742":{"position":[[334,2]]},"1768":{"position":[[692,2]]}}}],["17.7",{"_index":1701,"t":{"471":{"position":[[71,5]]}}}],["172k",{"_index":3567,"t":{"994":{"position":[[722,4]]}}}],["175",{"_index":3391,"t":{"905":{"position":[[51,3]]}}}],["175b",{"_index":1551,"t":{"397":{"position":[[36,5]]},"473":{"position":[[25,4]]},"479":{"position":[[57,4]]},"606":{"position":[[229,4],[302,4]]},"610":{"position":[[194,4]]},"612":{"position":[[274,4],[352,4]]},"717":{"position":[[6,4],[248,4]]},"719":{"position":[[698,4]]},"741":{"position":[[170,4],[341,4]]},"765":{"position":[[6,4]]},"770":{"position":[[43,4]]},"786":{"position":[[89,4]]},"1126":{"position":[[909,4]]},"1136":{"position":[[712,4]]},"1159":{"position":[[103,5]]},"1291":{"position":[[273,4]]},"1544":{"position":[[319,4]]},"1546":{"position":[[536,4]]},"1558":{"position":[[565,4],[2143,4]]},"1570":{"position":[[303,5],[315,4]]}}}],["178.3",{"_index":3727,"t":{"1082":{"position":[[209,5]]}}}],["17m",{"_index":1368,"t":{"326":{"position":[[361,3]]}}}],["18",{"_index":1409,"t":{"339":{"position":[[107,4]]}}}],["18.1",{"_index":3731,"t":{"1082":{"position":[[320,5]]}}}],["183m",{"_index":3023,"t":{"814":{"position":[[17,4]]}}}],["18k",{"_index":492,"t":{"102":{"position":[[82,3]]}}}],["18m",{"_index":2689,"t":{"770":{"position":[[108,3]]}}}],["19",{"_index":503,"t":{"102":{"position":[[227,2]]},"1442":{"position":[[2157,4]]},"1718":{"position":[[1029,2]]}}}],["19.0",{"_index":4680,"t":{"1431":{"position":[[2140,5]]}}}],["190",{"_index":2028,"t":{"569":{"position":[[0,4],[622,4]]}}}],["193",{"_index":1988,"t":{"544":{"position":[[164,4]]}}}],["1990",{"_index":1947,"t":{"531":{"position":[[374,5]]}}}],["1991",{"_index":4579,"t":{"1401":{"position":[[562,5]]}}}],["1993",{"_index":1949,"t":{"531":{"position":[[386,5]]}}}],["1=0.9,β2=0.98\\beta_1",{"_index":1318,"t":{"317":{"position":[[24,21]]}}}],["1=0.9\\beta_1",{"_index":523,"t":{"106":{"position":[[34,13]]}}}],["1\\alpha_1α1",{"_index":3700,"t":{"1067":{"position":[[1388,13],[1480,13]]}}}],["1\\beta_1β1",{"_index":3035,"t":{"814":{"position":[[549,12]]}}}],["1\\dot",{"_index":4021,"t":{"1167":{"position":[[644,8]]}}}],["1\\leq",{"_index":2120,"t":{"596":{"position":[[1340,6]]},"833":{"position":[[284,7]]}}}],["1\\}{0,0.25,0.5,0.75,1",{"_index":2564,"t":{"709":{"position":[[2174,22]]}}}],["1][10−7,1",{"_index":2435,"t":{"676":{"position":[[1048,10]]}}}],["1]s[j]−s[i−1",{"_index":4895,"t":{"1538":{"position":[[417,13]]}}}],["1a",{"_index":1394,"t":{"336":{"position":[[215,2]]},"786":{"position":[[2639,2]]},"1062":{"position":[[92,3]]},"1084":{"position":[[134,3]]}}}],["1b",{"_index":1399,"t":{"336":{"position":[[546,4]]},"786":{"position":[[2732,2]]},"1024":{"position":[[118,3]]},"1062":{"position":[[308,4]]},"1145":{"position":[[179,2]]}}}],["1c",{"_index":1402,"t":{"336":{"position":[[942,4]]},"1062":{"position":[[165,4]]}}}],["1c=1",{"_index":1052,"t":{"227":{"position":[[639,5]]}}}],["1d",{"_index":400,"t":{"91":{"position":[[43,2],[1251,2]]},"116":{"position":[[211,2]]}}}],["1dim⁡(b)∥b0−bf∥1\\frac{1}{\\dim(b)}\\parallel",{"_index":1909,"t":{"529":{"position":[[1237,42]]}}}],["1dk\\frac{1}{\\sqrt{d_k}}dk​​1",{"_index":1200,"t":{"298":{"position":[[705,29],[1226,29]]}}}],["1e",{"_index":292,"t":{"53":{"position":[[190,2]]},"80":{"position":[[16,2],[25,2]]},"372":{"position":[[108,2]]},"705":{"position":[[388,2]]},"1107":{"position":[[1068,2]]},"1111":{"position":[[1389,2]]},"1134":{"position":[[814,2]]},"1665":{"position":[[1313,2]]},"1674":{"position":[[377,2]]},"1682":{"position":[[203,2]]}}}],["1e−21",{"_index":5350,"t":{"1665":{"position":[[1412,6]]},"1674":{"position":[[484,6]]}}}],["1e−41",{"_index":666,"t":{"143":{"position":[[515,8]]}}}],["1e−5,3e−5,5e−5",{"_index":5348,"t":{"1665":{"position":[[1294,18],[1329,18]]},"1674":{"position":[[358,18],[393,18]]},"1682":{"position":[[184,18],[220,18]]}}}],["1e−51",{"_index":4845,"t":{"1496":{"position":[[658,6]]}}}],["1k",{"_index":490,"t":{"102":{"position":[[35,2]]},"143":{"position":[[587,2]]},"887":{"position":[[1335,2]]},"899":{"position":[[184,2]]},"924":{"position":[[90,2]]}}}],["1k=1",{"_index":4689,"t":{"1431":{"position":[[2867,4]]}}}],["1m∑k=1mλk",{"_index":5319,"t":{"1659":{"position":[[868,9]]}}}],["1r=1",{"_index":2726,"t":{"774":{"position":[[1193,4]]}}}],["1s",{"_index":3669,"t":{"1065":{"position":[[603,3]]}}}],["1x1",{"_index":479,"t":{"95":{"position":[[180,3]]},"104":{"position":[[407,5]]}}}],["1})p(yj​∣x,y1:j−1",{"_index":643,"t":{"140":{"position":[[77,19]]}}}],["1}ht−1",{"_index":1149,"t":{"285":{"position":[[168,7]]}}}],["1}slm+1​∈r(m+1)×1",{"_index":3349,"t":{"893":{"position":[[1424,17]]}}}],["1}y={yi​}i=1n",{"_index":1621,"t":{"441":{"position":[[203,14]]}}}],["1}zϱ−1",{"_index":468,"t":{"91":{"position":[[2228,7]]}}}],["1~4",{"_index":4445,"t":{"1377":{"position":[[454,4]]},"1379":{"position":[[1318,3]]}}}],["1×10−31",{"_index":3051,"t":{"821":{"position":[[441,7]]}}}],["1×1\\times1",{"_index":2361,"t":{"666":{"position":[[612,11]]}}}],["1​,xkeypoint",{"_index":616,"t":{"130":{"position":[[1300,12]]}}}],["1​,ykeypoint",{"_index":617,"t":{"130":{"position":[[1313,12]]}}}],["1⃗+δ))]j.\\begin{equ",{"_index":4414,"t":{"1354":{"position":[[404,26]]}}}],["1≤1",{"_index":2121,"t":{"596":{"position":[[1347,3]]},"833":{"position":[[292,5]]}}}],["1≤c≤c1",{"_index":1470,"t":{"358":{"position":[[317,7]]}}}],["1≤i≤641",{"_index":2708,"t":{"774":{"position":[[335,8]]}}}],["1≤i≤81",{"_index":2706,"t":{"774":{"position":[[235,7]]}}}],["1⋅10−5,3⋅10−5,1⋅10−4,3⋅10−3}\\{1\\cdot10",{"_index":2378,"t":{"670":{"position":[[200,41]]}}}],["2",{"_index":185,"t":{"25":{"position":[[756,2]]},"91":{"position":[[1942,3]]},"130":{"position":[[1172,3],[1251,4],[1277,4],[1339,5]]},"138":{"position":[[236,1]]},"153":{"position":[[29,1]]},"157":{"position":[[414,1]]},"182":{"position":[[119,1]]},"215":{"position":[[2316,1]]},"219":{"position":[[313,2]]},"244":{"position":[[176,1]]},"283":{"position":[[203,1]]},"298":{"position":[[63,2]]},"300":{"position":[[414,1]]},"302":{"position":[[822,2]]},"322":{"position":[[66,2],[657,1]]},"347":{"position":[[7,1]]},"352":{"position":[[26,1],[746,1]]},"354":{"position":[[522,1]]},"358":{"position":[[628,1]]},"399":{"position":[[472,3]]},"424":{"position":[[177,2]]},"457":{"position":[[174,1]]},"504":{"position":[[167,2]]},"517":{"position":[[1089,1]]},"529":{"position":[[625,2],[715,3],[864,1],[2698,1]]},"541":{"position":[[4,1]]},"596":{"position":[[1869,1]]},"598":{"position":[[2222,1],[3746,1]]},"618":{"position":[[377,1]]},"626":{"position":[[459,1]]},"662":{"position":[[268,1]]},"670":{"position":[[105,1],[1233,1]]},"674":{"position":[[692,3]]},"676":{"position":[[338,2],[863,1]]},"686":{"position":[[314,1]]},"688":{"position":[[1108,2]]},"694":{"position":[[671,2]]},"717":{"position":[[344,1]]},"743":{"position":[[23,1]]},"755":{"position":[[521,2],[569,1]]},"757":{"position":[[178,1]]},"763":{"position":[[52,1]]},"765":{"position":[[72,1]]},"770":{"position":[[143,3]]},"812":{"position":[[82,1]]},"814":{"position":[[689,1]]},"821":{"position":[[265,2]]},"833":{"position":[[5,1]]},"835":{"position":[[210,2]]},"839":{"position":[[357,1]]},"866":{"position":[[376,1]]},"870":{"position":[[2108,1]]},"873":{"position":[[607,1]]},"905":{"position":[[152,1]]},"914":{"position":[[209,1]]},"919":{"position":[[152,1]]},"951":{"position":[[180,1]]},"982":{"position":[[360,1]]},"997":{"position":[[300,2],[487,1],[543,1],[814,1]]},"999":{"position":[[813,1]]},"1002":{"position":[[10,1],[370,1],[960,1]]},"1004":{"position":[[6,1]]},"1006":{"position":[[2360,1]]},"1019":{"position":[[659,1]]},"1028":{"position":[[99,1],[296,1]]},"1047":{"position":[[6,1]]},"1052":{"position":[[265,2]]},"1062":{"position":[[462,1]]},"1070":{"position":[[36,1],[115,1],[260,1],[1769,2]]},"1080":{"position":[[59,2],[442,1]]},"1109":{"position":[[809,1]]},"1117":{"position":[[96,1]]},"1126":{"position":[[1853,2],[2048,1]]},"1136":{"position":[[458,2]]},"1145":{"position":[[628,1],[2250,1]]},"1147":{"position":[[990,1]]},"1149":{"position":[[495,1]]},"1167":{"position":[[950,2]]},"1199":{"position":[[453,1]]},"1203":{"position":[[219,2]]},"1205":{"position":[[64,2],[160,2]]},"1244":{"position":[[1553,3]]},"1246":{"position":[[62,1]]},"1250":{"position":[[77,2]]},"1253":{"position":[[83,1],[229,1],[311,2]]},"1262":{"position":[[132,1]]},"1289":{"position":[[494,1]]},"1291":{"position":[[245,1],[566,1]]},"1294":{"position":[[73,1]]},"1296":{"position":[[17,2],[132,1]]},"1298":{"position":[[263,1]]},"1305":{"position":[[242,1],[927,1]]},"1310":{"position":[[251,1]]},"1312":{"position":[[96,1]]},"1314":{"position":[[23,1],[38,1]]},"1317":{"position":[[261,1],[621,1],[684,1]]},"1319":{"position":[[8,2]]},"1321":{"position":[[175,3]]},"1323":{"position":[[524,1],[643,1]]},"1350":{"position":[[853,1]]},"1362":{"position":[[51,1]]},"1364":{"position":[[141,1]]},"1393":{"position":[[69,3],[716,1]]},"1395":{"position":[[949,1],[1520,1],[2800,2]]},"1397":{"position":[[747,1]]},"1411":{"position":[[155,2]]},"1429":{"position":[[1475,2],[1482,1]]},"1431":{"position":[[514,2]]},"1468":{"position":[[636,1]]},"1471":{"position":[[119,2]]},"1492":{"position":[[112,1]]},"1501":{"position":[[200,1]]},"1540":{"position":[[0,1]]},"1604":{"position":[[182,1]]},"1646":{"position":[[1985,1]]},"1651":{"position":[[957,1]]},"1657":{"position":[[595,1],[611,1]]},"1665":{"position":[[1028,1]]},"1669":{"position":[[6,1]]},"1674":{"position":[[574,1]]},"1704":{"position":[[378,2]]}}}],["2(4",{"_index":4177,"t":{"1244":{"position":[[1618,5]]}}}],["2(4)\\mathcal{l}_{hidden",{"_index":4172,"t":{"1244":{"position":[[1424,25]]}}}],["2(b",{"_index":4378,"t":{"1352":{"position":[[183,5]]}}}],["2(r+1)/n)d×m+n2rd+2d​=d(m+2(r+1)/n",{"_index":3565,"t":{"994":{"position":[[414,35]]}}}],["2)lstage1​=lretrieve​+lbox​+lmaskboxinst​(2",{"_index":878,"t":{"177":{"position":[[408,45]]}}}],["2,000",{"_index":4873,"t":{"1531":{"position":[[285,6]]}}}],["2,3,5}\\{2,3,5\\}{2,3,5",{"_index":2420,"t":{"674":{"position":[[383,23]]}}}],["2,300",{"_index":3464,"t":{"977":{"position":[[625,6]]}}}],["2,4,10,20}\\{2",{"_index":4424,"t":{"1357":{"position":[[487,15]]}}}],["2,4,8,16,32,64}\\{2",{"_index":2385,"t":{"670":{"position":[[434,20]]}}}],["2,4,8}\\{2",{"_index":3027,"t":{"814":{"position":[[244,11]]}}}],["2,k][2",{"_index":4191,"t":{"1246":{"position":[[417,8]]}}}],["2,xkeypoint",{"_index":612,"t":{"130":{"position":[[1160,11]]}}}],["2.0",{"_index":1345,"t":{"322":{"position":[[92,3]]},"870":{"position":[[325,3]]},"1049":{"position":[[186,3],[221,3]]}}}],["2.00",{"_index":3411,"t":{"926":{"position":[[35,7]]}}}],["2.04",{"_index":4859,"t":{"1501":{"position":[[340,6]]}}}],["2.1",{"_index":2216,"t":{"610":{"position":[[325,3]]},"676":{"position":[[1687,3]]}}}],["2.1.4",{"_index":4624,"t":{"1427":{"position":[[577,5]]}}}],["2.2",{"_index":206,"t":{"31":{"position":[[166,4]]}}}],["2.20",{"_index":3063,"t":{"830":{"position":[[108,5]]}}}],["2.4",{"_index":297,"t":{"53":{"position":[[247,3]]},"1409":{"position":[[893,4]]}}}],["2.5",{"_index":322,"t":{"60":{"position":[[40,4]]},"620":{"position":[[249,4]]},"1360":{"position":[[82,5]]}}}],["2.5%p",{"_index":4362,"t":{"1347":{"position":[[1663,6]]}}}],["2.6",{"_index":4067,"t":{"1205":{"position":[[190,5]]},"1314":{"position":[[919,5]]}}}],["2.6m",{"_index":3263,"t":{"870":{"position":[[1258,4]]}}}],["2.76",{"_index":2550,"t":{"707":{"position":[[171,5]]}}}],["2.7e163×11e9×1,000×8×103=2.7e16",{"_index":2220,"t":{"612":{"position":[[206,31]]}}}],["2.8",{"_index":309,"t":{"55":{"position":[[123,4]]},"205":{"position":[[97,3]]},"873":{"position":[[1742,4]]}}}],["2.84",{"_index":4855,"t":{"1499":{"position":[[730,7]]}}}],["2.9",{"_index":4333,"t":{"1321":{"position":[[308,3]]}}}],["2.96",{"_index":4847,"t":{"1499":{"position":[[316,5]]}}}],["2/3",{"_index":2648,"t":{"741":{"position":[[148,3]]},"1431":{"position":[[2819,3]]}}}],["20",{"_index":686,"t":{"149":{"position":[[260,4]]},"163":{"position":[[803,2]]},"165":{"position":[[2556,2],[2868,2]]},"209":{"position":[[114,2]]},"221":{"position":[[770,3]]},"322":{"position":[[529,4]]},"434":{"position":[[615,3]]},"483":{"position":[[708,4]]},"485":{"position":[[1561,3]]},"569":{"position":[[112,3],[564,2]]},"612":{"position":[[314,3],[378,2]]},"709":{"position":[[1208,3]]},"870":{"position":[[1525,3],[2166,3]]},"961":{"position":[[137,4]]},"999":{"position":[[743,2]]},"1033":{"position":[[142,3]]},"1060":{"position":[[978,3]]},"1062":{"position":[[1464,3],[1668,3]]},"1080":{"position":[[319,2]]},"1087":{"position":[[30,4]]},"1091":{"position":[[269,5]]},"1111":{"position":[[1469,2]]},"1139":{"position":[[24,3],[254,2]]},"1151":{"position":[[1899,3]]},"1203":{"position":[[34,3],[200,3]]},"1334":{"position":[[120,4],[161,3]]},"1357":{"position":[[419,3]]},"1362":{"position":[[95,2],[260,2]]},"1373":{"position":[[126,2],[256,3]]},"1427":{"position":[[852,5]]},"1442":{"position":[[1828,4]]},"1496":{"position":[[302,2],[405,5]]},"1511":{"position":[[14,3],[136,3],[260,2],[344,2]]}}}],["20,480",{"_index":4440,"t":{"1373":{"position":[[164,7]]}}}],["20,50,100}\\{20",{"_index":2383,"t":{"670":{"position":[[342,16]]}}}],["200",{"_index":4334,"t":{"1321":{"position":[[555,4],[607,4]]},"1326":{"position":[[106,4]]}}}],["2000",{"_index":1780,"t":{"515":{"position":[[166,4]]}}}],["2003",{"_index":1012,"t":{"215":{"position":[[2267,5]]}}}],["2005",{"_index":1021,"t":{"215":{"position":[[2360,6]]}}}],["2006",{"_index":1942,"t":{"531":{"position":[[319,5]]}}}],["200l=200",{"_index":3717,"t":{"1080":{"position":[[163,9]]}}}],["2012",{"_index":489,"t":{"102":{"position":[[21,4]]}}}],["2013",{"_index":1017,"t":{"215":{"position":[[2334,5]]},"531":{"position":[[423,5]]},"658":{"position":[[862,6]]},"851":{"position":[[827,6]]}}}],["2014",{"_index":1141,"t":{"283":{"position":[[176,4]]},"313":{"position":[[33,4],[190,4]]},"322":{"position":[[4,4],[227,4]]},"328":{"position":[[247,4],[276,4]]},"529":{"position":[[2227,5]]},"531":{"position":[[441,5]]},"658":{"position":[[924,5]]},"681":{"position":[[424,6]]}}}],["2015",{"_index":1944,"t":{"531":{"position":[[340,5],[459,5]]},"849":{"position":[[430,5]]},"851":{"position":[[73,5],[476,6]]},"853":{"position":[[428,5]]},"868":{"position":[[34,6]]},"1546":{"position":[[927,4]]}}}],["2016a",{"_index":1935,"t":{"529":{"position":[[2686,6]]}}}],["2017",{"_index":656,"t":{"143":{"position":[[39,4]]},"191":{"position":[[12,4],[55,4]]},"215":{"position":[[2296,6]]},"531":{"position":[[360,5],[483,5]]},"658":{"position":[[744,5]]},"662":{"position":[[1435,6]]},"670":{"position":[[868,7]]},"851":{"position":[[97,5],[637,5]]},"1347":{"position":[[1276,5]]},"1401":{"position":[[583,5]]}}}],["2017~2019",{"_index":5400,"t":{"1695":{"position":[[322,9]]}}}],["2018",{"_index":928,"t":{"191":{"position":[[31,4],[195,4]]},"531":{"position":[[1246,6]]},"658":{"position":[[1160,5]]},"662":{"position":[[1461,5]]},"666":{"position":[[99,6],[253,6]]},"670":{"position":[[887,6]]},"676":{"position":[[684,5]]},"849":{"position":[[863,5]]},"851":{"position":[[901,6]]},"861":{"position":[[87,5]]},"868":{"position":[[79,6]]},"873":{"position":[[917,6]]},"1589":{"position":[[269,5]]}}}],["2019",{"_index":49,"t":{"7":{"position":[[234,4],[256,4]]},"201":{"position":[[96,5]]},"215":{"position":[[454,7]]},"517":{"position":[[1050,6]]},"525":{"position":[[1032,5]]},"529":{"position":[[52,5]]},"531":{"position":[[719,5],[1094,6]]},"658":{"position":[[890,5]]},"662":{"position":[[1498,5]]},"681":{"position":[[584,5]]},"683":{"position":[[47,5],[152,5],[180,6]]},"997":{"position":[[618,4]]},"1070":{"position":[[177,4]]},"1075":{"position":[[5,4]]},"1147":{"position":[[328,4]]},"1369":{"position":[[540,5]]},"1379":{"position":[[1012,5]]},"1415":{"position":[[220,5]]}}}],["2020",{"_index":985,"t":{"215":{"position":[[475,6],[1780,5],[1799,5],[1825,6],[2174,6]]},"517":{"position":[[1107,6]]},"525":{"position":[[1173,5]]},"529":{"position":[[69,5],[1535,4]]},"531":{"position":[[502,6],[737,5],[759,5],[992,6],[1355,6],[1456,6]]},"681":{"position":[[544,5]]},"683":{"position":[[64,5],[85,5],[299,6],[324,6]]},"849":{"position":[[628,5],[1638,6]]},"851":{"position":[[159,5],[178,6],[202,5],[254,5],[314,5],[778,5]]},"853":{"position":[[1235,5],[2351,6]]},"861":{"position":[[1003,5]]},"868":{"position":[[116,5]]},"873":{"position":[[890,5]]},"1409":{"position":[[161,6]]},"1415":{"position":[[240,6]]},"1419":{"position":[[242,5],[937,6]]},"1421":{"position":[[448,6]]},"1431":{"position":[[1217,6]]},"1494":{"position":[[54,5]]}}}],["2021",{"_index":979,"t":{"215":{"position":[[380,6]]},"681":{"position":[[759,5],[779,5]]},"707":{"position":[[745,5]]},"709":{"position":[[112,5]]},"851":{"position":[[1164,6]]},"868":{"position":[[205,5]]},"1084":{"position":[[268,5]]},"1347":{"position":[[333,5],[355,5]]},"1362":{"position":[[165,5],[185,5]]},"1367":{"position":[[193,5],[377,5],[397,5]]},"1379":{"position":[[1047,5],[1069,5],[1100,5]]},"1384":{"position":[[2476,5]]},"1395":{"position":[[330,6],[654,6],[741,6]]},"1399":{"position":[[374,5],[396,5]]},"1407":{"position":[[103,6]]},"1409":{"position":[[472,6]]},"1415":{"position":[[52,6]]},"1421":{"position":[[18,6],[377,6]]},"1423":{"position":[[995,6]]},"1468":{"position":[[199,5]]},"1473":{"position":[[239,6],[378,5]]},"1475":{"position":[[291,6],[345,6]]},"1481":{"position":[[148,6]]},"1492":{"position":[[129,5]]},"1494":{"position":[[76,5],[182,5],[519,5]]},"1496":{"position":[[212,5],[230,5]]},"1511":{"position":[[316,4]]},"1665":{"position":[[586,7]]},"1695":{"position":[[743,4]]}}}],["2021a",{"_index":976,"t":{"215":{"position":[[281,7],[2497,7]]},"1665":{"position":[[878,8]]},"1682":{"position":[[51,7]]}}}],["2021c",{"_index":4839,"t":{"1494":{"position":[[298,6]]}}}],["2022",{"_index":1741,"t":{"498":{"position":[[149,6]]},"630":{"position":[[825,5]]},"648":{"position":[[752,5]]},"683":{"position":[[356,6]]},"707":{"position":[[761,5]]},"851":{"position":[[115,6],[220,6],[272,5]]},"868":{"position":[[139,5]]},"988":{"position":[[661,6]]},"1084":{"position":[[287,5]]},"1347":{"position":[[372,5],[423,5],[439,5],[490,5],[592,5],[1295,5]]},"1354":{"position":[[52,5]]},"1362":{"position":[[201,5],[383,5]]},"1364":{"position":[[249,5],[267,5]]},"1367":{"position":[[449,5],[465,5],[516,5],[532,6],[607,5],[625,5]]},"1369":{"position":[[274,6],[363,6],[429,6]]},"1473":{"position":[[509,5]]}}}],["2022a",{"_index":4419,"t":{"1357":{"position":[[101,7]]}}}],["2022b",{"_index":1766,"t":{"504":{"position":[[197,6],[321,6]]},"681":{"position":[[795,6]]},"1354":{"position":[[32,6]]}}}],["2023",{"_index":1594,"t":{"432":{"position":[[53,4]]},"648":{"position":[[884,5]]},"681":{"position":[[814,6]]},"683":{"position":[[99,6],[1110,5],[1136,5]]},"1367":{"position":[[643,5]]}}}],["2023a",{"_index":3737,"t":{"1084":{"position":[[327,6]]}}}],["2023b",{"_index":3734,"t":{"1084":{"position":[[306,6]]}}}],["2024",{"_index":5026,"t":{"1589":{"position":[[59,4],[97,4],[130,4],[171,4],[220,4],[258,4],[296,4]]}}}],["2048",{"_index":1680,"t":{"459":{"position":[[627,6]]},"517":{"position":[[703,5]]},"1291":{"position":[[861,5]]}}}],["2048dff​=2048",{"_index":1256,"t":{"304":{"position":[[547,13]]}}}],["20\\}{2,4,10,20",{"_index":4425,"t":{"1357":{"position":[[510,15]]}}}],["20\\}{3,20",{"_index":2367,"t":{"668":{"position":[[257,10]]}}}],["20b",{"_index":1560,"t":{"397":{"position":[[99,5]]}}}],["20k",{"_index":911,"t":{"185":{"position":[[52,4]]},"567":{"position":[[265,3]]}}}],["20k′=20",{"_index":1691,"t":{"466":{"position":[[225,7]]}}}],["20m=20",{"_index":3726,"t":{"1082":{"position":[[199,7],[290,7]]}}}],["20px",{"_index":5125,"t":{"1628":{"position":[[207,7]]}}}],["21",{"_index":1376,"t":{"326":{"position":[[840,2]]},"977":{"position":[[821,4]]},"979":{"position":[[1441,2]]},"997":{"position":[[155,4]]},"1070":{"position":[[27,2]]},"1492":{"position":[[114,3]]},"1680":{"position":[[206,2]]}}}],["21,841",{"_index":312,"t":{"58":{"position":[[14,6]]}}}],["21.0",{"_index":3729,"t":{"1082":{"position":[[268,4]]}}}],["21.5≈6.91/0.3221.5",{"_index":2737,"t":{"778":{"position":[[666,18]]}}}],["214,354",{"_index":1684,"t":{"464":{"position":[[8,7]]}}}],["218",{"_index":3148,"t":{"853":{"position":[[1865,4]]}}}],["21e−2",{"_index":5351,"t":{"1665":{"position":[[1421,5]]},"1674":{"position":[[491,5]]}}}],["21k",{"_index":396,"t":{"88":{"position":[[567,3]]},"102":{"position":[[61,3]]},"112":{"position":[[22,4]]},"924":{"position":[[35,3]]}}}],["22",{"_index":1373,"t":{"326":{"position":[[573,2]]},"1442":{"position":[[1794,4]]}}}],["22,000",{"_index":4327,"t":{"1314":{"position":[[431,7]]}}}],["22.9",{"_index":4429,"t":{"1360":{"position":[[278,5]]}}}],["220",{"_index":3935,"t":{"1136":{"position":[[717,5]]}}}],["220m",{"_index":1784,"t":{"517":{"position":[[49,4]]},"1070":{"position":[[784,4]]},"1183":{"position":[[87,6]]},"1255":{"position":[[43,4]]},"1409":{"position":[[860,6]]},"1413":{"position":[[38,5]]}}}],["222^222",{"_index":763,"t":{"170":{"position":[[726,7]]}}}],["224",{"_index":1124,"t":{"255":{"position":[[149,4],[156,4]]}}}],["23",{"_index":2007,"t":{"553":{"position":[[182,2]]},"565":{"position":[[117,4]]},"1060":{"position":[[999,2]]},"1062":{"position":[[1327,2],[1678,2]]},"1225":{"position":[[505,3]]},"1227":{"position":[[1232,2]]},"1253":{"position":[[107,3]]},"1774":{"position":[[499,2]]},"1782":{"position":[[2371,4],[2874,4]]}}}],["232k",{"_index":4091,"t":{"1227":{"position":[[1446,5]]}}}],["24",{"_index":2362,"t":{"668":{"position":[[32,2]]},"1054":{"position":[[319,2]]}}}],["24,576",{"_index":4441,"t":{"1373":{"position":[[221,7]]}}}],["24.4",{"_index":1712,"t":{"479":{"position":[[80,5]]}}}],["24.8",{"_index":3730,"t":{"1082":{"position":[[300,4]]}}}],["25",{"_index":952,"t":{"197":{"position":[[66,2]]},"741":{"position":[[351,3]]},"870":{"position":[[1435,3]]},"1197":{"position":[[400,3]]},"1546":{"position":[[761,3]]},"1762":{"position":[[483,3],[513,3]]},"1770":{"position":[[443,2]]}}}],["25,000",{"_index":284,"t":{"53":{"position":[[77,6]]}}}],["25.19",{"_index":3278,"t":{"881":{"position":[[398,6]]}}}],["250",{"_index":4066,"t":{"1201":{"position":[[405,4]]}}}],["25000",{"_index":1314,"t":{"313":{"position":[[326,5],[348,5]]}}}],["250k",{"_index":4235,"t":{"1291":{"position":[[1563,4]]}}}],["256",{"_index":1745,"t":{"498":{"position":[[517,3]]},"517":{"position":[[941,5]]},"668":{"position":[[595,3]]},"676":{"position":[[1354,3]]},"765":{"position":[[135,4]]},"1395":{"position":[[506,3]]}}}],["256256×256",{"_index":765,"t":{"170":{"position":[[785,10]]}}}],["256dmid​=256",{"_index":4559,"t":{"1395":{"position":[[1001,12]]}}}],["256×256256",{"_index":764,"t":{"170":{"position":[[767,10]]}}}],["26",{"_index":2305,"t":{"656":{"position":[[345,2]]},"1407":{"position":[[501,2]]},"1409":{"position":[[1164,2]]},"1425":{"position":[[297,2]]},"1782":{"position":[[3175,4]]}}}],["262,144",{"_index":4623,"t":{"1427":{"position":[[348,7]]}}}],["262,144s=s18=262,144",{"_index":4611,"t":{"1421":{"position":[[502,20]]}}}],["27",{"_index":5593,"t":{"1782":{"position":[[1755,4],[2376,3]]}}}],["27,000x",{"_index":4582,"t":{"1407":{"position":[[454,7]]},"1423":{"position":[[1231,7],[1456,7]]}}}],["27.2",{"_index":4430,"t":{"1360":{"position":[[303,5]]}}}],["27.8",{"_index":4962,"t":{"1558":{"position":[[2029,4]]}}}],["2750",{"_index":5025,"t":{"1589":{"position":[[34,5]]}}}],["28",{"_index":4888,"t":{"1538":{"position":[[238,3]]},"1587":{"position":[[30,2],[60,2]]},"1589":{"position":[[67,2],[105,2],[138,2],[179,2]]}}}],["28.4",{"_index":1143,"t":{"283":{"position":[[215,4]]},"322":{"position":[[124,4]]}}}],["280",{"_index":923,"t":{"189":{"position":[[184,4]]}}}],["282",{"_index":2016,"t":{"557":{"position":[[237,3]]},"573":{"position":[[156,3]]}}}],["288",{"_index":3030,"t":{"814":{"position":[[339,4]]},"821":{"position":[[363,4]]}}}],["29",{"_index":5584,"t":{"1782":{"position":[[389,4]]}}}],["29,000",{"_index":3839,"t":{"1107":{"position":[[251,6]]}}}],["29.1",{"_index":4628,"t":{"1427":{"position":[[817,7]]}}}],["29k",{"_index":3841,"t":{"1107":{"position":[[290,3]]},"1109":{"position":[[71,3],[783,3]]}}}],["2:8",{"_index":714,"t":{"155":{"position":[[796,3]]}}}],["2=0.999\\beta_2",{"_index":525,"t":{"106":{"position":[[63,15]]}}}],["2\\alpha_2α2",{"_index":3701,"t":{"1067":{"position":[[1458,13],[1496,13]]}}}],["2\\beta_2β2",{"_index":3036,"t":{"814":{"position":[[564,12]]},"1134":{"position":[[836,12]]}}}],["2\\pi10000⋅2",{"_index":1271,"t":{"308":{"position":[[715,12]]}}}],["2^{19}k=219",{"_index":4601,"t":{"1419":{"position":[[1096,11]]}}}],["2_\\text{f",{"_index":2859,"t":{"795":{"position":[[988,13],[1032,14]]}}}],["2_f}{\\min",{"_index":2717,"t":{"774":{"position":[[611,12]]}}}],["2a",{"_index":3653,"t":{"1062":{"position":[[519,4]]},"1084":{"position":[[838,3]]}}}],["2b",{"_index":1554,"t":{"397":{"position":[[55,3]]},"517":{"position":[[100,3],[137,3],[279,9],[1159,3]]},"1047":{"position":[[202,3]]},"1062":{"position":[[1210,3]]},"1067":{"position":[[43,2]]}}}],["2d",{"_index":402,"t":{"91":{"position":[[62,2],[186,2],[1204,2]]},"93":{"position":[[16,2],[136,2],[259,2]]},"97":{"position":[[397,2]]},"116":{"position":[[191,2]]},"994":{"position":[[215,2]]},"1218":{"position":[[462,2],[553,2]]}}}],["2d2d2d",{"_index":2356,"t":{"662":{"position":[[1517,6]]}}}],["2d_v",{"_index":2175,"t":{"598":{"position":[[2137,4]]}}}],["2d_{ff})l(2dk​+2dv​+2dff",{"_index":2176,"t":{"598":{"position":[[2144,26]]}}}],["2dd×r+r×d+2d=2rd+2d",{"_index":3561,"t":{"994":{"position":[[226,19]]}}}],["2dm",{"_index":4081,"t":{"1218":{"position":[[467,3]]}}}],["2dm+2d+dn2dm",{"_index":4083,"t":{"1218":{"position":[[538,12]]}}}],["2dm×d+d×+2d=2dm+2d",{"_index":4082,"t":{"1218":{"position":[[473,18]]}}}],["2e",{"_index":1798,"t":{"517":{"position":[[680,2]]},"866":{"position":[[373,2]]},"1111":{"position":[[1395,2]]}}}],["2i",{"_index":1262,"t":{"308":{"position":[[407,3],[464,2]]}}}],["2k",{"_index":917,"t":{"189":{"position":[[59,2]]},"550":{"position":[[384,2]]}}}],["2k>2",{"_index":2404,"t":{"672":{"position":[[588,4]]}}}],["2m",{"_index":2408,"t":{"672":{"position":[[863,2]]},"994":{"position":[[677,2]]}}}],["2md+d+m2md+d+m2md+d+m",{"_index":2347,"t":{"662":{"position":[[947,21]]}}}],["2n2n2n",{"_index":2202,"t":{"608":{"position":[[243,6]]}}}],["2n_\\text{layer}d_{\\text{hidden}}}wup​∈rdmid​×2nlayer​dhidden",{"_index":4481,"t":{"1384":{"position":[[2135,61]]}}}],["2nlayer2n_{\\text{layer}}2nlay",{"_index":4483,"t":{"1384":{"position":[[2284,32]]}}}],["2rd",{"_index":3560,"t":{"994":{"position":[[220,3]]}}}],["2x2",{"_index":391,"t":{"88":{"position":[[265,3]]}}}],["2}10−2",{"_index":2432,"t":{"676":{"position":[[956,6],[1099,6]]}}}],["2×175e9×(41×98+103)=1.4e152×175e9",{"_index":2214,"t":{"610":{"position":[[220,34]]}}}],["2×l^lora×dmodel×r|\\theta",{"_index":2679,"t":{"757":{"position":[[146,29]]}}}],["2π2\\pi2",{"_index":1269,"t":{"308":{"position":[[683,8]]}}}],["2​,xkeypoint",{"_index":618,"t":{"130":{"position":[[1326,12]]}}}],["3",{"_index":158,"t":{"25":{"position":[[5,1]]},"33":{"position":[[322,1]]},"49":{"position":[[429,1]]},"78":{"position":[[830,3]]},"91":{"position":[[2242,3]]},"104":{"position":[[491,1],[541,1]]},"165":{"position":[[1399,1]]},"168":{"position":[[55,1]]},"230":{"position":[[105,2],[110,2]]},"246":{"position":[[42,1]]},"279":{"position":[[42,3]]},"308":{"position":[[968,2]]},"339":{"position":[[189,1]]},"352":{"position":[[384,1]]},"370":{"position":[[67,1]]},"382":{"position":[[177,3],[379,1]]},"397":{"position":[[15,1]]},"409":{"position":[[406,1]]},"424":{"position":[[193,2],[254,1]]},"473":{"position":[[46,1]]},"517":{"position":[[1277,2]]},"529":{"position":[[1029,2],[1125,2],[1161,3],[1666,1]]},"541":{"position":[[26,1]]},"548":{"position":[[215,2]]},"569":{"position":[[572,1]]},"596":{"position":[[1526,1]]},"606":{"position":[[215,1],[300,1],[350,1]]},"610":{"position":[[192,1],[471,1]]},"612":{"position":[[272,1],[350,1]]},"640":{"position":[[6,1]]},"658":{"position":[[3066,2]]},"664":{"position":[[137,2]]},"668":{"position":[[182,1],[199,1]]},"672":{"position":[[257,1]]},"683":{"position":[[283,1]]},"694":{"position":[[674,2]]},"709":{"position":[[278,1],[976,1],[2522,1]]},"717":{"position":[[4,1],[246,1],[316,2],[352,1]]},"719":{"position":[[696,1],[1040,2]]},"741":{"position":[[168,1],[339,1]]},"765":{"position":[[4,1],[42,3]]},"770":{"position":[[41,1]]},"774":{"position":[[936,1],[1182,1]]},"786":{"position":[[87,1]]},"795":{"position":[[1756,1]]},"807":{"position":[[345,1]]},"812":{"position":[[122,1]]},"839":{"position":[[134,2]]},"841":{"position":[[5,1]]},"870":{"position":[[347,2],[627,2],[1214,2],[1320,2],[1368,3]]},"873":{"position":[[6,1],[403,2],[1214,1]]},"875":{"position":[[120,2]]},"877":{"position":[[216,2],[454,1]]},"881":{"position":[[265,2]]},"887":{"position":[[863,2]]},"988":{"position":[[1823,1]]},"990":{"position":[[42,1]]},"1004":{"position":[[344,1]]},"1006":{"position":[[686,1]]},"1012":{"position":[[449,2]]},"1014":{"position":[[1664,2]]},"1026":{"position":[[230,1]]},"1028":{"position":[[409,2]]},"1049":{"position":[[6,1]]},"1070":{"position":[[1678,2]]},"1095":{"position":[[4,1],[210,1]]},"1107":{"position":[[877,3],[886,2],[894,2],[936,3],[945,2]]},"1111":{"position":[[1764,1]]},"1117":{"position":[[6,2]]},"1124":{"position":[[118,1],[270,1]]},"1126":{"position":[[444,1],[907,1],[2050,1]]},"1128":{"position":[[629,1]]},"1132":{"position":[[21,1],[1703,1]]},"1136":{"position":[[559,1],[609,1],[664,1],[710,1]]},"1143":{"position":[[984,2]]},"1149":{"position":[[683,1]]},"1159":{"position":[[101,1]]},"1195":{"position":[[208,2],[318,1]]},"1242":{"position":[[219,1]]},"1244":{"position":[[1105,4]]},"1250":{"position":[[96,2]]},"1264":{"position":[[120,1]]},"1268":{"position":[[0,3]]},"1291":{"position":[[269,1],[617,1],[854,1]]},"1317":{"position":[[716,1]]},"1354":{"position":[[366,1]]},"1364":{"position":[[339,1]]},"1367":{"position":[[43,1]]},"1393":{"position":[[720,1]]},"1395":{"position":[[1888,1],[2047,4],[2924,1]]},"1397":{"position":[[1133,1]]},"1409":{"position":[[317,1]]},"1423":{"position":[[1438,2]]},"1427":{"position":[[642,1]]},"1431":{"position":[[2360,1],[2658,1]]},"1442":{"position":[[866,1]]},"1455":{"position":[[709,3]]},"1471":{"position":[[126,1]]},"1473":{"position":[[4,1]]},"1479":{"position":[[5,1]]},"1507":{"position":[[54,1]]},"1529":{"position":[[72,1]]},"1544":{"position":[[175,1],[328,1]]},"1546":{"position":[[265,1],[382,1],[510,1],[582,1],[628,1],[668,1],[756,1],[823,1],[943,1]]},"1550":{"position":[[89,1]]},"1552":{"position":[[177,3]]},"1558":{"position":[[36,1],[50,1],[116,1],[204,1],[2092,1],[2152,1]]},"1563":{"position":[[9,1]]},"1565":{"position":[[20,1],[55,1]]},"1570":{"position":[[360,2]]},"1573":{"position":[[330,1]]},"1595":{"position":[[180,1]]},"1644":{"position":[[712,3]]},"1646":{"position":[[3139,4]]},"1653":{"position":[[713,2]]},"1665":{"position":[[1112,1]]},"1672":{"position":[[15,1]]},"1684":{"position":[[11,1]]},"1700":{"position":[[88,1]]},"1702":{"position":[[550,1]]},"1708":{"position":[[209,1]]},"1752":{"position":[[247,1]]},"1794":{"position":[[1039,1]]}}}],["3(a",{"_index":3938,"t":{"1139":{"position":[[121,4]]}}}],["3(b",{"_index":3944,"t":{"1141":{"position":[[612,4]]}}}],["3(c",{"_index":3945,"t":{"1143":{"position":[[5,4],[219,4]]}}}],["3(d",{"_index":3948,"t":{"1143":{"position":[[432,4]]}}}],["3)\\mathcal{l}_{logit",{"_index":4157,"t":{"1244":{"position":[[827,23]]}}}],["3)lstage2​=lretrieve​+lbox​+lmask​(3",{"_index":886,"t":{"177":{"position":[[926,38]]}}}],["3,10,20}\\{3,10,20\\}{3,10,20",{"_index":2424,"t":{"674":{"position":[[563,29]]}}}],["3,20}\\{3",{"_index":2366,"t":{"668":{"position":[[246,10]]}}}],["3,640",{"_index":4972,"t":{"1570":{"position":[[332,5]]}}}],["3.0",{"_index":4331,"t":{"1317":{"position":[[363,6]]}}}],["3.1",{"_index":3067,"t":{"835":{"position":[[8,3]]}}}],["3.2",{"_index":3272,"t":{"873":{"position":[[1735,4]]},"992":{"position":[[313,3]]}}}],["3.26",{"_index":3410,"t":{"926":{"position":[[27,7]]},"1499":{"position":[[309,6]]}}}],["3.3",{"_index":3258,"t":{"870":{"position":[[614,3]]}}}],["3.4",{"_index":4427,"t":{"1360":{"position":[[100,4]]}}}],["3.4%p",{"_index":4363,"t":{"1347":{"position":[[1682,5]]}}}],["3.4x",{"_index":4560,"t":{"1395":{"position":[[1147,4]]}}}],["3.5",{"_index":1317,"t":{"315":{"position":[[116,6]]},"322":{"position":[[151,3]]},"672":{"position":[[1205,5]]},"1273":{"position":[[239,4]]}}}],["3.5x",{"_index":2296,"t":{"644":{"position":[[358,4]]}}}],["3.6",{"_index":323,"t":{"60":{"position":[[56,4]]},"644":{"position":[[365,3]]},"656":{"position":[[438,4]]}}}],["3.6x",{"_index":2295,"t":{"644":{"position":[[352,5]]}}}],["3.75",{"_index":3275,"t":{"877":{"position":[[433,4]]}}}],["30",{"_index":51,"t":{"7":{"position":[[242,2],[264,2]]},"58":{"position":[[169,4]]},"459":{"position":[[787,2],[853,2]]},"569":{"position":[[313,3]]},"612":{"position":[[481,3]]},"622":{"position":[[570,2]]},"626":{"position":[[172,3]]},"628":{"position":[[486,3]]},"670":{"position":[[1067,3]]},"870":{"position":[[1377,4]]},"1314":{"position":[[609,3]]},"1317":{"position":[[155,3]]},"1399":{"position":[[496,3]]},"1496":{"position":[[411,5]]},"1674":{"position":[[549,2]]},"1682":{"position":[[264,2]]},"1794":{"position":[[516,4]]}}}],["30,000",{"_index":3930,"t":{"1134":{"position":[[688,6]]}}}],["300",{"_index":1375,"t":{"326":{"position":[[765,3]]},"1262":{"position":[[164,3]]},"1399":{"position":[[769,4]]}}}],["300,000",{"_index":1316,"t":{"315":{"position":[[102,7]]}}}],["300l=300",{"_index":4222,"t":{"1277":{"position":[[88,8]]}}}],["300m",{"_index":382,"t":{"86":{"position":[[452,4]]},"88":{"position":[[577,4]]},"112":{"position":[[31,4],[62,4],[247,4]]},"120":{"position":[[146,5]]},"668":{"position":[[15,4]]},"786":{"position":[[67,5]]},"1014":{"position":[[1454,4]]},"1043":{"position":[[126,4]]}}}],["302",{"_index":953,"t":{"197":{"position":[[89,3]]}}}],["303m",{"_index":493,"t":{"102":{"position":[[86,5]]}}}],["3090",{"_index":3722,"t":{"1082":{"position":[[11,4]]}}}],["30b",{"_index":1703,"t":{"473":{"position":[[304,3]]}}}],["30k",{"_index":4608,"t":{"1421":{"position":[[403,3]]}}}],["30m",{"_index":547,"t":{"112":{"position":[[265,4]]}}}],["31",{"_index":3451,"t":{"961":{"position":[[81,2]]},"1782":{"position":[[3106,4]]}}}],["31k",{"_index":4927,"t":{"1552":{"position":[[566,5]]}}}],["32",{"_index":905,"t":{"182":{"position":[[336,3]]},"372":{"position":[[59,2]]},"614":{"position":[[183,2],[226,2]]},"630":{"position":[[1065,3]]},"666":{"position":[[379,2]]},"670":{"position":[[144,2],[465,3]]},"709":{"position":[[165,2]]},"765":{"position":[[171,3]]},"807":{"position":[[305,2]]},"814":{"position":[[196,3]]},"821":{"position":[[202,3]]},"828":{"position":[[204,2]]},"961":{"position":[[0,2]]},"979":{"position":[[1598,2]]},"1111":{"position":[[504,4],[1426,2]]},"1134":{"position":[[732,2]]},"1227":{"position":[[1572,2]]},"1264":{"position":[[36,3]]},"1379":{"position":[[1187,3]]},"1501":{"position":[[100,2],[128,2]]},"1669":{"position":[[721,2]]},"1718":{"position":[[714,2]]},"1730":{"position":[[956,2]]},"1736":{"position":[[1210,2]]},"1738":{"position":[[367,3]]},"1756":{"position":[[222,2]]},"1766":{"position":[[279,4],[320,4]]},"1788":{"position":[[872,4]]}}}],["32)k(k=4,16,32",{"_index":3600,"t":{"1004":{"position":[[269,17]]}}}],["32000",{"_index":1311,"t":{"313":{"position":[[222,5]]}}}],["3232×32",{"_index":777,"t":{"170":{"position":[[1198,8],[1375,7]]}}}],["32bit",{"_index":1105,"t":{"244":{"position":[[356,6]]}}}],["32k",{"_index":669,"t":{"143":{"position":[[571,3]]},"326":{"position":[[542,3]]}}}],["32n=32",{"_index":3394,"t":{"905":{"position":[[224,6]]}}}],["32×3232",{"_index":776,"t":{"170":{"position":[[1183,7],[1360,7]]}}}],["33",{"_index":2158,"t":{"598":{"position":[[1514,5]]},"1802":{"position":[[48,3]]}}}],["330k",{"_index":2375,"t":{"670":{"position":[[88,4]]}}}],["330m",{"_index":3644,"t":{"1056":{"position":[[48,5]]}}}],["335m",{"_index":2684,"t":{"759":{"position":[[108,6]]}}}],["33k",{"_index":4926,"t":{"1552":{"position":[[505,5]]}}}],["34",{"_index":5601,"t":{"1782":{"position":[[1949,4]]}}}],["34,039",{"_index":3837,"t":{"1107":{"position":[[76,8]]}}}],["345m",{"_index":3713,"t":{"1070":{"position":[[1593,6]]}}}],["34k",{"_index":3838,"t":{"1107":{"position":[[110,4]]},"1109":{"position":[[37,3]]}}}],["350",{"_index":293,"t":{"53":{"position":[[208,3]]},"80":{"position":[[6,3]]}}}],["3500",{"_index":3252,"t":{"866":{"position":[[623,4],[908,4]]},"1111":{"position":[[1667,4]]}}}],["350b",{"_index":2651,"t":{"741":{"position":[[195,4]]}}}],["350gb",{"_index":2654,"t":{"741":{"position":[[283,6]]}}}],["350m",{"_index":1548,"t":{"397":{"position":[[17,6]]},"517":{"position":[[187,4],[304,4]]}}}],["35k",{"_index":668,"t":{"143":{"position":[[547,3]]}}}],["35mb",{"_index":2655,"t":{"741":{"position":[[292,5]]},"770":{"position":[[115,4]]}}}],["36",{"_index":5444,"t":{"1718":{"position":[[810,2]]}}}],["36m",{"_index":1310,"t":{"313":{"position":[[178,3]]},"517":{"position":[[314,4]]}}}],["37",{"_index":2429,"t":{"676":{"position":[[379,4]]},"1006":{"position":[[403,3]]},"1738":{"position":[[779,2],[864,2],[895,2]]}}}],["37.18",{"_index":4866,"t":{"1507":{"position":[[333,6]]}}}],["37000",{"_index":1307,"t":{"313":{"position":[[110,5]]}}}],["38",{"_index":4889,"t":{"1538":{"position":[[242,3]]},"1782":{"position":[[725,4]]}}}],["3a",{"_index":4062,"t":{"1197":{"position":[[123,2]]}}}],["3b",{"_index":2025,"t":{"567":{"position":[[563,2]]},"594":{"position":[[526,2],[559,3]]},"598":{"position":[[3064,2]]},"604":{"position":[[18,2]]},"620":{"position":[[20,2]]},"633":{"position":[[299,2]]},"640":{"position":[[28,2]]},"644":{"position":[[249,2]]},"646":{"position":[[302,2],[389,2]]},"1006":{"position":[[433,2]]},"1197":{"position":[[282,2]]},"1413":{"position":[[50,3]]}}}],["3c=3",{"_index":1054,"t":{"227":{"position":[[662,6]]}}}],["3d",{"_index":1030,"t":{"221":{"position":[[198,2]]},"339":{"position":[[632,2]]}}}],["3e",{"_index":3273,"t":{"875":{"position":[[208,2]]},"1111":{"position":[[1401,2]]},"1665":{"position":[[1319,2]]},"1674":{"position":[[383,2]]},"1682":{"position":[[209,2]]}}}],["3e−13",{"_index":3740,"t":{"1084":{"position":[[1047,6]]}}}],["3e−3",{"_index":2193,"t":{"602":{"position":[[393,7]]}}}],["3k≤3",{"_index":4692,"t":{"1431":{"position":[[3068,4]]}}}],["3m",{"_index":1123,"t":{"255":{"position":[[93,2]]}}}],["3n3n3n",{"_index":2204,"t":{"608":{"position":[[499,6]]}}}],["3x3",{"_index":224,"t":{"38":{"position":[[183,5]]},"40":{"position":[[112,3]]},"78":{"position":[[917,3]]}}}],["3}1×10−3",{"_index":3052,"t":{"821":{"position":[[461,8]]}}}],["3}\\}{1⋅10−5,3⋅10−5,1⋅10−4,3⋅10−3",{"_index":2382,"t":{"670":{"position":[[284,33]]}}}],["3}\\}{3⋅10−5,1⋅10−4,3⋅10−4,1⋅10−3",{"_index":2423,"t":{"674":{"position":[[522,33]]}}}],["3}\\}{3⋅10−5,3⋅10−4,3⋅10−3",{"_index":2365,"t":{"668":{"position":[[212,26]]}}}],["3}e−3",{"_index":2194,"t":{"602":{"position":[[401,5]]}}}],["3~9",{"_index":181,"t":{"25":{"position":[[687,4]]}}}],["3×11e9×1,000×8×103=2.7e163",{"_index":2217,"t":{"612":{"position":[[151,26]]}}}],["3⋅10−5,1⋅10−4,3⋅10−4,1⋅10−3}\\{3\\cdot10",{"_index":2421,"t":{"674":{"position":[[438,41]]}}}],["3⋅10−5,3⋅10−4,3⋅10−3}\\{3",{"_index":2364,"t":{"668":{"position":[[141,25]]}}}],["3⋅10−5,5⋅10−5,1⋅10−4}\\{3\\cdot10",{"_index":2417,"t":{"674":{"position":[[286,34]]}}}],["4",{"_index":176,"t":{"25":{"position":[[455,2]]},"38":{"position":[[214,2]]},"53":{"position":[[371,5]]},"80":{"position":[[19,1]]},"91":{"position":[[956,2],[2424,3]]},"104":{"position":[[472,1],[511,2]]},"118":{"position":[[191,2]]},"128":{"position":[[117,1]]},"143":{"position":[[71,3]]},"155":{"position":[[191,1]]},"170":{"position":[[877,1]]},"205":{"position":[[288,1]]},"230":{"position":[[233,3]]},"251":{"position":[[4,1]]},"253":{"position":[[291,1]]},"322":{"position":[[561,1]]},"326":{"position":[[334,1]]},"339":{"position":[[86,1]]},"352":{"position":[[709,1]]},"358":{"position":[[1194,1]]},"360":{"position":[[230,2]]},"395":{"position":[[222,3]]},"424":{"position":[[198,2]]},"517":{"position":[[683,3]]},"529":{"position":[[539,1],[646,4]]},"640":{"position":[[204,1]]},"666":{"position":[[354,3]]},"668":{"position":[[195,3]]},"670":{"position":[[455,2]]},"672":{"position":[[506,1],[1226,2]]},"676":{"position":[[519,1],[1406,2]]},"696":{"position":[[1163,2]]},"721":{"position":[[402,1]]},"739":{"position":[[15,1]]},"765":{"position":[[32,1]]},"770":{"position":[[384,1]]},"776":{"position":[[71,1]]},"797":{"position":[[845,2]]},"812":{"position":[[156,1]]},"814":{"position":[[256,2],[685,3],[698,2]]},"821":{"position":[[192,2],[268,2]]},"823":{"position":[[0,1]]},"828":{"position":[[190,1]]},"830":{"position":[[0,1]]},"835":{"position":[[190,1]]},"837":{"position":[[100,1]]},"839":{"position":[[137,1],[258,2],[335,2]]},"875":{"position":[[72,1]]},"905":{"position":[[474,1]]},"907":{"position":[[4,1],[111,1]]},"932":{"position":[[107,1]]},"934":{"position":[[335,1]]},"951":{"position":[[29,1]]},"959":{"position":[[61,1],[121,1]]},"963":{"position":[[498,1]]},"965":{"position":[[253,1]]},"979":{"position":[[1596,1]]},"990":{"position":[[441,1]]},"992":{"position":[[793,1]]},"997":{"position":[[524,2],[659,3],[766,3]]},"1006":{"position":[[79,1],[623,1],[1029,1]]},"1113":{"position":[[383,4]]},"1117":{"position":[[9,1]]},"1126":{"position":[[2122,1]]},"1134":{"position":[[371,1]]},"1145":{"position":[[114,1],[2252,2]]},"1199":{"position":[[59,2]]},"1227":{"position":[[1570,1]]},"1250":{"position":[[99,2]]},"1253":{"position":[[98,2]]},"1264":{"position":[[29,2],[195,1]]},"1268":{"position":[[68,1]]},"1270":{"position":[[300,1]]},"1291":{"position":[[568,2]]},"1319":{"position":[[239,2]]},"1323":{"position":[[514,1]]},"1357":{"position":[[503,2]]},"1362":{"position":[[423,1]]},"1373":{"position":[[206,1]]},"1379":{"position":[[1209,1]]},"1391":{"position":[[15,1]]},"1395":{"position":[[1818,1],[2038,1],[2783,1]]},"1399":{"position":[[6,1],[659,2]]},"1429":{"position":[[1149,1]]},"1431":{"position":[[1893,2]]},"1440":{"position":[[651,1]]},"1483":{"position":[[135,1]]},"1509":{"position":[[98,1]]},"1589":{"position":[[157,1]]},"1667":{"position":[[25,1]]},"1669":{"position":[[10,1]]},"1674":{"position":[[582,1]]},"1676":{"position":[[119,1]]},"1708":{"position":[[360,1]]}}}],["4)lstage3​=lretrieve​+lbox​+lmask​+lembed​(4",{"_index":901,"t":{"177":{"position":[[1570,46]]}}}],["4,8,16,32,64",{"_index":3044,"t":{"821":{"position":[[175,16],[209,16]]}}}],["4.1",{"_index":2236,"t":{"620":{"position":[[230,4]]},"870":{"position":[[620,3]]},"1317":{"position":[[315,3]]}}}],["4.2",{"_index":1512,"t":{"376":{"position":[[178,3]]},"1026":{"position":[[218,3]]}}}],["4.2mb",{"_index":2221,"t":{"614":{"position":[[100,5],[274,5],[414,6]]}}}],["4.3",{"_index":2088,"t":{"594":{"position":[[964,3]]},"877":{"position":[[259,3]]},"1395":{"position":[[1123,3]]}}}],["4.4",{"_index":2997,"t":{"801":{"position":[[2679,3]]},"1423":{"position":[[217,4]]}}}],["4.5m",{"_index":1303,"t":{"313":{"position":[[2,4]]}}}],["4.65",{"_index":3065,"t":{"833":{"position":[[351,6]]}}}],["4.8",{"_index":4861,"t":{"1505":{"position":[[527,4]]}}}],["4.9m",{"_index":3401,"t":{"909":{"position":[[109,4]]}}}],["4/6/8",{"_index":4571,"t":{"1397":{"position":[[436,5]]}}}],["40",{"_index":951,"t":{"197":{"position":[[61,2]]},"851":{"position":[[1043,2]]},"1070":{"position":[[1036,2]]},"1334":{"position":[[125,4]]},"1442":{"position":[[2176,4]]},"1496":{"position":[[417,5]]},"1546":{"position":[[353,4]]},"1556":{"position":[[20,4]]},"1720":{"position":[[1839,2]]},"1732":{"position":[[61,2]]},"1736":{"position":[[1043,4]]},"1766":{"position":[[284,3]]},"1788":{"position":[[884,2]]}}}],["40.77",{"_index":3408,"t":{"919":{"position":[[134,6]]}}}],["400",{"_index":3250,"t":{"866":{"position":[[432,3]]},"1210":{"position":[[115,4]]}}}],["4000warmup_steps=4000",{"_index":1338,"t":{"317":{"position":[[579,21]]}}}],["400~20000",{"_index":3858,"t":{"1111":{"position":[[563,9]]}}}],["4096",{"_index":527,"t":{"106":{"position":[[109,4]]}}}],["40g",{"_index":1794,"t":{"517":{"position":[[417,3]]}}}],["40k",{"_index":1365,"t":{"326":{"position":[[262,3],[984,3]]},"672":{"position":[[1178,3]]}}}],["41",{"_index":2207,"t":{"608":{"position":[[710,4]]},"610":{"position":[[255,3],[451,3]]},"1107":{"position":[[50,4]]},"1720":{"position":[[2203,2]]},"1740":{"position":[[187,2]]},"1768":{"position":[[475,2]]}}}],["41.0",{"_index":1346,"t":{"322":{"position":[[277,4]]}}}],["41.5gb",{"_index":2227,"t":{"614":{"position":[[388,8],[502,10]]}}}],["41×98+10341",{"_index":2210,"t":{"608":{"position":[[1071,11]]}}}],["41×98×32bits=1641",{"_index":2224,"t":{"614":{"position":[[201,17]]}}}],["42",{"_index":5328,"t":{"1663":{"position":[[111,2]]}}}],["42.5m",{"_index":3261,"t":{"870":{"position":[[1244,6]]}}}],["420",{"_index":1802,"t":{"517":{"position":[[973,4]]}}}],["422m",{"_index":1553,"t":{"397":{"position":[[48,6]]}}}],["43",{"_index":3255,"t":{"866":{"position":[[1092,2]]},"1762":{"position":[[304,4]]}}}],["43.08",{"_index":3407,"t":{"919":{"position":[[92,7]]}}}],["43.3",{"_index":3846,"t":{"1109":{"position":[[44,5]]}}}],["44×4",{"_index":783,"t":{"170":{"position":[[1261,4]]}}}],["45",{"_index":3708,"t":{"1070":{"position":[[1067,2]]},"1538":{"position":[[246,3]]},"1802":{"position":[[1038,2]]}}}],["45.2",{"_index":3757,"t":{"1093":{"position":[[1287,5]]},"1109":{"position":[[78,5]]}}}],["45.6",{"_index":1700,"t":{"471":{"position":[[64,4]]}}}],["45e−4",{"_index":3743,"t":{"1084":{"position":[[1090,5]]}}}],["45x",{"_index":1904,"t":{"529":{"position":[[656,3]]}}}],["46",{"_index":5364,"t":{"1672":{"position":[[318,2]]},"1750":{"position":[[61,3]]}}}],["47",{"_index":5555,"t":{"1770":{"position":[[153,4]]}}}],["47.43",{"_index":3276,"t":{"881":{"position":[[322,6]]}}}],["47.7",{"_index":4683,"t":{"1431":{"position":[[2603,5]]}}}],["48",{"_index":4629,"t":{"1427":{"position":[[878,3]]},"1431":{"position":[[248,4],[1548,4],[2660,3]]},"1538":{"position":[[250,3]]},"1756":{"position":[[230,2]]}}}],["48.9",{"_index":3596,"t":{"1002":{"position":[[809,7]]}}}],["480",{"_index":244,"t":{"42":{"position":[[114,3]]}}}],["48dmid​=48",{"_index":4547,"t":{"1393":{"position":[[1038,10]]},"1395":{"position":[[602,10],[1060,11]]}}}],["48r=1,2,…,48",{"_index":4661,"t":{"1431":{"position":[[524,13]]}}}],["49",{"_index":5611,"t":{"1782":{"position":[[3111,3]]}}}],["4a",{"_index":713,"t":{"155":{"position":[[679,2]]}}}],["4b",{"_index":715,"t":{"155":{"position":[[900,2]]}}}],["4c",{"_index":717,"t":{"155":{"position":[[1039,2]]}}}],["4r=4",{"_index":2653,"t":{"741":{"position":[[212,4]]},"770":{"position":[[185,4]]},"778":{"position":[[655,4]]}}}],["4},1\\cdot10",{"_index":2422,"t":{"674":{"position":[[508,13]]}}}],["4},3\\cdot10",{"_index":2381,"t":{"670":{"position":[[270,13]]},"674":{"position":[[494,13]]}}}],["4}1e−4",{"_index":667,"t":{"143":{"position":[[524,6]]}}}],["4}\\}{3⋅10−5,5⋅10−5,1⋅10−4",{"_index":2419,"t":{"674":{"position":[[349,26]]}}}],["4×44",{"_index":782,"t":{"170":{"position":[[1249,4]]}}}],["5",{"_index":80,"t":{"11":{"position":[[39,1]]},"42":{"position":[[144,1]]},"53":{"position":[[193,1]]},"80":{"position":[[28,1]]},"130":{"position":[[691,1]]},"140":{"position":[[388,1]]},"157":{"position":[[198,1]]},"207":{"position":[[30,1],[80,1]]},"230":{"position":[[75,1]]},"322":{"position":[[452,3]]},"354":{"position":[[150,1]]},"366":{"position":[[53,1]]},"372":{"position":[[111,1]]},"397":{"position":[[0,3],[191,3]]},"403":{"position":[[85,1]]},"455":{"position":[[560,1]]},"563":{"position":[[166,1]]},"569":{"position":[[19,3],[382,3],[537,3]]},"618":{"position":[[364,1]]},"668":{"position":[[178,3],[445,2]]},"674":{"position":[[79,1]]},"676":{"position":[[1409,1]]},"705":{"position":[[391,1]]},"709":{"position":[[1201,2],[2474,1]]},"770":{"position":[[240,2]]},"814":{"position":[[659,3],[672,3]]},"839":{"position":[[347,1]]},"875":{"position":[[211,1]]},"877":{"position":[[63,1]]},"905":{"position":[[119,1]]},"963":{"position":[[488,1]]},"997":{"position":[[368,2]]},"999":{"position":[[797,1]]},"1006":{"position":[[1613,1]]},"1070":{"position":[[750,1],[1255,1]]},"1084":{"position":[[634,1],[985,1]]},"1107":{"position":[[1071,1]]},"1111":{"position":[[1392,2],[1398,2],[1404,1]]},"1113":{"position":[[66,2]]},"1115":{"position":[[920,1]]},"1117":{"position":[[124,1]]},"1126":{"position":[[2247,1]]},"1134":{"position":[[817,1]]},"1139":{"position":[[21,2]]},"1151":{"position":[[454,1]]},"1197":{"position":[[60,3]]},"1203":{"position":[[31,2],[196,1]]},"1210":{"position":[[98,3]]},"1246":{"position":[[240,1]]},"1259":{"position":[[87,1]]},"1266":{"position":[[168,1]]},"1275":{"position":[[62,1]]},"1277":{"position":[[51,1]]},"1314":{"position":[[297,1],[766,1]]},"1321":{"position":[[156,3]]},"1323":{"position":[[245,3]]},"1328":{"position":[[160,1]]},"1330":{"position":[[261,1]]},"1334":{"position":[[103,3]]},"1362":{"position":[[405,1]]},"1364":{"position":[[273,1]]},"1373":{"position":[[190,1]]},"1391":{"position":[[42,1]]},"1393":{"position":[[513,1]]},"1431":{"position":[[1687,1]]},"1511":{"position":[[181,1]]},"1581":{"position":[[134,1]]},"1589":{"position":[[198,1],[281,1]]},"1657":{"position":[[730,5],[2453,1],[3217,1]]},"1665":{"position":[[1316,2],[1327,1],[1453,1],[1545,2]]},"1669":{"position":[[763,3],[794,1]]},"1674":{"position":[[380,2],[391,1],[743,2]]},"1676":{"position":[[123,1]]},"1682":{"position":[[124,1],[206,2],[212,2],[218,1],[282,3],[331,3]]},"1708":{"position":[[404,1]]},"1718":{"position":[[847,1]]},"1748":{"position":[[132,1]]},"1778":{"position":[[125,1]]}}}],["5,000",{"_index":3942,"t":{"1141":{"position":[[248,5]]},"1421":{"position":[[606,7]]}}}],["5,046",{"_index":1687,"t":{"464":{"position":[[52,5]]}}}],["5,20,50,100}\\{5",{"_index":4422,"t":{"1357":{"position":[[401,17]]}}}],["5,5e",{"_index":5349,"t":{"1665":{"position":[[1322,4]]},"1674":{"position":[[386,4]]}}}],["5.0",{"_index":5358,"t":{"1672":{"position":[[181,3]]}}}],["5.1",{"_index":4037,"t":{"1170":{"position":[[102,4]]}}}],["5.1x",{"_index":2294,"t":{"644":{"position":[[324,4]]}}}],["5.3x",{"_index":2292,"t":{"644":{"position":[[217,5]]},"1395":{"position":[[1075,4]]}}}],["5.6",{"_index":1604,"t":{"434":{"position":[[574,4]]},"436":{"position":[[2303,4]]},"475":{"position":[[147,3]]},"1172":{"position":[[184,5]]},"1176":{"position":[[153,5]]}}}],["5.62",{"_index":2549,"t":{"707":{"position":[[163,5]]}}}],["5.6x",{"_index":2293,"t":{"644":{"position":[[223,4]]}}}],["5.7x",{"_index":2243,"t":{"626":{"position":[[568,4]]},"628":{"position":[[1427,4],[1644,4]]},"644":{"position":[[230,4]]}}}],["50",{"_index":677,"t":{"147":{"position":[[157,3],[182,3]]},"182":{"position":[[25,3]]},"201":{"position":[[14,2]]},"322":{"position":[[621,2]]},"354":{"position":[[39,3]]},"366":{"position":[[7,2],[377,4]]},"372":{"position":[[50,2]]},"376":{"position":[[206,2]]},"399":{"position":[[450,3],[526,4]]},"515":{"position":[[161,2],[468,3]]},"618":{"position":[[196,2]]},"670":{"position":[[359,3]]},"870":{"position":[[827,3],[1203,4],[1382,3]]},"1210":{"position":[[106,3],[152,2]]},"1314":{"position":[[707,3]]},"1357":{"position":[[423,3]]},"1362":{"position":[[112,2]]},"1399":{"position":[[502,3]]},"1496":{"position":[[423,5]]},"1728":{"position":[[172,2]]},"1762":{"position":[[309,3]]},"1790":{"position":[[226,5]]}}}],["50,000",{"_index":281,"t":{"53":{"position":[[11,6]]}}}],["50.6",{"_index":3847,"t":{"1109":{"position":[[52,5]]}}}],["50/80",{"_index":3453,"t":{"963":{"position":[[561,5]]}}}],["500",{"_index":4540,"t":{"1393":{"position":[[313,4]]},"1421":{"position":[[621,3]]},"1674":{"position":[[417,3]]}}}],["500\\}k={100,500",{"_index":4562,"t":{"1395":{"position":[[1402,16],[2620,17]]}}}],["500b",{"_index":2023,"t":{"567":{"position":[[179,4]]}}}],["500k",{"_index":1705,"t":{"475":{"position":[[88,4]]},"479":{"position":[[179,4]]},"949":{"position":[[228,4]]}}}],["500k=500",{"_index":4551,"t":{"1395":{"position":[[140,9],[1533,8]]}}}],["50\\}{1,5,10,20,50",{"_index":2558,"t":{"709":{"position":[[1212,18]]}}}],["50k",{"_index":3440,"t":{"949":{"position":[[252,3]]}}}],["50l=50",{"_index":4564,"t":{"1395":{"position":[[1768,6],[2099,6]]}}}],["50x16",{"_index":1457,"t":{"354":{"position":[[74,6]]}}}],["50x64",{"_index":1458,"t":{"354":{"position":[[88,5]]}}}],["51",{"_index":5496,"t":{"1730":{"position":[[427,2]]},"1772":{"position":[[454,2]]},"1802":{"position":[[143,2]]}}}],["511",{"_index":925,"t":{"189":{"position":[[194,3]]}}}],["512",{"_index":330,"t":{"63":{"position":[[120,3]]},"106":{"position":[[156,3],[170,3]]},"143":{"position":[[654,3]]},"358":{"position":[[208,5]]},"517":{"position":[[715,4],[769,4]]},"644":{"position":[[143,3],[278,3]]}}}],["512dmodel​=512",{"_index":1180,"t":{"292":{"position":[[506,14]]},"304":{"position":[[493,14]]}}}],["5150",{"_index":1783,"t":{"515":{"position":[[426,5]]}}}],["518",{"_index":530,"t":{"106":{"position":[[186,3]]}}}],["51e−5",{"_index":4846,"t":{"1496":{"position":[[665,5]]}}}],["52",{"_index":2396,"t":{"670":{"position":[[1532,3]]},"1736":{"position":[[491,2],[818,2]]},"1762":{"position":[[313,3],[404,3]]},"1782":{"position":[[291,4]]},"1790":{"position":[[427,4]]}}}],["52.4",{"_index":2027,"t":{"567":{"position":[[586,5]]}}}],["52k",{"_index":3281,"t":{"885":{"position":[[99,3]]},"887":{"position":[[288,3]]},"891":{"position":[[0,3]]},"905":{"position":[[21,3]]},"959":{"position":[[19,3]]}}}],["53",{"_index":5585,"t":{"1782":{"position":[[507,4]]}}}],["530b",{"_index":3989,"t":{"1159":{"position":[[116,5]]}}}],["540b",{"_index":1531,"t":{"382":{"position":[[298,4]]},"384":{"position":[[995,4]]},"388":{"position":[[33,4]]},"397":{"position":[[89,5]]},"399":{"position":[[339,4],[567,4]]},"416":{"position":[[96,5]]},"424":{"position":[[275,4]]},"539":{"position":[[267,4]]},"557":{"position":[[63,4],[408,6]]},"561":{"position":[[165,4]]},"567":{"position":[[242,4]]},"577":{"position":[[59,5]]},"581":{"position":[[96,4]]},"583":{"position":[[48,4]]}}}],["55",{"_index":4598,"t":{"1419":{"position":[[1005,2]]},"1724":{"position":[[452,2]]},"1772":{"position":[[344,2]]}}}],["56",{"_index":5596,"t":{"1782":{"position":[[1788,5]]}}}],["567k",{"_index":3447,"t":{"959":{"position":[[69,4]]}}}],["57",{"_index":2004,"t":{"553":{"position":[[135,2]]},"670":{"position":[[134,2]]}}}],["576",{"_index":3050,"t":{"821":{"position":[[368,3]]}}}],["576\\}{144,288,576",{"_index":3031,"t":{"814":{"position":[[344,18]]}}}],["58.9",{"_index":4625,"t":{"1427":{"position":[[744,5]]}}}],["5\\%0.5%−5",{"_index":2415,"t":{"672":{"position":[[1385,10]]}}}],["5a",{"_index":3605,"t":{"1006":{"position":[[1845,3]]}}}],["5e",{"_index":5381,"t":{"1682":{"position":[[215,2]]}}}],["5e−45",{"_index":3742,"t":{"1084":{"position":[[1083,6]]}}}],["5k",{"_index":653,"t":{"143":{"position":[[14,2]]},"185":{"position":[[23,3]]}}}],["5m",{"_index":3435,"t":{"945":{"position":[[929,3]]}}}],["5x5",{"_index":225,"t":{"38":{"position":[[189,4]]}}}],["5},1\\cdot10",{"_index":2380,"t":{"670":{"position":[[256,13]]},"674":{"position":[[335,13],[480,13]]}}}],["5},3\\cdot10",{"_index":2379,"t":{"670":{"position":[[242,13]]}}}],["5},5\\cdot10",{"_index":2418,"t":{"674":{"position":[[321,13]]}}}],["5}5⋅10−5",{"_index":4322,"t":{"1314":{"position":[[329,8]]}}}],["5~11",{"_index":184,"t":{"25":{"position":[[745,5]]}}}],["5~9",{"_index":4552,"t":{"1395":{"position":[[153,3]]}}}],["5×10−5,8×10−5,1×10−4,2×10−4",{"_index":3039,"t":{"814":{"position":[[701,31]]}}}],["5×10−5,8×10−5,1×10−4,2×10−4}\\{5",{"_index":3038,"t":{"814":{"position":[[619,32]]}}}],["5⋅10−55",{"_index":4321,"t":{"1314":{"position":[[310,7]]}}}],["6",{"_index":226,"t":{"38":{"position":[[217,2]]},"42":{"position":[[146,5]]},"147":{"position":[[256,1]]},"157":{"position":[[340,2]]},"163":{"position":[[726,1]]},"172":{"position":[[698,1],[734,1]]},"182":{"position":[[204,1],[222,1]]},"227":{"position":[[369,1]]},"409":{"position":[[222,1],[418,1]]},"414":{"position":[[155,2]]},"565":{"position":[[112,1]]},"587":{"position":[[771,2]]},"606":{"position":[[325,2]]},"676":{"position":[[116,1],[465,1]]},"709":{"position":[[1276,1]]},"776":{"position":[[247,1]]},"893":{"position":[[1661,1]]},"907":{"position":[[83,1]]},"997":{"position":[[19,3]]},"999":{"position":[[413,3]]},"1006":{"position":[[2097,1]]},"1113":{"position":[[273,4]]},"1115":{"position":[[237,2],[443,1]]},"1253":{"position":[[39,2]]},"1266":{"position":[[68,4]]},"1283":{"position":[[7,1],[232,1]]},"1314":{"position":[[790,1]]},"1334":{"position":[[157,1]]},"1347":{"position":[[1561,1],[1642,1]]},"1357":{"position":[[53,1]]},"1513":{"position":[[375,1]]},"1523":{"position":[[349,1]]},"1653":{"position":[[716,2]]},"1659":{"position":[[774,1]]},"1674":{"position":[[171,1]]},"1708":{"position":[[530,1]]}}}],["6,700",{"_index":1689,"t":{"464":{"position":[[109,5]]}}}],["6.4",{"_index":4349,"t":{"1341":{"position":[[269,6]]}}}],["6.5",{"_index":3728,"t":{"1082":{"position":[[231,4]]}}}],["6.7",{"_index":2198,"t":{"606":{"position":[[219,4]]}}}],["6.7b",{"_index":1550,"t":{"397":{"position":[[30,5]]},"473":{"position":[[17,4],[328,6]]}}}],["6.8",{"_index":151,"t":{"23":{"position":[[131,4]]},"25":{"position":[[441,4],[704,4]]},"76":{"position":[[210,4]]}}}],["6.88",{"_index":3406,"t":{"914":{"position":[[167,6]]}}}],["6.91/0.3221.5≈6.91/0.32",{"_index":2738,"t":{"778":{"position":[[693,23]]}}}],["60",{"_index":315,"t":{"58":{"position":[[163,2]]},"569":{"position":[[128,3]]},"602":{"position":[[429,2]]},"866":{"position":[[1008,2]]},"873":{"position":[[1080,3],[1559,3]]},"921":{"position":[[160,2]]},"1334":{"position":[[130,3]]},"1496":{"position":[[429,5]]}}}],["60.7",{"_index":2137,"t":{"596":{"position":[[2471,5]]}}}],["600",{"_index":1800,"t":{"517":{"position":[[819,6]]}}}],["60][15,28,38,45,48,60",{"_index":4890,"t":{"1538":{"position":[[254,22]]}}}],["60m",{"_index":3712,"t":{"1070":{"position":[[1538,6]]},"1255":{"position":[[230,5]]},"1268":{"position":[[197,3]]},"1413":{"position":[[33,4]]}}}],["61",{"_index":5588,"t":{"1782":{"position":[[1513,3]]}}}],["61.7",{"_index":3595,"t":{"1002":{"position":[[794,7]]}}}],["62",{"_index":5527,"t":{"1738":{"position":[[624,2]]},"1782":{"position":[[567,4]]},"1794":{"position":[[822,4]]}}}],["62.4",{"_index":4555,"t":{"1395":{"position":[[766,5]]}}}],["62.5",{"_index":4223,"t":{"1279":{"position":[[217,5]]}}}],["62.71",{"_index":2138,"t":{"596":{"position":[[2479,6]]}}}],["62.85",{"_index":4858,"t":{"1501":{"position":[[298,6]]}}}],["62b",{"_index":1558,"t":{"397":{"position":[[84,4]]},"399":{"position":[[547,3],[587,3]]},"539":{"position":[[555,3]]},"557":{"position":[[57,3],[395,3],[402,3]]},"567":{"position":[[171,3]]}}}],["63.3",{"_index":2139,"t":{"596":{"position":[[2497,5]]}}}],["64",{"_index":2261,"t":{"630":{"position":[[1069,2]]},"668":{"position":[[617,2]]},"672":{"position":[[814,2]]},"674":{"position":[[689,2]]},"676":{"position":[[148,2],[1349,2]]},"821":{"position":[[206,2]]},"828":{"position":[[157,2]]},"866":{"position":[[479,2]]},"905":{"position":[[165,2]]},"1091":{"position":[[245,3]]},"1120":{"position":[[198,3]]},"1395":{"position":[[497,3]]},"1665":{"position":[[1437,2]]},"1680":{"position":[[232,2]]}}}],["64,128,256",{"_index":4553,"t":{"1395":{"position":[[482,14],[510,14]]}}}],["64.2",{"_index":3755,"t":{"1093":{"position":[[1246,5]]},"1109":{"position":[[86,5]]}}}],["64.6",{"_index":2191,"t":{"600":{"position":[[510,4]]}}}],["64.9",{"_index":4969,"t":{"1570":{"position":[[281,4]]}}}],["640x640",{"_index":672,"t":{"143":{"position":[[662,7],[702,7]]},"147":{"position":[[431,7]]}}}],["641≤i≤64",{"_index":2709,"t":{"774":{"position":[[356,9]]}}}],["64\\}{2,4,8,16,32,64",{"_index":2386,"t":{"670":{"position":[[469,20]]}}}],["64\\}{8,16,32,64",{"_index":3026,"t":{"814":{"position":[[200,16]]}}}],["64c=64",{"_index":1059,"t":{"227":{"position":[[829,6]]}}}],["64dk​=dv​=dmodel​/h=64",{"_index":1238,"t":{"300":{"position":[[1316,22]]}}}],["64r=64",{"_index":2728,"t":{"776":{"position":[[8,6]]}}}],["65.8",{"_index":2192,"t":{"600":{"position":[[518,4]]}}}],["650b",{"_index":3439,"t":{"947":{"position":[[203,4]]}}}],["65b",{"_index":3452,"t":{"963":{"position":[[432,3]]}}}],["66",{"_index":5356,"t":{"1672":{"position":[[139,3]]},"1794":{"position":[[590,4]]}}}],["67",{"_index":5462,"t":{"1720":{"position":[[1083,2]]},"1736":{"position":[[1048,3]]},"1766":{"position":[[288,3]]}}}],["67m",{"_index":1791,"t":{"517":{"position":[[319,4]]}}}],["68",{"_index":5557,"t":{"1770":{"position":[[172,2]]}}}],["68.37",{"_index":1513,"t":{"376":{"position":[[272,5]]}}}],["68b",{"_index":1556,"t":{"397":{"position":[[63,4]]}}}],["69",{"_index":2430,"t":{"676":{"position":[[391,3]]},"1425":{"position":[[611,3]]}}}],["6b",{"_index":1786,"t":{"517":{"position":[[104,3],[141,3],[289,3],[1163,2],[1238,2]]},"1546":{"position":[[532,3]]},"1558":{"position":[[581,2]]}}}],["6m",{"_index":3566,"t":{"994":{"position":[[672,2]]}}}],["6n6n6n",{"_index":2203,"t":{"608":{"position":[[285,6]]}}}],["6n=6",{"_index":1173,"t":{"292":{"position":[[17,4]]},"294":{"position":[[18,4]]}}}],["6x",{"_index":1903,"t":{"529":{"position":[[583,2]]}}}],["6~7",{"_index":324,"t":{"60":{"position":[[77,4]]}}}],["7",{"_index":559,"t":{"114":{"position":[[199,1],[288,1]]},"157":{"position":[[343,1]]},"565":{"position":[[227,1]]},"676":{"position":[[1044,3]]},"801":{"position":[[2740,3]]},"837":{"position":[[34,1],[142,1]]},"866":{"position":[[577,1]]},"969":{"position":[[5,1]]},"994":{"position":[[754,2]]},"1111":{"position":[[115,3]]},"1113":{"position":[[56,2],[263,2],[373,2]]},"1126":{"position":[[2413,1]]},"1157":{"position":[[440,2]]},"1159":{"position":[[1774,2]]},"1195":{"position":[[242,2]]},"1203":{"position":[[214,2]]},"1221":{"position":[[104,1],[379,3]]},"1283":{"position":[[178,1]]},"1391":{"position":[[30,1]]},"1513":{"position":[[587,1]]},"1523":{"position":[[385,1]]},"1527":{"position":[[50,2]]},"1672":{"position":[[6,1]]}}}],["7.1x",{"_index":2291,"t":{"644":{"position":[[189,4]]}}}],["7.8",{"_index":4072,"t":{"1214":{"position":[[86,3]]}}}],["7/6/7",{"_index":4570,"t":{"1397":{"position":[[285,5]]}}}],["70",{"_index":2769,"t":{"786":{"position":[[2195,3]]},"866":{"position":[[533,5]]},"870":{"position":[[2030,3]]},"1496":{"position":[[435,5]]},"1782":{"position":[[1567,4]]}}}],["700",{"_index":926,"t":{"189":{"position":[[200,3]]}}}],["70b",{"_index":3438,"t":{"947":{"position":[[197,3]]}}}],["71",{"_index":5461,"t":{"1720":{"position":[[988,2],[1147,2]]},"1774":{"position":[[363,2]]},"1782":{"position":[[2561,4]]}}}],["71.3",{"_index":4224,"t":{"1279":{"position":[[225,6]]}}}],["71.8",{"_index":4620,"t":{"1423":{"position":[[1441,5]]}}}],["72",{"_index":3048,"t":{"821":{"position":[[354,3]]},"1770":{"position":[[158,3]]}}}],["72,144,288,576",{"_index":3047,"t":{"821":{"position":[[335,18],[372,18]]}}}],["72.8",{"_index":3589,"t":{"1002":{"position":[[395,4]]}}}],["73.2",{"_index":4614,"t":{"1423":{"position":[[505,4]]}}}],["73.5",{"_index":2234,"t":{"618":{"position":[[417,7]]}}}],["73.6",{"_index":4218,"t":{"1275":{"position":[[337,5]]}}}],["73.7",{"_index":4216,"t":{"1275":{"position":[[110,5]]},"1281":{"position":[[44,5]]}}}],["74",{"_index":5526,"t":{"1738":{"position":[[371,2]]}}}],["74.1",{"_index":4215,"t":{"1273":{"position":[[512,5]]}}}],["74.47",{"_index":4630,"t":{"1427":{"position":[[944,5]]}}}],["74.7",{"_index":4682,"t":{"1431":{"position":[[2594,5]]}}}],["75",{"_index":2248,"t":{"628":{"position":[[791,3]]},"1782":{"position":[[2826,4]]}}}],["75.2",{"_index":1980,"t":{"539":{"position":[[369,5]]},"561":{"position":[[172,5]]}}}],["75.8",{"_index":2233,"t":{"618":{"position":[[392,4]]}}}],["76",{"_index":5605,"t":{"1782":{"position":[[2778,4]]}}}],["76,800",{"_index":3711,"t":{"1070":{"position":[[1171,6]]}}}],["768",{"_index":1799,"t":{"517":{"position":[[814,4]]},"1070":{"position":[[1004,3]]}}}],["77",{"_index":5467,"t":{"1720":{"position":[[2021,2]]},"1762":{"position":[[364,3]]}}}],["77.5",{"_index":4685,"t":{"1431":{"position":[[2697,4]]}}}],["77.6k",{"_index":4090,"t":{"1227":{"position":[[1436,6]]}}}],["77.8",{"_index":4690,"t":{"1431":{"position":[[3040,4]]}}}],["77.8%±0.1%77.8",{"_index":2405,"t":{"672":{"position":[[751,16]]}}}],["770m",{"_index":1785,"t":{"517":{"position":[[56,4]]},"1070":{"position":[[1554,7]]},"1255":{"position":[[247,6]]},"1268":{"position":[[203,4]]},"1413":{"position":[[44,5]]}}}],["774m",{"_index":3714,"t":{"1070":{"position":[[1613,6]]},"1291":{"position":[[249,4]]}}}],["78",{"_index":5602,"t":{"1782":{"position":[[1954,3]]}}}],["78.31",{"_index":3404,"t":{"914":{"position":[[104,6]]}}}],["79",{"_index":2038,"t":{"569":{"position":[[655,3]]}}}],["79.6",{"_index":2372,"t":{"668":{"position":[[630,4]]}}}],["79.9",{"_index":574,"t":{"118":{"position":[[154,5]]}}}],["7b",{"_index":3282,"t":{"885":{"position":[[129,2]]},"887":{"position":[[651,2],[708,2]]},"905":{"position":[[201,2]]},"961":{"position":[[34,2]]},"963":{"position":[[368,2]]}}}],["8",{"_index":678,"t":{"147":{"position":[[216,3]]},"193":{"position":[[14,1]]},"285":{"position":[[491,2]]},"315":{"position":[[0,1]]},"322":{"position":[[136,1]]},"334":{"position":[[649,1],[664,1]]},"336":{"position":[[1974,1],[1988,1]]},"376":{"position":[[294,1]]},"382":{"position":[[274,3]]},"395":{"position":[[105,3],[181,2]]},"409":{"position":[[400,2]]},"424":{"position":[[264,1]]},"553":{"position":[[230,1]]},"555":{"position":[[180,2]]},"602":{"position":[[464,1]]},"612":{"position":[[109,1],[196,1]]},"630":{"position":[[1058,2]]},"633":{"position":[[12,2]]},"640":{"position":[[43,3]]},"644":{"position":[[160,1]]},"668":{"position":[[608,1]]},"670":{"position":[[458,2]]},"676":{"position":[[1301,1],[1346,2]]},"801":{"position":[[1197,1],[1309,1],[1469,1]]},"814":{"position":[[663,1]]},"821":{"position":[[195,2]]},"828":{"position":[[143,1]]},"870":{"position":[[2226,3]]},"885":{"position":[[206,3]]},"887":{"position":[[828,3]]},"905":{"position":[[104,2]]},"971":{"position":[[101,1]]},"997":{"position":[[352,2]]},"1080":{"position":[[7,1]]},"1111":{"position":[[49,3]]},"1134":{"position":[[452,3]]},"1181":{"position":[[33,3]]},"1321":{"position":[[425,3]]},"1379":{"position":[[1199,1]]},"1391":{"position":[[5,1]]},"1395":{"position":[[40,1],[1804,1],[2122,1],[2774,1]]},"1397":{"position":[[275,1],[426,1],[1342,1]]},"1499":{"position":[[103,1]]},"1523":{"position":[[5,1]]},"1669":{"position":[[714,2]]},"1672":{"position":[[120,3]]},"1674":{"position":[[590,1]]},"1676":{"position":[[6,1]]},"1782":{"position":[[445,3]]}}}],["8,16,32",{"_index":5353,"t":{"1669":{"position":[[702,11],[724,11]]}}}],["8,16,32,64}\\{8",{"_index":3025,"t":{"814":{"position":[[175,16]]}}}],["8,64,256}\\{8,64,256\\}{8,64,256",{"_index":2368,"t":{"668":{"position":[[304,32]]}}}],["8.5m",{"_index":3262,"t":{"870":{"position":[[1251,4]]}}}],["80",{"_index":1494,"t":{"368":{"position":[[22,2]]},"544":{"position":[[146,3]]},"866":{"position":[[701,3]]},"870":{"position":[[1325,3],[1388,3],[2113,3]]},"875":{"position":[[110,4]]},"879":{"position":[[484,3]]},"905":{"position":[[479,3]]},"1334":{"position":[[136,4]]},"1431":{"position":[[2768,3]]},"1440":{"position":[[655,3]]},"1496":{"position":[[441,5]]},"1738":{"position":[[538,2]]},"1768":{"position":[[230,3]]}}}],["80.0",{"_index":2369,"t":{"668":{"position":[[515,4]]}}}],["80.4",{"_index":2370,"t":{"668":{"position":[[543,4]]}}}],["80.7",{"_index":4631,"t":{"1427":{"position":[[953,4]]}}}],["80gb",{"_index":2230,"t":{"616":{"position":[[257,4]]}}}],["80k",{"_index":3449,"t":{"959":{"position":[[188,3]]},"963":{"position":[[304,3]]}}}],["80m",{"_index":2043,"t":{"577":{"position":[[48,3]]},"947":{"position":[[130,3]]}}}],["81",{"_index":5620,"t":{"1794":{"position":[[504,4]]}}}],["81≤i≤8",{"_index":2707,"t":{"774":{"position":[[255,7]]}}}],["82.8",{"_index":4613,"t":{"1423":{"position":[[498,4]]}}}],["83",{"_index":5589,"t":{"1782":{"position":[[1517,2]]}}}],["83.7%±0.1%83.7",{"_index":2409,"t":{"672":{"position":[[869,16]]}}}],["83.9",{"_index":2020,"t":{"561":{"position":[[267,5]]}}}],["84",{"_index":5534,"t":{"1750":{"position":[[239,2]]}}}],["84.4%±0.02%84.4",{"_index":2411,"t":{"672":{"position":[[948,17]]}}}],["84.5",{"_index":3259,"t":{"870":{"position":[[868,4]]}}}],["84.7",{"_index":3591,"t":{"1002":{"position":[[541,8]]}}}],["85.65",{"_index":3590,"t":{"1002":{"position":[[501,6]]}}}],["85.7",{"_index":2438,"t":{"676":{"position":[[1392,5]]},"870":{"position":[[914,4]]}}}],["85.8",{"_index":2437,"t":{"676":{"position":[[1384,5]]}}}],["85m",{"_index":3178,"t":{"857":{"position":[[365,3]]},"873":{"position":[[214,3],[328,3]]}}}],["86",{"_index":5359,"t":{"1672":{"position":[[219,2]]}}}],["86.2",{"_index":2436,"t":{"676":{"position":[[1377,6]]},"1002":{"position":[[582,7]]}}}],["87",{"_index":304,"t":{"53":{"position":[[379,2]]},"1738":{"position":[[405,2]]}}}],["87.36",{"_index":3041,"t":{"816":{"position":[[185,6]]}}}],["87.7",{"_index":182,"t":{"25":{"position":[[715,6]]}}}],["88",{"_index":5560,"t":{"1770":{"position":[[608,3]]}}}],["88.87",{"_index":3064,"t":{"833":{"position":[[322,6]]}}}],["88.89",{"_index":3066,"t":{"833":{"position":[[363,7]]}}}],["88.90",{"_index":4853,"t":{"1499":{"position":[[675,6]]}}}],["88×8",{"_index":781,"t":{"170":{"position":[[1243,5]]}}}],["89.2",{"_index":4618,"t":{"1423":{"position":[[1378,4]]}}}],["89.3",{"_index":4621,"t":{"1423":{"position":[[1504,6]]}}}],["89.9",{"_index":2427,"t":{"674":{"position":[[795,5]]}}}],["8\\%0.5−8",{"_index":2351,"t":{"662":{"position":[[1055,9]]}}}],["8\\}{1,2,4,8",{"_index":3046,"t":{"821":{"position":[[271,12]]}}}],["8\\}{2,4,8",{"_index":3028,"t":{"814":{"position":[[259,10]]}}}],["8b",{"_index":1555,"t":{"397":{"position":[[59,3],[79,4]]},"557":{"position":[[53,3],[389,3]]}}}],["8dmid​=8",{"_index":4549,"t":{"1393":{"position":[[1080,8]]}}}],["8h=8",{"_index":1234,"t":{"300":{"position":[[1247,4]]}}}],["8r=8",{"_index":2688,"t":{"770":{"position":[[96,4]]},"786":{"position":[[2098,5]]}}}],["8xa100",{"_index":1711,"t":{"479":{"position":[[45,6]]}}}],["8×88",{"_index":780,"t":{"170":{"position":[[1231,4]]}}}],["9",{"_index":687,"t":{"149":{"position":[[300,1]]},"339":{"position":[[284,1]]},"515":{"position":[[74,1]]},"529":{"position":[[529,1]]},"539":{"position":[[222,3]]},"546":{"position":[[78,1]]},"548":{"position":[[78,1]]},"561":{"position":[[21,1]]},"563":{"position":[[32,3]]},"594":{"position":[[1469,2]]},"598":{"position":[[3109,1]]},"971":{"position":[[205,1]]},"1323":{"position":[[217,2]]},"1431":{"position":[[2762,1]]},"1505":{"position":[[238,1]]},"1525":{"position":[[5,1]]},"1680":{"position":[[6,1]]},"1762":{"position":[[470,2]]},"1770":{"position":[[604,3]]},"1774":{"position":[[195,1]]}}}],["9.4",{"_index":2014,"t":{"557":{"position":[[179,4]]},"581":{"position":[[168,4]]}}}],["9.9",{"_index":2397,"t":{"670":{"position":[[1542,4]]}}}],["90",{"_index":1735,"t":{"494":{"position":[[185,3]]},"851":{"position":[[1048,3]]},"1425":{"position":[[648,3]]},"1431":{"position":[[2787,5]]},"1782":{"position":[[981,4],[1207,4]]}}}],["90%/10",{"_index":4420,"t":{"1357":{"position":[[162,7]]}}}],["90.4",{"_index":2425,"t":{"674":{"position":[[712,5]]}}}],["90.5",{"_index":4556,"t":{"1395":{"position":[[774,5]]}}}],["90.7",{"_index":2426,"t":{"674":{"position":[[735,5]]}}}],["90.87",{"_index":4852,"t":{"1499":{"position":[[666,6]]}}}],["900",{"_index":903,"t":{"182":{"position":[[269,3]]},"670":{"position":[[82,3]]}}}],["900m",{"_index":1413,"t":{"339":{"position":[[276,4]]}}}],["90\\%\\}{10%,20%,30%,40%,50%,60%,70%,80%,90",{"_index":4844,"t":{"1496":{"position":[[447,43]]}}}],["90m",{"_index":548,"t":{"112":{"position":[[270,3]]}}}],["91",{"_index":4707,"t":{"1440":{"position":[[615,3]]}}}],["91.2",{"_index":4617,"t":{"1423":{"position":[[1277,4]]}}}],["92.7",{"_index":4626,"t":{"1427":{"position":[[779,4]]}}}],["94.94",{"_index":4851,"t":{"1499":{"position":[[658,7]]}}}],["96",{"_index":2690,"t":{"770":{"position":[[212,3]]},"1746":{"position":[[370,2]]},"1762":{"position":[[317,3]]},"1798":{"position":[[58,2]]}}}],["97.0",{"_index":4627,"t":{"1427":{"position":[[787,5]]}}}],["97.1",{"_index":1931,"t":{"529":{"position":[[2519,4]]}}}],["97.11",{"_index":4849,"t":{"1499":{"position":[[641,7]]}}}],["97.2",{"_index":1929,"t":{"529":{"position":[[2476,5],[2488,4],[2507,5]]}}}],["97.4",{"_index":1930,"t":{"529":{"position":[[2482,5],[2513,5]]}}}],["98",{"_index":2209,"t":{"608":{"position":[[1028,2],[1090,2]]},"610":{"position":[[261,2]]},"614":{"position":[[221,2]]},"1750":{"position":[[65,3]]},"1792":{"position":[[177,5]]}}}],["98m",{"_index":3266,"t":{"870":{"position":[[2355,3]]}}}],["99",{"_index":5530,"t":{"1738":{"position":[[859,2]]},"1762":{"position":[[321,3]]}}}],["9:1",{"_index":716,"t":{"155":{"position":[[958,3]]}}}],["9m",{"_index":546,"t":{"112":{"position":[[261,3]]},"672":{"position":[[707,2]]}}}],["9th",{"_index":3270,"t":{"873":{"position":[[1537,3]]}}}],["9}ϵ=10−9",{"_index":1322,"t":{"317":{"position":[[108,8]]}}}],["9×9\\times9",{"_index":2373,"t":{"668":{"position":[[665,12]]}}}],["_",{"_index":5402,"t":{"1695":{"position":[[1002,2],[1072,2]]}}}],["_2",{"_index":5260,"t":{"1657":{"position":[[865,6]]}}}],["_3",{"_index":5261,"t":{"1657":{"position":[[872,6]]}}}],["_4",{"_index":5262,"t":{"1657":{"position":[[879,6]]}}}],["_5",{"_index":5263,"t":{"1657":{"position":[[901,6]]}}}],["_i",{"_index":2844,"t":{"795":{"position":[[459,2]]}}}],["_{1",{"_index":2845,"t":{"795":{"position":[[462,5]]},"797":{"position":[[2259,5]]}}}],["_{i=1",{"_index":2589,"t":{"723":{"position":[[233,8]]}}}],["_{k,i",{"_index":2954,"t":{"801":{"position":[[535,7]]}}}],["a.6",{"_index":4041,"t":{"1172":{"position":[[277,3]]},"1197":{"position":[[492,4]]}}}],["a1,…,at+1a_1",{"_index":3508,"t":{"988":{"position":[[228,13]]}}}],["a100",{"_index":1793,"t":{"517":{"position":[[412,4]]},"612":{"position":[[468,4]]},"616":{"position":[[262,4]]},"622":{"position":[[559,4]]},"885":{"position":[[210,4]]},"887":{"position":[[832,4]]},"905":{"position":[[107,4]]}}}],["a=(w⊙m)x\\text{a",{"_index":3111,"t":{"853":{"position":[[226,16]]}}}],["a=wx\\text{a",{"_index":3102,"t":{"853":{"position":[[0,12]]}}}],["a[0",{"_index":4879,"t":{"1538":{"position":[[75,4],[558,4],[611,4]]}}}],["a[1",{"_index":4880,"t":{"1538":{"position":[[82,4],[565,4],[618,4]]}}}],["a[2",{"_index":4896,"t":{"1538":{"position":[[431,4],[572,4],[643,4]]}}}],["a[3",{"_index":4900,"t":{"1538":{"position":[[579,4],[650,4]]}}}],["a[4",{"_index":4901,"t":{"1538":{"position":[[586,4],[657,4]]}}}],["a[5",{"_index":4897,"t":{"1538":{"position":[[438,4],[593,4],[664,4]]}}}],["a[i",{"_index":4881,"t":{"1538":{"position":[[96,3]]}}}],["a[i]s[i]=a[0]+a[1]+⋯a[i−1]+a[i",{"_index":4882,"t":{"1538":{"position":[[107,31]]}}}],["a[i]s[i]=s[i−1]+a[i",{"_index":4893,"t":{"1538":{"position":[[327,20]]}}}],["a^}j=1u",{"_index":1634,"t":{"451":{"position":[[17,10]]}}}],["a_j",{"_index":3540,"t":{"988":{"position":[[1661,3]]},"990":{"position":[[201,3]]}}}],["a_{i",{"_index":2827,"t":{"791":{"position":[[677,7]]}}}],["a_{r=64",{"_index":2714,"t":{"774":{"position":[[547,9]]}}}],["a_{r=8",{"_index":2713,"t":{"774":{"position":[[537,9]]}}}],["a_{t+1}a1​,…,at+1",{"_index":3509,"t":{"988":{"position":[[249,18]]}}}],["aaa",{"_index":2572,"t":{"719":{"position":[[901,3]]},"733":{"position":[[591,3],[861,3]]},"786":{"position":[[1992,4]]},"791":{"position":[[476,3],[591,3]]},"795":{"position":[[1826,3]]},"839":{"position":[[215,3]]},"1067":{"position":[[672,3],[1432,3]]},"1651":{"position":[[591,3],[665,3],[1006,3]]}}}],["abil",{"_index":5469,"t":{"1720":{"position":[[2307,7]]}}}],["ablat",{"_index":1126,"t":{"265":{"position":[[15,8]]},"267":{"position":[[17,8]]},"401":{"position":[[51,8]]},"461":{"position":[[98,8]]},"466":{"position":[[333,8]]},"620":{"position":[[44,8]]},"676":{"position":[[26,8]]},"681":{"position":[[1749,8]]},"709":{"position":[[635,8]]},"801":{"position":[[2660,8]]},"979":{"position":[[1698,8]]},"1006":{"position":[[457,8],[1317,8]]},"1126":{"position":[[2534,8]]},"1141":{"position":[[77,8]]},"1208":{"position":[[114,8]]},"1255":{"position":[[202,8]]},"1423":{"position":[[256,8]]},"1440":{"position":[[736,8]]},"1503":{"position":[[39,8]]}}}],["abov",{"_index":91,"t":{"15":{"position":[[25,6]]}}}],["absolut",{"_index":3084,"t":{"849":{"position":[[477,8],[645,8]]},"851":{"position":[[496,8]]},"853":{"position":[[434,8],[1177,8],[1751,8]]},"855":{"position":[[811,8]]},"1622":{"position":[[51,8]]}}}],["abstract",{"_index":1154,"t":{"287":{"position":[[454,11]]}}}],["acc",{"_index":2548,"t":{"707":{"position":[[123,3]]},"1672":{"position":[[355,6]]}}}],["acceler",{"_index":209,"t":{"33":{"position":[[89,11]]},"38":{"position":[[0,11]]}}}],["accept",{"_index":4537,"t":{"1393":{"position":[[23,13]]}}}],["access",{"_index":1823,"t":{"525":{"position":[[577,6]]},"527":{"position":[[246,6]]},"648":{"position":[[907,6]]},"1636":{"position":[[90,10]]}}}],["accord",{"_index":1676,"t":{"459":{"position":[[168,9]]}}}],["accumul",{"_index":2229,"t":{"616":{"position":[[186,11]]},"721":{"position":[[275,11]]}}}],["accuraci",{"_index":195,"t":{"27":{"position":[[278,8]]},"38":{"position":[[323,8]]},"78":{"position":[[692,8]]},"191":{"position":[[103,8]]},"193":{"position":[[114,8]]},"199":{"position":[[133,8]]},"319":{"position":[[378,8]]},"529":{"position":[[2148,8]]},"587":{"position":[[433,8]]},"594":{"position":[[1488,8]]},"633":{"position":[[75,8]]},"672":{"position":[[799,8],[917,8]]},"849":{"position":[[379,8]]},"870":{"position":[[873,8]]},"1002":{"position":[[518,8]]},"1341":{"position":[[1169,8]]},"1409":{"position":[[906,8]]},"1423":{"position":[[244,8]]},"1672":{"position":[[346,8]]},"1680":{"position":[[314,8]]}}}],["accuray",{"_index":2092,"t":{"594":{"position":[[1358,7]]},"881":{"position":[[416,7]]}}}],["act",{"_index":4733,"t":{"1447":{"position":[[260,3]]},"1802":{"position":[[481,7],[650,7]]}}}],["action",{"_index":1415,"t":{"339":{"position":[[596,6]]},"343":{"position":[[263,6]]},"453":{"position":[[162,6]]},"1442":{"position":[[98,8],[1284,6],[1410,6],[1585,6]]},"1445":{"position":[[45,6]]},"1447":{"position":[[29,6],[151,6],[331,6]]},"1451":{"position":[[469,6],[542,6],[725,6]]},"1453":{"position":[[395,6]]},"1462":{"position":[[78,6]]},"1626":{"position":[[143,6],[221,6]]}}}],["activ",{"_index":384,"t":{"86":{"position":[[688,10]]},"304":{"position":[[159,10]]},"587":{"position":[[502,11]]},"589":{"position":[[1980,11]]},"598":{"position":[[400,11],[486,10],[558,10],[716,11],[976,11],[1150,10],[1349,10],[2433,12],[2483,11],[3569,11]]},"616":{"position":[[140,11]]},"622":{"position":[[187,11]]},"630":{"position":[[953,11]]},"660":{"position":[[1027,10]]},"676":{"position":[[1553,10]]},"753":{"position":[[77,10],[111,10],[131,10]]},"789":{"position":[[835,10]]},"1101":{"position":[[578,9]]},"1126":{"position":[[1307,11]]},"1145":{"position":[[368,10]]},"1296":{"position":[[327,10],[480,10],[559,10],[643,11]]},"1298":{"position":[[234,10]]},"1303":{"position":[[806,10],[974,10]]},"1305":{"position":[[417,10],[1266,10],[1307,10]]},"1328":{"position":[[111,10]]},"1330":{"position":[[23,11],[62,10],[148,10],[354,10],[401,10]]},"1332":{"position":[[133,10],[449,10]]},"1341":{"position":[[399,10],[531,10],[611,10]]},"1347":{"position":[[1464,10],[1999,8]]},"1369":{"position":[[103,8]]},"1379":{"position":[[821,10]]},"1384":{"position":[[885,10],[3904,10]]},"1389":{"position":[[1397,10]]},"1653":{"position":[[350,12]]}}}],["actor",{"_index":4724,"t":{"1445":{"position":[[24,5],[174,5]]},"1447":{"position":[[0,5]]},"1449":{"position":[[44,5]]},"1453":{"position":[[75,5]]},"1455":{"position":[[16,5],[462,6]]}}}],["actual",{"_index":5470,"t":{"1720":{"position":[[2414,6]]}}}],["ad",{"_index":43,"t":{"7":{"position":[[151,5]]},"17":{"position":[[102,5]]},"940":{"position":[[265,5]]},"945":{"position":[[891,5]]},"949":{"position":[[554,5]]},"1084":{"position":[[508,5]]}}}],["adafactor",{"_index":1996,"t":{"550":{"position":[[171,9]]},"602":{"position":[[444,9]]},"616":{"position":[[165,9]]},"705":{"position":[[350,9]]},"1134":{"position":[[794,9]]},"1136":{"position":[[85,9]]},"1496":{"position":[[618,9]]}}}],["adalora",{"_index":2743,"t":{"784":{"position":[[449,7],[539,7],[875,7],[895,7]]},"786":{"position":[[3265,7],[3388,7],[4381,7],[4568,7]]},"795":{"position":[[1742,7]]},"803":{"position":[[674,7]]},"805":{"position":[[0,7]]},"809":{"position":[[0,7]]},"814":{"position":[[59,7],[278,7],[372,7]]},"816":{"position":[[22,7],[99,7],[168,7],[222,7]]},"819":{"position":[[46,7]]},"821":{"position":[[35,7],[290,7]]},"823":{"position":[[113,7]]},"826":{"position":[[31,7]]},"830":{"position":[[159,7]]},"833":{"position":[[117,7],[301,7]]},"835":{"position":[[228,7],[279,7]]},"837":{"position":[[0,7]]},"839":{"position":[[294,7],[454,7],[508,7]]},"841":{"position":[[9,7],[88,7],[290,7],[342,7]]},"843":{"position":[[43,7]]}}}],["adaloraγ=0_{\\gamma",{"_index":3073,"t":{"839":{"position":[[264,18]]}}}],["adam",{"_index":522,"t":{"106":{"position":[[27,4]]},"317":{"position":[[0,4]]},"666":{"position":[[275,4],[283,4]]},"717":{"position":[[220,4]]},"733":{"position":[[1027,4]]},"741":{"position":[[48,4]]},"1107":{"position":[[1075,4]]}}}],["adamix",{"_index":4434,"t":{"1364":{"position":[[205,6]]},"1369":{"position":[[438,6],[618,6]]}}}],["adamw",{"_index":904,"t":{"182":{"position":[[284,6]]},"244":{"position":[[10,5]]},"517":{"position":[[1014,5]]},"821":{"position":[[411,5]]},"1111":{"position":[[1233,5]]},"1314":{"position":[[137,5]]}}}],["adaprompt",{"_index":5345,"t":{"1665":{"position":[[887,9]]},"1669":{"position":[[1079,9]]}}}],["adapt",{"_index":155,"t":{"23":{"position":[[204,10]]},"47":{"position":[[440,10]]},"74":{"position":[[11,8]]},"76":{"position":[[71,10]]},"78":{"position":[[434,10]]},"334":{"position":[[188,7],[202,7],[675,7]]},"336":{"position":[[432,7],[446,7],[624,7],[737,7],[1999,7]]},"341":{"position":[[229,7],[244,7],[358,7],[406,7]]},"376":{"position":[[124,8],[315,7]]},"378":{"position":[[108,7],[122,7]]},"525":{"position":[[986,10],[1008,7],[1093,9],[1423,7],[1565,7]]},"529":{"position":[[300,8],[347,7],[411,7],[631,7]]},"531":{"position":[[1517,10]]},"567":{"position":[[413,7]]},"587":{"position":[[271,7]]},"592":{"position":[[75,8]]},"598":{"position":[[822,10],[2390,7],[3085,10],[3167,8],[3337,7]]},"602":{"position":[[61,10]]},"614":{"position":[[328,10]]},"618":{"position":[[309,8]]},"626":{"position":[[69,7],[362,10]]},"628":{"position":[[144,7],[1552,10]]},"630":{"position":[[251,8],[662,8],[1938,9]]},"633":{"position":[[515,5],[642,7],[967,7],[991,7],[1032,5]]},"635":{"position":[[40,5],[122,5]]},"648":{"position":[[270,7],[941,8]]},"650":{"position":[[159,8]]},"656":{"position":[[151,7],[319,7]]},"658":{"position":[[707,7],[1314,7],[1422,7],[1507,7],[1557,7],[1948,7],[2449,7],[2585,7],[2715,7],[2860,7],[2959,7],[3162,7]]},"660":{"position":[[256,7],[359,7],[447,7],[536,7],[628,7],[697,7],[740,7],[878,7],[919,7],[1004,7],[1070,7],[1110,7]]},"662":{"position":[[17,7],[122,7],[272,7],[564,7],[575,7],[678,7],[776,7],[1141,7],[1304,7],[1572,10]]},"664":{"position":[[4,7],[215,7]]},"668":{"position":[[274,7],[359,7],[383,7],[491,7],[556,7],[678,7]]},"670":{"position":[[0,7],[394,7],[421,7],[1210,7],[1335,7],[1550,7]]},"672":{"position":[[0,7],[48,7],[125,7],[465,7],[824,7],[1240,7],[1403,7]]},"674":{"position":[[7,7],[121,7],[407,7],[612,7],[676,7],[758,7]]},"676":{"position":[[4,7],[58,8],[135,7],[211,7],[248,7],[311,7],[352,7],[408,7],[530,7],[563,7],[598,7],[917,7],[1078,7],[1168,7],[1226,7],[1265,7],[1437,7],[1481,7],[1520,7],[1594,7],[1622,7],[1741,7]]},"679":{"position":[[211,8],[329,8]]},"681":{"position":[[266,8],[559,8],[1261,8],[1678,8]]},"683":{"position":[[777,7]]},"696":{"position":[[1718,10]]},"713":{"position":[[304,12]]},"717":{"position":[[59,11],[373,7],[435,10]]},"719":{"position":[[56,10],[134,8],[442,10],[516,10],[583,10],[981,8]]},"721":{"position":[[261,10]]},"725":{"position":[[22,7]]},"727":{"position":[[3,7],[104,7],[219,7],[293,7],[321,7],[474,7]]},"729":{"position":[[101,10]]},"733":{"position":[[112,8]]},"739":{"position":[[202,8]]},"741":{"position":[[242,8]]},"755":{"position":[[41,7],[58,7],[180,7],[287,7],[366,7],[694,7]]},"759":{"position":[[190,7]]},"768":{"position":[[142,10]]},"770":{"position":[[77,8],[166,8],[346,8]]},"780":{"position":[[168,10],[237,8]]},"784":{"position":[[519,10]]},"786":{"position":[[545,7],[577,8],[1178,10],[3210,10],[3273,9],[3292,11]]},"791":{"position":[[921,7]]},"793":{"position":[[31,11]]},"797":{"position":[[14,10],[344,7]]},"803":{"position":[[18,10]]},"809":{"position":[[40,10],[261,7],[311,8],[336,7],[357,7],[435,7],[463,7],[557,7],[779,7]]},"814":{"position":[[151,7]]},"821":{"position":[[148,7]]},"823":{"position":[[197,7],[216,7]]},"828":{"position":[[46,10]]},"839":{"position":[[29,10],[42,8],[151,10],[406,10]]},"843":{"position":[[97,10]]},"847":{"position":[[574,8]]},"849":{"position":[[526,8],[1148,8]]},"885":{"position":[[6,7],[81,10],[160,7],[267,10],[411,10],[476,7]]},"887":{"position":[[194,7],[393,10],[455,10],[587,7],[685,10],[807,10],[904,7],[1067,10]]},"891":{"position":[[140,10],[684,10]]},"893":{"position":[[0,10],[1256,10],[1533,10],[1956,10],[2461,10]]},"895":{"position":[[28,7],[661,10],[805,10],[1088,10]]},"897":{"position":[[33,10]]},"899":{"position":[[52,10]]},"905":{"position":[[94,7],[302,10]]},"907":{"position":[[15,7],[124,7]]},"909":{"position":[[83,7]]},"912":{"position":[[200,7]]},"914":{"position":[[6,7],[247,7]]},"919":{"position":[[29,7]]},"921":{"position":[[113,7],[225,7]]},"928":{"position":[[6,7]]},"932":{"position":[[9,7],[181,7],[201,7],[269,7],[694,7],[810,7],[831,7]]},"934":{"position":[[181,7],[195,7],[518,7],[549,7],[569,7],[624,10],[786,7],[937,10],[967,7],[1088,10],[1285,7],[1344,10],[1374,7],[1789,7],[2105,7],[2304,7]]},"938":{"position":[[70,7],[108,7],[128,7],[233,8],[306,10]]},"940":{"position":[[284,7]]},"942":{"position":[[6,7],[45,7],[124,10],[205,7]]},"945":{"position":[[6,7],[46,10],[156,10],[302,10],[518,7],[944,7]]},"949":{"position":[[14,7],[111,7],[498,10],[596,11]]},"951":{"position":[[363,7]]},"953":{"position":[[62,10],[123,7],[264,10],[291,7],[328,10],[404,10],[431,7]]},"955":{"position":[[83,7],[643,7]]},"959":{"position":[[6,7]]},"961":{"position":[[55,10]]},"963":{"position":[[56,7],[131,7],[534,7]]},"965":{"position":[[6,7],[92,7],[210,7]]},"967":{"position":[[6,7],[20,10],[172,7],[369,7],[490,7],[506,7]]},"971":{"position":[[133,7]]},"973":{"position":[[68,7]]},"979":{"position":[[1578,11]]},"992":{"position":[[1095,7]]},"994":{"position":[[509,7],[653,7]]},"999":{"position":[[175,8],[306,7]]},"1002":{"position":[[228,7],[574,7]]},"1004":{"position":[[185,8],[402,10]]},"1006":{"position":[[105,8],[439,7],[594,10]]},"1012":{"position":[[491,7]]},"1062":{"position":[[1814,9]]},"1070":{"position":[[438,8],[617,8]]},"1073":{"position":[[63,8]]},"1084":{"position":[[499,8]]},"1126":{"position":[[162,10],[207,10],[706,10],[1457,8]]},"1132":{"position":[[1437,10],[1581,10],[1676,10],[1865,10]]},"1134":{"position":[[181,7]]},"1143":{"position":[[293,10],[373,10],[405,8],[445,10],[662,8],[1090,10]]},"1145":{"position":[[1850,8],[2069,10],[2094,7],[2322,7],[2437,7]]},"1149":{"position":[[232,10]]},"1153":{"position":[[58,8]]},"1162":{"position":[[25,8]]},"1167":{"position":[[747,7],[969,7]]},"1197":{"position":[[377,7]]},"1225":{"position":[[48,5],[143,5],[440,5]]},"1230":{"position":[[0,7],[844,10]]},"1232":{"position":[[318,8]]},"1236":{"position":[[297,5]]},"1240":{"position":[[307,10],[408,5]]},"1246":{"position":[[530,10]]},"1253":{"position":[[352,8]]},"1257":{"position":[[89,10],[294,8]]},"1259":{"position":[[218,10]]},"1262":{"position":[[177,8]]},"1268":{"position":[[103,8]]},"1270":{"position":[[103,5]]},"1279":{"position":[[242,10]]},"1283":{"position":[[215,10]]},"1285":{"position":[[316,5]]},"1291":{"position":[[419,7],[504,7]]},"1312":{"position":[[127,7],[142,9]]},"1317":{"position":[[116,8],[213,7],[282,7],[348,7],[439,7]]},"1323":{"position":[[577,7]]},"1339":{"position":[[244,7],[295,7]]},"1341":{"position":[[68,7],[218,7],[334,7],[557,7],[669,7],[776,7]]},"1369":{"position":[[516,7],[583,7]]},"1379":{"position":[[988,7]]},"1384":{"position":[[68,8],[98,8],[983,7],[1008,7],[3867,7]]},"1389":{"position":[[234,7],[958,8],[1155,7],[1191,7],[1241,7],[1366,7],[1610,7]]},"1393":{"position":[[158,7],[992,7]]},"1395":{"position":[[183,8],[192,7],[692,7],[721,7],[755,7],[801,7],[888,7],[957,7],[1029,7],[1158,7],[1216,7],[1309,7],[1697,7],[2056,7],[2716,7]]},"1409":{"position":[[524,8]]},"1423":{"position":[[1401,10]]},"1468":{"position":[[349,9]]},"1494":{"position":[[246,8]]},"1499":{"position":[[912,8]]},"1646":{"position":[[616,10]]},"1665":{"position":[[912,8]]},"1682":{"position":[[664,8]]},"1768":{"position":[[351,8]]},"1778":{"position":[[69,10]]}}}],["adapter/prefix",{"_index":2774,"t":{"786":{"position":[[3111,14]]}}}],["adapterd\\text{adapter}^dadapterd",{"_index":2672,"t":{"755":{"position":[[386,32]]}}}],["adapterdrop",{"_index":3583,"t":{"999":{"position":[[184,11]]},"1070":{"position":[[626,11]]},"1189":{"position":[[275,11]]}}}],["adapterfus",{"_index":3586,"t":{"999":{"position":[[345,13]]}}}],["adapterh\\text{adapter}^hadapterh",{"_index":2669,"t":{"755":{"position":[[140,32]]}}}],["adapterl\\text{adapter}^ladapterl",{"_index":2670,"t":{"755":{"position":[[240,32]]}}}],["adapterp\\text{adapter}^padapterp",{"_index":2671,"t":{"755":{"position":[[311,32]]}}}],["adaptert_tt",{"_index":3403,"t":{"914":{"position":[[70,12]]}}}],["adaptor",{"_index":1066,"t":{"234":{"position":[[102,7],[131,7],[364,7],[384,7]]},"265":{"position":[[0,7],[102,7],[155,7],[231,7]]}}}],["adatp",{"_index":1400,"t":{"336":{"position":[[673,7]]},"967":{"position":[[552,7],[578,7]]}}}],["add",{"_index":36,"t":{"7":{"position":[[68,3]]},"78":{"position":[[626,3]]},"1583":{"position":[[89,3],[134,3],[165,3]]},"1595":{"position":[[65,3]]},"1606":{"position":[[40,3]]},"1610":{"position":[[0,3]]},"1632":{"position":[[31,3]]},"1638":{"position":[[41,3]]}}}],["addit",{"_index":1198,"t":{"298":{"position":[[587,8],[741,8],[1055,8]]},"527":{"position":[[2847,8]]},"594":{"position":[[336,10]]},"596":{"position":[[59,10],[1632,10],[2522,10]]},"598":{"position":[[2946,10]]},"622":{"position":[[236,10]]},"648":{"position":[[418,10]]},"658":{"position":[[493,10]]},"672":{"position":[[388,10],[1084,8]]},"786":{"position":[[682,10],[2104,10],[4233,10]]},"934":{"position":[[2017,10]]},"955":{"position":[[335,10]]},"1075":{"position":[[45,10]]},"1091":{"position":[[226,10]]},"1126":{"position":[[1563,10]]},"1145":{"position":[[300,10]]},"1164":{"position":[[210,10]]},"1172":{"position":[[97,10]]},"1291":{"position":[[464,10],[1518,10]]},"1373":{"position":[[44,10]]},"1382":{"position":[[38,10]]},"1384":{"position":[[2592,8],[2610,8]]},"1409":{"position":[[418,10]]},"1442":{"position":[[424,10]]},"1477":{"position":[[76,10]]},"1616":{"position":[[39,10]]},"1782":{"position":[[2061,10]]}}}],["adel",{"_index":984,"t":{"215":{"position":[[470,4]]}}}],["adipisc",{"_index":19,"t":{"3":{"position":[[160,10],[339,10],[518,10],[697,10],[876,10],[1055,10],[1234,10],[1413,10],[1592,10],[1771,10],[1950,10],[2129,10],[2308,10],[2487,10],[2666,10],[2845,10]]},"5":{"position":[[40,10]]}}}],["adjust",{"_index":156,"t":{"23":{"position":[[215,6]]},"47":{"position":[[451,6]]},"76":{"position":[[82,6]]},"78":{"position":[[445,6]]},"592":{"position":[[360,11]]},"1367":{"position":[[471,9]]}}}],["admonit",{"_index":5112,"t":{"1626":{"position":[[42,11]]}}}],["advantag",{"_index":5536,"t":{"1750":{"position":[[321,10]]},"1752":{"position":[[254,10]]},"1754":{"position":[[189,10]]},"1756":{"position":[[409,10]]},"1758":{"position":[[186,10]]}}}],["adversari",{"_index":3866,"t":{"1120":{"position":[[109,11]]},"1283":{"position":[[129,11]]}}}],["agent",{"_index":4696,"t":{"1440":{"position":[[22,6],[140,5],[241,5],[562,5],[715,5]]},"1442":{"position":[[31,5],[217,5],[251,5],[413,5],[630,5],[1960,5]]},"1447":{"position":[[390,5]]},"1451":{"position":[[353,5],[413,5],[531,5],[662,5],[809,5]]},"1453":{"position":[[380,5]]}}}],["aggreg",{"_index":5267,"t":{"1657":{"position":[[1088,11],[1109,10],[1868,10]]}}}],["agnost",{"_index":1602,"t":{"434":{"position":[[382,8]]},"447":{"position":[[863,8]]},"713":{"position":[[217,8]]},"1782":{"position":[[366,8]]}}}],["agost",{"_index":3556,"t":{"992":{"position":[[504,7]]}}}],["agument",{"_index":1770,"t":{"508":{"position":[[212,9]]}}}],["ai",{"_index":4977,"t":{"1577":{"position":[[99,3],[113,2]]}}}],["ai+1a_{i+1}ai+1",{"_index":4745,"t":{"1451":{"position":[[476,16],[495,16]]}}}],["ai+1′a'_{i+1}ai+1",{"_index":4747,"t":{"1451":{"position":[[575,19]]}}}],["ai+2′a'_{i+2}ai+2",{"_index":4748,"t":{"1451":{"position":[[597,19]]}}}],["aia_iai",{"_index":4744,"t":{"1451":{"position":[[450,8]]}}}],["aim",{"_index":161,"t":{"25":{"position":[[117,3]]},"27":{"position":[[20,3]]}}}],["ainsli",{"_index":2451,"t":{"683":{"position":[[53,7]]}}}],["aip",{"_index":4921,"t":{"1552":{"position":[[20,3]]}}}],["ai′a'_iai",{"_index":4746,"t":{"1451":{"position":[[549,11],[732,11]]}}}],["ai∗a_{i*}ai",{"_index":2824,"t":{"791":{"position":[[575,13]]}}}],["aj=1/ta_j",{"_index":3603,"t":{"1006":{"position":[[727,9]]}}}],["aj=ep^jhout/t∑k=1t+1ep^khout/t\\begin{equ",{"_index":3539,"t":{"988":{"position":[[1614,46]]}}}],["al",{"_index":975,"t":{"215":{"position":[[278,2],[377,2],[1775,4],[1794,4],[1820,4],[2169,4],[2291,4],[2329,4],[2492,4]]},"498":{"position":[[145,3]]},"504":{"position":[[192,4],[316,4]]},"517":{"position":[[1102,4]]},"525":{"position":[[1028,3],[1169,3]]},"529":{"position":[[48,3],[65,3],[1531,3],[2682,3]]},"531":{"position":[[314,4],[335,4],[355,4],[436,4],[454,4],[478,4],[499,2],[733,3],[755,3],[989,2],[1090,3],[1351,3],[1452,3]]},"598":{"position":[[1510,3]]},"630":{"position":[[820,4]]},"648":{"position":[[748,3],[880,3]]},"658":{"position":[[740,3],[858,3],[886,3]]},"662":{"position":[[1431,3],[1457,3],[1494,3]]},"666":{"position":[[96,2],[250,2]]},"670":{"position":[[884,2]]},"681":{"position":[[420,3],[540,3],[580,3],[755,3],[791,3],[810,3]]},"683":{"position":[[42,4],[80,4],[148,3],[176,3],[295,3],[320,3],[352,3],[1106,3],[1132,3]]},"707":{"position":[[741,3],[757,3]]},"849":{"position":[[426,3],[624,3],[1634,3]]},"851":{"position":[[68,4],[92,4],[110,4],[154,4],[173,4],[197,4],[215,4],[249,4],[267,4],[309,4],[472,3],[633,3],[774,3],[823,3],[1160,3]]},"853":{"position":[[424,3],[1231,3],[2347,3]]},"861":{"position":[[999,3]]},"868":{"position":[[30,3],[75,3],[112,3],[135,3],[201,3]]},"873":{"position":[[886,3]]},"988":{"position":[[657,3]]},"1002":{"position":[[666,3],[691,3],[718,3]]},"1004":{"position":[[75,3]]},"1006":{"position":[[190,3]]},"1008":{"position":[[424,3]]},"1084":{"position":[[263,4],[282,4],[301,4]]},"1347":{"position":[[368,3],[419,3],[435,3],[486,3],[588,3],[1272,3],[1291,3]]},"1354":{"position":[[28,3],[48,3]]},"1357":{"position":[[98,2]]},"1362":{"position":[[161,3],[197,3],[379,3]]},"1364":{"position":[[245,3],[263,3]]},"1367":{"position":[[189,3],[373,3],[445,3],[461,3],[512,3],[528,3],[603,3],[621,3],[639,3]]},"1369":{"position":[[271,2],[360,2],[426,2],[536,3]]},"1379":{"position":[[1008,3],[1065,3],[1096,3]]},"1384":{"position":[[2472,3]]},"1395":{"position":[[326,3],[650,3],[737,3]]},"1399":{"position":[[370,3],[392,3]]},"1401":{"position":[[558,3],[579,3]]},"1407":{"position":[[99,3]]},"1409":{"position":[[157,3],[468,3]]},"1415":{"position":[[48,3],[216,3],[236,3]]},"1419":{"position":[[238,3],[933,3]]},"1421":{"position":[[14,3],[373,3],[444,3]]},"1423":{"position":[[991,3]]},"1431":{"position":[[1213,3]]},"1468":{"position":[[195,3]]},"1473":{"position":[[235,3],[374,3],[505,3]]},"1475":{"position":[[287,3],[341,3]]},"1481":{"position":[[144,3]]},"1492":{"position":[[108,3],[126,2]]},"1494":{"position":[[50,3],[72,3],[178,3],[294,3]]},"1496":{"position":[[208,3],[226,3]]},"1511":{"position":[[312,3]]},"1665":{"position":[[875,2]]},"1669":{"position":[[478,3]]},"1682":{"position":[[46,4]]}}}],["albat",{"_index":4069,"t":{"1210":{"position":[[54,8]]}}}],["albert",{"_index":3758,"t":{"1093":{"position":[[1421,6]]},"1111":{"position":[[1830,6]]}}}],["alert('button",{"_index":73,"t":{"9":{"position":[[146,13]]}}}],["alert(`y",{"_index":5130,"t":{"1628":{"position":[[286,10]]}}}],["alfworld",{"_index":4719,"t":{"1442":{"position":[[1782,8]]}}}],["algebra",{"_index":1543,"t":{"391":{"position":[[100,9],[132,9]]},"428":{"position":[[151,9]]}}}],["algo",{"_index":2021,"t":{"561":{"position":[[358,4]]}}}],["algorithm",{"_index":367,"t":{"78":{"position":[[958,9]]},"138":{"position":[[222,9]]},"670":{"position":[[926,9]]},"807":{"position":[[393,9]]},"1126":{"position":[[1121,9]]},"1409":{"position":[[1523,9]]},"1425":{"position":[[563,9]]},"1589":{"position":[[19,9]]}}}],["align",{"_index":1159,"t":{"287":{"position":[[598,7],[758,7]]},"336":{"position":[[124,5]]},"339":{"position":[[99,5],[483,5]]},"436":{"position":[[650,5]]},"443":{"position":[[33,9],[87,5],[419,5]]},"485":{"position":[[1150,9]]},"500":{"position":[[118,9],[674,9]]},"628":{"position":[[1174,5]]},"630":{"position":[[477,5],[604,9]]},"932":{"position":[[540,9]]},"934":{"position":[[1050,9],[1177,9],[1510,9],[2361,9]]},"940":{"position":[[197,9]]},"967":{"position":[[715,9]]},"1070":{"position":[[1492,5]]},"1449":{"position":[[305,5]]},"1546":{"position":[[148,8],[175,8]]},"1560":{"position":[[0,7],[33,9],[70,9],[200,7]]},"1570":{"position":[[81,9],[114,9],[145,5],[210,5],[238,5]]},"1573":{"position":[[137,7]]}}}],["alik",{"_index":2775,"t":{"786":{"position":[[3312,5]]}}}],["aliquam",{"_index":29,"t":{"3":{"position":[[253,7],[432,7],[611,7],[790,7],[969,7],[1148,7],[1327,7],[1506,7],[1685,7],[1864,7],[2043,7],[2222,7],[2401,7],[2580,7],[2759,7],[2938,7]]},"5":{"position":[[133,7]]}}}],["allic",{"_index":3068,"t":{"835":{"position":[[57,10]]}}}],["alloc",{"_index":2744,"t":{"784":{"position":[[530,8]]},"793":{"position":[[124,11]]},"795":{"position":[[1993,10]]},"803":{"position":[[182,10]]},"839":{"position":[[58,10]]},"843":{"position":[[108,8],[319,8]]}}}],["allow",{"_index":5117,"t":{"1628":{"position":[[53,6]]}}}],["alpaca",{"_index":3287,"t":{"887":{"position":[[72,6],[711,6],[853,6]]},"905":{"position":[[9,6]]},"907":{"position":[[25,6],[46,6]]},"928":{"position":[[43,6]]},"934":{"position":[[60,6]]}}}],["alpha",{"_index":2641,"t":{"733":{"position":[[1004,8],[1042,8]]},"807":{"position":[[132,9],[168,8],[288,8],[368,8]]},"1384":{"position":[[3665,6],[3762,8]]},"1389":{"position":[[2094,8],[2164,8]]},"1395":{"position":[[2868,8],[2889,8],[3001,8],[3047,8]]}}}],["alpha_",{"_index":3140,"t":{"853":{"position":[[1504,8]]},"855":{"position":[[240,8]]}}}],["alpha_w",{"_index":3127,"t":{"853":{"position":[[786,8]]}}}],["alpha_wl및αw",{"_index":3135,"t":{"853":{"position":[[1091,13]]}}}],["altern",{"_index":2063,"t":{"589":{"position":[[486,11]]}}}],["altogeth",{"_index":3977,"t":{"1151":{"position":[[811,10],[876,10],[937,10]]}}}],["amaz",{"_index":3610,"t":{"1014":{"position":[[454,8]]},"1019":{"position":[[221,8]]},"1802":{"position":[[732,8]]}}}],["amet",{"_index":17,"t":{"3":{"position":[[142,5],[294,4],[321,5],[473,4],[500,5],[652,4],[679,5],[831,4],[858,5],[1010,4],[1037,5],[1189,4],[1216,5],[1368,4],[1395,5],[1547,4],[1574,5],[1726,4],[1753,5],[1905,4],[1932,5],[2084,4],[2111,5],[2263,4],[2290,5],[2442,4],[2469,5],[2621,4],[2648,5],[2800,4],[2827,5],[2979,4]]},"5":{"position":[[22,5],[174,4]]}}}],["ami",{"_index":1577,"t":{"422":{"position":[[45,4]]}}}],["amp",{"_index":1102,"t":{"244":{"position":[[294,5],[321,3]]}}}],["amplifi",{"_index":2180,"t":{"598":{"position":[[2416,10]]}}}],["anabi",{"_index":1004,"t":{"215":{"position":[[1805,5],[2150,9]]}}}],["analog",{"_index":5546,"t":{"1762":{"position":[[460,9]]}}}],["analysi",{"_index":3569,"t":{"997":{"position":[[96,9]]},"1006":{"position":[[2068,8]]},"1014":{"position":[[426,8]]},"1393":{"position":[[55,8]]},"1395":{"position":[[171,8],[1337,8],[2380,8]]},"1419":{"position":[[725,9]]},"1429":{"position":[[1460,8]]},"1698":{"position":[[338,8]]},"1702":{"position":[[290,8]]},"1788":{"position":[[148,8]]}}}],["anchor",{"_index":3825,"t":{"1101":{"position":[[1167,6],[1322,6],[1366,6]]},"1107":{"position":[[1018,6]]},"1720":{"position":[[2185,6]]}}}],["anger",{"_index":5478,"t":{"1728":{"position":[[441,9]]}}}],["angin",{"_index":5640,"t":{"1802":{"position":[[1232,11]]}}}],["anli",{"_index":2079,"t":{"594":{"position":[[837,6]]}}}],["annot",{"_index":638,"t":{"138":{"position":[[21,10]]},"143":{"position":[[127,11]]},"149":{"position":[[92,10]]},"163":{"position":[[162,11]]},"165":{"position":[[663,11],[1553,11]]},"168":{"position":[[286,10]]},"170":{"position":[[502,10],[569,11]]},"174":{"position":[[1863,10]]},"177":{"position":[[151,11],[627,11]]},"179":{"position":[[178,10]]},"203":{"position":[[249,10]]},"336":{"position":[[755,9]]},"341":{"position":[[522,10]]},"345":{"position":[[95,10]]},"356":{"position":[[337,10]]},"409":{"position":[[6,10],[92,9],[264,10],[501,10]]},"426":{"position":[[90,11]]},"436":{"position":[[228,10]]},"546":{"position":[[4,10]]},"561":{"position":[[8,10]]},"997":{"position":[[231,11]]},"1253":{"position":[[22,11]]},"1669":{"position":[[157,11],[210,11],[331,11],[934,11],[1004,10]]},"1672":{"position":[[98,9]]},"1689":{"position":[[361,11]]},"1700":{"position":[[27,9]]},"1736":{"position":[[595,8],[1201,8]]},"1746":{"position":[[274,9]]},"1794":{"position":[[189,10]]}}}],["answer",{"_index":592,"t":{"126":{"position":[[295,9]]},"221":{"position":[[126,9],[884,9]]},"287":{"position":[[685,9]]},"384":{"position":[[216,6]]},"386":{"position":[[102,6]]},"434":{"position":[[81,9],[430,9]]},"436":{"position":[[218,9],[567,9]]},"439":{"position":[[268,6]]},"447":{"position":[[249,6],[825,9]]},"449":{"position":[[93,9],[243,6]]},"451":{"position":[[4,6],[61,6]]},"453":{"position":[[30,6],[89,6],[147,6]]},"455":{"position":[[106,6],[183,8],[343,6],[466,6],[524,6],[679,6]]},"457":{"position":[[387,6]]},"459":{"position":[[28,6],[149,6],[347,7],[490,7],[501,6],[677,6],[752,6],[793,6],[859,6]]},"466":{"position":[[427,6],[442,6]]},"468":{"position":[[322,6]]},"471":{"position":[[167,6]]},"473":{"position":[[109,6]]},"479":{"position":[[25,6]]},"555":{"position":[[59,6]]},"596":{"position":[[1466,6],[1918,6]]},"622":{"position":[[335,6]]},"658":{"position":[[172,9],[3135,6]]},"664":{"position":[[191,9]]},"674":{"position":[[212,6]]},"784":{"position":[[799,9]]},"819":{"position":[[139,6]]},"866":{"position":[[211,6]]},"895":{"position":[[63,9]]},"951":{"position":[[194,7]]},"997":{"position":[[115,10],[602,10]]},"1014":{"position":[[1511,9]]},"1017":{"position":[[199,9]]},"1041":{"position":[[101,9]]},"1070":{"position":[[310,9]]},"1107":{"position":[[20,7],[491,6]]},"1111":{"position":[[138,9]]},"1234":{"position":[[120,9]]},"1419":{"position":[[751,9]]},"1527":{"position":[[86,9]]},"1554":{"position":[[123,7]]},"1702":{"position":[[228,6]]},"1704":{"position":[[231,6],[325,8],[348,6],[452,6]]},"1706":{"position":[[23,6],[85,6],[122,6],[266,6]]},"1708":{"position":[[274,6]]},"1714":{"position":[[185,10]]},"1722":{"position":[[6,6],[35,6],[103,6],[118,6]]},"1724":{"position":[[0,6],[209,6],[257,6],[389,6],[442,9]]},"1726":{"position":[[4,6],[42,6]]},"1728":{"position":[[17,6],[109,6],[223,6],[354,9],[626,6],[710,9]]},"1730":{"position":[[7,6],[63,6],[84,6],[98,6],[121,6],[179,6],[197,6],[239,6],[309,6],[493,6],[532,7],[569,6],[601,6],[650,6],[771,6],[946,6],[1174,6],[1307,6],[1374,6]]},"1732":{"position":[[30,6],[162,6]]},"1736":{"position":[[1158,6],[1333,6]]},"1738":{"position":[[86,6],[110,8],[543,8],[731,8],[939,6]]},"1742":{"position":[[159,6]]},"1752":{"position":[[69,6],[86,8],[413,8]]},"1756":{"position":[[260,6],[433,6],[547,6]]},"1762":{"position":[[226,6]]},"1764":{"position":[[215,8]]},"1766":{"position":[[301,6],[600,6]]},"1768":{"position":[[262,6],[360,6],[837,6]]},"1772":{"position":[[9,9],[70,6],[143,6],[254,6]]},"1774":{"position":[[240,8]]},"1780":{"position":[[245,9]]},"1782":{"position":[[1281,6],[1424,6]]},"1788":{"position":[[245,6],[431,6],[724,6],[763,6],[792,6],[857,6]]},"1790":{"position":[[56,6],[96,6],[138,6],[253,7],[310,6],[356,6]]},"1802":{"position":[[52,6],[220,8],[266,6],[355,8],[975,6],[1069,6],[1194,6],[1225,6]]}}}],["answer]\\textup{[answer]}[answ",{"_index":1644,"t":{"455":{"position":[[192,34],[307,33],[426,33]]},"459":{"position":[[355,34]]}}}],["anyth",{"_index":4985,"t":{"1581":{"position":[[186,8]]}}}],["anywher",{"_index":5053,"t":{"1600":{"position":[[151,8]]}}}],["ap",{"_index":679,"t":{"147":{"position":[[258,2],[457,2]]},"149":{"position":[[302,2],[431,2],[502,2]]},"185":{"position":[[114,2]]},"197":{"position":[[127,2]]},"205":{"position":[[101,2]]},"1393":{"position":[[749,4]]},"1395":{"position":[[1115,4],[2074,4]]},"1397":{"position":[[50,4],[236,4],[459,4],[823,4]]}}}],["apdat",{"_index":2339,"t":{"660":{"position":[[276,7]]},"879":{"position":[[105,10]]}}}],["api",{"_index":4710,"t":{"1442":{"position":[[68,3]]},"1462":{"position":[[381,3]]},"1544":{"position":[[127,3]]},"1552":{"position":[[315,3]]},"1554":{"position":[[50,3]]},"1560":{"position":[[463,3]]}}}],["apl",{"_index":4543,"t":{"1393":{"position":[[764,5]]},"1395":{"position":[[1138,5]]},"1397":{"position":[[34,5],[220,5],[394,5],[838,5]]}}}],["appear",{"_index":5067,"t":{"1606":{"position":[[248,7]]},"1638":{"position":[[241,7]]}}}],["append",{"_index":2524,"t":{"696":{"position":[[608,6]]}}}],["appendix",{"_index":1302,"t":{"310":{"position":[[1879,11]]},"1170":{"position":[[290,8]]},"1172":{"position":[[268,8]]},"1195":{"position":[[621,9]]},"1197":{"position":[[483,8]]},"1499":{"position":[[105,10]]},"1505":{"position":[[220,8]]}}}],["appl",{"_index":3934,"t":{"1136":{"position":[[135,6],[145,6]]}}}],["appli",{"_index":346,"t":{"78":{"position":[[63,5]]}}}],["applic",{"_index":2231,"t":{"618":{"position":[[100,12]]},"1022":{"position":[[43,11]]},"1126":{"position":[[1045,11]]},"1552":{"position":[[321,11]]}}}],["appoach",{"_index":3868,"t":{"1124":{"position":[[256,7]]}}}],["approach",{"_index":1118,"t":{"251":{"position":[[14,8]]},"334":{"position":[[442,8]]},"362":{"position":[[57,8]]},"376":{"position":[[41,8]]},"378":{"position":[[144,8]]},"384":{"position":[[821,8],[1054,8]]},"395":{"position":[[4,8]]},"436":{"position":[[419,8]]},"464":{"position":[[138,8]]},"525":{"position":[[920,11]]},"589":{"position":[[147,8],[498,8],[1765,8]]},"592":{"position":[[459,8]]},"608":{"position":[[67,8]]},"679":{"position":[[234,8]]},"681":{"position":[[735,8]]},"719":{"position":[[534,8]]},"723":{"position":[[903,8]]},"747":{"position":[[5,8]]},"784":{"position":[[632,8]]},"786":{"position":[[4510,8],[4682,8]]},"809":{"position":[[64,8]]},"885":{"position":[[685,8]]},"887":{"position":[[1319,8]]},"926":{"position":[[4,8]]},"934":{"position":[[2005,8]]},"945":{"position":[[988,8]]},"947":{"position":[[186,8]]},"955":{"position":[[749,8]]},"1052":{"position":[[6,8]]},"1084":{"position":[[418,10]]},"1107":{"position":[[336,10]]},"1109":{"position":[[146,8],[528,8]]},"1126":{"position":[[2083,8],[2132,8]]},"1128":{"position":[[18,8],[471,8]]},"1147":{"position":[[564,8]]},"1162":{"position":[[42,8]]},"1225":{"position":[[152,8],[525,8]]},"1227":{"position":[[362,8],[1253,8]]},"1232":{"position":[[282,8]]},"1234":{"position":[[242,8]]},"1238":{"position":[[177,8],[1040,8]]},"1255":{"position":[[25,8]]},"1407":{"position":[[724,8]]},"1451":{"position":[[709,8]]},"1736":{"position":[[888,8]]}}}],["approx",{"_index":2327,"t":{"658":{"position":[[2145,7]]},"778":{"position":[[685,7]]},"1389":{"position":[[1645,7]]}}}],["approxim",{"_index":2352,"t":{"662":{"position":[[1264,11]]},"786":{"position":[[3649,13]]}}}],["aprompt",{"_index":2443,"t":{"679":{"position":[[375,7]]},"681":{"position":[[1307,7],[1412,7],[1447,7],[1718,7]]},"705":{"position":[[0,7]]},"707":{"position":[[0,7],[113,7],[313,7],[504,7]]},"709":{"position":[[38,7],[336,7],[845,7],[985,7],[1042,7],[1986,7],[2301,8],[2345,7]]},"713":{"position":[[4,7]]}}}],["apt",{"_index":3704,"t":{"1070":{"position":[[601,3]]}}}],["aqua",{"_index":1542,"t":{"391":{"position":[[93,4]]},"395":{"position":[[161,4],[194,4]]}}}],["ar=64a_{r=64}ar=64",{"_index":2700,"t":{"774":{"position":[[19,19],[1033,19]]}}}],["ar=8,ar=64,i,j)=∣∣uar=8i⊤uar=64j∣∣f2min⁡(i,j)∈[0,1](4)\\phi",{"_index":2712,"t":{"774":{"position":[[476,60]]}}}],["ar=8a_{r=8}ar=8",{"_index":2699,"t":{"774":{"position":[[0,16],[965,16]]}}}],["arbitrari",{"_index":4923,"t":{"1552":{"position":[[217,9]]}}}],["arc",{"_index":4227,"t":{"1283":{"position":[[124,4]]}}}],["architectu",{"_index":2340,"t":{"660":{"position":[[427,12]]}}}],["architectur",{"_index":144,"t":{"23":{"position":[[23,12]]},"27":{"position":[[368,12]]},"78":{"position":[[795,12]]},"84":{"position":[[24,12]]},"126":{"position":[[1039,12]]},"483":{"position":[[39,12]]},"485":{"position":[[212,12],[542,12],[1380,12]]},"504":{"position":[[288,12]]},"598":{"position":[[2718,12]]},"662":{"position":[[103,12],[142,13],[280,12],[760,12]]},"676":{"position":[[1445,12],[1749,12]]},"786":{"position":[[816,12]]},"1298":{"position":[[61,12]]},"1379":{"position":[[1470,12]]},"1695":{"position":[[176,12],[266,12]]}}}],["area",{"_index":569,"t":{"116":{"position":[[592,4]]}}}],["arg",{"_index":1623,"t":{"441":{"position":[[261,4]]}}}],["argmax",{"_index":5430,"t":{"1704":{"position":[[650,6]]}}}],["argrank",{"_index":5591,"t":{"1782":{"position":[[1606,9]]}}}],["arg⁡max⁡pelog⁡p(y∣[pe;xe])\\begin{equ",{"_index":4785,"t":{"1477":{"position":[[741,42]]}}}],["arg⁡max⁡μ,θclog⁡p(i",{"_index":4399,"t":{"1352":{"position":[[1093,19]]}}}],["arg⁡max⁡ϕlog⁡pϕ(y∣[pθ;x]).\\begin{equ",{"_index":4376,"t":{"1350":{"position":[[644,42]]}}}],["arg⁡max⁡ϕlog⁡pϕ(y∣x).\\begin{equ",{"_index":4369,"t":{"1350":{"position":[[323,37]]}}}],["aribandi",{"_index":4838,"t":{"1494":{"position":[[60,8]]}}}],["arithmar",{"_index":1591,"t":{"430":{"position":[[61,11]]}}}],["arithmet",{"_index":1524,"t":{"382":{"position":[[190,11]]},"384":{"position":[[66,11],[185,10],[868,11]]},"386":{"position":[[364,11]]},"388":{"position":[[5,10]]},"409":{"position":[[555,10]]},"426":{"position":[[51,10]]},"546":{"position":[[101,10]]}}}],["around",{"_index":5022,"t":{"1587":{"position":[[474,6]]}}}],["arriv",{"_index":2307,"t":{"658":{"position":[[229,6]]}}}],["articl",{"_index":4236,"t":{"1294":{"position":[[209,7]]},"1655":{"position":[[361,7]]}}}],["artifici",{"_index":4599,"t":{"1419":{"position":[[1047,10]]}}}],["asai",{"_index":3733,"t":{"1084":{"position":[[274,4]]},"1367":{"position":[[613,4]]}}}],["asdiv",{"_index":1541,"t":{"391":{"position":[[62,5]]}}}],["ask",{"_index":3248,"t":{"866":{"position":[[140,4]]},"1270":{"position":[[213,4]]},"1395":{"position":[[2776,4]]}}}],["assign",{"_index":4717,"t":{"1442":{"position":[[1332,10]]}}}],["associ",{"_index":3812,"t":{"1101":{"position":[[313,11],[542,11]]}}}],["assumpt",{"_index":5624,"t":{"1796":{"position":[[179,11]]}}}],["at+1a_{t+1}at+1",{"_index":3606,"t":{"1006":{"position":[[2208,16]]}}}],["ata_tat",{"_index":4730,"t":{"1447":{"position":[[172,8]]}}}],["att(q^{1",{"_index":1851,"t":{"527":{"position":[[1234,9]]}}}],["attemp",{"_index":4095,"t":{"1230":{"position":[[686,6]]}}}],["attempt",{"_index":3463,"t":{"977":{"position":[[201,7],[568,7],[846,7]]},"979":{"position":[[605,7],[784,7],[1157,7],[1284,7],[1459,8],[1618,7]]},"982":{"position":[[0,7],[277,7],[573,7]]},"986":{"position":[[364,7]]},"988":{"position":[[0,7]]},"990":{"position":[[626,7]]},"992":{"position":[[10,7],[753,7],[952,7]]},"994":{"position":[[454,7],[536,7],[703,7]]},"999":{"position":[[15,7],[239,7],[387,7],[397,7],[441,7],[526,7],[590,7]]},"1002":{"position":[[147,7],[375,7],[453,7],[598,7],[944,7]]},"1004":{"position":[[20,7],[148,7],[214,9],[348,7]]},"1006":{"position":[[42,7],[114,8],[148,7],[266,7],[369,7],[393,7],[479,7],[1337,7],[1395,7],[1548,7],[1641,7],[1688,7],[1954,7],[2101,7],[2645,7]]},"1008":{"position":[[15,7],[189,7],[655,7]]},"1070":{"position":[[592,8]]},"1084":{"position":[[560,7]]},"1189":{"position":[[292,7]]},"1197":{"position":[[262,7]]},"1227":{"position":[[1386,9]]},"1257":{"position":[[209,7]]},"1268":{"position":[[117,7]]}}}],["attempt(attent",{"_index":3465,"t":{"979":{"position":[[300,19]]}}}],["atten",{"_index":568,"t":{"116":{"position":[[584,7]]}}}],["attend",{"_index":1063,"t":{"232":{"position":[[332,6]]},"294":{"position":[[309,9]]},"300":{"position":[[513,6]]},"302":{"position":[[237,6],[512,6],[604,6]]}}}],["attens",{"_index":1207,"t":{"300":{"position":[[73,9]]}}}],["attent",{"_index":167,"t":{"25":{"position":[[169,9]]},"86":{"position":[[30,9]]},"88":{"position":[[52,9],[92,9],[131,9],[202,9],[281,9],[391,9],[429,9],[469,9],[506,9]]},"91":{"position":[[1355,9],[2175,9]]},"93":{"position":[[64,9]]},"116":{"position":[[194,9],[606,9],[641,9],[690,9],[754,9],[773,9],[879,9]]},"153":{"position":[[508,9]]},"172":{"position":[[298,9]]},"174":{"position":[[312,9],[1102,9]]},"225":{"position":[[239,9]]},"232":{"position":[[5,9],[244,9]]},"234":{"position":[[425,9]]},"283":{"position":[[73,9]]},"285":{"position":[[260,9],[394,9]]},"287":{"position":[[251,9],[326,9],[351,9],[411,9],[630,9],[829,9]]},"289":{"position":[[455,9]]},"292":{"position":[[96,9]]},"294":{"position":[[150,9],[259,9]]},"296":{"position":[[0,9]]},"298":{"position":[[9,9],[40,9],[288,9],[565,9],[596,9],[638,9],[664,9],[750,9],[876,9],[1064,9]]},"300":{"position":[[297,9],[440,9],[535,9],[1213,9],[1396,9]]},"302":{"position":[[25,9],[69,9],[301,9],[344,9],[373,9],[542,9],[624,9],[721,9]]},"304":{"position":[[0,9]]},"308":{"position":[[865,9]]},"310":{"position":[[202,9],[361,9],[878,9],[1163,9],[1762,9],[1825,9],[1854,9],[1900,9],[1949,9]]},"324":{"position":[[164,9],[182,9],[252,9],[328,9]]},"326":{"position":[[596,9]]},"328":{"position":[[26,9],[134,9]]},"330":{"position":[[0,9]]},"443":{"position":[[294,9]]},"457":{"position":[[820,9]]},"466":{"position":[[157,9]]},"485":{"position":[[1325,9],[1450,9]]},"498":{"position":[[264,9]]},"500":{"position":[[240,9],[271,9],[304,9],[557,9]]},"504":{"position":[[481,9],[532,9],[585,9],[668,9],[822,9]]},"510":{"position":[[120,9]]},"527":{"position":[[523,9],[549,9],[1152,9]]},"598":{"position":[[1221,9],[1249,9],[1399,9],[1541,9],[2177,9],[2205,9],[3183,9]]},"633":{"position":[[685,9],[817,9]]},"662":{"position":[[368,9]]},"676":{"position":[[1573,9]]},"679":{"position":[[349,9],[405,9],[465,9],[530,9]]},"681":{"position":[[1186,9],[1281,9],[1534,9],[1575,9],[1605,9],[1767,9],[1838,9],[1943,9],[1999,9]]},"683":{"position":[[1191,9]]},"692":{"position":[[4,9],[55,9],[224,9],[349,9]]},"696":{"position":[[257,9],[369,9],[397,9],[424,9],[565,9],[678,9],[895,9],[1131,9],[1231,9],[1661,9],[1678,9]]},"707":{"position":[[60,9],[271,9],[519,9]]},"709":{"position":[[862,9],[1957,9],[2386,9]]},"711":{"position":[[22,9],[74,9],[193,9],[230,9]]},"713":{"position":[[71,9]]},"721":{"position":[[119,9]]},"739":{"position":[[45,9],[183,9]]},"755":{"position":[[5,9]]},"770":{"position":[[5,9],[58,9],[147,9]]},"786":{"position":[[2695,9]]},"789":{"position":[[94,9],[217,9]]},"809":{"position":[[372,9]]},"857":{"position":[[583,9],[630,9]]},"873":{"position":[[1144,9]]},"877":{"position":[[279,9],[389,9]]},"885":{"position":[[353,9],[660,9]]},"887":{"position":[[507,9],[540,9],[1227,9]]},"891":{"position":[[919,9]]},"893":{"position":[[153,9],[191,9],[384,9],[829,9],[1277,9],[1506,9],[2068,9],[2214,9],[2443,9]]},"897":{"position":[[17,9]]},"899":{"position":[[107,9]]},"901":{"position":[[48,9],[95,9]]},"907":{"position":[[171,9]]},"919":{"position":[[79,9],[122,9],[207,9],[244,9]]},"926":{"position":[[93,9]]},"928":{"position":[[123,9]]},"934":{"position":[[222,9]]},"938":{"position":[[287,9]]},"945":{"position":[[33,9]]},"953":{"position":[[555,9]]},"977":{"position":[[209,12],[381,9],[452,9]]},"979":{"position":[[691,9],[727,9],[1294,9],[1728,11],[1825,9]]},"982":{"position":[[158,9],[446,9],[554,9],[587,10],[1174,9]]},"986":{"position":[[122,9]]},"988":{"position":[[23,10],[108,9],[210,9],[1509,10],[1842,9]]},"990":{"position":[[53,9],[351,10]]},"992":{"position":[[20,9],[288,9],[411,9],[512,9]]},"994":{"position":[[110,9]]},"999":{"position":[[505,9],[550,9]]},"1006":{"position":[[666,9],[758,10],[1189,9],[1276,9],[2080,11],[2138,9],[2237,9],[2320,9],[2443,9],[2565,9],[2665,9],[2767,9]]},"1060":{"position":[[605,9]]},"1187":{"position":[[359,9]]},"1230":{"position":[[746,9]]},"1341":{"position":[[505,9]]},"1384":{"position":[[1139,9],[3183,9]]},"1389":{"position":[[219,9]]},"1395":{"position":[[2254,9]]},"1401":{"position":[[347,9]]},"1667":{"position":[[74,9]]},"1782":{"position":[[2696,9],[2715,9],[2742,9],[2790,9],[2945,9],[3030,9],[3067,9]]}}}],["attention(q,k,v)=softmax(qktdk)v\\begin{equ",{"_index":1194,"t":{"298":{"position":[[384,48]]}}}],["attet",{"_index":3608,"t":{"1006":{"position":[[2885,8]]}}}],["attn([p,x])=softmax(qtknewd)vnewattn([p",{"_index":2471,"t":{"688":{"position":[[294,40]]}}}],["attribut",{"_index":1670,"t":{"457":{"position":[[692,11]]},"531":{"position":[[1108,11]]}}}],["auc",{"_index":920,"t":{"189":{"position":[[106,6]]}}}],["augasta",{"_index":1950,"t":{"531":{"position":[[392,7]]}}}],["augment",{"_index":246,"t":{"47":{"position":[[216,15],[243,13],[267,13]]},"49":{"position":[[563,12]]},"63":{"position":[[210,12]]},"136":{"position":[[135,12]]},"138":{"position":[[68,12],[269,12]]},"145":{"position":[[27,12]]},"213":{"position":[[88,12]]},"215":{"position":[[649,12],[1285,12],[1499,12]]},"384":{"position":[[555,9]]},"640":{"position":[[381,12]]},"1667":{"position":[[670,12]]},"1689":{"position":[[375,9]]},"1738":{"position":[[7,12],[636,12],[791,12],[913,12]]},"1752":{"position":[[110,12],[182,12]]},"1774":{"position":[[267,10]]},"1778":{"position":[[144,12]]},"1780":{"position":[[83,12]]},"1782":{"position":[[554,12],[749,12],[787,12],[3125,12],[3303,12]]},"1794":{"position":[[661,12],[687,12]]}}}],["author",{"_index":42,"t":{"7":{"position":[[136,7]]},"1587":{"position":[[114,8]]}}}],["authors.yml",{"_index":44,"t":{"7":{"position":[[160,12]]}}}],["auto",{"_index":1035,"t":{"225":{"position":[[208,4]]},"277":{"position":[[132,4]]},"289":{"position":[[338,4]]},"302":{"position":[[669,4]]},"466":{"position":[[407,4]]},"485":{"position":[[1011,4]]},"494":{"position":[[10,4]]},"670":{"position":[[1160,4]]},"1646":{"position":[[1730,4],[2840,4],[3020,4]]},"1712":{"position":[[86,4]]}}}],["autogress",{"_index":2585,"t":{"723":{"position":[[87,12]]}}}],["autom",{"_index":3145,"t":{"853":{"position":[[1822,9]]}}}],["automat",{"_index":101,"t":{"17":{"position":[[85,13]]},"19":{"position":[[432,13]]},"215":{"position":[[497,9]]},"244":{"position":[[268,9],[500,9]]},"1595":{"position":[[11,13]]}}}],["automl",{"_index":2391,"t":{"670":{"position":[[919,6],[1094,6],[1240,6]]}}}],["autoprompt",{"_index":3842,"t":{"1107":{"position":[[389,10]]},"1109":{"position":[[98,10]]},"1126":{"position":[[1013,12]]},"1720":{"position":[[1529,10]]},"1730":{"position":[[792,10]]}}}],["autoregress",{"_index":660,"t":{"143":{"position":[[304,14]]},"159":{"position":[[496,14],[588,14]]},"236":{"position":[[27,14],[110,14]]},"441":{"position":[[68,16]]},"633":{"position":[[105,14]]},"1132":{"position":[[0,14]]},"1296":{"position":[[39,14],[577,14]]},"1298":{"position":[[154,16],[423,14]]},"1305":{"position":[[16,14]]},"1774":{"position":[[80,14]]}}}],["auxiliari",{"_index":838,"t":{"174":{"position":[[450,9]]},"177":{"position":[[210,9]]},"221":{"position":[[537,9]]},"225":{"position":[[517,9]]},"232":{"position":[[400,9]]},"262":{"position":[[216,9]]},"870":{"position":[[782,9]]}}}],["avail",{"_index":3010,"t":{"807":{"position":[[38,9]]},"1587":{"position":[[541,9]]},"1593":{"position":[[127,9]]},"1612":{"position":[[277,9]]},"1614":{"position":[[139,9]]}}}],["averag",{"_index":300,"t":{"53":{"position":[[276,7]]},"174":{"position":[[1935,7]]},"191":{"position":[[127,8],[262,8]]},"199":{"position":[[157,8]]},"287":{"position":[[241,9]]},"555":{"position":[[267,7],[289,8]]},"567":{"position":[[360,7]]},"801":{"position":[[2157,7]]},"1002":{"position":[[400,7],[510,7]]},"1149":{"position":[[718,7]]},"1397":{"position":[[131,7]]},"1409":{"position":[[898,7]]},"1423":{"position":[[236,7],[1263,7]]},"1427":{"position":[[764,8],[928,7]]},"1429":{"position":[[514,7],[545,7],[853,7],[932,7],[1174,7]]},"1431":{"position":[[742,7],[838,7],[1437,7],[2463,7],[2730,7],[2850,7]]},"1499":{"position":[[292,7]]},"1531":{"position":[[165,8]]},"1659":{"position":[[1075,7]]},"1736":{"position":[[282,9],[717,9],[759,7]]},"1782":{"position":[[539,7]]}}}],["awar",{"_index":220,"t":{"38":{"position":[[59,5]]},"44":{"position":[[66,5]]},"76":{"position":[[9,5]]},"78":{"position":[[935,5]]},"91":{"position":[[1207,5]]},"172":{"position":[[207,5]]},"174":{"position":[[241,5]]},"793":{"position":[[113,5]]}}}],["awesom",{"_index":5114,"t":{"1626":{"position":[[91,7],[183,7]]}}}],["axi",{"_index":2319,"t":{"658":{"position":[[1384,4]]}}}],["a∈rn\\text{a",{"_index":3109,"t":{"853":{"position":[[165,12]]}}}],["a∈rr×d2a",{"_index":2759,"t":{"786":{"position":[[1840,8]]},"791":{"position":[[333,8]]}}}],["a∈rr×ka",{"_index":2625,"t":{"733":{"position":[[446,7]]}}}],["a∈rs×ra",{"_index":3678,"t":{"1067":{"position":[[311,7]]}}}],["b",{"_index":659,"t":{"143":{"position":[[279,2]]},"253":{"position":[[363,1]]},"260":{"position":[[5,3]]},"324":{"position":[[321,3]]},"409":{"position":[[105,1]]},"759":{"position":[[176,1]]},"866":{"position":[[993,1]]},"945":{"position":[[656,3],[686,1]]},"1002":{"position":[[89,1]]},"1006":{"position":[[676,3]]},"1070":{"position":[[121,1]]},"1253":{"position":[[198,2]]},"1395":{"position":[[121,1],[1273,3],[1861,1],[1919,2],[2589,1]]},"1427":{"position":[[1182,2]]},"1429":{"position":[[1547,1]]},"1431":{"position":[[1900,1]]},"1651":{"position":[[641,4],[1229,2]]},"1657":{"position":[[116,2]]}}}],["b(0)b^{(0)}b(0",{"_index":2998,"t":{"803":{"position":[[302,15]]},"814":{"position":[[385,15]]}}}],["b(t",{"_index":2921,"t":{"797":{"position":[[1755,4],[2186,4]]}}}],["b(t)b^{(t)}b(t",{"_index":2942,"t":{"797":{"position":[[2359,15]]},"803":{"position":[[151,15],[334,15],[368,15],[520,15],[538,15],[564,15]]},"814":{"position":[[301,15],[403,15]]},"821":{"position":[[317,15]]},"841":{"position":[[439,15],[508,15]]}}}],["b(⋅){\\color{red}{b^{(\\cdot)}}}b",{"_index":1890,"t":{"527":{"position":[[2867,34]]}}}],["b(⋅)ℓ,(⋅){\\color{red}{b^{\\el",{"_index":1882,"t":{"527":{"position":[[2541,30]]}}}],["b),b",{"_index":5178,"t":{"1651":{"position":[[646,5]]}}}],["b.2",{"_index":4038,"t":{"1170":{"position":[[299,3]]},"1195":{"position":[[631,4]]}}}],["b/16",{"_index":557,"t":{"114":{"position":[[168,5],[257,5]]},"118":{"position":[[133,4]]},"239":{"position":[[241,4]]},"354":{"position":[[108,5]]},"366":{"position":[[215,4]]},"924":{"position":[[66,4]]}}}],["b/32",{"_index":556,"t":{"114":{"position":[[162,5],[251,5]]},"354":{"position":[[98,5]]},"366":{"position":[[205,5]]}}}],["b0b_0b0",{"_index":1913,"t":{"529":{"position":[[1349,8]]}}}],["b4",{"_index":213,"t":{"33":{"position":[[256,2]]}}}],["b7",{"_index":307,"t":{"55":{"position":[[70,2]]}}}],["b^{(0",{"_index":3001,"t":{"803":{"position":[[443,7]]}}}],["b^{(t",{"_index":2932,"t":{"797":{"position":[[2015,9]]}}}],["b_0",{"_index":1910,"t":{"529":{"position":[[1280,3]]}}}],["b_1)w_2",{"_index":1250,"t":{"304":{"position":[[252,7]]}}}],["b_1)w_{f2",{"_index":2810,"t":{"789":{"position":[[915,10]]}}}],["b_2",{"_index":1251,"t":{"304":{"position":[[262,3]]}}}],["b_2ffn(x)=relu(xwfi​+b1​)wf2​+b2",{"_index":2811,"t":{"789":{"position":[[928,33]]}}}],["b_f",{"_index":1911,"t":{"529":{"position":[[1286,3]]}}}],["b_{*i",{"_index":2828,"t":{"791":{"position":[[685,6]]}}}],["ba",{"_index":2754,"t":{"786":{"position":[[1724,3]]},"1067":{"position":[[579,2]]}}}],["baas",{"_index":4210,"t":{"1255":{"position":[[82,5]]}}}],["bababa",{"_index":2643,"t":{"737":{"position":[[28,6]]},"795":{"position":[[1545,6]]}}}],["bachmark",{"_index":4706,"t":{"1440":{"position":[[603,8]]}}}],["back",{"_index":996,"t":{"215":{"position":[[1082,4]]},"358":{"position":[[1311,4]]},"531":{"position":[[1201,4]]},"1730":{"position":[[432,4]]}}}],["backbon",{"_index":1037,"t":{"225":{"position":[[412,8]]},"227":{"position":[[44,8]]},"253":{"position":[[424,8]]},"443":{"position":[[359,8]]},"630":{"position":[[1237,8],[1834,8]]},"681":{"position":[[469,8]]},"686":{"position":[[421,8]]},"690":{"position":[[43,8]]},"694":{"position":[[913,8]]},"707":{"position":[[14,8],[381,8],[444,8],[636,8]]},"979":{"position":[[1651,8]]},"1006":{"position":[[20,8],[236,8],[336,8]]},"1008":{"position":[[450,8]]},"1039":{"position":[[115,9]]},"1065":{"position":[[157,8]]},"1665":{"position":[[1262,8]]},"1674":{"position":[[328,8]]},"1682":{"position":[[87,8]]}}}],["backgroundcolor",{"_index":5123,"t":{"1628":{"position":[[169,16]]}}}],["backpropag",{"_index":1106,"t":{"244":{"position":[[426,15]]},"616":{"position":[[106,15]]},"626":{"position":[[143,15]]},"1124":{"position":[[158,15]]},"1128":{"position":[[1367,15]]}}}],["backward",{"_index":1283,"t":{"310":{"position":[[613,8]]}}}],["bad",{"_index":3612,"t":{"1014":{"position":[[542,5]]},"1704":{"position":[[141,6]]}}}],["balanc",{"_index":2560,"t":{"709":{"position":[[1975,10]]},"934":{"position":[[2315,8]]},"1354":{"position":[[87,7],[183,7]]}}}],["banana",{"_index":4874,"t":{"1536":{"position":[[19,6],[526,6]]}}}],["banking77",{"_index":5374,"t":{"1680":{"position":[[129,9]]}}}],["bar",{"_index":4995,"t":{"1583":{"position":[[178,3]]}}}],["barack",{"_index":4284,"t":{"1303":{"position":[[149,8]]}}}],["barrier",{"_index":2574,"t":{"719":{"position":[[1032,7]]}}}],["bart",{"_index":2787,"t":{"786":{"position":[[4493,4]]},"805":{"position":[[32,4]]},"826":{"position":[[41,4]]},"1145":{"position":[[632,4],[719,4]]},"1289":{"position":[[510,4]]},"1298":{"position":[[80,5]]},"1314":{"position":[[74,4]]},"1471":{"position":[[146,4]]},"1768":{"position":[[697,4]]},"1772":{"position":[[487,5]]},"1782":{"position":[[2153,8]]},"1802":{"position":[[85,5],[179,5]]}}}],["bartscor",{"_index":5512,"t":{"1736":{"position":[[635,9]]}}}],["bar{x}))]_j\\cdot",{"_index":4396,"t":{"1352":{"position":[[861,18]]}}}],["base",{"_index":513,"t":{"104":{"position":[[10,5]]},"153":{"position":[[82,5]]},"213":{"position":[[77,5]]},"215":{"position":[[1274,5]]},"239":{"position":[[211,4],[230,4]]},"255":{"position":[[74,4]]},"319":{"position":[[193,4]]},"322":{"position":[[160,4],[432,4]]},"324":{"position":[[557,4]]},"326":{"position":[[696,4]]},"500":{"position":[[983,5]]},"504":{"position":[[338,5]]},"506":{"position":[[110,5]]},"529":{"position":[[696,4],[723,4]]},"531":{"position":[[1009,5]]},"587":{"position":[[142,5]]},"589":{"position":[[234,5],[753,5],[1948,5]]},"594":{"position":[[356,5]]},"608":{"position":[[12,5],[118,5]]},"626":{"position":[[497,5]]},"628":{"position":[[526,5],[721,4],[878,5]]},"630":{"position":[[2337,5]]},"633":{"position":[[202,4],[263,4],[481,5]]},"638":{"position":[[5,4]]},"640":{"position":[[13,4]]},"648":{"position":[[614,4]]},"650":{"position":[[226,4]]},"658":{"position":[[666,5],[758,5],[1119,5],[1174,5],[1430,5],[1565,5],[1588,5],[1702,5],[2457,5],[2976,4]]},"662":{"position":[[25,5]]},"664":{"position":[[223,5]]},"666":{"position":[[38,4]]},"670":{"position":[[554,4],[782,5]]},"705":{"position":[[143,5]]},"707":{"position":[[367,4]]},"759":{"position":[[80,4]]},"786":{"position":[[439,4],[562,4],[645,4],[4482,4]]},"793":{"position":[[25,5]]},"797":{"position":[[8,5]]},"805":{"position":[[25,4]]},"812":{"position":[[25,4]]},"814":{"position":[[10,4]]},"819":{"position":[[66,4]]},"823":{"position":[[90,4]]},"828":{"position":[[10,4],[40,5]]},"833":{"position":[[40,4]]},"839":{"position":[[145,5],[378,4]]},"841":{"position":[[43,4]]},"857":{"position":[[376,6]]},"866":{"position":[[27,4],[671,4],[694,4],[802,4],[848,4]]},"999":{"position":[[626,4]]},"1006":{"position":[[279,4]]},"1070":{"position":[[752,4],[805,4],[1239,4],[1391,4]]},"1105":{"position":[[103,4]]},"1111":{"position":[[1759,4],[1773,5]]},"1113":{"position":[[5,4],[131,4],[180,4],[242,4],[283,4],[500,5],[571,5]]},"1117":{"position":[[39,5],[73,5],[109,5]]},"1126":{"position":[[700,5]]},"1134":{"position":[[62,5]]},"1141":{"position":[[662,5]]},"1143":{"position":[[743,5]]},"1145":{"position":[[1933,4],[2002,4]]},"1157":{"position":[[355,4],[367,4],[418,4]]},"1159":{"position":[[1700,4],[1712,4],[1749,4]]},"1183":{"position":[[66,4],[82,4]]},"1191":{"position":[[17,5]]},"1197":{"position":[[85,4],[385,5]]},"1221":{"position":[[320,5]]},"1227":{"position":[[1312,4]]},"1347":{"position":[[1656,4],[2046,4]]},"1357":{"position":[[281,4]]},"1360":{"position":[[71,4]]},"1373":{"position":[[114,4]]},"1393":{"position":[[827,4]]},"1407":{"position":[[242,5]]},"1409":{"position":[[855,4],[1563,5]]},"1413":{"position":[[7,5]]},"1423":{"position":[[75,4]]},"1427":{"position":[[323,4]]},"1442":{"position":[[1156,5]]},"1447":{"position":[[83,5]]},"1473":{"position":[[391,5]]},"1494":{"position":[[382,5]]},"1552":{"position":[[299,5]]},"1644":{"position":[[572,5]]},"1653":{"position":[[1013,5]]},"1665":{"position":[[474,5],[680,5],[1044,5]]},"1674":{"position":[[77,5]]},"1682":{"position":[[531,5]]},"1684":{"position":[[432,5]]},"1693":{"position":[[24,5],[137,5]]},"1700":{"position":[[57,5]]},"1708":{"position":[[457,5]]},"1718":{"position":[[500,5],[532,5],[1044,4]]},"1720":{"position":[[1011,5]]},"1766":{"position":[[15,5]]},"1768":{"position":[[609,5],[713,5]]},"1782":{"position":[[7,5],[492,5],[1019,5],[1241,5],[1373,5],[2313,5],[2868,5]]},"1784":{"position":[[7,5]]},"1786":{"position":[[21,5],[99,5]]},"1788":{"position":[[52,5],[102,5]]},"1796":{"position":[[22,5]]},"1800":{"position":[[162,5]]}}}],["baselin",{"_index":1564,"t":{"399":{"position":[[153,9]]},"405":{"position":[[146,8]]},"407":{"position":[[147,8]]},"409":{"position":[[288,8]]},"485":{"position":[[1694,8]]},"598":{"position":[[3665,8],[3793,8]]},"604":{"position":[[70,8]]},"633":{"position":[[578,8]]},"670":{"position":[[1247,8]]},"672":{"position":[[150,8]]},"679":{"position":[[576,8]]},"707":{"position":[[45,8]]},"709":{"position":[[48,8],[378,8]]},"711":{"position":[[279,8]]},"784":{"position":[[905,8]]},"814":{"position":[[69,8]]},"816":{"position":[[32,8],[202,8]]},"821":{"position":[[24,8]]},"830":{"position":[[143,8]]},"833":{"position":[[101,8]]},"999":{"position":[[0,10],[603,8]]},"1002":{"position":[[306,8]]},"1006":{"position":[[1326,8]]},"1012":{"position":[[617,8]]},"1056":{"position":[[171,8]]},"1070":{"position":[[371,10],[386,9]]},"1075":{"position":[[145,9]]},"1136":{"position":[[217,8]]},"1225":{"position":[[631,8]]},"1227":{"position":[[1377,8]]},"1250":{"position":[[33,8]]},"1257":{"position":[[9,9]]},"1317":{"position":[[107,8]]},"1345":{"position":[[471,8]]},"1347":{"position":[[2065,8]]},"1357":{"position":[[30,8],[212,10]]},"1360":{"position":[[18,8],[148,8]]},"1373":{"position":[[322,8]]},"1415":{"position":[[10,9]]},"1431":{"position":[[1481,9],[2573,8]]},"1440":{"position":[[553,8]]},"1442":{"position":[[2237,8]]},"1501":{"position":[[277,8]]},"1558":{"position":[[2070,9]]},"1644":{"position":[[795,9]]},"1646":{"position":[[3236,9]]},"1665":{"position":[[114,9],[542,8]]},"1667":{"position":[[914,8]]},"1674":{"position":[[48,8],[700,8]]},"1676":{"position":[[25,8]]},"1684":{"position":[[29,9]]},"1689":{"position":[[444,9]]}}}],["baselinb",{"_index":970,"t":{"213":{"position":[[423,9]]}}}],["basic",{"_index":4978,"t":{"1581":{"position":[[26,6]]},"1651":{"position":[[6,5]]}}}],["basics/cr",{"_index":5049,"t":{"1595":{"position":[[431,13]]}}}],["batch",{"_index":164,"t":{"25":{"position":[[138,5]]},"53":{"position":[[170,5]]},"63":{"position":[[124,5]]},"104":{"position":[[242,5]]},"106":{"position":[[98,5],[145,5]]},"138":{"position":[[177,5],[297,5],[334,5]]},"313":{"position":[[315,5]]},"372":{"position":[[62,5]]},"498":{"position":[[612,7],[667,5],[702,5]]},"500":{"position":[[1091,5],[1185,5]]},"531":{"position":[[1364,5]]},"550":{"position":[[84,5]]},"589":{"position":[[1418,5],[1458,7],[2282,7]]},"592":{"position":[[179,7]]},"598":{"position":[[178,7],[201,7],[261,5],[352,5],[543,7],[657,7],[2472,5],[2566,7]]},"600":{"position":[[363,5]]},"602":{"position":[[477,5]]},"612":{"position":[[111,5]]},"644":{"position":[[147,5],[282,5]]},"662":{"position":[[1398,5]]},"666":{"position":[[382,5]]},"670":{"position":[[147,5]]},"801":{"position":[[1388,5]]},"821":{"position":[[397,5]]},"828":{"position":[[160,5],[207,5]]},"866":{"position":[[482,5],[736,5]]},"905":{"position":[[154,5]]},"1111":{"position":[[1411,5]]},"1134":{"position":[[735,5]]},"1246":{"position":[[356,5],[402,5],[510,7]]},"1314":{"position":[[239,5],[299,5],[641,5],[847,5],[897,5]]},"1369":{"position":[[238,5]]},"1496":{"position":[[265,5]]},"1665":{"position":[[1440,5]]},"1674":{"position":[[460,5]]},"1682":{"position":[[104,5]]}}}],["batch/lay",{"_index":2439,"t":{"676":{"position":[[1491,11]]}}}],["bath",{"_index":5638,"t":{"1802":{"position":[[1056,5]]}}}],["bathtub",{"_index":5639,"t":{"1802":{"position":[[1109,9]]}}}],["baw0​+△w=w0​+ba",{"_index":2622,"t":{"733":{"position":[[378,15]]}}}],["bax",{"_index":2638,"t":{"733":{"position":[[827,3]]},"791":{"position":[[212,4]]}}}],["ba△w=ba",{"_index":2632,"t":{"733":{"position":[[658,7],[921,7]]},"1067":{"position":[[764,7]]}}}],["bbb",{"_index":1908,"t":{"529":{"position":[[1226,3]]},"719":{"position":[[907,3]]},"733":{"position":[[597,3],[885,3]]},"786":{"position":[[1997,3]]},"791":{"position":[[521,3],[625,3]]},"795":{"position":[[1832,3]]},"839":{"position":[[221,3]]},"945":{"position":[[538,3]]},"1067":{"position":[[678,3],[1438,3]]},"1651":{"position":[[659,3],[1012,3]]}}}],["bbd100k",{"_index":939,"t":{"193":{"position":[[45,7]]}}}],["bbh",{"_index":2006,"t":{"553":{"position":[[162,3]]},"555":{"position":[[18,3]]},"561":{"position":[[354,3]]},"565":{"position":[[143,3]]}}}],["bbn",{"_index":5360,"t":{"1672":{"position":[[237,3]]}}}],["bdd100k",{"_index":948,"t":{"195":{"position":[[12,7]]}}}],["bdd10k",{"_index":894,"t":{"177":{"position":[[1284,8]]}}}],["be",{"_index":1640,"t":{"453":{"position":[[114,5],[172,5]]}}}],["beam",{"_index":646,"t":{"140":{"position":[[142,4]]},"246":{"position":[[32,4],[47,4],[282,4],[374,5],[397,4]]},"322":{"position":[[551,4]]},"324":{"position":[[112,4]]},"326":{"position":[[634,4],[828,4]]},"828":{"position":[[145,4],[192,4]]},"1314":{"position":[[745,4],[792,4]]}}}],["beauti",{"_index":5631,"t":{"1802":{"position":[[518,9],[687,9]]}}}],["bebias",{"_index":5572,"t":{"1778":{"position":[[289,9]]}}}],["befor",{"_index":4520,"t":{"1389":{"position":[[1255,7]]}}}],["begin{align",{"_index":3123,"t":{"853":{"position":[[699,14]]},"893":{"position":[[536,15]]},"945":{"position":[[577,13]]},"1101":{"position":[[758,14]]},"1655":{"position":[[880,14],[1799,14]]},"1657":{"position":[[757,14],[1323,14],[2743,14]]}}}],["begin{array}{l",{"_index":800,"t":{"170":{"position":[[2049,17]]},"172":{"position":[[482,17]]},"174":{"position":[[2088,17]]}}}],["begin{equ",{"_index":5215,"t":{"1655":{"position":[[861,18],[1780,18]]}}}],["behavior",{"_index":3959,"t":{"1145":{"position":[[2404,8],[2497,8]]}}}],["bello",{"_index":393,"t":{"88":{"position":[[401,5]]}}}],["ben",{"_index":1923,"t":{"529":{"position":[[2216,3]]},"1379":{"position":[[1082,4]]}}}],["bench",{"_index":1573,"t":{"412":{"position":[[69,5]]},"414":{"position":[[77,5]]},"539":{"position":[[536,5]]},"553":{"position":[[172,5]]},"555":{"position":[[245,5]]},"559":{"position":[[182,5]]}}}],["benchmark",{"_index":1722,"t":{"483":{"position":[[726,10]]},"537":{"position":[[272,10]]},"553":{"position":[[217,9]]},"587":{"position":[[707,9]]},"1442":{"position":[[2290,10]]},"1527":{"position":[[10,10]]}}}],["benefit",{"_index":1603,"t":{"434":{"position":[[488,7]]},"1427":{"position":[[594,10]]}}}],["bengio",{"_index":3101,"t":{"851":{"position":[[812,7]]}}}],["berkeleypars",{"_index":1380,"t":{"326":{"position":[[1008,14]]}}}],["berkleypars",{"_index":1370,"t":{"326":{"position":[[405,13]]}}}],["bert",{"_index":424,"t":{"91":{"position":[[754,4]]},"104":{"position":[[30,4]]},"118":{"position":[[38,4]]},"172":{"position":[[742,4]]},"182":{"position":[[83,4]]},"498":{"position":[[315,4]]},"521":{"position":[[128,4]]},"523":{"position":[[0,4]]},"527":{"position":[[467,4]]},"529":{"position":[[98,5]]},"656":{"position":[[338,4]]},"658":{"position":[[123,4],[3025,4]]},"664":{"position":[[78,4]]},"666":{"position":[[19,4],[54,4],[456,4]]},"668":{"position":[[658,4]]},"670":{"position":[[777,4],[1258,4],[1293,4]]},"683":{"position":[[132,4]]},"786":{"position":[[60,4]]},"849":{"position":[[0,4]]},"851":{"position":[[1036,4]]},"857":{"position":[[371,4],[513,4]]},"859":{"position":[[49,4],[149,4]]},"866":{"position":[[22,4],[295,4],[666,4],[797,4]]},"870":{"position":[[976,4]]},"873":{"position":[[218,4]]},"879":{"position":[[361,4],[530,4]]},"947":{"position":[[49,4]]},"1037":{"position":[[120,4]]},"1043":{"position":[[7,4]]},"1091":{"position":[[332,4],[397,4]]},"1093":{"position":[[319,5],[1350,4],[1380,4],[1636,4],[1740,4]]},"1103":{"position":[[91,4]]},"1107":{"position":[[155,4],[183,4]]},"1109":{"position":[[1107,4],[1220,4]]},"1111":{"position":[[1754,4],[1779,4]]},"1113":{"position":[[0,4],[18,4],[203,4],[278,4],[326,4],[566,4],[614,4]]},"1117":{"position":[[68,4]]},"1120":{"position":[[245,4]]},"1126":{"position":[[149,4]]},"1145":{"position":[[2225,4]]},"1157":{"position":[[362,4]]},"1159":{"position":[[1707,4]]},"1183":{"position":[[40,4],[61,4]]},"1185":{"position":[[341,4]]},"1393":{"position":[[168,4]]},"1471":{"position":[[31,4]]},"1682":{"position":[[595,4]]},"1750":{"position":[[129,4]]},"1800":{"position":[[20,4]]}}}],["bert$\\text{bas",{"_index":2395,"t":{"670":{"position":[[1397,17]]},"672":{"position":[[163,17]]}}}],["bert_bas",{"_index":5370,"t":{"1674":{"position":[[318,9]]}}}],["bertbase_\\text{base}bas",{"_index":1884,"t":{"527":{"position":[[2635,25]]},"529":{"position":[[179,26],[744,25],[1670,25],[2041,25],[2372,26]]},"670":{"position":[[696,25]]},"672":{"position":[[1147,25]]},"676":{"position":[[153,25]]},"1393":{"position":[[799,25]]}}}],["bertlarge_\\text{large}larg",{"_index":1885,"t":{"527":{"position":[[2663,28]]},"529":{"position":[[206,28],[470,28],[822,28],[2399,28]]},"672":{"position":[[1420,28]]},"1393":{"position":[[858,28]]},"1399":{"position":[[736,30]]}}}],["bertlarge_{\\text{large}}larg",{"_index":2363,"t":{"668":{"position":[[60,30]]}}}],["best",{"_index":1355,"t":{"324":{"position":[[264,4]]},"569":{"position":[[497,4]]},"594":{"position":[[98,4]]},"666":{"position":[[442,4]]},"668":{"position":[[346,4],[477,4]]},"670":{"position":[[1146,4]]},"709":{"position":[[254,4],[1390,4],[1825,4]]},"1033":{"position":[[83,4]]},"1091":{"position":[[262,4]]},"1093":{"position":[[608,4]]},"1113":{"position":[[290,4]]},"1115":{"position":[[486,4],[974,4]]},"1117":{"position":[[173,4]]},"1141":{"position":[[685,4]]},"1149":{"position":[[737,4]]},"1377":{"position":[[532,4]]},"1379":{"position":[[1301,4],[1746,4]]},"1389":{"position":[[618,4]]},"1393":{"position":[[432,4],[595,4]]},"1397":{"position":[[112,4],[126,4],[300,4],[314,4],[785,4],[916,4],[1189,4],[1354,4],[1387,4],[1503,4]]},"1403":{"position":[[257,4]]},"1409":{"position":[[39,4]]},"1423":{"position":[[290,4],[485,4],[778,4],[1258,4]]},"1425":{"position":[[623,4]]},"1427":{"position":[[884,4]]},"1431":{"position":[[576,4],[710,4],[1569,4],[2425,4],[2511,4],[2875,4],[2976,4],[3078,4]]},"1492":{"position":[[186,4]]},"1496":{"position":[[568,4]]},"1499":{"position":[[684,4]]},"1501":{"position":[[164,4],[307,4]]},"1505":{"position":[[954,4]]},"1531":{"position":[[106,5]]}}}],["beta",{"_index":4951,"t":{"1558":{"position":[[1568,5],[1926,7]]}}}],["beta_1",{"_index":2980,"t":{"801":{"position":[[1726,7],[2074,8]]}}}],["beta_1)i^{(t)}(w_{ij",{"_index":2983,"t":{"801":{"position":[[1768,23]]}}}],["beta_2",{"_index":1319,"t":{"317":{"position":[[53,7]]},"801":{"position":[[1825,7],[1867,8],[2083,7]]}}}],["better",{"_index":1905,"t":{"529":{"position":[[772,6]]},"587":{"position":[[426,6]]},"589":{"position":[[125,6]]},"1669":{"position":[[518,6]]}}}],["between",{"_index":4674,"t":{"1431":{"position":[[1632,7]]}}}],["beyond",{"_index":5615,"t":{"1788":{"position":[[6,6]]}}}],["bfb_fbf",{"_index":1914,"t":{"529":{"position":[[1378,8]]}}}],["bi",{"_index":816,"t":{"172":{"position":[[277,2],[315,3]]}}}],["bia",{"_index":380,"t":{"86":{"position":[[402,4],[539,4],[554,4],[651,4],[737,4],[808,4]]},"93":{"position":[[107,4]]},"97":{"position":[[470,4]]},"112":{"position":[[100,4],[503,4]]},"120":{"position":[[39,4]]},"521":{"position":[[46,4]]},"523":{"position":[[684,4],[744,4],[787,4],[825,4],[1019,4]]},"527":{"position":[[11,5],[90,4],[347,4],[2605,4],[2616,4],[2694,4],[2856,4],[2999,4]]},"529":{"position":[[885,4],[1138,4],[1165,4],[1214,4],[1438,4],[1474,4],[1560,4],[1614,4],[1786,4],[1846,4],[2007,4]]},"531":{"position":[[842,4],[938,4],[950,4],[1034,4],[1132,4],[1156,4],[1286,4],[1465,4],[1547,4]]},"533":{"position":[[143,4],[348,4],[422,4]]},"598":{"position":[[3143,4]]},"648":{"position":[[556,4]]},"681":{"position":[[521,4]]},"683":{"position":[[711,4]]},"735":{"position":[[21,4]]},"749":{"position":[[0,4]]},"755":{"position":[[100,4]]},"809":{"position":[[234,4]]},"932":{"position":[[243,4]]},"934":{"position":[[1754,4],[1820,4]]},"945":{"position":[[255,4],[427,4],[533,4],[747,4],[797,4]]},"947":{"position":[[0,4],[241,4],[299,4]]},"949":{"position":[[560,4]]},"961":{"position":[[199,4]]},"963":{"position":[[0,4],[195,4]]},"1230":{"position":[[48,4]]},"1382":{"position":[[169,4]]},"1384":{"position":[[914,4]]},"1395":{"position":[[2422,4]]},"1401":{"position":[[278,4]]},"1546":{"position":[[694,4]]},"1558":{"position":[[1066,4]]},"1560":{"position":[[528,4]]},"1565":{"position":[[81,4]]},"1573":{"position":[[280,4]]},"1695":{"position":[[166,4],[312,4]]},"1802":{"position":[[305,5],[318,5],[337,6]]}}}],["bias",{"_index":2346,"t":{"662":{"position":[[933,6]]},"809":{"position":[[114,6]]},"1778":{"position":[[232,6]]}}}],["bicyl",{"_index":756,"t":{"170":{"position":[[289,7]]}}}],["bidirect",{"_index":1743,"t":{"498":{"position":[[245,13]]},"523":{"position":[[9,13]]},"1043":{"position":[[101,13]]},"1093":{"position":[[242,13]]},"1107":{"position":[[625,13],[853,13]]},"1109":{"position":[[450,13]]},"1111":{"position":[[1689,13]]},"1113":{"position":[[622,13]]},"1120":{"position":[[286,13]]},"1298":{"position":[[104,13],[321,13]]}}}],["big",{"_index":1344,"t":{"322":{"position":[[37,3],[260,3],[374,5],[510,3]]},"412":{"position":[[65,3]]},"414":{"position":[[73,3]]},"539":{"position":[[532,3]]},"553":{"position":[[168,3]]},"555":{"position":[[241,3]]},"559":{"position":[[178,3]]},"1531":{"position":[[68,3],[128,3],[190,3]]},"1533":{"position":[[54,3]]}}}],["bigotim",{"_index":4140,"t":{"1242":{"position":[[470,10],[676,10]]},"1244":{"position":[[379,10]]},"1246":{"position":[[730,10]]}}}],["billion",{"_index":3990,"t":{"1159":{"position":[[313,7]]}}}],["bilstm",{"_index":5468,"t":{"1720":{"position":[[2142,6]]}}}],["bimod",{"_index":1730,"t":{"488":{"position":[[122,7],[258,7]]},"496":{"position":[[24,7],[125,7],[198,7]]},"500":{"position":[[140,7]]},"515":{"position":[[507,7],[598,7],[741,7]]}}}],["bin",{"_index":671,"t":{"143":{"position":[[614,4]]}}}],["binari",{"_index":651,"t":{"140":{"position":[[676,6]]},"500":{"position":[[714,6]]},"512":{"position":[[131,6]]},"849":{"position":[[1542,6]]},"853":{"position":[[348,6]]},"855":{"position":[[482,6]]},"870":{"position":[[1102,6],[1287,6]]},"1442":{"position":[[332,6],[888,6],[974,6]]},"1451":{"position":[[144,6]]},"1655":{"position":[[160,6],[1240,10],[2091,6],[2216,6]]}}}],["bioasq",{"_index":3962,"t":{"1147":{"position":[[618,7]]}}}],["biomed",{"_index":3963,"t":{"1147":{"position":[[628,11]]}}}],["biparit",{"_index":703,"t":{"153":{"position":[[197,8]]}}}],["bit",{"_index":518,"t":{"104":{"position":[[328,3]]},"110":{"position":[[43,3]]},"114":{"position":[[15,4],[371,3]]},"614":{"position":[[186,3],[229,4]]}}}],["bitfir",{"_index":4450,"t":{"1382":{"position":[[154,6],[297,6]]}}}],["bitfit",{"_index":1809,"t":{"521":{"position":[[4,6],[135,6]]},"527":{"position":[[4,6]]},"529":{"position":[[10,6],[323,6],[520,6],[956,9],[2168,6],[2496,6],[2560,6],[2716,6],[2793,6]]},"533":{"position":[[4,6]]},"598":{"position":[[3134,6]]},"648":{"position":[[520,6]]},"809":{"position":[[167,6]]},"947":{"position":[[71,6],[115,6]]},"994":{"position":[[663,6]]},"999":{"position":[[198,6]]},"1002":{"position":[[170,6],[436,6],[534,6]]},"1070":{"position":[[638,6]]},"1077":{"position":[[86,6]]},"1230":{"position":[[39,6]]},"1257":{"position":[[305,6]]},"1379":{"position":[[1075,6]]},"1393":{"position":[[699,7]]},"1395":{"position":[[2392,6],[2450,6],[2524,6],[2565,6]]}}}],["bk{\\color{red}{b_k}}bk",{"_index":1916,"t":{"529":{"position":[[1479,23]]}}}],["black",{"_index":1044,"t":{"227":{"position":[[410,5]]},"1560":{"position":[[330,5]]},"1782":{"position":[[1115,5]]}}}],["blackground",{"_index":1658,"t":{"457":{"position":[[222,11]]}}}],["blank",{"_index":3861,"t":{"1111":{"position":[[983,5]]}}}],["bleu",{"_index":1144,"t":{"283":{"position":[[220,4]]},"319":{"position":[[389,4]]},"322":{"position":[[96,4],[119,4],[272,4]]},"324":{"position":[[280,4]]},"1317":{"position":[[319,4]]},"1321":{"position":[[312,4]]}}}],["blip",{"_index":1612,"t":{"436":{"position":[[1418,5]]},"457":{"position":[[493,4]]},"466":{"position":[[36,4],[116,4]]},"914":{"position":[[197,4],[204,4]]},"967":{"position":[[212,4]]}}}],["block",{"_index":388,"t":{"88":{"position":[[170,5]]},"91":{"position":[[1371,5],[1415,5]]},"234":{"position":[[435,5]]},"504":{"position":[[508,5]]},"598":{"position":[[1912,5],[1992,5],[2096,5]]},"681":{"position":[[1544,5]]},"696":{"position":[[379,5]]},"789":{"position":[[37,6]]},"809":{"position":[[290,6]]},"857":{"position":[[640,5]]},"891":{"position":[[911,5]]},"1341":{"position":[[515,5]]},"1570":{"position":[[178,5]]},"1624":{"position":[[14,6]]}}}],["blog",{"_index":3,"t":{"3":{"position":[[35,4],[87,4]]},"7":{"position":[[11,8],[48,4],[107,4],[131,4],[177,4],[286,4],[334,4],[356,4],[408,5],[450,5]]},"9":{"position":[[0,4],[111,4]]},"1542":{"position":[[167,4]]},"1585":{"position":[[35,4],[57,4]]},"1587":{"position":[[524,4]]}}}],["blog/2021",{"_index":5002,"t":{"1587":{"position":[[17,9],[47,9]]}}}],["bloom",{"_index":1088,"t":{"239":{"position":[[167,5]]},"477":{"position":[[47,6]]}}}],["blue",{"_index":5136,"t":{"1628":{"position":[[548,4]]}}}],["blue</highlight",{"_index":5134,"t":{"1628":{"position":[[485,16]]}}}],["bm2(⋅){\\color{red}{b^{(\\cdot)}_{m2}}}bm2",{"_index":1894,"t":{"527":{"position":[[3123,45]]},"529":{"position":[[1741,44],[1924,44]]}}}],["bm2{\\color{red}{b_m2}}bm​2",{"_index":1918,"t":{"529":{"position":[[1619,26]]}}}],["boat",{"_index":1665,"t":{"457":{"position":[[343,4]]}}}],["bookqa",{"_index":1648,"t":{"455":{"position":[[615,6]]}}}],["boolq",{"_index":2286,"t":{"633":{"position":[[34,5]]},"638":{"position":[[96,5]]},"640":{"position":[[92,6],[289,6]]},"701":{"position":[[54,6]]},"707":{"position":[[103,5]]},"709":{"position":[[346,6]]},"997":{"position":[[412,6]]},"1002":{"position":[[788,5]]},"1004":{"position":[[94,6]]},"1006":{"position":[[1161,5],[1201,5],[1671,5],[1934,5]]},"1031":{"position":[[207,5]]},"1052":{"position":[[274,5]]},"1070":{"position":[[155,5]]},"1084":{"position":[[598,6]]},"1151":{"position":[[1801,5]]},"1181":{"position":[[54,6]]},"1253":{"position":[[155,6]]},"1264":{"position":[[80,6]]},"1364":{"position":[[468,5],[530,5]]},"1429":{"position":[[1442,7]]},"1431":{"position":[[2069,6]]},"1499":{"position":[[620,6]]},"1501":{"position":[[249,6]]}}}],["boost",{"_index":1514,"t":{"376":{"position":[[280,5]]}}}],["borderradiu",{"_index":5124,"t":{"1628":{"position":[[193,13]]}}}],["born",{"_index":3834,"t":{"1105":{"position":[[168,4]]},"1655":{"position":[[1472,4],[1535,4],[1592,4],[1769,4],[1944,4],[2063,4]]}}}],["both",{"_index":3967,"t":{"1147":{"position":[[868,4]]}}}],["botnet",{"_index":192,"t":{"27":{"position":[[133,6]]}}}],["bottleneck",{"_index":1131,"t":{"265":{"position":[[243,10]]},"660":{"position":[[245,10]]},"662":{"position":[[749,10],[1068,10]]},"668":{"position":[[287,11]]},"676":{"position":[[1693,10]]},"727":{"position":[[340,10]]},"1145":{"position":[[2115,10]]},"1159":{"position":[[1186,10]]},"1167":{"position":[[1036,10]]},"1218":{"position":[[303,10]]},"1384":{"position":[[168,10],[190,10],[425,10],[467,10]]},"1393":{"position":[[1000,10]]},"1395":{"position":[[528,10],[811,10],[1187,10]]}}}],["bottom",{"_index":2772,"t":{"786":{"position":[[2769,6]]},"1227":{"position":[[1224,7]]},"1262":{"position":[[76,8]]}}}],["bound",{"_index":579,"t":{"124":{"position":[[222,8]]},"126":{"position":[[408,8]]},"130":{"position":[[52,8],[496,8]]},"140":{"position":[[362,8],[451,8]]},"143":{"position":[[109,8]]},"149":{"position":[[181,8],[240,9]]},"159":{"position":[[714,8]]},"1397":{"position":[[734,6]]}}}],["box",{"_index":580,"t":{"124":{"position":[[231,3]]},"126":{"position":[[417,6]]},"130":{"position":[[61,6],[505,5]]},"140":{"position":[[371,5],[460,3]]},"143":{"position":[[118,3]]},"149":{"position":[[190,3],[250,3]]},"159":{"position":[[723,3]]},"165":{"position":[[108,3],[675,4]]},"174":{"position":[[1369,5]]},"227":{"position":[[416,3]]},"1560":{"position":[[336,3]]},"1782":{"position":[[1121,3]]}}}],["boxinst",{"_index":872,"t":{"177":{"position":[[195,7]]}}}],["bpe",{"_index":1424,"t":{"350":{"position":[[141,5]]}}}],["bq(⋅){\\color{red}{b^{(\\cdot)}_q}}bq",{"_index":1893,"t":{"527":{"position":[[3081,39]]},"529":{"position":[[1699,39],[1882,39]]}}}],["bq{\\color{red}{b_q}}bq",{"_index":1917,"t":{"529":{"position":[[1565,23]]}}}],["brach",{"_index":871,"t":{"177":{"position":[[178,5]]}}}],["bridg",{"_index":2242,"t":{"626":{"position":[[392,6]]},"628":{"position":[[1214,6]]},"630":{"position":[[72,6],[216,6],[708,6],[838,6],[1003,6],[1155,6],[1886,6],[1971,6],[2059,6],[2219,6]]},"633":{"position":[[330,6],[389,6]]},"642":{"position":[[111,6],[153,6],[202,6],[281,6]]},"646":{"position":[[7,6],[245,6],[266,6],[347,6],[413,6],[464,6]]},"650":{"position":[[135,6]]}}}],["britain",{"_index":3781,"t":{"1099":{"position":[[734,7],[799,9]]}}}],["broad",{"_index":4913,"t":{"1546":{"position":[[232,5]]}}}],["broadcast",{"_index":2150,"t":{"598":{"position":[[1010,13]]}}}],["broader",{"_index":3745,"t":{"1087":{"position":[[129,7]]}}}],["brown",{"_index":1578,"t":{"422":{"position":[[50,6]]},"683":{"position":[[285,6]]},"1126":{"position":[[397,6]]},"1409":{"position":[[148,5]]}}}],["brute",{"_index":4670,"t":{"1431":{"position":[[1584,5]]}}}],["bu",{"_index":5405,"t":{"1695":{"position":[[1053,3]]}}}],["bucilua",{"_index":1941,"t":{"531":{"position":[[301,9]]}}}],["budget",{"_index":2742,"t":{"784":{"position":[[346,6],[510,6],[706,6],[936,6]]},"786":{"position":[[2945,7],[3047,6],[3201,6],[3364,6],[3433,6],[3610,6],[4582,6]]},"797":{"position":[[134,6],[2415,6],[2506,6]]},"803":{"position":[[46,6],[144,6],[175,6],[255,6],[295,6],[327,6],[513,6],[626,6]]},"814":{"position":[[42,6],[130,6],[168,6],[294,6]]},"816":{"position":[[4,6],[149,6],[238,6]]},"821":{"position":[[14,6],[127,6]]},"823":{"position":[[5,6],[127,6],[240,6]]},"830":{"position":[[5,6],[118,6]]},"833":{"position":[[13,6],[130,6],[171,6],[207,6],[270,6],[344,6]]},"835":{"position":[[262,6]]},"839":{"position":[[51,6]]},"841":{"position":[[125,6],[379,6]]},"843":{"position":[[88,6],[274,6]]}}}],["buggi",{"_index":4987,"t":{"1581":{"position":[[206,5]]}}}],["build",{"_index":128,"t":{"19":{"position":[[242,6]]},"1570":{"position":[[169,8]]},"1597":{"position":[[65,6]]},"1599":{"position":[[0,5],[40,5],[84,5]]},"1600":{"position":[[21,5],[54,5],[131,5]]},"1640":{"position":[[0,5],[47,5],[71,5],[131,5]]}}}],["busi",{"_index":4338,"t":{"1323":{"position":[[420,9]]}}}],["button",{"_index":71,"t":{"9":{"position":[[123,7]]}}}],["byte",{"_index":1306,"t":{"313":{"position":[[71,4]]},"350":{"position":[[122,4]]}}}],["bytenet",{"_index":1152,"t":{"287":{"position":[[49,8],[187,7]]}}}],["b′a′b'a'b′a",{"_index":2644,"t":{"737":{"position":[[38,12]]},"741":{"position":[[397,12]]}}}],["b∈rd1×rb",{"_index":2761,"t":{"786":{"position":[[1888,8]]},"791":{"position":[[381,8]]}}}],["b∈rd×rb",{"_index":2623,"t":{"733":{"position":[[403,7]]}}}],["b∈rr×db",{"_index":3680,"t":{"1067":{"position":[[355,7]]}}}],["b∗ib_{*i}b∗i",{"_index":2825,"t":{"791":{"position":[[609,13]]}}}],["c",{"_index":411,"t":{"91":{"position":[[261,1],[1716,1]]},"174":{"position":[[2136,1]]},"227":{"position":[[589,1]]},"262":{"position":[[5,3]]},"324":{"position":[[429,3]]},"358":{"position":[[330,1]]},"409":{"position":[[109,1]]},"515":{"position":[[125,2],[128,4],[133,4]]},"891":{"position":[[821,2]]},"893":{"position":[[2376,2]]},"895":{"position":[[984,2]]},"1006":{"position":[[789,3]]},"1665":{"position":[[136,1]]}}}],["c(p,e,q)\\mathcal{c",{"_index":2890,"t":{"797":{"position":[[753,19]]}}}],["c1",{"_index":5449,"t":{"1720":{"position":[[287,3]]}}}],["c1≤c≤c",{"_index":1472,"t":{"358":{"position":[[337,7]]}}}],["c2",{"_index":5464,"t":{"1720":{"position":[[1413,3]]}}}],["c3",{"_index":5466,"t":{"1720":{"position":[[1905,3]]}}}],["c3,c4,c5,c6",{"_index":768,"t":{"170":{"position":[[1081,15]]}}}],["c3​,c4​,c5​,c6",{"_index":773,"t":{"170":{"position":[[1116,19]]}}}],["c4",{"_index":4590,"t":{"1419":{"position":[[152,2],[999,3]]},"1423":{"position":[[519,2]]}}}],["c=1c",{"_index":1051,"t":{"227":{"position":[[632,4]]}}}],["c=3c",{"_index":1053,"t":{"227":{"position":[[655,4]]}}}],["c=64c",{"_index":1058,"t":{"227":{"position":[[821,5]]}}}],["c][ymin​,xmin​,ymax​,xmax​,c",{"_index":607,"t":{"130":{"position":[[656,29]]}}}],["c_3",{"_index":769,"t":{"170":{"position":[[1097,4]]}}}],["c_4",{"_index":770,"t":{"170":{"position":[[1102,4]]}}}],["c_5",{"_index":771,"t":{"170":{"position":[[1107,4]]}}}],["c_6",{"_index":772,"t":{"170":{"position":[[1112,3]]}}}],["c_{c=1}{fctext​}c=1c",{"_index":1427,"t":{"350":{"position":[[283,24]]}}}],["c_{c=1}{vc​}c=1c",{"_index":1483,"t":{"358":{"position":[[782,20]]},"360":{"position":[[76,20]]}}}],["cach",{"_index":1401,"t":{"336":{"position":[[717,5]]},"341":{"position":[[378,5]]},"610":{"position":[[399,7]]},"616":{"position":[[154,7]]}}}],["cai",{"_index":1971,"t":{"531":{"position":[[1445,3]]},"681":{"position":[[532,4]]}}}],["calibr",{"_index":5626,"t":{"1802":{"position":[[0,11]]}}}],["call",{"_index":792,"t":{"170":{"position":[[1768,5]]},"1494":{"position":[[585,7]]},"1597":{"position":[[44,6]]},"1618":{"position":[[44,6]]}}}],["callout",{"_index":5113,"t":{"1626":{"position":[[58,9]]}}}],["caltech101",{"_index":1503,"t":{"374":{"position":[[44,10]]}}}],["candid",{"_index":4687,"t":{"1431":{"position":[[2793,9]]},"1646":{"position":[[986,9]]}}}],["cap",{"_index":3257,"t":{"868":{"position":[[124,3]]},"870":{"position":[[762,3]]}}}],["capabl",{"_index":1829,"t":{"525":{"position":[[811,12],[875,12]]},"1442":{"position":[[1462,12]]}}}],["capac",{"_index":1353,"t":{"322":{"position":[[739,8]]},"934":{"position":[[1882,8]]},"1028":{"position":[[439,8]]},"1126":{"position":[[2068,8]]},"1462":{"position":[[172,8]]}}}],["capit",{"_index":3780,"t":{"1099":{"position":[[723,7],[766,7]]}}}],["caption",{"_index":584,"t":{"124":{"position":[[343,10]]},"126":{"position":[[265,10],[959,10]]},"128":{"position":[[201,10]]},"130":{"position":[[174,10],[1511,10],[1548,7]]},"140":{"position":[[777,10]]},"143":{"position":[[218,8]]},"151":{"position":[[47,10]]},"153":{"position":[[588,10],[638,7],[666,7]]},"155":{"position":[[827,10],[851,10],[937,10]]},"157":{"position":[[108,10],[428,7],[513,10]]},"221":{"position":[[98,11],[834,11]]},"236":{"position":[[313,7]]},"242":{"position":[[54,8],[67,8],[107,9],[135,7]]},"246":{"position":[[6,10],[87,10]]},"249":{"position":[[29,7],[63,7]]},"251":{"position":[[71,10],[185,7]]},"253":{"position":[[73,7],[152,7]]},"255":{"position":[[114,8]]},"271":{"position":[[62,11]]},"339":{"position":[[622,7]]},"436":{"position":[[1137,7]]},"445":{"position":[[193,7],[317,7]]},"449":{"position":[[136,7],[161,7]]},"455":{"position":[[36,9],[539,7],[952,7],[1152,7]]},"457":{"position":[[50,8],[126,7],[318,7],[442,7],[1005,7],[1026,7],[1104,7],[1144,7],[1166,7],[1213,7]]},"459":{"position":[[57,7],[195,7],[265,10]]},"461":{"position":[[63,7]]},"466":{"position":[[12,7],[48,7],[274,7]]},"479":{"position":[[6,7]]},"885":{"position":[[536,7]]},"887":{"position":[[1112,7]]},"912":{"position":[[230,7]]},"914":{"position":[[185,7],[257,7]]},"928":{"position":[[250,7]]},"934":{"position":[[765,7],[807,7],[849,7],[1646,7],[2042,12],[2475,10]]},"942":{"position":[[26,7]]},"949":{"position":[[138,10],[381,10]]},"951":{"position":[[157,10]]},"955":{"position":[[109,10],[281,8],[392,8],[589,7],[613,7]]},"959":{"position":[[74,10],[100,7]]},"965":{"position":[[105,7],[229,10]]},"967":{"position":[[92,7],[135,10],[291,7],[421,10],[525,10]]},"971":{"position":[[106,7]]},"1070":{"position":[[337,7]]},"1780":{"position":[[180,7]]}}}],["captioning/ocr",{"_index":3417,"t":{"932":{"position":[[729,15]]}}}],["captions]\\textup{[al",{"_index":1677,"t":{"459":{"position":[[228,21]]}}}],["captions]}[al",{"_index":1678,"t":{"459":{"position":[[250,14]]}}}],["captur",{"_index":1038,"t":{"225":{"position":[[539,7]]},"786":{"position":[[3543,7]]},"1109":{"position":[[252,7]]},"1126":{"position":[[2282,7]]},"1429":{"position":[[1116,7],[1340,7],[1811,7]]},"1646":{"position":[[100,7]]}}}],["caput",{"_index":2285,"t":{"630":{"position":[[2366,6]]}}}],["car",{"_index":329,"t":{"63":{"position":[[57,4]]}}}],["car_rent",{"_index":5201,"t":{"1653":{"position":[[478,12]]}}}],["carbin",{"_index":1961,"t":{"531":{"position":[[711,7]]},"849":{"position":[[855,7]]},"851":{"position":[[894,6]]}}}],["card",{"_index":5199,"t":{"1653":{"position":[[291,6],[332,6]]}}}],["card_activ",{"_index":5197,"t":{"1653":{"position":[[254,17]]}}}],["card_link",{"_index":5198,"t":{"1653":{"position":[[274,14]]}}}],["care",{"_index":5116,"t":{"1626":{"position":[[133,4],[211,4]]}}}],["case",{"_index":3457,"t":{"967":{"position":[[629,4]]},"1113":{"position":[[10,5],[29,5]]},"1395":{"position":[[286,4]]},"1425":{"position":[[628,4]]},"1427":{"position":[[668,4]]},"1431":{"position":[[2057,5]]},"1442":{"position":[[957,5]]},"1531":{"position":[[112,6],[174,6],[228,6]]}}}],["catastroph",{"_index":5535,"t":{"1750":{"position":[[252,12]]},"1752":{"position":[[289,12]]}}}],["categori",{"_index":724,"t":{"163":{"position":[[116,8]]},"165":{"position":[[124,10],[304,8],[339,8],[1134,10],[1413,8]]},"168":{"position":[[134,8]]},"170":{"position":[[194,8],[332,8]]},"174":{"position":[[1718,8],[1747,8]]},"179":{"position":[[0,8],[43,10]]},"191":{"position":[[248,10]]},"197":{"position":[[76,10]]},"1595":{"position":[[382,11]]}}}],["caus",{"_index":361,"t":{"78":{"position":[[684,7]]}}}],["causal",{"_index":1721,"t":{"483":{"position":[[543,6]]},"496":{"position":[[259,6]]},"500":{"position":[[228,6],[545,6]]},"502":{"position":[[413,6]]},"577":{"position":[[91,7]]},"1111":{"position":[[203,6]]}}}],["caution",{"_index":5148,"t":{"1636":{"position":[[174,7]]}}}],["cb",{"_index":2080,"t":{"594":{"position":[[844,2]]},"633":{"position":[[40,2]]},"640":{"position":[[99,3],[170,3],[296,3]]},"642":{"position":[[33,3]]},"701":{"position":[[61,3]]},"709":{"position":[[353,3],[2239,2]]},"997":{"position":[[419,3]]},"1002":{"position":[[975,4]]},"1004":{"position":[[101,2]]},"1052":{"position":[[310,2]]},"1070":{"position":[[169,2]]},"1084":{"position":[[605,3]]},"1115":{"position":[[1064,3]]},"1181":{"position":[[61,3]]},"1201":{"position":[[402,2]]},"1208":{"position":[[152,4]]},"1253":{"position":[[173,2]]},"1264":{"position":[[87,2]]},"1427":{"position":[[739,2]]},"1429":{"position":[[1503,3]]},"1431":{"position":[[1929,2]]},"1499":{"position":[[611,3]]}}}],["ccc",{"_index":415,"t":{"91":{"position":[[318,3]]},"350":{"position":[[36,3],[346,3],[466,3]]},"358":{"position":[[265,3],[313,3],[531,3],[872,3]]},"441":{"position":[[122,3]]},"891":{"position":[[317,3]]},"1352":{"position":[[1281,3]]}}}],["cd",{"_index":120,"t":{"19":{"position":[[28,2],[60,2]]}}}],["cdec",{"_index":1760,"t":{"502":{"position":[[198,6]]}}}],["cdot",{"_index":410,"t":{"91":{"position":[[255,5],[1710,5]]},"308":{"position":[[709,5]]},"310":{"position":[[1677,5],[1685,5],[1697,5]]},"350":{"position":[[788,6],[795,5]]},"358":{"position":[[832,5],[1294,5]]},"527":{"position":[[1596,5],[1824,5],[1931,5]]},"668":{"position":[[167,5],[184,5],[201,5]]},"696":{"position":[[1362,7]]},"774":{"position":[[828,5]]},"801":{"position":[[2541,5]]},"857":{"position":[[1392,13]]},"893":{"position":[[1818,5]]},"945":{"position":[[597,5],[630,5],[639,5]]},"982":{"position":[[333,6]]},"1296":{"position":[[420,7]]},"1314":{"position":[[318,5]]},"1352":{"position":[[1355,5]]},"1485":{"position":[[170,5]]},"1487":{"position":[[600,5]]},"1538":{"position":[[89,6]]},"1655":{"position":[[555,9]]},"1657":{"position":[[1036,14],[1051,6],[1058,13]]}}}],["cdot)f",{"_index":5194,"t":{"1651":{"position":[[1419,16]]}}}],["cdot)feo",{"_index":5196,"t":{"1651":{"position":[[1495,16]]}}}],["cdot)fes​,eo​​(⋅,{’",{"_index":5228,"t":{"1655":{"position":[[1555,21]]}}}],["cdot)}_{(\\cdot)}}}b",{"_index":1883,"t":{"527":{"position":[[2572,30]]}}}],["cdot)}_{(\\cdot)}}}g(⋅)ℓ​,b",{"_index":1881,"t":{"527":{"position":[[2458,37]]}}}],["cdots;h^{(n)}_{<i}]h<i​=[h<i(1)​;⋯;h<i(n",{"_index":5458,"t":{"1720":{"position":[[769,44]]}}}],["cdots][ykeypoint",{"_index":615,"t":{"130":{"position":[[1282,17]]}}}],["central",{"_index":3978,"t":{"1151":{"position":[[1521,10]]}}}],["cer",{"_index":2312,"t":{"658":{"position":[[878,4]]}}}],["chain",{"_index":1518,"t":{"382":{"position":[[0,5],[105,5]]},"384":{"position":[[737,5],[832,5]]},"537":{"position":[[174,5]]},"539":{"position":[[152,6]]},"583":{"position":[[94,5]]},"1328":{"position":[[380,5]]},"1447":{"position":[[225,5]]}}}],["challeng",{"_index":1360,"t":{"326":{"position":[[95,9]]},"418":{"position":[[16,11]]},"553":{"position":[[185,11]]},"565":{"position":[[129,11]]},"579":{"position":[[44,8]]},"1028":{"position":[[116,9]]},"1303":{"position":[[690,11]]},"1644":{"position":[[341,9]]},"1646":{"position":[[252,9]]}}}],["chang",{"_index":121,"t":{"19":{"position":[[71,7],[464,8]]},"1442":{"position":[[1305,9]]},"1581":{"position":[[61,7]]}}}],["channel",{"_index":767,"t":{"170":{"position":[[853,7],[879,7]]},"227":{"position":[[608,7]]},"895":{"position":[[356,7]]}}}],["character",{"_index":2238,"t":{"622":{"position":[[455,16]]}}}],["chatbot",{"_index":3450,"t":{"959":{"position":[[217,7]]},"963":{"position":[[277,7],[341,7],[373,7],[455,7]]},"973":{"position":[[314,7]]}}}],["chatgpt",{"_index":3454,"t":{"963":{"position":[[581,7]]},"1542":{"position":[[159,7]]},"1575":{"position":[[0,7]]},"1579":{"position":[[0,7]]}}}],["check",{"_index":94,"t":{"15":{"position":[[80,5]]}}}],["checkbox",{"_index":95,"t":{"15":{"position":[[90,10]]}}}],["checkpoint",{"_index":664,"t":{"143":{"position":[[425,10]]},"322":{"position":[[456,10],[534,10]]},"324":{"position":[[132,10]]},"384":{"position":[[440,10],[1098,10]]},"485":{"position":[[1281,10]]},"579":{"position":[[12,10]]},"614":{"position":[[288,10],[377,10]]},"709":{"position":[[259,10]]},"741":{"position":[[257,10]]},"1134":{"position":[[30,11],[91,11],[764,10]]},"1357":{"position":[[249,10]]},"1393":{"position":[[437,10]]},"1421":{"position":[[634,10],[670,10]]},"1427":{"position":[[419,10]]},"1429":{"position":[[287,10],[309,10]]},"1431":{"position":[[1371,10]]},"1492":{"position":[[191,10]]},"1496":{"position":[[164,10],[573,10]]},"1501":{"position":[[169,10]]},"1665":{"position":[[1497,10]]}}}],["chen",{"_index":1962,"t":{"531":{"position":[[725,4]]},"662":{"position":[[1485,5]]},"1354":{"position":[[19,5]]},"1357":{"position":[[90,4]]},"1475":{"position":[[279,4]]},"1665":{"position":[[581,4],[867,4]]}}}],["children",{"_index":5120,"t":{"1628":{"position":[[129,11],[335,13],[353,10]]}}}],["choic",{"_index":1547,"t":{"395":{"position":[[209,6]]},"589":{"position":[[1889,6]]},"594":{"position":[[1167,6],[1262,6]]},"596":{"position":[[407,6],[1074,6],[1112,6],[1228,6],[1253,6],[1304,6],[1473,6],[1493,6],[1925,6]]},"598":{"position":[[4060,7]]},"602":{"position":[[254,7]]},"608":{"position":[[821,6]]},"610":{"position":[[105,6]]},"622":{"position":[[285,6],[342,7]]},"919":{"position":[[171,6]]},"1126":{"position":[[2526,7]]},"1283":{"position":[[101,6]]},"1442":{"position":[[1592,6]]},"1453":{"position":[[402,6]]},"1462":{"position":[[85,6]]},"1708":{"position":[[64,6]]},"1724":{"position":[[426,6]]},"1728":{"position":[[338,6],[694,6]]},"1772":{"position":[[172,6]]}}}],["chowdheri",{"_index":2455,"t":{"683":{"position":[[338,10]]}}}],["cifar",{"_index":325,"t":{"63":{"position":[[27,5],[37,5]]},"65":{"position":[[14,5]]},"102":{"position":[[177,5],[290,5]]}}}],["circ",{"_index":4143,"t":{"1242":{"position":[[649,5],[665,5],[728,7]]},"1244":{"position":[[368,5]]},"1246":{"position":[[719,5]]},"1354":{"position":[[472,5]]}}}],["citi",{"_index":5305,"t":{"1659":{"position":[[191,6],[222,6]]}}}],["cl",{"_index":1395,"t":{"336":{"position":[[244,6]]},"341":{"position":[[63,7]]},"350":{"position":[[96,6]]},"356":{"position":[[49,6]]},"368":{"position":[[222,6]]},"498":{"position":[[355,5]]},"1052":{"position":[[196,5],[367,5]]},"1099":{"position":[[576,5]]},"1111":{"position":[[1884,5]]},"1185":{"position":[[39,5],[243,6],[359,5]]}}}],["cla",{"_index":5390,"t":{"1689":{"position":[[17,4]]}}}],["class",{"_index":425,"t":{"91":{"position":[[763,5]]},"97":{"position":[[179,5]]},"126":{"position":[[424,5]]},"130":{"position":[[68,5]]},"143":{"position":[[631,5]]},"145":{"position":[[53,5]]},"168":{"position":[[61,5],[168,5]]},"170":{"position":[[236,5]]},"193":{"position":[[19,5]]},"195":{"position":[[69,5]]},"253":{"position":[[51,6]]},"336":{"position":[[1255,5]]},"341":{"position":[[15,5]]},"350":{"position":[[40,5],[186,5]]},"358":{"position":[[269,7],[307,5],[525,5],[849,5],[879,5]]},"360":{"position":[[135,5]]},"531":{"position":[[1180,5]]},"666":{"position":[[216,5]]},"670":{"position":[[97,5]]},"1082":{"position":[[77,5]]},"1128":{"position":[[85,5],[222,5],[305,5]]},"1130":{"position":[[477,7],[629,7]]},"1134":{"position":[[197,5]]},"1141":{"position":[[313,5],[366,5],[446,5],[548,5],[656,5],[759,5],[790,5]]},"1143":{"position":[[808,5]]},"1145":{"position":[[1075,5]]},"1151":{"position":[[1164,6],[1194,5],[1374,5],[1463,7],[1499,5]]},"1159":{"position":[[512,7]]},"1162":{"position":[[211,7]]},"1187":{"position":[[122,5]]},"1244":{"position":[[1272,5]]},"1546":{"position":[[238,5]]},"1644":{"position":[[180,5],[292,5],[721,5]]},"1646":{"position":[[814,5],[1293,5],[1342,7],[1370,7],[1448,5],[1914,5],[2706,5],[3149,5]]},"1649":{"position":[[5,5]]},"1653":{"position":[[534,5]]},"1657":{"position":[[2340,5],[2474,7]]},"1659":{"position":[[53,5],[137,5],[172,5],[423,5]]},"1665":{"position":[[996,5]]},"1672":{"position":[[222,7],[321,7]]},"1706":{"position":[[169,5]]},"1728":{"position":[[649,5]]},"1732":{"position":[[70,5]]},"1790":{"position":[[5,5],[34,5]]}}}],["classfic",{"_index":3880,"t":{"1128":{"position":[[239,13]]},"1655":{"position":[[2110,13]]}}}],["classic",{"_index":99,"t":{"17":{"position":[[41,7],[63,7],[189,7]]},"1126":{"position":[[2367,7]]}}}],["classif",{"_index":199,"t":{"27":{"position":[[400,15]]},"91":{"position":[[994,14],[1038,14],[2477,14]]},"215":{"position":[[140,14]]},"221":{"position":[[852,15]]},"246":{"position":[[184,14]]},"253":{"position":[[97,14]]},"271":{"position":[[85,14]]},"336":{"position":[[1908,14]]},"343":{"position":[[186,15]]},"374":{"position":[[12,14]]},"525":{"position":[[133,14]]},"527":{"position":[[117,14],[405,9]]},"589":{"position":[[1863,14]]},"594":{"position":[[1067,15],[1208,14],[1236,14]]},"596":{"position":[[441,14],[1027,14],[1376,14]]},"622":{"position":[[591,14]]},"658":{"position":[[135,14],[2919,14],[3219,14]]},"664":{"position":[[154,14]]},"666":{"position":[[64,14],[148,15]]},"670":{"position":[[44,14]]},"672":{"position":[[274,14]]},"674":{"position":[[17,14],[593,14]]},"676":{"position":[[1303,14]]},"812":{"position":[[100,14]]},"861":{"position":[[880,14]]},"866":{"position":[[238,14]]},"924":{"position":[[6,14]]},"1008":{"position":[[559,14]]},"1017":{"position":[[27,14]]},"1019":{"position":[[799,14]]},"1033":{"position":[[108,14]]},"1037":{"position":[[160,14]]},"1045":{"position":[[121,14]]},"1099":{"position":[[508,14]]},"1126":{"position":[[298,15],[1422,14]]},"1128":{"position":[[108,14]]},"1130":{"position":[[298,14],[370,14]]},"1145":{"position":[[1133,14]]},"1162":{"position":[[82,14]]},"1187":{"position":[[54,14]]},"1283":{"position":[[79,15]]},"1419":{"position":[[506,14]]},"1442":{"position":[[981,14]]},"1644":{"position":[[129,14],[186,14],[298,14],[370,14],[652,15],[691,14],[727,14]]},"1646":{"position":[[478,15],[879,14],[1073,14],[1299,14],[1454,14],[1485,14],[1920,14],[1990,14],[2306,14],[2521,14],[3079,15],[3118,14],[3155,14],[3281,14]]},"1649":{"position":[[11,14]]},"1651":{"position":[[48,14],[322,14],[976,14]]},"1653":{"position":[[103,14],[233,14],[540,14],[575,14],[646,14],[744,15],[783,14]]},"1655":{"position":[[177,14],[404,14],[1376,14],[2177,14]]},"1663":{"position":[[16,14],[95,15]]},"1665":{"position":[[9,14],[84,14],[252,14],[794,14]]},"1678":{"position":[[20,14]]},"1682":{"position":[[7,14],[345,14],[479,14],[721,14],[861,14]]},"1684":{"position":[[231,14],[780,14]]},"1689":{"position":[[27,14],[266,15],[305,14]]},"1698":{"position":[[250,14]]},"1712":{"position":[[284,14]]},"1714":{"position":[[333,14],[533,14]]},"1720":{"position":[[2455,14]]},"1724":{"position":[[272,14]]},"1728":{"position":[[290,14]]},"1736":{"position":[[983,14]]},"1766":{"position":[[0,14],[207,14],[417,14],[514,14]]},"1768":{"position":[[22,14],[156,14]]},"1788":{"position":[[13,14],[74,14]]},"1790":{"position":[[11,14],[103,14]]}}}],["classifi",{"_index":744,"t":{"165":{"position":[[1027,10],[2344,10]]},"174":{"position":[[2536,11]]},"512":{"position":[[138,10]]},"525":{"position":[[166,10],[237,13]]},"681":{"position":[[431,10]]},"1730":{"position":[[867,10],[905,10]]}}}],["clean",{"_index":4592,"t":{"1419":{"position":[[165,5]]}}}],["clear",{"_index":4305,"t":{"1305":{"position":[[1199,5]]}}}],["click",{"_index":76,"t":{"9":{"position":[[191,5]]},"1628":{"position":[[297,7]]}}}],["clicked!')}>click",{"_index":74,"t":{"9":{"position":[[160,17]]}}}],["clinc150",{"_index":5373,"t":{"1680":{"position":[[35,8]]}}}],["clip",{"_index":1055,"t":{"227":{"position":[[745,4]]},"239":{"position":[[103,5]]},"334":{"position":[[0,4],[183,4],[379,4],[570,4]]},"336":{"position":[[4,4],[221,4],[427,4],[619,4],[732,4],[953,4],[1156,4],[1549,4],[1812,4],[1935,4]]},"339":{"position":[[79,4],[548,4]]},"341":{"position":[[224,4],[401,4]]},"347":{"position":[[124,5],[580,4]]},"350":{"position":[[4,4],[75,4],[213,4],[388,4],[743,4]]},"352":{"position":[[11,4],[192,4],[229,4],[627,4]]},"354":{"position":[[0,4],[127,4],[273,4],[314,4]]},"356":{"position":[[4,4]]},"358":{"position":[[4,4],[197,5],[695,4],[805,4]]},"360":{"position":[[99,4],[180,4]]},"362":{"position":[[3,4]]},"366":{"position":[[15,4],[66,4],[260,4],[359,5]]},"368":{"position":[[0,4],[68,4]]},"376":{"position":[[69,4],[170,4],[218,4],[253,4]]},"378":{"position":[[70,4],[103,4]]},"895":{"position":[[208,4]]},"912":{"position":[[65,4]]},"940":{"position":[[79,4]]},"1070":{"position":[[1220,4],[1250,4],[1357,4],[1504,4]]}}}],["clipcap",{"_index":1697,"t":{"468":{"position":[[208,7]]},"914":{"position":[[269,7]]}}}],["clipclap",{"_index":1708,"t":{"475":{"position":[[195,8]]}}}],["clm",{"_index":1732,"t":{"490":{"position":[[120,3]]},"494":{"position":[[235,5],[294,5]]},"510":{"position":[[27,5]]},"517":{"position":[[583,3],[709,5],[786,4],[839,4],[895,3]]}}}],["close",{"_index":1111,"t":{"246":{"position":[[258,6],[432,5],[543,5]]},"965":{"position":[[48,5]]},"1423":{"position":[[925,5]]},"1622":{"position":[[289,5]]},"1702":{"position":[[631,5]]},"1712":{"position":[[3,5],[176,5],[236,5]]},"1714":{"position":[[110,5]]},"1724":{"position":[[147,5]]},"1746":{"position":[[64,5]]},"1762":{"position":[[154,5]]},"1766":{"position":[[235,5],[537,5]]}}}],["cloud",{"_index":1796,"t":{"517":{"position":[[437,5]]},"666":{"position":[[365,5]]}}}],["cloze",{"_index":2078,"t":{"594":{"position":[[794,5]]},"1105":{"position":[[129,5]]},"1117":{"position":[[203,5]]},"1130":{"position":[[336,5]]},"1494":{"position":[[332,5]]},"1646":{"position":[[346,5],[901,5]]},"1714":{"position":[[299,5]]}}}],["cls]\\text{[cls]}[cl",{"_index":3206,"t":{"859":{"position":[[392,22]]}}}],["cluster",{"_index":3975,"t":{"1151":{"position":[[491,8],[763,7],[976,7],[995,7],[1122,10]]},"1425":{"position":[[423,7]]},"1429":{"position":[[1256,9]]}}}],["cnn",{"_index":376,"t":{"84":{"position":[[68,3]]},"86":{"position":[[9,3],[65,3]]},"88":{"position":[[377,3],[451,3],[495,3],[611,3]]},"93":{"position":[[0,3],[89,4]]},"95":{"position":[[34,3],[127,3],[288,3]]},"104":{"position":[[203,3]]},"110":{"position":[[22,3]]},"116":{"position":[[361,3],[711,3],[798,3]]},"153":{"position":[[57,3],[121,3],[146,3],[355,3],[459,3],[555,3]]},"283":{"position":[[57,3]]},"287":{"position":[[14,3],[772,3]]},"531":{"position":[[1411,3]]}}}],["cnn/dailymail",{"_index":2789,"t":{"786":{"position":[[4538,14]]},"805":{"position":[[127,14]]},"826":{"position":[[108,14]]},"828":{"position":[[171,13]]}}}],["co",{"_index":55,"t":{"7":{"position":[[324,2]]},"1111":{"position":[[179,2]]},"1587":{"position":[[150,2]]}}}],["coars",{"_index":787,"t":{"170":{"position":[[1516,6],[1719,6]]},"457":{"position":[[749,6]]}}}],["coco",{"_index":655,"t":{"143":{"position":[[34,4],[444,4],[488,4]]},"157":{"position":[[141,4]]},"170":{"position":[[264,4]]},"177":{"position":[[563,4],[1204,5]]},"185":{"position":[[10,4]]},"201":{"position":[[37,6]]},"242":{"position":[[15,4]]},"249":{"position":[[24,4],[58,4]]},"885":{"position":[[531,4]]},"887":{"position":[[1107,4]]},"912":{"position":[[225,4]]},"914":{"position":[[180,4]]},"928":{"position":[[245,4]]},"934":{"position":[[760,4]]},"942":{"position":[[21,4]]},"955":{"position":[[608,4]]},"959":{"position":[[95,4]]},"967":{"position":[[87,4]]},"1077":{"position":[[24,5]]}}}],["code",{"_index":114,"t":{"17":{"position":[[307,4]]},"80":{"position":[[85,4]]},"298":{"position":[[920,4]]},"483":{"position":[[3,4],[319,4],[474,4],[527,4],[713,4],[804,4],[859,4],[886,4]]},"485":{"position":[[229,4],[332,4],[387,4],[1126,4],[1252,4],[1569,4]]},"488":{"position":[[0,4],[51,4],[308,4]]},"490":{"position":[[84,4],[157,4]]},"496":{"position":[[19,4],[64,4],[72,4]]},"498":{"position":[[17,4],[78,4],[109,4],[158,4],[230,4],[433,4]]},"500":{"position":[[33,4],[86,4],[181,4],[417,4],[464,4],[515,4],[655,4],[795,4]]},"502":{"position":[[46,4],[53,4],[238,4],[288,4],[425,4]]},"508":{"position":[[34,4],[130,4],[155,4]]},"510":{"position":[[230,4]]},"512":{"position":[[194,4],[224,4]]},"515":{"position":[[14,4],[500,4],[520,4],[806,4],[829,4]]},"1109":{"position":[[973,6]]},"1440":{"position":[[522,7],[596,6]]},"1442":{"position":[[2274,4]]},"1462":{"position":[[319,4]]},"1624":{"position":[[9,4]]}}}],["code/text",{"_index":1756,"t":{"500":{"position":[[1103,9]]}}}],["codegen",{"_index":1788,"t":{"517":{"position":[[124,7],[174,7],[223,7],[377,7]]}}}],["codesearchnet",{"_index":1772,"t":{"515":{"position":[[30,13],[231,13],[449,13],[584,13],[725,13]]}}}],["codet",{"_index":1728,"t":{"485":{"position":[[1661,6]]},"490":{"position":[[4,6]]}}}],["codet5",{"_index":1716,"t":{"483":{"position":[[358,7],[605,7],[698,7]]},"485":{"position":[[1172,7],[1223,7],[1584,7]]},"488":{"position":[[63,7],[101,7]]},"504":{"position":[[45,7]]},"506":{"position":[[22,7]]},"508":{"position":[[24,7]]},"510":{"position":[[258,7]]},"512":{"position":[[0,7]]},"515":{"position":[[378,6],[709,6],[755,7]]},"517":{"position":[[4,7],[41,7],[92,7],[244,7],[363,6],[460,8],[1151,7],[1230,7]]}}}],["codex",{"_index":1561,"t":{"397":{"position":[[105,5]]}}}],["coeffici",{"_index":2902,"t":{"797":{"position":[[1106,11]]},"814":{"position":[[446,11]]},"1659":{"position":[[1083,11]]}}}],["coffe",{"_index":4233,"t":{"1291":{"position":[[1044,6],[1109,8]]}}}],["coin",{"_index":1584,"t":{"424":{"position":[[221,4]]}}}],["cola",{"_index":2402,"t":{"672":{"position":[[535,4],[991,4],[1195,4]]},"676":{"position":[[127,4],[384,4],[1163,4]]},"835":{"position":[[219,5]]},"866":{"position":[[997,4]]},"997":{"position":[[447,5]]},"1002":{"position":[[774,4]]},"1070":{"position":[[132,4]]},"1253":{"position":[[188,5]]},"1393":{"position":[[37,7]]},"1395":{"position":[[914,6],[1851,5]]},"1397":{"position":[[615,4]]}}}],["collect",{"_index":1877,"t":{"527":{"position":[[2304,10]]},"594":{"position":[[1045,10]]}}}],["coloc",{"_index":5102,"t":{"1622":{"position":[[273,8]]}}}],["color",{"_index":5121,"t":{"1628":{"position":[[141,7],[186,6],[215,6],[309,5],[315,8]]}}}],["color=\"#1877f2\">facebook",{"_index":5133,"t":{"1628":{"position":[[460,24]]}}}],["color=\"#25c2a0\">docusauru",{"_index":5131,"t":{"1628":{"position":[[394,26]]}}}],["color{blue}{g^\\ell_{ln_1",{"_index":1861,"t":{"527":{"position":[[1661,29]]}}}],["color{blue}{g^\\ell_{ln_2",{"_index":1873,"t":{"527":{"position":[[2000,30]]}}}],["color{blue}{w^{m",{"_index":1843,"t":{"527":{"position":[[733,19],[815,19],[897,19]]}}}],["color{red}{b^\\ell_{ln_1",{"_index":1865,"t":{"527":{"position":[[1737,32]]}}}],["color{red}{b^\\ell_{ln_2",{"_index":1875,"t":{"527":{"position":[[2084,30]]}}}],["color{red}{b^\\ell_{m1",{"_index":1859,"t":{"527":{"position":[[1614,29]]}}}],["color{red}{b^\\ell_{m2",{"_index":1868,"t":{"527":{"position":[[1842,31]]}}}],["color{red}{b^\\ell_{m3",{"_index":1871,"t":{"527":{"position":[[1949,31]]}}}],["color{red}{b^{\\el",{"_index":1880,"t":{"527":{"position":[[2436,21]]}}}],["color{red}{b^{m",{"_index":1845,"t":{"527":{"position":[[766,18],[848,18],[930,18]]}}}],["coloss",{"_index":4591,"t":{"1419":{"position":[[155,9]]}}}],["column",{"_index":2273,"t":{"630":{"position":[[1604,7]]},"696":{"position":[[842,8]]},"774":{"position":[[809,7]]},"791":{"position":[[638,7]]},"1307":{"position":[[438,6]]}}}],["comapr",{"_index":3982,"t":{"1153":{"position":[[70,10]]}}}],["comb",{"_index":3640,"t":{"1045":{"position":[[46,7]]}}}],["combin",{"_index":392,"t":{"88":{"position":[[365,11]]},"310":{"position":[[693,11]]},"608":{"position":[[872,8]]},"709":{"position":[[615,12]]},"713":{"position":[[98,11]]},"979":{"position":[[710,11]]},"1093":{"position":[[352,9]]},"1425":{"position":[[333,12]]}}}],["command",{"_index":104,"t":{"17":{"position":[[142,8],[215,7],[228,7],[324,7]]},"19":{"position":[[63,7],[234,7]]}}}],["comment",{"_index":8,"t":{"3":{"position":[[70,7]]}}}],["common",{"_index":2061,"t":{"589":{"position":[[140,6]]},"776":{"position":[[198,6]]},"853":{"position":[[373,6]]},"1141":{"position":[[233,8]]},"1143":{"position":[[860,6]]},"1442":{"position":[[942,6]]},"1802":{"position":[[324,6]]}}}],["commons",{"_index":1607,"t":{"436":{"position":[[366,11]]}}}],["commonsens",{"_index":1525,"t":{"382":{"position":[[202,11]]},"384":{"position":[[78,11],[880,11]]},"386":{"position":[[376,11]]},"426":{"position":[[129,11]]},"430":{"position":[[73,11]]},"997":{"position":[[126,11]]},"1283":{"position":[[147,11]]},"1419":{"position":[[777,11]]},"1429":{"position":[[1585,11]]},"1770":{"position":[[90,11]]}}}],["commonsenseqa",{"_index":1649,"t":{"455":{"position":[[622,13]]}}}],["commun",{"_index":5000,"t":{"1583":{"position":[[258,9]]}}}],["compact",{"_index":2184,"t":{"598":{"position":[[3256,9],[3268,11],[3907,9],[3919,11]]},"658":{"position":[[385,7],[457,7],[2536,7]]},"672":{"position":[[1293,7]]},"1002":{"position":[[670,10]]},"1004":{"position":[[79,9]]}}}],["compar",{"_index":1891,"t":{"527":{"position":[[2939,10]]},"626":{"position":[[540,10]]},"633":{"position":[[553,10]]},"638":{"position":[[78,10]]},"640":{"position":[[66,10],[249,10]]},"644":{"position":[[61,10]]},"648":{"position":[[237,10]]},"650":{"position":[[248,10]]},"786":{"position":[[746,10]]},"887":{"position":[[720,10],[1127,10]]},"907":{"position":[[55,10]]},"928":{"position":[[52,10],[260,10]]},"940":{"position":[[351,10]]},"967":{"position":[[219,10]]},"1014":{"position":[[1083,10]]},"1019":{"position":[[838,10]]},"1024":{"position":[[71,10]]},"1047":{"position":[[343,10],[443,10]]},"1056":{"position":[[87,10]]},"1093":{"position":[[1643,10]]},"1113":{"position":[[315,10],[410,11],[585,10]]},"1120":{"position":[[252,10]]},"1124":{"position":[[371,10]]},"1126":{"position":[[1960,10],[2505,10]]},"1136":{"position":[[387,10]]},"1153":{"position":[[150,10]]},"1317":{"position":[[186,10],[400,10]]},"1347":{"position":[[162,10]]},"1379":{"position":[[237,10]]},"1393":{"position":[[633,8]]},"1395":{"position":[[1707,10]]},"1409":{"position":[[621,10],[949,10]]},"1468":{"position":[[1598,10]]},"1689":{"position":[[397,10]]}}}],["comparison",{"_index":1899,"t":{"529":{"position":[[269,10]]}}}],["compat",{"_index":1187,"t":{"296":{"position":[[173,14]]},"298":{"position":[[812,13]]}}}],["competit",{"_index":999,"t":{"215":{"position":[[1124,11]]},"521":{"position":[[168,11],[238,11]]},"979":{"position":[[921,11],[1666,11]]},"1060":{"position":[[230,11]]},"1136":{"position":[[205,11]]},"1384":{"position":[[2565,11]]},"1395":{"position":[[2727,11]]},"1434":{"position":[[279,11]]},"1466":{"position":[[574,11]]},"1468":{"position":[[439,11]]},"1473":{"position":[[687,11]]},"1494":{"position":[[261,11]]}}}],["compil",{"_index":4718,"t":{"1442":{"position":[[1701,8]]}}}],["complementar",{"_index":5583,"t":{"1782":{"position":[[89,20]]}}}],["complet",{"_index":1771,"t":{"510":{"position":[[235,10]]},"594":{"position":[[761,10]]},"849":{"position":[[304,8]]},"1151":{"position":[[788,10],[847,10],[914,10]]}}}],["complex",{"_index":1523,"t":{"382":{"position":[[69,7]]},"569":{"position":[[66,7],[141,8]]},"579":{"position":[[172,8]]},"1060":{"position":[[375,10],[526,10]]},"1062":{"position":[[805,10]]},"1067":{"position":[[1251,10]]},"1653":{"position":[[638,7]]},"1655":{"position":[[2157,7]]}}}],["complic",{"_index":2975,"t":{"801":{"position":[[1442,11]]}}}],["compon",{"_index":1032,"t":{"221":{"position":[[787,10]]},"227":{"position":[[117,10]]},"255":{"position":[[47,9]]},"271":{"position":[[37,10]]},"324":{"position":[[18,10]]},"483":{"position":[[271,9]]},"504":{"position":[[55,9]]},"523":{"position":[[749,10]]},"839":{"position":[[12,10],[534,9]]},"893":{"position":[[1090,9],[1667,9]]},"1006":{"position":[[1036,10]]},"1067":{"position":[[124,10]]},"1244":{"position":[[72,9]]},"1273":{"position":[[158,10],[295,9]]},"1275":{"position":[[25,9]]},"1279":{"position":[[66,9],[171,9],[260,9]]},"1285":{"position":[[279,9]]},"1447":{"position":[[426,9]]},"1449":{"position":[[32,9]]},"1453":{"position":[[300,10]]},"1455":{"position":[[609,9]]},"1462":{"position":[[293,9]]},"1628":{"position":[[76,10]]}}}],["composit",{"_index":3587,"t":{"999":{"position":[[904,11]]},"1740":{"position":[[7,11],[70,9]]},"1794":{"position":[[392,11],[628,11]]}}}],["comprehens",{"_index":733,"t":{"163":{"position":[[695,14]]},"165":{"position":[[409,13]]},"287":{"position":[[439,14]]},"947":{"position":[[155,13]]}}}],["compress",{"_index":1937,"t":{"531":{"position":[[75,11]]},"1234":{"position":[[58,12]]},"1487":{"position":[[1143,11]]},"1517":{"position":[[168,11]]}}}],["comput",{"_index":305,"t":{"55":{"position":[[16,9]]},"124":{"position":[[35,8],[129,8]]},"126":{"position":[[308,8],[342,8]]},"128":{"position":[[4,8]]},"405":{"position":[[179,7]]},"504":{"position":[[122,7]]},"533":{"position":[[290,11]]},"567":{"position":[[748,7]]},"587":{"position":[[450,13]]},"589":{"position":[[2249,7]]},"592":{"position":[[35,13],[119,13]]},"598":{"position":[[291,13],[2957,13]]},"608":{"position":[[533,13]]},"610":{"position":[[416,13]]},"622":{"position":[[43,13],[424,13]]},"648":{"position":[[999,7]]},"679":{"position":[[475,11]]},"681":{"position":[[1615,11],[1953,11]]},"692":{"position":[[65,11]]},"696":{"position":[[692,11],[1241,11]]},"711":{"position":[[240,11]]},"784":{"position":[[733,12]]},"786":{"position":[[1314,11],[3596,13],[4296,12]]},"795":{"position":[[1431,11],[1450,13]]},"1303":{"position":[[1041,11]]}}}],["computation",{"_index":4286,"t":{"1303":{"position":[[674,15]]},"1471":{"position":[[248,15]]}}}],["concat[e([cl",{"_index":4047,"t":{"1185":{"position":[[122,16]]}}}],["concat[p",{"_index":4058,"t":{"1187":{"position":[[272,10]]}}}],["concaten",{"_index":1210,"t":{"300":{"position":[[372,18]]},"424":{"position":[[153,13]]}}}],["conceptnet",{"_index":1616,"t":{"439":{"position":[[189,10]]}}}],["conceptu",{"_index":1093,"t":{"242":{"position":[[43,10],[76,10]]},"255":{"position":[[103,10]]}}}],["conclus",{"_index":3744,"t":{"1087":{"position":[[0,11]]}}}],["concret",{"_index":3099,"t":{"851":{"position":[[686,8]]}}}],["condid",{"_index":1450,"t":{"352":{"position":[[509,10]]}}}],["condit",{"_index":1079,"t":{"236":{"position":[[334,12]]},"662":{"position":[[1386,11]]},"1126":{"position":[[804,12]]},"1128":{"position":[[166,11],[431,9],[1246,11]]},"1143":{"position":[[120,9]]},"1187":{"position":[[76,11]]},"1238":{"position":[[218,11]]},"1409":{"position":[[577,12]]},"1466":{"position":[[60,12]]},"1473":{"position":[[616,11]]},"1651":{"position":[[418,11],[1616,11]]},"1698":{"position":[[481,11]]}}}],["condition",{"_index":4438,"t":{"1369":{"position":[[89,13]]}}}],["conference.pdf",{"_index":1517,"t":{"380":{"position":[[112,14]]}}}],["confid",{"_index":1369,"t":{"326":{"position":[[392,10]]},"336":{"position":[[1385,10]]},"347":{"position":[[237,10],[346,10]]},"352":{"position":[[163,9],[635,10],[755,9]]},"368":{"position":[[261,9]]},"988":{"position":[[1866,9]]}}}],["config",{"_index":65,"t":{"7":{"position":[[481,7]]}}}],["configur",{"_index":3929,"t":{"1134":{"position":[[137,13]]},"1583":{"position":[[49,13]]}}}],["congratul",{"_index":5020,"t":{"1587":{"position":[[408,16]]}}}],["coninu",{"_index":3953,"t":{"1145":{"position":[[1287,9]]}}}],["conjunct",{"_index":5249,"t":{"1657":{"position":[[497,11]]}}}],["conll03",{"_index":1007,"t":{"215":{"position":[[2227,7]]}}}],["conll04",{"_index":3633,"t":{"1031":{"position":[[151,8]]}}}],["conll12",{"_index":3634,"t":{"1031":{"position":[[215,8]]}}}],["connect",{"_index":440,"t":{"91":{"position":[[1437,10]]},"234":{"position":[[293,10]]},"265":{"position":[[60,10]]},"289":{"position":[[485,9]]},"292":{"position":[[126,9],[180,10],[394,10]]},"294":{"position":[[202,10]]},"304":{"position":[[81,9]]},"436":{"position":[[1523,7]]},"633":{"position":[[741,10]]},"662":{"position":[[469,10],[593,10],[660,10],[1171,10],[1187,10]]},"683":{"position":[[977,10]]},"703":{"position":[[312,10]]},"755":{"position":[[26,10],[82,9]]},"789":{"position":[[117,9],[1091,10]]},"809":{"position":[[424,10]]},"853":{"position":[[43,9]]},"1157":{"position":[[259,10]]},"1159":{"position":[[1359,10]]},"1167":{"position":[[32,10],[434,10]]},"1170":{"position":[[13,10],[273,10]]},"1195":{"position":[[413,10],[455,10],[506,10]]},"1208":{"position":[[22,10]]},"1221":{"position":[[266,10],[302,10],[391,10],[460,10]]},"1384":{"position":[[317,10]]},"1389":{"position":[[1221,10]]},"1591":{"position":[[30,9]]}}}],["connet",{"_index":166,"t":{"25":{"position":[[161,7]]}}}],["consectetur",{"_index":18,"t":{"3":{"position":[[148,11],[327,11],[506,11],[685,11],[864,11],[1043,11],[1222,11],[1401,11],[1580,11],[1759,11],[1938,11],[2117,11],[2296,11],[2475,11],[2654,11],[2833,11]]},"5":{"position":[[28,11]]}}}],["consequat",{"_index":30,"t":{"3":{"position":[[261,10],[440,10],[619,10],[798,10],[977,10],[1156,10],[1335,10],[1514,10],[1693,10],[1872,10],[2051,10],[2230,10],[2409,10],[2588,10],[2767,10],[2946,10]]},"5":{"position":[[141,10]]}}}],["consist",{"_index":2018,"t":{"561":{"position":[[107,12]]}}}],["const",{"_index":5119,"t":{"1628":{"position":[[111,5]]}}}],["constant",{"_index":3602,"t":{"1006":{"position":[[712,8],[1180,8]]},"1389":{"position":[[2070,8]]}}}],["constrain",{"_index":2468,"t":{"688":{"position":[[55,11]]},"1728":{"position":[[264,11]]}}}],["construct",{"_index":5580,"t":{"1778":{"position":[[782,12]]}}}],["cont",{"_index":2024,"t":{"567":{"position":[[206,4]]}}}],["contain",{"_index":5573,"t":{"1778":{"position":[[392,8]]}}}],["content",{"_index":3458,"t":{"969":{"position":[[21,7]]},"971":{"position":[[167,8]]},"1132":{"position":[[206,7]]},"1321":{"position":[[463,7]]},"1634":{"position":[[86,7],[151,7],[217,7]]}}}],["context",{"_index":815,"t":{"172":{"position":[[140,8]]},"253":{"position":[[202,7]]},"273":{"position":[[13,7],[109,7]]},"384":{"position":[[381,7]]},"393":{"position":[[35,7]]},"445":{"position":[[212,7],[355,7],[388,7]]},"447":{"position":[[419,7],[712,7]]},"449":{"position":[[16,7]]},"455":{"position":[[227,8],[397,7],[772,7]]},"459":{"position":[[185,9],[212,10]]},"488":{"position":[[433,7]]},"490":{"position":[[162,7]]},"494":{"position":[[70,7]]},"500":{"position":[[603,7]]},"510":{"position":[[68,7]]},"569":{"position":[[56,9]]},"587":{"position":[[12,7]]},"589":{"position":[[512,7]]},"608":{"position":[[957,7]]},"610":{"position":[[347,7]]},"614":{"position":[[152,7]]},"696":{"position":[[293,7]]},"723":{"position":[[154,7]]},"895":{"position":[[150,7],[1050,7]]},"955":{"position":[[532,7],[579,7]]},"963":{"position":[[253,7]]},"969":{"position":[[126,7],[228,7]]},"971":{"position":[[82,8]]},"1099":{"position":[[324,7],[612,7],[791,7],[834,7]]},"1151":{"position":[[1979,7]]},"1159":{"position":[[1159,7]]},"1291":{"position":[[651,7],[687,7],[841,7],[883,7]]},"1294":{"position":[[12,7]]},"1296":{"position":[[616,7]]},"1298":{"position":[[199,7]]},"1303":{"position":[[50,7],[123,7],[268,7],[287,7],[443,7],[565,7]]},"1305":{"position":[[1287,7]]},"1442":{"position":[[435,7]]},"1447":{"position":[[404,7]]},"1449":{"position":[[122,7]]},"1453":{"position":[[314,7]]},"1455":{"position":[[722,7]]},"1471":{"position":[[79,7]]},"1560":{"position":[[22,7]]},"1738":{"position":[[817,7],[964,7]]},"1752":{"position":[[131,7],[389,7]]},"1764":{"position":[[178,7]]},"1772":{"position":[[26,7],[123,7],[349,7]]},"1774":{"position":[[210,7]]},"1782":{"position":[[672,7],[834,7]]},"1802":{"position":[[434,7],[838,7],[1256,7]]}}}],["context]\\textup{[context]}[context",{"_index":1645,"t":{"455":{"position":[[236,37],[358,36],[478,36]]}}}],["contextsquestionoptionansw",{"_index":3369,"t":{"895":{"position":[[114,28]]},"912":{"position":[[258,28]]}}}],["contextu",{"_index":1633,"t":{"447":{"position":[[264,10]]},"525":{"position":[[80,14]]},"688":{"position":[[230,10]]},"694":{"position":[[770,10]]},"698":{"position":[[212,10]]},"891":{"position":[[952,10]]},"1145":{"position":[[518,13]]},"1730":{"position":[[817,14]]}}}],["contigu",{"_index":1292,"t":{"310":{"position":[[1385,10]]}}}],["continu",{"_index":995,"t":{"215":{"position":[[1059,10]]},"289":{"position":[[152,10]]},"336":{"position":[[580,10]]},"341":{"position":[[163,10]]},"343":{"position":[[466,10],[609,10]]},"356":{"position":[[252,10]]},"358":{"position":[[350,10]]},"498":{"position":[[279,10]]},"567":{"position":[[627,9],[690,9]]},"633":{"position":[[859,10]]},"658":{"position":[[2485,9],[2608,9]]},"676":{"position":[[186,10]]},"681":{"position":[[911,10]]},"1012":{"position":[[54,10]]},"1014":{"position":[[754,10],[845,10],[1286,10],[1328,10]]},"1019":{"position":[[525,10],[557,10]]},"1028":{"position":[[37,10]]},"1035":{"position":[[49,10]]},"1039":{"position":[[240,10]]},"1045":{"position":[[144,10]]},"1054":{"position":[[62,10]]},"1060":{"position":[[18,12]]},"1062":{"position":[[262,10]]},"1091":{"position":[[111,10]]},"1093":{"position":[[853,10],[949,10],[999,10],[1070,10]]},"1095":{"position":[[483,10]]},"1099":{"position":[[1787,10],[1864,10]]},"1101":{"position":[[0,10],[1010,10]]},"1109":{"position":[[730,10],[1070,10]]},"1120":{"position":[[19,10]]},"1132":{"position":[[1563,12]]},"1145":{"position":[[0,10],[1491,10]]},"1151":{"position":[[153,10]]},"1159":{"position":[[825,10],[1130,9]]},"1227":{"position":[[279,10]]},"1230":{"position":[[203,10]]},"1289":{"position":[[296,10]]},"1291":{"position":[[1142,10]]},"1303":{"position":[[743,10]]},"1328":{"position":[[18,10]]},"1473":{"position":[[175,10]]},"1494":{"position":[[416,10],[553,10]]},"1702":{"position":[[729,10],[772,10]]},"1716":{"position":[[245,10]]},"1720":{"position":[[0,10],[332,10],[993,10],[1494,10],[1877,10],[2040,10]]},"1736":{"position":[[95,10]]},"1762":{"position":[[335,10]]},"1780":{"position":[[106,10]]}}}],["contol",{"_index":5604,"t":{"1782":{"position":[[2596,9]]}}}],["contour",{"_index":931,"t":{"191":{"position":[[95,7]]},"199":{"position":[[125,7]]}}}],["contradict",{"_index":5223,"t":{"1655":{"position":[[1336,17]]}}}],["contraint",{"_index":1361,"t":{"326":{"position":[[138,10]]}}}],["contras",{"_index":1720,"t":{"483":{"position":[[501,10]]}}}],["contrast",{"_index":1383,"t":{"334":{"position":[[33,11]]},"339":{"position":[[495,11]]},"485":{"position":[[1089,11]]},"496":{"position":[[226,11]]},"500":{"position":[[971,11]]},"870":{"position":[[724,11]]},"1682":{"position":[[741,11],[794,11]]}}}],["contribut",{"_index":1406,"t":{"336":{"position":[[1660,12]]},"436":{"position":[[1838,12]]},"681":{"position":[[1809,13]]},"1062":{"position":[[1524,12]]},"1347":{"position":[[1716,12]]},"1379":{"position":[[1545,13]]},"1442":{"position":[[1885,12]]}}}],["control",{"_index":1659,"t":{"457":{"position":[[255,7]]},"893":{"position":[[1544,7]]},"1782":{"position":[[1656,10],[2105,11],[2282,10],[2340,7]]}}}],["conv1x1",{"_index":211,"t":{"33":{"position":[[153,7]]}}}],["conv3x3",{"_index":210,"t":{"33":{"position":[[143,7],[178,7]]}}}],["convbert",{"_index":5384,"t":{"1682":{"position":[[584,8]]}}}],["conveni",{"_index":54,"t":{"7":{"position":[[310,10]]}}}],["convers",{"_index":1759,"t":{"502":{"position":[[87,10]]},"743":{"position":[[130,13]]},"959":{"position":[[192,12]]},"963":{"position":[[308,12]]}}}],["convert",{"_index":5383,"t":{"1682":{"position":[[502,7]]}}}],["convnet",{"_index":626,"t":{"132":{"position":[[213,8]]}}}],["convnext",{"_index":902,"t":{"182":{"position":[[29,8]]}}}],["convolut",{"_index":148,"t":{"23":{"position":[[91,11]]},"25":{"position":[[306,11]]},"33":{"position":[[30,11],[52,11]]},"38":{"position":[[169,11]]},"78":{"position":[[108,12]]},"104":{"position":[[299,11]]},"112":{"position":[[481,11]]},"116":{"position":[[807,13]]},"230":{"position":[[34,11],[77,11],[149,13],[381,13]]},"304":{"position":[[422,11]]},"308":{"position":[[20,11]]},"310":{"position":[[174,13],[1324,13],[1430,11],[1457,11],[1566,13],[1641,11]]},"328":{"position":[[198,13]]},"670":{"position":[[1017,13]]}}}],["convs2",{"_index":1153,"t":{"287":{"position":[[58,9],[167,7]]}}}],["coop",{"_index":1387,"t":{"334":{"position":[[177,5],[656,4]]},"336":{"position":[[421,5],[551,4],[1981,4]]},"341":{"position":[[156,4]]},"347":{"position":[[371,4]]},"356":{"position":[[197,4],[301,4]]},"376":{"position":[[113,6],[303,4]]},"378":{"position":[[97,5]]}}}],["coordin",{"_index":670,"t":{"143":{"position":[[590,10]]},"733":{"position":[[705,10]]}}}],["cop",{"_index":683,"t":{"149":{"position":[[32,6]]}}}],["copa",{"_index":2075,"t":{"594":{"position":[[772,6]]},"633":{"position":[[43,4]]},"638":{"position":[[104,4]]},"640":{"position":[[174,5]]},"646":{"position":[[313,5]]},"701":{"position":[[65,5]]},"1181":{"position":[[65,5]]},"1208":{"position":[[157,5]]},"1427":{"position":[[812,4]]}}}],["copi",{"_index":2445,"t":{"681":{"position":[[229,4]]},"683":{"position":[[567,4]]},"786":{"position":[[251,4]]},"849":{"position":[[185,4]]},"1014":{"position":[[272,4],[633,4]]},"1126":{"position":[[641,4]]},"1159":{"position":[[298,4]]},"1289":{"position":[[150,4]]},"1291":{"position":[[192,4],[1438,4],[1500,4]]},"1305":{"position":[[1187,4]]},"1401":{"position":[[75,4]]},"1604":{"position":[[94,6]]},"1634":{"position":[[0,4]]}}}],["cordonni",{"_index":390,"t":{"88":{"position":[[250,10]]},"529":{"position":[[1517,10]]}}}],["core",{"_index":4709,"t":{"1442":{"position":[[12,4]]}}}],["corefer",{"_index":2081,"t":{"594":{"position":[[854,11]]}}}],["corpora",{"_index":1371,"t":{"326":{"position":[[419,7]]},"523":{"position":[[89,7]]},"658":{"position":[[87,7]]},"1341":{"position":[[105,7]]},"1646":{"position":[[38,7]]}}}],["corpu",{"_index":980,"t":{"215":{"position":[[397,6],[1575,6]]},"594":{"position":[[160,6]]},"849":{"position":[[27,6]]},"1095":{"position":[[410,6]]},"1141":{"position":[[288,6]]},"1419":{"position":[[179,7]]},"1672":{"position":[[284,6]]},"1682":{"position":[[628,6]]},"1718":{"position":[[118,6]]},"1782":{"position":[[3052,6]]}}}],["corrdin",{"_index":3684,"t":{"1067":{"position":[[462,10]]}}}],["correct",{"_index":1964,"t":{"531":{"position":[[824,7]]},"596":{"position":[[263,7],[1104,7],[1910,7]]},"608":{"position":[[979,7]]},"1128":{"position":[[523,7]]},"1167":{"position":[[1267,7]]}}}],["correct/incorrect",{"_index":2105,"t":{"596":{"position":[[389,17]]}}}],["correl",{"_index":4673,"t":{"1431":{"position":[[1620,11],[1860,11]]},"1653":{"position":[[407,11]]}}}],["corrupt",{"_index":2044,"t":{"577":{"position":[[108,10],[138,12]]},"1132":{"position":[[67,10],[816,10],[958,10],[1218,10],[1315,10]]},"1143":{"position":[[90,10],[346,10],[492,10],[695,10],[1030,10]]}}}],["cos(\\frac{1}{\\mathcal{l}}\\sum_ie^1_i",{"_index":4640,"t":{"1429":{"position":[[649,38]]}}}],["cos(po",{"_index":1266,"t":{"308":{"position":[[475,7]]}}}],["cosin",{"_index":332,"t":{"63":{"position":[[145,6]]},"350":{"position":[[810,6]]},"372":{"position":[[13,6]]},"628":{"position":[[771,6]]},"1141":{"position":[[859,6]]},"1151":{"position":[[397,6]]},"1270":{"position":[[164,6],[321,6]]},"1429":{"position":[[493,6],[580,6],[825,6],[861,6],[940,6],[1153,6],[1221,6]]},"1431":{"position":[[2082,6],[2471,6]]},"1558":{"position":[[252,6]]}}}],["cosmosqa",{"_index":4653,"t":{"1429":{"position":[[1632,9]]}}}],["cost",{"_index":2053,"t":{"587":{"position":[[464,4]]},"592":{"position":[[49,4],[143,4]]},"598":{"position":[[58,4],[2971,4]]},"608":{"position":[[84,4],[547,4],[588,5],[657,4]]},"610":{"position":[[48,5],[430,4],[477,5]]},"612":{"position":[[51,4],[339,4]]},"614":{"position":[[21,4]]},"622":{"position":[[57,4],[438,5]]},"683":{"position":[[509,4]]},"797":{"position":[[748,4]]},"885":{"position":[[242,4]]},"932":{"position":[[759,4]]},"1060":{"position":[[953,4]]},"1062":{"position":[[864,5],[1456,5],[1662,5]]},"1080":{"position":[[121,5]]},"1130":{"position":[[705,4]]},"1145":{"position":[[1759,4]]},"1149":{"position":[[163,4]]},"1153":{"position":[[452,4]]},"1347":{"position":[[1618,4]]},"1360":{"position":[[141,4]]},"1371":{"position":[[198,4]]},"1600":{"position":[[191,4]]}}}],["cos⁡\\cosco",{"_index":4644,"t":{"1429":{"position":[[811,11]]}}}],["cot",{"_index":1528,"t":{"382":{"position":[[278,3]]},"384":{"position":[[980,3]]},"386":{"position":[[134,3],[175,3],[211,3],[293,3],[356,3],[425,3],[433,3]]},"388":{"position":[[53,3]]},"395":{"position":[[58,3],[147,3],[184,3]]},"399":{"position":[[0,3],[103,3],[110,3],[277,3],[346,3],[375,3],[436,3],[466,3]]},"401":{"position":[[0,3]]},"403":{"position":[[0,3],[149,3]]},"405":{"position":[[0,3],[82,3],[197,3]]},"407":{"position":[[0,3],[72,3],[126,3],[171,3]]},"409":{"position":[[23,3],[48,3],[119,3],[134,3],[147,3],[260,3],[306,3],[341,3],[422,3],[522,4],[581,3]]},"414":{"position":[[43,3],[122,3],[178,3]]},"416":{"position":[[57,3],[108,3]]},"418":{"position":[[0,3]]},"424":{"position":[[282,3],[316,3],[442,3],[482,3]]},"426":{"position":[[32,3],[147,3],[310,3],[348,3],[408,3],[457,3],[569,3],[622,3]]},"428":{"position":[[345,3]]},"430":{"position":[[0,3],[100,3],[133,3]]},"537":{"position":[[255,5]]},"539":{"position":[[148,3],[206,3],[226,3],[301,3],[477,3]]},"544":{"position":[[197,3]]},"546":{"position":[[0,3],[23,3]]},"548":{"position":[[68,3]]},"555":{"position":[[71,3],[216,3]]},"557":{"position":[[76,4]]},"559":{"position":[[33,3],[94,3],[121,3],[157,3]]},"561":{"position":[[4,3],[85,3],[208,3],[256,3],[369,3]]},"563":{"position":[[36,3],[54,3],[64,3],[89,3],[132,3],[181,3],[231,3],[254,3],[334,4],[339,5],[391,3],[397,3]]},"565":{"position":[[25,3],[90,3],[202,3]]},"569":{"position":[[188,3],[234,3],[714,3]]},"571":{"position":[[65,3],[138,3]]},"575":{"position":[[0,3],[49,3],[67,3],[114,3],[153,3],[159,3],[196,3],[214,3],[237,3],[285,3]]},"579":{"position":[[204,5]]},"583":{"position":[[111,5],[172,3],[197,3],[232,3]]}}}],["count",{"_index":1029,"t":{"221":{"position":[[188,9]]},"1540":{"position":[[522,8]]}}}],["coupl",{"_index":3655,"t":{"1062":{"position":[[1105,6]]}}}],["cp",{"_index":5144,"t":{"1634":{"position":[[108,2]]}}}],["cpet",{"_index":5378,"t":{"1682":{"position":[[28,4]]}}}],["cpft",{"_index":5385,"t":{"1682":{"position":[[707,4],[822,4]]}}}],["cpu",{"_index":2394,"t":{"670":{"position":[[1082,3]]}}}],["cr",{"_index":4650,"t":{"1429":{"position":[[1486,4]]}}}],["craft",{"_index":1397,"t":{"336":{"position":[[362,7],[563,7],[1101,7]]},"347":{"position":[[528,7]]},"356":{"position":[[209,7]]},"368":{"position":[[33,7]]}}}],["crawl",{"_index":4593,"t":{"1419":{"position":[[171,7]]}}}],["creat",{"_index":69,"t":{"9":{"position":[[92,6]]},"13":{"position":[[15,8]]},"19":{"position":[[147,7]]},"1585":{"position":[[11,7]]},"1587":{"position":[[0,6]]},"1593":{"position":[[0,6]]},"1595":{"position":[[25,7],[259,6]]},"1604":{"position":[[154,8]]},"1610":{"position":[[44,6]]},"1612":{"position":[[0,6]]},"1614":{"position":[[0,6]]},"1620":{"position":[[95,7],[145,7],[207,6]]},"1626":{"position":[[35,6]]}}}],["creativ",{"_index":2029,"t":{"569":{"position":[[28,12]]}}}],["creator",{"_index":5010,"t":{"1587":{"position":[[153,7]]}}}],["credit",{"_index":4716,"t":{"1442":{"position":[[1325,6]]}}}],["criteria",{"_index":4738,"t":{"1449":{"position":[[404,8]]}}}],["criterion",{"_index":2947,"t":{"799":{"position":[[208,9]]}}}],["critic",{"_index":2776,"t":{"786":{"position":[[3448,8]]},"1646":{"position":[[243,8]]}}}],["croiss",{"_index":1672,"t":{"457":{"position":[[813,6]]}}}],["crop",{"_index":681,"t":{"147":{"position":[[354,7],[396,7]]},"149":{"position":[[217,4],[235,4]]},"155":{"position":[[500,7]]}}}],["cross",{"_index":818,"t":{"172":{"position":[[292,5]]},"225":{"position":[[233,5]]},"232":{"position":[[326,5]]},"234":{"position":[[419,5]]},"249":{"position":[[3,5]]},"358":{"position":[[1235,5]]},"443":{"position":[[253,5],[288,5]]},"466":{"position":[[151,5]]},"485":{"position":[[1319,5],[1444,5]]},"488":{"position":[[288,5]]},"496":{"position":[[147,5],[214,5]]},"500":{"position":[[298,5],[660,5]]},"502":{"position":[[103,5]]},"504":{"position":[[526,5],[579,5],[662,5],[816,5]]},"510":{"position":[[114,5]]},"596":{"position":[[92,5],[1881,5]]},"1008":{"position":[[708,5]]},"1134":{"position":[[662,5]]},"1185":{"position":[[726,5]]},"1187":{"position":[[437,5]]},"1225":{"position":[[221,5]]},"1234":{"position":[[308,5]]},"1244":{"position":[[520,5]]},"1270":{"position":[[29,5]]},"1273":{"position":[[336,5]]},"1523":{"position":[[277,5]]}}}],["crow",{"_index":4967,"t":{"1560":{"position":[[513,5]]}}}],["crowspair",{"_index":4920,"t":{"1546":{"position":[[802,10]]}}}],["crucial",{"_index":3069,"t":{"835":{"position":[[113,7]]},"841":{"position":[[300,7]]}}}],["csqa",{"_index":1570,"t":{"412":{"position":[[0,4]]},"414":{"position":[[0,4]]}}}],["css",{"_index":5052,"t":{"1597":{"position":[[120,3]]}}}],["cubic",{"_index":3004,"t":{"803":{"position":[[591,5]]},"853":{"position":[[2038,5]]},"861":{"position":[[44,5]]},"866":{"position":[[543,5]]}}}],["cue",{"_index":4727,"t":{"1445":{"position":[[211,4]]}}}],["current",{"_index":1614,"t":{"436":{"position":[[1865,7]]},"447":{"position":[[693,7]]},"459":{"position":[[396,7]]},"1389":{"position":[[464,7]]},"1447":{"position":[[115,7]]},"1451":{"position":[[199,7]]},"1604":{"position":[[254,7]]},"1622":{"position":[[220,7]]}}}],["curriculum",{"_index":197,"t":{"27":{"position":[[300,10]]},"1686":{"position":[[349,10]]}}}],["cursor",{"_index":5128,"t":{"1628":{"position":[[247,7]]}}}],["curv",{"_index":919,"t":{"189":{"position":[[100,5]]},"424":{"position":[[453,6]]},"426":{"position":[[279,6],[341,6]]},"430":{"position":[[196,6]]},"573":{"position":[[90,5]]},"919":{"position":[[224,6]]}}}],["custom",{"_index":2315,"t":{"658":{"position":[[964,6]]},"1583":{"position":[[140,6]]},"1595":{"position":[[81,9]]},"1618":{"position":[[165,6]]}}}],["cvpr",{"_index":1593,"t":{"432":{"position":[[48,4]]}}}],["cxc",{"_index":4633,"t":{"1427":{"position":[[1160,3],[1286,3]]},"1429":{"position":[[1551,5]]}}}],["c|h",{"_index":4052,"t":{"1185":{"position":[[530,4]]}}}],["c}im​∈r1×c",{"_index":3374,"t":{"895":{"position":[[323,10]]}}}],["c}ip​∈r1×c",{"_index":3383,"t":{"895":{"position":[[647,10]]}}}],["c}pl​∈rk×c",{"_index":3296,"t":{"891":{"position":[[273,10]]}}}],["c}rh×w×c",{"_index":1046,"t":{"227":{"position":[[548,8]]}}}],["c}ti​∈rm×c",{"_index":3302,"t":{"891":{"position":[[599,10]]}}}],["c}tl​∈r1×c",{"_index":3313,"t":{"893":{"position":[[338,10]]}}}],["c}x∈rh×w×c",{"_index":405,"t":{"91":{"position":[[163,10]]}}}],["d",{"_index":842,"t":{"174":{"position":[[846,2]]},"205":{"position":[[70,2]]},"310":{"position":[[1691,1]]},"324":{"position":[[435,3]]},"733":{"position":[[521,3]]},"988":{"position":[[1294,2]]},"994":{"position":[[211,1]]},"1067":{"position":[[607,3],[1028,1],[1041,1],[1050,2]]},"1070":{"position":[[1124,1],[1133,2]]},"1143":{"position":[[10,2]]},"1218":{"position":[[447,1],[451,1]]},"1248":{"position":[[218,2],[392,2]]},"1505":{"position":[[229,1]]}}}],["d(m",{"_index":3564,"t":{"994":{"position":[[408,3]]}}}],["d)(l×d",{"_index":4200,"t":{"1248":{"position":[[122,7]]}}}],["d)(l×d)+(l×d",{"_index":4202,"t":{"1248":{"position":[[233,13]]}}}],["d)\\tau(l×d)+(l×d",{"_index":4206,"t":{"1248":{"position":[[407,18]]}}}],["d)wdown​∈rd×r(r<d",{"_index":3531,"t":{"988":{"position":[[1228,18]]}}}],["d)wup​∈rr×d(r<d",{"_index":3533,"t":{"988":{"position":[[1302,16]]}}}],["d/hd/hd/h",{"_index":2807,"t":{"789":{"position":[[753,9]]}}}],["d1",{"_index":5439,"t":{"1718":{"position":[[28,3]]}}}],["d1=d2=1024d_1",{"_index":2767,"t":{"786":{"position":[[2048,13]]}}}],["d2",{"_index":5440,"t":{"1718":{"position":[[230,3]]}}}],["d3",{"_index":5442,"t":{"1718":{"position":[[487,3]]}}}],["d4",{"_index":5443,"t":{"1718":{"position":[[643,3]]}}}],["d5",{"_index":5446,"t":{"1718":{"position":[[1010,3]]}}}],["d^2)o(k⋅n⋅d+n⋅d2",{"_index":1299,"t":{"310":{"position":[[1703,17]]}}}],["d^2l×d2",{"_index":4204,"t":{"1248":{"position":[[277,7]]}}}],["d_1",{"_index":2764,"t":{"786":{"position":[[1954,4]]},"791":{"position":[[447,4]]},"795":{"position":[[520,5],[1270,5]]}}}],["d_2",{"_index":2765,"t":{"786":{"position":[[1959,3],[2064,3]]},"791":{"position":[[452,3]]}}}],["d_2)d_1d_2)o(min(d1​,d2​)d1​d2",{"_index":2864,"t":{"795":{"position":[[1276,32]]}}}],["d_2)r≪min(d1​,d2",{"_index":2848,"t":{"795":{"position":[[526,18]]}}}],["d_2}a∈rr×d2",{"_index":2760,"t":{"786":{"position":[[1874,13]]},"791":{"position":[[367,13]]}}}],["d_2}q∈rr×d2",{"_index":2840,"t":{"795":{"position":[[300,12]]}}}],["d_2}△∈rd1​×d2",{"_index":2758,"t":{"786":{"position":[[1824,15]]},"791":{"position":[[317,15]]}}}],["d_\\text{hidden}}wk​∈rdhidden​×dhidden",{"_index":4499,"t":{"1384":{"position":[[3538,38]]}}}],["d_\\text{hidden}}wup​∈rdmid​×dhidden",{"_index":4497,"t":{"1384":{"position":[[3410,36]]}}}],["d_\\text{mid}}wdown​∈rdhidden​×dmid",{"_index":4495,"t":{"1384":{"position":[[3307,35]]}}}],["d_\\text{model",{"_index":1265,"t":{"308":{"position":[[436,16],[497,16]]}}}],["d_h}wqi​,wki​,wvi​∈rd×dh",{"_index":2805,"t":{"789":{"position":[[666,25]]}}}],["d_k",{"_index":1228,"t":{"300":{"position":[[1039,5],[1089,5]]}}}],["d_l}w∈rdb​×dl",{"_index":2264,"t":{"630":{"position":[[1293,14]]}}}],["d_m}wf1​∈rd×dm",{"_index":2813,"t":{"789":{"position":[[1003,15]]}}}],["d_v",{"_index":1236,"t":{"300":{"position":[[1289,3]]},"598":{"position":[[2040,3]]}}}],["d_v}wiq​∈rdmodel​×dk​,wik​∈rdmodel​×dk​,wiv​∈rdmodel​×dv",{"_index":1231,"t":{"300":{"position":[[1139,57]]}}}],["d_x",{"_index":4806,"t":{"1485":{"position":[[652,4]]},"1487":{"position":[[952,4]]}}}],["d_{\\pi^{rl}_\\phi}}[r_\\theta(x,i",{"_index":4950,"t":{"1558":{"position":[[1533,32]]}}}],["d_{\\text{hidden}}}wup​∈rdmid​×dhidden",{"_index":4466,"t":{"1384":{"position":[[826,39]]}}}],["d_{\\text{hidden}}}wv​∈rdhidden​×dhidden",{"_index":4471,"t":{"1384":{"position":[[1520,40]]}}}],["d_{\\text{kl",{"_index":3237,"t":{"861":{"position":[[1820,13]]}}}],["d_{\\text{mid}}}wdown​∈rdhidden​×dmid",{"_index":4463,"t":{"1384":{"position":[[720,38],[2022,38]]}}}],["d_{\\text{model",{"_index":1325,"t":{"317":{"position":[[248,18]]}}}],["d_{\\text{model}}/h",{"_index":1237,"t":{"300":{"position":[[1295,18]]}}}],["d_{ff})l(dk​+dv​+dff",{"_index":2173,"t":{"598":{"position":[[2046,22]]}}}],["d_{model",{"_index":2662,"t":{"751":{"position":[[157,9]]},"753":{"position":[[211,9]]},"755":{"position":[[531,9],[556,10]]},"757":{"position":[[209,9]]}}}],["d_{model}dffn​=4×dmodel",{"_index":2584,"t":{"721":{"position":[[411,24]]}}}],["d_{model}r≪dmodel",{"_index":2647,"t":{"741":{"position":[[121,18]]}}}],["d_{model}∣θ∣=l^adpt​×(2×dmodel​×r+r+dmodel​)+2×l^ln​×dmodel",{"_index":2676,"t":{"755":{"position":[[598,60]]}}}],["d_{pretrain}}[log(\\pi^{rl}_\\phi",{"_index":4955,"t":{"1558":{"position":[[1645,31]]}}}],["dai",{"_index":983,"t":{"215":{"position":[[462,3]]}}}],["dall",{"_index":3759,"t":{"1095":{"position":[[8,4],[214,4]]}}}],["danger",{"_index":5115,"t":{"1626":{"position":[[118,9],[153,9],[231,9]]}}}],["dant",{"_index":3833,"t":{"1105":{"position":[[157,6]]}}}],["dart",{"_index":4317,"t":{"1310":{"position":[[64,4],[145,4]]},"1317":{"position":[[520,4]]}}}],["data",{"_index":268,"t":{"49":{"position":[[558,4]]},"63":{"position":[[205,4]]},"138":{"position":[[320,4]]},"155":{"position":[[573,4]]},"213":{"position":[[83,4],[241,4],[331,4],[378,4],[504,4]]},"215":{"position":[[81,4],[111,4],[253,5],[311,4],[345,4],[434,4],[545,4],[644,4],[703,4],[790,4],[1280,4],[1357,4],[1494,4]]},"255":{"position":[[96,4]]},"326":{"position":[[214,4]]},"341":{"position":[[450,4]]},"343":{"position":[[112,4],[133,4]]},"352":{"position":[[414,4]]},"354":{"position":[[601,4]]},"356":{"position":[[244,4]]},"358":{"position":[[45,4]]},"434":{"position":[[196,4]]},"441":{"position":[[45,4]]},"488":{"position":[[318,4]]},"490":{"position":[[29,4]]},"496":{"position":[[32,4],[133,4]]},"515":{"position":[[606,4]]},"521":{"position":[[107,4],[196,4]]},"523":{"position":[[157,4],[589,4]]},"529":{"position":[[2545,5],[2733,4],[2766,4],[2818,4]]},"537":{"position":[[191,4]]},"539":{"position":[[305,6]]},"559":{"position":[[109,4]]},"589":{"position":[[51,4],[118,4],[1564,4]]},"592":{"position":[[424,4]]},"594":{"position":[[147,4]]},"600":{"position":[[141,4]]},"630":{"position":[[1572,4]]},"692":{"position":[[336,4]]},"696":{"position":[[101,4],[191,4]]},"707":{"position":[[235,4]]},"709":{"position":[[297,4],[460,4]]},"887":{"position":[[311,4]]},"891":{"position":[[23,4]]},"921":{"position":[[18,4]]},"932":{"position":[[459,4]]},"934":{"position":[[711,4],[1631,4],[1678,4],[2288,4],[2467,4],[2486,4],[2515,4]]},"945":{"position":[[295,4],[836,4]]},"949":{"position":[[149,4],[268,4],[392,4],[486,4]]},"951":{"position":[[79,4],[168,4],[283,4],[401,4],[449,4]]},"955":{"position":[[120,4],[145,4],[241,4]]},"959":{"position":[[47,4],[85,4],[159,4],[205,4]]},"963":{"position":[[39,4],[321,4]]},"965":{"position":[[141,4]]},"969":{"position":[[291,4]]},"973":{"position":[[141,4],[293,4]]},"992":{"position":[[561,4]]},"997":{"position":[[635,4]]},"1065":{"position":[[152,4]]},"1126":{"position":[[1074,4]]},"1227":{"position":[[788,4]]},"1238":{"position":[[97,4]]},"1289":{"position":[[566,4],[589,4]]},"1294":{"position":[[140,4]]},"1321":{"position":[[96,4],[206,4],[278,4],[447,4]]},"1323":{"position":[[339,4]]},"1326":{"position":[[215,4]]},"1332":{"position":[[13,4]]},"1334":{"position":[[0,4],[334,4]]},"1345":{"position":[[313,4],[402,4]]},"1347":{"position":[[1089,4]]},"1352":{"position":[[53,4]]},"1377":{"position":[[113,4],[354,4]]},"1379":{"position":[[423,4],[711,4],[1211,4]]},"1382":{"position":[[204,4]]},"1387":{"position":[[321,4]]},"1389":{"position":[[112,4],[488,4],[998,4]]},"1391":{"position":[[17,4]]},"1393":{"position":[[198,4],[226,4]]},"1395":{"position":[[12,4],[235,4],[1292,4],[1469,4],[2486,4],[2968,4]]},"1403":{"position":[[130,4]]},"1419":{"position":[[9,4],[65,4]]},"1427":{"position":[[146,4]]},"1431":{"position":[[2196,5]]},"1485":{"position":[[804,4]]},"1646":{"position":[[130,4]]},"1667":{"position":[[256,4],[665,4]]},"1684":{"position":[[209,4]]},"1689":{"position":[[385,4]]},"1693":{"position":[[420,4]]},"1695":{"position":[[117,4]]},"1700":{"position":[[37,4]]},"1746":{"position":[[171,4]]},"1774":{"position":[[389,4]]},"1782":{"position":[[3120,4],[3298,4]]}}}],["databas",{"_index":4767,"t":{"1462":{"position":[[233,9],[255,8]]}}}],["dataset",{"_index":487,"t":{"102":{"position":[[6,7],[125,7]]},"136":{"position":[[43,7],[69,7]]},"143":{"position":[[44,7]]},"177":{"position":[[518,8]]},"249":{"position":[[103,7]]},"313":{"position":[[53,7],[210,7]]},"336":{"position":[[517,7],[822,7]]},"341":{"position":[[335,7],[540,7]]},"343":{"position":[[72,7],[416,7]]},"345":{"position":[[85,7]]},"347":{"position":[[144,7]]},"350":{"position":[[59,7]]},"352":{"position":[[42,7],[327,7],[344,7]]},"356":{"position":[[322,7]]},"358":{"position":[[291,7]]},"360":{"position":[[45,7]]},"374":{"position":[[27,7]]},"403":{"position":[[210,7]]},"515":{"position":[[58,7],[536,7]]},"525":{"position":[[563,7]]},"527":{"position":[[232,7]]},"529":{"position":[[0,9]]},"539":{"position":[[230,7]]},"589":{"position":[[1817,7]]},"594":{"position":[[249,7],[401,7],[800,9]]},"598":{"position":[[3038,7]]},"600":{"position":[[449,7]]},"602":{"position":[[534,7],[643,7],[671,7]]},"606":{"position":[[32,7]]},"608":{"position":[[689,7]]},"612":{"position":[[414,7]]},"618":{"position":[[141,8],[324,7]]},"628":{"position":[[435,7]]},"658":{"position":[[3098,7]]},"662":{"position":[[228,7]]},"668":{"position":[[571,7]]},"670":{"position":[[493,7]]},"709":{"position":[[1415,7]]},"786":{"position":[[4461,7],[4666,7]]},"816":{"position":[[66,7]]},"833":{"position":[[255,7]]},"924":{"position":[[39,7]]},"932":{"position":[[634,7]]},"942":{"position":[[34,7]]},"953":{"position":[[389,7]]},"967":{"position":[[100,7]]},"973":{"position":[[560,7]]},"977":{"position":[[830,8]]},"979":{"position":[[1444,8],[1517,8]]},"984":{"position":[[43,8]]},"997":{"position":[[35,8],[396,8],[919,7]]},"1031":{"position":[[111,7],[131,7],[193,7]]},"1037":{"position":[[54,7]]},"1070":{"position":[[0,8],[78,8]]},"1077":{"position":[[64,7]]},"1105":{"position":[[84,7]]},"1107":{"position":[[0,9],[140,7],[424,7]]},"1111":{"position":[[1435,8],[1497,8]]},"1126":{"position":[[1657,7]]},"1134":{"position":[[582,7]]},"1145":{"position":[[1915,7]]},"1147":{"position":[[351,7],[376,7],[409,7],[998,7]]},"1151":{"position":[[1807,7]]},"1181":{"position":[[37,8]]},"1244":{"position":[[10,7]]},"1250":{"position":[[12,7]]},"1264":{"position":[[208,7]]},"1310":{"position":[[40,7],[75,7]]},"1314":{"position":[[547,7]]},"1319":{"position":[[120,7],[228,7],[279,7]]},"1321":{"position":[[241,7]]},"1362":{"position":[[540,7]]},"1393":{"position":[[185,7]]},"1417":{"position":[[80,7]]},"1419":{"position":[[187,7],[604,7],[1016,8],[1058,7]]},"1421":{"position":[[422,7]]},"1423":{"position":[[655,7],[764,7]]},"1427":{"position":[[10,7],[30,7],[471,7]]},"1429":{"position":[[1648,7]]},"1431":{"position":[[1267,7],[1284,7]]},"1475":{"position":[[245,7]]},"1496":{"position":[[68,7]]},"1552":{"position":[[443,7],[497,7],[558,7]]},"1554":{"position":[[42,7],[81,7]]},"1577":{"position":[[68,7],[91,7]]},"1669":{"position":[[820,7]]},"1672":{"position":[[20,7],[108,7],[185,7]]},"1778":{"position":[[774,7]]}}}],["date",{"_index":45,"t":{"7":{"position":[[187,4]]},"412":{"position":[[89,4]]},"1589":{"position":[[29,4]]}}}],["datset",{"_index":4207,"t":{"1250":{"position":[[60,6]]}}}],["davi",{"_index":927,"t":{"191":{"position":[[6,5],[49,5]]}}}],["david",{"_index":1924,"t":{"529":{"position":[[2220,6]]}}}],["davis17",{"_index":955,"t":{"199":{"position":[[22,7]]}}}],["day",{"_index":4971,"t":{"1570":{"position":[[298,4],[350,4]]}}}],["dbd_bdb",{"_index":2267,"t":{"630":{"position":[[1333,8]]}}}],["dbr\\frac{d_b}{r}rdb",{"_index":2274,"t":{"630":{"position":[[1619,21]]}}}],["ddd",{"_index":423,"t":{"91":{"position":[[482,3],[541,3]]},"310":{"position":[[1070,3]]},"358":{"position":[[171,3]]},"630":{"position":[[1577,3]]},"662":{"position":[[798,3],[886,3]]},"686":{"position":[[376,3]]},"694":{"position":[[43,3]]},"719":{"position":[[742,5]]},"984":{"position":[[372,3]]},"994":{"position":[[91,3]]},"1070":{"position":[[998,3]]},"1167":{"position":[[996,3]]},"1218":{"position":[[274,3]]},"1238":{"position":[[533,3]]},"1558":{"position":[[1029,3]]}}}],["ddev32\\mathcal{d}_{dev32}ddev32",{"_index":3860,"t":{"1111":{"position":[[716,34],[791,32],[1323,32]]},"1115":{"position":[[448,32],[860,32]]}}}],["ddev\\mathcal{d}_{dev}ddev",{"_index":3855,"t":{"1111":{"position":[[394,28],[1293,26]]}}}],["de",{"_index":648,"t":{"140":{"position":[[285,3]]},"215":{"position":[[2255,2]]},"662":{"position":[[1418,3]]}}}],["de)activ",{"_index":4513,"t":{"1389":{"position":[[762,14]]}}}],["deberta",{"_index":2569,"t":{"717":{"position":[[331,8]]},"743":{"position":[[9,7]]},"761":{"position":[[0,7],[65,7]]},"1043":{"position":[[34,7]]}}}],["debertav",{"_index":3075,"t":{"839":{"position":[[368,9]]}}}],["debertav3",{"_index":2786,"t":{"786":{"position":[[4472,9]]},"805":{"position":[[15,9]]},"812":{"position":[[15,9]]},"814":{"position":[[0,9]]},"819":{"position":[[56,9]]},"823":{"position":[[80,9]]},"828":{"position":[[0,9]]},"833":{"position":[[30,9]]},"841":{"position":[[33,9]]}}}],["debias",{"_index":5569,"t":{"1778":{"position":[[210,9],[241,8],[493,9]]}}}],["decay",{"_index":288,"t":{"53":{"position":[[143,6],[202,5],[228,7],[297,5]]},"63":{"position":[[152,5],[191,6]]},"80":{"position":[[37,6]]},"106":{"position":[[121,5]]},"112":{"position":[[206,5]]},"182":{"position":[[303,5]]},"244":{"position":[[23,6]]},"372":{"position":[[20,5]]},"602":{"position":[[414,5]]},"705":{"position":[[382,5]]},"905":{"position":[[190,5]]},"1111":{"position":[[1204,7]]},"1134":{"position":[[826,5],[849,5]]},"1496":{"position":[[652,5]]},"1558":{"position":[[273,5]]},"1665":{"position":[[1404,5]]},"1674":{"position":[[478,5]]}}}],["decent",{"_index":2862,"t":{"795":{"position":[[1122,6]]}}}],["decis",{"_index":3459,"t":{"969":{"position":[[159,8]]},"1440":{"position":[[505,8]]},"1442":{"position":[[673,8],[1542,8],[1759,8]]},"1449":{"position":[[370,8],[462,8]]},"1451":{"position":[[393,8],[693,8],[856,8]]}}}],["decod",{"_index":624,"t":{"132":{"position":[[93,7],[114,7],[260,7]]},"143":{"position":[[319,8]]},"165":{"position":[[2189,7],[2208,7]]},"174":{"position":[[151,7],[371,8],[546,7],[583,7],[1263,7]]},"182":{"position":[[178,7],[224,7]]},"225":{"position":[[18,7],[198,7]]},"232":{"position":[[207,7]]},"234":{"position":[[408,7]]},"236":{"position":[[81,7],[289,7]]},"239":{"position":[[118,7]]},"246":{"position":[[302,7]]},"265":{"position":[[81,7]]},"283":{"position":[[38,7]]},"285":{"position":[[41,7]]},"289":{"position":[[45,7],[239,7],[432,7]]},"294":{"position":[[0,7],[238,7]]},"302":{"position":[[61,7],[107,7],[181,7],[293,7],[527,7],[560,7],[587,7]]},"304":{"position":[[35,7]]},"306":{"position":[[128,7]]},"308":{"position":[[127,7]]},"310":{"position":[[281,7]]},"319":{"position":[[126,7]]},"328":{"position":[[81,7]]},"397":{"position":[[124,8]]},"459":{"position":[[531,8]]},"483":{"position":[[67,7],[92,7],[343,7]]},"485":{"position":[[297,7],[427,7],[534,7],[644,7],[689,7],[1303,7],[1371,8],[1406,7]]},"488":{"position":[[85,7]]},"492":{"position":[[41,7]]},"494":{"position":[[246,7],[325,7]]},"500":{"position":[[9,7],[200,7],[449,7],[535,7],[584,7],[740,7]]},"502":{"position":[[19,7],[171,7],[228,7],[306,7]]},"504":{"position":[[75,9],[242,7],[279,8],[352,7],[453,7],[500,7],[611,7],[712,7]]},"506":{"position":[[75,7]]},"508":{"position":[[8,7],[186,7]]},"510":{"position":[[78,7],[104,7],[160,7],[268,7]]},"512":{"position":[[171,7]]},"517":{"position":[[114,7]]},"567":{"position":[[85,7],[124,7]]},"577":{"position":[[7,8],[30,9],[193,7],[216,7]]},"594":{"position":[[229,7]]},"598":{"position":[[1241,7],[2102,7],[2197,7]]},"608":{"position":[[193,7],[338,7],[360,7],[419,7]]},"612":{"position":[[71,7]]},"709":{"position":[[1676,7],[1792,7]]},"739":{"position":[[113,7]]},"828":{"position":[[69,7]]},"905":{"position":[[440,8]]},"1080":{"position":[[26,7],[41,7]]},"1128":{"position":[[347,7],[1882,7]]},"1132":{"position":[[51,7],[1145,7]]},"1145":{"position":[[753,7]]},"1183":{"position":[[8,7]]},"1259":{"position":[[174,7]]},"1298":{"position":[[53,7],[138,7],[438,7]]},"1305":{"position":[[119,7]]}}}],["decoder(t5",{"_index":4073,"t":{"1214":{"position":[[182,11]]}}}],["decompos",{"_index":3649,"t":{"1060":{"position":[[798,10]]},"1062":{"position":[[1019,10]]},"1244":{"position":[[119,12]]},"1273":{"position":[[175,12],[571,12]]},"1646":{"position":[[2082,11]]},"1649":{"position":[[102,11]]},"1651":{"position":[[460,11]]}}}],["decomposit",{"_index":2568,"t":{"717":{"position":[[149,13]]},"719":{"position":[[622,13]]},"733":{"position":[[327,13]]},"757":{"position":[[26,13]]},"774":{"position":[[93,13]]},"784":{"position":[[564,13]]},"793":{"position":[[81,13]]},"795":{"position":[[66,13]]},"843":{"position":[[171,13]]},"851":{"position":[[287,13]]},"1067":{"position":[[4,13]]},"1240":{"position":[[217,14]]},"1242":{"position":[[7,13],[765,13]]},"1244":{"position":[[44,13]]},"1266":{"position":[[23,13]]},"1273":{"position":[[90,13],[263,13],[491,13]]},"1285":{"position":[[104,13],[258,13]]},"1730":{"position":[[1252,13]]},"1742":{"position":[[81,13],[356,13]]},"1794":{"position":[[408,13],[551,13]]}}}],["deem",{"_index":4761,"t":{"1455":{"position":[[533,5]]}}}],["deep",{"_index":971,"t":{"215":{"position":[[0,4]]},"485":{"position":[[1366,4],[1401,4]]},"504":{"position":[[274,4]]},"658":{"position":[[2199,4]]},"786":{"position":[[1373,4]]},"945":{"position":[[202,4]]},"1012":{"position":[[499,4]]},"1014":{"position":[[1176,4],[1307,4]]},"1026":{"position":[[376,4]]},"1028":{"position":[[265,4]]}}}],["deeper",{"_index":3631,"t":{"1028":{"position":[[482,6]]}}}],["deepspe",{"_index":1805,"t":{"517":{"position":[[1067,10],[1256,9]]}}}],["default",{"_index":1469,"t":{"358":{"position":[[248,7]]},"814":{"position":[[579,7]]},"905":{"position":[[432,7]]},"1134":{"position":[[129,7],[258,7]]},"1136":{"position":[[40,7]]},"1141":{"position":[[11,7]]},"1393":{"position":[[935,7]]},"1612":{"position":[[142,7]]}}}],["defaultlocal",{"_index":5138,"t":{"1632":{"position":[[110,14]]}}}],["deffer",{"_index":363,"t":{"78":{"position":[[766,10]]}}}],["defici",{"_index":2570,"t":{"717":{"position":[[454,10]]}}}],["defin",{"_index":4712,"t":{"1442":{"position":[[919,7]]},"1449":{"position":[[432,7]]}}}],["definit",{"_index":3875,"t":{"1126":{"position":[[2269,10]]}}}],["deform",{"_index":836,"t":{"174":{"position":[[120,10],[296,10],[419,10],[1091,10]]}}}],["degeneraci",{"_index":5623,"t":{"1796":{"position":[[168,10]]}}}],["delet",{"_index":63,"t":{"7":{"position":[[419,6]]}}}],["delta_\\text{task}θtask​=θpr",{"_index":4493,"t":{"1384":{"position":[[2945,29]]},"1389":{"position":[[2326,29]]}}}],["demonstr",{"_index":5525,"t":{"1738":{"position":[[22,13],[227,13]]},"1780":{"position":[[231,13]]},"1794":{"position":[[727,13],[773,13]]}}}],["denois",{"_index":1719,"t":{"483":{"position":[[490,10]]},"485":{"position":[[933,9]]},"490":{"position":[[108,9]]}}}],["dens",{"_index":581,"t":{"124":{"position":[[237,5]]},"140":{"position":[[536,5]]},"447":{"position":[[330,5]]},"719":{"position":[[596,5],[661,5]]},"733":{"position":[[13,5]]},"786":{"position":[[1431,5]]}}}],["densenet",{"_index":186,"t":{"27":{"position":[[24,9]]}}}],["deocder",{"_index":1764,"t":{"502":{"position":[[358,7]]}}}],["depend",{"_index":97,"t":{"15":{"position":[[112,13]]},"17":{"position":[[360,12]]},"285":{"position":[[448,12]]},"310":{"position":[[445,12],[485,12],[552,12],[735,12]]},"1718":{"position":[[209,10]]}}}],["deploy",{"_index":2770,"t":{"786":{"position":[[2334,6]]},"1600":{"position":[[120,6],[206,10]]}}}],["dept",{"_index":3650,"t":{"1060":{"position":[[823,6]]},"1062":{"position":[[1044,6],[1540,4]]},"1070":{"position":[[20,4],[900,4],[1008,4]]},"1073":{"position":[[0,4],[241,4]]},"1077":{"position":[[33,4]]},"1080":{"position":[[293,4]]},"1082":{"position":[[185,4],[276,4],[336,4]]},"1084":{"position":[[60,4],[371,4],[406,4],[591,4],[658,4],[791,4],[871,4],[1178,4]]},"1087":{"position":[[12,4],[84,4]]}}}],["depth",{"_index":567,"t":{"116":{"position":[[573,5]]},"221":{"position":[[592,6]]},"225":{"position":[[111,6]]},"227":{"position":[[264,6],[624,5]]},"260":{"position":[[48,5],[67,5]]},"719":{"position":[[275,5]]},"873":{"position":[[949,5]]},"1145":{"position":[[1738,5]]},"1303":{"position":[[1025,5]]}}}],["depthwis",{"_index":172,"t":{"25":{"position":[[296,9]]},"33":{"position":[[20,9],[133,9]]},"78":{"position":[[98,9]]}}}],["dequant",{"_index":650,"t":{"140":{"position":[[435,12],[519,10],[761,12]]}}}],["dequeu",{"_index":1748,"t":{"498":{"position":[[710,7]]}}}],["descent",{"_index":3754,"t":{"1093":{"position":[[1128,7]]},"1101":{"position":[[206,7]]},"1159":{"position":[[779,7]]}}}],["describ",{"_index":1737,"t":{"496":{"position":[[103,10]]}}}],["descript",{"_index":587,"t":{"124":{"position":[[534,11]]},"126":{"position":[[154,11],[1204,11]]},"128":{"position":[[47,11]]},"130":{"position":[[204,12],[437,11],[520,11]]},"159":{"position":[[13,11]]},"334":{"position":[[116,12]]},"447":{"position":[[368,11]]},"1126":{"position":[[515,11],[736,11]]},"1291":{"position":[[1075,11]]},"1294":{"position":[[169,11]]},"1618":{"position":[[118,12],[143,11]]}}}],["design",{"_index":1128,"t":{"265":{"position":[[110,6]]},"267":{"position":[[189,6]]},"341":{"position":[[210,6]]},"620":{"position":[[6,6]]},"683":{"position":[[394,6]]},"1126":{"position":[[414,6],[985,6],[1148,6],[2519,6]]},"1128":{"position":[[1050,6]]},"1130":{"position":[[656,6]]},"1136":{"position":[[521,6],[618,6]]},"1145":{"position":[[699,6],[1623,8]]},"1159":{"position":[[382,6],[742,9]]},"1409":{"position":[[175,6]]},"1583":{"position":[[147,6]]},"1646":{"position":[[2697,6]]},"1722":{"position":[[125,6]]},"1728":{"position":[[8,6]]}}}],["desir",{"_index":1818,"t":{"525":{"position":[[286,7]]}}}],["destruct",{"_index":3601,"t":{"1004":{"position":[[458,11]]},"1006":{"position":[[1351,11]]}}}],["detail",{"_index":2237,"t":{"622":{"position":[[446,8]]},"951":{"position":[[295,8]]},"967":{"position":[[602,6]]},"999":{"position":[[374,8]]},"1070":{"position":[[775,8]]},"1132":{"position":[[985,7]]},"1393":{"position":[[790,8]]}}}],["detect",{"_index":201,"t":{"27":{"position":[[423,10]]},"120":{"position":[[158,10]]},"124":{"position":[[282,10],[325,9]]},"126":{"position":[[396,9],[502,9],[893,10],[942,10]]},"128":{"position":[[144,9],[185,9]]},"130":{"position":[[40,9],[146,9],[486,9]]},"132":{"position":[[416,9]]},"140":{"position":[[721,9]]},"143":{"position":[[398,9]]},"149":{"position":[[139,9]]},"151":{"position":[[7,10],[69,9]]},"153":{"position":[[7,9]]},"155":{"position":[[467,9],[692,9],[1009,9]]},"157":{"position":[[47,10],[90,9],[210,9],[310,9]]},"163":{"position":[[617,10]]},"165":{"position":[[73,10],[1445,10]]},"168":{"position":[[82,10]]},"177":{"position":[[97,9],[743,10]]},"185":{"position":[[80,9]]},"203":{"position":[[352,9]]},"221":{"position":[[177,10]]},"225":{"position":[[594,9],[646,9]]},"279":{"position":[[64,9]]},"339":{"position":[[562,10]]},"343":{"position":[[209,10]]},"512":{"position":[[94,9]]},"934":{"position":[[2055,9]]},"955":{"position":[[401,9]]},"979":{"position":[[1926,10]]},"997":{"position":[[75,10],[909,9]]},"1147":{"position":[[271,9],[749,9]]},"1680":{"position":[[174,9]]}}}],["detector",{"_index":695,"t":{"153":{"position":[[37,8],[88,8]]},"165":{"position":[[1056,8],[2169,8]]}}}],["determinist",{"_index":4768,"t":{"1462":{"position":[[347,13]]}}}],["detr",{"_index":698,"t":{"153":{"position":[[99,4]]},"174":{"position":[[131,4],[430,4]]},"182":{"position":[[192,4]]}}}],["dev",{"_index":909,"t":{"185":{"position":[[42,3]]},"324":{"position":[[92,3]]},"326":{"position":[[576,3]]},"464":{"position":[[39,3]]},"529":{"position":[[425,3]]},"816":{"position":[[51,3]]},"1111":{"position":[[708,3]]},"1134":{"position":[[490,3]]},"1136":{"position":[[545,3]]},"1323":{"position":[[206,3]]},"1357":{"position":[[114,3]]},"1496":{"position":[[586,3]]},"1663":{"position":[[188,3],[276,4]]},"1665":{"position":[[1471,3]]},"1669":{"position":[[588,3]]}}}],["develop",{"_index":118,"t":{"19":{"position":[[8,11],[294,11]]},"1393":{"position":[[413,11],[462,11],[577,11]]},"1397":{"position":[[81,11]]},"1636":{"position":[[185,12]]}}}],["deviat",{"_index":3715,"t":{"1070":{"position":[[1721,10]]}}}],["devlin",{"_index":2358,"t":{"666":{"position":[[86,6],[240,6]]},"683":{"position":[[137,7]]},"1415":{"position":[[205,7]]}}}],["devset",{"_index":1919,"t":{"529":{"position":[[1816,6]]}}}],["dff=2048d_{ff",{"_index":1255,"t":{"304":{"position":[[530,14]]}}}],["dffn=4×dmodeld_{ffn",{"_index":2583,"t":{"721":{"position":[[379,20]]}}}],["dhd_hdh",{"_index":2806,"t":{"789":{"position":[[736,8]]}}}],["dhiddend_{\\text{hidden}}dhidden",{"_index":4453,"t":{"1384":{"position":[[392,32]]}}}],["diagnosi",{"_index":5571,"t":{"1778":{"position":[[272,9],[319,9],[355,9],[587,9]]}}}],["diagon",{"_index":2781,"t":{"786":{"position":[[4034,8]]},"795":{"position":[[357,8],[707,8]]}}}],["dialog",{"_index":3461,"t":{"973":{"position":[[342,6]]},"1554":{"position":[[131,7]]}}}],["dialogu",{"_index":4976,"t":{"1577":{"position":[[82,8]]},"1682":{"position":[[619,8]]}}}],["dice",{"_index":882,"t":{"177":{"position":[[647,4]]}}}],["dicnli",{"_index":4651,"t":{"1429":{"position":[[1507,6]]}}}],["diff",{"_index":1832,"t":{"525":{"position":[[1148,4],[1433,4],[1550,4]]},"529":{"position":[[283,4],[332,4],[396,4],[545,4],[605,4]]},"786":{"position":[[959,4],[1027,4],[1143,4],[1255,4],[2275,4]]},"1230":{"position":[[70,4]]},"1384":{"position":[[3057,4]]}}}],["differ",{"_index":1834,"t":{"525":{"position":[[1217,10],[1238,10]]},"529":{"position":[[686,9]]},"709":{"position":[[558,10]]},"1084":{"position":[[955,9]]},"1384":{"position":[[2749,11],[3787,11]]}}}],["differenti",{"_index":3762,"t":{"1097":{"position":[[100,12]]},"1128":{"position":[[866,14]]}}}],["difficulti",{"_index":4681,"t":{"1431":{"position":[[2213,11]]},"1589":{"position":[[8,10]]}}}],["dignissim",{"_index":23,"t":{"3":{"position":[[200,9],[379,9],[558,9],[737,9],[916,9],[1095,9],[1274,9],[1453,9],[1632,9],[1811,9],[1990,9],[2169,9],[2348,9],[2527,9],[2706,9],[2885,9]]},"5":{"position":[[80,9]]}}}],["dilat",{"_index":1294,"t":{"310":{"position":[[1449,7]]}}}],["dim",{"_index":2266,"t":{"630":{"position":[[1319,3],[1342,3]]}}}],["dimens",{"_index":1178,"t":{"292":{"position":[[467,9]]},"298":{"position":[[74,9],[111,9]]},"300":{"position":[[171,10]]},"308":{"position":[[629,9]]},"310":{"position":[[1060,9]]},"324":{"position":[[204,10]]},"529":{"position":[[1390,9]]},"628":{"position":[[1162,9],[1261,10]]},"630":{"position":[[353,9],[465,9],[2156,9]]},"646":{"position":[[103,9]]},"650":{"position":[[93,9]]},"662":{"position":[[832,9],[890,9],[1079,9]]},"686":{"position":[[399,9]]},"694":{"position":[[47,9]]},"719":{"position":[[403,9]]},"721":{"position":[[78,10],[367,9]]},"723":{"position":[[753,9]]},"727":{"position":[[351,9]]},"733":{"position":[[156,10]]},"774":{"position":[[1104,9]]},"786":{"position":[[1079,9],[2019,9]]},"809":{"position":[[574,9],[593,9]]},"821":{"position":[[163,9]]},"891":{"position":[[351,9],[710,9]]},"895":{"position":[[364,9],[694,9]]},"984":{"position":[[381,9]]},"988":{"position":[[463,9]]},"994":{"position":[[100,9],[281,9]]},"1128":{"position":[[1563,9]]},"1130":{"position":[[745,9]]},"1305":{"position":[[449,9]]},"1341":{"position":[[834,9]]},"1350":{"position":[[471,9]]},"1477":{"position":[[379,9]]}}}],["dimension",{"_index":1206,"t":{"300":{"position":[[30,11],[332,11]]},"498":{"position":[[521,11]]},"598":{"position":[[3505,11]]},"630":{"position":[[991,11]]},"662":{"position":[[802,11]]},"778":{"position":[[70,11]]},"786":{"position":[[3888,11]]},"795":{"position":[[1325,11]]},"1341":{"position":[[880,11]]}}}],["diment",{"_index":2249,"t":{"628":{"position":[[1042,9]]}}}],["ding",{"_index":1002,"t":{"215":{"position":[[1764,7]]},"1492":{"position":[[118,4]]},"1496":{"position":[[218,4]]}}}],["direct",{"_index":817,"t":{"172":{"position":[[280,11]]},"555":{"position":[[37,6],[139,6],[191,6]]},"776":{"position":[[220,9]]},"778":{"position":[[566,9],[619,9]]},"1147":{"position":[[1085,9]]}}}],["directori",{"_index":40,"t":{"7":{"position":[[112,10],[431,10]]},"19":{"position":[[83,9]]},"1622":{"position":[[100,9]]}}}],["direict",{"_index":3968,"t":{"1147":{"position":[[873,11]]}}}],["disabl",{"_index":335,"t":{"63":{"position":[[177,7]]}}}],["disadvantag",{"_index":5537,"t":{"1750":{"position":[[395,13]]},"1752":{"position":[[336,13]]},"1754":{"position":[[302,13]]},"1756":{"position":[[507,13]]},"1758":{"position":[[230,13]]}}}],["disambigu",{"_index":2085,"t":{"594":{"position":[[907,14]]},"1111":{"position":[[231,14]]},"1113":{"position":[[471,14]]}}}],["disconnect",{"_index":1597,"t":{"434":{"position":[[150,10],[168,10]]},"436":{"position":[[527,10],[586,10],[1084,10],[1102,10],[1559,10],[1979,10],[2024,10]]},"447":{"position":[[57,13],[141,13],[312,10],[394,10],[512,13],[587,10]]},"455":{"position":[[875,10],[1035,13],[1119,13]]}}}],["discov",{"_index":78,"t":{"11":{"position":[[6,8]]}}}],["discoveri",{"_index":753,"t":{"168":{"position":[[601,9]]}}}],["discret",{"_index":585,"t":{"124":{"position":[[401,8]]},"130":{"position":[[696,8],[1522,8]]},"140":{"position":[[794,8]]},"159":{"position":[[55,8]]},"1014":{"position":[[643,8],[720,8]]},"1019":{"position":[[85,8]]},"1093":{"position":[[783,8],[868,8],[1090,8]]},"1095":{"position":[[355,8]]},"1097":{"position":[[0,8]]},"1099":{"position":[[39,8],[1139,8]]},"1101":{"position":[[63,12],[140,8],[527,12],[609,12]]},"1109":{"position":[[120,8]]},"1124":{"position":[[122,8]]},"1126":{"position":[[1095,8]]},"1151":{"position":[[133,8]]},"1230":{"position":[[426,8]]},"1303":{"position":[[636,8],[702,8],[909,8]]},"1328":{"position":[[243,8],[282,8],[392,8]]},"1473":{"position":[[128,8]]},"1646":{"position":[[1803,8]]},"1716":{"position":[[216,8]]},"1718":{"position":[[0,8]]},"1720":{"position":[[1036,8],[1441,8],[1457,8],[1545,8]]},"1730":{"position":[[54,8]]},"1736":{"position":[[76,8]]},"1756":{"position":[[170,8]]},"1762":{"position":[[279,8]]},"1782":{"position":[[252,8]]}}}],["discrimin",{"_index":1084,"t":{"236":{"position":[[555,14]]}}}],["disjoint",{"_index":3423,"t":{"934":{"position":[[1583,8]]},"949":{"position":[[336,10]]}}}],["disk",{"_index":2226,"t":{"614":{"position":[[256,4]]}}}],["display",{"_index":140,"t":{"19":{"position":[[450,8]]}}}],["dist",{"_index":2222,"t":{"614":{"position":[[106,4]]}}}],["distanc",{"_index":570,"t":{"116":{"position":[[700,8],[783,8]]},"774":{"position":[[432,8]]},"1141":{"position":[[866,10]]},"1151":{"position":[[404,8]]},"1275":{"position":[[207,8],[303,8]]}}}],["distil",{"_index":1064,"t":{"232":{"position":[[420,12]]},"648":{"position":[[1017,12]]},"851":{"position":[[132,12]]},"861":{"position":[[576,12],[623,12],[1637,12],[1705,12]]},"870":{"position":[[174,12],[497,12],[531,12],[1816,12],[1921,12],[1987,12]]},"873":{"position":[[21,12]]},"1115":{"position":[[767,12],[1119,12]]},"1145":{"position":[[1574,12]]},"1225":{"position":[[348,10]]},"1227":{"position":[[1112,12]]},"1230":{"position":[[804,12]]},"1234":{"position":[[10,12]]},"1236":{"position":[[563,12]]},"1240":{"position":[[281,12]]},"1244":{"position":[[194,12],[500,12],[1815,12],[1842,10],[2326,12]]},"1246":{"position":[[254,12]]},"1259":{"position":[[141,12]]},"1273":{"position":[[209,12],[384,12]]},"1275":{"position":[[7,12],[262,12],[283,12],[372,12]]},"1285":{"position":[[121,12]]},"1736":{"position":[[1062,12],[1113,12]]}}}],["distribut",{"_index":793,"t":{"170":{"position":[[1856,12]]},"310":{"position":[[1864,12]]},"660":{"position":[[1038,12]]},"696":{"position":[[127,12]]},"841":{"position":[[364,12]]},"851":{"position":[[695,12]]},"861":{"position":[[2007,12]]},"873":{"position":[[674,12],[1113,12]]},"979":{"position":[[1304,13],[1835,13]]},"1101":{"position":[[169,12]]},"1107":{"position":[[498,12]]},"1244":{"position":[[717,13],[1143,12]]},"1296":{"position":[[962,12]]},"1300":{"position":[[87,12]]},"1303":{"position":[[377,12]]},"1485":{"position":[[809,12]]},"1558":{"position":[[1913,12]]}}}],["diverg",{"_index":3242,"t":{"861":{"position":[[1921,10]]},"1244":{"position":[[659,10]]}}}],["divid",{"_index":4345,"t":{"1332":{"position":[[246,8]]}}}],["dk=dv=dmodel/h=64d_k",{"_index":1235,"t":{"300":{"position":[[1266,20]]}}}],["dk\\sqrt{d_k}dk",{"_index":1191,"t":{"298":{"position":[[188,16]]}}}],["dkd_kdk",{"_index":1189,"t":{"298":{"position":[[84,8],[973,8],[1025,8],[1114,8]]},"300":{"position":[[141,9],[151,8]]}}}],["dkld_{\\text{kl}}dkl",{"_index":3240,"t":{"861":{"position":[[1895,20]]}}}],["dld_ldl",{"_index":2265,"t":{"630":{"position":[[1310,8]]}}}],["dlr\\frac{d_l}{r}rdl",{"_index":2275,"t":{"630":{"position":[[1643,21]]}}}],["dl×d",{"_index":3707,"t":{"1070":{"position":[[977,4]]},"1248":{"position":[[70,4]]}}}],["dmid=256d_\\text{mid",{"_index":4558,"t":{"1395":{"position":[[978,20]]}}}],["dmid=48d_\\text{mid",{"_index":4546,"t":{"1393":{"position":[[1016,19]]},"1395":{"position":[[580,19],[1037,20]]}}}],["dmid=8d_\\text{mid",{"_index":4548,"t":{"1393":{"position":[[1059,18]]}}}],["dmidd_\\text{mid}dmid",{"_index":4554,"t":{"1395":{"position":[[544,21],[827,22],[858,21]]}}}],["dmidd_{\\text{mid}}dmid",{"_index":4454,"t":{"1384":{"position":[[443,23]]}}}],["dmodel=1024d_{model",{"_index":1366,"t":{"326":{"position":[[292,20]]}}}],["dmodel=512d_\\text{model",{"_index":1253,"t":{"304":{"position":[[466,24]]}}}],["dmodel=512d_{\\text{model",{"_index":1179,"t":{"292":{"position":[[477,26]]}}}],["dmodel\\sqrt{d_\\text{model}}dmodel",{"_index":1259,"t":{"306":{"position":[[360,35]]}}}],["dmodeld_\\text{model}dmodel",{"_index":1257,"t":{"306":{"position":[[57,27]]},"308":{"position":[[215,27]]}}}],["dmodeld_{\\text{model}}dmodel",{"_index":1205,"t":{"300":{"position":[[0,29]]}}}],["dmodeld_{model}dmodel",{"_index":2575,"t":{"721":{"position":[[91,22]]}}}],["dmodel×(lp+li)|\\theta",{"_index":2661,"t":{"751":{"position":[[128,26]]}}}],["dm×d",{"_index":3558,"t":{"994":{"position":[[55,4]]}}}],["dm≪d",{"_index":2349,"t":{"662":{"position":[[978,4]]}}}],["dn2dm+2d+dn",{"_index":4084,"t":{"1218":{"position":[[558,11]]}}}],["dndndn",{"_index":4085,"t":{"1218":{"position":[[674,6]]}}}],["doc",{"_index":5039,"t":{"1595":{"position":[[52,4]]},"1602":{"position":[[48,5]]},"1604":{"position":[[79,4],[168,4],[249,4],[327,4]]},"1606":{"position":[[226,4]]},"1608":{"position":[[33,4]]},"1618":{"position":[[86,3]]}}}],["doc.md",{"_index":5093,"t":{"1618":{"position":[[68,6]]}}}],["docs/curr",{"_index":5143,"t":{"1634":{"position":[[94,13]]}}}],["docs/current/intro.md",{"_index":5145,"t":{"1634":{"position":[[159,21],[225,21]]}}}],["docs/hello.md",{"_index":5036,"t":{"1593":{"position":[[26,14],[41,13]]},"1595":{"position":[[123,13]]},"1608":{"position":[[143,13]]}}}],["docs/intro.md",{"_index":135,"t":{"19":{"position":[[368,13]]},"1630":{"position":[[16,13]]},"1634":{"position":[[9,13],[111,13]]}}}],["docs:vers",{"_index":5057,"t":{"1604":{"position":[[58,12]]}}}],["docstr",{"_index":1736,"t":{"496":{"position":[[93,9]]}}}],["docsversiondropdown",{"_index":5066,"t":{"1606":{"position":[[184,22]]}}}],["document",{"_index":4096,"t":{"1234":{"position":[[132,8]]},"1583":{"position":[[18,13]]},"1591":{"position":[[0,9]]},"1593":{"position":[[93,11],[111,8]]},"1595":{"position":[[224,11],[447,11]]},"1618":{"position":[[9,9],[103,8],[134,8]]},"1628":{"position":[[18,13]]},"1772":{"position":[[34,8],[131,8]]}}}],["docusauru",{"_index":31,"t":{"7":{"position":[[0,10],[470,10]]},"9":{"position":[[19,10]]},"11":{"position":[[15,10]]},"13":{"position":[[43,10]]},"17":{"position":[[15,10],[389,11]]},"19":{"position":[[155,10]]},"1581":{"position":[[36,10],[94,10]]},"1583":{"position":[[207,10],[247,10]]},"1585":{"position":[[0,10]]},"1587":{"position":[[164,10],[289,10]]},"1593":{"position":[[82,10]]},"1595":{"position":[[0,10],[213,10]]},"1597":{"position":[[0,10]]},"1602":{"position":[[0,10]]},"1604":{"position":[[47,10]]},"1616":{"position":[[0,10]]},"1622":{"position":[[139,12],[329,12]]},"1626":{"position":[[0,10]]},"1628":{"position":[[512,10]]}}}],["docusaurus!</h1",{"_index":5110,"t":{"1624":{"position":[[159,16],[265,17]]}}}],["docusaurus.config.j",{"_index":4990,"t":{"1583":{"position":[[68,20]]},"1606":{"position":[[75,20],[102,20]]},"1632":{"position":[[7,20],[62,20]]},"1638":{"position":[[75,20],[102,20]]}}}],["docusaurus.new",{"_index":87,"t":{"13":{"position":[[71,15]]}}}],["docusaurus@latest",{"_index":107,"t":{"17":{"position":[[160,17]]}}}],["docvqa",{"_index":3460,"t":{"971":{"position":[[210,6]]}}}],["dolor",{"_index":15,"t":{"3":{"position":[[132,5],[284,5],[311,5],[463,5],[490,5],[642,5],[669,5],[821,5],[848,5],[1000,5],[1027,5],[1179,5],[1206,5],[1358,5],[1385,5],[1537,5],[1564,5],[1716,5],[1743,5],[1895,5],[1922,5],[2074,5],[2101,5],[2253,5],[2280,5],[2432,5],[2459,5],[2611,5],[2638,5],[2790,5],[2817,5],[2969,5]]},"5":{"position":[[12,5],[164,5]]}}}],["domain",{"_index":742,"t":{"165":{"position":[[874,6],[939,6],[2375,6],[2791,7]]},"213":{"position":[[234,6],[371,6],[497,6]]},"215":{"position":[[304,6],[408,6]]},"219":{"position":[[156,6],[205,6]]},"221":{"position":[[321,6],[383,6]]},"227":{"position":[[162,6]]},"234":{"position":[[448,6]]},"242":{"position":[[3,6]]},"258":{"position":[[68,6]]},"260":{"position":[[139,6]]},"279":{"position":[[102,6]]},"336":{"position":[[308,6]]},"352":{"position":[[355,6]]},"356":{"position":[[106,6]]},"424":{"position":[[384,6]]},"436":{"position":[[327,6]]},"979":{"position":[[1417,7],[1571,6]]},"1004":{"position":[[395,6]]},"1006":{"position":[[2412,6],[2831,6]]},"1124":{"position":[[583,6]]},"1126":{"position":[[2325,6],[2602,6]]},"1147":{"position":[[202,6],[296,6],[369,6],[402,6],[456,6],[501,6],[600,6],[692,6],[926,7],[955,7],[1198,6]]},"1151":{"position":[[1969,6]]},"1153":{"position":[[197,6],[376,6]]},"1310":{"position":[[118,6],[137,7],[169,6]]},"1317":{"position":[[561,6]]},"1341":{"position":[[173,6]]},"1429":{"position":[[1723,6]]},"1431":{"position":[[2225,6]]},"1517":{"position":[[290,6],[297,7]]},"1680":{"position":[[80,6],[144,6],[209,6]]},"1682":{"position":[[612,6]]},"1718":{"position":[[866,6]]},"1778":{"position":[[62,6]]},"1782":{"position":[[1794,6]]},"1794":{"position":[[864,7]]}}}],["don't",{"_index":61,"t":{"7":{"position":[[395,5]]}}}],["donwstream",{"_index":4231,"t":{"1291":{"position":[[59,10]]},"1667":{"position":[[490,10]]}}}],["dop",{"_index":1357,"t":{"324":{"position":[[387,3]]}}}],["dot",{"_index":1162,"t":{"289":{"position":[[127,6],[209,6],[297,6]]},"298":{"position":[[28,3],[165,3],[608,3],[652,3],[864,3],[1076,3],[1128,3],[1212,3]]},"300":{"position":[[718,6]]},"302":{"position":[[709,3]]},"310":{"position":[[67,6],[126,6]]},"596":{"position":[[323,6],[898,6]]},"694":{"position":[[331,6],[677,6]]},"789":{"position":[[353,6]]},"797":{"position":[[1152,6]]},"984":{"position":[[102,6],[287,6]]},"988":{"position":[[242,6]]},"1019":{"position":[[594,6],[709,6]]},"1099":{"position":[[118,6],[267,6],[1543,5],[1576,5]]},"1128":{"position":[[680,6],[1475,5]]},"1167":{"position":[[136,5],[303,5],[331,5]]},"1236":{"position":[[87,6],[209,6]]},"1238":{"position":[[590,6]]},"1246":{"position":[[971,6]]},"1350":{"position":[[157,6]]},"1352":{"position":[[711,6]]},"1431":{"position":[[517,6]]},"1477":{"position":[[239,6],[450,6]]},"1485":{"position":[[252,6]]},"1487":{"position":[[377,6],[663,6]]},"1655":{"position":[[456,5],[466,5],[476,5],[597,5],[1016,8],[1546,8],[1955,8]]}}}],["dots,n,}z={(xi​,yi​)}i=1,…,n",{"_index":2590,"t":{"723":{"position":[[242,31]]}}}],["dots,s_k",{"_index":4189,"t":{"1246":{"position":[[184,9]]}}}],["doublet",{"_index":2830,"t":{"791":{"position":[[719,7]]},"795":{"position":[[1552,7],[1581,7],[1665,7],[1708,7],[1857,8],[1882,8]]},"835":{"position":[[28,7],[73,8],[121,8]]}}}],["down",{"_index":1060,"t":{"227":{"position":[[839,4]]},"234":{"position":[[186,4]]},"644":{"position":[[430,4]]},"988":{"position":[[859,4]]},"990":{"position":[[657,4]]},"1167":{"position":[[775,4]]},"1172":{"position":[[21,4]]},"1218":{"position":[[122,4]]}}}],["down+up",{"_index":4451,"t":{"1384":{"position":[[246,7]]}}}],["downsampl",{"_index":2259,"t":{"630":{"position":[[1022,12]]}}}],["downstream",{"_index":480,"t":{"97":{"position":[[36,10],[168,10]]},"177":{"position":[[996,10]]},"269":{"position":[[199,10]]},"334":{"position":[[218,10]]},"336":{"position":[[140,10],[460,10],[847,10]]},"352":{"position":[[236,10]]},"483":{"position":[[212,10],[308,10]]},"485":{"position":[[63,10],[116,10],[791,10],[882,10],[967,10],[1673,10]]},"502":{"position":[[469,10]]},"515":{"position":[[250,10]]},"589":{"position":[[207,10],[338,10],[581,10]]},"600":{"position":[[59,10],[438,10]]},"602":{"position":[[45,10],[523,10],[632,10]]},"628":{"position":[[939,10],[1465,10]]},"630":{"position":[[295,10]]},"648":{"position":[[50,10],[760,10],[923,10]]},"656":{"position":[[72,10]]},"658":{"position":[[409,10],[971,10],[1055,10]]},"660":{"position":[[7,10],[180,10],[338,10],[398,10]]},"686":{"position":[[23,10],[445,10]]},"698":{"position":[[2,10]]},"717":{"position":[[168,10]]},"719":{"position":[[12,10]]},"723":{"position":[[136,10],[670,10]]},"729":{"position":[[125,10]]},"737":{"position":[[3,10]]},"739":{"position":[[244,11]]},"784":{"position":[[43,10],[153,10]]},"786":{"position":[[190,10]]},"847":{"position":[[448,10],[556,10]]},"849":{"position":[[63,10],[147,10],[510,10],[1505,10]]},"851":{"position":[[1116,10],[1232,10]]},"879":{"position":[[89,10]]},"955":{"position":[[763,10]]},"1062":{"position":[[18,10]]},"1070":{"position":[[420,10]]},"1093":{"position":[[1544,10]]},"1095":{"position":[[63,10],[223,10]]},"1099":{"position":[[349,10],[1818,10]]},"1124":{"position":[[23,10],[456,10]]},"1126":{"position":[[11,10],[612,10],[839,10],[1034,10],[1531,10],[1783,10]]},"1132":{"position":[[1260,10],[1355,10],[1605,10]]},"1141":{"position":[[346,10]]},"1143":{"position":[[234,10]]},"1153":{"position":[[40,10],[308,10]]},"1162":{"position":[[0,10]]},"1167":{"position":[[1052,10]]},"1225":{"position":[[119,10],[409,10]]},"1227":{"position":[[47,10]]},"1238":{"position":[[1307,10]]},"1240":{"position":[[383,10]]},"1257":{"position":[[71,10]]},"1273":{"position":[[314,10]]},"1285":{"position":[[360,10]]},"1289":{"position":[[55,10]]},"1341":{"position":[[926,10]]},"1401":{"position":[[40,10]]},"1407":{"position":[[37,10]]},"1409":{"position":[[193,10],[503,10]]},"1417":{"position":[[32,10]]},"1466":{"position":[[243,10]]},"1473":{"position":[[94,10]]},"1481":{"position":[[90,10]]},"1487":{"position":[[146,10]]},"1494":{"position":[[228,10]]},"1499":{"position":[[896,10]]},"1558":{"position":[[80,10]]},"1646":{"position":[[181,10],[598,10]]},"1667":{"position":[[284,10],[1077,10]]},"1695":{"position":[[695,10],[869,10],[913,10]]},"1710":{"position":[[30,10]]},"1718":{"position":[[592,10],[983,10]]},"1720":{"position":[[223,10]]},"1736":{"position":[[170,10]]},"1746":{"position":[[291,10],[322,10],[380,10]]},"1748":{"position":[[10,10]]},"1750":{"position":[[71,10]]},"1754":{"position":[[51,10]]},"1756":{"position":[[578,10],[617,10]]},"1782":{"position":[[3266,10]]},"1796":{"position":[[84,10],[108,10]]}}}],["downweight",{"_index":4512,"t":{"1389":{"position":[[548,14]]}}}],["dp",{"_index":1762,"t":{"502":{"position":[[331,2]]}}}],["dpretraind_{pretrain}dpretrain",{"_index":4960,"t":{"1558":{"position":[[1867,31]]}}}],["dret",{"_index":699,"t":{"153":{"position":[[127,4],[178,4]]}}}],["drf",{"_index":5445,"t":{"1718":{"position":[[890,6],[925,3]]},"1778":{"position":[[178,4]]}}}],["driven",{"_index":4695,"t":{"1440":{"position":[[15,6]]}}}],["drop",{"_index":196,"t":{"27":{"position":[[287,4]]},"49":{"position":[[464,8]]},"78":{"position":[[701,4]]},"786":{"position":[[4346,4]]},"1307":{"position":[[505,4]]},"1429":{"position":[[1427,5]]},"1546":{"position":[[906,5]]}}}],["dropdown",{"_index":5065,"t":{"1606":{"position":[[54,9],[239,8]]},"1638":{"position":[[54,9],[228,8]]}}}],["dropout",{"_index":253,"t":{"49":{"position":[[202,7],[445,7]]},"53":{"position":[[340,7]]},"78":{"position":[[558,8],[740,7]]},"112":{"position":[[212,7]]},"153":{"position":[[717,7]]},"319":{"position":[[43,8],[75,7],[182,7]]},"322":{"position":[[382,7]]},"324":{"position":[[456,7]]},"326":{"position":[[587,8]]},"550":{"position":[[96,8]]},"1558":{"position":[[288,7]]}}}],["dtd",{"_index":1504,"t":{"374":{"position":[[55,3]]}}}],["dtrain32\\mathcal{d}_{train32}dtrain32",{"_index":3857,"t":{"1111":{"position":[[516,40]]}}}],["dtrain\\mathcal{d}_{train}dtrain",{"_index":3854,"t":{"1111":{"position":[[315,34]]}}}],["dual",{"_index":1758,"t":{"502":{"position":[[71,4]]}}}],["dublet",{"_index":2865,"t":{"795":{"position":[[1639,6]]}}}],["dunlabeled\\mathcal{d}_{unlabeled}dunlabel",{"_index":3859,"t":{"1111":{"position":[[593,46]]}}}],["duplic",{"_index":2254,"t":{"630":{"position":[[540,11],[577,11]]}}}],["dvd_vdv",{"_index":1190,"t":{"298":{"position":[[121,8]]},"300":{"position":[[162,8],[323,8]]}}}],["dxd_xdx",{"_index":4811,"t":{"1485":{"position":[[784,8]]}}}],["dynam",{"_index":843,"t":{"174":{"position":[[871,7]]},"205":{"position":[[106,7],[246,7]]},"533":{"position":[[412,7]]},"843":{"position":[[307,11]]},"934":{"position":[[1295,7],[1389,7]]},"961":{"position":[[96,7]]}}}],["d};ps​∈rm×d",{"_index":3677,"t":{"1067":{"position":[[209,12]]}}}],["d}[log(\\sigma",{"_index":4935,"t":{"1558":{"position":[[762,13]]}}}],["d}[p;t]∈r(l+n)×d",{"_index":4129,"t":{"1238":{"position":[[1021,16]]}}}],["d}[p;wi​]∈r(l+1s)×d",{"_index":3670,"t":{"1065":{"position":[[614,19]]}}}],["d}b∈rr×d",{"_index":3681,"t":{"1067":{"position":[[388,8]]}}}],["d}fins​∈rn×d",{"_index":847,"t":{"174":{"position":[[1238,12]]}}}],["d}fp​∈r1024×d",{"_index":786,"t":{"170":{"position":[[1453,13]]}}}],["d}fp​∈rl×d",{"_index":760,"t":{"170":{"position":[[483,10]]}}}],["d}p=[p1​,…,pm​]∈rm×d",{"_index":3486,"t":{"984":{"position":[[324,21]]}}}],["d}p^k​∈r100×d",{"_index":4213,"t":{"1255":{"position":[[183,14]]}}}],["d}pj​∈rm×d",{"_index":3513,"t":{"988":{"position":[[374,10]]}}}],["d}p∈rl×d",{"_index":3664,"t":{"1065":{"position":[[359,8]]},"1067":{"position":[[109,8]]},"1238":{"position":[[730,8]]}}}],["d}p∗∈rl×d",{"_index":4133,"t":{"1242":{"position":[[261,9]]}}}],["d}t=[t1​,t2​,…,tn​]∈rn×d",{"_index":4122,"t":{"1238":{"position":[[627,24]]}}}],["d}wf2​∈rdm​×d",{"_index":2816,"t":{"789":{"position":[[1062,13]]}}}],["d}wi​∈rs×d",{"_index":3662,"t":{"1065":{"position":[[265,10]]}}}],["d}wo​∈rd×d",{"_index":2801,"t":{"789":{"position":[[570,10]]}}}],["d}wup​∈rm×d",{"_index":4028,"t":{"1167":{"position":[[918,11]]},"1218":{"position":[[256,11]]}}}],["d}w∈r1×d",{"_index":852,"t":{"174":{"position":[[1822,8]]}}}],["d}x∈rl×d",{"_index":3511,"t":{"988":{"position":[[315,8]]}}}],["d}x∈rn×d",{"_index":2794,"t":{"789":{"position":[[185,9]]}}}],["d}x∈rt×d",{"_index":2149,"t":{"598":{"position":[[965,8]]}}}],["d}zo​=[xclass",{"_index":454,"t":{"91":{"position":[[1762,15]]}}}],["d×kd",{"_index":482,"t":{"97":{"position":[[115,4]]}}}],["d×m+2rd+2dn=d(m+2(r+1)/n)d",{"_index":3562,"t":{"994":{"position":[[351,26]]}}}],["d×nd",{"_index":4077,"t":{"1218":{"position":[[351,4]]}}}],["d×r+r×d+2d=2rd+2dd",{"_index":3559,"t":{"994":{"position":[[172,18]]}}}],["e",{"_index":249,"t":{"49":{"position":[[167,2]]},"91":{"position":[[1677,1]]},"308":{"position":[[971,2]]},"324":{"position":[[486,3]]},"1095":{"position":[[13,1],[219,1]]},"1185":{"position":[[273,1]]},"1768":{"position":[[467,4]]}}}],["e([\\text{p}_{0:i",{"_index":3791,"t":{"1099":{"position":[[1286,20]]}}}],["e([\\text{p}_{i+1:m",{"_index":3793,"t":{"1099":{"position":[[1320,22]]}}}],["e([p0:i]),e(x),e([pi+1:m]),e(y)}\\begin{equ",{"_index":3790,"t":{"1099":{"position":[[1233,49]]}}}],["e(\\text{\"[mask]\"})][e(x),e(\"it\"),e(\"is\"),e(\"[mask",{"_index":3623,"t":{"1019":{"position":[[353,53]]}}}],["e(\\text{\"[mask]\"})][e(x),h0​,…,hi​,e(\"[mask",{"_index":3629,"t":{"1019":{"position":[[721,47]]}}}],["e(\\text{\"i",{"_index":3622,"t":{"1019":{"position":[[337,15]]}}}],["e(\\text{\"it",{"_index":3621,"t":{"1019":{"position":[[321,15]]}}}],["e(\\text{i",{"_index":3794,"t":{"1099":{"position":[[1343,11],[1587,11]]}}}],["e(\\text{x",{"_index":3792,"t":{"1099":{"position":[[1307,12],[1554,12]]}}}],["e(s)]x^=concat[p′,e(",{"_index":4059,"t":{"1187":{"position":[[283,23]]}}}],["e(s[eos])]x^=concat[e([cls]),p′,e(s[eo",{"_index":4048,"t":{"1185":{"position":[[144,42]]}}}],["e(x),e(\"it\"),e(\"is\"),e(\"[mask]\")][e(\\text{x",{"_index":3620,"t":{"1019":{"position":[[273,47]]}}}],["e(x),h0,…,hi,e(\"[mask]\")][e(\\text{x",{"_index":3626,"t":{"1019":{"position":[[664,39]]}}}],["e(x0),e(x1),…,e(xn",{"_index":3770,"t":{"1099":{"position":[[227,23]]}}}],["e(x0​),e(x1​),…,e(xn",{"_index":3774,"t":{"1099":{"position":[[281,26]]}}}],["e(x_0",{"_index":3771,"t":{"1099":{"position":[[251,7]]}}}],["e(x_1",{"_index":3772,"t":{"1099":{"position":[[259,7]]}}}],["e(x_n",{"_index":3773,"t":{"1099":{"position":[[274,6]]}}}],["e)z1=l1​(pi1​,",{"_index":2513,"t":{"694":{"position":[[559,16]]}}}],["e.g",{"_index":359,"t":{"78":{"position":[[551,6]]},"221":{"position":[[586,5],[627,5]]},"225":{"position":[[105,5]]},"227":{"position":[[619,4]]},"422":{"position":[[39,5]]},"424":{"position":[[49,5]]},"541":{"position":[[141,5]]},"569":{"position":[[195,5]]},"587":{"position":[[265,5]]},"589":{"position":[[1354,5]]},"594":{"position":[[1399,5]]},"608":{"position":[[218,5]]},"786":{"position":[[2042,5],[3103,7]]},"803":{"position":[[362,5]]},"807":{"position":[[438,5]]},"932":{"position":[[723,5]]},"953":{"position":[[461,5]]},"967":{"position":[[276,5]]},"979":{"position":[[1896,5]]},"1006":{"position":[[2495,5]]},"1008":{"position":[[614,5]]},"1014":{"position":[[448,5]]},"1031":{"position":[[139,5],[201,5]]},"1045":{"position":[[40,5]]},"1087":{"position":[[165,5]]},"1093":{"position":[[231,5],[313,5],[386,5]]},"1151":{"position":[[1559,5],[1987,5]]},"1159":{"position":[[91,5],[500,7]]},"1291":{"position":[[75,5],[1013,5],[1557,5]]},"1296":{"position":[[7,5]]},"1298":{"position":[[74,5]]},"1303":{"position":[[81,5],[143,5],[503,5]]},"1389":{"position":[[186,5]]},"1395":{"position":[[111,5],[1263,5],[1491,5]]},"1399":{"position":[[730,5]]},"1427":{"position":[[1106,5],[1154,5],[1228,5]]},"1431":{"position":[[2063,5]]},"1646":{"position":[[454,5]]}}}],["e1e^1e1",{"_index":4636,"t":{"1429":{"position":[[444,8],[778,8]]}}}],["e2",{"_index":4208,"t":{"1253":{"position":[[366,3]]},"1266":{"position":[[138,3]]},"1310":{"position":[[50,4],[101,3]]},"1334":{"position":[[92,3]]}}}],["e2e^2e2",{"_index":4637,"t":{"1429":{"position":[[453,7],[787,7]]}}}],["e2vpt",{"_index":2459,"t":{"683":{"position":[[1118,5]]}}}],["e={λk}k=1n\\mathcal{",{"_index":2885,"t":{"797":{"position":[[624,21]]}}}],["e^2_j),sim(t1,t2)=l21​i∑​j∑​cos(ej1​,ej2",{"_index":4649,"t":{"1429":{"position":[[1056,43]]}}}],["e^t)sim(es,et",{"_index":4656,"t":{"1431":{"position":[[344,14]]}}}],["e^t_{\\text{great}}h[cls]​egreatt",{"_index":3204,"t":{"859":{"position":[[308,33]]}}}],["e_",{"_index":5204,"t":{"1655":{"position":[[462,3],[937,5],[1842,3]]}}}],["e_o",{"_index":5205,"t":{"1655":{"position":[[472,3],[1827,5],[1865,5],[1897,5]]},"1657":{"position":[[910,3]]}}}],["e_o}(\\cdot",{"_index":5226,"t":{"1655":{"position":[[1495,10]]}}}],["e_o}(a",{"_index":5241,"t":{"1657":{"position":[[86,8]]}}}],["e_o}(a,'\\text{",{"_index":5188,"t":{"1651":{"position":[[1200,15]]}}}],["e_o}fes​,eo",{"_index":5230,"t":{"1655":{"position":[[1632,13]]}}}],["e_t)},αr​=∑l=1k​sim(esl​,et​)sim(esr​,et",{"_index":4667,"t":{"1431":{"position":[[1035,44]]}}}],["e_t)}{\\sum^k_{l=1}sim(e^{s_l",{"_index":4666,"t":{"1431":{"position":[[1004,30]]}}}],["e_{(x,i",{"_index":4949,"t":{"1558":{"position":[[1519,8]]}}}],["e_{po",{"_index":452,"t":{"91":{"position":[[1667,9],[1723,7]]}}}],["e_{x",{"_index":4954,"t":{"1558":{"position":[[1635,4]]}}}],["each",{"_index":3905,"t":{"1130":{"position":[[90,4]]},"1427":{"position":[[605,4]]},"1585":{"position":[[30,4]]}}}],["earli",{"_index":348,"t":{"78":{"position":[[133,5],[269,5],[474,5],[815,5]]},"165":{"position":[[1974,5]]},"172":{"position":[[225,5],[771,5]]},"174":{"position":[[1665,5]]},"203":{"position":[[65,5],[97,5],[206,5]]},"322":{"position":[[640,5]]},"932":{"position":[[341,5],[365,5]]},"934":{"position":[[1243,5],[2415,5]]},"953":{"position":[[101,5],[590,5]]},"967":{"position":[[327,5]]},"1111":{"position":[[1572,5]]},"1134":{"position":[[746,5]]},"1429":{"position":[[303,5]]},"1496":{"position":[[597,5]]}}}],["easili",{"_index":5054,"t":{"1600":{"position":[[160,7]]}}}],["ecod",{"_index":3402,"t":{"912":{"position":[[146,7]]}}}],["edg",{"_index":1042,"t":{"227":{"position":[[280,5]]}}}],["edit",{"_index":137,"t":{"19":{"position":[[398,4]]},"1587":{"position":[[485,4]]},"1608":{"position":[[18,4]]}}}],["editor",{"_index":115,"t":{"17":{"position":[[312,7]]}}}],["eee",{"_index":478,"t":{"95":{"position":[[115,3],[349,3]]},"694":{"position":[[907,3]]},"1019":{"position":[[81,3]]},"1101":{"position":[[116,3]]},"1128":{"position":[[1575,3]]},"1130":{"position":[[723,3]]},"1350":{"position":[[481,3]]},"1477":{"position":[[357,3]]}}}],["effect",{"_index":349,"t":{"78":{"position":[[150,9]]},"97":{"position":[[272,9]]},"658":{"position":[[2949,9]]},"709":{"position":[[1947,6]]},"1006":{"position":[[1512,7]]},"1646":{"position":[[2680,9]]}}}],["effici",{"_index":1590,"t":{"428":{"position":[[259,9]]},"504":{"position":[[130,9],[556,9]]},"525":{"position":[[1459,10]]},"527":{"position":[[324,9]]},"567":{"position":[[756,9]]},"587":{"position":[[236,9]]},"589":{"position":[[56,9],[1228,9]]},"622":{"position":[[77,9]]},"648":{"position":[[26,9]]},"658":{"position":[[1295,9],[1344,9],[2886,9]]},"662":{"position":[[1109,9],[1562,9]]},"664":{"position":[[39,9]]},"672":{"position":[[25,9],[1267,9]]},"681":{"position":[[325,9],[970,9]]},"683":{"position":[[533,9],[612,9]]},"686":{"position":[[61,9]]},"707":{"position":[[490,9]]},"723":{"position":[[893,9]]},"727":{"position":[[43,9],[179,9]]},"739":{"position":[[159,10]]},"786":{"position":[[888,9],[1231,9]]},"791":{"position":[[811,9],[968,9]]},"809":{"position":[[191,9],[628,9]]},"843":{"position":[[14,9]]},"847":{"position":[[872,9]]},"855":{"position":[[84,9]]},"870":{"position":[[943,9]]},"887":{"position":[[339,10],[1249,9]]},"932":{"position":[[138,9]]},"934":{"position":[[265,9],[465,9],[1995,9],[2235,9]]},"938":{"position":[[42,9]]},"945":{"position":[[978,9]]},"947":{"position":[[27,9]]},"955":{"position":[[150,9]]},"973":{"position":[[16,9]]},"977":{"position":[[27,9],[591,9]]},"979":{"position":[[262,9],[909,9],[1638,9]]},"982":{"position":[[93,9],[1151,10]]},"1002":{"position":[[67,11]]},"1008":{"position":[[283,10]]},"1028":{"position":[[467,9]]},"1056":{"position":[[129,9]]},"1060":{"position":[[114,9],[1168,9]]},"1070":{"position":[[1321,9]]},"1126":{"position":[[1823,9]]},"1145":{"position":[[246,9]]},"1153":{"position":[[515,9],[546,9]]},"1157":{"position":[[210,9]]},"1164":{"position":[[476,9]]},"1172":{"position":[[255,10]]},"1176":{"position":[[184,9]]},"1197":{"position":[[464,9]]},"1227":{"position":[[331,9]]},"1230":{"position":[[385,9]]},"1232":{"position":[[308,9]]},"1238":{"position":[[358,9],[1386,9]]},"1250":{"position":[[121,9]]},"1257":{"position":[[329,9]]},"1262":{"position":[[30,9],[98,9],[211,9]]},"1268":{"position":[[182,9]]},"1285":{"position":[[389,9]]},"1317":{"position":[[464,9]]},"1334":{"position":[[5,10]]},"1345":{"position":[[55,9]]},"1347":{"position":[[48,9],[1729,9]]},"1367":{"position":[[128,9]]},"1369":{"position":[[458,9],[640,9]]},"1377":{"position":[[13,9]]},"1379":{"position":[[135,9]]},"1399":{"position":[[85,11],[312,9],[433,11],[455,10]]},"1401":{"position":[[10,9]]},"1403":{"position":[[21,9]]},"1466":{"position":[[550,9]]},"1468":{"position":[[1351,9]]},"1507":{"position":[[37,10],[115,9]]},"1515":{"position":[[261,9]]},"1646":{"position":[[2666,9]]}}}],["efficieci",{"_index":4357,"t":{"1347":{"position":[[557,9]]}}}],["efficientnet",{"_index":171,"t":{"25":{"position":[[244,12]]},"27":{"position":[[34,12],[94,12]]},"31":{"position":[[0,12]]},"33":{"position":[[0,12],[243,12]]},"35":{"position":[[0,12],[146,12]]},"38":{"position":[[74,12],[255,12]]},"40":{"position":[[32,12],[131,12]]},"53":{"position":[[99,12]]},"55":{"position":[[57,12]]},"68":{"position":[[17,13]]},"76":{"position":[[134,12],[192,12]]},"78":{"position":[[782,12]]},"110":{"position":[[53,12]]}}}],["efficientnetn2",{"_index":320,"t":{"60":{"position":[[12,14]]}}}],["efficientnetv2",{"_index":142,"t":{"23":{"position":[[0,15]]},"40":{"position":[[3,14]]},"42":{"position":[[15,14],[46,14],[124,14]]},"44":{"position":[[93,14]]},"55":{"position":[[38,14],[104,14]]},"65":{"position":[[27,14]]},"68":{"position":[[0,14]]}}}],["egreate_{\\text{great}}egreat",{"_index":3207,"t":{"859":{"position":[[430,29]]}}}],["ei1e^1_iei1",{"_index":4642,"t":{"1429":{"position":[[749,13]]}}}],["ei2e^2_iei2",{"_index":4643,"t":{"1429":{"position":[[763,12]]}}}],["eisner",{"_index":4353,"t":{"1347":{"position":[[347,7]]}}}],["ej1e^1_jej1",{"_index":4645,"t":{"1429":{"position":[[900,14]]}}}],["ej2e^2_jej2",{"_index":4646,"t":{"1429":{"position":[[915,13]]}}}],["ek",{"_index":251,"t":{"49":{"position":[[192,5]]}}}],["eleanor",{"_index":5558,"t":{"1770":{"position":[[297,8]]}}}],["electr",{"_index":1660,"t":{"457":{"position":[[263,13]]}}}],["electra",{"_index":4777,"t":{"1471":{"position":[[130,8]]}}}],["elemen",{"_index":2949,"t":{"801":{"position":[[164,6]]}}}],["element",{"_index":2141,"t":{"598":{"position":[[748,7],[904,7],[2777,7]]},"786":{"position":[[1127,7]]},"940":{"position":[[250,7]]},"1062":{"position":[[1186,7]]}}}],["elementum",{"_index":22,"t":{"3":{"position":[[190,9],[369,9],[548,9],[727,9],[906,9],[1085,9],[1264,9],[1443,9],[1622,9],[1801,9],[1980,9],[2159,9],[2338,9],[2517,9],[2696,9],[2875,9]]},"5":{"position":[[70,9]]}}}],["elementwis",{"_index":2181,"t":{"598":{"position":[[2675,11]]}}}],["eleph",{"_index":4344,"t":{"1332":{"position":[[233,10]]}}}],["elit",{"_index":20,"t":{"3":{"position":[[171,5],[350,5],[529,5],[708,5],[887,5],[1066,5],[1245,5],[1424,5],[1603,5],[1782,5],[1961,5],[2140,5],[2319,5],[2498,5],[2677,5],[2856,5]]},"5":{"position":[[51,5]]}}}],["ell",{"_index":1837,"t":{"527":{"position":[[505,6],[1244,6],[1257,6],[1270,6],[1287,6],[1300,6]]}}}],["ell)(m",{"_index":1839,"t":{"527":{"position":[[573,10]]}}}],["ell}(x",{"_index":1842,"t":{"527":{"position":[[722,8],[804,8],[886,8]]}}}],["ell})h1ℓ​=att(q1,ℓ,k1,ℓ,v1,ℓ,..,qm,ℓ,km,ℓ,vm",{"_index":1854,"t":{"527":{"position":[[1313,48]]}}}],["ell}_q}x",{"_index":1844,"t":{"527":{"position":[[753,10],[835,10],[917,10]]}}}],["ell}}_q",{"_index":1846,"t":{"527":{"position":[[785,9],[867,9],[949,9]]}}}],["elmo",{"_index":3869,"t":{"1126":{"position":[[49,4]]}}}],["em",{"_index":3056,"t":{"823":{"position":[[166,2]]},"1449":{"position":[[332,4]]}}}],["ema",{"_index":301,"t":{"53":{"position":[[284,5]]}}}],["embed",{"_index":399,"t":{"91":{"position":[[31,9],[105,9],[581,9],[785,9],[810,9],[1132,9],[1171,9],[1189,9],[1222,9],[1263,9],[1276,9]]},"93":{"position":[[214,9],[236,9]]},"95":{"position":[[94,9],[328,9]]},"97":{"position":[[339,9],[385,9]]},"116":{"position":[[214,9],[235,9],[326,9],[402,9],[438,9],[515,9]]},"165":{"position":[[2022,9]]},"170":{"position":[[437,9],[1304,9],[1476,9]]},"172":{"position":[[161,9]]},"174":{"position":[[1186,9],[1395,9],[1601,9],[1688,9],[1763,9],[1971,9]]},"177":{"position":[[1392,9]]},"179":{"position":[[136,9]]},"203":{"position":[[25,9],[153,9]]},"205":{"position":[[269,9]]},"227":{"position":[[763,9]]},"230":{"position":[[292,9],[318,10],[422,9],[496,9]]},"232":{"position":[[183,9],[314,9]]},"292":{"position":[[441,9]]},"294":{"position":[[347,9]]},"306":{"position":[[112,9],[242,9],[326,9]]},"308":{"position":[[205,9]]},"319":{"position":[[143,9],[166,9]]},"324":{"position":[[539,9]]},"339":{"position":[[464,9]]},"341":{"position":[[21,9],[302,9]]},"350":{"position":[[192,9]]},"358":{"position":[[182,9],[548,9],[855,9]]},"360":{"position":[[141,9]]},"443":{"position":[[75,9]]},"498":{"position":[[398,10],[533,10]]},"500":{"position":[[210,9],[638,9],[757,9]]},"512":{"position":[[76,9]]},"527":{"position":[[1098,9]]},"598":{"position":[[500,9],[3404,10]]},"600":{"position":[[27,10],[223,10]]},"630":{"position":[[972,10]]},"658":{"position":[[787,9],[822,9],[952,9]]},"666":{"position":[[184,9]]},"670":{"position":[[980,9]]},"681":{"position":[[922,9]]},"686":{"position":[[382,9]]},"688":{"position":[[241,9],[599,9]]},"694":{"position":[[57,9],[215,9],[781,9],[943,9]]},"696":{"position":[[932,9]]},"698":{"position":[[223,9]]},"753":{"position":[[7,9],[37,9]]},"765":{"position":[[116,9]]},"859":{"position":[[60,9],[160,9],[227,9],[476,9]]},"866":{"position":[[199,9]]},"940":{"position":[[179,9]]},"977":{"position":[[106,9]]},"979":{"position":[[512,10]]},"982":{"position":[[517,8]]},"984":{"position":[[416,9],[544,10]]},"988":{"position":[[446,9],[705,9]]},"992":{"position":[[881,9]]},"999":{"position":[[57,10],[158,9]]},"1006":{"position":[[2753,9]]},"1014":{"position":[[765,9],[798,10]]},"1019":{"position":[[65,9],[252,9],[568,10],[631,9]]},"1028":{"position":[[63,9],[187,10]]},"1031":{"position":[[21,10]]},"1062":{"position":[[1173,10],[1249,9]]},"1065":{"position":[[218,10],[382,9],[506,10]]},"1067":{"position":[[261,9],[490,9]]},"1070":{"position":[[1403,9],[1448,9]]},"1091":{"position":[[129,10]]},"1097":{"position":[[87,10],[127,10]]},"1099":{"position":[[165,9],[216,10],[400,10],[1703,9]]},"1101":{"position":[[106,9],[332,10],[388,10],[656,10],[1115,9]]},"1111":{"position":[[1091,10],[1160,9],[1635,10]]},"1128":{"position":[[742,9],[1066,10],[1219,10],[1532,9],[1545,9],[1752,8]]},"1130":{"position":[[134,9],[491,9],[583,9],[735,9]]},"1141":{"position":[[399,9],[482,9],[845,9]]},"1145":{"position":[[411,8]]},"1151":{"position":[[164,9],[346,9],[1067,9]]},"1157":{"position":[[289,10]]},"1159":{"position":[[836,9],[1221,10],[1385,9],[1493,9],[1650,10]]},"1164":{"position":[[70,10]]},"1167":{"position":[[173,10],[1008,10],[1077,10]]},"1170":{"position":[[159,9]]},"1176":{"position":[[20,9],[100,9]]},"1178":{"position":[[38,10],[164,10],[258,10],[366,10],[406,10],[536,10],[573,10]]},"1185":{"position":[[226,9],[292,9],[652,10]]},"1187":{"position":[[173,9],[209,9],[465,10]]},"1195":{"position":[[573,9]]},"1201":{"position":[[90,10]]},"1212":{"position":[[41,9]]},"1218":{"position":[[84,10],[280,9]]},"1221":{"position":[[411,9],[647,9],[659,9]]},"1238":{"position":[[491,10],[521,9],[770,10]]},"1270":{"position":[[357,10]]},"1303":{"position":[[759,10],[891,10]]},"1328":{"position":[[29,9],[50,9],[77,9],[180,9],[226,9],[300,9],[330,9],[413,9]]},"1347":{"position":[[1393,9],[1883,9]]},"1350":{"position":[[102,9],[221,9],[461,9]]},"1352":{"position":[[97,9],[368,10],[589,9]]},"1367":{"position":[[231,9],[270,9]]},"1407":{"position":[[615,10]]},"1409":{"position":[[1390,10],[1434,9],[1819,10],[1867,9]]},"1421":{"position":[[99,10],[266,9],[563,10]]},"1425":{"position":[[391,9],[474,9]]},"1429":{"position":[[188,10],[246,9],[355,9],[433,10],[1105,10],[1208,9],[1299,10],[1711,9],[1859,9]]},"1431":{"position":[[9,9],[288,9],[407,10],[1124,9],[1712,9],[1803,9],[2331,10],[2521,9]]},"1434":{"position":[[344,9]]},"1436":{"position":[[188,9]]},"1462":{"position":[[223,9]]},"1473":{"position":[[204,10]]},"1477":{"position":[[291,10],[363,9],[401,9]]},"1481":{"position":[[190,10]]},"1487":{"position":[[69,9],[127,9],[280,9],[823,9]]},"1702":{"position":[[749,9]]},"1720":{"position":[[1365,9],[2071,8],[2130,9]]},"1732":{"position":[[112,9],[143,9]]},"1770":{"position":[[550,9]]},"1780":{"position":[[117,9]]},"1782":{"position":[[426,9]]}}}],["empir",{"_index":1526,"t":{"382":{"position":[[248,9]]}}}],["empti",{"_index":3951,"t":{"1143":{"position":[[902,5]]}}}],["en",{"_index":5139,"t":{"1632":{"position":[[125,5],[140,6]]}}}],["encl\\textup{enc}_lencl",{"_index":755,"t":{"170":{"position":[[156,23],[385,23]]}}}],["encod",{"_index":428,"t":{"91":{"position":[[894,7],[1306,7],[1331,7],[1929,8],[2120,7]]},"120":{"position":[[95,7]]},"132":{"position":[[74,7],[106,7],[140,7]]},"143":{"position":[[282,7]]},"153":{"position":[[749,7]]},"165":{"position":[[1903,7],[1930,7]]},"170":{"position":[[146,7],[618,7],[1009,7]]},"172":{"position":[[38,7]]},"174":{"position":[[143,7],[211,7],[478,7],[621,7]]},"177":{"position":[[1369,7]]},"182":{"position":[[64,7],[95,7],[170,7],[206,7]]},"225":{"position":[[10,7],[474,7]]},"227":{"position":[[151,8]]},"232":{"position":[[224,7]]},"236":{"position":[[73,7],[242,7]]},"239":{"position":[[82,7]]},"265":{"position":[[73,7]]},"277":{"position":[[137,8]]},"283":{"position":[[28,7]]},"285":{"position":[[33,7]]},"289":{"position":[[37,7],[64,7],[422,7]]},"292":{"position":[[0,7]]},"294":{"position":[[50,7],[111,7],[163,7]]},"302":{"position":[[53,7],[149,7],[285,7],[329,7],[443,7],[470,7],[489,7]]},"304":{"position":[[25,7]]},"308":{"position":[[117,7],[160,9],[189,9],[295,9],[652,8],[912,8]]},"310":{"position":[[270,7]]},"313":{"position":[[81,8]]},"319":{"position":[[118,7]]},"324":{"position":[[509,8]]},"328":{"position":[[73,7]]},"336":{"position":[[86,7],[101,7]]},"339":{"position":[[326,8],[340,7],[370,7],[417,7]]},"343":{"position":[[600,8]]},"350":{"position":[[132,8],[225,7],[401,7]]},"358":{"position":[[709,7],[817,7],[1279,7],[1334,7],[1430,7],[1445,7]]},"360":{"position":[[111,7],[193,7]]},"366":{"position":[[83,7]]},"436":{"position":[[674,7],[827,7]]},"443":{"position":[[209,7]]},"457":{"position":[[520,7],[1077,7]]},"466":{"position":[[141,7]]},"483":{"position":[[52,8],[84,7],[335,7]]},"485":{"position":[[282,7],[372,7],[526,7],[636,7],[679,7],[1294,8],[1357,8],[1434,7]]},"488":{"position":[[77,7]]},"492":{"position":[[0,7]]},"494":{"position":[[304,7]]},"498":{"position":[[204,7],[589,7],[649,7],[744,7],[763,7],[808,7]]},"500":{"position":[[327,7],[938,7]]},"502":{"position":[[9,7]]},"504":{"position":[[65,9],[232,7],[262,7],[443,7],[652,7]]},"508":{"position":[[0,7],[115,7],[176,7]]},"510":{"position":[[8,7],[94,7]]},"512":{"position":[[51,7],[161,7]]},"517":{"position":[[164,7]]},"525":{"position":[[51,7],[182,7],[212,8]]},"527":{"position":[[57,7],[472,7],[605,7],[1048,7],[1078,7]]},"567":{"position":[[116,7]]},"577":{"position":[[22,7],[208,7]]},"594":{"position":[[221,7]]},"598":{"position":[[1233,7],[2010,7],[2189,7]]},"608":{"position":[[330,7],[349,8],[408,7]]},"612":{"position":[[63,7]]},"688":{"position":[[273,7]]},"692":{"position":[[181,7]]},"694":{"position":[[134,7],[415,7],[469,7],[736,7]]},"696":{"position":[[54,7],[352,7],[1628,7]]},"698":{"position":[[183,7]]},"709":{"position":[[1666,7],[1782,7]]},"739":{"position":[[103,7]]},"828":{"position":[[59,7]]},"866":{"position":[[76,6]]},"870":{"position":[[2009,7],[2144,7]]},"873":{"position":[[223,7]]},"895":{"position":[[200,7]]},"912":{"position":[[79,7]]},"940":{"position":[[66,7]]},"953":{"position":[[170,7],[189,8],[304,7]]},"955":{"position":[[510,7],[542,8]]},"977":{"position":[[278,8]]},"1031":{"position":[[67,7]]},"1080":{"position":[[18,7]]},"1101":{"position":[[512,7]]},"1128":{"position":[[339,7],[1874,7]]},"1132":{"position":[[43,7]]},"1145":{"position":[[745,7],[802,7]]},"1183":{"position":[[0,7],[27,7]]},"1185":{"position":[[373,7]]},"1214":{"position":[[174,7],[196,7]]},"1259":{"position":[[164,7]]},"1298":{"position":[[45,7],[118,7],[179,8],[335,7]]},"1305":{"position":[[109,7]]},"1442":{"position":[[1975,8]]},"1644":{"position":[[421,8]]},"1646":{"position":[[2051,8],[2234,8],[2620,8]]},"1720":{"position":[[1257,7]]}}}],["encv\\textup{enc}_{\\textup{v}}encv",{"_index":813,"t":{"172":{"position":[[46,34]]}}}],["encvref\\textup{enc}_{\\textup{v}}^{\\textup{ref}}encvref",{"_index":762,"t":{"170":{"position":[[628,55],[1017,55]]}}}],["end",{"_index":1112,"t":{"246":{"position":[[265,5],[424,5],[438,5],[449,4],[549,5]]},"287":{"position":[[560,3],[567,3]]},"434":{"position":[[203,3],[210,3],[288,3],[295,3],[504,3],[511,3],[674,3],[681,3]]},"436":{"position":[[928,3],[935,3],[1051,3],[1058,3],[1763,3],[1770,3],[2060,3],[2067,3],[2220,3],[2227,3]]},"475":{"position":[[15,3],[22,3]]},"479":{"position":[[202,3],[209,3]]},"523":{"position":[[311,3]]},"525":{"position":[[272,3],[279,3],[974,3]]},"533":{"position":[[70,3]]},"569":{"position":[[816,5]]},"866":{"position":[[231,6]]},"932":{"position":[[65,5],[877,5]]},"934":{"position":[[904,5]]},"1124":{"position":[[237,3],[244,3]]},"1126":{"position":[[1619,3],[1626,3]]},"1702":{"position":[[620,3],[669,3]]}}}],["end_index",{"_index":4908,"t":{"1540":{"position":[[330,9],[450,12],[470,10],[491,12],[511,10]]}}}],["endless",{"_index":2336,"t":{"658":{"position":[[2629,7]]}}}],["endoer",{"_index":1033,"t":{"225":{"position":[[50,6]]}}}],["end{align",{"_index":3130,"t":{"853":{"position":[[885,12]]},"945":{"position":[[735,11]]},"1101":{"position":[[911,12]]},"1655":{"position":[[1025,12],[1964,12]]},"1657":{"position":[[917,12],[1675,12],[3032,12]]}}}],["end{align*}multihead(q,k,v)wher",{"_index":1223,"t":{"300":{"position":[[820,33]]}}}],["end{align*}pe(pos,2i)pe(pos,2i+1)​=sin(pos/100002i/dmodel​)=cos(pos/100002i/dmodel",{"_index":1267,"t":{"308":{"position":[[514,86]]}}}],["end{align*}qm,ℓ(x)=wqm,ℓ​x+bm,ℓq​km,ℓ(x)=wqm,ℓ​x+bm,ℓq​vm,ℓ(x)=wqm,ℓ​x+bm,ℓq",{"_index":1849,"t":{"527":{"position":[[959,79]]}}}],["end{align*}​fes​​(a,person)∧fes​,eo​​(a,′",{"_index":5191,"t":{"1651":{"position":[[1305,43]]}}}],["end{align*}​s[5]s[1]s[5]−s[1]​​=a[0]+a[1]+a[2]+a[3]+a[4]+a[5]=a[0]+a[1]=a[2]+a[3]+a[4]+a[5",{"_index":4903,"t":{"1538":{"position":[[669,93]]}}}],["end{align}h2ℓ​h3ℓ​h4ℓ​h5ℓ​outℓ​=====​dropout(gln1​ℓ​⊙geludropoutgln2​ℓ​⊙​wm1ℓ​⋅h1ℓ​σ(h2ℓ​+x)−μ​(wm2ℓ​⋅h3ℓ​(wm3ℓ​⋅h4ℓ​σ(h5ℓ​+h3ℓ​)−μ​​+++++​​bm1ℓ​)bln1​ℓ​bm2ℓ​)bm3ℓ​)bln2",{"_index":1876,"t":{"527":{"position":[[2115,175]]}}}],["end{align}i(t)(wij​)u(t)(wij​)​=β1​i(t−1)(wij​)+(1−β1​)i(t)(wij​)=β2​u(t−1)(wij​)+(1−β2​)∣∣​i(t)(wij​)−i(t)(wij",{"_index":2987,"t":{"801":{"position":[[1939,120]]}}}],["end{align}​ql​=linearq",{"_index":3326,"t":{"893":{"position":[[689,25]]}}}],["end{array",{"_index":808,"t":{"170":{"position":[[2305,11]]},"172":{"position":[[597,11]]},"174":{"position":[[2242,11]]}}}],["end{array}hdown​hup​hout​​=wdown⊤​(x^)=w⊤​up(nonlinear(hdown​))=layernorm(hup",{"_index":3529,"t":{"988":{"position":[[1088,82]]}}}],["end{equation}[pl​;tl​]∈r(k+m)×c",{"_index":3306,"t":{"891":{"position":[[824,34]]}}}],["end{equation}aj​=∑k=1t+1​ep^k​hout​/tep^j​hout​/t",{"_index":3544,"t":{"988":{"position":[[1739,53]]}}}],["end{equation}attention(q,k,v)=softmax(dk​​qkt​)v",{"_index":1197,"t":{"298":{"position":[[502,51]]}}}],["end{equation}ffn(x)=max(0,xw1​+b1​)w2​+b2",{"_index":1252,"t":{"304":{"position":[[266,45]]}}}],["end{equation}h=w(0)x+△x=w(0)x+bax",{"_index":2821,"t":{"791":{"position":[[217,37]]}}}],["end{equation}h^0:m​=hargmin",{"_index":3807,"t":{"1099":{"position":[[2075,29]]}}}],["end{equation}ha​=wup⊤​ϕ(wdown⊤​hfn",{"_index":4460,"t":{"1384":{"position":[[605,40]]}}}],["end{equation}hi​=lmϕ​(zi​,h<i",{"_index":4256,"t":{"1296":{"position":[[751,35]]}}}],["end{equation}hi​={pθ​[i,:],lmϕ​(zi​,h<i​),​ifi∈pidx​otherwis",{"_index":4301,"t":{"1305":{"position":[[835,66]]}}}],["end{equation}hi​​=mlp([hi",{"_index":3822,"t":{"1101":{"position":[[924,27]]}}}],["end{equation}i(wij​)=∣∣​wij​▽wij​​l",{"_index":2972,"t":{"801":{"position":[[1110,42]]}}}],["end{equation}ipi​​=ex∼dx",{"_index":4809,"t":{"1485":{"position":[[711,27]]}}}],["end{equation}ip​=projection(concat({im​}m=1m",{"_index":3381,"t":{"895":{"position":[[560,50]]}}}],["end{equation}iqi​​=ex∼dx",{"_index":4833,"t":{"1487":{"position":[[1010,27]]}}}],["end{equation}l=lce​+λr​vf​vt​​r(",{"_index":3221,"t":{"861":{"position":[[797,37]]}}}],["end{equation}ldept​=−i∑​logp(yi​∣[ps​,wi",{"_index":3692,"t":{"1067":{"position":[[910,49]]}}}],["end{equation}lkd​=dkl​(ps​∣∣pt",{"_index":3239,"t":{"861":{"position":[[1859,35]]}}}],["end{equation}llindep​(x)ljoint​(x)​=∣x∣1​x∈x∑​[lindep​(x)+ljoint​(x)],=−n1​j=1∑n​logp([m]j​=ϕj​(yx​)∣t(x)),=−logp(yx​∣x",{"_index":5302,"t":{"1657":{"position":[[3045,125]]}}}],["end{equation}lln​=−logexp(β(x,y))+∑n=1n​exp(β(x,y^​(n)))exp(β(x,i",{"_index":2134,"t":{"596":{"position":[[2198,71]]}}}],["end{equation}lpt​=−i∑​logp(yi​∣[p,wi",{"_index":3675,"t":{"1065":{"position":[[775,45]]}}}],["end{equation}lrate=dmodel−0.5​⋅min(step_num−0.5,step_num⋅warmup_steps−1.5",{"_index":1333,"t":{"317":{"position":[[340,77]]}}}],["end{equation}lul​=−∑n=1n​t(n)∑n=1n​∑t=1t(n)​log(1−p(y^​i(n)​∣x,y^​<t(n",{"_index":2112,"t":{"596":{"position":[[669,78]]}}}],["end{equation}m1​k=1∑m​λk",{"_index":5324,"t":{"1659":{"position":[[975,26]]}}}],["end{equation}p(y∣x)=∑y~​∈y​∏j=1n​p([m]j​=ϕ(y~​)∣t(x))∏j=1n​p([m]j​=ϕ(y)∣t(x",{"_index":5287,"t":{"1657":{"position":[[2195,81]]}}}],["end{equation}p^e​=γ⋅p",{"_index":4794,"t":{"1485":{"position":[[180,26]]}}}],["end{equation}pe​argmax​logp(y∣[pe​;x",{"_index":4788,"t":{"1477":{"position":[[831,43]]}}}],["end{equation}pinstance​(x)=ptarget​+j=1∑t+1​aj​pj",{"_index":3551,"t":{"990":{"position":[[210,54]]}}}],["end{equation}pj​(x)=[softmax(lμ​(x",{"_index":4417,"t":{"1354":{"position":[[502,37]]}}}],["end{equation}pj​(x)=[softmax(lμ​(xˉ))]j",{"_index":4397,"t":{"1352":{"position":[[880,44]]}}}],["end{equation}plv​=pl​+repeat(ip​)∈rk×c",{"_index":3388,"t":{"895":{"position":[[987,41]]}}}],["end{equation}pmax",{"_index":3494,"t":{"984":{"position":[[648,19]]}}}],["end{equation}ptarget​,gmax",{"_index":3506,"t":{"986":{"position":[[511,28]]}}}],["end{equation}p′=[p1′​,…,pn′​]=[φ(p1​),…,φ(pn",{"_index":4015,"t":{"1167":{"position":[[351,51]]}}}],["end{equation}p′=wup⊤​ϕ(wdown⊤​p",{"_index":4477,"t":{"1384":{"position":[[1911,36]]}}}],["end{equation}q=(wq⊤​+αwup⊤​wdown⊤​)hin",{"_index":4503,"t":{"1384":{"position":[[3719,42]]}}}],["end{equation}r(p,q)=∥∥​p⊤p−i∥∥​f2​=∥∥​qq⊤−i∥∥​f2",{"_index":2861,"t":{"795":{"position":[[1047,53]]}}}],["end{equation}s(t)(wij​)=i(t)(wij​)⋅u(t)(wij",{"_index":2996,"t":{"801":{"position":[[2575,49]]}}}],["end{equation}si,j(t)​=−αs​t<t∑​(∂wi,j​∂l​)(t)wi,j(t",{"_index":3143,"t":{"853":{"position":[[1606,56]]}}}],["end{equation}si,j(t)​=−αs​wi,j​t<t∑​(∂wi,j′​∂l​)(t",{"_index":3161,"t":{"855":{"position":[[337,54]]}}}],["end{equation}si,j(t)​​=∣∣​wi,j(t)​∣∣​=∣∣​wi,j​−αw​t<t∑​(∂wi,j​∂l​)(t",{"_index":3131,"t":{"853":{"position":[[898,76]]}}}],["end{equation}sk,i​=s(λk,i​)+d1​1​j=1∑d1​​s(pk,ji​)+d2​1​j=1∑d2​​s(qk,ij",{"_index":2961,"t":{"801":{"position":[[634,77]]}}}],["end{equation}slg​=[softmax(slk​)⋅gl",{"_index":3359,"t":{"893":{"position":[[1861,38]]}}}],["end{equation}sl​=[slk​;slm+1​]t",{"_index":3344,"t":{"893":{"position":[[1171,34]]}}}],["end{equation}sl​=ql​klt​/c​∈r1×(k+m+1",{"_index":3337,"t":{"893":{"position":[[950,41]]}}}],["end{equation}softmax(dk​​q(lk​⊙kt)​)(lv​⊙v",{"_index":2164,"t":{"598":{"position":[[1687,46]]}}}],["end{equation}tlo​=linearo​(slg​vl​)∈r1×c",{"_index":3366,"t":{"893":{"position":[[2379,43]]}}}],["end{equation}v(⋅)l​=∑l′=1l​r(s(⋅)l′​)r(s(⋅)l​)l​v",{"_index":3193,"t":{"857":{"position":[[1129,52]]}}}],["end{equation}vt​={vf​−vf​(1−nt​)3vf​​t<no.w",{"_index":3214,"t":{"861":{"position":[[288,48]]}}}],["end{equation}w=w(0)+△=w(0)+ba",{"_index":2755,"t":{"786":{"position":[[1728,33]]}}}],["end{equation}w=w(0)+△=w(0)+pλq",{"_index":2836,"t":{"795":{"position":[[182,34]]}}}],["end{equation}wi′​=wi​+△wi​=wi​+ba∈rs×d",{"_index":3687,"t":{"1067":{"position":[[611,42]]}}}],["end{equation}{e([p0:i​]),e(x),e([pi+1:m​]),e(i",{"_index":3795,"t":{"1099":{"position":[[1358,51]]}}}],["end{equation}{h0​,…hi​,e(x),hi+1​,…hm​,e(i",{"_index":3799,"t":{"1099":{"position":[[1602,47]]}}}],["end{equation}θmax​x,y∈t∑​logpθ​(y∣x",{"_index":4001,"t":{"1162":{"position":[[319,40]]}}}],["end{equation}θp​,θϕ​max​x,y∈t∑​logpθ​(y∣[p′;x",{"_index":4035,"t":{"1167":{"position":[[1439,51]]}}}],["end{equation}θp​max​x,y∈t∑​logpθ​(y∣[p;x",{"_index":4004,"t":{"1164":{"position":[[378,46]]}}}],["end{equation}λk(t+1)​=t(λ~k(t)​,sk(t)​),witht(λ~k(t)​,sk(t)​)ii​={λ~k,iit​0​sk,it",{"_index":2937,"t":{"797":{"position":[[2088,83]]}}}],["end{equation}λ~k(t)​=λk(t)​−η▽λk​​l(p(t).e(t),q(t",{"_index":2916,"t":{"797":{"position":[[1514,55]]}}}],["end{equation}μ,θc​argmax​logp(i",{"_index":4405,"t":{"1352":{"position":[[1225,32]]}}}],["end{equation}φ(pi​)=ϕ(pi​)+pi",{"_index":4022,"t":{"1167":{"position":[[658,31]]}}}],["end{equation}ϕargmax​logpϕ​(y∣[pθ​;x",{"_index":4377,"t":{"1350":{"position":[[748,42]]}}}],["end{equation}ϕargmax​logpϕ​(y∣x",{"_index":4372,"t":{"1350":{"position":[[409,36]]}}}],["end{equation}ϕmax",{"_index":4279,"t":{"1300":{"position":[[364,19]]}}}],["end{equation}​t(x)=[tfes​​​(x);tfes​,eo​​​(x);tfeo​​​(x)]=‘‘x",{"_index":5264,"t":{"1657":{"position":[[930,62]]}}}],["end{equation}​tfes​,eo​​​=‘‘x",{"_index":5236,"t":{"1655":{"position":[[1977,30]]}}}],["end{equation}​tfes​​​=‘‘x",{"_index":5220,"t":{"1655":{"position":[[1038,26]]}}}],["end{equation}​v[m]1​={‘‘person’’,‘‘organization’’,…},v[m]2​={‘‘’s’’,‘‘was’’,…},v[m]3​={‘‘parent’’,‘‘born’’,…},l[m]4​={‘‘was’’,‘‘in’’,…},l[m]5​={‘‘person’’,‘‘organ",{"_index":5279,"t":{"1657":{"position":[[1688,179]]}}}],["end{matrix}\\right",{"_index":2936,"t":{"797":{"position":[[2068,19]]},"861":{"position":[[268,19]]},"1305":{"position":[[815,19]]}}}],["engin",{"_index":1386,"t":{"334":{"position":[[156,11],[424,11],[584,11]]},"336":{"position":[[337,11],[912,11],[1693,11],[1950,11]]},"341":{"position":[[105,11]]},"345":{"position":[[37,11]]},"356":{"position":[[132,11]]},"368":{"position":[[117,11]]},"376":{"position":[[83,11],[146,11]]},"378":{"position":[[52,11]]},"955":{"position":[[303,7],[706,6]]},"1062":{"position":[[103,11]]},"1091":{"position":[[374,11]]},"1093":{"position":[[696,11]]},"1151":{"position":[[1858,12]]},"1695":{"position":[[86,11],[189,11],[520,11],[889,11],[1243,11]]},"1708":{"position":[[135,11],[281,11]]},"1710":{"position":[[16,11]]},"1722":{"position":[[13,11]]},"1736":{"position":[[152,11]]},"1752":{"position":[[370,11]]},"1754":{"position":[[410,11]]},"1756":{"position":[[267,11],[293,11],[440,11],[554,11]]},"1766":{"position":[[267,11],[308,11]]},"1768":{"position":[[269,11]]},"1782":{"position":[[1200,6]]},"1788":{"position":[[252,11],[438,11]]}}}],["english",{"_index":1304,"t":{"313":{"position":[[38,7],[157,7],[195,7]]},"322":{"position":[[9,7],[232,7]]},"324":{"position":[[74,7]]},"326":{"position":[[678,7]]},"328":{"position":[[252,7],[281,7]]},"1702":{"position":[[510,8]]}}}],["english:i",{"_index":5403,"t":{"1695":{"position":[[1031,10]]}}}],["ength",{"_index":4864,"t":{"1505":{"position":[[927,5]]}}}],["enhanc",{"_index":5335,"t":{"1665":{"position":[[448,8]]},"1667":{"position":[[327,8],[558,8],[950,8]]}}}],["enqueu",{"_index":1747,"t":{"498":{"position":[[679,7]]}}}],["enrich",{"_index":2284,"t":{"630":{"position":[[2166,9]]}}}],["ensembl",{"_index":1142,"t":{"283":{"position":[[189,10]]},"354":{"position":[[240,8]]},"1124":{"position":[[634,10]]},"1126":{"position":[[2381,10],[2654,10]]},"1149":{"position":[[6,10],[349,10],[536,10],[628,10]]},"1153":{"position":[[579,10]]},"1517":{"position":[[329,10]]},"1736":{"position":[[7,10],[203,10],[1250,10],[1309,10]]},"1762":{"position":[[386,8]]},"1782":{"position":[[61,8]]},"1794":{"position":[[7,10],[27,10],[267,8],[364,10]]}}}],["ent",{"_index":5343,"t":{"1665":{"position":[[702,3]]}}}],["entail",{"_index":1082,"t":{"236":{"position":[[527,10]]},"287":{"position":[[489,10]]},"979":{"position":[[1902,10]]},"997":{"position":[[52,11]]},"1111":{"position":[[164,10]]},"1655":{"position":[[1307,15]]}}}],["entangl",{"_index":5618,"t":{"1788":{"position":[[695,12]]}}}],["entir",{"_index":2304,"t":{"656":{"position":[[108,6]]},"658":{"position":[[272,6]]},"1126":{"position":[[1504,6]]},"1151":{"position":[[776,9],[833,8],[900,11]]},"1345":{"position":[[395,6]]}}}],["entiti",{"_index":3615,"t":{"1014":{"position":[[1529,6]]},"1017":{"position":[[158,6]]},"1041":{"position":[[61,6]]},"1107":{"position":[[684,6]]},"1644":{"position":[[668,6]]},"1646":{"position":[[1519,8],[2352,6],[2430,6],[2457,8],[2498,6],[3095,6]]},"1651":{"position":[[92,8],[176,8],[220,8],[263,8],[997,8],[1446,6],[1514,8]]},"1653":{"position":[[760,6]]},"1655":{"position":[[261,6],[298,6],[698,6],[723,6],[1127,6],[1404,8]]},"1659":{"position":[[105,6],[125,6],[303,6],[321,6]]},"1665":{"position":[[402,6],[636,6],[715,6],[831,6]]},"1669":{"position":[[230,6],[282,6],[394,6],[914,6]]},"1672":{"position":[[61,6],[124,6],[146,6]]},"1674":{"position":[[0,6],[656,6]]},"1676":{"position":[[255,6],[327,6],[375,6],[502,6],[562,6],[611,6]]},"1684":{"position":[[671,6],[797,6]]},"1689":{"position":[[282,6]]},"1724":{"position":[[328,6]]},"1728":{"position":[[541,6]]},"1742":{"position":[[243,7]]},"1768":{"position":[[432,6],[529,6],[562,6]]},"1788":{"position":[[480,6]]}}}],["entitiy",{"_index":5477,"t":{"1728":{"position":[[307,7]]}}}],["entri",{"_index":2154,"t":{"598":{"position":[[1085,5]]},"786":{"position":[[1098,5],[1469,5]]},"795":{"position":[[1673,7]]},"801":{"position":[[121,7],[273,5],[888,7]]},"837":{"position":[[55,5]]}}}],["entropi",{"_index":1113,"t":{"249":{"position":[[9,7]]},"358":{"position":[[1241,7]]},"596":{"position":[[98,7],[1887,7]]},"1134":{"position":[[668,7]]},"1185":{"position":[[732,7]]},"1187":{"position":[[443,7]]},"1738":{"position":[[607,7]]}}}],["enviro",{"_index":4711,"t":{"1442":{"position":[[895,10]]}}}],["environ",{"_index":4731,"t":{"1447":{"position":[[191,11]]}}}],["eo",{"_index":1750,"t":{"500":{"position":[[501,5],[623,5]]},"550":{"position":[[289,3]]},"1185":{"position":[[250,5]]},"1657":{"position":[[1027,8]]}}}],["eo\",\\begin{equ",{"_index":5254,"t":{"1657":{"position":[[736,20]]}}}],["eo\",vfes,eo={‘‘’",{"_index":5233,"t":{"1655":{"position":[[1733,17]]}}}],["eoe_oeo",{"_index":5211,"t":{"1655":{"position":[[705,8],[1134,8]]}}}],["eo​\",vfes​,eo​​​={‘‘’",{"_index":5238,"t":{"1655":{"position":[[2022,22]]}}}],["epepep",{"_index":3908,"t":{"1130":{"position":[[712,6]]}}}],["episod",{"_index":4700,"t":{"1440":{"position":[[318,8]]},"1442":{"position":[[1373,8]]}}}],["epoch",{"_index":179,"t":{"25":{"position":[[580,6]]},"53":{"position":[[212,5],[251,5]]},"78":{"position":[[480,6]]},"80":{"position":[[10,5]]},"114":{"position":[[112,6],[151,6],[201,6],[236,6],[290,6],[327,6]]},"143":{"position":[[540,6]]},"372":{"position":[[53,5],[94,5]]},"668":{"position":[[239,6]]},"670":{"position":[[328,6]]},"674":{"position":[[376,6],[556,6]]},"828":{"position":[[136,6]]},"866":{"position":[[452,6],[470,6],[579,6],[958,6],[1011,6],[1020,6],[1095,6]]},"905":{"position":[[121,5],[146,5]]},"921":{"position":[[163,5]]},"999":{"position":[[746,6],[776,6],[799,5]]},"1111":{"position":[[1472,5],[1535,5]]},"1259":{"position":[[89,6]]},"1314":{"position":[[231,7],[290,6],[453,5],[485,5],[557,5]]},"1496":{"position":[[279,5]]},"1558":{"position":[[245,6],[345,5]]},"1665":{"position":[[1455,6]]},"1674":{"position":[[523,6],[552,6]]},"1682":{"position":[[267,6]]}}}],["epose_{pos}epo",{"_index":459,"t":{"91":{"position":[[1883,16]]}}}],["epos​∈r(n+1)×d",{"_index":458,"t":{"91":{"position":[[1826,14]]}}}],["epos∈r(n+1)×dz_o",{"_index":447,"t":{"91":{"position":[[1565,16]]}}}],["epsilon",{"_index":266,"t":{"49":{"position":[[539,10]]}}}],["eq",{"_index":2126,"t":{"596":{"position":[[1865,3]]},"795":{"position":[[1752,3]]},"797":{"position":[[841,3]]},"801":{"position":[[1193,3],[1305,3],[1465,3],[2713,4],[2735,4]]},"807":{"position":[[341,3]]},"837":{"position":[[30,3],[138,3]]},"839":{"position":[[130,3],[253,4],[330,4]]},"893":{"position":[[1658,2]]},"986":{"position":[[296,3]]},"988":{"position":[[1819,3]]},"990":{"position":[[38,3],[437,3]]},"992":{"position":[[789,3]]},"1006":{"position":[[619,3],[682,3]]},"1246":{"position":[[237,2],[799,2]]},"1275":{"position":[[59,2]]},"1298":{"position":[[410,3]]},"1305":{"position":[[365,3],[923,3]]},"1354":{"position":[[362,3]]},"1655":{"position":[[1206,3]]},"1657":{"position":[[607,3],[2449,3],[3213,3]]},"1659":{"position":[[770,3]]}}}],["eq.1",{"_index":5251,"t":{"1657":{"position":[[600,4]]}}}],["equal",{"_index":353,"t":{"78":{"position":[[219,7]]}}}],["equat",{"_index":1566,"t":{"403":{"position":[[92,8],[242,8]]}}}],["equivari",{"_index":378,"t":{"86":{"position":[[365,12]]}}}],["ero",{"_index":28,"t":{"3":{"position":[[248,4],[427,4],[606,4],[785,4],[964,4],[1143,4],[1322,4],[1501,4],[1680,4],[1859,4],[2038,4],[2217,4],[2396,4],[2575,4],[2754,4],[2933,4]]},"5":{"position":[[128,4]]}}}],["error",{"_index":1925,"t":{"529":{"position":[[2244,5],[2257,5]]},"1143":{"position":[[867,5]]},"1431":{"position":[[1766,5],[2150,5],[2614,5]]},"1442":{"position":[[645,6]]},"1451":{"position":[[759,6]]},"1669":{"position":[[1015,5]]}}}],["es",{"_index":5232,"t":{"1655":{"position":[[1717,2],[2008,3]]}}}],["es\",vfes={‘‘person\",‘‘organ",{"_index":5214,"t":{"1655":{"position":[[823,37]]}}}],["ese^s",{"_index":4658,"t":{"1431":{"position":[[418,7]]}}}],["ese_s",{"_index":5210,"t":{"1655":{"position":[[651,8],[679,8]]}}}],["esre^{s_r}esr",{"_index":4668,"t":{"1431":{"position":[[1080,14]]}}}],["estim",{"_index":2200,"t":{"608":{"position":[[149,9],[455,9]]},"851":{"position":[[802,9]]},"853":{"position":[[1339,9]]}}}],["es​\",vfes​​​={‘‘person\",‘‘organ",{"_index":5221,"t":{"1655":{"position":[[1073,46]]}}}],["et",{"_index":974,"t":{"215":{"position":[[275,2],[374,2],[1772,2],[1791,2],[1817,2],[2166,2],[2288,2],[2326,2],[2489,2]]},"498":{"position":[[142,2]]},"504":{"position":[[189,2],[313,2]]},"517":{"position":[[1099,2]]},"525":{"position":[[1025,2],[1166,2]]},"529":{"position":[[45,2],[62,2],[1528,2],[2679,2]]},"531":{"position":[[311,2],[332,2],[352,2],[433,2],[451,2],[475,2],[496,2],[730,2],[752,2],[986,2],[1087,2],[1348,2],[1449,2]]},"598":{"position":[[1507,2]]},"630":{"position":[[817,2]]},"648":{"position":[[745,2],[877,2]]},"658":{"position":[[737,2],[855,2],[883,2]]},"662":{"position":[[1428,2],[1454,2],[1491,2]]},"666":{"position":[[93,2],[247,2]]},"670":{"position":[[881,2]]},"681":{"position":[[417,2],[537,2],[577,2],[752,2],[788,2],[807,2]]},"683":{"position":[[39,2],[77,2],[145,2],[173,2],[292,2],[317,2],[349,2],[1103,2],[1129,2]]},"707":{"position":[[738,2],[754,2]]},"849":{"position":[[423,2],[621,2],[1631,2]]},"851":{"position":[[65,2],[89,2],[107,2],[151,2],[170,2],[194,2],[212,2],[246,2],[264,2],[306,2],[469,2],[630,2],[771,2],[820,2],[1157,2]]},"853":{"position":[[421,2],[1228,2],[2344,2]]},"861":{"position":[[996,2]]},"868":{"position":[[27,2],[72,2],[109,2],[132,2],[198,2]]},"873":{"position":[[883,2]]},"988":{"position":[[654,2]]},"1002":{"position":[[663,2],[688,2],[715,2]]},"1004":{"position":[[72,2]]},"1006":{"position":[[187,2]]},"1008":{"position":[[421,2]]},"1084":{"position":[[260,2],[279,2],[298,2]]},"1347":{"position":[[365,2],[416,2],[432,2],[483,2],[585,2],[1269,2],[1288,2]]},"1354":{"position":[[25,2],[45,2]]},"1357":{"position":[[95,2]]},"1362":{"position":[[158,2],[194,2],[376,2]]},"1364":{"position":[[242,2],[260,2]]},"1367":{"position":[[186,2],[370,2],[442,2],[458,2],[509,2],[525,2],[600,2],[618,2],[636,2]]},"1369":{"position":[[268,2],[357,2],[423,2],[533,2]]},"1379":{"position":[[1005,2],[1062,2],[1093,2]]},"1384":{"position":[[2469,2]]},"1395":{"position":[[323,2],[647,2],[734,2]]},"1399":{"position":[[367,2],[389,2]]},"1401":{"position":[[555,2],[576,2]]},"1407":{"position":[[96,2]]},"1409":{"position":[[154,2],[465,2]]},"1415":{"position":[[45,2],[213,2],[233,2]]},"1419":{"position":[[235,2],[930,2]]},"1421":{"position":[[11,2],[370,2],[441,2]]},"1423":{"position":[[988,2]]},"1431":{"position":[[1210,2]]},"1468":{"position":[[192,2]]},"1473":{"position":[[232,2],[371,2],[502,2]]},"1475":{"position":[[284,2],[338,2]]},"1481":{"position":[[141,2]]},"1492":{"position":[[105,2],[123,2]]},"1494":{"position":[[47,2],[69,2],[175,2],[291,2]]},"1496":{"position":[[205,2],[223,2]]},"1511":{"position":[[309,2]]},"1665":{"position":[[872,2]]},"1669":{"position":[[475,2]]},"1682":{"position":[[43,2]]}}}],["eta",{"_index":2911,"t":{"797":{"position":[[1413,4]]}}}],["etc",{"_index":2051,"t":{"587":{"position":[[318,4]]},"1431":{"position":[[2244,5]]}}}],["ete^tet",{"_index":4654,"t":{"1431":{"position":[[298,7]]}}}],["eurosat",{"_index":1505,"t":{"374":{"position":[[59,7]]}}}],["evalu",{"_index":1545,"t":{"395":{"position":[[80,10]]},"537":{"position":[[261,10]]},"539":{"position":[[611,10]]},"550":{"position":[[362,10]]},"569":{"position":[[993,10]]},"579":{"position":[[147,10]]},"594":{"position":[[1223,10]]},"596":{"position":[[1536,10],[1608,10]]},"608":{"position":[[723,10]]},"1107":{"position":[[521,11]]},"1357":{"position":[[363,10]]},"1442":{"position":[[1045,10],[1065,10],[1451,10]]},"1445":{"position":[[67,9]]},"1449":{"position":[[22,9],[226,9],[393,10],[514,9]]},"1455":{"position":[[63,9],[469,9],[523,9]]}}}],["exact",{"_index":1782,"t":{"515":{"position":[[294,5]]},"555":{"position":[[156,5]]},"589":{"position":[[1018,5]]},"1449":{"position":[[320,5]]}}}],["exam",{"_index":2005,"t":{"553":{"position":[[145,4]]}}}],["exampl",{"_index":1538,"t":{"384":{"position":[[1173,8]]},"414":{"position":[[47,7],[126,7],[158,7]]},"548":{"position":[[191,7]]},"550":{"position":[[212,7]]},"569":{"position":[[132,8],[627,8]]},"587":{"position":[[97,8],[188,8]]},"589":{"position":[[558,7],[675,7],[725,7],[1427,8]]},"592":{"position":[[210,8]]},"594":{"position":[[16,8],[409,8],[634,7]]},"596":{"position":[[1166,7]]},"598":{"position":[[271,8],[322,7],[362,8]]},"602":{"position":[[569,7]]},"608":{"position":[[770,7],[965,8],[1048,7]]},"610":{"position":[[355,8]]},"612":{"position":[[288,7],[381,8]]},"614":{"position":[[160,7]]},"618":{"position":[[208,7]]},"670":{"position":[[72,7]]},"709":{"position":[[168,8]]},"934":{"position":[[105,8]]},"949":{"position":[[182,8]]},"963":{"position":[[381,8]]},"999":{"position":[[722,7]]},"1070":{"position":[[1651,8]]},"1124":{"position":[[194,8]]},"1126":{"position":[[532,8]]},"1132":{"position":[[358,7]]},"1134":{"position":[[622,7]]},"1145":{"position":[[352,8],[508,7]]},"1149":{"position":[[393,7],[442,7]]},"1259":{"position":[[21,8]]},"1264":{"position":[[13,8]]},"1289":{"position":[[640,8]]},"1314":{"position":[[439,8]]},"1321":{"position":[[65,7]]},"1419":{"position":[[946,8],[1108,8]]},"1427":{"position":[[260,7]]},"1431":{"position":[[1226,7]]},"1501":{"position":[[106,7]]},"1674":{"position":[[686,8]]}}}],["examplar",{"_index":1993,"t":{"548":{"position":[[165,8]]}}}],["excel",{"_index":5417,"t":{"1704":{"position":[[113,13]]},"1706":{"position":[[202,12]]}}}],["exemplar",{"_index":1529,"t":{"382":{"position":[[282,8]]},"384":{"position":[[488,8]]},"386":{"position":[[159,8]]},"395":{"position":[[38,9],[118,9],[151,9],[226,8]]},"397":{"position":[[175,8],[251,8]]},"409":{"position":[[80,9],[361,9],[447,8],[600,9]]},"424":{"position":[[320,8]]},"426":{"position":[[102,9],[446,8]]},"434":{"position":[[412,8]]},"445":{"position":[[220,8],[249,8],[363,8]]},"447":{"position":[[427,8],[636,8],[720,8],[756,8]]},"449":{"position":[[47,8]]},"455":{"position":[[791,8],[902,8],[931,8],[986,8],[1071,8]]},"457":{"position":[[4,8]]},"459":{"position":[[70,8],[285,8]]},"565":{"position":[[0,8]]}}}],["exist",{"_index":1830,"t":{"525":{"position":[[866,8],[911,8]]}}}],["exp",{"_index":1433,"t":{"350":{"position":[[561,4],[619,4]]},"358":{"position":[[976,4],[1028,4]]},"1244":{"position":[[1231,4]]}}}],["exp(\\beta(\\text{x",{"_index":2132,"t":{"596":{"position":[[2153,20]]}}}],["expand",{"_index":5434,"t":{"1708":{"position":[[373,9]]}}}],["expans",{"_index":3096,"t":{"851":{"position":[[576,9]]}}}],["expect",{"_index":3926,"t":{"1132":{"position":[[1281,8]]},"1151":{"position":[[1447,8]]},"1449":{"position":[[280,8]]}}}],["expens",{"_index":163,"t":{"25":{"position":[[128,9]]},"1471":{"position":[[264,9]]}}}],["experi",{"_index":1835,"t":{"525":{"position":[[1527,11]]},"1455":{"position":[[442,10]]}}}],["experiments/blob/main/image%20classification/models/net/efficientnet.pi",{"_index":371,"t":{"80":{"position":[[128,71]]}}}],["expert",{"_index":1027,"t":{"219":{"position":[[163,7],[212,7],[242,6]]},"221":{"position":[[277,7],[693,7],[704,6],[965,7],[998,7]]},"225":{"position":[[604,6],[672,6]]},"227":{"position":[[28,7],[53,7],[230,7],[380,6],[400,7],[433,7],[706,7],[869,7]]},"230":{"position":[[3,7],[415,6]]},"232":{"position":[[50,7],[102,7],[132,7],[154,7]]},"239":{"position":[[13,7]]},"253":{"position":[[400,7]]},"258":{"position":[[29,7],[133,7]]},"260":{"position":[[14,6],[123,7]]},"262":{"position":[[36,6],[152,6]]},"275":{"position":[[35,6],[131,7]]},"277":{"position":[[46,7],[102,7],[177,7]]},"279":{"position":[[13,7]]},"579":{"position":[[34,7]]},"887":{"position":[[931,6]]},"932":{"position":[[709,6]]},"934":{"position":[[2028,6],[2079,6],[2146,6],[2568,6],[2587,6]]},"955":{"position":[[314,6],[420,6],[554,6],[653,6],[717,6],[788,6]]},"965":{"position":[[313,6]]},"971":{"position":[[48,6],[114,6],[223,6]]},"973":{"position":[[378,6],[397,6],[477,6]]},"1347":{"position":[[1170,8],[1252,7]]},"1354":{"position":[[11,7],[71,7]]},"1369":{"position":[[11,7],[74,9],[208,7],[309,7],[502,7],[680,7]]},"1401":{"position":[[454,8],[533,7],[599,7],[645,7],[793,9]]}}}],["expertis",{"_index":3288,"t":{"887":{"position":[[879,9]]}}}],["explain",{"_index":1589,"t":{"428":{"position":[[143,7]]}}}],["explan",{"_index":2031,"t":{"569":{"position":[[96,12],[172,12]]}}}],["explicitli",{"_index":5044,"t":{"1595":{"position":[[279,10]]}}}],["explod",{"_index":3536,"t":{"988":{"position":[[1481,7]]}}}],["exploit",{"_index":3906,"t":{"1130":{"position":[[324,11]]},"1714":{"position":[[288,10]]}}}],["explor",{"_index":2613,"t":{"727":{"position":[[118,10]]},"1132":{"position":[[570,10]]},"1354":{"position":[[144,11]]}}}],["exponenti",{"_index":298,"t":{"53":{"position":[[257,11]]},"801":{"position":[[2138,11]]},"814":{"position":[[519,11]]}}}],["export",{"_index":5082,"t":{"1612":{"position":[[135,6]]},"1628":{"position":[[104,6]]}}}],["expos",{"_index":1827,"t":{"525":{"position":[[694,9],[888,9]]}}}],["express",{"_index":732,"t":{"163":{"position":[[684,10]]},"165":{"position":[[398,10],[440,10],[546,11],[1504,11]]},"168":{"position":[[214,10]]},"170":{"position":[[350,10]]},"174":{"position":[[1843,10]]},"179":{"position":[[158,10]]}}}],["expressionb",{"_index":726,"t":{"163":{"position":[[141,13]]}}}],["ext",{"_index":915,"t":{"189":{"position":[[36,4]]}}}],["extend",{"_index":1151,"t":{"287":{"position":[[27,9]]}}}],["extens",{"_index":2309,"t":{"658":{"position":[[396,10],[532,10],[3187,10]]}}}],["extra",{"_index":2447,"t":{"681":{"position":[[370,5],[496,5]]},"683":{"position":[[665,5],[749,5]]},"1128":{"position":[[446,5]]},"1667":{"position":[[402,5],[780,5]]},"1669":{"position":[[319,5]]}}}],["extract",{"_index":46,"t":{"7":{"position":[[199,9]]},"658":{"position":[[152,10],[3114,10]]},"1014":{"position":[[1491,10]]},"1017":{"position":[[179,10]]},"1041":{"position":[[81,10]]},"1554":{"position":[[154,11]]},"1665":{"position":[[618,10]]},"1676":{"position":[[136,10]]},"1724":{"position":[[310,10]]},"1740":{"position":[[106,10]]},"1768":{"position":[[59,10],[106,10]]},"1772":{"position":[[99,10]]},"1788":{"position":[[130,10]]}}}],["extrapol",{"_index":4335,"t":{"1323":{"position":[[48,13],[68,13],[325,13],[553,13],[614,13],[685,13]]}}}],["extrem",{"_index":1204,"t":{"298":{"position":[[1174,9]]},"847":{"position":[[168,9]]},"1466":{"position":[[390,9]]}}}],["e}[pe​;xe​]∈r(m+n)×",{"_index":4784,"t":{"1477":{"position":[[618,20]]}}}],["e}[pe​;xe​]∈r(p+n)×",{"_index":3902,"t":{"1128":{"position":[[1846,20]]}}}],["e}pe​={p1​,p2​,…,pm​}∈rm×",{"_index":4781,"t":{"1477":{"position":[[489,26]]}}}],["e}pe​∈rp×",{"_index":3898,"t":{"1128":{"position":[[1703,10]]}}}],["e}xe​∈rn×",{"_index":3895,"t":{"1128":{"position":[[1620,10]]},"1477":{"position":[[338,10]]}}}],["e}θj​∈rl×",{"_index":4388,"t":{"1352":{"position":[[557,10]]}}}],["e}θ∈rl×",{"_index":4375,"t":{"1350":{"position":[[573,8]]}}}],["e∈m",{"_index":3768,"t":{"1099":{"position":[[181,4]]}}}],["e∈rn×(p2⋅c",{"_index":446,"t":{"91":{"position":[[1552,12],[1813,12]]}}}],["f'_p",{"_index":830,"t":{"172":{"position":[[573,4]]},"174":{"position":[[2197,4]]}}}],["f'_p[i",{"_index":857,"t":{"174":{"position":[[2106,8]]}}}],["f'_v",{"_index":828,"t":{"172":{"position":[[549,4]]}}}],["f(a,f(a,f(a",{"_index":5176,"t":{"1651":{"position":[[561,12]]}}}],["f(a,′f(a,'f(a,′",{"_index":5177,"t":{"1651":{"position":[[613,16]]}}}],["f(f(3))f(f(3))f(f(3",{"_index":5565,"t":{"1770":{"position":[[673,21]]}}}],["f(x)=x∗xf(x",{"_index":5563,"t":{"1770":{"position":[[643,12]]}}}],["f1",{"_index":942,"t":{"193":{"position":[[140,2]]},"633":{"position":[[87,2]]},"674":{"position":[[709,2],[792,2]]},"786":{"position":[[4703,2]]},"823":{"position":[[171,2]]},"833":{"position":[[329,2],[371,3]]},"870":{"position":[[584,2]]},"1002":{"position":[[408,2]]},"1147":{"position":[[582,2],[1122,2]]},"1672":{"position":[[374,2],[397,2]]}}}],["f\\mathcal{f}f",{"_index":932,"t":{"191":{"position":[[112,14],[218,13]]},"199":{"position":[[142,14]]},"1651":{"position":[[443,13]]}}}],["f^{imag",{"_index":1434,"t":{"350":{"position":[[582,9],[639,9]]},"358":{"position":[[992,9],[1044,9]]}}}],["f^{text}_c",{"_index":1426,"t":{"350":{"position":[[272,10],[569,10]]}}}],["f^{text}_j",{"_index":1437,"t":{"350":{"position":[[627,11]]}}}],["f_",{"_index":866,"t":{"174":{"position":[[2435,3]]}}}],["f_p",{"_index":827,"t":{"172":{"position":[[541,4],[580,3]]}}}],["f_v",{"_index":829,"t":{"172":{"position":[[556,3]]}}}],["f_{e_",{"_index":5187,"t":{"1651":{"position":[[1192,7]]},"1655":{"position":[[545,9],[1483,11]]}}}],["f_{e_o}(b",{"_index":5189,"t":{"1651":{"position":[[1239,10]]}}}],["f_{e_s}(a",{"_index":5184,"t":{"1651":{"position":[[1159,10]]}}}],["f_{p2v",{"_index":823,"t":{"172":{"position":[[500,8],[562,8]]}}}],["f_{v2p",{"_index":824,"t":{"172":{"position":[[509,7],[586,7]]}}}],["fabul",{"_index":5431,"t":{"1706":{"position":[[215,11]]}}}],["face",{"_index":4320,"t":{"1314":{"position":[[163,4]]}}}],["facebook",{"_index":5135,"t":{"1628":{"position":[[539,8]]}}}],["facet",{"_index":4739,"t":{"1449":{"position":[[559,7]]}}}],["fact",{"_index":3830,"t":{"1105":{"position":[[21,4]]},"1573":{"position":[[208,4]]}}}],["factor",{"_index":223,"t":{"38":{"position":[[119,10]]},"598":{"position":[[2224,6]]},"630":{"position":[[1045,6]]},"633":{"position":[[362,6]]},"642":{"position":[[10,6]]},"893":{"position":[[1483,6]]},"901":{"position":[[175,6]]},"938":{"position":[[367,6]]},"945":{"position":[[183,6],[440,6],[760,6]]},"949":{"position":[[573,6]]},"1389":{"position":[[2087,6],[2124,6]]},"1395":{"position":[[2861,6],[2945,6]]}}}],["factoris",{"_index":1070,"t":{"236":{"position":[[125,13]]}}}],["factr",{"_index":5544,"t":{"1762":{"position":[[207,5]]}}}],["factual",{"_index":5543,"t":{"1762":{"position":[[0,7]]}}}],["failur",{"_index":3456,"t":{"967":{"position":[[621,7]]},"1442":{"position":[[949,7]]},"1451":{"position":[[421,7]]}}}],["fals",{"_index":64,"t":{"7":{"position":[[456,5]]},"1052":{"position":[[294,7],[326,7]]}}}],["far",{"_index":2342,"t":{"660":{"position":[[1143,3]]}}}],["fast",{"_index":1972,"t":{"533":{"position":[[84,4]]},"1242":{"position":[[870,6]]}}}],["faster",{"_index":696,"t":{"153":{"position":[[48,6],[112,6],[137,6],[346,6],[450,6]]}}}],["fctextf^{text}_cfctext",{"_index":1428,"t":{"350":{"position":[[320,23]]}}}],["fctext}c=1c",{"_index":1425,"t":{"350":{"position":[[257,14]]}}}],["fear",{"_index":5481,"t":{"1728":{"position":[[469,8]]}}}],["featur",{"_index":32,"t":{"7":{"position":[[20,8]]},"9":{"position":[[39,9]]},"88":{"position":[[410,7]]},"95":{"position":[[40,7],[131,7],[210,7],[292,7]]},"104":{"position":[[381,7]]},"168":{"position":[[579,7]]},"170":{"position":[[1149,7]]},"172":{"position":[[109,8],[189,8],[368,8],[683,7]]},"174":{"position":[[78,8],[254,7],[398,7],[609,8],[901,8],[1157,8],[2379,8]]},"203":{"position":[[7,8],[293,7],[328,7]]},"225":{"position":[[178,8],[266,8]]},"232":{"position":[[288,8],[389,8],[505,8]]},"234":{"position":[[12,8],[149,7]]},"236":{"position":[[264,7]]},"277":{"position":[[68,8]]},"336":{"position":[[638,7]]},"341":{"position":[[272,7],[288,7]]},"350":{"position":[[422,7]]},"358":{"position":[[729,7]]},"360":{"position":[[213,7]]},"457":{"position":[[684,7]]},"498":{"position":[[40,7]]},"658":{"position":[[658,7],[750,7],[1111,7],[1166,7],[1580,7],[1694,7]]},"662":{"position":[[814,7]]},"676":{"position":[[719,7],[760,7]]},"891":{"position":[[343,7]]},"893":{"position":[[1044,7]]},"895":{"position":[[240,7],[389,8],[686,7]]},"912":{"position":[[50,7]]},"934":{"position":[[614,7],[1078,7]]},"940":{"position":[[106,7],[217,7]]},"942":{"position":[[179,7]]},"967":{"position":[[48,7]]},"1616":{"position":[[50,9]]},"1626":{"position":[[99,7],[191,7]]},"1695":{"position":[[78,7],[125,7],[241,7]]},"1718":{"position":[[882,7]]},"1782":{"position":[[415,7]]}}}],["feature/represent",{"_index":594,"t":{"126":{"position":[[645,22]]}}}],["fedu",{"_index":4361,"t":{"1347":{"position":[[1282,5]]},"1354":{"position":[[39,5]]},"1369":{"position":[[262,5]]}}}],["feed",{"_index":1174,"t":{"292":{"position":[[136,4]]},"298":{"position":[[784,4]]},"304":{"position":[[91,4]]},"310":{"position":[[1785,4]]},"587":{"position":[[108,7]]},"598":{"position":[[1313,4],[1431,4],[1751,4],[1858,4],[3209,4]]},"688":{"position":[[289,4]]},"786":{"position":[[2645,4]]},"857":{"position":[[601,4],[773,4]]},"1159":{"position":[[1450,4]]},"1178":{"position":[[188,4],[618,4]]},"1187":{"position":[[388,4]]},"1585":{"position":[[95,7]]}}}],["feedback",{"_index":2040,"t":{"569":{"position":[[920,9],[968,8]]},"1440":{"position":[[271,8],[455,8],[673,8],[690,8]]},"1442":{"position":[[349,8],[378,8],[469,8],[770,8],[906,8],[1271,8]]},"1451":{"position":[[58,8],[291,8],[310,8],[824,8]]},"1455":{"position":[[264,8],[453,8]]},"1542":{"position":[[150,8]]},"1544":{"position":[[229,8]]},"1546":{"position":[[291,8]]},"1570":{"position":[[32,8],[65,8]]},"1573":{"position":[[39,8]]},"1579":{"position":[[315,8]]}}}],["feedforward",{"_index":484,"t":{"97":{"position":[[134,11]]},"662":{"position":[[386,11]]},"670":{"position":[[1003,11]]},"721":{"position":[[355,11]]},"1307":{"position":[[109,11]]},"1384":{"position":[[135,11],[286,11],[1786,11]]},"1389":{"position":[[244,11],[1169,11],[1415,11],[1973,11],[2217,11]]},"1401":{"position":[[361,11]]}}}],["feel",{"_index":5021,"t":{"1587":{"position":[[456,4]]}}}],["feo(⋅,⋅)f_{e_o}(\\cdot",{"_index":5195,"t":{"1651":{"position":[[1472,22]]}}}],["feof_{e_o}feo",{"_index":5222,"t":{"1655":{"position":[[1149,15]]}}}],["fes(a,person)∧fes,eo(a,′",{"_index":5182,"t":{"1651":{"position":[[1073,25]]}}}],["fes(⋅,{person",{"_index":5207,"t":{"1655":{"position":[[512,13]]}}}],["fes(⋅,⋅)f_{e_s}(\\cdot",{"_index":5193,"t":{"1651":{"position":[[1396,22]]}}}],["fes,eo(⋅,{’",{"_index":5224,"t":{"1655":{"position":[[1444,12]]}}}],["fes,eof_{e_",{"_index":5229,"t":{"1655":{"position":[[1618,13]]}}}],["fesf_{e_s}f",{"_index":5212,"t":{"1655":{"position":[[730,15]]}}}],["fes​​(⋅,{person",{"_index":5209,"t":{"1655":{"position":[[606,16]]}}}],["few",{"_index":532,"t":{"108":{"position":[[0,3],[203,3]]},"112":{"position":[[370,3]]},"126":{"position":[[765,3]]},"143":{"position":[[214,3],[621,3]]},"219":{"position":[[372,3]]},"253":{"position":[[0,3],[227,3],[273,3],[340,3]]},"273":{"position":[[97,3]]},"334":{"position":[[254,3]]},"336":{"position":[[683,3]]},"341":{"position":[[433,3]]},"384":{"position":[[389,3],[471,3],[644,3],[773,3],[1169,3]]},"386":{"position":[[140,3],[439,3]]},"393":{"position":[[59,3]]},"395":{"position":[[15,3],[109,3]]},"409":{"position":[[71,3]]},"414":{"position":[[34,3],[113,3]]},"426":{"position":[[437,3]]},"434":{"position":[[598,3]]},"436":{"position":[[1231,3],[1646,3],[2317,3]]},"443":{"position":[[149,3]]},"445":{"position":[[166,3]]},"447":{"position":[[407,3]]},"461":{"position":[[15,3]]},"468":{"position":[[99,3],[167,3]]},"475":{"position":[[42,3]]},"523":{"position":[[433,3]]},"539":{"position":[[466,3]]},"548":{"position":[[125,3]]},"569":{"position":[[317,3],[752,3]]},"571":{"position":[[116,3]]},"587":{"position":[[0,3],[392,3],[605,3],[696,3]]},"589":{"position":[[458,3],[608,3],[2136,3],[2199,3]]},"592":{"position":[[438,3]]},"594":{"position":[[622,3],[945,3],[1036,3]]},"596":{"position":[[21,3],[2382,3]]},"598":{"position":[[0,3],[80,3],[121,3],[3029,3],[3933,3]]},"600":{"position":[[70,3]]},"602":{"position":[[7,3],[756,3]]},"604":{"position":[[2,3],[57,3]]},"606":{"position":[[47,3],[115,3],[161,3],[236,3],[251,3],[309,3],[373,3],[411,3]]},"608":{"position":[[2,3],[49,3],[935,3]]},"610":{"position":[[12,3],[68,3],[205,3],[487,3]]},"612":{"position":[[2,3],[249,3],[326,3],[363,3],[427,3]]},"614":{"position":[[2,3]]},"616":{"position":[[53,3],[237,3]]},"618":{"position":[[0,3],[51,3],[303,3],[386,3],[436,3]]},"620":{"position":[[2,3],[40,3]]},"622":{"position":[[6,3],[20,3],[94,3],[122,3],[269,3],[384,3],[479,3],[485,3],[666,3],[696,3]]},"656":{"position":[[206,3],[383,3]]},"681":{"position":[[455,3]]},"696":{"position":[[837,4]]},"727":{"position":[[370,3]]},"979":{"position":[[1562,3]]},"1004":{"position":[[117,3],[386,3]]},"1039":{"position":[[326,3]]},"1060":{"position":[[1137,3]]},"1062":{"position":[[1735,3]]},"1070":{"position":[[1630,3]]},"1084":{"position":[[0,3],[32,3],[138,3],[357,3],[440,3],[702,3],[751,3]]},"1091":{"position":[[436,3]]},"1093":{"position":[[995,3],[1311,3],[1452,3],[1705,3],[1778,3]]},"1111":{"position":[[273,3],[426,3],[450,3],[704,3],[867,3],[933,3],[1041,3],[1586,3],[1807,3],[1943,3]]},"1115":{"position":[[80,3],[265,3],[515,3],[644,3],[687,3],[1036,3],[1177,3]]},"1124":{"position":[[274,3]]},"1126":{"position":[[378,3],[916,3],[1680,3]]},"1130":{"position":[[356,3]]},"1132":{"position":[[1756,3]]},"1136":{"position":[[563,3]]},"1145":{"position":[[1767,3]]},"1157":{"position":[[547,3]]},"1159":{"position":[[614,3],[1953,3]]},"1227":{"position":[[1588,3]]},"1232":{"position":[[194,3]]},"1250":{"position":[[80,3]]},"1259":{"position":[[374,3]]},"1264":{"position":[[0,3],[102,3],[157,3]]},"1379":{"position":[[197,3]]},"1395":{"position":[[1606,3]]},"1399":{"position":[[202,3]]},"1401":{"position":[[111,3]]},"1409":{"position":[[322,3]]},"1552":{"position":[[253,3]]},"1616":{"position":[[35,3]]},"1644":{"position":[[176,3]]},"1646":{"position":[[1289,3],[2760,3]]},"1669":{"position":[[441,3],[525,3],[546,3],[960,3]]},"1674":{"position":[[536,3]]},"1714":{"position":[[153,3],[319,3],[380,3],[505,3],[574,3]]},"1720":{"position":[[1296,3]]},"1738":{"position":[[218,3],[336,3]]},"1746":{"position":[[204,3]]},"1754":{"position":[[252,3]]},"1756":{"position":[[110,3],[490,3]]},"1764":{"position":[[76,3]]},"1766":{"position":[[369,3],[570,3]]},"1774":{"position":[[317,3],[368,3]]},"1780":{"position":[[199,3],[227,3]]},"1782":{"position":[[296,3],[574,3]]},"1798":{"position":[[70,3],[169,3]]}}}],["few/no",{"_index":5397,"t":{"1693":{"position":[[405,6]]}}}],["few/zero",{"_index":5398,"t":{"1693":{"position":[[427,8]]}}}],["fewer",{"_index":1900,"t":{"529":{"position":[[364,5],[660,5],[1132,5]]},"598":{"position":[[3855,5]]},"622":{"position":[[528,5]]},"658":{"position":[[1462,5]]},"670":{"position":[[1474,5]]},"672":{"position":[[58,5],[346,5],[410,5]]},"674":{"position":[[622,5]]},"1060":{"position":[[202,5]]},"1062":{"position":[[318,5]]},"1073":{"position":[[27,5]]},"1159":{"position":[[1878,5]]},"1379":{"position":[[359,5]]},"1395":{"position":[[780,5],[1661,5],[2683,5]]},"1397":{"position":[[537,5]]}}}],["fewglu",{"_index":3856,"t":{"1111":{"position":[[462,9]]}}}],["fewnerd",{"_index":5388,"t":{"1686":{"position":[[47,7]]}}}],["fewnert",{"_index":5355,"t":{"1672":{"position":[[38,7]]}}}],["fewvlm",{"_index":1696,"t":{"468":{"position":[[199,6]]}}}],["fff",{"_index":2257,"t":{"630":{"position":[[861,3],[932,3]]},"1628":{"position":[[222,7]]}}}],["ffill(x′,z)f_{fill}(x",{"_index":5419,"t":{"1704":{"position":[[247,23]]}}}],["ffn",{"_index":2771,"t":{"786":{"position":[[2667,5]]},"789":{"position":[[127,3],[789,3]]},"791":{"position":[[846,3]]},"809":{"position":[[391,3],[473,3]]},"841":{"position":[[101,3],[161,3]]}}}],["ffn(x)=max⁡(0,xw1+b1)w2+b2\\begin{equ",{"_index":1246,"t":{"304":{"position":[[178,42]]}}}],["ffn(x)=relu(xwfi+b1)wf2+b2\\text{ffn}(x",{"_index":2808,"t":{"789":{"position":[[851,39]]}}}],["fft",{"_index":3466,"t":{"979":{"position":[[859,5],[1547,3]]},"1060":{"position":[[1097,5]]},"1062":{"position":[[201,3],[1363,4],[1693,3]]},"1073":{"position":[[105,3]]},"1075":{"position":[[141,3]]},"1077":{"position":[[107,3]]}}}],["fgvcaircraft",{"_index":1506,"t":{"374":{"position":[[67,12]]}}}],["field",{"_index":572,"t":{"116":{"position":[[727,5],[907,5],[923,5]]}}}],["fietun",{"_index":2013,"t":{"557":{"position":[[146,9]]}}}],["fig",{"_index":1117,"t":{"251":{"position":[[0,3]]},"253":{"position":[[287,3]]},"298":{"position":[[57,5]]},"300":{"position":[[409,4]]},"302":{"position":[[816,5]]},"386":{"position":[[200,4]]},"393":{"position":[[0,3]]},"395":{"position":[[136,3]]},"403":{"position":[[81,3]]},"409":{"position":[[218,3],[414,3]]},"424":{"position":[[249,4],[260,3]]},"504":{"position":[[162,4]]},"529":{"position":[[1415,4],[2693,4]]},"541":{"position":[[0,3],[22,3]]},"548":{"position":[[210,4]]},"563":{"position":[[162,3]]},"565":{"position":[[108,3],[223,3]]},"598":{"position":[[3741,4]]},"628":{"position":[[418,4],[694,5]]},"658":{"position":[[1354,4]]},"662":{"position":[[263,4]]},"672":{"position":[[252,4],[501,4]]},"674":{"position":[[74,4]]},"676":{"position":[[111,4],[460,4],[1401,4]]},"686":{"position":[[308,5]]},"688":{"position":[[1102,5]]},"696":{"position":[[1157,5]]},"709":{"position":[[1271,4]]},"719":{"position":[[890,3]]},"765":{"position":[[68,3]]},"774":{"position":[[932,3]]},"776":{"position":[[67,3]]},"786":{"position":[[2531,4],[2634,4],[2727,4]]},"833":{"position":[[0,4]]},"841":{"position":[[0,4]]},"870":{"position":[[1278,4],[1636,5]]},"873":{"position":[[585,4],[602,4],[1209,4]]},"877":{"position":[[449,4]]},"887":{"position":[[597,3]]},"907":{"position":[[0,3],[79,3]]},"951":{"position":[[142,5],[175,4]]},"963":{"position":[[358,4],[444,5],[483,4]]},"969":{"position":[[0,4]]},"971":{"position":[[96,4],[200,4]]},"979":{"position":[[347,4]]},"982":{"position":[[354,5]]},"994":{"position":[[748,5]]},"1006":{"position":[[74,4],[1608,4],[1840,4],[2092,4]]},"1028":{"position":[[292,3]]},"1062":{"position":[[86,5],[159,5],[302,5],[513,5],[1204,5]]},"1067":{"position":[[38,4]]},"1084":{"position":[[128,5],[832,5],[980,4]]},"1126":{"position":[[1739,5],[1847,5]]},"1134":{"position":[[366,4]]},"1136":{"position":[[331,4],[579,4]]},"1139":{"position":[[116,4]]},"1141":{"position":[[607,4]]},"1143":{"position":[[0,4],[214,4],[427,4]]},"1145":{"position":[[109,4]]},"1149":{"position":[[490,4]]},"1195":{"position":[[313,4]]},"1199":{"position":[[53,5]]},"1221":{"position":[[99,4],[373,5]]},"1227":{"position":[[711,4],[1218,5]]},"1242":{"position":[[214,4]]},"1277":{"position":[[47,3]]},"1305":{"position":[[237,4]]},"1347":{"position":[[818,5]]},"1350":{"position":[[848,4]]},"1352":{"position":[[177,5]]},"1389":{"position":[[140,4],[936,5]]},"1395":{"position":[[944,4],[2919,4]]},"1411":{"position":[[149,5]]},"1427":{"position":[[637,4]]},"1429":{"position":[[1144,4]]},"1431":{"position":[[1682,4]]},"1468":{"position":[[631,4],[1475,4]]},"1479":{"position":[[0,4]]},"1483":{"position":[[130,4]]},"1499":{"position":[[840,5]]},"1505":{"position":[[233,4],[242,4],[338,4]]},"1523":{"position":[[0,4]]},"1525":{"position":[[0,4],[9,4],[100,4]]},"1646":{"position":[[318,4],[382,3],[756,4],[1688,4],[1790,4],[1980,4]]},"1651":{"position":[[952,4]]},"1657":{"position":[[590,4]]},"1794":{"position":[[1034,4]]}}}],["fig.3",{"_index":5389,"t":{"1686":{"position":[[88,5]]}}}],["figur",{"_index":712,"t":{"155":{"position":[[654,6],[672,6],[893,6],[1032,6]]},"157":{"position":[[191,6],[333,6]]},"336":{"position":[[208,6],[538,7],[934,7]]},"347":{"position":[[0,6]]},"352":{"position":[[377,6],[702,6]]},"354":{"position":[[143,6]]},"358":{"position":[[621,6]]},"366":{"position":[[46,6]]},"443":{"position":[[7,6]]},"445":{"position":[[103,6]]},"457":{"position":[[167,6]]},"1002":{"position":[[79,6]]},"1019":{"position":[[652,6]]},"1028":{"position":[[91,7]]},"1167":{"position":[[942,7]]},"1268":{"position":[[61,6]]},"1270":{"position":[[293,6]]},"1291":{"position":[[1212,6],[1366,6]]},"1294":{"position":[[66,6]]},"1296":{"position":[[125,6]]},"1298":{"position":[[256,6]]},"1334":{"position":[[150,6]]},"1442":{"position":[[608,6]]},"1710":{"position":[[155,6]]}}}],["file",{"_index":38,"t":{"7":{"position":[[81,5]]},"1587":{"position":[[9,4]]},"1593":{"position":[[18,4]]},"1597":{"position":[[124,6]]},"1599":{"position":[[57,5]]},"1606":{"position":[[96,5]]},"1610":{"position":[[22,5]]},"1612":{"position":[[9,4]]},"1614":{"position":[[9,4]]},"1620":{"position":[[66,4]]},"1622":{"position":[[228,4],[311,5]]},"1634":{"position":[[23,4]]},"1638":{"position":[[96,5]]}}}],["filenam",{"_index":47,"t":{"7":{"position":[[214,10]]}}}],["fill",{"_index":3862,"t":{"1111":{"position":[[989,7]]},"1704":{"position":[[292,6],[427,6]]},"1718":{"position":[[1193,6]]}}}],["film",{"_index":2354,"t":{"662":{"position":[[1442,4]]},"1802":{"position":[[528,5],[697,5]]}}}],["filter",{"_index":566,"t":{"116":{"position":[[338,6],[347,6],[365,6]]},"242":{"position":[[123,6]]},"569":{"position":[[479,9]]}}}],["fimagef^{image}fimag",{"_index":1430,"t":{"350":{"position":[[432,21]]},"358":{"position":[[737,21]]}}}],["final",{"_index":1535,"t":{"384":{"position":[[210,5]]},"386":{"position":[[96,5]]},"527":{"position":[[392,5]]},"814":{"position":[[288,5]]},"821":{"position":[[300,5]]},"982":{"position":[[774,5]]},"990":{"position":[[18,5]]},"1132":{"position":[[258,5]]},"1352":{"position":[[981,5]]},"1384":{"position":[[946,5]]},"1389":{"position":[[1310,5]]},"1431":{"position":[[1358,5]]},"1657":{"position":[[2598,5]]}}}],["financ",{"_index":5483,"t":{"1728":{"position":[[496,10]]}}}],["find",{"_index":4996,"t":{"1583":{"position":[[182,4]]}}}],["fine",{"_index":207,"t":{"31":{"position":[[202,4]]},"63":{"position":[[68,4]]},"91":{"position":[[974,4],[1094,4]]},"93":{"position":[[186,4]]},"97":{"position":[[54,4],[212,4],[303,4]]},"106":{"position":[[131,4]]},"108":{"position":[[161,4]]},"112":{"position":[[344,4]]},"170":{"position":[[533,4],[1501,4],[1531,4]]},"203":{"position":[[239,4]]},"215":{"position":[[733,4],[830,4],[1211,4],[1364,4],[1436,4]]},"219":{"position":[[358,4]]},"244":{"position":[[87,4]]},"246":{"position":[[67,4]]},"249":{"position":[[39,4]]},"251":{"position":[[50,4]]},"253":{"position":[[258,4]]},"269":{"position":[[34,4],[217,4]]},"339":{"position":[[171,4]]},"500":{"position":[[105,4]]},"521":{"position":[[154,4],[215,4],[265,4]]},"523":{"position":[[164,4],[221,4],[363,4],[410,4],[619,4],[696,4],[801,4],[916,4],[1036,4]]},"525":{"position":[[0,4],[313,4],[372,4],[449,4],[485,4],[745,4],[785,4],[1394,4]]},"527":{"position":[[22,4],[168,4],[295,4],[2904,4],[2925,4],[3023,4],[3171,4],[3191,4]]},"529":{"position":[[1189,4],[1360,4],[1798,4],[2120,4],[2836,4]]},"531":{"position":[[22,4],[112,4],[534,4],[1015,4],[1293,4],[1472,4]]},"533":{"position":[[89,4],[104,4],[355,4],[400,4]]},"587":{"position":[[246,4]]},"589":{"position":[[240,4],[255,4],[356,4],[987,4],[1238,4],[1315,4],[1384,4],[1521,4],[1847,4],[2105,4]]},"594":{"position":[[27,4],[287,4],[646,4]]},"596":{"position":[[30,4]]},"598":{"position":[[3049,4],[3679,4],[3781,4],[3958,4],[4003,4]]},"600":{"position":[[87,4],[462,4],[493,4]]},"612":{"position":[[438,4]]},"622":{"position":[[215,4]]},"626":{"position":[[31,4],[519,4]]},"628":{"position":[[60,4],[108,4],[443,4]]},"630":{"position":[[101,4],[229,4],[2095,4],[2113,4]]},"633":{"position":[[529,4],[597,4],[630,4]]},"638":{"position":[[49,4]]},"640":{"position":[[123,4]]},"644":{"position":[[40,4],[170,4],[305,4]]},"648":{"position":[[0,4],[146,4],[223,4]]},"650":{"position":[[191,4]]},"656":{"position":[[18,4],[465,4],[501,4]]},"658":{"position":[[683,4],[993,4],[1094,4],[1191,4],[1271,4],[1445,4],[1872,4],[3014,4],[3074,5]]},"660":{"position":[[570,4]]},"664":{"position":[[85,4],[113,4]]},"666":{"position":[[463,4],[499,4],[556,4]]},"668":{"position":[[529,4],[644,4]]},"670":{"position":[[380,4],[509,4],[590,4],[1175,4],[1197,4],[1356,4],[1383,4],[1443,4],[1501,4]]},"672":{"position":[[200,4],[361,4],[438,4],[660,4],[724,4],[934,4],[1315,4]]},"674":{"position":[[107,4],[229,4],[652,4],[721,4]]},"676":{"position":[[641,4],[800,4],[823,4]]},"679":{"position":[[111,4],[451,4],[606,4]]},"681":{"position":[[121,4],[218,4],[295,4],[484,4],[688,4],[887,4],[980,4],[1032,4],[1113,4]]},"683":{"position":[[435,4],[470,4],[622,4]]},"686":{"position":[[463,4]]},"690":{"position":[[348,4],[422,4],[615,4],[779,4],[935,4]]},"692":{"position":[[324,4]]},"696":{"position":[[108,4],[179,4],[1005,4]]},"698":{"position":[[90,4]]},"703":{"position":[[27,4],[58,4]]},"707":{"position":[[336,4],[660,4],[775,4]]},"709":{"position":[[418,4],[515,4]]},"711":{"position":[[216,4]]},"713":{"position":[[48,4]]},"717":{"position":[[19,4],[228,4]]},"719":{"position":[[77,4],[1209,4]]},"723":{"position":[[319,4],[650,4],[840,4]]},"763":{"position":[[19,4]]},"780":{"position":[[6,4],[199,4]]},"784":{"position":[[62,4],[133,4],[187,4],[403,4]]},"786":{"position":[[0,4],[221,4],[302,4],[427,4],[732,4],[1515,4],[1977,4],[2177,4],[2217,4],[2446,4],[2605,4],[2675,4],[3318,4],[3498,4],[3854,4],[4612,4]]},"803":{"position":[[195,4],[659,4]]},"805":{"position":[[45,4]]},"809":{"position":[[26,4],[73,4],[201,4],[249,4],[638,4],[731,4]]},"812":{"position":[[32,4]]},"819":{"position":[[71,4]]},"823":{"position":[[95,4]]},"826":{"position":[[56,4]]},"830":{"position":[[15,4]]},"833":{"position":[[47,4]]},"839":{"position":[[166,4],[385,4],[423,4]]},"841":{"position":[[19,4]]},"843":{"position":[[24,4]]},"847":{"position":[[319,4],[378,4],[433,4],[832,4]]},"849":{"position":[[753,4],[961,4],[976,4],[1115,4],[1355,4]]},"853":{"position":[[1158,4],[2224,4],[2288,4]]},"866":{"position":[[335,4]]},"868":{"position":[[164,4],[276,4]]},"870":{"position":[[895,4],[2061,4],[2188,4]]},"875":{"position":[[233,4]]},"879":{"position":[[131,4],[159,4],[229,4],[279,4],[516,4]]},"881":{"position":[[84,4],[288,4]]},"885":{"position":[[60,4],[230,4],[625,4]]},"887":{"position":[[119,4],[251,4],[762,4],[1259,4],[1299,4]]},"891":{"position":[[113,4]]},"893":{"position":[[73,4]]},"895":{"position":[[1167,4]]},"899":{"position":[[199,4]]},"901":{"position":[[116,4]]},"905":{"position":[[127,4]]},"909":{"position":[[168,4]]},"921":{"position":[[6,4]]},"924":{"position":[[73,4]]},"934":{"position":[[159,4],[275,4]]},"938":{"position":[[52,4]]},"942":{"position":[[88,4]]},"945":{"position":[[207,4]]},"947":{"position":[[54,4],[323,4]]},"953":{"position":[[18,4],[611,4]]},"955":{"position":[[127,4]]},"967":{"position":[[110,4]]},"973":{"position":[[586,4]]},"977":{"position":[[610,4]]},"979":{"position":[[12,4],[809,4],[847,4]]},"992":{"position":[[1080,4]]},"994":{"position":[[519,4]]},"1012":{"position":[[401,4],[583,4]]},"1014":{"position":[[69,4],[664,4],[1069,4],[1383,4],[1597,4],[1667,4]]},"1060":{"position":[[124,4],[1085,4]]},"1070":{"position":[[401,4]]},"1084":{"position":[[481,4]]},"1091":{"position":[[5,4]]},"1093":{"position":[[419,4],[1322,4],[1573,4],[1716,4]]},"1095":{"position":[[81,4],[142,4],[162,4],[245,4]]},"1109":{"position":[[182,4],[284,4],[390,4],[594,4],[671,4],[1189,4]]},"1111":{"position":[[1478,4]]},"1115":{"position":[[737,4]]},"1117":{"position":[[401,4],[493,4]]},"1126":{"position":[[190,5],[277,4],[929,4]]},"1132":{"position":[[1075,4]]},"1159":{"position":[[177,4],[281,4],[356,4],[938,4]]},"1162":{"position":[[72,4]]},"1164":{"position":[[16,4]]},"1189":{"position":[[221,4]]},"1214":{"position":[[4,4]]},"1289":{"position":[[0,4]]},"1291":{"position":[[0,4],[316,4]]},"1312":{"position":[[69,4],[105,4]]},"1314":{"position":[[471,4],[592,4],[693,4]]},"1317":{"position":[[327,4]]},"1321":{"position":[[402,4],[503,4],[537,4]]},"1334":{"position":[[69,4],[196,4],[291,4]]},"1341":{"position":[[0,4],[851,4],[1216,4]]},"1345":{"position":[[21,4]]},"1347":{"position":[[24,4],[148,4]]},"1350":{"position":[[5,4],[277,4]]},"1357":{"position":[[346,4]]},"1360":{"position":[[332,4]]},"1367":{"position":[[68,4],[138,4],[282,4]]},"1369":{"position":[[468,4],[650,4]]},"1377":{"position":[[80,4],[475,4]]},"1379":{"position":[[82,4],[223,4],[377,4],[476,4],[1338,4],[1707,4]]},"1382":{"position":[[62,4],[86,4],[223,4]]},"1384":{"position":[[996,4],[1018,4],[2626,4]]},"1387":{"position":[[60,4]]},"1389":{"position":[[779,4]]},"1393":{"position":[[664,4]]},"1395":{"position":[[248,4],[294,4],[404,4],[1441,4]]},"1397":{"position":[[691,4],[1280,4]]},"1399":{"position":[[58,4],[179,4],[481,4]]},"1403":{"position":[[198,4]]},"1407":{"position":[[428,4]]},"1409":{"position":[[120,4],[374,4]]},"1415":{"position":[[193,4],[299,4]]},"1423":{"position":[[1486,4]]},"1440":{"position":[[101,4]]},"1466":{"position":[[133,4]]},"1468":{"position":[[127,4],[289,4],[423,4],[1584,4],[1699,4]]},"1471":{"position":[[204,4],[297,4]]},"1473":{"position":[[338,4],[673,4]]},"1477":{"position":[[961,4]]},"1483":{"position":[[314,4]]},"1494":{"position":[[0,4],[27,4],[140,4]]},"1499":{"position":[[54,4],[535,4],[577,4],[700,4],[772,4]]},"1507":{"position":[[140,4]]},"1509":{"position":[[22,4]]},"1515":{"position":[[56,4]]},"1544":{"position":[[190,4],[264,4]]},"1546":{"position":[[204,4],[269,4],[397,4],[881,4],[1114,4]]},"1550":{"position":[[116,4],[301,4]]},"1552":{"position":[[402,4],[524,4]]},"1558":{"position":[[147,4],[208,4],[1241,4],[2156,4]]},"1565":{"position":[[102,4]]},"1567":{"position":[[19,4]]},"1570":{"position":[[404,4]]},"1646":{"position":[[137,4],[209,4],[285,4],[397,4],[3208,4]]},"1665":{"position":[[222,4],[276,4],[324,4],[1050,4]]},"1667":{"position":[[469,4],[626,4],[811,4],[1142,4]]},"1674":{"position":[[27,4]]},"1676":{"position":[[98,4],[230,4]]},"1680":{"position":[[90,4],[154,4],[219,4]]},"1682":{"position":[[395,4],[645,4],[768,4]]},"1684":{"position":[[101,4]]},"1689":{"position":[[416,4]]},"1695":{"position":[[387,4],[492,4],[549,4],[727,4],[778,4]]},"1750":{"position":[[11,4]]},"1782":{"position":[[2200,4]]},"1788":{"position":[[553,4]]}}}],["finetun",{"_index":673,"t":{"143":{"position":[[689,10]]},"177":{"position":[[545,10],[1068,10]]},"343":{"position":[[145,10],[545,10]]},"382":{"position":[[365,9]]},"384":{"position":[[281,10],[453,10],[576,10]]},"388":{"position":[[100,10]]},"399":{"position":[[315,10]]},"426":{"position":[[479,10]]},"434":{"position":[[685,10]]},"436":{"position":[[690,10],[774,10],[793,10]]},"439":{"position":[[118,10]]},"443":{"position":[[110,10],[220,10]]},"447":{"position":[[446,10]]},"455":{"position":[[156,10],[583,10]]},"483":{"position":[[389,8],[765,11]]},"485":{"position":[[1617,10]]},"502":{"position":[[498,8]]},"521":{"position":[[22,10]]},"537":{"position":[[15,10],[91,10],[160,10]]},"539":{"position":[[16,10],[50,10],[123,10],[193,10],[432,10]]},"541":{"position":[[72,10],[108,10]]},"544":{"position":[[0,10],[70,10]]},"546":{"position":[[32,10]]},"550":{"position":[[39,10],[105,10]]},"553":{"position":[[55,10]]},"557":{"position":[[9,10],[161,10],[200,10],[415,10],[432,10]]},"559":{"position":[[12,10],[98,10],[128,10],[161,10]]},"561":{"position":[[31,10]]},"563":{"position":[[19,10],[95,10],[190,10],[237,10],[283,10]]},"565":{"position":[[49,10]]},"567":{"position":[[12,10],[155,10],[315,10],[385,10],[498,9],[530,10],[610,10]]},"569":{"position":[[292,10],[794,10],[946,10]]},"571":{"position":[[18,10],[34,10],[74,10],[97,9]]},"573":{"position":[[12,10],[40,10],[238,10]]},"575":{"position":[[4,10],[71,10],[176,10],[241,10]]},"577":{"position":[[163,10],[252,10]]},"579":{"position":[[271,10]]},"581":{"position":[[49,10],[119,10],[188,10]]},"583":{"position":[[12,10],[73,10],[159,10],[216,10]]},"681":{"position":[[616,8]]},"1225":{"position":[[620,10]]},"1227":{"position":[[0,10],[104,10],[223,10],[439,10],[480,10],[681,10],[1482,10]]},"1232":{"position":[[101,9]]},"1236":{"position":[[441,10],[456,10]]},"1238":{"position":[[204,10]]},"1257":{"position":[[29,10]]},"1262":{"position":[[40,10]]},"1268":{"position":[[86,10]]},"1285":{"position":[[476,10]]},"1442":{"position":[[1209,10]]},"1468":{"position":[[21,8]]},"1720":{"position":[[1621,10]]},"1730":{"position":[[1195,10]]},"1736":{"position":[[1643,9]]},"1750":{"position":[[169,10],[290,10]]},"1756":{"position":[[39,10],[238,10],[596,10]]},"1758":{"position":[[68,10],[129,10]]},"1772":{"position":[[406,10]]},"1792":{"position":[[134,8]]},"1800":{"position":[[39,8]]}}}],["finnish",{"_index":5414,"t":{"1702":{"position":[[496,9]]}}}],["fins∈rn×df_{in",{"_index":846,"t":{"174":{"position":[[1196,16]]}}}],["fintun",{"_index":2022,"t":{"563":{"position":[[68,9]]}}}],["first",{"_index":1502,"t":{"372":{"position":[[88,5]]},"527":{"position":[[1071,6]]},"666":{"position":[[126,5]]},"709":{"position":[[1721,5],[1746,5]]},"847":{"position":[[141,5],[251,5],[353,5],[404,5],[589,5],[719,5],[758,5]]},"849":{"position":[[694,5],[1076,5],[1433,5],[1613,5]]},"851":{"position":[[396,5],[557,5],[839,5]]},"855":{"position":[[11,5]]},"861":{"position":[[337,5]]},"870":{"position":[[956,5],[1492,5],[1652,5],[1746,5]]},"879":{"position":[[188,5],[244,5],[306,5]]},"953":{"position":[[509,5]]},"1093":{"position":[[366,5]]},"1244":{"position":[[742,5]]},"1455":{"position":[[0,5],[226,5]]},"1587":{"position":[[444,5]]},"1593":{"position":[[74,7]]},"1595":{"position":[[205,7]]},"1651":{"position":[[714,5]]}}}],["first_do",{"_index":788,"t":{"170":{"position":[[1629,11]]}}}],["fish",{"_index":2186,"t":{"598":{"position":[[3418,4]]},"1230":{"position":[[85,4]]}}}],["fisher",{"_index":2187,"t":{"598":{"position":[[3430,6]]},"630":{"position":[[1098,6],[1179,6]]}}}],["fist",{"_index":3094,"t":{"851":{"position":[[529,4]]}}}],["fit",{"_index":991,"t":{"215":{"position":[[848,7],[1230,7]]},"921":{"position":[[62,7],[128,7]]},"1126":{"position":[[824,3]]},"1750":{"position":[[388,3]]}}}],["five",{"_index":2010,"t":{"555":{"position":[[5,5]]}}}],["fix",{"_index":333,"t":{"63":{"position":[[158,5]]},"308":{"position":[[275,5],[744,5]]},"358":{"position":[[537,5]]},"523":{"position":[[969,3]]},"589":{"position":[[1657,5]]},"668":{"position":[[268,5]]},"690":{"position":[[70,5],[151,5],[223,5],[499,5],[656,5],[693,5]]},"707":{"position":[[578,4]]},"709":{"position":[[128,5]]},"1128":{"position":[[1079,5],[1164,5]]},"1164":{"position":[[153,3]]},"1384":{"position":[[2851,5],[3809,5]]},"1481":{"position":[[38,6]]},"1728":{"position":[[153,5]]},"1754":{"position":[[0,5]]},"1756":{"position":[[0,5]]},"1766":{"position":[[343,5]]},"1768":{"position":[[125,5]]},"1774":{"position":[[337,5],[409,5]]},"1780":{"position":[[48,5]]}}}],["fixr",{"_index":177,"t":{"25":{"position":[[487,10]]},"31":{"position":[[124,6]]},"78":{"position":[[69,6]]}}}],["fla",{"_index":2037,"t":{"569":{"position":[[642,3]]}}}],["flamingo",{"_index":1121,"t":{"253":{"position":[[171,8],[313,8]]},"434":{"position":[[562,8]]},"436":{"position":[[730,8],[2291,8]]},"443":{"position":[[242,8]]},"459":{"position":[[548,8]]},"468":{"position":[[74,9]]},"479":{"position":[[164,8]]}}}],["flamingo80b_{80b}80b",{"_index":1707,"t":{"475":{"position":[[122,21]]}}}],["flan",{"_index":1976,"t":{"539":{"position":[[274,4],[443,4],[495,4]]},"541":{"position":[[91,4],[127,6],[147,4]]},"553":{"position":[[0,4]]},"559":{"position":[[72,4]]},"561":{"position":[[155,4],[244,4],[303,4]]},"565":{"position":[[154,4],[239,4]]},"567":{"position":[[568,4]]},"569":{"position":[[610,4],[688,4],[730,4]]},"577":{"position":[[284,5]]},"579":{"position":[[127,4]]},"583":{"position":[[31,4]]},"1558":{"position":[[2127,5]]}}}],["flat",{"_index":1586,"t":{"426":{"position":[[266,4]]},"430":{"position":[[183,4]]}}}],["flatten",{"_index":406,"t":{"91":{"position":[[176,9],[499,7]]},"95":{"position":[[228,7],[318,7]]},"170":{"position":[[1489,7]]},"232":{"position":[[304,9]]}}}],["flax",{"_index":3933,"t":{"1134":{"position":[[881,4]]}}}],["fld",{"_index":1412,"t":{"339":{"position":[[272,3]]}}}],["flexibl",{"_index":790,"t":{"170":{"position":[[1684,9]]},"1167":{"position":[[60,8]]}}}],["flip",{"_index":1392,"t":{"336":{"position":[[11,4]]},"339":{"position":[[134,4]]},"424":{"position":[[226,4]]}}}],["float",{"_index":1352,"t":{"322":{"position":[[724,8]]},"614":{"position":[[84,6]]}}}],["flop",{"_index":203,"t":{"27":{"position":[[451,5]]},"33":{"position":[[76,5],[345,5]]},"60":{"position":[[66,6]]},"608":{"position":[[132,5],[250,5],[292,5],[439,5],[514,5],[643,5]]},"610":{"position":[[175,5],[306,5]]},"612":{"position":[[238,5],[304,5]]},"622":{"position":[[534,5]]},"727":{"position":[[410,5]]},"1357":{"position":[[671,5]]},"1360":{"position":[[319,4],[386,4],[418,4]]},"1399":{"position":[[587,5]]}}}],["florenc",{"_index":1411,"t":{"339":{"position":[[261,8]]}}}],["flow",{"_index":1243,"t":{"302":{"position":[[657,4]]}}}],["flower",{"_index":328,"t":{"63":{"position":[[48,8]]}}}],["flowers102",{"_index":501,"t":{"102":{"position":[[208,10]]},"374":{"position":[[88,10]]}}}],["focal",{"_index":868,"t":{"174":{"position":[[2493,5]]}}}],["focu",{"_index":883,"t":{"177":{"position":[[659,5]]},"723":{"position":[[56,5]]},"1145":{"position":[[651,5]]}}}],["folder",{"_index":39,"t":{"7":{"position":[[91,8],[296,6]]},"1595":{"position":[[57,7]]},"1599":{"position":[[90,7]]},"1600":{"position":[[60,6],[137,6]]},"1604":{"position":[[84,6]]},"1608":{"position":[[58,7]]},"1634":{"position":[[43,7]]}}}],["follow",{"_index":2039,"t":{"569":{"position":[[889,6]]},"885":{"position":[[36,9]]},"887":{"position":[[101,9],[227,9],[743,9],[1155,9]]},"891":{"position":[[103,9]]},"905":{"position":[[37,9],[502,9]]},"909":{"position":[[27,9]]},"932":{"position":[[309,9],[449,9],[564,9],[624,9],[950,9]]},"934":{"position":[[21,9],[141,9],[591,9],[1127,9],[1542,9],[1668,9],[1910,9],[2385,9],[2505,9]]},"938":{"position":[[12,9],[492,9]]},"942":{"position":[[169,9]]},"945":{"position":[[285,9],[864,9]]},"949":{"position":[[302,9],[658,9]]},"951":{"position":[[124,9],[439,9]]},"955":{"position":[[456,9]]},"963":{"position":[[89,9]]},"965":{"position":[[346,9]]},"967":{"position":[[403,9]]},"973":{"position":[[131,9],[240,9],[283,9],[431,9],[519,9]]},"1303":{"position":[[524,9]]},"1542":{"position":[[119,6]]},"1778":{"position":[[377,9]]}}}],["food101",{"_index":1507,"t":{"374":{"position":[[80,7]]}}}],["footer",{"_index":4992,"t":{"1583":{"position":[[104,6]]}}}],["footprint",{"_index":3984,"t":{"1153":{"position":[[352,9]]}}}],["forc",{"_index":4671,"t":{"1431":{"position":[[1590,5]]}}}],["forget",{"_index":1630,"t":{"443":{"position":[[407,11]]},"658":{"position":[[2693,6]]},"1750":{"position":[[265,10]]},"1752":{"position":[[302,10]]}}}],["form",{"_index":4703,"t":{"1440":{"position":[[418,4]]},"1646":{"position":[[307,5],[659,5],[923,4]]},"1657":{"position":[[516,8]]},"1772":{"position":[[213,4]]}}}],["format",{"_index":2064,"t":{"589":{"position":[[1024,10]]},"594":{"position":[[508,6]]},"1006":{"position":[[2815,6]]}}}],["formul",{"_index":746,"t":{"165":{"position":[[1646,11],[1777,11],[2658,11]]}}}],["forward",{"_index":1069,"t":{"236":{"position":[[102,7],[397,7]]},"292":{"position":[[141,7]]},"298":{"position":[[789,7]]},"304":{"position":[[96,7]]},"310":{"position":[[603,7],[1790,7]]},"598":{"position":[[1318,7],[1436,7],[1756,7],[1863,7],[3214,7]]},"733":{"position":[[751,7]]},"786":{"position":[[2650,7]]},"791":{"position":[[111,7]]},"857":{"position":[[606,7],[778,7]]},"1149":{"position":[[422,7]]},"1187":{"position":[[393,7]]}}}],["fozen",{"_index":1710,"t":{"477":{"position":[[146,5]]}}}],["fp16",{"_index":1103,"t":{"244":{"position":[[303,4],[383,4]]},"517":{"position":[[1114,5],[1178,5]]}}}],["fp2v,fv2p=bi",{"_index":820,"t":{"172":{"position":[[424,12]]}}}],["fp32",{"_index":1104,"t":{"244":{"position":[[339,4]]},"517":{"position":[[1217,5]]}}}],["fp={enclrefexpress",{"_index":794,"t":{"170":{"position":[[1933,21]]}}}],["fprompt",{"_index":5521,"t":{"1736":{"position":[[1570,8]]}}}],["fprompt(x)f_{prompt}(x)fprompt​(x",{"_index":5412,"t":{"1702":{"position":[[12,34]]},"1708":{"position":[[214,34]]},"1710":{"position":[[80,34]]}}}],["fprompt(⋅)f_{prompt}(\\cdot)fprompt",{"_index":5413,"t":{"1702":{"position":[[82,38]]}}}],["fprompt,i(⋅)f_{prompt",{"_index":5509,"t":{"1736":{"position":[[430,22]]}}}],["fpt",{"_index":4358,"t":{"1347":{"position":[[574,3]]}}}],["fp′=fp+fv2p(1)\\left",{"_index":822,"t":{"172":{"position":[[461,20]]}}}],["fp′f'_pfp",{"_index":848,"t":{"174":{"position":[[1698,11],[1981,11]]}}}],["fp′​=fp​+fv2p​​(1",{"_index":834,"t":{"172":{"position":[[664,18]]}}}],["fp∈r1024×df_p",{"_index":784,"t":{"170":{"position":[[1411,13]]}}}],["fp∈rl×df_p",{"_index":758,"t":{"170":{"position":[[447,10]]}}}],["fr",{"_index":5137,"t":{"1632":{"position":[[51,2],[147,6]]},"1636":{"position":[[64,2]]},"1640":{"position":[[65,2]]}}}],["frac",{"_index":1432,"t":{"350":{"position":[[554,6]]},"358":{"position":[[969,6]]},"774":{"position":[[565,8]]}}}],["frac{(h^\\ell_2",{"_index":1863,"t":{"527":{"position":[[1697,16]]}}}],["frac{(h^\\ell_5",{"_index":1874,"t":{"527":{"position":[[2037,16]]}}}],["frac{1}{\\binom{k}{2}}e_{(x,y_w,y_l",{"_index":4934,"t":{"1558":{"position":[[720,36]]}}}],["frac{1}{\\mathcal{l^2}}\\sum_i\\sum_j\\cos(e^1_j",{"_index":4648,"t":{"1429":{"position":[[1009,46]]}}}],["frac{1}{d_1",{"_index":2955,"t":{"801":{"position":[[545,13]]}}}],["frac{1}{d_2",{"_index":2958,"t":{"801":{"position":[[590,13]]}}}],["frac{1}{k",{"_index":5505,"t":{"1736":{"position":[[354,11],[1426,11]]}}}],["frac{1}{l",{"_index":858,"t":{"174":{"position":[[2170,11]]}}}],["frac{1}{m",{"_index":5321,"t":{"1659":{"position":[[913,11]]}}}],["frac{1}{n",{"_index":5298,"t":{"1657":{"position":[[2914,11]]}}}],["frac{1}{t",{"_index":2095,"t":{"596":{"position":[[145,11]]}}}],["frac{1}{t}\\sum^t_{t=1",{"_index":2124,"t":{"596":{"position":[[1769,23]]}}}],["frac{1}{z",{"_index":4167,"t":{"1244":{"position":[[1219,11]]}}}],["frac{1}{|\\mathcal{x",{"_index":5294,"t":{"1657":{"position":[[2773,23]]}}}],["frac{1}{|d|}\\sum^{|d|}_{i=1}(\\triangledown_w",{"_index":2270,"t":{"630":{"position":[[1442,45]]}}}],["frac{2rd+2d}{n",{"_index":3563,"t":{"994":{"position":[[389,16]]}}}],["frac{\\exp(\\beta(\\text{x",{"_index":2129,"t":{"596":{"position":[[2067,26]]}}}],["frac{\\parti",{"_index":3129,"t":{"853":{"position":[[814,14],[1530,15]]},"855":{"position":[[274,15],[565,14],[732,14]]},"1485":{"position":[[659,15]]},"1487":{"position":[[959,15]]}}}],["frac{\\prod_{j=1}^n",{"_index":5282,"t":{"1657":{"position":[[2069,19]]}}}],["frac{\\sum^n_{n=1",{"_index":2108,"t":{"596":{"position":[[547,18]]}}}],["frac{d_l}{r}}wb​∈rrdb​​×rdl",{"_index":2279,"t":{"630":{"position":[[1796,30]]}}}],["frac{e^{\\hat{p}_j",{"_index":3541,"t":{"988":{"position":[[1667,18]]}}}],["frac{e^{w_c",{"_index":4053,"t":{"1185":{"position":[[537,12]]}}}],["frac{q(l_k",{"_index":2161,"t":{"598":{"position":[[1628,11]]}}}],["frac{r",{"_index":3189,"t":{"857":{"position":[[1034,7]]}}}],["frac{sim(e^{s_r",{"_index":4665,"t":{"1431":{"position":[[985,18]]}}}],["frac{t",{"_index":3153,"t":{"853":{"position":[[1965,7]]}}}],["frac{t}{n})^3",{"_index":3212,"t":{"861":{"position":[[224,14]]}}}],["frac{v_t}{v_f}r(\\text{",{"_index":3220,"t":{"861":{"position":[[770,26]]}}}],["framework",{"_index":1393,"t":{"336":{"position":[[28,9]]},"339":{"position":[[538,9]]},"648":{"position":[[980,9]]},"1084":{"position":[[807,9]]},"1238":{"position":[[1405,9]]},"1240":{"position":[[4,9]]},"1389":{"position":[[378,9]]},"1403":{"position":[[83,9]]},"1447":{"position":[[311,9]]},"1449":{"position":[[10,9]]},"1451":{"position":[[119,9]]},"1646":{"position":[[2994,9]]},"1653":{"position":[[1035,9]]}}}],["frankl",{"_index":1960,"t":{"531":{"position":[[698,8],[1340,7]]},"849":{"position":[[842,8]]},"851":{"position":[[882,7]]}}}],["free",{"_index":2252,"t":{"628":{"position":[[1575,4]]},"648":{"position":[[697,4]]},"1093":{"position":[[1010,4]]},"1132":{"position":[[879,5]]},"1291":{"position":[[1342,4]]},"1305":{"position":[[430,4]]},"1328":{"position":[[89,4]]},"1440":{"position":[[413,4]]},"1587":{"position":[[461,4]]},"1600":{"position":[[172,4]]},"1752":{"position":[[7,4],[158,4],[216,4]]},"1754":{"position":[[209,4],[277,4]]},"1772":{"position":[[208,4]]},"1802":{"position":[[442,4],[846,4]]}}}],["freez",{"_index":1132,"t":{"269":{"position":[[4,8],[59,8],[150,8]]},"523":{"position":[[672,8]]},"527":{"position":[[78,8],[2835,8]]},"658":{"position":[[2761,8]]},"660":{"position":[[664,8]]},"670":{"position":[[610,8]]},"686":{"position":[[432,8]]},"688":{"position":[[678,8]]},"717":{"position":[[107,6]]},"719":{"position":[[880,6]]},"733":{"position":[[560,6]]},"739":{"position":[[233,6]]},"749":{"position":[[31,8]]},"786":{"position":[[452,8]]},"855":{"position":[[466,8]]},"859":{"position":[[84,8]]},"866":{"position":[[316,8]]},"870":{"position":[[1004,8]]},"875":{"position":[[277,8]]},"885":{"position":[[140,8]]},"887":{"position":[[327,8],[656,8]]},"938":{"position":[[88,8]]},"961":{"position":[[276,8]]},"1012":{"position":[[38,8]]},"1014":{"position":[[356,8]]},"1109":{"position":[[769,8]]},"1126":{"position":[[590,8]]},"1145":{"position":[[2238,8]]},"1167":{"position":[[1176,8]]},"1178":{"position":[[19,8]]},"1279":{"position":[[183,9]]},"1289":{"position":[[281,8]]},"1291":{"position":[[364,8]]},"1473":{"position":[[277,8]]}}}],["french",{"_index":1309,"t":{"313":{"position":[[165,6],[203,6]]},"322":{"position":[[243,6]]},"328":{"position":[[289,6]]},"1630":{"position":[[33,7]]},"1634":{"position":[[250,7]]},"1636":{"position":[[23,6]]},"1695":{"position":[[1064,7]]}}}],["frequenc",{"_index":1769,"t":{"504":{"position":[[795,9]]},"853":{"position":[[2184,9]]},"1496":{"position":[[348,11]]}}}],["frobeniu",{"_index":2734,"t":{"778":{"position":[[278,9]]}}}],["front",{"_index":5091,"t":{"1618":{"position":[[51,5]]}}}],["frozem",{"_index":1692,"t":{"468":{"position":[[40,6]]}}}],["frozen",{"_index":963,"t":{"213":{"position":[[123,6]]},"436":{"position":[[950,6]]},"443":{"position":[[172,6]]},"445":{"position":[[147,6]]},"468":{"position":[[84,7]]},"471":{"position":[[25,6],[87,6]]},"483":{"position":[[628,6]]},"529":{"position":[[2034,6]]},"628":{"position":[[366,6]]},"633":{"position":[[908,6]]},"648":{"position":[[185,6],[471,6],[529,6]]},"696":{"position":[[1567,6]]},"719":{"position":[[1176,6]]},"741":{"position":[[64,6]]},"934":{"position":[[239,6],[954,6]]},"945":{"position":[[66,6]]},"953":{"position":[[156,6]]},"982":{"position":[[753,6]]},"984":{"position":[[445,6]]},"1019":{"position":[[449,6]]},"1039":{"position":[[93,6]]},"1062":{"position":[[1161,6]]},"1065":{"position":[[370,6]]},"1067":{"position":[[665,6]]},"1070":{"position":[[1225,8]]},"1124":{"position":[[46,6],[438,6],[560,6]]},"1126":{"position":[[56,6],[433,6],[1253,6],[1497,6],[1808,6]]},"1128":{"position":[[765,6],[1059,6]]},"1130":{"position":[[186,6]]},"1132":{"position":[[778,6],[1229,6],[1657,6]]},"1134":{"position":[[0,6]]},"1145":{"position":[[2140,6]]},"1147":{"position":[[0,6]]},"1149":{"position":[[597,6]]},"1151":{"position":[[280,6]]},"1153":{"position":[[16,6],[461,6]]},"1159":{"position":[[407,6],[591,6]]},"1164":{"position":[[196,6]]},"1178":{"position":[[601,6]]},"1409":{"position":[[242,6],[306,6],[562,6]]},"1411":{"position":[[207,6],[363,6]]},"1413":{"position":[[81,6]]},"1419":{"position":[[275,6]]},"1466":{"position":[[16,6]]},"1494":{"position":[[214,6]]},"1720":{"position":[[389,6],[1213,6]]}}}],["frozen\\textcolor{blue}{\\text{frozen}}frozen",{"_index":2521,"t":{"694":{"position":[[855,43]]}}}],["frzen",{"_index":4581,"t":{"1407":{"position":[[144,5]]}}}],["ft",{"_index":1928,"t":{"529":{"position":[[2469,2],[2574,2],[2746,2]]},"765":{"position":[[54,2]]},"999":{"position":[[36,3],[291,2]]},"1002":{"position":[[239,2]]},"1004":{"position":[[180,4]]},"1006":{"position":[[128,2],[301,2]]},"1014":{"position":[[81,4],[937,2]]},"1019":{"position":[[833,2]]},"1022":{"position":[[83,2]]},"1024":{"position":[[66,2],[135,2]]},"1026":{"position":[[273,2]]},"1035":{"position":[[36,2]]},"1039":{"position":[[77,2]]},"1047":{"position":[[175,2],[266,2],[338,2],[383,2],[438,2]]},"1049":{"position":[[45,2]]},"1056":{"position":[[82,2]]},"1062":{"position":[[0,2]]},"1070":{"position":[[413,2]]},"1084":{"position":[[493,5]]},"1109":{"position":[[606,4],[649,2],[689,3],[716,2],[823,2],[909,2],[995,2],[1180,2],[1322,2]]},"1111":{"position":[[1172,2],[1648,2],[1877,2],[1908,2]]},"1113":{"position":[[110,2],[446,2]]},"1117":{"position":[[232,2]]},"1227":{"position":[[115,4]]},"1257":{"position":[[40,4]]},"1268":{"position":[[97,5]]},"1289":{"position":[[12,4],[91,2],[218,2],[599,2]]},"1291":{"position":[[12,4],[116,2],[546,2],[959,2],[1381,2]]},"1300":{"position":[[5,2]]},"1312":{"position":[[81,3]]},"1317":{"position":[[127,2],[181,2]]},"1319":{"position":[[39,2],[95,2]]},"1323":{"position":[[547,2]]}}}],["fttop2",{"_index":4318,"t":{"1312":{"position":[[117,9]]}}}],["fttop2\\text{ft}^{top2}fttop2",{"_index":2659,"t":{"747":{"position":[[39,28]]}}}],["full",{"_index":998,"t":{"215":{"position":[[1104,4]]},"521":{"position":[[149,4]]},"525":{"position":[[1389,4]]},"527":{"position":[[2920,4],[3186,4]]},"529":{"position":[[2115,4],[2569,4],[2741,4]]},"589":{"position":[[2100,4]]},"598":{"position":[[3674,4],[3776,4],[3953,4],[3998,4]]},"622":{"position":[[210,4]]},"633":{"position":[[524,4]]},"640":{"position":[[118,4]]},"644":{"position":[[35,4]]},"648":{"position":[[141,4],[892,4]]},"650":{"position":[[186,4]]},"656":{"position":[[460,4],[496,4]]},"668":{"position":[[524,4]]},"672":{"position":[[929,4],[1310,4]]},"674":{"position":[[647,4]]},"676":{"position":[[818,4]]},"681":{"position":[[290,4],[683,4],[1027,4]]},"703":{"position":[[53,4]]},"707":{"position":[[331,4]]},"719":{"position":[[732,4],[1204,4]]},"723":{"position":[[645,4]]},"733":{"position":[[70,4]]},"735":{"position":[[44,4]]},"763":{"position":[[14,4]]},"786":{"position":[[216,4],[727,4],[1510,4],[2172,4],[2212,4],[4607,4]]},"789":{"position":[[112,4]]},"809":{"position":[[21,4]]},"868":{"position":[[291,4]]},"870":{"position":[[884,4],[2050,4],[2177,4]]},"899":{"position":[[194,4]]},"977":{"position":[[605,4]]},"979":{"position":[[7,4],[842,4]]},"992":{"position":[[1075,4]]},"1006":{"position":[[1833,6]]},"1037":{"position":[[49,4]]},"1060":{"position":[[1080,4]]},"1062":{"position":[[57,4]]},"1084":{"position":[[476,4]]},"1126":{"position":[[1644,4]]},"1147":{"position":[[1046,4]]},"1159":{"position":[[351,4],[933,4]]},"1162":{"position":[[163,4]]},"1225":{"position":[[615,4]]},"1227":{"position":[[85,4],[218,4],[434,4],[475,4],[1477,4]]},"1250":{"position":[[55,4]]},"1257":{"position":[[24,4]]},"1268":{"position":[[81,4]]},"1285":{"position":[[471,4]]},"1289":{"position":[[145,4],[561,4]]},"1300":{"position":[[0,4]]},"1312":{"position":[[64,4],[85,6]]},"1317":{"position":[[174,6]]},"1319":{"position":[[90,4]]},"1334":{"position":[[286,4]]},"1345":{"position":[[16,4]]},"1347":{"position":[[19,4],[143,4]]},"1350":{"position":[[0,4],[272,4]]},"1357":{"position":[[341,4]]},"1360":{"position":[[327,4]]},"1367":{"position":[[63,4]]},"1407":{"position":[[422,5]]},"1423":{"position":[[1481,4]]},"1475":{"position":[[380,4]]},"1505":{"position":[[505,4]]},"1507":{"position":[[129,4]]},"1669":{"position":[[806,4]]},"1746":{"position":[[166,4]]}}}],["fulli",{"_index":1171,"t":{"289":{"position":[[479,5]]},"292":{"position":[[120,5]]},"304":{"position":[[75,5]]},"525":{"position":[[479,5]]},"527":{"position":[[162,5]]},"658":{"position":[[3008,5]]},"755":{"position":[[76,5]]},"853":{"position":[[37,5]]},"1039":{"position":[[340,5]]},"1111":{"position":[[254,5],[288,5],[1175,5]]},"1674":{"position":[[608,5]]},"1695":{"position":[[0,5],[346,5]]}}}],["function",{"_index":385,"t":{"86":{"position":[[699,8]]},"124":{"position":[[102,8],[474,8]]},"126":{"position":[[562,8],[618,8],[1061,8]]},"130":{"position":[[275,8]]},"153":{"position":[[269,8]]},"155":{"position":[[115,10],[251,8]]},"159":{"position":[[153,8]]},"177":{"position":[[242,8],[685,8]]},"234":{"position":[[321,8]]},"296":{"position":[[10,8],[188,10]]},"298":{"position":[[298,8],[575,9],[826,8],[1163,8]]},"300":{"position":[[83,8],[307,8]]},"306":{"position":[[218,8]]},"308":{"position":[[825,8]]},"496":{"position":[[77,8]]},"500":{"position":[[478,13]]},"502":{"position":[[384,13]]},"504":{"position":[[775,8]]},"515":{"position":[[613,8]]},"658":{"position":[[1639,8],[1746,8],[1973,8],[2082,8]]},"660":{"position":[[943,8],[1156,8]]},"662":{"position":[[1285,8]]},"676":{"position":[[1564,8]]},"789":{"position":[[227,8]]},"801":{"position":[[921,8]]},"847":{"position":[[645,8]]},"849":{"position":[[1308,8]]},"857":{"position":[[80,9],[107,8],[213,8],[311,8],[501,8]]},"861":{"position":[[665,8],[1041,8]]},"870":{"position":[[81,8],[117,8],[260,8]]},"873":{"position":[[58,8],[115,8],[191,8],[304,8],[462,8],[547,8],[1360,8],[1604,8],[1767,8]]},"881":{"position":[[462,8]]},"893":{"position":[[795,8],[1693,8],[1937,8]]},"1065":{"position":[[652,8],[830,8]]},"1067":{"position":[[781,8]]},"1099":{"position":[[1834,8]]},"1167":{"position":[[508,8]]},"1195":{"position":[[528,8]]},"1238":{"position":[[803,8]]},"1244":{"position":[[1977,8]]},"1246":{"position":[[272,8]]},"1296":{"position":[[657,8]]},"1305":{"position":[[1098,8]]},"1350":{"position":[[304,8],[625,8]]},"1352":{"position":[[1069,8]]},"1384":{"position":[[896,9],[3915,8]]},"1389":{"position":[[1482,8],[1800,8],[1906,8],[1940,8]]},"1395":{"position":[[2834,8]]},"1449":{"position":[[202,8],[358,8],[450,8]]},"1462":{"position":[[371,9],[401,9],[435,9]]},"1485":{"position":[[775,8]]},"1558":{"position":[[623,8],[1183,8],[1371,8]]},"1612":{"position":[[150,8]]},"1624":{"position":[[110,8],[218,8]]},"1651":{"position":[[430,8],[482,8],[517,8],[1628,9]]},"1655":{"position":[[204,9],[286,9],[349,9],[2098,9],[2223,9],[2255,9]]},"1657":{"position":[[551,9],[1100,8]]},"1659":{"position":[[28,8]]},"1695":{"position":[[480,8],[601,8]]},"1702":{"position":[[73,8]]},"1710":{"position":[[71,8]]}}}],["fune",{"_index":3420,"t":{"934":{"position":[[1210,6]]}}}],["funtion",{"_index":1761,"t":{"502":{"position":[[254,12]]}}}],["fusc",{"_index":25,"t":{"3":{"position":[[221,5],[400,5],[579,5],[758,5],[937,5],[1116,5],[1295,5],[1474,5],[1653,5],[1832,5],[2011,5],[2190,5],[2369,5],[2548,5],[2727,5],[2906,5]]},"5":{"position":[[101,5]]}}}],["fuse",{"_index":174,"t":{"25":{"position":[[369,5]]},"33":{"position":[[193,5],[267,5],[297,5]]},"38":{"position":[[153,5]]},"40":{"position":[[77,5]]},"76":{"position":[[161,5]]},"78":{"position":[[206,5],[854,5]]},"953":{"position":[[373,6]]}}}],["fusion",{"_index":750,"t":{"165":{"position":[[1980,6]]},"168":{"position":[[587,6]]},"172":{"position":[[231,6],[719,6],[777,6]]},"174":{"position":[[1671,6]]},"203":{"position":[[39,6],[71,6],[103,6],[212,6],[301,6],[336,6]]},"755":{"position":[[295,6]]},"809":{"position":[[443,6]]},"932":{"position":[[371,6]]},"934":{"position":[[1249,6],[2421,6]]},"953":{"position":[[107,6],[596,6]]},"967":{"position":[[333,6]]}}}],["futur",{"_index":2739,"t":{"780":{"position":[[146,6]]},"807":{"position":[[544,6]]},"1451":{"position":[[30,6]]}}}],["fvf_vfv",{"_index":814,"t":{"172":{"position":[[118,8]]}}}],["fv′f'_vfv",{"_index":844,"t":{"174":{"position":[[910,11]]}}}],["fyll",{"_index":1927,"t":{"529":{"position":[[2464,4]]}}}],["f∈ff",{"_index":5174,"t":{"1651":{"position":[[491,4],[746,4]]},"1655":{"position":[[8,4]]}}}],["g",{"_index":1485,"t":{"358":{"position":[[838,5],[1300,5]]}}}],["g(v_c",{"_index":1487,"t":{"358":{"position":[[984,7]]}}}],["g(v_j",{"_index":1488,"t":{"358":{"position":[[1036,7]]}}}],["g(⋅)g",{"_index":1484,"t":{"358":{"position":[[825,6],[1287,6]]}}}],["g(⋅){\\color{blue}{g^{(\\cdot)}}}g",{"_index":1889,"t":{"527":{"position":[[2797,35]]}}}],["g(⋅)ℓ,b(⋅)ℓ,(⋅){\\color{blue}{g^\\ell_{(\\cdot",{"_index":1879,"t":{"527":{"position":[[2387,48]]}}}],["g={p∗i,λi,qi∗}\\mathcal{g",{"_index":2850,"t":{"795":{"position":[[606,25]]}}}],["g={p∗i​,λi​,qi",{"_index":2854,"t":{"795":{"position":[[665,19]]}}}],["g\\mathcal{g}g",{"_index":938,"t":{"191":{"position":[[287,13]]},"982":{"position":[[463,13],[916,13],[1184,13]]},"986":{"position":[[102,13],[618,13]]},"988":{"position":[[125,13],[597,13],[836,13]]},"992":{"position":[[37,13],[105,13],[709,13]]},"999":{"position":[[876,13],[930,13],[977,13]]},"1006":{"position":[[2284,13],[2722,13],[2848,13]]}}}],["g_l",{"_index":3357,"t":{"893":{"position":[[1824,3]]}}}],["gain",{"_index":1527,"t":{"382":{"position":[[258,4]]},"805":{"position":[[152,4]]},"1425":{"position":[[641,4]]}}}],["gamma",{"_index":264,"t":{"49":{"position":[[488,8]]},"598":{"position":[[1804,6],[1847,8]]},"797":{"position":[[1005,6]]},"807":{"position":[[144,9],[179,8],[215,8],[245,8]]},"814":{"position":[[458,8]]},"1485":{"position":[[163,6]]},"1558":{"position":[[1628,6],[1955,8],[1993,8],[2018,8]]}}}],["gamma_1",{"_index":4796,"t":{"1485":{"position":[[230,11]]}}}],["gamma_2",{"_index":4797,"t":{"1485":{"position":[[242,9]]}}}],["gamma_i",{"_index":4808,"t":{"1485":{"position":[[700,10]]}}}],["gamma_m\\}γ={γ1​,γ2​,…,γm",{"_index":4798,"t":{"1485":{"position":[[259,27]]}}}],["gao",{"_index":5352,"t":{"1669":{"position":[[471,3]]}}}],["gap",{"_index":854,"t":{"174":{"position":[[1951,5]]},"502":{"position":[[507,3]]},"529":{"position":[[2102,4],[2192,3]]},"707":{"position":[[701,3]]},"1126":{"position":[[1727,3]]},"1153":{"position":[[180,3]]},"1409":{"position":[[658,3]]},"1423":{"position":[[935,3],[1078,3],[1096,3]]},"1466":{"position":[[313,3],[647,3]]},"1468":{"position":[[453,3],[1619,3]]},"1473":{"position":[[353,3]]},"1477":{"position":[[978,3]]},"1499":{"position":[[69,3],[820,3],[885,3]]},"1646":{"position":[[313,4],[573,3],[665,3]]}}}],["gate",{"_index":1130,"t":{"265":{"position":[[181,6]]},"285":{"position":[[13,5]]},"504":{"position":[[768,6]]},"885":{"position":[[375,6]]},"887":{"position":[[568,6],[791,6]]},"893":{"position":[[1476,6]]},"901":{"position":[[168,6]]},"928":{"position":[[82,6]]},"938":{"position":[[360,6],[389,6]]},"945":{"position":[[176,6]]},"949":{"position":[[445,6],[524,7]]},"990":{"position":[[424,4]]},"1230":{"position":[[251,6]]},"1345":{"position":[[375,6]]},"1347":{"position":[[1235,5],[1328,6],[1947,6]]},"1352":{"position":[[152,6]]},"1364":{"position":[[0,6]]},"1369":{"position":[[36,6],[292,5]]},"1377":{"position":[[393,6]]},"1379":{"position":[[834,6]]},"1389":{"position":[[734,6],[902,4],[1046,4],[1475,6],[1793,6],[1899,6],[1933,6]]},"1395":{"position":[[2827,6]]},"1397":{"position":[[1436,6]]},"1401":{"position":[[682,5]]}}}],["gaussian",{"_index":2433,"t":{"676":{"position":[[975,8]]},"733":{"position":[[874,8]]},"791":{"position":[[489,8]]},"795":{"position":[[838,8]]},"1067":{"position":[[715,8]]},"1354":{"position":[[299,8]]}}}],["gcn",{"_index":5332,"t":{"1665":{"position":[[138,3]]}}}],["geforc",{"_index":4325,"t":{"1314":{"position":[[389,7]]}}}],["gelu",{"_index":441,"t":{"91":{"position":[[1468,4]]}}}],["gem",{"_index":4596,"t":{"1419":{"position":[[837,3]]}}}],["gener",{"_index":98,"t":{"17":{"position":[[0,8]]},"163":{"position":[[53,10]]},"165":{"position":[[1951,10],[2455,7]]},"168":{"position":[[555,10]]},"170":{"position":[[11,10]]},"177":{"position":[[24,7]]},"205":{"position":[[18,10]]},"215":{"position":[[389,7],[1200,10],[1918,14],[1984,14]]},"225":{"position":[[495,9]]},"236":{"position":[[471,10]]},"347":{"position":[[45,10]]},"428":{"position":[[109,11]]},"436":{"position":[[1435,10]]},"451":{"position":[[107,10],[180,10]]},"485":{"position":[[256,10],[392,10],[406,10],[582,10]]},"488":{"position":[[21,10]]},"494":{"position":[[26,10],[257,10]]},"496":{"position":[[175,10]]},"502":{"position":[[115,10],[243,10],[373,10],[458,10]]},"506":{"position":[[58,10]]},"508":{"position":[[39,10],[77,10],[160,10],[222,10]]},"510":{"position":[[279,10]]},"515":{"position":[[846,10]]},"529":{"position":[[2087,14],[2177,14]]},"531":{"position":[[166,16]]},"594":{"position":[[312,14],[590,14],[684,14]]},"622":{"position":[[641,10]]},"727":{"position":[[139,10]]},"743":{"position":[[82,10]]},"784":{"position":[[828,10]]},"895":{"position":[[1216,10]]},"905":{"position":[[351,10]]},"934":{"position":[[796,10]]},"967":{"position":[[282,8]]},"1008":{"position":[[603,10]]},"1070":{"position":[[345,10]]},"1093":{"position":[[214,10]]},"1109":{"position":[[0,7]]},"1126":{"position":[[1223,10]]},"1128":{"position":[[48,10],[178,10],[418,10],[1258,10]]},"1153":{"position":[[232,14],[250,7]]},"1187":{"position":[[88,10]]},"1230":{"position":[[182,10]]},"1253":{"position":[[334,10]]},"1289":{"position":[[190,10],[474,10]]},"1310":{"position":[[29,10]]},"1312":{"position":[[14,10]]},"1317":{"position":[[74,10],[478,10],[639,10]]},"1332":{"position":[[156,10]]},"1411":{"position":[[443,7]]},"1419":{"position":[[860,10]]},"1442":{"position":[[1654,10],[2279,10]]},"1447":{"position":[[161,10],[282,10],[338,10]]},"1462":{"position":[[324,10],[361,9]]},"1477":{"position":[[57,10]]},"1554":{"position":[[101,11]]},"1597":{"position":[[28,9]]},"1599":{"position":[[67,9]]},"1646":{"position":[[1735,9],[2845,9],[3025,9]]},"1698":{"position":[[498,10]]},"1714":{"position":[[394,10],[555,10]]},"1718":{"position":[[654,10]]},"1736":{"position":[[652,10],[1270,10],[1281,10]]},"1772":{"position":[[435,10]]},"1774":{"position":[[5,10]]},"1778":{"position":[[168,9]]},"1782":{"position":[[1667,10],[2117,11],[2293,10],[2324,10],[2432,10],[2491,10],[2611,10]]},"1788":{"position":[[32,10],[91,10]]},"1790":{"position":[[265,10],[289,10],[375,10]]}}}],["generalis",{"_index":1134,"t":{"273":{"position":[[21,14]]}}}],["generalist",{"_index":3874,"t":{"1126":{"position":[[2183,12],[2294,10]]}}}],["generation/complet",{"_index":1723,"t":{"483":{"position":[[809,22]]}}}],["genom",{"_index":1092,"t":{"242":{"position":[[27,6]]},"249":{"position":[[120,6]]}}}],["geometr",{"_index":511,"t":{"102":{"position":[[350,10]]}}}],["german",{"_index":1305,"t":{"313":{"position":[[46,6]]},"322":{"position":[[20,6]]},"324":{"position":[[85,6]]},"326":{"position":[[689,6]]},"328":{"position":[[263,6]]}}}],["get",{"_index":5147,"t":{"1636":{"position":[[138,7]]}}}],["ggg",{"_index":2258,"t":{"630":{"position":[[1016,3],[1168,3],[2072,3],[2232,3]]},"873":{"position":[[200,3],[322,3],[440,3],[699,3],[1613,3],[1679,3],[1750,3]]}}}],["gi={ai∗,b∗i}\\mathcal{g}_i",{"_index":2826,"t":{"791":{"position":[[646,25]]}}}],["git",{"_index":1122,"t":{"253":{"position":[[306,3]]}}}],["github",{"_index":1724,"t":{"485":{"position":[[25,6]]},"490":{"position":[[42,6]]},"515":{"position":[[7,6],[201,6],[561,6]]}}}],["given",{"_index":2748,"t":{"786":{"position":[[911,5]]},"789":{"position":[[131,5]]},"797":{"position":[[1601,5]]},"1151":{"position":[[1243,5]]},"1236":{"position":[[0,6]]},"1238":{"position":[[0,6]]}}}],["gi​={ai∗​,b∗i",{"_index":2829,"t":{"791":{"position":[[692,17]]}}}],["gk,i={pk,∗i,λk,i,qk,i∗}\\mathcal{g}_{k,i",{"_index":2876,"t":{"797":{"position":[[370,40]]}}}],["gk,i\\mathcal{g}_{k,i}gk,i",{"_index":2950,"t":{"801":{"position":[[360,26],[807,26]]}}}],["gk,i​={pk,∗i​,λk,i​,qk,i",{"_index":2880,"t":{"797":{"position":[[450,29]]}}}],["gl",{"_index":3361,"t":{"893":{"position":[[2164,3]]}}}],["glg_lgl",{"_index":3351,"t":{"893":{"position":[[1490,8],[1563,8],[1718,8],[1986,8],[2095,8]]}}}],["glip",{"_index":835,"t":{"172":{"position":[[760,4]]}}}],["glm",{"_index":3638,"t":{"1043":{"position":[[51,3]]},"1047":{"position":[[216,3]]}}}],["global",{"_index":845,"t":{"174":{"position":[[935,6],[1928,6]]},"285":{"position":[[441,6]]},"803":{"position":[[248,6]]},"857":{"position":[[296,6],[486,6]]},"873":{"position":[[176,6],[1589,6]]},"895":{"position":[[233,6]]},"912":{"position":[[43,6]]}}}],["glue",{"_index":1895,"t":{"529":{"position":[[19,4],[2296,4],[2551,4]]},"533":{"position":[[157,4]]},"656":{"position":[[359,4],[423,4]]},"658":{"position":[[3000,4]]},"664":{"position":[[66,4]]},"668":{"position":[[0,4],[501,4]]},"670":{"position":[[743,4],[1315,4]]},"672":{"position":[[338,4],[512,4]]},"761":{"position":[[31,4]]},"786":{"position":[[4430,6]]},"805":{"position":[[82,7]]},"812":{"position":[[54,6]]},"816":{"position":[[46,4]]},"864":{"position":[[51,4]]},"866":{"position":[[643,4]]},"868":{"position":[[153,4]]},"870":{"position":[[2081,4]]},"879":{"position":[[508,4]]},"997":{"position":[[200,5],[317,4],[355,4],[489,4],[512,4]]},"999":{"position":[[207,4]]},"1002":{"position":[[15,4],[94,4]]},"1004":{"position":[[227,4]]},"1017":{"position":[[74,4]]},"1070":{"position":[[92,4]]},"1073":{"position":[[7,4]]},"1080":{"position":[[0,4],[329,4]]},"1082":{"position":[[27,4]]},"1084":{"position":[[638,4]]},"1145":{"position":[[2274,4]]},"1147":{"position":[[729,4]]},"1253":{"position":[[176,4]]},"1377":{"position":[[418,4]]},"1379":{"position":[[1172,4]]},"1393":{"position":[[144,4],[572,4]]},"1395":{"position":[[25,4]]},"1417":{"position":[[0,4]]},"1419":{"position":[[630,5]]},"1423":{"position":[[82,4],[165,4],[433,4],[463,4]]},"1425":{"position":[[83,4],[101,4]]}}}],["glue/suerglu",{"_index":3588,"t":{"1002":{"position":[[332,13]]}}}],["gmi\\mathcal{g}_{m_i}gmi",{"_index":4518,"t":{"1389":{"position":[[907,25]]}}}],["go",{"_index":1778,"t":{"515":{"position":[[116,3]]}}}],["goal",{"_index":4694,"t":{"1440":{"position":[[10,4]]}}}],["gold",{"_index":5610,"t":{"1782":{"position":[[3062,4]]},"1802":{"position":[[970,4],[1064,4],[1189,4]]}}}],["good",{"_index":1936,"t":{"531":{"position":[[0,4]]},"999":{"position":[[892,4]]},"1014":{"position":[[533,6]]},"1698":{"position":[[564,5]]},"1704":{"position":[[127,7]]}}}],["googl",{"_index":1795,"t":{"517":{"position":[[430,6]]},"666":{"position":[[358,6]]}}}],["gordon",{"_index":1955,"t":{"531":{"position":[[489,6]]}}}],["gp\\mathcal{g}_pgp",{"_index":4533,"t":{"1389":{"position":[[1949,18]]}}}],["gpipe/efficientnet",{"_index":338,"t":{"65":{"position":[[52,19]]}}}],["gpt",{"_index":1534,"t":{"382":{"position":[[375,3]]},"397":{"position":[[11,3]]},"399":{"position":[[182,3]]},"477":{"position":[[29,4],[37,3]]},"596":{"position":[[1521,4]]},"606":{"position":[[211,3],[296,3],[346,3]]},"608":{"position":[[224,5]]},"610":{"position":[[188,3],[467,3]]},"612":{"position":[[268,3],[346,3]]},"626":{"position":[[455,3]]},"681":{"position":[[63,4]]},"683":{"position":[[279,3]]},"717":{"position":[[0,3],[242,3],[340,3],[348,3]]},"719":{"position":[[692,3]]},"723":{"position":[[68,3]]},"741":{"position":[[164,3],[335,3]]},"743":{"position":[[19,3]]},"763":{"position":[[48,3]]},"765":{"position":[[0,3]]},"770":{"position":[[37,3]]},"774":{"position":[[1178,3]]},"786":{"position":[[83,3]]},"905":{"position":[[470,3]]},"907":{"position":[[107,3]]},"932":{"position":[[103,3]]},"959":{"position":[[57,3]]},"963":{"position":[[494,3]]},"965":{"position":[[249,3]]},"1080":{"position":[[54,4],[380,4]]},"1091":{"position":[[21,3],[213,3],[292,3]]},"1093":{"position":[[237,4],[406,3],[925,3],[1163,3],[1199,3],[1485,3],[1624,3],[1734,3]]},"1095":{"position":[[0,3],[206,3]]},"1103":{"position":[[71,3]]},"1107":{"position":[[177,3],[721,3]]},"1109":{"position":[[348,3],[1114,3],[1214,3]]},"1113":{"position":[[210,3]]},"1117":{"position":[[105,3]]},"1120":{"position":[[224,3]]},"1124":{"position":[[114,3],[266,3]]},"1126":{"position":[[143,3],[440,3],[903,3]]},"1128":{"position":[[625,3]]},"1132":{"position":[[17,3],[1699,3]]},"1136":{"position":[[555,3],[605,3],[660,3],[706,3]]},"1145":{"position":[[624,3]]},"1159":{"position":[[97,3]]},"1289":{"position":[[490,3]]},"1291":{"position":[[241,3],[265,3],[613,3],[849,4]]},"1296":{"position":[[13,3]]},"1314":{"position":[[19,3],[34,3]]},"1317":{"position":[[617,3],[680,3],[712,3]]},"1367":{"position":[[39,3]]},"1409":{"position":[[313,3]]},"1423":{"position":[[1433,4]]},"1440":{"position":[[647,3]]},"1471":{"position":[[115,3],[122,3]]},"1473":{"position":[[0,3]]},"1544":{"position":[[171,3],[324,3]]},"1546":{"position":[[261,3],[378,3],[506,3],[578,3],[624,3],[664,3],[752,3],[819,3],[939,3]]},"1550":{"position":[[85,3]]},"1558":{"position":[[32,3],[46,3],[112,3],[200,3],[2088,3],[2148,3]]},"1563":{"position":[[5,3]]},"1565":{"position":[[16,3],[51,3]]},"1570":{"position":[[355,4]]},"1573":{"position":[[326,3]]},"1752":{"position":[[243,3]]}}}],["gpt2",{"_index":2247,"t":{"628":{"position":[[706,4],[716,4],[729,4],[1373,4],[1595,4]]},"633":{"position":[[135,4],[187,4],[197,4],[224,4]]},"638":{"position":[[0,4],[17,4]]},"644":{"position":[[109,4]]},"1070":{"position":[[1562,4],[1581,4],[1602,4]]},"1111":{"position":[[1768,4],[1792,4]]},"1113":{"position":[[126,4],[138,4],[175,4],[237,4],[359,4],[559,4],[659,4]]},"1772":{"position":[[493,5]]},"1802":{"position":[[189,5]]}}}],["gpt3",{"_index":157,"t":{"25":{"position":[[0,4]]},"459":{"position":[[619,4]]},"628":{"position":[[0,5]]}}}],["gpt4",{"_index":2244,"t":{"628":{"position":[[6,5]]}}}],["gpu",{"_index":159,"t":{"25":{"position":[[52,4]]},"86":{"position":[[98,3]]},"88":{"position":[[221,3]]},"182":{"position":[[349,4]]},"225":{"position":[[348,3]]},"244":{"position":[[110,3]]},"269":{"position":[[164,3]]},"285":{"position":[[499,3]]},"287":{"position":[[44,4]]},"315":{"position":[[14,4]]},"322":{"position":[[143,4],[708,3],[718,3]]},"517":{"position":[[421,4]]},"612":{"position":[[473,3]]},"616":{"position":[[267,3]]},"622":{"position":[[564,3]]},"628":{"position":[[464,3],[492,3]]},"705":{"position":[[74,3]]},"717":{"position":[[303,3]]},"807":{"position":[[97,4]]},"885":{"position":[[215,3]]},"887":{"position":[[837,3]]},"905":{"position":[[112,3]]},"1082":{"position":[[16,3]]},"1314":{"position":[[624,3],[675,3]]},"1339":{"position":[[98,3]]}}}],["gpu/tpu",{"_index":205,"t":{"31":{"position":[[48,7]]}}}],["gp∈(0,1)\\mathcal{g}_p",{"_index":4531,"t":{"1389":{"position":[[1809,21]]}}}],["gradcam",{"_index":1669,"t":{"457":{"position":[[672,7],[789,7]]},"466":{"position":[[177,7],[200,7]]}}}],["grade",{"_index":4737,"t":{"1449":{"position":[[337,7]]}}}],["gradient",{"_index":639,"t":{"138":{"position":[[148,8],[185,8]]},"236":{"position":[[376,8]]},"244":{"position":[[150,8]]},"253":{"position":[[182,8]]},"298":{"position":[[1190,9]]},"358":{"position":[[1263,8]]},"457":{"position":[[889,8]]},"587":{"position":[[133,8]]},"589":{"position":[[225,8],[744,8]]},"594":{"position":[[347,8]]},"616":{"position":[[177,8]]},"626":{"position":[[132,8],[202,9],[488,8]]},"628":{"position":[[517,8],[569,9],[869,8],[1566,8]]},"630":{"position":[[2328,8]]},"633":{"position":[[472,8]]},"648":{"position":[[605,8],[688,8],[801,8]]},"650":{"position":[[0,8],[217,8]]},"681":{"position":[[154,8]]},"719":{"position":[[1091,8]]},"721":{"position":[[287,8]]},"723":{"position":[[391,8]]},"733":{"position":[[569,8]]},"741":{"position":[[315,8]]},"786":{"position":[[1480,8]]},"795":{"position":[[1113,8]]},"797":{"position":[[1265,8]]},"801":{"position":[[977,8]]},"809":{"position":[[150,8]]},"853":{"position":[[1241,8],[1312,8],[1385,8]]},"861":{"position":[[1331,8]]},"988":{"position":[[1471,9]]},"1014":{"position":[[167,8]]},"1093":{"position":[[1119,8]]},"1095":{"position":[[426,8]]},"1101":{"position":[[197,8]]},"1128":{"position":[[1413,8]]},"1159":{"position":[[214,9],[770,8]]},"1185":{"position":[[705,8]]},"1300":{"position":[[137,8]]},"1395":{"position":[[3087,8]]},"1442":{"position":[[491,8]]},"1468":{"position":[[66,8]]},"1487":{"position":[[435,8]]},"1505":{"position":[[304,8]]},"1525":{"position":[[69,8]]},"1558":{"position":[[1289,8],[1312,8]]},"1718":{"position":[[491,8],[523,8]]},"1750":{"position":[[105,8]]}}}],["gradual",{"_index":351,"t":{"78":{"position":[[176,9],[334,9],[592,9]]},"853":{"position":[[1832,7]]}}}],["grain",{"_index":761,"t":{"170":{"position":[[538,7],[1506,7],[1523,7],[1536,7],[1726,7]]},"339":{"position":[[176,7]]},"500":{"position":[[110,7]]},"786":{"position":[[3503,7]]},"1389":{"position":[[784,7]]},"1483":{"position":[[319,7]]},"1509":{"position":[[27,7]]},"1680":{"position":[[95,7],[159,7],[224,7]]},"1788":{"position":[[558,7]]}}}],["granular",{"_index":4773,"t":{"1466":{"position":[[485,11]]},"1468":{"position":[[1179,11]]}}}],["graph",{"_index":704,"t":{"153":{"position":[[206,5]]},"598":{"position":[[305,5]]},"1665":{"position":[[184,5]]},"1667":{"position":[[100,5]]},"1788":{"position":[[367,6]]}}}],["grassmann",{"_index":2711,"t":{"774":{"position":[[422,9]]}}}],["great",{"_index":3201,"t":{"859":{"position":[[200,7],[462,7]]},"1646":{"position":[[1103,9],[1177,7]]}}}],["greedi",{"_index":641,"t":{"138":{"position":[[427,6]]},"151":{"position":[[173,6]]},"155":{"position":[[603,6]]},"397":{"position":[[117,6]]},"459":{"position":[[524,6]]},"912":{"position":[[157,6]]},"1111":{"position":[[1272,6]]}}}],["green",{"_index":3928,"t":{"1134":{"position":[[108,5]]},"1628":{"position":[[523,5]]}}}],["green</highlight",{"_index":5132,"t":{"1628":{"position":[[421,17]]}}}],["greet",{"_index":5006,"t":{"1587":{"position":[[86,9],[103,10],[392,11]]}}}],["greetings.md",{"_index":5004,"t":{"1587":{"position":[[33,13],[63,12]]}}}],["ground",{"_index":684,"t":{"149":{"position":[[79,6]]},"436":{"position":[[196,6]]},"457":{"position":[[506,8]]},"466":{"position":[[127,8]]},"1669":{"position":[[381,6]]},"1796":{"position":[[126,6]]}}}],["group",{"_index":516,"t":{"104":{"position":[[264,5]]},"533":{"position":[[190,5]]},"801":{"position":[[225,5]]},"949":{"position":[[357,6]]},"1238":{"position":[[311,5]]},"1246":{"position":[[1027,5]]},"1248":{"position":[[324,5]]},"1591":{"position":[[14,6]]}}}],["gsm8k",{"_index":1533,"t":{"382":{"position":[[341,5]]},"384":{"position":[[968,5]]},"388":{"position":[[119,6]]},"391":{"position":[[0,5]]},"399":{"position":[[147,5],[407,5]]},"403":{"position":[[118,5]]},"409":{"position":[[239,5],[389,5]]},"561":{"position":[[235,5]]}}}],["gsum",{"_index":5603,"t":{"1782":{"position":[[2277,4]]}}}],["gtx",{"_index":4326,"t":{"1314":{"position":[[397,3]]}}}],["guid",{"_index":751,"t":{"165":{"position":[[2651,6]]},"168":{"position":[[420,6]]},"170":{"position":[[203,6],[341,6],[361,6],[513,6]]},"174":{"position":[[1727,6],[1854,6],[1874,6]]},"179":{"position":[[9,6],[169,6],[189,6]]},"209":{"position":[[17,6]]},"679":{"position":[[489,5]]},"681":{"position":[[1637,5]]},"694":{"position":[[259,5]]},"696":{"position":[[80,5],[1737,5]]},"711":{"position":[[255,5]]},"841":{"position":[[323,5]]},"1600":{"position":[[217,7]]}}}],["guidanc",{"_index":5592,"t":{"1782":{"position":[[1725,8]]}}}],["guied",{"_index":745,"t":{"165":{"position":[[1621,7]]},"170":{"position":[[2118,8],[2179,8],[2296,8],[2426,8]]}}}],["guiededannot",{"_index":812,"t":{"170":{"position":[[2408,17]]}}}],["guiededcategori",{"_index":811,"t":{"170":{"position":[[2392,15]]}}}],["guiededenclrefcategori",{"_index":795,"t":{"170":{"position":[[1955,22]]}}}],["guiededf_p",{"_index":798,"t":{"170":{"position":[[2027,10]]}}}],["guiededmerge(encvref[templ",{"_index":796,"t":{"170":{"position":[[1978,30]]}}}],["gumbel",{"_index":4433,"t":{"1364":{"position":[[166,6]]}}}],["guo",{"_index":1740,"t":{"498":{"position":[[138,3]]},"525":{"position":[[1161,4]]},"529":{"position":[[58,3]]}}}],["gym",{"_index":4723,"t":{"1442":{"position":[[2211,3]]}}}],["g∈(0,1)\\mathcal{g",{"_index":4524,"t":{"1389":{"position":[[1491,18]]}}}],["g≈0\\mathcal{g",{"_index":4529,"t":{"1389":{"position":[[1630,14]]}}}],["h",{"_index":1048,"t":{"227":{"position":[[582,3]]},"594":{"position":[[779,1]]},"791":{"position":[[172,1]]},"853":{"position":[[1857,2]]},"861":{"position":[[79,2]]}}}],["h,w)(h",{"_index":413,"t":{"91":{"position":[[288,8]]}}}],["h/14",{"_index":531,"t":{"106":{"position":[[196,4]]},"110":{"position":[[4,4]]},"114":{"position":[[214,4]]}}}],["h0,…,hi][h_0",{"_index":3624,"t":{"1019":{"position":[[579,14]]}}}],["h0,…hi,e(x),hi+1,…hm,e(y)}\\begin{equ",{"_index":3796,"t":{"1099":{"position":[[1491,43]]}}}],["h1>hello",{"_index":5109,"t":{"1624":{"position":[[148,10],[254,10]]}}}],["h1>mi",{"_index":5085,"t":{"1612":{"position":[[193,6]]}}}],["h1ℓ=att(q1,ℓ,k1,ℓ,v1,ℓ,..,qm,ℓ,km,ℓ,vm,ℓ)h^\\ell_1",{"_index":1850,"t":{"527":{"position":[[1182,49]]}}}],["h2ℓ=dropout(wm1ℓ⋅h1ℓ+bm1ℓ)h3ℓ=gln1ℓ⊙(h2ℓ+x)−μσ+bln1ℓh4ℓ=gelu(wm2ℓ⋅h3ℓ+bm2ℓ)h5ℓ=dropout(wm3ℓ⋅h4ℓ+bm3ℓ)outℓ=gln2ℓ⊙(h5ℓ+h3ℓ)−μσ+bln2ℓ\\begin{align",{"_index":1855,"t":{"527":{"position":[[1395,143]]}}}],["h<i",{"_index":4282,"t":{"1300":{"position":[[425,8]]}}}],["h<i(n)]h_{<i",{"_index":5456,"t":{"1720":{"position":[[737,14]]}}}],["h<i).\\begin{equ",{"_index":4273,"t":{"1300":{"position":[[205,21]]}}}],["h<i=[h<i(1",{"_index":5455,"t":{"1720":{"position":[[723,13]]}}}],["h=8h",{"_index":1233,"t":{"300":{"position":[[1240,4]]}}}],["h=w(0)h",{"_index":2817,"t":{"791":{"position":[[77,7]]}}}],["h=w(0)x+△x=w(0)x+bax,\\begin{equ",{"_index":2819,"t":{"791":{"position":[[134,37]]}}}],["h=w0x+△wx=w0x+bax(3)h",{"_index":2635,"t":{"733":{"position":[[774,21]]}}}],["h=w0xh",{"_index":2633,"t":{"733":{"position":[[726,6]]}}}],["h[cls]egreatth_{\\text{[cl",{"_index":3203,"t":{"859":{"position":[[278,29]]}}}],["h[cls]h_{[cls]}h[cl",{"_index":4049,"t":{"1185":{"position":[[396,22]]}}}],["h[cls]h_{\\text{[cls]}}h[cl",{"_index":3205,"t":{"859":{"position":[[346,29]]}}}],["h^0:m=argmin⁡h",{"_index":3802,"t":{"1099":{"position":[[1941,14]]}}}],["h^\\ell_1",{"_index":1858,"t":{"527":{"position":[[1602,8]]}}}],["h^\\ell_2",{"_index":1856,"t":{"527":{"position":[[1539,8]]}}}],["h^\\ell_3",{"_index":1860,"t":{"527":{"position":[[1647,8],[1830,8],[2056,9]]}}}],["h^\\ell_4",{"_index":1866,"t":{"527":{"position":[[1770,8],[1937,8]]}}}],["h^\\ell_5",{"_index":1869,"t":{"527":{"position":[[1874,8]]}}}],["h^kp",{"_index":2486,"t":{"688":{"position":[[832,6]]}}}],["h^kp^*pk​=hkp",{"_index":2498,"t":{"690":{"position":[[284,14]]}}}],["h^kx",{"_index":2487,"t":{"688":{"position":[[839,5]]}}}],["h^kx_{new",{"_index":2476,"t":{"688":{"position":[[470,11],[819,10]]}}}],["h^qx",{"_index":2474,"t":{"688":{"position":[[454,5]]}}}],["h^vp^*pv​=hvp",{"_index":2500,"t":{"690":{"position":[[314,14]]}}}],["h^vx_{new}q=hqx,knew​=hkxnew​,vnew​=hvxnew",{"_index":2478,"t":{"688":{"position":[[492,43]]}}}],["h^{(1)}_{<i",{"_index":5457,"t":{"1720":{"position":[[754,14]]}}}],["h_0",{"_index":3627,"t":{"1019":{"position":[[704,4]]},"1099":{"position":[[1538,4]]}}}],["h_a",{"_index":4457,"t":{"1384":{"position":[[549,3]]},"1389":{"position":[[1339,3],[1575,3]]}}}],["h_fha′​=ga​ha​+hf",{"_index":4528,"t":{"1389":{"position":[[1581,18]]}}}],["h_fha′​=ha​+hf",{"_index":4523,"t":{"1389":{"position":[[1345,15]]}}}],["h_i",{"_index":3628,"t":{"1019":{"position":[[716,4]]},"1099":{"position":[[1549,4]]},"1101":{"position":[[773,3]]},"1296":{"position":[[713,3]]},"1305":{"position":[[676,3]]}}}],["h_i][h0​,…,hi",{"_index":3625,"t":{"1019":{"position":[[601,15]]}}}],["h_i^{(1",{"_index":4249,"t":{"1296":{"position":[[408,11]]}}}],["h_i^{(n)})pϕ​(zi+1",{"_index":4261,"t":{"1296":{"position":[[913,19]]}}}],["h_i^{(n)}]hi​=[hi(1)​;⋯;hi(n",{"_index":4250,"t":{"1296":{"position":[[428,31]]}}}],["h_m",{"_index":3798,"t":{"1099":{"position":[[1582,4]]}}}],["h_{<i",{"_index":4255,"t":{"1296":{"position":[[742,8]]},"1300":{"position":[[355,8]]},"1305":{"position":[[786,8]]}}}],["h_{<i};\\theta;\\phi)\\tag{2}ϕmax​logp(y∣x;θ;ϕ)=ϕmax​yi​∑​logp(yi​,h<i​;θ;ϕ)(2",{"_index":5453,"t":{"1720":{"position":[[547,76]]}}}],["h_{[cls]}}}p(y=c∣h)=∑k∈c​ewk​h[cls]​ewc​h[cl",{"_index":4056,"t":{"1185":{"position":[[593,48]]}}}],["h_{[cls]}}}{\\sum_{k",{"_index":4054,"t":{"1185":{"position":[[550,19]]}}}],["h_{\\leq",{"_index":4259,"t":{"1296":{"position":[[875,7]]}}}],["h_{down",{"_index":3523,"t":{"988":{"position":[[974,8]]}}}],["h_{i+1",{"_index":3797,"t":{"1099":{"position":[[1567,8]]}}}],["h_{k,i",{"_index":4173,"t":{"1244":{"position":[[1521,7]]}}}],["h_{k,i}^{(teach",{"_index":4174,"t":{"1244":{"position":[[1531,19]]}}}],["h_{out",{"_index":3527,"t":{"988":{"position":[[1058,7]]}}}],["h_{out}}/t",{"_index":3543,"t":{"988":{"position":[[1727,11]]}}}],["h_{out}}/t}{\\sum^{t+1}_{k=1}e^{\\hat{p}_k",{"_index":3542,"t":{"988":{"position":[[1686,40]]}}}],["h_{up",{"_index":3525,"t":{"988":{"position":[[1012,6]]}}}],["ha",{"_index":3274,"t":{"877":{"position":[[399,4]]}}}],["ha=wup⊤ϕ(wdown⊤hfn),\\begin{equ",{"_index":4456,"t":{"1384":{"position":[[512,36]]}}}],["hadamard",{"_index":4146,"t":{"1242":{"position":[[738,8]]},"1246":{"position":[[660,8]]},"1285":{"position":[[238,8]]}}}],["hah_aha",{"_index":4455,"t":{"1384":{"position":[[484,8]]},"1389":{"position":[[1296,8]]}}}],["hambardzumyan",{"_index":3873,"t":{"1126":{"position":[[1338,14],[1905,14]]}}}],["han",{"_index":1953,"t":{"531":{"position":[[447,3]]},"683":{"position":[[1124,4]]},"849":{"position":[[418,4]]},"851":{"position":[[60,4],[464,4]]},"853":{"position":[[416,4]]},"868":{"position":[[22,4]]}}}],["hand",{"_index":1396,"t":{"336":{"position":[[357,4],[558,4],[1096,4]]},"347":{"position":[[523,4]]},"356":{"position":[[204,4]]},"368":{"position":[[28,4]]},"1145":{"position":[[1618,4]]}}}],["handcraft",{"_index":3835,"t":{"1105":{"position":[[188,9]]},"1107":{"position":[[564,9]]}}}],["handl",{"_index":3427,"t":{"945":{"position":[[313,6]]}}}],["hard",{"_index":1752,"t":{"500":{"position":[[887,4],[1011,4]]},"709":{"position":[[1444,6]]},"851":{"position":[[681,4]]},"1012":{"position":[[255,4]]},"1014":{"position":[[950,4],[1358,4],[1551,4]]},"1017":{"position":[[94,4]]},"1033":{"position":[[157,4]]},"1109":{"position":[[968,4]]},"1720":{"position":[[1909,4],[1977,4]]}}}],["harder",{"_index":1755,"t":{"500":{"position":[[1041,6]]}}}],["hardwar",{"_index":1825,"t":{"525":{"position":[[619,8]]},"533":{"position":[[304,8]]},"719":{"position":[[1023,8]]}}}],["harmless",{"_index":4964,"t":{"1560":{"position":[[187,8],[438,8]]}}}],["hat{\\text{y}}^{(n",{"_index":2133,"t":{"596":{"position":[[2174,23]]}}}],["hat{a",{"_index":1635,"t":{"451":{"position":[[28,7]]}}}],["hat{a}_j",{"_index":1653,"t":{"455":{"position":[[715,9]]}}}],["hat{h}_{0:m",{"_index":3804,"t":{"1099":{"position":[[1982,13]]}}}],["hat{l}_{adpt",{"_index":2674,"t":{"755":{"position":[[499,14]]}}}],["hat{l}_{ln",{"_index":2675,"t":{"755":{"position":[[578,12]]}}}],["hat{l}_{lora",{"_index":2680,"t":{"757":{"position":[[187,14]]}}}],["hat{p}_",{"_index":4792,"t":{"1485":{"position":[[151,9]]}}}],["hat{p}_k",{"_index":4162,"t":{"1244":{"position":[[1000,10]]}}}],["hat{q}_j",{"_index":1652,"t":{"455":{"position":[[704,10]]}}}],["hat{y}^{(n)}_{<t}))}{\\sum^n_{n=1}t^{(n",{"_index":2111,"t":{"596":{"position":[[626,42]]}}}],["hat{y}_1",{"_index":2114,"t":{"596":{"position":[[875,11]]}}}],["hat{y}_2",{"_index":2115,"t":{"596":{"position":[[887,10]]}}}],["hat{y}_i^{(n)}|\\text{x",{"_index":2110,"t":{"596":{"position":[[599,26]]}}}],["hat{y}_{t^(n)}y^​(n)=(y^​1​,y^​2​,…,y^​t(n",{"_index":2116,"t":{"596":{"position":[[905,45]]}}}],["ha′=gaha+hfh'_a",{"_index":4526,"t":{"1389":{"position":[[1543,15]]}}}],["ha′=ha+hfh'_a",{"_index":4522,"t":{"1389":{"position":[[1323,13]]}}}],["hdown=wdown⊤(x^)hup=w⊤up(nonlinear(hdown))hout=layernorm(hup),\\begin{array}{l",{"_index":3522,"t":{"988":{"position":[[894,79]]}}}],["head",{"_index":432,"t":{"91":{"position":[[1009,4],[1053,4],[1345,4],[2170,4],[2402,4]]},"97":{"position":[[97,4]]},"116":{"position":[[558,4],[764,4]]},"126":{"position":[[697,4],[1119,4]]},"174":{"position":[[471,4],[1326,5],[1358,4],[1405,4],[2573,4]]},"177":{"position":[[1402,4]]},"287":{"position":[[321,4]]},"292":{"position":[[86,4]]},"294":{"position":[[145,4]]},"300":{"position":[[435,4],[545,4],[1232,5],[1259,4],[1346,4],[1391,4]]},"302":{"position":[[20,4]]},"310":{"position":[[1910,5],[1959,4]]},"324":{"position":[[174,4],[247,4],[302,4]]},"328":{"position":[[129,4]]},"527":{"position":[[533,5],[559,4]]},"681":{"position":[[442,4]]},"692":{"position":[[384,4]]},"696":{"position":[[1651,4]]},"698":{"position":[[81,4]]},"789":{"position":[[89,4],[209,4],[727,4]]},"849":{"position":[[1338,4],[1377,4]]},"859":{"position":[[14,4],[42,4],[142,4]]},"866":{"position":[[127,4],[284,4]]},"870":{"position":[[997,4]]},"873":{"position":[[1154,4],[1180,4],[1229,5],[1315,4],[1374,4],[1405,4],[1495,4],[1552,4]]},"875":{"position":[[18,4],[220,4],[270,4]]},"877":{"position":[[289,4],[471,4]]},"893":{"position":[[2117,4]]},"1037":{"position":[[22,4],[175,4]]},"1052":{"position":[[39,4],[141,4],[217,4],[228,4]]},"1101":{"position":[[1001,4],[1063,4],[1142,4]]},"1145":{"position":[[1194,4]]},"1185":{"position":[[670,5]]},"1187":{"position":[[347,6]]},"1382":{"position":[[31,4]]},"1384":{"position":[[963,4],[1134,4],[3178,4]]},"1389":{"position":[[214,4]]},"1395":{"position":[[2249,4]]},"1401":{"position":[[272,5],[342,4]]},"1618":{"position":[[192,7]]},"1646":{"position":[[448,5]]}}}],["headi=attention(qwiq,kwik,vwiv)\\begin{align",{"_index":1213,"t":{"300":{"position":[[616,45]]}}}],["headi​​=concat(head1​,…,headh​)wo=attention(qwiq​,kwik​,vwiv",{"_index":1224,"t":{"300":{"position":[[854,63]]}}}],["health",{"_index":5482,"t":{"1728":{"position":[[485,10]]}}}],["heatmap",{"_index":2428,"t":{"676":{"position":[[277,7]]},"1427":{"position":[[647,7]]},"1429":{"position":[[1266,7]]}}}],["heavi",{"_index":5538,"t":{"1752":{"position":[[364,5]]}}}],["height",{"_index":1049,"t":{"227":{"position":[[593,7]]}}}],["held",{"_index":1998,"t":{"550":{"position":[[336,4]]},"553":{"position":[[76,4]]},"575":{"position":[[254,4]]},"594":{"position":[[995,4]]},"598":{"position":[[3013,4]]}}}],["hellaswag",{"_index":4652,"t":{"1429":{"position":[[1620,9]]},"1546":{"position":[[912,10]]}}}],["hello",{"_index":5037,"t":{"1593":{"position":[[57,5]]},"1595":{"position":[[188,5],[365,8]]}}}],["hellodocusauru",{"_index":5108,"t":{"1624":{"position":[[119,17],[227,17]]}}}],["help",{"_index":4616,"t":{"1423":{"position":[[919,5]]},"1431":{"position":[[2345,8]]},"1560":{"position":[[170,8],[221,7],[233,7]]}}}],["heurist",{"_index":986,"t":{"215":{"position":[[507,9]]},"1442":{"position":[[927,10],[1479,11]]},"1449":{"position":[[440,9]]},"1653":{"position":[[961,9]]},"1684":{"position":[[872,9]]}}}],["hf",{"_index":3738,"t":{"1084":{"position":[[554,5]]}}}],["hfh_fhf",{"_index":4521,"t":{"1389":{"position":[[1278,8]]}}}],["hfnh_{fn}hfn",{"_index":4452,"t":{"1384":{"position":[[364,13]]},"1389":{"position":[[1451,13]]}}}],["hhh",{"_index":1208,"t":{"300":{"position":[[210,3]]},"789":{"position":[[205,3]]},"1101":{"position":[[156,3],[1125,3]]}}}],["hi",{"_index":5042,"t":{"1595":{"position":[[156,5]]}}}],["hi(0≤i≤m)h_i",{"_index":3800,"t":{"1099":{"position":[[1650,12],[1882,12]]}}}],["hi(j)h_i^{(j)}hi(j",{"_index":4251,"t":{"1296":{"position":[[503,20]]}}}],["hi(n)]h_i",{"_index":4248,"t":{"1296":{"position":[[395,10]]}}}],["hi(n)h_i^{(n)}hi(n",{"_index":4264,"t":{"1296":{"position":[[1001,20]]}}}],["hi=[hi(1",{"_index":4247,"t":{"1296":{"position":[[383,11]]}}}],["hi=lmϕ(zi,h<i),\\begin{equ",{"_index":4253,"t":{"1296":{"position":[[681,31]]}}}],["hi=mlp([h→i",{"_index":3815,"t":{"1101":{"position":[[691,11]]}}}],["hi={pθ[i,:],ifi∈pidxlmϕ(zi,h<i),otherwise.\\begin{equ",{"_index":4297,"t":{"1305":{"position":[[617,58]]}}}],["hidden",{"_index":433,"t":{"91":{"position":[[1075,6]]},"132":{"position":[[158,6]]},"265":{"position":[[254,6]]},"285":{"position":[[132,6]]},"287":{"position":[[107,6]]},"298":{"position":[[769,6]]},"310":{"position":[[291,6]]},"628":{"position":[[329,6]]},"786":{"position":[[667,6]]},"809":{"position":[[567,6]]},"814":{"position":[[161,6]]},"821":{"position":[[156,6]]},"859":{"position":[[417,6]]},"1070":{"position":[[986,6]]},"1172":{"position":[[136,6]]},"1210":{"position":[[70,6]]},"1244":{"position":[[1341,6],[1724,6],[1756,6]]},"1259":{"position":[[184,6]]},"1275":{"position":[[66,6],[139,6],[355,6]]},"1384":{"position":[[215,6],[378,6]]}}}],["hiden",{"_index":625,"t":{"132":{"position":[[190,5]]}}}],["hierach",{"_index":4775,"t":{"1468":{"position":[[1080,11]]}}}],["hierarch",{"_index":774,"t":{"170":{"position":[[1136,12]]},"172":{"position":[[89,12]]},"174":{"position":[[221,12]]},"1429":{"position":[[1241,14]]},"1466":{"position":[[444,12]]},"1477":{"position":[[1193,12]]},"1479":{"position":[[66,12]]},"1481":{"position":[[260,12]]},"1483":{"position":[[0,12]]},"1489":{"position":[[172,12]]},"1505":{"position":[[0,12],[1188,12]]},"1507":{"position":[[197,12]]},"1515":{"position":[[110,12]]},"1517":{"position":[[39,12]]},"1653":{"position":[[562,12]]}}}],["hierarchi",{"_index":5371,"t":{"1676":{"position":[[401,9]]}}}],["high",{"_index":494,"t":{"102":{"position":[[92,4]]},"215":{"position":[[51,4]]},"221":{"position":[[601,4]]},"227":{"position":[[286,4],[669,4]]},"230":{"position":[[183,4]]},"326":{"position":[[387,4]]},"786":{"position":[[3481,4],[3883,4]]},"795":{"position":[[1320,4]]},"833":{"position":[[202,4],[339,4]]},"847":{"position":[[178,4]]},"853":{"position":[[1172,4],[2425,4]]},"866":{"position":[[591,4]]},"870":{"position":[[10,4],[1551,4],[1687,4]]},"877":{"position":[[96,4]]},"881":{"position":[[170,4]]},"934":{"position":[[2254,4]]},"945":{"position":[[811,4]]},"951":{"position":[[42,4],[376,4]]},"963":{"position":[[14,4]]},"977":{"position":[[654,4]]},"979":{"position":[[162,4]]},"984":{"position":[[29,4]]},"1109":{"position":[[1162,4]]},"1153":{"position":[[556,4]]},"1332":{"position":[[107,4]]},"1389":{"position":[[401,4]]},"1393":{"position":[[614,4]]},"1397":{"position":[[1100,4],[1447,4]]},"1427":{"position":[[1061,4]]},"1429":{"position":[[1782,4],[1871,4]]},"1468":{"position":[[1423,4]]},"1492":{"position":[[11,4]]},"1505":{"position":[[203,4]]}}}],["higher",{"_index":2357,"t":{"664":{"position":[[246,6]]},"797":{"position":[[2462,6]]},"891":{"position":[[439,6]]},"994":{"position":[[570,6]]}}}],["highest",{"_index":4398,"t":{"1352":{"position":[[933,7],[1287,7]]}}}],["highli",{"_index":3436,"t":{"945":{"position":[[961,6]]},"979":{"position":[[892,6]]}}}],["highlight",{"_index":5105,"t":{"1624":{"position":[[47,13]]},"1628":{"position":[[117,9],[383,10],[449,10]]},"1782":{"position":[[1916,11]]}}}],["hih_ihi",{"_index":3813,"t":{"1101":{"position":[[343,8],[445,8]]},"1296":{"position":[[669,8],[787,8]]},"1298":{"position":[[399,8]]},"1305":{"position":[[1061,8],[1157,8],[1339,8]]},"1720":{"position":[[882,9]]}}}],["hinh_\\text{in}hin",{"_index":4472,"t":{"1384":{"position":[[1563,18]]},"1389":{"position":[[2024,18],[2176,18]]}}}],["hinton",{"_index":1943,"t":{"531":{"position":[[325,6]]}}}],["hin∈rdhidden×l0h_\\text{in",{"_index":4467,"t":{"1384":{"position":[[1320,26]]}}}],["histori",{"_index":2002,"t":{"553":{"position":[[115,8]]},"1453":{"position":[[195,7]]}}}],["hi​])=mlp([lstm(h0:i",{"_index":3823,"t":{"1101":{"position":[[954,22]]}}}],["hi′h_i'hi",{"_index":3814,"t":{"1101":{"position":[[667,11]]}}}],["hi∈rdh_i",{"_index":4245,"t":{"1296":{"position":[[347,8]]}}}],["hk,i(teacher)h_{k,i}^{(teacher)}hk,i(teach",{"_index":4178,"t":{"1244":{"position":[[1624,46]]}}}],["hk,ih_{k,i}hk,i",{"_index":4179,"t":{"1244":{"position":[[1673,16]]}}}],["hk,i​−hk,i(teach",{"_index":4176,"t":{"1244":{"position":[[1597,20]]}}}],["hk,i−hk,i(teach",{"_index":4171,"t":{"1244":{"position":[[1405,18]]}}}],["hkh^khk",{"_index":2483,"t":{"688":{"position":[[627,7]]}}}],["holist",{"_index":5531,"t":{"1742":{"position":[[40,8],[97,8]]}}}],["home",{"_index":5376,"t":{"1680":{"position":[[271,4]]}}}],["honest",{"_index":4963,"t":{"1560":{"position":[[179,7],[316,6]]}}}],["hop",{"_index":1572,"t":{"412":{"position":[[51,3]]},"546":{"position":[[129,3]]}}}],["horribl",{"_index":5418,"t":{"1704":{"position":[[148,11]]}}}],["hotpotqa",{"_index":3573,"t":{"997":{"position":[[693,9]]},"1070":{"position":[[212,8]]},"1253":{"position":[[257,9]]},"1442":{"position":[[1816,8]]}}}],["houlsbi",{"_index":1831,"t":{"525":{"position":[[1016,8]]},"529":{"position":[[36,8]]},"681":{"position":[[568,8]]},"809":{"position":[[349,7]]},"823":{"position":[[189,7]]},"1369":{"position":[[524,8]]},"1379":{"position":[[996,8]]}}}],["hour",{"_index":1706,"t":{"475":{"position":[[97,4]]},"887":{"position":[[757,4]]}}}],["houth_{out}hout",{"_index":3538,"t":{"988":{"position":[[1546,16]]}}}],["howard",{"_index":2316,"t":{"658":{"position":[[1143,7]]},"676":{"position":[[667,7]]},"1126":{"position":[[314,7]]}}}],["hqh^qhq",{"_index":2482,"t":{"688":{"position":[[618,8]]}}}],["hth_tht",{"_index":1147,"t":{"285":{"position":[[145,8]]}}}],["html",{"_index":5051,"t":{"1597":{"position":[[99,5]]}}}],["http://boyangli.org/paper/jiaxian",{"_index":1592,"t":{"432":{"position":[[14,33]]}}}],["http://localhost:3000",{"_index":133,"t":{"19":{"position":[[339,23]]},"1600":{"position":[[84,23]]}}}],["http://localhost:3000/blog/greet",{"_index":5024,"t":{"1587":{"position":[[554,37]]}}}],["http://localhost:3000/doc",{"_index":5060,"t":{"1604":{"position":[[201,27]]}}}],["http://localhost:3000/docs/hello",{"_index":5038,"t":{"1593":{"position":[[140,33]]},"1608":{"position":[[110,32]]}}}],["http://localhost:3000/docs/next",{"_index":5061,"t":{"1604":{"position":[[265,32]]}}}],["http://localhost:3000/docs/next/hello",{"_index":5070,"t":{"1608":{"position":[[165,37]]}}}],["http://localhost:3000/fr",{"_index":5146,"t":{"1636":{"position":[[104,25]]}}}],["http://localhost:3000/mi",{"_index":5089,"t":{"1612":{"position":[[290,24]]},"1614":{"position":[[152,24]]}}}],["https://aclanthology.org/2021.acl",{"_index":4229,"t":{"1287":{"position":[[14,33]]}}}],["https://aclanthology.org/2022.acl",{"_index":1807,"t":{"519":{"position":[[14,33]]},"1375":{"position":[[14,33]]},"1405":{"position":[[14,33]]}}}],["https://aclanthology.org/2022.emnlp",{"_index":4770,"t":{"1464":{"position":[[14,35]]}}}],["https://aclanthology.org/2023.acl",{"_index":3078,"t":{"845":{"position":[[14,33]]}}}],["https://aclanthology.org/2023.eacl",{"_index":957,"t":{"211":{"position":[[14,34]]}}}],["https://aclanthology.org/2023.emnlp",{"_index":2239,"t":{"624":{"position":[[14,35]]},"679":{"position":[[14,35]]},"1343":{"position":[[14,35]]}}}],["https://arxiv.org/abs/2010.11929v2",{"_index":372,"t":{"82":{"position":[[14,34]]}}}],["https://arxiv.org/abs/2104.00298",{"_index":141,"t":{"21":{"position":[[14,32]]}}}],["https://arxiv.org/pdf/1706.03762.pdf",{"_index":1136,"t":{"281":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/1902.00751.pdf",{"_index":2303,"t":{"654":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2103.10385.pdf",{"_index":3746,"t":{"1089":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2104.08691.pdf",{"_index":3867,"t":{"1122":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2106.09685.pdf",{"_index":2567,"t":{"715":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2110.07602.pdf",{"_index":3609,"t":{"1010":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2203.02155.pdf",{"_index":4909,"t":{"1542":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2204.03649.pdf",{"_index":1381,"t":{"332":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2205.05638.pdf",{"_index":2047,"t":{"585":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2205.11961v2.pdf",{"_index":3462,"t":{"975":{"position":[[14,38]]}}}],["https://arxiv.org/pdf/2206.07669v2.pdf",{"_index":576,"t":{"122":{"position":[[14,38]]}}}],["https://arxiv.org/pdf/2210.11416.pdf",{"_index":1973,"t":{"535":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2303.02506.pdf",{"_index":1025,"t":{"217":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2303.02861.pdf",{"_index":4086,"t":{"1223":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2303.06674v1.pdf",{"_index":719,"t":{"161":{"position":[[14,38]]}}}],["https://arxiv.org/pdf/2303.10512.pdf",{"_index":2740,"t":{"782":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2303.11366v3.pdf",{"_index":4693,"t":{"1438":{"position":[[14,38]]}}}],["https://arxiv.org/pdf/2303.16199.pdf",{"_index":3280,"t":{"883":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2304.15010.pdf",{"_index":3415,"t":{"930":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2305.03937v1.pdf",{"_index":3985,"t":{"1155":{"position":[[13,38]]}}}],["https://arxiv.org/pdf/2305.07922v2.pdf",{"_index":1713,"t":{"481":{"position":[[14,38]]}}}],["https://arxiv.org/pdf/2309.05173v1.pdf",{"_index":3645,"t":{"1058":{"position":[[14,38]]}}}],["https://dl.acm.org/doi/pdf/10.1145/3560815",{"_index":5391,"t":{"1691":{"position":[[14,42]]}}}],["https://github.com/garyyufei/promda",{"_index":1024,"t":{"215":{"position":[[2684,35]]}}}],["https://github.com/joelmarcey",{"_index":5012,"t":{"1587":{"position":[[182,29]]}}}],["https://github.com/joelmarcey.png",{"_index":5014,"t":{"1587":{"position":[[223,33]]}}}],["https://github.com/salesforce/lavis/tree/main/projects/img2llm",{"_index":1606,"t":{"434":{"position":[[777,62]]}}}],["https://github.com/slorber.png",{"_index":5019,"t":{"1587":{"position":[[355,30]]}}}],["https://github.com/tonyhuang2022/upl",{"_index":1391,"t":{"334":{"position":[[698,36]]}}}],["https://github.com/whdnjsdyd111/pap",{"_index":370,"t":{"80":{"position":[[90,37]]}}}],["https://namecensus.com",{"_index":1580,"t":{"422":{"position":[[92,25]]}}}],["https://openai.com/blog/chatgpt",{"_index":4910,"t":{"1542":{"position":[[51,31]]}}}],["https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4",{"_index":1515,"t":{"380":{"position":[[14,91]]}}}],["https://sebastienlorber.com",{"_index":5018,"t":{"1587":{"position":[[316,27]]}}}],["https://www.sciencedirect.com/science/article/pii/s2666651022000183",{"_index":5151,"t":{"1642":{"position":[[13,67]]}}}],["ht−1h_{t",{"_index":1148,"t":{"285":{"position":[[159,8]]}}}],["hu",{"_index":395,"t":{"88":{"position":[[445,2]]},"809":{"position":[[817,4]]},"1379":{"position":[[1058,3]]}}}],["huang",{"_index":4359,"t":{"1347":{"position":[[578,6]]},"1367":{"position":[[502,6]]}}}],["hub",{"_index":2393,"t":{"670":{"position":[[953,3]]}}}],["hug",{"_index":4319,"t":{"1314":{"position":[[155,7]]}}}],["huge",{"_index":514,"t":{"104":{"position":[[23,4]]},"182":{"position":[[50,4]]}}}],["huggigfac",{"_index":3011,"t":{"807":{"position":[[48,10]]}}}],["huggingfac",{"_index":1897,"t":{"529":{"position":[[148,11]]},"759":{"position":[[33,11]]},"1082":{"position":[[57,11]]},"1314":{"position":[[96,11]]},"1357":{"position":[[223,11]]}}}],["human",{"_index":596,"t":{"126":{"position":[[927,5]]},"569":{"position":[[914,5],[962,5],[987,5]]},"579":{"position":[[141,5]]},"587":{"position":[[757,5]]},"589":{"position":[[689,5],[2235,5]]},"622":{"position":[[408,5]]},"1542":{"position":[[144,5]]},"1544":{"position":[[223,5]]},"1546":{"position":[[285,5]]},"1573":{"position":[[33,5]]},"1579":{"position":[[309,5]]},"1646":{"position":[[2955,5]]},"1651":{"position":[[12,5]]},"1669":{"position":[[151,5],[325,5],[928,5],[1097,5]]},"1680":{"position":[[265,5]]}}}],["humanev",{"_index":4705,"t":{"1440":{"position":[[586,9]]},"1442":{"position":[[1852,9]]}}}],["huomenta",{"_index":5410,"t":{"1698":{"position":[[536,9]]}}}],["huph_{up}hup",{"_index":3535,"t":{"988":{"position":[[1388,13],[1446,13]]}}}],["hutter",{"_index":1804,"t":{"517":{"position":[[1042,7]]}}}],["hvh^vhv",{"_index":2484,"t":{"688":{"position":[[637,7]]}}}],["hw/p^2n=hw/p2",{"_index":419,"t":{"91":{"position":[[373,13]]}}}],["hwu64",{"_index":5375,"t":{"1680":{"position":[[198,5]]}}}],["hybrid",{"_index":477,"t":{"95":{"position":[[68,6]]},"99":{"position":[[13,6]]},"104":{"position":[[363,6]]},"114":{"position":[[20,6],[390,6]]},"1093":{"position":[[325,6]]},"1389":{"position":[[350,6],[2437,6]]},"1397":{"position":[[160,6]]},"1720":{"position":[[1926,6]]}}}],["hyp",{"_index":3829,"t":{"1101":{"position":[[1408,7]]}}}],["hyper",{"_index":3666,"t":{"1065":{"position":[[441,5]]},"1070":{"position":[[907,5]]},"1087":{"position":[[148,5]]},"1157":{"position":[[110,5]]},"1473":{"position":[[529,5]]},"1788":{"position":[[582,5]]}}}],["hypercomplex",{"_index":2185,"t":{"598":{"position":[[3302,12]]}}}],["hyperdecod",{"_index":3585,"t":{"999":{"position":[[330,12]]},"1002":{"position":[[276,12]]},"1070":{"position":[[657,12]]}}}],["hyperform",{"_index":3584,"t":{"999":{"position":[[317,12]]},"1002":{"position":[[261,11]]},"1004":{"position":[[194,12]]},"1070":{"position":[[645,11]]},"1084":{"position":[[542,11]]}}}],["hypernetwork",{"_index":4778,"t":{"1473":{"position":[[553,12]]}}}],["hyperparamet",{"_index":1994,"t":{"550":{"position":[[126,14]]},"589":{"position":[[1663,14]]},"592":{"position":[[309,14]]},"596":{"position":[[2415,14],[2533,14]]},"598":{"position":[[4045,14]]},"602":{"position":[[359,14],[679,14]]},"604":{"position":[[117,14]]},"666":{"position":[[393,14]]},"668":{"position":[[103,14],[400,14]]},"670":{"position":[[840,14]]},"709":{"position":[[1100,14]]},"733":{"position":[[1117,14]]},"861":{"position":[[937,14]]},"866":{"position":[[400,14]]},"912":{"position":[[177,14]]},"921":{"position":[[77,14]]},"1002":{"position":[[744,15]]},"1052":{"position":[[174,14]]},"1087":{"position":[[228,14]]},"1111":{"position":[[363,14],[660,14],[1252,14],[1613,14]]},"1115":{"position":[[804,14]]},"1136":{"position":[[48,14]]},"1141":{"position":[[27,14]]},"1159":{"position":[[1022,14]]},"1164":{"position":[[528,14]]},"1238":{"position":[[746,15]]},"1273":{"position":[[3,14]]},"1314":{"position":[[214,14]]},"1384":{"position":[[3822,14]]},"1393":{"position":[[943,14]]},"1395":{"position":[[358,14]]},"1665":{"position":[[1203,14]]},"1754":{"position":[[366,14]]}}}],["hyperprompt",{"_index":4093,"t":{"1230":{"position":[[288,11]]},"1473":{"position":[[515,11]]}}}],["hypothesi",{"_index":1959,"t":{"531":{"position":[[687,10]]},"849":{"position":[[825,10]]},"851":{"position":[[925,10]]},"879":{"position":[[383,10]]},"1466":{"position":[[347,10]]},"1468":{"position":[[489,10]]},"1475":{"position":[[15,10]]},"1477":{"position":[[1146,10]]}}}],["hypter",{"_index":1468,"t":{"358":{"position":[[220,6]]}}}],["hyv",{"_index":5409,"t":{"1698":{"position":[[529,6]]}}}],["h←i])=mlp([lstm(h0:i",{"_index":3816,"t":{"1101":{"position":[[705,21]]}}}],["h≤i)=softmax(wϕhi(n))p_{\\phi}(z_{i+1",{"_index":4258,"t":{"1296":{"position":[[833,38]]}}}],["h≤i​)=softmax(wϕ​hi(n",{"_index":4262,"t":{"1296":{"position":[[935,24]]}}}],["i(t)i^{(t)}i(t",{"_index":2992,"t":{"801":{"position":[[2222,15]]}}}],["i(w_{ij",{"_index":2968,"t":{"801":{"position":[[1038,9]]}}}],["i(wij)=∣wij▽wijl∣,\\begin{equ",{"_index":2967,"t":{"801":{"position":[[1003,34]]}}}],["i(x),z<t)p(z_t|x,z_{<t",{"_index":5516,"t":{"1736":{"position":[[1398,24]]}}}],["i(x)f_{\\textup{prompt",{"_index":5522,"t":{"1736":{"position":[[1579,22]]}}}],["i,:])pθ​[i:0]=mlpθ​(pθ′​[i",{"_index":4315,"t":{"1307":{"position":[[260,31]]}}}],["i,j)th(i",{"_index":2152,"t":{"598":{"position":[[1059,10]]}}}],["i.",{"_index":1567,"t":{"405":{"position":[[28,5]]},"563":{"position":[[324,5]]},"594":{"position":[[330,5]]},"598":{"position":[[776,5]]},"786":{"position":[[2953,4]]},"791":{"position":[[866,5]]},"795":{"position":[[1533,5]]},"797":{"position":[[246,4]]},"799":{"position":[[47,4]]},"803":{"position":[[111,5]]},"809":{"position":[[893,5]]},"979":{"position":[[1590,5]]},"1062":{"position":[[828,5]]},"1067":{"position":[[1190,5]]},"1246":{"position":[[683,4]]},"1330":{"position":[[174,5]]},"1384":{"position":[[1267,5]]},"1387":{"position":[[114,5]]},"1401":{"position":[[255,5],[330,5]]},"1468":{"position":[[1197,5]]}}}],["i18n",{"_index":4984,"t":{"1581":{"position":[[180,5]]},"1632":{"position":[[102,5]]}}}],["i18n/fr",{"_index":5140,"t":{"1634":{"position":[[35,7]]}}}],["i18n/fr/docusauru",{"_index":5142,"t":{"1634":{"position":[[60,18],[125,18],[191,18]]}}}],["i:0",{"_index":4312,"t":{"1307":{"position":[[223,5]]}}}],["i\\gamma_iγi",{"_index":4790,"t":{"1485":{"position":[[107,13]]}}}],["i\\zeta_iζi",{"_index":4817,"t":{"1487":{"position":[[554,12]]}}}],["i^{(t)}(w_{ij",{"_index":2986,"t":{"801":{"position":[[1884,15]]}}}],["i_m",{"_index":3371,"t":{"895":{"position":[[262,3],[535,3]]}}}],["i_p",{"_index":3377,"t":{"895":{"position":[[485,3]]}}}],["i_{p_i",{"_index":4804,"t":{"1485":{"position":[[623,7]]}}}],["i_{q_i",{"_index":4831,"t":{"1487":{"position":[[923,7]]}}}],["ia)3",{"_index":2228,"t":{"614":{"position":[[470,5]]}}}],["ia)3(ia)^3(ia)3",{"_index":2054,"t":{"587":{"position":[[532,16]]},"589":{"position":[[2028,16],[2048,16]]},"598":{"position":[[2356,16],[2453,16],[2615,16],[2753,16],[2927,16],[2988,16],[3757,16],[3875,16]]},"600":{"position":[[262,16],[404,16]]},"602":{"position":[[77,16],[142,16]]},"614":{"position":[[29,16],[347,16]]},"622":{"position":[[128,16]]}}}],["iamg",{"_index":1408,"t":{"339":{"position":[[11,5]]}}}],["icl",{"_index":2048,"t":{"587":{"position":[[29,6],[169,3],[401,3]]},"589":{"position":[[529,5],[539,3],[738,3],[819,3],[870,3],[885,3],[975,3],[1081,3],[1480,3],[2149,3]]},"592":{"position":[[96,3]]},"598":{"position":[[9,3],[154,3]]},"604":{"position":[[66,3]]},"606":{"position":[[124,3],[170,3],[245,3],[318,3],[420,3]]},"608":{"position":[[8,3],[944,3],[1035,3]]},"610":{"position":[[21,3],[214,3],[410,3],[473,3]]},"612":{"position":[[258,3],[372,3]]},"614":{"position":[[126,3]]},"622":{"position":[[103,3],[494,3]]}}}],["id",{"_index":945,"t":{"193":{"position":[[176,5]]},"195":{"position":[[55,2]]},"992":{"position":[[187,2],[222,2]]},"1618":{"position":[[79,3],[90,2]]}}}],["idea",{"_index":3809,"t":{"1101":{"position":[[30,4]]}}}],["ideal",{"_index":3949,"t":{"1143":{"position":[[641,5]]}}}],["ident",{"_index":941,"t":{"193":{"position":[[131,8],[158,8]]},"234":{"position":[[312,8]]},"358":{"position":[[562,9]]},"660":{"position":[[854,8],[934,8],[1147,8]]},"662":{"position":[[1276,8]]},"1195":{"position":[[519,8]]},"1728":{"position":[[203,8]]}}}],["idf1",{"_index":943,"t":{"193":{"position":[[149,6]]}}}],["ie\\triangle^e_i△i",{"_index":3956,"t":{"1145":{"position":[[1704,20]]}}}],["ii",{"_index":1821,"t":{"525":{"position":[[511,4],[1325,5]]},"527":{"position":[[192,4]]},"1589":{"position":[[51,2]]}}}],["iii",{"_index":1185,"t":{"294":{"position":[[388,3],[401,3]]},"308":{"position":[[623,3]]},"350":{"position":[[378,3]]},"525":{"position":[[553,5],[1361,5]]},"527":{"position":[[265,5]]},"774":{"position":[[269,3],[755,3],[894,3]]},"789":{"position":[[732,3]]},"791":{"position":[[597,3],[631,3],[712,3]]},"795":{"position":[[557,3]]},"797":{"position":[[501,3]]},"1244":{"position":[[1738,3]]},"1296":{"position":[[309,3],[536,3]]},"1589":{"position":[[162,3],[247,3]]},"1720":{"position":[[825,3]]}}}],["iiit",{"_index":499,"t":{"102":{"position":[[197,4]]}}}],["iiith",{"_index":5511,"t":{"1736":{"position":[[478,5]]}}}],["ik",{"_index":259,"t":{"49":{"position":[[318,5]]}}}],["ilsvrc",{"_index":488,"t":{"102":{"position":[[14,6]]}}}],["ilsvrc2012",{"_index":283,"t":{"53":{"position":[[46,10]]},"58":{"position":[[108,10]]},"63":{"position":[[9,10]]}}}],["imag",{"_index":57,"t":{"7":{"position":[[344,7]]},"27":{"position":[[394,5]]},"78":{"position":[[44,5],[87,5],[294,5],[353,5],[516,5],[611,5]]},"95":{"position":[[5,5]]},"102":{"position":[[44,7],[70,7],[108,7]]},"116":{"position":[[665,5]]},"120":{"position":[[14,5]]},"124":{"position":[[337,5]]},"126":{"position":[[259,5],[479,5],[953,5]]},"128":{"position":[[195,5]]},"130":{"position":[[123,5],[168,5]]},"132":{"position":[[8,5],[68,5],[134,5],[314,5],[911,5]]},"134":{"position":[[9,5]]},"136":{"position":[[24,5],[129,5]]},"138":{"position":[[62,5],[98,5],[263,5]]},"151":{"position":[[41,5]]},"153":{"position":[[582,5]]},"155":{"position":[[821,5],[931,5]]},"157":{"position":[[102,5]]},"159":{"position":[[397,5]]},"163":{"position":[[592,5]]},"168":{"position":[[566,5]]},"172":{"position":[[134,5]]},"177":{"position":[[454,5],[512,5],[1114,5],[1158,5]]},"185":{"position":[[27,7],[57,7]]},"221":{"position":[[92,5],[828,5],[846,5]]},"225":{"position":[[78,5]]},"230":{"position":[[346,6]]},"236":{"position":[[496,5]]},"242":{"position":[[101,5],[160,5]]},"246":{"position":[[0,5],[81,5],[178,5]]},"251":{"position":[[65,5]]},"271":{"position":[[56,5],[79,5]]},"334":{"position":[[229,5]]},"336":{"position":[[49,5],[80,5],[471,5],[858,5],[972,5],[1902,5]]},"339":{"position":[[118,5],[290,5],[449,5]]},"341":{"position":[[282,5]]},"343":{"position":[[180,5],[339,5],[587,7]]},"345":{"position":[[140,5]]},"347":{"position":[[165,5]]},"350":{"position":[[395,5]]},"352":{"position":[[247,5]]},"358":{"position":[[671,5],[687,5],[1180,5],[1424,5]]},"360":{"position":[[163,5],[187,5],[238,5]]},"374":{"position":[[6,5]]},"436":{"position":[[760,5],[1129,5],[1596,5],[1873,5],[1890,5]]},"439":{"position":[[83,5]]},"445":{"position":[[187,5]]},"447":{"position":[[627,5],[675,5],[701,5]]},"449":{"position":[[4,5]]},"453":{"position":[[134,7],[192,7]]},"455":{"position":[[30,5]]},"457":{"position":[[44,5],[500,5],[574,5],[734,5],[989,5]]},"466":{"position":[[62,5],[121,5]]},"479":{"position":[[0,5]]},"887":{"position":[[1009,5],[1052,5]]},"895":{"position":[[166,5],[712,5],[1044,5]]},"912":{"position":[[23,5]]},"924":{"position":[[0,5]]},"932":{"position":[[419,5],[529,5],[599,5],[772,5]]},"934":{"position":[[824,6],[982,5],[1166,5],[1499,5],[1640,5],[2122,5],[2350,5]]},"940":{"position":[[27,5]]},"949":{"position":[[127,5],[233,5],[370,5],[619,5]]},"951":{"position":[[93,5],[209,5],[414,5]]},"955":{"position":[[52,5],[103,5],[170,5],[230,5],[478,5],[677,5]]},"965":{"position":[[223,5]]},"967":{"position":[[129,5],[186,5],[308,6],[415,5],[519,5],[704,5]]},"969":{"position":[[15,5],[184,5],[260,5]]},"971":{"position":[[152,5],[248,5]]},"973":{"position":[[100,5],[252,5]]},"1070":{"position":[[331,5]]},"1622":{"position":[[17,6],[79,6],[197,6],[282,6]]},"1720":{"position":[[1386,5]]},"1780":{"position":[[174,5]]},"1782":{"position":[[2837,6]]}}}],["image/text",{"_index":1098,"t":{"242":{"position":[[177,10]]}}}],["image_url",{"_index":5013,"t":{"1587":{"position":[[212,10],[344,10]]}}}],["imagenet",{"_index":180,"t":{"25":{"position":[[675,8]]},"53":{"position":[[37,8]]},"58":{"position":[[99,8]]},"63":{"position":[[0,8],[91,8]]},"86":{"position":[[306,16]]},"88":{"position":[[544,8],[558,8]]},"102":{"position":[[26,8],[52,8],[154,8],[163,8]]},"112":{"position":[[3,9],[13,8]]},"118":{"position":[[142,8]]},"253":{"position":[[12,8]]},"334":{"position":[[601,8]]},"368":{"position":[[8,8],[196,8]]},"374":{"position":[[35,8]]},"924":{"position":[[26,8]]}}}],["imagenet21k",{"_index":311,"t":{"58":{"position":[[0,11]]}}}],["imageri",{"_index":509,"t":{"102":{"position":[[329,7]]}}}],["img2llm",{"_index":1599,"t":{"434":{"position":[[266,7],[475,7]]},"436":{"position":[[1257,7],[1378,7],[1748,7],[1932,7],[2044,7],[2198,7]]},"447":{"position":[[608,7],[849,7]]},"471":{"position":[[0,7]]},"475":{"position":[[0,7],[176,7],[215,7]]},"477":{"position":[[0,7],[76,7]]}}}],["img2llm.pdf",{"_index":1595,"t":{"432":{"position":[[58,11]]}}}],["immedi",{"_index":86,"t":{"13":{"position":[[54,11]]}}}],["imort",{"_index":4827,"t":{"1487":{"position":[[783,9]]}}}],["impact",{"_index":2556,"t":{"709":{"position":[[548,6],[1017,6],[1600,6]]},"1087":{"position":[[137,7]]},"1477":{"position":[[1109,7]]}}}],["implement",{"_index":369,"t":{"80":{"position":[[65,11]]},"786":{"position":[[1347,14],[2322,9]]},"999":{"position":[[359,14]]},"1070":{"position":[[760,14]]},"1393":{"position":[[775,14]]}}}],["import",{"_index":2268,"t":{"630":{"position":[[1388,10]]},"703":{"position":[[208,9]]},"709":{"position":[[2437,9]]},"784":{"position":[[478,10]]},"786":{"position":[[1158,9],[2887,9],[2998,9],[3167,10]]},"789":{"position":[[770,9]]},"793":{"position":[[102,10],[144,10]]},"797":{"position":[[160,10],[538,10],[1607,10],[2339,10],[2427,9],[2522,10]]},"801":{"position":[[0,10],[131,10],[428,10],[770,10],[910,10],[1339,10],[2321,10],[2629,10]]},"837":{"position":[[11,10],[105,10],[244,10]]},"841":{"position":[[268,10]]},"843":{"position":[[54,10],[216,10]]},"853":{"position":[[564,10],[1056,10],[1257,10],[1397,10],[2378,10]]},"855":{"position":[[135,10]]},"857":{"position":[[263,10],[326,10],[1374,10],[1509,10]]},"861":{"position":[[510,10],[1244,10]]},"877":{"position":[[461,9]]},"1084":{"position":[[941,10]]},"1389":{"position":[[1376,10]]},"1485":{"position":[[413,10],[433,10],[538,10],[851,10],[1111,10]]},"1487":{"position":[[845,10],[1065,10]]},"1505":{"position":[[267,10],[359,10]]},"1521":{"position":[[56,10],[102,10],[152,10]]},"1525":{"position":[[33,10],[117,10]]},"1612":{"position":[[72,6],[99,6]]}}}],["importr",{"_index":2276,"t":{"630":{"position":[[1665,11]]}}}],["improv",{"_index":358,"t":{"78":{"position":[[393,8]]},"1002":{"position":[[614,8]]},"1423":{"position":[[19,8]]},"1442":{"position":[[1665,11]]},"1445":{"position":[[160,11]]}}}],["impur",{"_index":4769,"t":{"1462":{"position":[[394,6]]}}}],["im}m=1m",{"_index":3370,"t":{"895":{"position":[[251,10]]}}}],["im∈r1×ci_m",{"_index":3373,"t":{"895":{"position":[[287,10]]}}}],["includ",{"_index":521,"t":{"106":{"position":[[12,7]]},"1640":{"position":[[90,7]]}}}],["incorpor",{"_index":3416,"t":{"932":{"position":[[402,13]]},"1440":{"position":[[699,13]]}}}],["incorrect",{"_index":2065,"t":{"589":{"position":[[1087,9]]},"596":{"position":[[752,9],[803,9],[959,9],[1064,9]]},"602":{"position":[[244,9]]},"622":{"position":[[275,9]]}}}],["increas",{"_index":356,"t":{"78":{"position":[[344,8],[602,8]]}}}],["increment",{"_index":2741,"t":{"784":{"position":[[237,11],[326,11],[589,11]]},"786":{"position":[[857,11],[974,11],[2370,11],[3398,11],[3457,11]]},"791":{"position":[[54,11]]},"793":{"position":[[43,11]]},"795":{"position":[[30,11],[1337,11],[2015,11]]},"797":{"position":[[220,11],[2478,11]]},"803":{"position":[[77,11],[396,11]]},"809":{"position":[[685,11]]},"841":{"position":[[52,11]]},"843":{"position":[[135,11],[283,11]]}}}],["independ",{"_index":1157,"t":{"287":{"position":[[507,11]]},"1657":{"position":[[2517,11]]}}}],["index",{"_index":4265,"t":{"1298":{"position":[[223,8]]},"1352":{"position":[[1322,5]]},"1585":{"position":[[62,5]]}}}],["indic",{"_index":4243,"t":{"1296":{"position":[[236,7]]},"1305":{"position":[[293,7],[407,7]]}}}],["induct",{"_index":379,"t":{"86":{"position":[[392,9],[529,9],[544,9],[641,9],[727,9],[798,9]]},"93":{"position":[[97,9]]},"97":{"position":[[460,9]]},"112":{"position":[[90,9],[493,9]]},"120":{"position":[[29,9]]},"428":{"position":[[86,9]]},"531":{"position":[[832,9]]},"1695":{"position":[[302,9]]}}}],["ineffici",{"_index":2444,"t":{"681":{"position":[[190,11]]},"1468":{"position":[[151,11]]},"1471":{"position":[[234,11]]}}}],["infer",{"_index":191,"t":{"27":{"position":[[109,9],[170,9],[459,9]]},"326":{"position":[[729,9]]},"347":{"position":[[587,9]]},"350":{"position":[[11,9]]},"362":{"position":[[187,9]]},"368":{"position":[[50,9]]},"531":{"position":[[251,9]]},"533":{"position":[[321,9]]},"546":{"position":[[161,9]]},"589":{"position":[[2259,9]]},"592":{"position":[[156,9]]},"594":{"position":[[827,9]]},"602":{"position":[[511,9]]},"608":{"position":[[467,9]]},"610":{"position":[[38,9]]},"616":{"position":[[0,9],[59,9]]},"622":{"position":[[506,9]]},"628":{"position":[[1324,9]]},"630":{"position":[[156,9],[2194,10],[2316,9]]},"644":{"position":[[413,9],[489,9]]},"717":{"position":[[392,9]]},"719":{"position":[[1234,9]]},"737":{"position":[[85,9]]},"780":{"position":[[59,9]]},"812":{"position":[[175,9]]},"932":{"position":[[675,9]]},"971":{"position":[[29,9]]},"982":{"position":[[1141,9]]},"992":{"position":[[643,10],[1025,9],[1161,9]]},"1014":{"position":[[230,9]]},"1062":{"position":[[960,9],[1627,9]]},"1082":{"position":[[34,9],[106,9]]},"1087":{"position":[[318,9]]},"1101":{"position":[[1094,9]]},"1130":{"position":[[406,10]]},"1149":{"position":[[153,9],[362,9]]},"1178":{"position":[[471,9]]},"1341":{"position":[[235,9]]},"1345":{"position":[[197,9],[498,9]]},"1347":{"position":[[784,9],[965,9],[1608,9],[1750,9]]},"1357":{"position":[[661,9]]},"1360":{"position":[[131,9],[309,9],[371,9]]},"1371":{"position":[[39,9],[188,9]]},"1399":{"position":[[423,9],[553,9],[620,9],[776,9]]},"1419":{"position":[[664,9]]},"1453":{"position":[[57,9]]},"1644":{"position":[[163,9]]},"1646":{"position":[[1273,9]]},"1651":{"position":[[18,10]]},"1655":{"position":[[1274,9]]},"1657":{"position":[[1928,9]]},"1669":{"position":[[264,9],[366,9]]},"1714":{"position":[[369,10]]}}}],["infin",{"_index":1245,"t":{"302":{"position":[[792,8]]}}}],["infix",{"_index":2660,"t":{"751":{"position":[[83,10],[236,5]]},"1330":{"position":[[235,5],[271,5],[380,5]]}}}],["inflex",{"_index":1714,"t":{"483":{"position":[[126,13]]}}}],["inform",{"_index":1242,"t":{"302":{"position":[[645,11]]},"598":{"position":[[3437,11]]},"628":{"position":[[233,11]]},"630":{"position":[[1105,11],[1186,11]]},"648":{"position":[[362,11]]},"696":{"position":[[1029,11]]},"786":{"position":[[3527,11]]},"847":{"position":[[263,11]]},"849":{"position":[[449,11],[706,11]]},"851":{"position":[[851,11]]},"853":{"position":[[547,11]]},"895":{"position":[[1070,11]]},"969":{"position":[[103,11]]},"1128":{"position":[[452,11]]},"1230":{"position":[[316,11]]},"1236":{"position":[[761,11]]},"1485":{"position":[[1020,11],[1077,11]]},"1523":{"position":[[289,11]]},"1653":{"position":[[46,11],[154,11],[939,11]]},"1665":{"position":[[844,11]]},"1676":{"position":[[334,11],[411,11],[569,11]]},"1788":{"position":[[118,11],[327,11]]}}}],["infus",{"_index":2178,"t":{"598":{"position":[[2381,8]]}}}],["inhibit",{"_index":2179,"t":{"598":{"position":[[2401,10]]}}}],["init",{"_index":106,"t":{"17":{"position":[[155,4]]},"919":{"position":[[117,4],[239,4]]}}}],["initi",{"_index":565,"t":{"116":{"position":[[311,7]]},"215":{"position":[[1419,14]]},"529":{"position":[[1331,7]]},"531":{"position":[[1399,11]]},"630":{"position":[[1147,7]]},"658":{"position":[[2049,7]]},"660":{"position":[[559,10],[863,14]]},"676":{"position":[[869,14],[990,14],[1124,14]]},"791":{"position":[[498,14]]},"803":{"position":[[287,7]]},"849":{"position":[[1382,14]]},"853":{"position":[[2104,7]]},"875":{"position":[[23,14]]},"885":{"position":[[341,11],[648,11]]},"887":{"position":[[528,11],[779,11],[1215,11]]},"893":{"position":[[179,11],[2431,11]]},"897":{"position":[[5,11]]},"899":{"position":[[126,11]]},"901":{"position":[[36,11],[83,11]]},"907":{"position":[[159,11]]},"919":{"position":[[5,11],[67,11],[195,11]]},"926":{"position":[[81,11]]},"928":{"position":[[111,11]]},"934":{"position":[[210,11]]},"938":{"position":[[275,11]]},"945":{"position":[[21,11]]},"949":{"position":[[433,11]]},"953":{"position":[[543,11]]},"999":{"position":[[1058,15]]},"1037":{"position":[[148,11]]},"1111":{"position":[[1076,7]]},"1130":{"position":[[24,10],[55,14],[147,14],[269,14]]},"1141":{"position":[[56,14],[93,14],[181,12],[325,14],[627,14],[668,14],[712,14],[771,14]]},"1149":{"position":[[32,14]]},"1157":{"position":[[515,14]]},"1159":{"position":[[1846,15]]},"1201":{"position":[[127,14],[323,14]]},"1212":{"position":[[287,16]]},"1332":{"position":[[26,14],[73,14],[292,14],[336,14],[378,14]]},"1334":{"position":[[29,14],[249,14],[357,14]]},"1513":{"position":[[67,14],[206,14],[300,14],[447,14]]},"1523":{"position":[[324,14]]},"1581":{"position":[[76,7]]},"1720":{"position":[[1424,11]]}}}],["inject",{"_index":3284,"t":{"885":{"position":[[422,7]]},"1659":{"position":[[10,9]]}}}],["inner",{"_index":1254,"t":{"304":{"position":[[512,5]]},"598":{"position":[[2427,5]]},"622":{"position":[[181,5]]}}}],["inport",{"_index":2777,"t":{"786":{"position":[[3559,10]]}}}],["input",{"_index":420,"t":{"91":{"position":[[419,5]]},"104":{"position":[[74,5],[121,5]]},"128":{"position":[[33,5]]},"130":{"position":[[320,5]]},"132":{"position":[[14,5],[905,5]]},"163":{"position":[[343,5]]},"165":{"position":[[1381,5]]},"174":{"position":[[72,5],[264,5],[556,5],[677,5]]},"215":{"position":[[1041,5],[1970,8]]},"225":{"position":[[66,5]]},"232":{"position":[[164,5]]},"234":{"position":[[143,5],[242,5]]},"246":{"position":[[131,5]]},"267":{"position":[[158,5]]},"285":{"position":[[76,5],[193,5],[282,5],[422,5]]},"287":{"position":[[74,5],[786,5]]},"289":{"position":[[97,5]]},"298":{"position":[[66,5]]},"302":{"position":[[204,5]]},"304":{"position":[[447,5]]},"306":{"position":[[39,5]]},"310":{"position":[[653,5],[804,5],[1175,5],[1346,5]]},"319":{"position":[[86,5]]},"322":{"position":[[606,5]]},"326":{"position":[[155,5]]},"384":{"position":[[475,5],[614,5],[729,7]]},"393":{"position":[[12,5]]},"441":{"position":[[133,5]]},"455":{"position":[[175,5]]},"459":{"position":[[588,5]]},"492":{"position":[[8,5]]},"498":{"position":[[332,5],[414,5],[427,5]]},"500":{"position":[[422,5],[520,5]]},"502":{"position":[[159,5],[181,5],[280,5],[316,5]]},"510":{"position":[[16,5]]},"525":{"position":[[69,5]]},"550":{"position":[[272,5]]},"569":{"position":[[272,5],[832,5]]},"587":{"position":[[70,5]]},"589":{"position":[[568,9],[629,5],[933,5]]},"596":{"position":[[232,5]]},"598":{"position":[[3370,5]]},"608":{"position":[[839,5]]},"610":{"position":[[86,5]]},"662":{"position":[[415,5],[630,5]]},"679":{"position":[[259,5]]},"681":{"position":[[856,5],[1162,5],[1343,5],[1655,5],[1823,5],[1892,5]]},"683":{"position":[[900,5],[1041,5]]},"686":{"position":[[157,5],[221,5],[354,5]]},"688":{"position":[[40,5],[128,5],[1135,5]]},"690":{"position":[[436,5],[565,5],[793,5],[871,5],[919,5]]},"692":{"position":[[143,5],[197,5]]},"694":{"position":[[27,5],[150,5],[274,5],[441,5]]},"696":{"position":[[0,5],[235,5],[880,5]]},"703":{"position":[[109,5],[123,5]]},"705":{"position":[[176,6],[230,5]]},"707":{"position":[[204,5],[545,5]]},"709":{"position":[[680,5],[828,5],[905,5],[1851,5],[2366,5],[2479,5]]},"711":{"position":[[59,5]]},"721":{"position":[[63,5]]},"725":{"position":[[41,5]]},"733":{"position":[[672,5]]},"735":{"position":[[134,5]]},"751":{"position":[[0,5]]},"786":{"position":[[658,5]]},"789":{"position":[[137,5]]},"809":{"position":[[586,6]]},"853":{"position":[[201,5]]},"887":{"position":[[414,5],[1015,5]]},"891":{"position":[[635,5]]},"893":{"position":[[400,5]]},"895":{"position":[[52,5],[160,5],[1139,5]]},"912":{"position":[[17,5]]},"932":{"position":[[33,5]]},"940":{"position":[[308,5]]},"947":{"position":[[255,5],[286,5]]},"953":{"position":[[148,5],[486,5]]},"955":{"position":[[472,5]]},"967":{"position":[[75,5]]},"982":{"position":[[526,5],[780,5],[796,5]]},"984":{"position":[[221,5],[410,5]]},"986":{"position":[[341,5]]},"988":{"position":[[10,5],[141,5],[276,5]]},"992":{"position":[[875,5]]},"1006":{"position":[[2825,5]]},"1008":{"position":[[364,5]]},"1014":{"position":[[787,5],[1240,5]]},"1019":{"position":[[197,5],[246,5],[625,5]]},"1026":{"position":[[129,5]]},"1028":{"position":[[57,5],[181,5]]},"1060":{"position":[[71,5],[328,5],[537,5],[623,5],[731,5]]},"1062":{"position":[[289,5],[754,5],[1547,5]]},"1065":{"position":[[191,5],[537,5]]},"1067":{"position":[[1175,5]]},"1097":{"position":[[34,5],[81,5]]},"1099":{"position":[[48,5],[210,5]]},"1101":{"position":[[650,5]]},"1126":{"position":[[789,5],[1367,5],[1550,5]]},"1128":{"position":[[67,5],[497,5],[1761,5]]},"1130":{"position":[[207,5]]},"1132":{"position":[[112,5],[372,5],[868,5],[1506,5]]},"1134":{"position":[[290,5]]},"1143":{"position":[[875,5]]},"1145":{"position":[[420,5],[502,5],[986,5],[1171,5],[1306,5],[1345,5],[1656,5],[2451,5],[2546,5],[2579,5]]},"1147":{"position":[[97,5]]},"1159":{"position":[[811,5],[1432,5]]},"1162":{"position":[[107,5]]},"1164":{"position":[[113,5]]},"1167":{"position":[[1247,5]]},"1178":{"position":[[153,5],[271,5],[562,5]]},"1185":{"position":[[305,5]]},"1187":{"position":[[162,5],[238,5],[326,5]]},"1230":{"position":[[143,5]]},"1238":{"position":[[485,5],[541,5],[764,5],[962,5]]},"1244":{"position":[[1745,5]]},"1291":{"position":[[775,5],[988,5],[1134,5]]},"1294":{"position":[[0,5]]},"1303":{"position":[[302,5],[336,5]]},"1319":{"position":[[306,5]]},"1345":{"position":[[127,6]]},"1347":{"position":[[78,5],[378,5],[634,5],[756,5],[1376,5]]},"1352":{"position":[[80,5],[293,5],[583,5],[635,5],[925,5]]},"1354":{"position":[[138,5]]},"1360":{"position":[[346,5]]},"1367":{"position":[[207,5]]},"1384":{"position":[[1151,5],[1312,5]]},"1389":{"position":[[1249,5],[1445,5],[2018,5],[2197,5]]},"1401":{"position":[[477,5],[633,5]]},"1421":{"position":[[110,5]]},"1462":{"position":[[476,5]]},"1468":{"position":[[208,5]]},"1473":{"position":[[16,5]]},"1477":{"position":[[119,5],[196,5],[643,5]]},"1481":{"position":[[0,5]]},"1494":{"position":[[638,5]]},"1496":{"position":[[133,5]]},"1536":{"position":[[4,7],[26,7],[230,7],[359,7],[453,5]]},"1552":{"position":[[541,5]]},"1646":{"position":[[854,5]]},"1651":{"position":[[526,5]]},"1659":{"position":[[479,5]]},"1665":{"position":[[351,5],[652,5]]},"1693":{"position":[[70,5],[174,5]]},"1698":{"position":[[31,5],[187,5],[350,5],[517,5]]},"1702":{"position":[[0,5],[174,5],[189,5],[244,5]]},"1712":{"position":[[311,5],[358,5]]},"1718":{"position":[[55,5],[459,5],[858,5],[954,5],[1141,5]]},"1720":{"position":[[324,5],[1088,5],[1380,5],[1702,5],[2080,5]]},"1728":{"position":[[410,5]]},"1738":{"position":[[55,5],[385,5]]},"1742":{"position":[[25,5],[184,5]]},"1756":{"position":[[319,5]]},"1762":{"position":[[178,5]]},"1768":{"position":[[300,5]]},"1772":{"position":[[50,5]]},"1774":{"position":[[462,5]]},"1778":{"position":[[136,5],[508,5],[597,5],[608,5],[888,5]]},"1782":{"position":[[691,5],[802,5],[904,5],[1680,5],[2034,5],[2170,5],[2575,5]]},"1788":{"position":[[353,5]]},"1794":{"position":[[454,5],[743,5]]},"1802":{"position":[[447,5],[466,7],[511,6],[556,6],[616,5],[635,7],[680,6],[725,6],[851,5],[952,5]]}}}],["input(head",{"_index":5447,"t":{"1718":{"position":[[1073,10]]}}}],["insert",{"_index":3299,"t":{"891":{"position":[[521,8]]},"893":{"position":[[214,8]]},"895":{"position":[[759,8]]},"899":{"position":[[90,8]]},"953":{"position":[[247,8]]},"1477":{"position":[[133,8]]}}}],["insid",{"_index":5118,"t":{"1628":{"position":[[87,6]]}}}],["inspir",{"_index":4997,"t":{"1583":{"position":[[187,12]]}}}],["instac",{"_index":3476,"t":{"982":{"position":[[662,7]]}}}],["instal",{"_index":92,"t":{"15":{"position":[[37,10]]},"17":{"position":[[337,8]]}}}],["instanc",{"_index":582,"t":{"124":{"position":[[293,8]]},"126":{"position":[[436,8],[904,8]]},"128":{"position":[[154,8]]},"130":{"position":[[80,8],[781,8],[821,8]]},"140":{"position":[[471,8]]},"143":{"position":[[146,8],[186,8]]},"147":{"position":[[333,8]]},"149":{"position":[[11,8]]},"151":{"position":[[18,8]]},"155":{"position":[[704,8]]},"157":{"position":[[58,8],[277,8]]},"159":{"position":[[817,8]]},"163":{"position":[[17,8],[89,8],[275,8],[464,8],[628,8],[777,8]]},"165":{"position":[[84,8],[265,8],[748,8],[777,8],[814,8],[1179,8],[1253,8],[1350,8],[1456,8],[1714,8],[1757,8],[1819,8],[2072,8],[2118,8],[2180,8],[2226,8],[2271,8],[2506,8],[2615,8],[2682,8],[2840,8]]},"168":{"position":[[27,8],[93,8],[179,8],[385,8]]},"174":{"position":[[89,8],[180,8],[362,8],[389,8],[718,8],[1177,8],[1286,8],[1349,8],[1500,8],[2348,8],[2587,8]]},"177":{"position":[[754,8]]},"179":{"position":[[56,8],[127,8]]},"185":{"position":[[92,8]]},"193":{"position":[[25,8]]},"209":{"position":[[47,8]]},"215":{"position":[[873,8],[921,8]]},"221":{"position":[[633,9]]},"230":{"position":[[251,8],[309,8]]},"977":{"position":[[304,8]]},"982":{"position":[[144,8],[245,8],[486,8]]},"986":{"position":[[215,8],[229,8],[318,8]]},"988":{"position":[[64,8]]},"990":{"position":[[0,8],[599,8]]},"992":{"position":[[230,8],[326,8],[738,8],[899,8]]},"1008":{"position":[[121,8]]},"1347":{"position":[[1382,8],[1872,8]]},"1352":{"position":[[86,8]]},"1367":{"position":[[409,8]]},"1371":{"position":[[96,8]]},"1389":{"position":[[1014,9]]},"1669":{"position":[[623,9],[653,9]]}}}],["instris",{"_index":2616,"t":{"733":{"position":[[146,9]]}}}],["instruct",{"_index":1674,"t":{"459":{"position":[[44,12],[111,11]]},"483":{"position":[[670,11],[777,11]]},"485":{"position":[[1533,11],[1630,11]]},"537":{"position":[[0,11],[79,11]]},"539":{"position":[[4,11],[38,11],[111,11],[181,11],[420,11],[572,11]]},"541":{"position":[[36,11],[60,11]]},"544":{"position":[[53,11]]},"548":{"position":[[40,13],[98,11]]},"550":{"position":[[27,11]]},"557":{"position":[[134,11]]},"559":{"position":[[0,11]]},"563":{"position":[[7,11],[351,11]]},"565":{"position":[[37,11]]},"567":{"position":[[0,11],[143,11],[218,11],[303,11],[373,11],[517,11],[598,11],[672,11]]},"569":{"position":[[280,11],[782,11],[896,12]]},"571":{"position":[[6,11],[85,11]]},"573":{"position":[[0,11],[226,11]]},"577":{"position":[[151,11],[240,11]]},"579":{"position":[[259,11]]},"581":{"position":[[37,11],[107,11],[176,11]]},"583":{"position":[[0,11],[147,11]]},"589":{"position":[[710,12]]},"602":{"position":[[579,11]]},"885":{"position":[[24,11],[108,11],[389,11],[498,11]]},"887":{"position":[[18,11],[89,11],[215,11],[292,11],[420,11],[731,11],[974,11],[991,11],[1143,11]]},"891":{"position":[[4,11],[91,11],[641,11],[875,11]]},"893":{"position":[[1611,11],[2509,13]]},"895":{"position":[[5,11]]},"897":{"position":[[53,11]]},"905":{"position":[[25,11],[55,11],[490,11]]},"909":{"position":[[15,11]]},"928":{"position":[[136,11]]},"932":{"position":[[78,11],[155,11],[297,11],[437,11],[552,11],[612,11],[895,11],[938,11]]},"934":{"position":[[9,11],[93,11],[129,11],[367,11],[482,11],[579,11],[657,11],[692,11],[922,11],[1115,11],[1198,11],[1530,11],[1619,11],[1656,11],[1730,11],[1898,11],[2207,11],[2276,11],[2331,11],[2373,11],[2446,11],[2493,11]]},"938":{"position":[[0,11],[480,11]]},"942":{"position":[[157,11]]},"945":{"position":[[273,11],[824,11],[852,11]]},"949":{"position":[[170,11],[256,11],[290,11],[474,11],[646,11]]},"951":{"position":[[67,11],[112,11],[271,11],[389,11],[427,11]]},"955":{"position":[[444,11]]},"959":{"position":[[35,11],[147,11]]},"963":{"position":[[27,11],[77,11]]},"965":{"position":[[28,11],[129,11],[177,11],[334,11]]},"967":{"position":[[391,11],[456,11]]},"969":{"position":[[279,11]]},"973":{"position":[[33,12],[119,11],[188,11],[228,11],[271,11],[419,11],[548,11]]},"1291":{"position":[[747,11]]},"1303":{"position":[[491,11],[645,11],[725,11]]},"1434":{"position":[[314,11]]},"1542":{"position":[[126,12]]},"1546":{"position":[[244,14]]},"1552":{"position":[[130,8],[264,11]]},"1714":{"position":[[427,13]]},"1738":{"position":[[410,11]]},"1778":{"position":[[250,11],[804,11]]}}}],["instructgpt",{"_index":2041,"t":{"569":{"position":[[930,12]]},"934":{"position":[[69,11]]},"1544":{"position":[[294,11]]},"1546":{"position":[[327,13],[589,11],[610,11],[650,11],[1065,11],[1095,11],[1148,11]]},"1552":{"position":[[56,11]]},"1554":{"position":[[56,11]]},"1558":{"position":[[2041,11],[2113,11]]},"1563":{"position":[[18,11],[90,11]]},"1565":{"position":[[0,11],[35,11]]},"1567":{"position":[[0,11],[64,11]]},"1570":{"position":[[363,11]]},"1573":{"position":[[0,11],[119,11],[219,11],[304,11]]},"1575":{"position":[[10,11]]},"1577":{"position":[[0,11],[56,11]]}}}],["integ",{"_index":2223,"t":{"614":{"position":[[190,10]]}}}],["integr",{"_index":113,"t":{"17":{"position":[[279,10]]},"934":{"position":[[2553,11]]}}}],["intens",{"_index":2301,"t":{"648":{"position":[[1007,9]]},"679":{"position":[[140,9]]},"786":{"position":[[4286,9]]},"795":{"position":[[1417,9]]},"1442":{"position":[[1631,10]]}}}],["intent",{"_index":5154,"t":{"1644":{"position":[[684,6]]},"1646":{"position":[[2514,6],[3111,6]]},"1653":{"position":[[226,6],[776,6]]},"1678":{"position":[[13,6]]},"1680":{"position":[[110,7],[167,6],[235,7]]},"1682":{"position":[[0,6],[338,6],[472,6],[714,6],[854,6]]},"1684":{"position":[[194,6],[224,6],[497,6],[656,6]]},"1689":{"position":[[298,6]]}}}],["inter",{"_index":2201,"t":{"608":{"position":[[230,9]]}}}],["interact",{"_index":70,"t":{"9":{"position":[[99,11]]},"628":{"position":[[1071,11],[1195,11],[1295,11]]},"630":{"position":[[631,11],[688,11],[764,11]]},"646":{"position":[[179,11]]},"650":{"position":[[114,11]]},"676":{"position":[[1648,11]]},"696":{"position":[[1041,11]]},"1628":{"position":[[37,11]]}}}],["interest",{"_index":710,"t":{"155":{"position":[[508,8]]}}}],["interfac",{"_index":578,"t":{"124":{"position":[[184,9],[389,9]]},"126":{"position":[[228,9],[841,9],[1001,9]]},"130":{"position":[[345,9],[414,9]]},"434":{"position":[[659,9]]}}}],["interference/neg",{"_index":4615,"t":{"1423":{"position":[[805,21]]}}}],["intermedi",{"_index":1520,"t":{"382":{"position":[[19,12]]},"384":{"position":[[295,12]]},"386":{"position":[[62,12],[230,12]]},"405":{"position":[[34,12],[215,12]]},"428":{"position":[[54,12]]},"445":{"position":[[32,12]]},"447":{"position":[[346,12]]},"529":{"position":[[1591,12]]},"589":{"position":[[1967,12]]},"598":{"position":[[1336,12]]},"616":{"position":[[127,12]]},"630":{"position":[[940,12]]},"1126":{"position":[[1980,12]]},"1145":{"position":[[534,12]]},"1244":{"position":[[1786,12]]}}}],["intern",{"_index":563,"t":{"116":{"position":[[27,8],[59,8],[261,8]]},"1653":{"position":[[134,8]]}}}],["interpol",{"_index":263,"t":{"49":{"position":[[382,13]]},"97":{"position":[[403,15]]},"498":{"position":[[780,13]]},"977":{"position":[[363,11]]},"982":{"position":[[643,13]]},"986":{"position":[[180,13]]},"1006":{"position":[[563,13],[1009,13]]},"1008":{"position":[[104,13]]}}}],["interpret",{"_index":3469,"t":{"979":{"position":[[1384,16]]},"1006":{"position":[[2050,17]]},"1442":{"position":[[1712,11]]}}}],["intial",{"_index":2999,"t":{"803":{"position":[[417,6]]}}}],["intrins",{"_index":2188,"t":{"598":{"position":[[3484,9]]},"719":{"position":[[393,9],[471,10]]},"772":{"position":[[138,10]]},"776":{"position":[[129,10]]},"1341":{"position":[[824,9]]},"1653":{"position":[[397,9]]}}}],["intro",{"_index":5048,"t":{"1595":{"position":[[356,8]]}}}],["introduc",{"_index":2190,"t":{"598":{"position":[[3845,9]]}}}],["introduct",{"_index":752,"t":{"168":{"position":[[0,12]]}}}],["intuit",{"_index":4285,"t":{"1303":{"position":[[224,9]]},"1389":{"position":[[13,10]]}}}],["invari",{"_index":1814,"t":{"523":{"position":[[492,11]]}}}],["invit",{"_index":3913,"t":{"1132":{"position":[[305,8],[507,8]]}}}],["involv",{"_index":4999,"t":{"1583":{"position":[[231,8]]}}}],["iou",{"_index":702,"t":{"153":{"position":[[190,3]]},"187":{"position":[[89,3]]}}}],["ip=projection(concat({im}m=1m))\\begin{equ",{"_index":3376,"t":{"895":{"position":[[437,47]]}}}],["ipi=ex∼dx",{"_index":4802,"t":{"1485":{"position":[[586,9]]}}}],["ipi_pip",{"_index":3384,"t":{"895":{"position":[[730,8]]}}}],["ipii_{p_i}ipi",{"_index":4801,"t":{"1485":{"position":[[555,15]]}}}],["ipsum",{"_index":14,"t":{"3":{"position":[[126,5],[235,5],[278,5],[305,5],[414,5],[457,5],[484,5],[593,5],[636,5],[663,5],[772,5],[815,5],[842,5],[951,5],[994,5],[1021,5],[1130,5],[1173,5],[1200,5],[1309,5],[1352,5],[1379,5],[1488,5],[1531,5],[1558,5],[1667,5],[1710,5],[1737,5],[1846,5],[1889,5],[1916,5],[2025,5],[2068,5],[2095,5],[2204,5],[2247,5],[2274,5],[2383,5],[2426,5],[2453,5],[2562,5],[2605,5],[2632,5],[2741,5],[2784,5],[2811,5],[2920,5],[2963,5]]},"5":{"position":[[6,5],[115,5],[158,5]]}}}],["ip∈r1×ci_p",{"_index":3382,"t":{"895":{"position":[[611,10]]}}}],["iqi=ex∼dx",{"_index":4829,"t":{"1487":{"position":[[886,9]]}}}],["iqii_{q_i}iqi",{"_index":4828,"t":{"1487":{"position":[[862,15]]}}}],["isol",{"_index":1815,"t":{"523":{"position":[[545,7]]}}}],["it",{"_index":1666,"t":{"457":{"position":[[528,5],[568,3],[663,3],[837,3],[1282,3]]}}}],["item",{"_index":1656,"t":{"457":{"position":[[196,5]]},"1583":{"position":[[111,5]]},"1595":{"position":[[413,6]]},"1606":{"position":[[167,6]]},"1638":{"position":[[167,6]]}}}],["iter",{"_index":3017,"t":{"807":{"position":[[551,10]]},"992":{"position":[[442,9]]},"1159":{"position":[[1893,10]]}}}],["ithi^{th}ith",{"_index":3782,"t":{"1099":{"position":[[939,12]]}}}],["it’",{"_index":5438,"t":{"1714":{"position":[[441,4]]}}}],["iv",{"_index":1824,"t":{"525":{"position":[[609,4],[1580,4]]},"1589":{"position":[[87,2]]}}}],["i}(\\cdot)fprompt,i",{"_index":5510,"t":{"1736":{"position":[[453,22]]}}}],["i}(x))p(z∣x):=k1​∑ik​p(z∣fprompt,i​(x",{"_index":5508,"t":{"1736":{"position":[[390,39]]}}}],["i}1≤i≤r",{"_index":2843,"t":{"795":{"position":[[439,11]]}}}],["i}pk,∗i",{"_index":2963,"t":{"801":{"position":[[731,9]]}}}],["i}}(x",{"_index":5518,"t":{"1736":{"position":[[1472,7]]}}}],["i}}(x)fprompt",{"_index":5523,"t":{"1736":{"position":[[1602,14]]}}}],["i​(x",{"_index":5524,"t":{"1736":{"position":[[1617,5]]}}}],["i​(x),z<t",{"_index":5520,"t":{"1736":{"position":[[1524,11]]}}}],["i​∂l(x",{"_index":4810,"t":{"1485":{"position":[[739,14]]},"1487":{"position":[[1038,14]]}}}],["i‾(t)(wij)=β1i‾(t−1)(wij)+(1−β1)i(t)(wij)u‾(t)(wij)=β2u‾(t−1)(wij)+(1−β2)∣i(t)(wij)−i‾(t)(wij)∣,\\begin{align",{"_index":2978,"t":{"801":{"position":[[1586,109]]}}}],["i‾(t)\\overline{i}^{(t)}i(t",{"_index":2990,"t":{"801":{"position":[[2108,27],[2240,27],[2334,27]]}}}],["i∈pidxi",{"_index":4303,"t":{"1305":{"position":[[1111,7]]}}}],["i∈xidxi",{"_index":4266,"t":{"1298":{"position":[[278,7]]}}}],["i∈yidxi",{"_index":4268,"t":{"1298":{"position":[[351,7]]}}}],["i∈{0,1,...,c−1}category1l∑i=0lfp′(i,j)expression/annotationw",{"_index":856,"t":{"174":{"position":[[2016,60]]}}}],["i∈{0,1,...,c−1}l1​∑i=0l​fp′​(i,j)​categoryexpression/annot",{"_index":863,"t":{"174":{"position":[[2276,64]]}}}],["i∈{0,1}\\gamma_i",{"_index":4799,"t":{"1485":{"position":[[287,16]]}}}],["i∈{0,1}\\zeta_i",{"_index":4825,"t":{"1487":{"position":[[697,15]]}}}],["i∈{1…n",{"_index":4023,"t":{"1167":{"position":[[690,10]]}}}],["i∈{1…n}\\begin{equ",{"_index":4018,"t":{"1167":{"position":[[581,24]]}}}],["i∉pidxi",{"_index":4306,"t":{"1305":{"position":[[1209,7]]}}}],["i∣mi∣≪∣m∣\\sum_i",{"_index":4506,"t":{"1387":{"position":[[120,16]]}}}],["i∣|\\lambda_i|∣λi",{"_index":3071,"t":{"837":{"position":[[203,20]]}}}],["j",{"_index":860,"t":{"174":{"position":[[2206,2]]},"477":{"position":[[34,2]]},"694":{"position":[[667,1]]},"774":{"position":[[560,2],[628,3]]}}}],["j&f\\mathcal{j",{"_index":934,"t":{"191":{"position":[[142,14]]},"199":{"position":[[172,14]]}}}],["j(y)\\phi_j(y)ϕj​(i",{"_index":5289,"t":{"1657":{"position":[[2317,20]]}}}],["j(yx)=wj\\phi_j(y_x",{"_index":5309,"t":{"1659":{"position":[[583,20]]}}}],["j(yx)={wj,1,wj,2,…,wj,m}\\phi_j(y_x",{"_index":5311,"t":{"1659":{"position":[[625,36]]}}}],["j)^{th}(i,j)th",{"_index":2153,"t":{"598":{"position":[[1070,14]]}}}],["j[𝙼]_j[m]j",{"_index":5291,"t":{"1657":{"position":[[2374,16]]},"1659":{"position":[[530,16]]}}}],["j\\mathcal{j}j",{"_index":930,"t":{"191":{"position":[[80,14],[202,13]]},"199":{"position":[[110,14]]}}}],["jacob",{"_index":4578,"t":{"1401":{"position":[[547,7]]}}}],["jamstack",{"_index":5050,"t":{"1597":{"position":[[51,10]]}}}],["java",{"_index":1775,"t":{"515":{"position":[[92,5]]}}}],["javascript",{"_index":1777,"t":{"515":{"position":[[104,11]]},"1597":{"position":[[105,10]]}}}],["jax",{"_index":3931,"t":{"1134":{"position":[[785,3]]}}}],["jft",{"_index":397,"t":{"88":{"position":[[573,3]]},"102":{"position":[[78,3]]},"112":{"position":[[27,3],[58,3],[243,3]]},"120":{"position":[[142,3]]}}}],["jiang",{"_index":4354,"t":{"1347":{"position":[[409,6]]},"1367":{"position":[[435,6]]}}}],["jiao",{"_index":3090,"t":{"851":{"position":[[145,5]]}}}],["jitter",{"_index":675,"t":{"145":{"position":[[168,9]]}}}],["jjj",{"_index":2710,"t":{"774":{"position":[[372,3],[900,3]]},"1244":{"position":[[1278,3]]},"1296":{"position":[[544,3]]},"1352":{"position":[[740,3]]}}}],["jjjth",{"_index":5290,"t":{"1657":{"position":[[2352,5]]},"1659":{"position":[[508,5]]}}}],["joel",{"_index":5008,"t":{"1587":{"position":[[131,4]]}}}],["joinli",{"_index":3455,"t":{"965":{"position":[[148,6]]}}}],["joint",{"_index":879,"t":{"177":{"position":[[466,5],[977,5]]},"932":{"position":[[466,5]]},"934":{"position":[[1563,5],[1701,5],[2538,5]]},"949":{"position":[[201,5]]},"951":{"position":[[0,5]]},"953":{"position":[[664,5]]},"967":{"position":[[342,5]]},"973":{"position":[[82,5]]},"1657":{"position":[[2556,5]]}}}],["jointli",{"_index":2042,"t":{"575":{"position":[[168,7]]},"583":{"position":[[208,7]]},"1062":{"position":[[653,7]]}}}],["journal",{"_index":5363,"t":{"1672":{"position":[[255,7]]}}}],["joy",{"_index":5479,"t":{"1728":{"position":[[451,6]]}}}],["jsx",{"_index":5106,"t":{"1624":{"position":[[61,6]]}}}],["jthj_{th}jth",{"_index":2509,"t":{"694":{"position":[[389,13],[722,13]]}}}],["judgment",{"_index":4973,"t":{"1573":{"position":[[66,8]]}}}],["j}j=1k\\{\\theta_j\\}^k_{j=1}{θj​}j=1k",{"_index":4386,"t":{"1352":{"position":[[461,38]]}}}],["j​(yx​)={wj,1​,wj,2​,…,wj,m",{"_index":5315,"t":{"1659":{"position":[[696,32]]}}}],["j∈rl×e\\theta_j",{"_index":4387,"t":{"1352":{"position":[[516,15]]}}}],["k",{"_index":252,"t":{"49":{"position":[[198,1]]},"298":{"position":[[453,2]]},"457":{"position":[[976,1],[1191,1]]},"797":{"position":[[2270,1]]},"1395":{"position":[[1425,2]]},"1431":{"position":[[2757,2],[2776,1]]},"1501":{"position":[[352,1]]}}}],["k(k=4,16,32)k",{"_index":3598,"t":{"1004":{"position":[[245,13]]}}}],["k(t)=λk(t)−η▽λkl(p(t).e(t),q(t)),\\begin{equ",{"_index":2908,"t":{"797":{"position":[[1317,51]]}}}],["k(t)\\lambda^{(t)}_kλk(t",{"_index":2904,"t":{"797":{"position":[[1195,26]]}}}],["k(t)\\lambda_k^{(t)}λk(t",{"_index":2907,"t":{"797":{"position":[[1285,26]]}}}],["k(t+1)=t(λ~k(t),sk(t)),witht(λ~k(t),sk(t))ii={λ~k,iitsk,it",{"_index":2920,"t":{"797":{"position":[[1681,59]]}}}],["k)r≪min(d,k",{"_index":2629,"t":{"733":{"position":[[525,12]]}}}],["k+m+1",{"_index":3336,"t":{"893":{"position":[[941,8]]}}}],["k+m+1k+m+1k+m+1",{"_index":3339,"t":{"893":{"position":[[1018,15]]}}}],["k<nk",{"_index":1289,"t":{"310":{"position":[[1303,4]]}}}],["k<n−lk",{"_index":3421,"t":{"934":{"position":[[1432,6]]}}}],["k=1,…,nk",{"_index":2873,"t":{"797":{"position":[[309,8],[1138,8]]}}}],["k=100k",{"_index":4565,"t":{"1395":{"position":[[1784,6]]},"1397":{"position":[[631,7]]}}}],["k=100k=100k=100",{"_index":4557,"t":{"1395":{"position":[[921,16],[1497,15]]}}}],["k=10k=10k=10",{"_index":3395,"t":{"905":{"position":[[289,12]]}}}],["k=16k",{"_index":1453,"t":{"352":{"position":[[877,5]]}}}],["k=1k",{"_index":4688,"t":{"1431":{"position":[[2860,4]]}}}],["k=219\\mathcal{k",{"_index":4600,"t":{"1419":{"position":[[1077,16]]}}}],["k=4",{"_index":3599,"t":{"1004":{"position":[[259,5]]}}}],["k=500k",{"_index":4550,"t":{"1395":{"position":[[131,6],[1524,6]]}}}],["k=nk",{"_index":1300,"t":{"310":{"position":[[1734,4]]}}}],["k=pkλkqk\\triangle_k",{"_index":2870,"t":{"797":{"position":[[251,20]]}}}],["k={100,500,1000",{"_index":4541,"t":{"1393":{"position":[[323,18]]}}}],["k={100,500,1000}k",{"_index":4539,"t":{"1393":{"position":[[285,17]]}}}],["k={100,500}k",{"_index":4561,"t":{"1395":{"position":[[1380,12],[2597,13]]}}}],["k>2k",{"_index":2403,"t":{"672":{"position":[[581,4]]}}}],["k\\lambda_kλk",{"_index":5326,"t":{"1659":{"position":[[1024,14],[1103,14]]}}}],["k\\triangle_k△k",{"_index":2881,"t":{"797":{"position":[[482,16]]}}}],["k][2,k",{"_index":4192,"t":{"1246":{"position":[[426,7]]}}}],["k]knew​=hkxnew​=[hkp,hkx]=[pk​,k",{"_index":2489,"t":{"688":{"position":[[853,33]]}}}],["k^t)}{\\sqrt{d_k",{"_index":2162,"t":{"598":{"position":[[1646,17]]}}}],["k^{1",{"_index":1852,"t":{"527":{"position":[[1251,5]]}}}],["k^{m",{"_index":1847,"t":{"527":{"position":[[798,5],[1294,5]]}}}],["k_l",{"_index":3322,"t":{"893":{"position":[[592,3]]}}}],["k_l^t",{"_index":3334,"t":{"893":{"position":[[899,5]]}}}],["k_{new",{"_index":2475,"t":{"688":{"position":[[460,7]]}}}],["karimi",{"_index":3732,"t":{"1084":{"position":[[243,7]]}}}],["karnin",{"_index":1946,"t":{"531":{"position":[[366,7]]}}}],["kathirvalavakumar",{"_index":1951,"t":{"531":{"position":[[404,18]]}}}],["kd×k",{"_index":483,"t":{"97":{"position":[[127,4]]}}}],["kernel",{"_index":241,"t":{"40":{"position":[[116,6]]},"78":{"position":[[907,6]]},"304":{"position":[[402,6]]},"310":{"position":[[1296,6],[1396,7]]}}}],["key",{"_index":708,"t":{"155":{"position":[[485,3]]},"232":{"position":[[549,3]]},"296":{"position":[[29,3],[76,4],[159,3]]},"298":{"position":[[105,5],[150,4],[313,4]]},"300":{"position":[[42,5],[194,4],[272,4]]},"302":{"position":[[137,3],[395,5]]},"324":{"position":[[192,3],[338,3]]},"336":{"position":[[713,3]]},"341":{"position":[[368,3]]},"527":{"position":[[586,4]]},"529":{"position":[[1468,5]]},"598":{"position":[[1266,4]]},"610":{"position":[[377,3]]},"633":{"position":[[835,3]]},"679":{"position":[[508,3]]},"681":{"position":[[1363,3],[1464,3],[1917,3]]},"683":{"position":[[1159,3]]},"688":{"position":[[67,3],[587,3],[991,3],[1051,3],[1115,3]]},"690":{"position":[[76,3],[94,3],[129,3],[157,3],[229,3],[329,3],[370,3],[403,3],[452,3],[505,3],[585,3],[629,3],[662,3],[699,3],[725,3],[809,3],[851,3]]},"692":{"position":[[253,3]]},"696":{"position":[[450,3],[464,3],[505,3],[602,3],[648,3],[713,3],[779,3],[860,3],[970,3],[976,3],[1101,3],[1170,3],[1189,3],[1195,3]]},"705":{"position":[[189,3],[195,3],[262,3],[268,3]]},"709":{"position":[[703,3],[718,3],[745,3],[751,3],[932,3],[938,3],[1059,3],[1065,3],[1377,3],[2002,3],[2008,3],[2097,3]]},"711":{"position":[[92,3],[140,3]]},"789":{"position":[[701,3]]},"893":{"position":[[424,4]]},"1384":{"position":[[1595,3],[3587,3]]}}}],["keypoint",{"_index":583,"t":{"124":{"position":[[316,8]]},"126":{"position":[[493,8],[514,9],[933,8]]},"128":{"position":[[176,8]]},"130":{"position":[[137,8],[158,9],[1039,8],[1095,8],[1109,8],[1374,8],[1448,8]]},"140":{"position":[[712,8],[733,8]]},"143":{"position":[[200,9]]},"149":{"position":[[532,8]]},"151":{"position":[[60,8]]},"153":{"position":[[381,8]]},"155":{"position":[[458,8],[1000,8]]},"157":{"position":[[81,8],[301,8]]},"159":{"position":[[780,8]]}}}],["keyword",{"_index":5597,"t":{"1782":{"position":[[1874,8]]}}}],["khashabi",{"_index":3519,"t":{"988":{"position":[[645,8]]}}}],["kim",{"_index":1009,"t":{"215":{"position":[[2242,3]]}}}],["kkk",{"_index":485,"t":{"97":{"position":[[162,3]]},"298":{"position":[[337,3]]},"308":{"position":[[757,3]]},"310":{"position":[[1622,3]]},"336":{"position":[[1276,3],[1833,3]]},"347":{"position":[[319,3]]},"352":{"position":[[778,3]]},"672":{"position":[[187,3]]},"797":{"position":[[214,3]]},"891":{"position":[[284,3]]},"893":{"position":[[1252,3]]},"895":{"position":[[741,3],[792,3]]},"934":{"position":[[1416,3]]},"1054":{"position":[[111,3]]},"1070":{"position":[[1645,3],[1691,3]]},"1126":{"position":[[1574,3]]},"1242":{"position":[[162,3],[380,3],[547,3]]},"1244":{"position":[[234,3]]},"1246":{"position":[[437,3],[469,3]]},"1259":{"position":[[399,3]]},"1264":{"position":[[22,4]]},"1352":{"position":[[352,3]]},"1384":{"position":[[1599,3],[1728,3]]},"1389":{"position":[[1715,5]]},"1431":{"position":[[588,3],[596,3],[690,3],[729,3],[754,3],[1138,3],[1165,3],[2437,3],[2702,3],[2718,3],[2837,3],[2887,3],[2988,3],[3009,3],[3090,3]]},"1487":{"position":[[315,3]]},"1669":{"position":[[607,3],[635,3],[696,3]]},"1674":{"position":[[645,3],[670,3]]},"1730":{"position":[[922,3],[994,3]]},"1736":{"position":[[507,3]]}}}],["kl",{"_index":3241,"t":{"861":{"position":[[1918,2]]},"1244":{"position":[[656,2],[916,2]]},"1558":{"position":[[1164,2],[1936,2]]}}}],["kl=lineark",{"_index":3317,"t":{"893":{"position":[[486,13]]}}}],["klk_lkl",{"_index":3331,"t":{"893":{"position":[[818,8]]}}}],["kl​=lineark",{"_index":3327,"t":{"893":{"position":[[719,15]]}}}],["knew=hkxnew=[hkp,hkx]=[pk,k]k_{new",{"_index":2485,"t":{"688":{"position":[[781,35]]}}}],["knewk_{new}knew",{"_index":2480,"t":{"688":{"position":[[539,17]]}}}],["knoledg",{"_index":3831,"t":{"1105":{"position":[[94,8]]}}}],["knowbert",{"_index":5337,"t":{"1665":{"position":[[519,9]]},"1667":{"position":[[585,8]]}}}],["knowladg",{"_index":1135,"t":{"279":{"position":[[109,9]]}}}],["knowledg",{"_index":743,"t":{"165":{"position":[[949,9]]},"219":{"position":[[249,9]]},"221":{"position":[[328,9],[390,9],[495,9],[547,9]]},"225":{"position":[[527,9]]},"227":{"position":[[169,9]]},"232":{"position":[[410,9]]},"258":{"position":[[75,9]]},"260":{"position":[[146,9]]},"269":{"position":[[114,9]]},"336":{"position":[[315,9]]},"356":{"position":[[113,9]]},"358":{"position":[[1348,9]]},"407":{"position":[[186,9]]},"436":{"position":[[378,9]]},"439":{"position":[[158,9]]},"521":{"position":[[297,9],[351,9]]},"531":{"position":[[153,10]]},"553":{"position":[[18,9]]},"557":{"position":[[298,9],[343,9]]},"628":{"position":[[1238,9]]},"630":{"position":[[130,9],[732,9],[2184,9],[2260,9],[2389,9]]},"640":{"position":[[473,9]]},"642":{"position":[[121,9]]},"644":{"position":[[466,9]]},"648":{"position":[[824,9],[1089,9]]},"696":{"position":[[30,9]]},"709":{"position":[[1473,9]]},"849":{"position":[[38,9]]},"851":{"position":[[122,9]]},"861":{"position":[[566,9],[613,9],[1627,9],[1695,9]]},"870":{"position":[[164,9],[487,9],[521,9],[1806,9],[1911,9],[1977,9]]},"873":{"position":[[11,9]]},"885":{"position":[[449,9]]},"887":{"position":[[938,9]]},"891":{"position":[[887,9]]},"893":{"position":[[2031,9],[2562,9]]},"928":{"position":[[188,9]]},"932":{"position":[[392,9]]},"934":{"position":[[302,9],[1266,9],[1920,9]]},"938":{"position":[[242,9]]},"945":{"position":[[91,9]]},"963":{"position":[[171,9]]},"977":{"position":[[168,9],[691,9],[765,9]]},"979":{"position":[[189,9],[442,9],[1026,9],[1958,9]]},"982":{"position":[[25,9]]},"986":{"position":[[750,9]]},"990":{"position":[[398,9],[587,9]]},"999":{"position":[[852,9]]},"1004":{"position":[[442,9]]},"1006":{"position":[[812,9],[1467,9]]},"1008":{"position":[[526,9]]},"1091":{"position":[[177,9]]},"1093":{"position":[[1228,9],[1758,9]]},"1103":{"position":[[15,9]]},"1105":{"position":[[0,9]]},"1107":{"position":[[987,9]]},"1109":{"position":[[240,9],[933,9],[1094,9]]},"1145":{"position":[[1564,9]]},"1176":{"position":[[208,9]]},"1225":{"position":[[232,9],[359,9]]},"1227":{"position":[[1102,9]]},"1230":{"position":[[794,9]]},"1234":{"position":[[0,9],[319,9]]},"1236":{"position":[[553,9],[616,9]]},"1238":{"position":[[1294,9]]},"1240":{"position":[[271,9]]},"1242":{"position":[[55,9],[135,9],[955,9]]},"1244":{"position":[[184,9],[531,9]]},"1246":{"position":[[244,9]]},"1266":{"position":[[270,9]]},"1270":{"position":[[40,9],[117,9]]},"1273":{"position":[[347,9],[548,9]]},"1285":{"position":[[92,9]]},"1429":{"position":[[92,9]]},"1442":{"position":[[1621,9]]},"1644":{"position":[[46,9],[398,9]]},"1646":{"position":[[88,9],[165,9],[586,9],[2039,9],[2224,9],[2254,9],[2584,9],[2608,9],[3265,9]]},"1651":{"position":[[137,9]]},"1665":{"position":[[438,9],[464,9]]},"1667":{"position":[[272,9],[317,9],[422,9],[513,9],[548,9],[653,9],[750,9],[786,9],[848,9],[940,9],[1050,9],[1098,9],[1181,9]]},"1669":{"position":[[1103,9],[1121,9]]},"1676":{"position":[[279,9],[529,9]]},"1684":{"position":[[310,9],[386,9],[513,9],[543,9]]},"1686":{"position":[[269,9],[328,9]]},"1689":{"position":[[154,9]]},"1714":{"position":[[81,9]]},"1718":{"position":[[1034,9]]},"1736":{"position":[[1052,9],[1103,9]]},"1754":{"position":[[237,9]]},"1782":{"position":[[633,9],[2858,9]]},"1794":{"position":[[86,9],[162,9]]}}}],["kw^k_i",{"_index":1221,"t":{"300":{"position":[[804,7]]}}}],["k{−1,1}k",{"_index":537,"t":{"108":{"position":[[71,11]]}}}],["k}a∈rr×k",{"_index":2627,"t":{"733":{"position":[[479,8]]}}}],["k}pepos+k",{"_index":1273,"t":{"308":{"position":[[783,10]]}}}],["k}w0​∈rd×k",{"_index":2619,"t":{"733":{"position":[[299,10]]}}}],["k}μ∈re×k",{"_index":4380,"t":{"1352":{"position":[[224,8]]}}}],["k′=20k",{"_index":1690,"t":{"466":{"position":[[215,7]]}}}],["k≤3k",{"_index":4691,"t":{"1431":{"position":[[3058,4]]}}}],["k⋅lk",{"_index":4407,"t":{"1352":{"position":[[1350,4]]}}}],["l",{"_index":321,"t":{"60":{"position":[[27,1],[35,1]]},"65":{"position":[[42,1]]},"91":{"position":[[2106,1],[2396,1]]},"253":{"position":[[371,1]]},"358":{"position":[[409,2]]},"598":{"position":[[2874,2]]},"753":{"position":[[202,1]]},"857":{"position":[[1073,1]]},"870":{"position":[[95,2],[160,1],[238,1],[283,1],[449,1],[558,1],[601,1],[1733,1],[1852,1],[1951,1]]},"875":{"position":[[80,1]]},"877":{"position":[[189,1],[364,1]]},"1067":{"position":[[1211,1]]},"1214":{"position":[[40,1]]},"1248":{"position":[[223,2],[397,2]]},"1310":{"position":[[261,1]]},"1389":{"position":[[886,2],[954,1]]}}}],["l(2dk+2dv+2dff)l(2d_k",{"_index":2174,"t":{"598":{"position":[[2113,21]]}}}],["l(dk+dv+dff)l(d_k",{"_index":2172,"t":{"598":{"position":[[2020,17]]}}}],["l(m(x,i",{"_index":3808,"t":{"1099":{"position":[[2105,11]]}}}],["l(m(x,y))\\begin{equ",{"_index":3803,"t":{"1099":{"position":[[1956,25]]}}}],["l(p,e,q)=c(p,e,q)+γ∑k=1nr(pk,qk)\\mathcal{l}(\\mathcal{p",{"_index":2894,"t":{"797":{"position":[[867,56]]}}}],["l(x)∂γi∣\\begin{equ",{"_index":4803,"t":{"1485":{"position":[[596,26]]}}}],["l(x)∂ζi∣\\begin{equ",{"_index":4830,"t":{"1487":{"position":[[896,26]]}}}],["l(⋅)=mlp(ln(msa",{"_index":2532,"t":{"696":{"position":[[1372,21]]}}}],["l(⋅)=mlp(ln(msa(⋅)))l(\\cdot",{"_index":2528,"t":{"696":{"position":[[1263,28]]}}}],["l)(l≤l",{"_index":3298,"t":{"891":{"position":[[413,7],[549,7]]}}}],["l,e\\mathcal{l",{"_index":4605,"t":{"1421":{"position":[[217,15]]}}}],["l/14",{"_index":1090,"t":{"239":{"position":[[286,4]]},"354":{"position":[[118,4]]},"366":{"position":[[226,4]]}}}],["l/16",{"_index":183,"t":{"25":{"position":[[737,4]]},"104":{"position":[[108,4]]},"106":{"position":[[180,5]]},"110":{"position":[[15,4]]},"114":{"position":[[180,4],[269,4],[305,4]]}}}],["l/17",{"_index":560,"t":{"114":{"position":[[208,5]]}}}],["l/32",{"_index":558,"t":{"114":{"position":[[174,5],[263,5]]},"116":{"position":[[298,4],[386,4]]}}}],["l0_00",{"_index":3256,"t":{"868":{"position":[[41,6]]}}}],["l0l_0l0",{"_index":3097,"t":{"851":{"position":[[597,8],[645,8]]},"1384":{"position":[[1233,8]]}}}],["l2",{"_index":1744,"t":{"498":{"position":[[489,2]]}}}],["l=100\\mathcal{l",{"_index":4607,"t":{"1421":{"position":[[290,16]]}}}],["l=100l",{"_index":4219,"t":{"1277":{"position":[[9,6]]}}}],["l=10l",{"_index":4544,"t":{"1393":{"position":[[977,5]]},"1395":{"position":[[1826,6],[2141,5]]}}}],["l=16l",{"_index":1497,"t":{"370":{"position":[[79,5]]}}}],["l=1∣x∣∑x∈x[lindep(x)+ljoint(x)],lindep(x)=−1n∑j=1nlog⁡p([𝙼]j=ϕj(yx)∣t(x)),ljoint(x)=−log⁡p(yx∣x),\\begin{equ",{"_index":5293,"t":{"1657":{"position":[[2628,114]]}}}],["l=200l",{"_index":3716,"t":{"1080":{"position":[[153,7]]}}}],["l=300l",{"_index":4221,"t":{"1277":{"position":[[79,6]]}}}],["l=30l=30l=30",{"_index":3396,"t":{"905":{"position":[[327,12]]},"953":{"position":[[467,13]]}}}],["l=50l",{"_index":4563,"t":{"1395":{"position":[[1760,5],[2091,5]]}}}],["l=50l=50l=50",{"_index":4567,"t":{"1395":{"position":[[2023,12]]}}}],["l=lce+λrvtvfr(s)\\begin{equ",{"_index":3217,"t":{"861":{"position":[[687,32]]}}}],["l=−∑t=1t",{"_index":1071,"t":{"236":{"position":[[142,8]]}}}],["l=△{xi,yi}i=1nl",{"_index":3656,"t":{"1065":{"position":[[0,15]]}}}],["l\\mathcal{l}l",{"_index":3233,"t":{"861":{"position":[[1679,13]]},"1099":{"position":[[1843,13]]},"1485":{"position":[[754,13]]}}}],["l^adpt\\hat{l}_{adpt}l^adpt",{"_index":2677,"t":{"755":{"position":[[664,27]]}}}],["l^adpt×(2×dmodel×r+r+dmodel)+2×l^ln×dmodel|\\theta",{"_index":2673,"t":{"755":{"position":[[442,54]]}}}],["l^ln\\hat{l}_{ln}l^ln",{"_index":2678,"t":{"755":{"position":[[710,21]]}}}],["l^lora\\hat{l}_{lora}l^lora",{"_index":2682,"t":{"757":{"position":[[251,27]]}}}],["l_0}hin​∈rdhidden​×l0",{"_index":4469,"t":{"1384":{"position":[[1388,22]]}}}],["l_i)∣θ∣=dmodel​×(lp​+li",{"_index":2664,"t":{"751":{"position":[[181,25]]}}}],["l_i)∣θ∣=l×dmodel​×+(lp​+li",{"_index":2668,"t":{"753":{"position":[[237,28]]}}}],["l_p",{"_index":2663,"t":{"751":{"position":[[174,4]]},"753":{"position":[[230,4]]}}}],["l_v",{"_index":2163,"t":{"598":{"position":[[1673,4]]}}}],["l_{\\textup{box",{"_index":875,"t":{"177":{"position":[[345,16],[882,16],[1505,16]]}}}],["l_{\\textup{emb",{"_index":900,"t":{"177":{"position":[[1544,18]]}}}],["l_{\\textup{mask",{"_index":885,"t":{"177":{"position":[[901,17],[1524,17]]}}}],["l_{\\textup{mask}}^{\\textup{boxinst",{"_index":876,"t":{"177":{"position":[[364,36]]}}}],["l_{\\textup{retriev",{"_index":874,"t":{"177":{"position":[[321,21],[858,21],[1481,21]]}}}],["l_{\\text{indep}}(x",{"_index":5295,"t":{"1657":{"position":[[2822,20]]}}}],["l_{\\text{ln",{"_index":2128,"t":{"596":{"position":[[2044,13]]}}}],["l_{\\text{ul",{"_index":2107,"t":{"596":{"position":[[530,13]]}}}],["l_{l=1}{pl​}l=1l",{"_index":3293,"t":{"891":{"position":[[179,20]]}}}],["labal",{"_index":1448,"t":{"352":{"position":[[406,7]]}}}],["label",{"_index":317,"t":{"58":{"position":[[193,6]]},"112":{"position":[[220,5]]},"126":{"position":[[430,5]]},"130":{"position":[[74,5],[1383,5]]},"143":{"position":[[637,5]]},"163":{"position":[[418,5]]},"165":{"position":[[1071,5]]},"174":{"position":[[2644,5]]},"215":{"position":[[64,7],[103,7],[166,9],[244,8],[327,8],[695,7],[1340,7]]},"221":{"position":[[653,6]]},"225":{"position":[[92,5],[98,6],[679,6]]},"227":{"position":[[320,7],[341,7],[354,7],[484,6]]},"230":{"position":[[11,6],[203,6]]},"253":{"position":[[408,5]]},"260":{"position":[[54,6]]},"275":{"position":[[93,5]]},"279":{"position":[[74,6]]},"319":{"position":[[243,5],[271,5]]},"336":{"position":[[990,5],[1015,5],[1367,5],[1411,5],[1447,5],[1591,5],[1798,8]]},"341":{"position":[[442,7]]},"343":{"position":[[90,5],[104,7],[436,5]]},"345":{"position":[[158,5]]},"347":{"position":[[39,5],[180,5],[226,5],[476,5]]},"352":{"position":[[543,5],[661,5]]},"354":{"position":[[201,5],[234,5],[484,5],[593,7]]},"356":{"position":[[236,7]]},"358":{"position":[[37,7],[663,7],[1227,5]]},"366":{"position":[[125,5],[303,5]]},"368":{"position":[[83,5],[178,5]]},"376":{"position":[[238,8]]},"589":{"position":[[110,7],[1097,6],[1558,5]]},"592":{"position":[[202,7],[416,7]]},"594":{"position":[[8,7],[626,7],[1104,5],[1376,5]]},"618":{"position":[[185,5]]},"666":{"position":[[222,5]]},"819":{"position":[[107,8]]},"859":{"position":[[175,5],[264,5]]},"866":{"position":[[147,5]]},"1012":{"position":[[269,8]]},"1014":{"position":[[565,5],[964,8]]},"1017":{"position":[[48,5],[108,8]]},"1026":{"position":[[146,5]]},"1033":{"position":[[171,8]]},"1037":{"position":[[82,8]]},"1041":{"position":[[127,8]]},"1045":{"position":[[89,9]]},"1052":{"position":[[202,5]]},"1065":{"position":[[134,8]]},"1124":{"position":[[186,7]]},"1126":{"position":[[1649,7]]},"1128":{"position":[[228,5],[311,5]]},"1134":{"position":[[203,6]]},"1141":{"position":[[319,5],[452,5],[554,5],[765,5],[796,5]]},"1143":{"position":[[814,5]]},"1151":{"position":[[1171,6],[1200,5],[1249,5],[1269,5],[1380,5]]},"1162":{"position":[[138,5]]},"1187":{"position":[[128,5]]},"1227":{"position":[[1575,5]]},"1323":{"position":[[186,5]]},"1350":{"position":[[209,5]]},"1419":{"position":[[1008,7]]},"1477":{"position":[[707,5]]},"1595":{"position":[[103,5],[394,6]]},"1628":{"position":[[329,5]]},"1646":{"position":[[731,5],[820,6],[941,5],[1093,5],[1408,5],[1651,5],[2731,5]]},"1651":{"position":[[815,5]]},"1653":{"position":[[81,5],[126,5],[191,5],[316,5],[438,5]]},"1655":{"position":[[108,5],[329,8],[770,5],[1189,5],[1670,5]]},"1657":{"position":[[1120,5],[2393,5]]},"1659":{"position":[[68,5],[180,5],[364,5],[399,5],[438,5],[569,5],[1043,5]]},"1665":{"position":[[899,5],[956,5],[968,5]]},"1669":{"position":[[250,5]]},"1674":{"position":[[106,5]]},"1689":{"position":[[223,5]]},"1693":{"position":[[412,7]]},"1698":{"position":[[119,6],[279,5],[307,5],[384,5],[454,5]]},"1730":{"position":[[630,5],[756,5],[1230,5],[1246,5]]},"1732":{"position":[[76,5]]},"1768":{"position":[[214,5],[671,5]]},"1796":{"position":[[139,6]]},"1802":{"position":[[299,5],[382,5]]}}}],["labeld",{"_index":711,"t":{"155":{"position":[[566,6]]},"343":{"position":[[126,6]]}}}],["ladder",{"_index":2297,"t":{"648":{"position":[[720,6]]},"1070":{"position":[[1277,6]]},"1230":{"position":[[353,6]]}}}],["ladders",{"_index":2255,"t":{"630":{"position":[[793,10]]}}}],["lama",{"_index":3748,"t":{"1091":{"position":[[195,6]]},"1093":{"position":[[1223,4],[1753,4]]},"1099":{"position":[[693,5]]},"1103":{"position":[[10,4]]},"1105":{"position":[[79,4]]},"1107":{"position":[[10,4],[105,4],[130,4],[228,4],[285,4],[537,4],[764,4]]},"1109":{"position":[[32,4],[66,4],[561,4],[778,4]]},"1714":{"position":[[65,4]]},"1752":{"position":[[236,4]]},"1762":{"position":[[198,4]]}}}],["lambda",{"_index":279,"t":{"49":{"position":[[850,9]]},"786":{"position":[[3999,7],[4050,9]]},"795":{"position":[[171,7],[451,7],[695,9],[755,9],[1149,9]]},"1244":{"position":[[2071,7],[2314,9]]}}}],["lambda)x_ix~i​=λxj​+(1−λ)xi",{"_index":275,"t":{"49":{"position":[[726,29]]}}}],["lambda)y_iy~​i​=λyj​+(1−λ)yi",{"_index":278,"t":{"49":{"position":[[807,30]]}}}],["lambda_k",{"_index":2871,"t":{"797":{"position":[[278,9],[651,9]]},"1659":{"position":[[938,9]]}}}],["lambda_k^{(t",{"_index":2910,"t":{"797":{"position":[[1395,15]]}}}],["lambda_k^{(t+1",{"_index":2923,"t":{"797":{"position":[[1794,17]]}}}],["lambda_r",{"_index":3219,"t":{"861":{"position":[[760,9]]}}}],["lambda_{i",{"_index":2852,"t":{"795":{"position":[[645,12]]}}}],["lambda_{k,i",{"_index":2878,"t":{"797":{"position":[[426,14]]}}}],["lambda_{k,i}sk,i​=λk,i",{"_index":2946,"t":{"799":{"position":[[71,24]]}}}],["lambda{x}_j",{"_index":274,"t":{"49":{"position":[[708,12]]}}}],["lambda{y}_j",{"_index":277,"t":{"49":{"position":[[789,12]]}}}],["lamda",{"_index":1552,"t":{"397":{"position":[[42,5],[140,5]]},"399":{"position":[[418,5]]},"409":{"position":[[226,5]]}}}],["lan",{"_index":3093,"t":{"851":{"position":[[301,4]]}}}],["langaug",{"_index":1382,"t":{"334":{"position":[[21,8]]}}}],["languag",{"_index":589,"t":{"126":{"position":[[219,8]]},"130":{"position":[[195,8]]},"163":{"position":[[132,8],[659,8]]},"165":{"position":[[537,8],[1495,8]]},"170":{"position":[[137,8]]},"172":{"position":[[710,8]]},"213":{"position":[[27,8],[142,8]]},"219":{"position":[[10,8],[97,8],[278,8]]},"221":{"position":[[81,8],[522,8]]},"225":{"position":[[224,8],[397,8],[722,8],[750,8],[778,8]]},"227":{"position":[[70,8]]},"232":{"position":[[198,8]]},"234":{"position":[[52,8],[399,8],[466,8],[486,8]]},"236":{"position":[[280,8],[462,8]]},"239":{"position":[[109,8]]},"287":{"position":[[667,8],[697,8]]},"334":{"position":[[305,8]]},"339":{"position":[[148,8]]},"434":{"position":[[6,8]]},"436":{"position":[[25,8],[505,8],[538,8],[617,8],[1399,8],[1723,8],[1958,8],[1992,8]]},"441":{"position":[[410,8]]},"443":{"position":[[66,8],[179,8]]},"447":{"position":[[359,8]]},"455":{"position":[[843,8]]},"457":{"position":[[1432,8]]},"468":{"position":[[245,8]]},"521":{"position":[[315,8]]},"523":{"position":[[30,8]]},"539":{"position":[[334,8]]},"544":{"position":[[11,8]]},"546":{"position":[[152,8]]},"553":{"position":[[246,8],[280,9]]},"567":{"position":[[443,8]]},"569":{"position":[[870,8]]},"587":{"position":[[48,8]]},"589":{"position":[[384,9],[438,8]]},"594":{"position":[[176,8],[818,8]]},"602":{"position":[[199,8]]},"626":{"position":[[6,8]]},"633":{"position":[[120,8]]},"679":{"position":[[69,8],[186,8]]},"683":{"position":[[12,8],[206,8]]},"717":{"position":[[413,8]]},"727":{"position":[[150,8]]},"743":{"position":[[52,8]]},"784":{"position":[[18,8],[769,8],[819,8]]},"812":{"position":[[166,8]]},"847":{"position":[[12,8]]},"887":{"position":[[1187,8]]},"891":{"position":[[467,8]]},"895":{"position":[[1130,8]]},"897":{"position":[[92,8]]},"901":{"position":[[203,8]]},"914":{"position":[[30,8]]},"932":{"position":[[924,8]]},"934":{"position":[[353,8],[735,8],[1041,8],[1189,8],[2198,8],[2267,8]]},"940":{"position":[[170,8]]},"949":{"position":[[33,8],[156,8],[465,8]]},"951":{"position":[[257,8]]},"953":{"position":[[9,8]]},"963":{"position":[[244,8]]},"965":{"position":[[19,8],[65,8],[115,8]]},"967":{"position":[[382,8]]},"969":{"position":[[117,8],[318,8]]},"977":{"position":[[37,8]]},"1008":{"position":[[714,8]]},"1012":{"position":[[16,8],[133,8]]},"1014":{"position":[[376,8]]},"1019":{"position":[[495,8]]},"1039":{"position":[[100,8]]},"1060":{"position":[[48,8],[466,8],[1010,8],[1045,8]]},"1091":{"position":[[41,8]]},"1093":{"position":[[122,8],[177,8],[205,8],[256,8],[284,8],[332,8],[458,8]]},"1107":{"position":[[646,8],[743,8]]},"1111":{"position":[[908,8],[1016,8],[1918,8]]},"1124":{"position":[[53,8]]},"1126":{"position":[[262,8],[357,9]]},"1130":{"position":[[397,8]]},"1132":{"position":[[709,8]]},"1145":{"position":[[2359,8]]},"1151":{"position":[[40,8]]},"1153":{"position":[[268,8]]},"1159":{"position":[[12,8],[430,8],[474,8]]},"1187":{"position":[[18,8]]},"1225":{"position":[[92,8]]},"1227":{"position":[[22,8]]},"1230":{"position":[[567,8]]},"1289":{"position":[[37,8],[96,8],[181,8]]},"1291":{"position":[[37,8],[733,8]]},"1296":{"position":[[61,8]]},"1303":{"position":[[477,8]]},"1350":{"position":[[795,8]]},"1377":{"position":[[23,8]]},"1379":{"position":[[12,8],[145,8]]},"1403":{"position":[[31,8]]},"1407":{"position":[[12,8]]},"1409":{"position":[[211,8]]},"1411":{"position":[[49,8]]},"1419":{"position":[[655,8],[851,8]]},"1440":{"position":[[131,8],[232,8],[423,9],[530,8]]},"1466":{"position":[[35,8]]},"1471":{"position":[[55,8]]},"1542":{"position":[[100,8]]},"1544":{"position":[[6,8]]},"1546":{"position":[[10,8],[184,8]]},"1554":{"position":[[180,8]]},"1558":{"position":[[15,8]]},"1638":{"position":[[30,10]]},"1644":{"position":[[16,8],[154,8]]},"1646":{"position":[[1264,8]]},"1655":{"position":[[1265,8]]},"1669":{"position":[[502,8]]},"1695":{"position":[[408,8]]},"1702":{"position":[[696,8]]},"1714":{"position":[[133,8],[360,8],[418,8],[480,8]]},"1720":{"position":[[1277,8]]},"1788":{"position":[[600,8]]},"1794":{"position":[[872,8]]}}}],["larg",{"_index":344,"t":{"78":{"position":[[38,5]]},"104":{"position":[[16,6],[135,7]]},"110":{"position":[[47,5]]},"182":{"position":[[38,5]]},"189":{"position":[[5,5]]},"215":{"position":[[39,5]]},"239":{"position":[[204,6],[274,5]]},"298":{"position":[[1101,5]]},"434":{"position":[[0,5]]},"455":{"position":[[146,5]]},"521":{"position":[[190,5]]},"525":{"position":[[722,5]]},"531":{"position":[[215,5],[793,5]]},"594":{"position":[[154,5]]},"618":{"position":[[241,5]]},"626":{"position":[[0,5]]},"633":{"position":[[234,5],[273,5],[313,5]]},"640":{"position":[[211,5]]},"658":{"position":[[76,5]]},"660":{"position":[[26,5]]},"670":{"position":[[828,5]]},"679":{"position":[[63,5]]},"690":{"position":[[37,5]]},"705":{"position":[[152,6]]},"707":{"position":[[95,5]]},"725":{"position":[[78,5]]},"741":{"position":[[28,5]]},"759":{"position":[[102,5]]},"763":{"position":[[63,5]]},"784":{"position":[[0,5]]},"786":{"position":[[520,5],[3866,5],[4498,5]]},"805":{"position":[[37,5]]},"826":{"position":[[46,5]]},"849":{"position":[[15,5],[96,5]]},"866":{"position":[[913,5]]},"897":{"position":[[108,5]]},"977":{"position":[[251,5]]},"979":{"position":[[467,5]]},"997":{"position":[[23,5]]},"1002":{"position":[[606,7]]},"1006":{"position":[[290,5]]},"1008":{"position":[[173,5]]},"1043":{"position":[[12,6],[27,6]]},"1060":{"position":[[460,5]]},"1070":{"position":[[1548,5],[1607,5]]},"1082":{"position":[[242,5]]},"1093":{"position":[[535,5]]},"1111":{"position":[[1784,5]]},"1113":{"position":[[23,5],[331,5]]},"1136":{"position":[[698,5]]},"1143":{"position":[[749,5]]},"1145":{"position":[[2230,5]]},"1157":{"position":[[345,6]]},"1159":{"position":[[122,5],[1079,5],[1690,6]]},"1199":{"position":[[253,5]]},"1203":{"position":[[116,5]]},"1205":{"position":[[50,5]]},"1225":{"position":[[86,5]]},"1255":{"position":[[241,5]]},"1266":{"position":[[107,5]]},"1289":{"position":[[19,5]]},"1291":{"position":[[19,5]]},"1307":{"position":[[103,5]]},"1314":{"position":[[40,5],[79,5]]},"1317":{"position":[[686,5]]},"1347":{"position":[[1673,5],[2056,5]]},"1357":{"position":[[288,5]]},"1360":{"position":[[91,5],[205,5]]},"1395":{"position":[[1580,5],[2204,5]]},"1401":{"position":[[61,5]]},"1407":{"position":[[516,5]]},"1409":{"position":[[0,5],[1690,5]]},"1413":{"position":[[13,6]]},"1421":{"position":[[416,5]]},"1427":{"position":[[972,5],[1088,5]]},"1468":{"position":[[1626,5]]},"1471":{"position":[[159,5]]},"1496":{"position":[[175,7]]},"1499":{"position":[[268,6]]},"1546":{"position":[[4,5]]},"1646":{"position":[[26,5]]},"1667":{"position":[[234,5]]},"1672":{"position":[[77,5]]},"1682":{"position":[[439,5]]},"1684":{"position":[[182,5]]},"1718":{"position":[[107,5]]}}}],["large(770m",{"_index":4045,"t":{"1183":{"position":[[99,11]]}}}],["larger",{"_index":1202,"t":{"298":{"position":[[1010,6]]},"326":{"position":[[380,6]]},"795":{"position":[[1961,6]]},"1047":{"position":[[188,6]]},"1084":{"position":[[1131,6]]},"1111":{"position":[[1490,6]]},"1147":{"position":[[593,6]]},"1738":{"position":[[957,6]]},"1782":{"position":[[665,6],[827,6]]}}}],["lasot",{"_index":890,"t":{"177":{"position":[[1241,6]]},"189":{"position":[[23,6],[30,5]]}}}],["last",{"_index":365,"t":{"78":{"position":[[890,4]]},"424":{"position":[[141,4]]},"500":{"position":[[579,4]]},"531":{"position":[[1145,4]]},"681":{"position":[[450,4]]},"683":{"position":[[724,4]]},"709":{"position":[[1734,4],[1763,4]]},"893":{"position":[[114,4]]},"905":{"position":[[322,4]]},"934":{"position":[[1320,4]]},"953":{"position":[[445,4]]},"961":{"position":[[76,4]]},"1132":{"position":[[331,4],[540,4]]},"1296":{"position":[[798,4]]}}}],["late",{"_index":3441,"t":{"949":{"position":[[493,4]]},"1132":{"position":[[1789,4]]}}}],["latenc",{"_index":2205,"t":{"608":{"position":[[559,8]]},"717":{"position":[[402,7]]},"719":{"position":[[1244,7]]},"725":{"position":[[93,7]]},"727":{"position":[[278,7],[440,7]]},"737":{"position":[[95,7]]},"780":{"position":[[69,7]]}}}],["latent",{"_index":421,"t":{"91":{"position":[[464,6],[599,6],[616,6]]},"232":{"position":[[356,6],[438,6],[524,6]]}}}],["later",{"_index":350,"t":{"78":{"position":[[163,5]]}}}],["layer",{"_index":168,"t":{"25":{"position":[[179,5]]},"78":{"position":[[139,6]]},"86":{"position":[[661,5],[674,5]]},"91":{"position":[[1082,5],[1117,5],[1384,5],[2136,5]]},"97":{"position":[[146,5]]},"104":{"position":[[497,5]]},"116":{"position":[[741,5],[821,5]]},"172":{"position":[[726,5],[747,5]]},"182":{"position":[[214,5],[232,5]]},"230":{"position":[[46,5],[89,6],[163,5],[458,5]]},"234":{"position":[[82,5]]},"265":{"position":[[145,5]]},"289":{"position":[[495,5]]},"292":{"position":[[28,5],[51,5],[68,6],[163,5],[202,5],[231,5],[379,5],[432,6],[451,6]]},"294":{"position":[[29,5],[58,5],[77,6],[99,5],[185,5],[215,5]]},"298":{"position":[[776,5]]},"300":{"position":[[1223,5]]},"302":{"position":[[79,6],[115,5],[354,5],[383,5],[451,5],[497,5],[552,5]]},"304":{"position":[[14,6],[358,5],[518,5]]},"306":{"position":[[252,6],[336,6]]},"310":{"position":[[188,6],[212,6],[298,5],[391,5],[774,5],[888,5],[960,5],[1093,6],[1338,5],[1442,6],[1580,6],[1605,5],[1798,6]]},"319":{"position":[[58,5]]},"326":{"position":[[336,5]]},"328":{"position":[[114,6],[212,6]]},"343":{"position":[[537,5]]},"443":{"position":[[304,5]]},"466":{"position":[[167,5]]},"485":{"position":[[1335,5],[1460,5]]},"498":{"position":[[383,5],[476,5]]},"500":{"position":[[220,5],[250,5],[314,5],[777,5]]},"504":{"position":[[491,5],[542,5],[595,5],[619,5],[678,5],[832,5]]},"510":{"position":[[130,6]]},"525":{"position":[[148,5],[1058,6]]},"527":{"position":[[132,5],[415,5],[486,5],[499,5],[628,5],[1056,5],[1086,5],[1108,5],[1374,5],[3069,5]]},"529":{"position":[[1450,5],[1608,5]]},"531":{"position":[[1150,5],[1375,5]]},"598":{"position":[[1906,5],[1986,5],[2090,5],[3247,5],[3693,5]]},"608":{"position":[[374,5]]},"628":{"position":[[175,6],[321,5],[358,5]]},"630":{"position":[[502,6],[531,6],[555,5],[598,5],[869,5],[1704,5]]},"633":{"position":[[672,5],[827,5],[924,5]]},"648":{"position":[[299,6],[409,6],[463,5]]},"658":{"position":[[1250,5],[2281,5]]},"660":{"position":[[479,5],[544,5],[593,5],[776,5]]},"662":{"position":[[333,5],[357,6],[378,5],[398,5],[406,5],[421,5],[456,5],[489,5],[506,5],[541,5],[700,5],[914,5],[1217,5],[1321,5],[1348,5],[1509,5],[1590,5]]},"664":{"position":[[253,5]]},"666":{"position":[[203,5]]},"668":{"position":[[35,6]]},"670":{"position":[[582,5],[733,6],[1480,5]]},"672":{"position":[[191,6],[212,5],[352,6],[416,6],[558,6],[716,5],[1022,5],[1065,5]]},"674":{"position":[[255,6]]},"676":{"position":[[197,5],[242,5],[302,5],[475,5],[487,5],[521,5],[582,5],[625,5],[694,5],[739,5],[792,5],[1530,5],[1583,5],[1610,5]]},"679":{"position":[[265,5],[540,5]]},"681":{"position":[[459,6],[1168,5],[1520,5]]},"683":{"position":[[729,6],[916,5],[1047,5]]},"688":{"position":[[209,5],[281,5],[739,5]]},"692":{"position":[[42,5],[189,5]]},"694":{"position":[[142,5],[423,5],[477,5],[744,5]]},"696":{"position":[[62,5],[360,5],[1580,5],[1599,5],[1636,5]]},"698":{"position":[[197,5]]},"703":{"position":[[115,5],[168,5]]},"709":{"position":[[1727,6],[1739,6],[1755,7],[1771,6],[1800,5],[1857,5],[1873,5]]},"711":{"position":[[84,5],[203,5]]},"717":{"position":[[126,5]]},"719":{"position":[[602,5],[667,5]]},"721":{"position":[[55,5]]},"725":{"position":[[30,5],[47,5]]},"727":{"position":[[112,5],[227,5],[250,5],[301,5],[329,5],[482,5]]},"733":{"position":[[19,6]]},"747":{"position":[[24,5]]},"753":{"position":[[67,5],[96,5],[284,6]]},"755":{"position":[[49,5],[66,5],[92,5],[188,5],[374,5],[702,5]]},"765":{"position":[[153,5]]},"770":{"position":[[216,5]]},"786":{"position":[[674,5],[2495,6],[2596,6],[2742,6],[2776,6]]},"789":{"position":[[1109,5]]},"797":{"position":[[41,5]]},"809":{"position":[[305,5],[548,5]]},"828":{"position":[[77,5]]},"841":{"position":[[111,6],[196,6]]},"853":{"position":[[53,5]]},"857":{"position":[[528,5],[553,6],[569,5],[593,5],[786,5],[1482,6]]},"873":{"position":[[648,5],[943,5],[1063,5],[1097,5],[1541,5]]},"885":{"position":[[311,5]]},"887":{"position":[[375,5],[491,5]]},"891":{"position":[[34,5],[218,5],[292,5],[394,5],[530,5],[929,6]]},"893":{"position":[[135,6],[223,5],[2224,5],[2259,5]]},"895":{"position":[[780,5],[840,5]]},"899":{"position":[[39,5],[99,5]]},"905":{"position":[[243,5],[340,5]]},"917":{"position":[[12,5],[31,5]]},"932":{"position":[[351,5]]},"934":{"position":[[1020,5],[1329,5],[1420,5],[1486,6],[1776,6],[1814,5]]},"938":{"position":[[136,5],[164,5]]},"940":{"position":[[138,5],[239,5]]},"942":{"position":[[80,5]]},"945":{"position":[[351,6],[394,5],[460,5],[568,5]]},"949":{"position":[[417,5]]},"953":{"position":[[229,5],[256,5],[365,5],[454,6],[527,5]]},"961":{"position":[[15,6],[84,6],[153,5],[178,7],[193,5]]},"988":{"position":[[880,5],[1372,5],[1404,5],[1424,5]]},"994":{"position":[[153,5],[488,5],[577,6]]},"999":{"position":[[560,5]]},"1014":{"position":[[1246,5],[1278,5]]},"1019":{"position":[[75,5]]},"1028":{"position":[[310,6],[489,6]]},"1049":{"position":[[267,5]]},"1054":{"position":[[56,5],[115,6],[166,5],[190,5],[253,5],[309,6],[347,5]]},"1070":{"position":[[1435,5]]},"1099":{"position":[[175,5]]},"1101":{"position":[[592,5]]},"1126":{"position":[[87,5],[1289,5],[1993,5],[2032,7]]},"1134":{"position":[[296,5]]},"1145":{"position":[[288,5],[343,5],[547,5],[992,5],[1055,5],[1676,5],[2126,6],[2167,5]]},"1167":{"position":[[930,6]]},"1172":{"position":[[4,5],[143,5]]},"1174":{"position":[[18,5],[101,5]]},"1185":{"position":[[479,5]]},"1187":{"position":[[401,6]]},"1210":{"position":[[77,5]]},"1218":{"position":[[196,5],[268,5]]},"1230":{"position":[[27,6]]},"1291":{"position":[[453,6],[489,6]]},"1296":{"position":[[491,6],[551,5],[803,5]]},"1303":{"position":[[817,6],[985,6]]},"1312":{"position":[[98,6]]},"1328":{"position":[[122,6],[190,5],[310,5]]},"1339":{"position":[[280,5]]},"1341":{"position":[[410,5],[577,5]]},"1347":{"position":[[294,5]]},"1369":{"position":[[317,5]]},"1382":{"position":[[10,6]]},"1384":{"position":[[127,5],[179,5],[201,5],[330,5],[478,5],[924,5],[1120,5],[1306,5],[2239,6],[2506,5]]},"1389":{"position":[[256,5],[819,5],[1129,5],[2012,5],[2133,5]]},"1395":{"position":[[680,5]]},"1401":{"position":[[373,5]]},"1468":{"position":[[379,6]]},"1494":{"position":[[630,5]]},"1558":{"position":[[495,5]]},"1646":{"position":[[467,6]]},"1667":{"position":[[66,7],[91,6],[113,6]]},"1689":{"position":[[347,6]]}}}],["layernorm",{"_index":437,"t":{"91":{"position":[[1395,9]]},"727":{"position":[[240,9]]},"755":{"position":[[211,9],[744,10]]},"809":{"position":[[486,9]]},"1174":{"position":[[26,10],[64,9]]},"1218":{"position":[[341,9]]}}}],["layernorm(h_{up",{"_index":3528,"t":{"988":{"position":[[1069,18]]}}}],["layernorm(x+sublayer(x))\\text{layernorm}(x",{"_index":1175,"t":{"292":{"position":[[243,42]]}}}],["layout",{"_index":4994,"t":{"1583":{"position":[[158,6]]},"1612":{"position":[[106,6],[184,8],[244,9]]}}}],["lazebnik",{"_index":3269,"t":{"873":{"position":[[907,9]]}}}],["lce\\mathcal{l}_{\\text{ce}}lc",{"_index":3222,"t":{"861":{"position":[[835,30]]}}}],["ldept=−∑ilog⁡p(yi∣[ps,wi′];θ)\\begin{equ",{"_index":3688,"t":{"1067":{"position":[[800,45]]}}}],["le",{"_index":2314,"t":{"658":{"position":[[909,3]]},"670":{"position":[[865,2]]}}}],["leanabl",{"_index":3426,"t":{"938":{"position":[[177,8]]}}}],["learn",{"_index":153,"t":{"23":{"position":[[161,8]]},"25":{"position":[[478,8],[565,8]]},"27":{"position":[[311,8]]},"44":{"position":[[19,8]]},"47":{"position":[[416,8]]},"49":{"position":[[31,8]]},"53":{"position":[[360,8]]},"72":{"position":[[12,8]]},"76":{"position":[[60,8],[89,8]]},"78":{"position":[[424,9]]},"86":{"position":[[499,8]]},"102":{"position":[[142,8]]},"104":{"position":[[346,8]]},"112":{"position":[[460,8],[522,8]]},"118":{"position":[[178,8]]},"219":{"position":[[381,8]]},"232":{"position":[[516,7]]},"262":{"position":[[226,8]]},"300":{"position":[[107,7]]},"306":{"position":[[104,7],[178,7]]},"308":{"position":[[265,7],[893,7]]},"317":{"position":[[126,8],[479,8]]},"324":{"position":[[520,7]]},"326":{"position":[[618,8],[813,8]]},"334":{"position":[[45,8],[73,8],[273,8],[473,8],[509,8],[527,8]]},"336":{"position":[[1753,8],[1771,8]]},"339":{"position":[[52,8],[507,8]]},"341":{"position":[[137,8]]},"343":{"position":[[36,8]]},"352":{"position":[[128,8]]},"356":{"position":[[21,8]]},"372":{"position":[[26,8]]},"378":{"position":[[25,8]]},"384":{"position":[[398,8]]},"428":{"position":[[121,8]]},"443":{"position":[[158,8]]},"449":{"position":[[24,8]]},"455":{"position":[[780,8]]},"483":{"position":[[512,9]]},"485":{"position":[[1101,8]]},"496":{"position":[[238,9]]},"502":{"position":[[525,8]]},"525":{"position":[[26,8],[681,8],[824,9]]},"527":{"position":[[2961,8]]},"550":{"position":[[69,8]]},"587":{"position":[[20,8],[485,7]]},"589":{"position":[[520,8],[1994,7],[2208,8]]},"598":{"position":[[468,7],[730,7],[865,7],[1170,7],[2506,7]]},"602":{"position":[[379,8],[765,8]]},"606":{"position":[[76,8],[392,8]]},"608":{"position":[[58,8]]},"618":{"position":[[9,8]]},"622":{"position":[[29,8],[163,7],[705,8]]},"648":{"position":[[971,8]]},"658":{"position":[[442,8],[647,8],[2495,8],[2524,8],[2618,8]]},"666":{"position":[[290,8]]},"668":{"position":[[127,8]]},"670":{"position":[[172,8]]},"674":{"position":[[272,8],[424,8]]},"696":{"position":[[924,7]]},"719":{"position":[[349,7]]},"727":{"position":[[62,8],[198,10]]},"786":{"position":[[1378,8]]},"791":{"position":[[830,9]]},"797":{"position":[[1587,8]]},"807":{"position":[[262,8]]},"814":{"position":[[603,8]]},"821":{"position":[[427,8]]},"853":{"position":[[1126,8],[1144,8],[1692,8]]},"866":{"position":[[359,8],[749,8]]},"870":{"position":[[736,8],[792,8]]},"875":{"position":[[194,8]]},"905":{"position":[[168,8]]},"934":{"position":[[1742,8]]},"977":{"position":[[189,8]]},"979":{"position":[[999,8],[1338,8],[1720,7],[1751,8]]},"992":{"position":[[157,8]]},"999":{"position":[[464,8],[953,8]]},"1035":{"position":[[11,8]]},"1049":{"position":[[338,8]]},"1052":{"position":[[75,8]]},"1060":{"position":[[913,8],[1146,8],[1187,8]]},"1062":{"position":[[692,10],[1276,8],[1744,8]]},"1067":{"position":[[1321,9],[1374,8],[1444,8]]},"1070":{"position":[[574,8],[699,8],[1340,10]]},"1073":{"position":[[139,8],[161,8]]},"1075":{"position":[[78,8]]},"1084":{"position":[[9,9],[114,8],[760,8],[856,8],[965,8],[997,8],[1033,8],[1069,8],[1102,8],[1193,8]]},"1087":{"position":[[171,8]]},"1091":{"position":[[311,8]]},"1107":{"position":[[1054,8]]},"1111":{"position":[[1212,8],[1375,8],[1595,8],[1816,8]]},"1115":{"position":[[89,8],[274,8],[653,9]]},"1124":{"position":[[248,7],[283,8]]},"1126":{"position":[[2418,7]]},"1132":{"position":[[604,8]]},"1134":{"position":[[718,8]]},"1136":{"position":[[63,9]]},"1141":{"position":[[810,7]]},"1145":{"position":[[19,8],[1785,8]]},"1151":{"position":[[203,7],[424,7],[1771,7]]},"1153":{"position":[[319,8]]},"1157":{"position":[[492,8]]},"1159":{"position":[[1140,8],[1825,8]]},"1170":{"position":[[120,8]]},"1178":{"position":[[304,7]]},"1197":{"position":[[230,8]]},"1199":{"position":[[7,8],[86,8],[172,8],[313,8]]},"1212":{"position":[[264,9]]},"1227":{"position":[[350,8],[1597,8]]},"1232":{"position":[[10,8],[163,8],[261,8]]},"1234":{"position":[[80,9],[284,8]]},"1236":{"position":[[730,8]]},"1238":{"position":[[1357,8]]},"1246":{"position":[[865,8],[1046,8]]},"1264":{"position":[[166,8]]},"1285":{"position":[[408,8]]},"1291":{"position":[[659,8],[695,8],[891,8],[1469,7]]},"1314":{"position":[[187,8],[251,8],[338,8]]},"1407":{"position":[[257,8]]},"1409":{"position":[[1362,7],[1578,8]]},"1419":{"position":[[133,8],[380,8]]},"1429":{"position":[[60,7],[1286,7]]},"1434":{"position":[[233,8]]},"1436":{"position":[[32,8]]},"1440":{"position":[[71,8]]},"1442":{"position":[[1162,8]]},"1473":{"position":[[406,8],[659,8]]},"1489":{"position":[[412,8]]},"1496":{"position":[[11,9],[247,8]]},"1513":{"position":[[154,7]]},"1517":{"position":[[268,8]]},"1523":{"position":[[200,7]]},"1550":{"position":[[104,8]]},"1558":{"position":[[176,8],[259,8],[1110,8],[1350,8]]},"1581":{"position":[[14,7]]},"1646":{"position":[[546,8]]},"1665":{"position":[[46,8],[1280,8]]},"1667":{"position":[[155,8]]},"1669":{"position":[[450,8]]},"1674":{"position":[[344,8]]},"1682":{"position":[[170,8]]},"1686":{"position":[[360,8]]},"1693":{"position":[[30,8],[61,8],[143,8],[441,8]]},"1695":{"position":[[17,8]]},"1698":{"position":[[20,8]]},"1700":{"position":[[11,8],[63,8]]},"1714":{"position":[[583,8]]},"1720":{"position":[[1017,8],[1305,8]]},"1734":{"position":[[13,8],[38,8]]},"1738":{"position":[[36,8],[972,8]]},"1746":{"position":[[10,8],[142,8],[176,8],[213,8],[412,8]]},"1748":{"position":[[26,8]]},"1752":{"position":[[139,8],[397,8]]},"1762":{"position":[[355,8],[395,8]]},"1764":{"position":[[186,8]]},"1768":{"position":[[615,8]]},"1774":{"position":[[218,8]]},"1776":{"position":[[29,8]]},"1780":{"position":[[19,8],[208,8]]},"1782":{"position":[[13,8],[32,8],[70,8],[305,8],[380,8],[436,8],[498,8],[680,8],[842,8],[1025,8],[1247,8],[1353,8],[2226,8],[2511,8],[2649,8],[2923,8]]},"1784":{"position":[[13,8]]},"1786":{"position":[[27,8],[105,8]]},"1788":{"position":[[58,8]]},"1790":{"position":[[395,8]]},"1794":{"position":[[276,8],[923,8],[1078,8]]},"1796":{"position":[[28,8]]},"1798":{"position":[[79,8]]},"1800":{"position":[[168,8]]}}}],["learnabl",{"_index":1129,"t":{"265":{"position":[[171,9]]},"267":{"position":[[80,9],[100,9]]},"336":{"position":[[1024,9]]},"347":{"position":[[386,9]]},"358":{"position":[[86,9],[1373,9]]},"681":{"position":[[511,9],[639,9],[831,9]]},"683":{"position":[[872,9]]},"694":{"position":[[431,9]]},"885":{"position":[[180,9],[257,9]]},"887":{"position":[[383,9],[558,9]]},"891":{"position":[[130,9],[674,9]]},"893":{"position":[[1293,9],[1466,9]]},"895":{"position":[[405,9]]},"901":{"position":[[184,9]]},"909":{"position":[[39,9]]},"912":{"position":[[94,9]]},"932":{"position":[[216,9],[495,9]]},"934":{"position":[[1836,9]]},"940":{"position":[[117,9]]},"945":{"position":[[405,9]]},"953":{"position":[[201,9]]},"963":{"position":[[214,9]]},"1145":{"position":[[127,9],[1038,9],[1277,9],[1685,9],[1796,9]]},"1238":{"position":[[422,9],[673,9]]},"1367":{"position":[[215,9]]},"1389":{"position":[[2142,9]]},"1409":{"position":[[429,9]]},"1720":{"position":[[1944,9]]},"1774":{"position":[[437,9],[542,9]]},"1782":{"position":[[2082,9]]}}}],["learner",{"_index":1984,"t":{"544":{"position":[[41,9]]},"589":{"position":[[428,9],[467,9]]},"1111":{"position":[[942,9],[1050,9],[1952,10]]},"1126":{"position":[[387,9]]},"1132":{"position":[[1765,7]]},"1669":{"position":[[534,9]]},"1714":{"position":[[162,8],[514,8]]}}}],["lee",{"_index":1020,"t":{"215":{"position":[[2355,4]]}}}],["leetcod",{"_index":4721,"t":{"1442":{"position":[[2185,8]]}}}],["leetcodehardgym",{"_index":4720,"t":{"1442":{"position":[[2133,15]]}}}],["left",{"_index":799,"t":{"170":{"position":[[2040,5]]},"174":{"position":[[2079,5]]},"686":{"position":[[316,5]]},"795":{"position":[[959,5],[1004,5]]},"801":{"position":[[1050,5],[1876,5]]},"853":{"position":[[731,5],[768,5],[806,5],[1524,5]]},"855":{"position":[[268,5]]},"857":{"position":[[1042,5],[1093,5]]},"895":{"position":[[509,6]]},"1296":{"position":[[611,4]]},"1298":{"position":[[194,4]]},"1305":{"position":[[1282,4]]},"1411":{"position":[[158,5]]},"1712":{"position":[[133,4]]}}}],["left/right",{"_index":2731,"t":{"778":{"position":[[170,10]]},"786":{"position":[[4136,10]]},"795":{"position":[[329,10]]}}}],["left\\{\\begin{matrix",{"_index":2929,"t":{"797":{"position":[[1931,21]]},"861":{"position":[[189,21]]},"1305":{"position":[[682,21]]}}}],["leftward",{"_index":1241,"t":{"302":{"position":[[636,8]]}}}],["legal",{"_index":3907,"t":{"1130":{"position":[[616,5]]},"1143":{"position":[[802,5]]}}}],["len",{"_index":4586,"t":{"1409":{"position":[[1002,4]]}}}],["length",{"_index":486,"t":{"97":{"position":[[291,6]]},"104":{"position":[[155,6],[443,6],[527,6]]},"310":{"position":[[36,6],[467,6],[642,6],[844,6],[1032,6],[1265,6]]},"313":{"position":[[290,6]]},"322":{"position":[[563,6],[612,6]]},"326":{"position":[[756,6]]},"370":{"position":[[72,6]]},"569":{"position":[[405,6]]},"589":{"position":[[1927,6]]},"596":{"position":[[1397,6],[1428,6],[1549,6],[1590,6],[1677,6],[1934,6]]},"598":{"position":[[990,6]]},"602":{"position":[[309,6]]},"608":{"position":[[900,6],[1019,6]]},"612":{"position":[[91,6]]},"620":{"position":[[197,6]]},"622":{"position":[[352,6]]},"644":{"position":[[134,6],[269,6]]},"670":{"position":[[125,6]]},"686":{"position":[[341,6],[369,6]]},"705":{"position":[[213,6]]},"709":{"position":[[1034,7],[1084,6],[1129,6],[1173,6],[1333,6]]},"713":{"position":[[144,6]]},"759":{"position":[[153,6]]},"780":{"position":[[92,6]]},"828":{"position":[[150,6]]},"891":{"position":[[310,6],[616,6]]},"895":{"position":[[796,6]]},"905":{"position":[[282,6]]},"961":{"position":[[128,6]]},"984":{"position":[[365,6]]},"988":{"position":[[402,7]]},"994":{"position":[[84,6]]},"1008":{"position":[[376,6],[475,6]]},"1028":{"position":[[138,6]]},"1033":{"position":[[7,6],[74,6]]},"1060":{"position":[[552,6],[640,6],[746,6]]},"1062":{"position":[[716,6],[1562,6]]},"1080":{"position":[[89,6],[312,6]]},"1128":{"position":[[1733,6]]},"1130":{"position":[[677,6],[768,6]]},"1132":{"position":[[1876,6]]},"1134":{"position":[[234,6]]},"1139":{"position":[[69,6],[149,6]]},"1141":{"position":[[511,7]]},"1157":{"position":[[469,6]]},"1159":{"position":[[1167,6]]},"1305":{"position":[[358,6]]},"1314":{"position":[[274,6],[362,6],[803,6]]},"1347":{"position":[[688,6],[1839,6]]},"1350":{"position":[[487,6]]},"1352":{"position":[[1341,6],[1383,6]]},"1357":{"position":[[529,6]]},"1362":{"position":[[22,6],[67,6],[506,6]]},"1371":{"position":[[59,6]]},"1373":{"position":[[17,6]]},"1384":{"position":[[1224,6],[1280,7]]},"1393":{"position":[[970,6]]},"1395":{"position":[[1753,6],[2179,6]]},"1421":{"position":[[257,6]]},"1477":{"position":[[537,6]]},"1496":{"position":[[295,6]]},"1505":{"position":[[881,6],[1016,6],[1118,6]]},"1511":{"position":[[7,6],[56,6],[112,6],[213,6]]},"1728":{"position":[[159,6]]},"1782":{"position":[[1766,6]]}}}],["leq",{"_index":1471,"t":{"358":{"position":[[325,4],[332,4]]},"774":{"position":[[243,4],[250,4],[344,4],[351,4]]},"795":{"position":[[468,4],[475,4]]},"797":{"position":[[2265,4],[2272,4],[2282,4],[2289,4]]},"891":{"position":[[408,4],[544,4]]},"1099":{"position":[[1666,4],[1673,4],[1898,4],[1905,4]]},"1431":{"position":[[3063,4]]}}}],["less",{"_index":79,"t":{"11":{"position":[[29,4]]},"589":{"position":[[105,4],[2244,4]]},"786":{"position":[[2882,4],[3554,4]]},"797":{"position":[[2422,4]]},"1073":{"position":[[193,4]]},"1360":{"position":[[115,4]]}}}],["lester",{"_index":2449,"t":{"681":{"position":[[744,7]]},"707":{"position":[[730,7]]},"1002":{"position":[[681,6]]},"1006":{"position":[[180,6]]},"1008":{"position":[[414,6]]},"1019":{"position":[[429,7]]},"1022":{"position":[[16,7]]},"1024":{"position":[[16,7]]},"1026":{"position":[[16,7],[252,7]]},"1028":{"position":[[16,7]]},"1039":{"position":[[153,7]]},"1047":{"position":[[74,7],[246,7],[313,7]]},"1049":{"position":[[113,7],[160,7]]},"1054":{"position":[[16,7]]},"1362":{"position":[[150,7]]},"1367":{"position":[[178,7]]},"1384":{"position":[[2461,7]]},"1407":{"position":[[89,6]]},"1409":{"position":[[458,6]]},"1415":{"position":[[38,6]]},"1421":{"position":[[4,6],[363,6]]},"1423":{"position":[[981,6]]},"1468":{"position":[[184,7]]},"1473":{"position":[[224,7]]},"1492":{"position":[[97,7]]},"1494":{"position":[[167,7]]},"1496":{"position":[[198,6]]},"1511":{"position":[[302,6]]}}}],["let'",{"_index":77,"t":{"11":{"position":[[0,5]]},"559":{"position":[[196,6]]},"565":{"position":[[166,6]]},"569":{"position":[[201,6]]},"1620":{"position":[[78,5],[128,5],[190,5]]},"1630":{"position":[[0,5]]}}}],["letter",{"_index":1583,"t":{"424":{"position":[[146,6]]}}}],["level",{"_index":730,"t":{"163":{"position":[[473,5],[598,5],[737,5],[786,5]]},"165":{"position":[[2515,5],[2691,5]]},"170":{"position":[[1349,5]]},"177":{"position":[[460,5],[971,5],[1046,5],[1120,5],[1164,5]]},"221":{"position":[[565,5],[606,5]]},"227":{"position":[[242,5],[291,5],[674,5]]},"230":{"position":[[188,5]]},"515":{"position":[[622,5]]},"529":{"position":[[2283,5],[2320,5],[2340,5]]},"548":{"position":[[199,5]]},"658":{"position":[[930,5]]},"676":{"position":[[713,5]]},"703":{"position":[[224,5],[238,5]]},"786":{"position":[[1341,5]]},"814":{"position":[[49,6]]},"816":{"position":[[90,5]]},"823":{"position":[[134,5]]},"830":{"position":[[125,6]]},"833":{"position":[[20,6],[137,5],[277,6]]},"835":{"position":[[269,6]]},"841":{"position":[[386,7]]},"847":{"position":[[534,5],[691,6]]},"849":{"position":[[1493,6],[1572,5]]},"853":{"position":[[1879,5]]},"857":{"position":[[469,5],[888,5],[952,5],[1470,5]]},"861":{"position":[[1205,5]]},"870":{"position":[[316,5],[1076,5],[1968,5],[2245,5],[2302,5]]},"881":{"position":[[184,5]]},"891":{"position":[[446,5]]},"982":{"position":[[254,5]]},"1389":{"position":[[406,5]]},"1397":{"position":[[203,5]]},"1419":{"position":[[500,5]]},"1427":{"position":[[1066,5]]},"1466":{"position":[[497,6]]},"1468":{"position":[[1147,5],[1191,5],[1209,6]]},"1483":{"position":[[157,5],[276,5]]},"1485":{"position":[[1180,5]]},"1487":{"position":[[6,5],[232,5],[1059,5],[1204,5],[1218,5]]},"1509":{"position":[[6,5],[41,5],[66,5],[148,5],[202,5],[216,5],[347,5]]},"1515":{"position":[[169,5],[183,5]]},"1665":{"position":[[603,5]]},"1782":{"position":[[2543,5]]}}}],["lffl_{ff}lff",{"_index":2171,"t":{"598":{"position":[[1946,13],[2261,13]]}}}],["lff⊙γ(w1x))w2(l_{ff",{"_index":2165,"t":{"598":{"position":[[1776,21]]}}}],["lhidden=∑k∈s∣∑(xi,yi)∈sk",{"_index":4170,"t":{"1244":{"position":[[1378,24]]}}}],["li",{"_index":1765,"t":{"504":{"position":[[185,3],[309,3]]},"681":{"position":[[765,2]]},"1126":{"position":[[1207,2],[1885,2]]},"1347":{"position":[[318,3]]},"1362":{"position":[[171,2]]},"1367":{"position":[[383,2]]},"1379":{"position":[[1032,3]]},"1494":{"position":[[504,3]]}}}],["liang",{"_index":2450,"t":{"681":{"position":[[772,6]]},"851":{"position":[[1151,5]]},"868":{"position":[[191,6]]},"1126":{"position":[[1214,6],[1892,6]]},"1347":{"position":[[326,6]]},"1362":{"position":[[178,6]]},"1367":{"position":[[390,6]]},"1379":{"position":[[1040,6]]},"1475":{"position":[[332,5]]},"1481":{"position":[[135,5]]},"1494":{"position":[[512,6]]}}}],["librari",{"_index":4842,"t":{"1496":{"position":[[38,7]]}}}],["light",{"_index":4350,"t":{"1341":{"position":[[1203,5]]}}}],["lightweight",{"_index":1065,"t":{"234":{"position":[[90,11],[119,11]]},"692":{"position":[[411,11]]},"1147":{"position":[[1009,11]]},"1153":{"position":[[330,11]]},"1291":{"position":[[304,11],[947,11]]},"1317":{"position":[[95,11]]}}}],["lignuist",{"_index":5551,"t":{"1762":{"position":[[622,10]]}}}],["likelihood",{"_index":628,"t":{"132":{"position":[[731,10]]},"140":{"position":[[33,10]]},"236":{"position":[[347,12]]},"246":{"position":[[237,10]]},"253":{"position":[[131,10]]},"1128":{"position":[[537,10],[1345,10]]},"1141":{"position":[[297,10]]},"1167":{"position":[[1292,10]]},"1300":{"position":[[111,10]]},"1477":{"position":[[719,10]]},"1546":{"position":[[991,10],[1181,10]]},"1720":{"position":[[698,10]]},"1730":{"position":[[737,10]]}}}],["lil_ili",{"_index":2666,"t":{"751":{"position":[[225,8]]}}}],["limit",{"_index":9,"t":{"3":{"position":[[81,5]]},"483":{"position":[[242,7]]},"592":{"position":[[194,7],[408,7]]},"594":{"position":[[0,7]]},"628":{"position":[[1063,7]]},"630":{"position":[[623,7]]},"709":{"position":[[211,7],[289,7],[452,7]]},"1008":{"position":[[260,12]]},"1087":{"position":[[113,11]]},"1132":{"position":[[585,6]]},"1382":{"position":[[187,7]]},"1419":{"position":[[1071,5]]}}}],["line",{"_index":138,"t":{"19":{"position":[[408,6]]},"510":{"position":[[225,4]]}}}],["linear",{"_index":262,"t":{"49":{"position":[[375,6]]},"91":{"position":[[510,6],[1110,6],[1477,9]]},"108":{"position":[[196,6]]},"112":{"position":[[363,6]]},"116":{"position":[[319,6]]},"234":{"position":[[163,9]]},"300":{"position":[[115,6]]},"304":{"position":[[124,6],[312,6]]},"306":{"position":[[186,6],[273,6]]},"308":{"position":[[818,6]]},"317":{"position":[[495,6]]},"498":{"position":[[469,6],[773,6]]},"500":{"position":[[770,6]]},"525":{"position":[[159,6]]},"527":{"position":[[398,6],[621,6]]},"602":{"position":[[407,6]]},"630":{"position":[[383,6],[902,6],[2000,6]]},"646":{"position":[[208,6]]},"666":{"position":[[196,6]]},"789":{"position":[[799,6]]},"866":{"position":[[859,6]]},"893":{"position":[[448,6],[2241,6]]},"934":{"position":[[1769,6]]},"945":{"position":[[387,6],[453,6],[561,6]]},"961":{"position":[[186,6]]},"988":{"position":[[1365,6]]},"1045":{"position":[[114,6]]},"1052":{"position":[[134,6],[210,6]]},"1174":{"position":[[41,9],[94,6]]},"1185":{"position":[[447,6],[663,6]]},"1195":{"position":[[537,11]]},"1291":{"position":[[996,10]]},"1294":{"position":[[129,10]]},"1314":{"position":[[180,6]]},"1319":{"position":[[289,10]]},"1352":{"position":[[256,6]]},"1364":{"position":[[71,6],[440,6]]},"1384":{"position":[[1417,6]]},"1646":{"position":[[460,6]]},"1665":{"position":[[1378,6]]},"1674":{"position":[[429,6]]}}}],["linearli",{"_index":1209,"t":{"300":{"position":[[216,8]]},"841":{"position":[[457,8]]},"1111":{"position":[[1195,8]]},"1496":{"position":[[494,8]]}}}],["linguist",{"_index":1938,"t":{"531":{"position":[[141,11]]},"1393":{"position":[[12,10]]},"1646":{"position":[[48,11]]},"1762":{"position":[[419,10]]}}}],["link",{"_index":5095,"t":{"1620":{"position":[[17,5]]},"1653":{"position":[[366,9]]}}}],["links](./hello.md",{"_index":5094,"t":{"1618":{"position":[[219,19]]}}}],["lipani",{"_index":3736,"t":{"1084":{"position":[[319,7]]}}}],["list",{"_index":11,"t":{"3":{"position":[[109,4]]},"466":{"position":[[449,4]]},"979":{"position":[[1097,4]]},"1431":{"position":[[448,4]]}}}],["liu",{"_index":1952,"t":{"531":{"position":[[429,3]]},"683":{"position":[[168,4]]},"1347":{"position":[[361,3]]},"1367":{"position":[[365,4]]},"1494":{"position":[[286,4]]}}}],["ljoint\\mathcal{l}_{\\text{joint}}ljoint",{"_index":5303,"t":{"1657":{"position":[[3171,39]]}}}],["ljxi,jl_j",{"_index":2155,"t":{"598":{"position":[[1093,9]]}}}],["lk<n−l",{"_index":3422,"t":{"934":{"position":[[1445,6]]}}}],["lkd=dkl(ps∣∣pt)\\begin{equ",{"_index":3235,"t":{"861":{"position":[[1762,31]]}}}],["lkd\\mathcal{l}_{\\text{kd}}lkd",{"_index":3234,"t":{"861":{"position":[[1723,30]]}}}],["lkl_klk",{"_index":2169,"t":{"598":{"position":[[1925,9],[2240,9]]}}}],["lk⋅l",{"_index":4408,"t":{"1352":{"position":[[1361,4]]}}}],["ll",{"_index":2332,"t":{"658":{"position":[[2311,3]]},"662":{"position":[[974,3]]},"723":{"position":[[1065,3]]},"733":{"position":[[512,3]]},"741":{"position":[[117,3]]},"786":{"position":[[1947,3]]},"791":{"position":[[440,3]]},"795":{"position":[[511,3]]},"1067":{"position":[[415,3]]},"1387":{"position":[[143,3]]}}}],["llama",{"_index":2246,"t":{"628":{"position":[[20,5]]},"681":{"position":[[56,6]]},"885":{"position":[[0,5],[16,5],[123,5],[154,5],[403,5],[470,5]]},"887":{"position":[[81,5],[188,5],[207,5],[319,5],[353,5],[581,5],[645,5],[919,5]]},"891":{"position":[[71,5],[323,5]]},"893":{"position":[[1598,5],[2013,5],[2542,5]]},"895":{"position":[[22,5],[1115,5]]},"905":{"position":[[88,5],[266,5]]},"907":{"position":[[9,5],[118,5]]},"909":{"position":[[77,5],[153,5]]},"912":{"position":[[194,5]]},"914":{"position":[[0,5],[64,5],[241,5]]},"919":{"position":[[23,5]]},"921":{"position":[[107,5]]},"928":{"position":[[0,5],[168,5]]},"932":{"position":[[3,5],[175,5],[195,5],[283,5],[688,5],[804,5],[825,5],[844,5]]},"934":{"position":[[121,5],[175,5],[246,5],[512,5],[543,5],[563,5],[780,5],[961,5],[1279,5],[1368,5],[1783,5],[2099,5],[2298,5]]},"938":{"position":[[64,5],[80,5],[144,5],[254,5],[410,5],[434,5]]},"940":{"position":[[278,5]]},"942":{"position":[[0,5],[199,5]]},"945":{"position":[[0,5],[73,5],[326,5],[512,5],[912,5],[938,5]]},"949":{"position":[[8,5],[105,5]]},"951":{"position":[[357,5]]},"953":{"position":[[117,5],[285,5],[425,5]]},"955":{"position":[[77,5],[637,5]]},"959":{"position":[[0,5]]},"961":{"position":[[28,5],[252,5]]},"963":{"position":[[50,5],[69,5],[125,5],[528,5]]},"965":{"position":[[0,5],[86,5],[204,5]]},"967":{"position":[[0,5],[166,5],[363,5],[484,5],[500,5],[546,5],[572,5]]},"971":{"position":[[127,5]]},"973":{"position":[[62,5]]}}}],["llava",{"_index":3419,"t":{"934":{"position":[[339,5]]},"951":{"position":[[33,5]]},"955":{"position":[[11,5]]},"959":{"position":[[125,5]]},"973":{"position":[[462,5]]}}}],["lll",{"_index":635,"t":{"132":{"position":[[940,4]]},"170":{"position":[[424,3]]},"358":{"position":[[214,3]]},"504":{"position":[[607,3]]},"527":{"position":[[482,3]]},"598":{"position":[[1982,3],[2086,3]]},"753":{"position":[[266,3]]},"789":{"position":[[25,3]]},"857":{"position":[[537,3]]},"873":{"position":[[313,3],[426,3],[530,3],[562,3],[847,3],[1468,3],[1484,3]]},"891":{"position":[[202,3],[390,3],[514,3]]},"893":{"position":[[119,3],[207,3],[2207,3]]},"895":{"position":[[786,3],[833,3]]},"899":{"position":[[45,3]]},"934":{"position":[[1325,3]]},"953":{"position":[[450,3]]},"1065":{"position":[[414,3]]},"1067":{"position":[[1132,3]]},"1070":{"position":[[851,3]]},"1238":{"position":[[739,4]]},"1350":{"position":[[494,3]]},"1352":{"position":[[1392,3]]},"1384":{"position":[[1290,3]]},"1395":{"position":[[2210,3]]},"1477":{"position":[[87,3]]}}}],["lll=1",{"_index":1767,"t":{"504":{"position":[[628,11]]}}}],["lllth",{"_index":3179,"t":{"857":{"position":[[619,5],[767,5]]}}}],["llm",{"_index":1398,"t":{"336":{"position":[[499,3]]},"382":{"position":[[63,3],[181,3]]},"384":{"position":[[162,3],[357,3],[1163,3]]},"397":{"position":[[4,3]]},"399":{"position":[[196,3],[268,3]]},"426":{"position":[[364,3],[561,3]]},"434":{"position":[[21,6],[128,3],[282,3],[359,3],[378,3],[456,3],[641,3],[699,4],[745,4]]},"436":{"position":[[312,4],[447,4],[474,4],[661,3],[837,3],[860,3],[911,3],[971,3],[1033,3],[1171,3],[1290,4],[1534,3],[2112,3],[2174,3]]},"441":{"position":[[0,4],[58,4],[151,3],[351,3]]},"443":{"position":[[97,4],[370,3],[429,4],[460,4]]},"445":{"position":[[154,3],[443,3]]},"447":{"position":[[0,3],[73,4],[105,4],[157,4],[214,4],[459,3],[500,3],[576,3],[796,3],[859,3],[890,4]]},"455":{"position":[[765,3],[1000,3]]},"457":{"position":[[61,3],[367,3],[458,3]]},"459":{"position":[[86,3],[517,3],[584,3]]},"466":{"position":[[289,4],[357,4],[395,4]]},"468":{"position":[[47,3]]},"471":{"position":[[32,4],[94,3]]},"473":{"position":[[0,4],[195,3],[235,3],[274,4]]},"477":{"position":[[25,3],[116,4]]},"483":{"position":[[8,4],[351,4],[649,4]]},"485":{"position":[[0,4],[234,3],[1257,4],[1414,3]]},"488":{"position":[[56,4]]},"504":{"position":[[110,3]]},"622":{"position":[[686,3]]},"626":{"position":[[22,6],[250,4],[326,4]]},"628":{"position":[[28,4],[606,4],[846,4],[900,3],[1025,3],[1148,4],[1187,3],[1234,3],[1257,3],[1353,3],[1458,4],[1546,3]]},"630":{"position":[[189,3],[324,3],[492,3],[591,3],[650,3],[728,3],[857,3],[928,3],[1077,3],[1124,3],[1200,3],[2152,3],[2254,3],[2290,3],[2310,3]]},"633":{"position":[[404,3],[503,3],[1026,3]]},"635":{"position":[[34,3],[116,3]]},"638":{"position":[[27,3],[37,3]]},"640":{"position":[[33,3],[233,3],[316,3],[418,3],[445,3],[497,3]]},"642":{"position":[[104,3]]},"644":{"position":[[389,3],[460,3]]},"646":{"position":[[69,3],[97,3]]},"648":{"position":[[44,3],[179,3],[818,3],[917,3],[1079,3],[1110,3]]},"650":{"position":[[15,3],[85,3],[153,3]]},"652":{"position":[[18,3]]},"683":{"position":[[636,3]]},"719":{"position":[[37,3]]},"780":{"position":[[0,3]]},"887":{"position":[[0,3]]},"909":{"position":[[162,3]]},"921":{"position":[[0,3]]},"932":{"position":[[19,4],[347,3]]},"934":{"position":[[3,3],[1932,3]]},"945":{"position":[[109,3]]},"947":{"position":[[226,3]]},"951":{"position":[[234,3]]},"955":{"position":[[37,3]]},"959":{"position":[[63,3]]},"967":{"position":[[248,3]]},"973":{"position":[[165,3]]},"979":{"position":[[0,4],[1660,3]]},"1008":{"position":[[444,3]]},"1060":{"position":[[482,6]]},"1062":{"position":[[1000,4],[1503,4],[1789,4]]},"1082":{"position":[[346,4]]},"1095":{"position":[[17,3]]},"1117":{"position":[[511,3]]},"1120":{"position":[[185,3]]},"1126":{"position":[[0,3],[2480,3]]},"1162":{"position":[[386,3]]},"1225":{"position":[[107,5]]},"1291":{"position":[[1463,3]]},"1434":{"position":[[88,3]]},"1440":{"position":[[3,4]]},"1442":{"position":[[8,3],[56,4],[409,3],[963,4],[1205,3],[1440,3],[1986,3],[2029,3]]},"1447":{"position":[[56,3]]},"1449":{"position":[[527,3]]},"1451":{"position":[[0,3]]},"1453":{"position":[[391,3]]},"1455":{"position":[[241,3],[730,3]]}}}],["llm=−1t∑tlog⁡p(yt∣x,y<t)l_{lm",{"_index":2094,"t":{"596":{"position":[[111,30]]}}}],["llml_{\\text{lm}}llm",{"_index":2135,"t":{"596":{"position":[[2270,21],[2441,20]]},"602":{"position":[[222,21]]}}}],["lln=−log⁡exp⁡(β(x,y))exp⁡(β(x,y))+∑n=1nexp⁡(β(x,y^(n)))\\begin{equ",{"_index":2127,"t":{"596":{"position":[[1972,71]]}}}],["llnl_{\\text{ln}}lln",{"_index":2136,"t":{"596":{"position":[[2315,20]]},"602":{"position":[[332,20]]}}}],["llogit=∑k∈s∣∑(xi,yi)∈skkl",{"_index":4153,"t":{"1244":{"position":[[756,25]]}}}],["lm",{"_index":989,"t":{"215":{"position":[[667,2]]},"384":{"position":[[4,2],[437,2]]},"386":{"position":[[485,2]]},"388":{"position":[[0,2],[48,2]]},"409":{"position":[[531,2]]},"424":{"position":[[475,2]]},"426":{"position":[[112,2]]},"430":{"position":[[16,2],[155,2]]},"483":{"position":[[550,2]]},"496":{"position":[[266,2]]},"502":{"position":[[420,2]]},"523":{"position":[[100,2]]},"525":{"position":[[740,2]]},"527":{"position":[[1385,4]]},"529":{"position":[[1339,2]]},"531":{"position":[[221,2]]},"533":{"position":[[434,2]]},"567":{"position":[[410,2]]},"569":{"position":[[957,2]]},"577":{"position":[[99,3],[128,2]]},"581":{"position":[[0,2]]},"587":{"position":[[63,4]]},"589":{"position":[[12,2],[90,2],[170,2]]},"596":{"position":[[16,2],[84,2]]},"606":{"position":[[207,3],[406,2]]},"608":{"position":[[124,2]]},"648":{"position":[[85,2]]},"652":{"position":[[53,2]]},"717":{"position":[[428,4]]},"723":{"position":[[51,2],[100,2]]},"733":{"position":[[136,2]]},"786":{"position":[[248,2]]},"977":{"position":[[539,2]]},"979":{"position":[[366,2],[1225,2]]},"982":{"position":[[760,2]]},"984":{"position":[[378,2],[452,2]]},"986":{"position":[[706,2]]},"994":{"position":[[97,2],[485,2],[567,2]]},"1002":{"position":[[216,2]]},"1006":{"position":[[29,2],[135,2],[245,2],[345,2]]},"1008":{"position":[[161,2]]},"1012":{"position":[[31,4]]},"1014":{"position":[[12,2],[291,2],[335,2],[399,2],[512,2],[1270,2]]},"1019":{"position":[[0,2],[46,2],[468,2]]},"1037":{"position":[[19,2]]},"1052":{"position":[[36,2],[225,2]]},"1060":{"position":[[64,4]]},"1062":{"position":[[51,3]]},"1087":{"position":[[361,3]]},"1093":{"position":[[137,4],[1045,2],[1539,2],[1679,2],[1808,2]]},"1099":{"position":[[12,2],[877,2]]},"1101":{"position":[[625,2]]},"1105":{"position":[[38,2],[214,2]]},"1109":{"position":[[222,2],[316,2],[711,2],[756,2],[828,2],[1273,2]]},"1115":{"position":[[322,2],[391,2]]},"1120":{"position":[[344,2]]},"1124":{"position":[[68,4]]},"1126":{"position":[[1362,2],[1466,2],[1523,2],[2065,2]]},"1132":{"position":[[1434,2],[1491,2],[1673,2]]},"1134":{"position":[[178,2]]},"1143":{"position":[[290,2],[370,2],[506,2],[1087,2]]},"1145":{"position":[[1010,2],[1558,2],[2104,2]]},"1147":{"position":[[7,2]]},"1149":{"position":[[218,2],[316,2]]},"1153":{"position":[[35,2]]},"1159":{"position":[[1445,2]]},"1178":{"position":[[183,2]]},"1185":{"position":[[54,2]]},"1232":{"position":[[177,2],[293,2]]},"1238":{"position":[[19,2],[957,2]]},"1289":{"position":[[111,4],[266,2],[356,2]]},"1291":{"position":[[121,2],[177,2],[211,2],[344,2],[448,2],[625,2],[793,2],[1250,2],[1389,2]]},"1296":{"position":[[599,2]]},"1300":{"position":[[84,2]]},"1303":{"position":[[32,2],[71,2],[158,2],[241,2],[623,2]]},"1305":{"position":[[31,2],[973,2]]},"1323":{"position":[[662,2]]},"1332":{"position":[[430,2]]},"1339":{"position":[[160,2]]},"1341":{"position":[[91,2],[134,2],[470,2],[574,2],[755,2],[794,3]]},"1419":{"position":[[258,3]]},"1546":{"position":[[26,5]]},"1693":{"position":[[340,2],[491,3]]},"1695":{"position":[[423,4],[629,2],[680,2],[864,2],[1013,2],[1198,2]]},"1704":{"position":[[0,2],[392,2],[706,2]]},"1708":{"position":[[61,2],[116,2],[491,2]]},"1712":{"position":[[102,2],[166,2]]},"1714":{"position":[[76,2]]},"1716":{"position":[[265,2]]},"1718":{"position":[[1063,2],[1187,2]]},"1720":{"position":[[20,2],[64,2],[195,2],[396,2],[666,2],[976,2],[1220,2],[2355,2]]},"1724":{"position":[[63,2]]},"1728":{"position":[[731,2]]},"1730":{"position":[[1190,2]]},"1732":{"position":[[199,2]]},"1736":{"position":[[1653,2]]},"1738":{"position":[[49,2],[428,2]]},"1748":{"position":[[65,3],[151,2]]},"1750":{"position":[[36,2],[164,2],[285,2],[353,2]]},"1752":{"position":[[47,2]]},"1754":{"position":[[6,2],[133,2],[232,2]]},"1756":{"position":[[13,2],[53,2],[235,2],[609,2]]},"1758":{"position":[[30,2]]},"1762":{"position":[[65,2],[114,2],[455,2],[599,2]]},"1764":{"position":[[70,2],[245,2]]},"1766":{"position":[[191,2],[356,2]]},"1768":{"position":[[138,2]]},"1770":{"position":[[417,2],[562,2],[718,2]]},"1772":{"position":[[478,3]]},"1774":{"position":[[106,2],[350,2],[415,2],[485,2],[582,2]]},"1778":{"position":[[226,3],[848,2]]},"1780":{"position":[[54,2],[160,2]]},"1782":{"position":[[627,2],[1266,2],[2150,2],[2257,2],[2413,2],[2480,2]]},"1786":{"position":[[4,3],[84,2]]},"1790":{"position":[[156,3]]},"1792":{"position":[[8,4]]},"1800":{"position":[[66,3]]},"1802":{"position":[[77,3],[171,3],[257,3],[911,3]]}}}],["lm'",{"_index":3851,"t":{"1109":{"position":[[1044,4]]}}}],["ln",{"_index":438,"t":{"91":{"position":[[1405,4],[2156,4]]},"696":{"position":[[1562,2]]}}}],["load",{"_index":3467,"t":{"979":{"position":[[1237,6]]},"992":{"position":[[1046,7]]},"1062":{"position":[[730,4]]},"1354":{"position":[[82,4],[178,4]]}}}],["local",{"_index":129,"t":{"19":{"position":[[262,7]]},"86":{"position":[[380,8]]},"93":{"position":[[6,9]]},"102":{"position":[[361,12]]},"116":{"position":[[842,12]]},"153":{"position":[[533,5]]},"157":{"position":[[379,9]]},"168":{"position":[[248,10]]},"523":{"position":[[555,8]]},"533":{"position":[[14,10]]},"801":{"position":[[2272,5]]},"857":{"position":[[93,5]]},"870":{"position":[[67,5],[246,5]]},"873":{"position":[[290,5]]},"1101":{"position":[[290,5]]},"1151":{"position":[[1727,8]]},"1462":{"position":[[115,5]]},"1600":{"position":[[27,8]]},"1632":{"position":[[54,7],[131,8]]},"1636":{"position":[[30,7],[57,6],[72,9],[219,6]]},"1638":{"position":[[47,6],[221,6]]},"1640":{"position":[[31,7],[58,6],[106,7]]}}}],["localedropdown",{"_index":5149,"t":{"1638":{"position":[[184,17]]}}}],["localhost:3000",{"_index":5074,"t":{"1610":{"position":[[91,15]]}}}],["localhost:3000/foo",{"_index":5076,"t":{"1610":{"position":[[126,18]]}}}],["localhost:3000/foo/bar",{"_index":5078,"t":{"1610":{"position":[[168,22]]}}}],["localis",{"_index":1671,"t":{"457":{"position":[[756,12]]}}}],["locat",{"_index":56,"t":{"7":{"position":[[327,6]]},"1728":{"position":[[586,10]]}}}],["location/c",{"_index":5304,"t":{"1659":{"position":[[143,15]]}}}],["location/lake_sea_ocean",{"_index":5307,"t":{"1659":{"position":[[264,25]]}}}],["log",{"_index":631,"t":{"132":{"position":[[826,4]]},"236":{"position":[[151,3],[186,4],[217,3]]},"246":{"position":[[233,3]]},"253":{"position":[[127,3]]},"569":{"position":[[429,3],[545,3]]},"594":{"position":[[1127,3]]},"596":{"position":[[164,4],[587,4],[1695,3],[1793,4],[1952,3],[2062,4]]},"630":{"position":[[1488,4]]},"723":{"position":[[559,4],[1252,4]]},"1065":{"position":[[742,4]]},"1067":{"position":[[876,4]]},"1162":{"position":[[303,4]]},"1164":{"position":[[356,4]]},"1167":{"position":[[1288,3],[1413,4]]},"1238":{"position":[[883,4]]},"1300":{"position":[[107,3],[250,4],[332,4]]},"1350":{"position":[[388,4],[714,4]]},"1477":{"position":[[810,4]]},"1540":{"position":[[107,4]]},"1546":{"position":[[987,3],[1177,3]]},"1657":{"position":[[2941,4],[3015,4]]},"1720":{"position":[[478,4],[694,3]]}}}],["log(\\pi^{rl}_\\phi(i",{"_index":4952,"t":{"1558":{"position":[[1574,20]]}}}],["loger",{"_index":4005,"t":{"1164":{"position":[[566,5]]}}}],["logist",{"_index":5500,"t":{"1730":{"position":[[858,8],[896,8]]}}}],["logit",{"_index":3545,"t":{"988":{"position":[[1827,5]]},"1145":{"position":[[1081,5]]},"1244":{"position":[[1287,5]]},"1275":{"position":[[127,6],[346,6]]},"1296":{"position":[[1035,6]]}}}],["logo](./img/docusaurus.png",{"_index":5103,"t":{"1622":{"position":[[342,27]]}}}],["logo](/img/docusaurus.png",{"_index":5100,"t":{"1622":{"position":[[152,26]]}}}],["logpϕ​(i",{"_index":4280,"t":{"1300":{"position":[[384,8]]}}}],["log⁡pϕ(i",{"_index":4271,"t":{"1300":{"position":[[167,8]]}}}],["long",{"_index":2,"t":{"3":{"position":[[30,4]]},"308":{"position":[[1006,4]]},"310":{"position":[[434,4],[474,4],[724,4],[1113,4]]},"735":{"position":[[129,4]]},"949":{"position":[[28,4]]},"951":{"position":[[290,4]]},"1008":{"position":[[589,4]]},"1143":{"position":[[440,4]]},"1159":{"position":[[1063,4]]},"1303":{"position":[[1036,4]]},"1345":{"position":[[87,4],[424,4]]},"1367":{"position":[[680,4]]},"1442":{"position":[[1085,4]]},"1453":{"position":[[36,4],[91,4],[264,4]]},"1462":{"position":[[145,4]]},"1782":{"position":[[2807,4]]},"1790":{"position":[[91,4]]}}}],["long.346.pdf",{"_index":4580,"t":{"1405":{"position":[[48,12]]}}}],["long.35.pdf",{"_index":3079,"t":{"845":{"position":[[48,11]]}}}],["long.353.pdf",{"_index":4230,"t":{"1287":{"position":[[48,12]]}}}],["long.433.pdf",{"_index":4442,"t":{"1375":{"position":[[48,12]]}}}],["longer",{"_index":2559,"t":{"709":{"position":[[1499,6]]},"1060":{"position":[[321,6]]},"1141":{"position":[[497,6]]},"1151":{"position":[[1545,6]]},"1326":{"position":[[0,6]]},"1345":{"position":[[239,6]]},"1347":{"position":[[749,6],[840,6],[1050,6]]},"1423":{"position":[[274,6],[346,6]]},"1724":{"position":[[361,6]]}}}],["longest",{"_index":1296,"t":{"310":{"position":[[1546,7]]}}}],["look",{"_index":4983,"t":{"1581":{"position":[[157,4]]}}}],["loop",{"_index":4968,"t":{"1570":{"position":[[41,4],[74,4]]}}}],["loos",{"_index":5365,"t":{"1672":{"position":[[362,5],[385,5]]}}}],["lora",{"_index":2189,"t":{"598":{"position":[[3613,4]]},"626":{"position":[[101,4]]},"628":{"position":[[349,4]]},"630":{"position":[[260,5],[1948,5]]},"633":{"position":[[888,5]]},"635":{"position":[[70,4],[84,4]]},"648":{"position":[[442,4]]},"717":{"position":[[71,4],[261,4],[366,4],[482,4]]},"719":{"position":[[527,6],[709,4],[770,4],[789,4],[840,4],[974,4],[1257,4]]},"721":{"position":[[321,4]]},"723":{"position":[[0,4]]},"735":{"position":[[28,4]]},"741":{"position":[[361,4]]},"743":{"position":[[28,4]]},"757":{"position":[[114,4],[281,4]]},"759":{"position":[[11,4]]},"761":{"position":[[58,4]]},"763":{"position":[[0,4]]},"768":{"position":[[0,4],[94,4]]},"772":{"position":[[19,4]]},"780":{"position":[[44,4],[158,4],[214,4],[230,4]]},"786":{"position":[[1557,4],[2205,4],[2348,4],[2621,4],[3093,4],[3307,4]]},"791":{"position":[[0,4],[727,4],[953,4]]},"795":{"position":[[1483,4],[1819,4]]},"807":{"position":[[107,4],[329,4],[379,4]]},"809":{"position":[[611,4],[824,4],[866,4],[1003,4]]},"814":{"position":[[226,4]]},"821":{"position":[[232,4]]},"835":{"position":[[21,4],[238,4],[299,4]]},"839":{"position":[[123,4],[208,4],[437,4]]},"947":{"position":[[311,4]]},"1062":{"position":[[1824,5]]},"1067":{"position":[[695,4]]},"1070":{"position":[[679,4]]},"1073":{"position":[[72,4]]},"1379":{"position":[[1053,4]]},"1384":{"position":[[3051,5],[3091,4],[3129,4],[3837,4]]},"1389":{"position":[[982,4],[2048,4]]},"1393":{"position":[[707,5],[1049,4]]},"1395":{"position":[[2401,5],[2575,4],[2809,4],[2900,4],[2930,4]]}}}],["loraregu_{\\text{regu}}regu",{"_index":3072,"t":{"839":{"position":[[178,27]]}}}],["lorber",{"_index":5016,"t":{"1587":{"position":[[275,6]]}}}],["lorem",{"_index":13,"t":{"3":{"position":[[120,5],[272,5],[299,5],[451,5],[478,5],[630,5],[657,5],[809,5],[836,5],[988,5],[1015,5],[1167,5],[1194,5],[1346,5],[1373,5],[1525,5],[1552,5],[1704,5],[1731,5],[1883,5],[1910,5],[2062,5],[2089,5],[2241,5],[2268,5],[2420,5],[2447,5],[2599,5],[2626,5],[2778,5],[2805,5],[2957,5]]},"5":{"position":[[0,5],[152,5]]}}}],["lose",{"_index":4774,"t":{"1468":{"position":[[1005,6],[1056,6],[1114,6]]}}}],["loshchilov",{"_index":1803,"t":{"517":{"position":[[1026,11]]}}}],["loss",{"_index":319,"t":{"58":{"position":[[216,4]]},"124":{"position":[[97,4],[469,4]]},"126":{"position":[[557,4],[613,4]]},"130":{"position":[[270,4]]},"132":{"position":[[1000,4]]},"138":{"position":[[141,4]]},"149":{"position":[[391,4]]},"153":{"position":[[264,4]]},"155":{"position":[[246,4],[630,4]]},"159":{"position":[[148,4]]},"174":{"position":[[2499,4]]},"177":{"position":[[220,6],[237,4],[652,4],[665,4],[680,4]]},"244":{"position":[[395,4]]},"249":{"position":[[17,4]]},"358":{"position":[[1249,4]]},"525":{"position":[[256,4]]},"589":{"position":[[1954,4]]},"596":{"position":[[70,4],[106,4],[1643,4],[1895,4],[2362,4],[2514,4]]},"602":{"position":[[217,4],[281,4],[327,4]]},"608":{"position":[[749,4]]},"622":{"position":[[374,4]]},"658":{"position":[[69,4]]},"786":{"position":[[4226,4]]},"801":{"position":[[39,4],[1221,4]]},"861":{"position":[[660,4],[895,4],[1674,4],[1718,4]]},"881":{"position":[[457,4]]},"919":{"position":[[219,4],[272,4]]},"992":{"position":[[381,4]]},"1065":{"position":[[647,4],[825,4]]},"1067":{"position":[[776,4]]},"1099":{"position":[[1829,4]]},"1134":{"position":[[676,4]]},"1185":{"position":[[740,4]]},"1187":{"position":[[451,4]]},"1238":{"position":[[798,4]]},"1244":{"position":[[748,4],[1370,4],[1828,4],[1972,4],[2307,6],[2339,4]]},"1246":{"position":[[267,4],[819,4]]},"1259":{"position":[[203,4]]},"1273":{"position":[[438,4]]},"1275":{"position":[[79,4],[224,4],[235,4],[275,4],[296,4],[312,4],[385,4]]},"1326":{"position":[[172,4]]},"1485":{"position":[[770,4]]},"1558":{"position":[[358,4],[618,4],[1051,4],[1978,4]]},"1657":{"position":[[2613,4]]},"1695":{"position":[[596,4]]}}}],["loss(θ)=−1(k2)e(x,yw,yl)∼d[log",{"_index":4932,"t":{"1558":{"position":[[640,32]]}}}],["lotteri",{"_index":1957,"t":{"531":{"position":[[672,7]]},"849":{"position":[[810,7]]},"851":{"position":[[910,7]]},"879":{"position":[[368,7]]},"1466":{"position":[[331,7]]},"1468":{"position":[[473,7],[812,7]]},"1475":{"position":[[0,7],[148,7],[176,7],[307,7]]},"1477":{"position":[[1131,7]]}}}],["louizo",{"_index":3098,"t":{"851":{"position":[[621,8]]},"868":{"position":[[63,8]]}}}],["love",{"_index":5408,"t":{"1698":{"position":[[365,4]]},"1702":{"position":[[325,4],[400,4]]}}}],["low",{"_index":959,"t":{"213":{"position":[[6,3],[319,3]]},"215":{"position":[[187,3],[620,3],[1187,3],[1471,3]]},"221":{"position":[[561,3]]},"227":{"position":[[238,3]]},"598":{"position":[[3282,3],[3501,3],[3641,3]]},"628":{"position":[[383,3]]},"633":{"position":[[932,3]]},"648":{"position":[[487,3]]},"709":{"position":[[11,3],[59,3]]},"717":{"position":[[50,3]]},"719":{"position":[[389,3],[507,3],[721,3],[1119,3]]},"733":{"position":[[141,4],[318,3]]},"784":{"position":[[932,3]]},"786":{"position":[[1337,3],[1623,3],[3283,3],[4578,3]]},"803":{"position":[[9,3]]},"828":{"position":[[27,3]]},"833":{"position":[[266,3]]},"847":{"position":[[781,3]]},"849":{"position":[[1645,3],[1679,3]]},"853":{"position":[[2481,3]]},"864":{"position":[[67,3]]},"866":{"position":[[493,3]]},"949":{"position":[[587,3]]},"1060":{"position":[[879,3]]},"1062":{"position":[[1115,3],[1138,3]]},"1067":{"position":[[292,3],[439,3],[1414,3]]},"1070":{"position":[[1043,3],[1822,3]]},"1080":{"position":[[195,3],[459,3]]},"1084":{"position":[[193,3],[1144,3]]},"1087":{"position":[[188,3]]},"1143":{"position":[[992,3]]},"1225":{"position":[[483,3]]},"1227":{"position":[[976,3],[1183,3]]},"1240":{"position":[[179,3],[347,3]]},"1242":{"position":[[788,3],[895,3]]},"1246":{"position":[[635,3]]},"1289":{"position":[[585,3]]},"1321":{"position":[[92,3],[202,3],[274,3],[443,3]]},"1332":{"position":[[90,3]]},"1334":{"position":[[330,3]]},"1341":{"position":[[876,3]]},"1384":{"position":[[1042,3],[3146,3]]},"1393":{"position":[[257,3]]},"1395":{"position":[[386,3],[1936,3]]},"1397":{"position":[[0,3],[582,3],[1217,3]]},"1427":{"position":[[227,3]]},"1468":{"position":[[1439,3]]},"1487":{"position":[[779,3]]},"1492":{"position":[[27,3]]},"1501":{"position":[[10,3]]},"1505":{"position":[[355,3],[780,3]]}}}],["lower",{"_index":2052,"t":{"587":{"position":[[444,5]]},"622":{"position":[[297,5]]},"630":{"position":[[985,5]]},"658":{"position":[[1244,5]]},"676":{"position":[[469,5],[707,5]]},"786":{"position":[[3624,5]]},"1084":{"position":[[1160,5]]}}}],["lpaqa",{"_index":3848,"t":{"1109":{"position":[[111,5]]}}}],["lpl_plp",{"_index":2665,"t":{"751":{"position":[[207,8]]}}}],["lplm=∑k∈∣s∣lplmk\\mathcal{l}_{plm",{"_index":4185,"t":{"1244":{"position":[[2172,33]]}}}],["lplm=−∑ilog⁡p(yi∣xi",{"_index":4123,"t":{"1238":{"position":[[825,19]]}}}],["lpt=−∑ilog⁡p(yi∣[p,wi];θ),\\begin{equ",{"_index":3671,"t":{"1065":{"position":[[671,42]]}}}],["lr",{"_index":295,"t":{"53":{"position":[[224,3]]},"63":{"position":[[141,3]]},"80":{"position":[[21,3]]},"143":{"position":[[533,2]]},"372":{"position":[[4,2],[105,2]]},"517":{"position":[[652,7]]}}}],["lrate",{"_index":1324,"t":{"317":{"position":[[240,5]]}}}],["lrate=dmodel−0.5⋅min⁡(step_num−0.5,step_num⋅warmup_steps−1.5)\\begin{equ",{"_index":1323,"t":{"317":{"position":[[162,77]]}}}],["ls=0.1\\epsilon_{l",{"_index":1341,"t":{"319":{"position":[[293,20]]}}}],["lst",{"_index":3593,"t":{"1002":{"position":[[722,5]]},"1070":{"position":[[684,3],[1271,5]]},"1073":{"position":[[79,3]]},"1230":{"position":[[347,3]]}}}],["lstage1=lretrieve+lbox+lmaskboxinst(2)l_{\\textup{stage1",{"_index":873,"t":{"177":{"position":[[261,57]]}}}],["lstage2=lretrieve+lbox+lmask(3)l_{\\textup{stage2",{"_index":884,"t":{"177":{"position":[[805,50]]}}}],["lstage3=lretrieve+lbox+lmask+lembed(4)l_{\\textup{stage3",{"_index":899,"t":{"177":{"position":[[1421,57]]}}}],["lstm",{"_index":1145,"t":{"285":{"position":[[6,4]]},"1101":{"position":[[561,4],[996,4],[1058,4],[1137,4]]},"1189":{"position":[[216,4]]},"1195":{"position":[[83,5]]},"1665":{"position":[[129,4]]}}}],["lstm(hi:m",{"_index":3824,"t":{"1101":{"position":[[979,16]]}}}],["lstm(hi:m)])\\begin{equ",{"_index":3817,"t":{"1101":{"position":[[729,28]]}}}],["lth",{"_index":3086,"t":{"849":{"position":[[836,5]]},"851":{"position":[[936,5],[1006,3],[1226,3]]},"1468":{"position":[[500,5],[679,3],[694,3],[1234,3]]},"1489":{"position":[[0,3],[155,3]]},"1515":{"position":[[90,3]]}}}],["ltotal=lplm+λ(llogits+lhidden)(5)\\mathcal{l}_{tot",{"_index":4180,"t":{"1244":{"position":[[1996,52]]}}}],["luke",{"_index":5338,"t":{"1665":{"position":[[529,4]]},"1667":{"position":[[578,4]]}}}],["lul=−∑n=1n∑t=1t(n)log⁡(1−p(y^i(n)∣x,y^<t(n)))∑n=1nt(n)\\begin{equ",{"_index":2106,"t":{"596":{"position":[[459,70]]}}}],["lull_{\\text{ul}}lul",{"_index":2117,"t":{"596":{"position":[[994,20],[2292,20]]},"602":{"position":[[286,20]]}}}],["lvl_vlv",{"_index":2170,"t":{"598":{"position":[[1935,8],[2250,8]]}}}],["lz'_\\varrho",{"_index":461,"t":{"91":{"position":[[1978,11]]}}}],["lz_\\varrho",{"_index":470,"t":{"91":{"position":[[2274,10]]}}}],["lzϱ​=mlp(ln(zϱ′​))+zϱ′​,ϱ=1",{"_index":473,"t":{"91":{"position":[[2364,27]]}}}],["lzϱ′​=msa(ln(zϱ−1​))+zϱ−1",{"_index":465,"t":{"91":{"position":[[2070,27]]}}}],["l}\\}mi​∈{a",{"_index":4517,"t":{"1389":{"position":[[871,11]]}}}],["l}m_i",{"_index":4515,"t":{"1389":{"position":[[847,5]]}}}],["l}pv​∈rdhidden​×l",{"_index":4474,"t":{"1384":{"position":[[1708,17]]}}}],["l}v∈rd×l",{"_index":1467,"t":{"358":{"position":[[154,8]]}}}],["l}∈rdhidden​×l",{"_index":4485,"t":{"1384":{"position":[[2383,14]]}}}],["l×d)(l",{"_index":4199,"t":{"1248":{"position":[[107,7]]}}}],["l×d)+(l×d)(l",{"_index":4201,"t":{"1248":{"position":[[197,13]]}}}],["l×d)+(l×d)τ(l",{"_index":4205,"t":{"1248":{"position":[[370,14]]}}}],["l×d2l",{"_index":4203,"t":{"1248":{"position":[[264,5]]}}}],["l×d=m×d+(s+d)×rl",{"_index":3693,"t":{"1067":{"position":[[1004,16]]}}}],["l×dl",{"_index":3706,"t":{"1070":{"position":[[965,4]]},"1248":{"position":[[58,4]]}}}],["l×dmodel×+(lp+li)|\\theta",{"_index":2667,"t":{"753":{"position":[[170,29]]}}}],["lμl_\\mul",{"_index":4382,"t":{"1352":{"position":[[276,10]]}}}],["l∂wi,j",{"_index":3172,"t":{"855":{"position":[[722,9]]}}}],["l∈rdl",{"_index":2145,"t":{"598":{"position":[[836,5]]}}}],["l≤l)(l",{"_index":3297,"t":{"891":{"position":[[400,7],[536,7]]}}}],["l⊙wx=(l⊙w)xl",{"_index":2182,"t":{"598":{"position":[[2849,12]]}}}],["l⊙xl",{"_index":2143,"t":{"598":{"position":[[802,4],[1041,4]]}}}],["l및αw\\mathcal{l",{"_index":3134,"t":{"853":{"position":[[1073,15]]}}}],["m",{"_index":257,"t":{"49":{"position":[[248,1],[258,1],[291,1]]},"55":{"position":[[53,1],[119,1]]},"833":{"position":[[80,2]]},"994":{"position":[[385,1]]},"999":{"position":[[314,2],[405,1],[449,1]]},"1002":{"position":[[155,1],[383,1],[461,1]]},"1067":{"position":[[1032,1]]},"1646":{"position":[[790,11],[969,11],[1048,13],[1150,11]]},"1655":{"position":[[1069,3]]},"1657":{"position":[[1899,11]]}}}],["m)hi​(0≤i≤m",{"_index":3801,"t":{"1099":{"position":[[1678,12],[1910,12]]}}}],["m+1)(m",{"_index":3310,"t":{"893":{"position":[[262,7]]}}}],["m+1)(m+1)(m+1",{"_index":3314,"t":{"893":{"position":[[354,15]]}}}],["m+1m+1m+1",{"_index":3350,"t":{"893":{"position":[[1444,9]]}}}],["m+n)}xnew​=[p,x]∈rd×(m+n",{"_index":2466,"t":{"686":{"position":[[278,26]]}}}],["m+s<l+sm",{"_index":3697,"t":{"1067":{"position":[[1196,8]]}}}],["m,ℓ)(m",{"_index":1838,"t":{"527":{"position":[[564,8]]}}}],["m/l",{"_index":243,"t":{"42":{"position":[[61,3]]}}}],["m=0m",{"_index":3718,"t":{"1080":{"position":[[414,5]]}}}],["m=20m",{"_index":3725,"t":{"1082":{"position":[[190,6],[281,6]]}}}],["m=topv(s)\\text{m",{"_index":3117,"t":{"853":{"position":[[449,17]]},"857":{"position":[[132,17]]}}}],["m\\mathcal{m}m",{"_index":3616,"t":{"1019":{"position":[[3,13],[49,13]]},"1099":{"position":[[15,13],[880,13],[1727,13]]},"1101":{"position":[[76,13],[628,13]]},"1387":{"position":[[31,13]]}}}],["m\\text{m}m",{"_index":3138,"t":{"853":{"position":[[1365,10]]},"857":{"position":[[24,10]]},"861":{"position":[[1604,10]]}}}],["m\\theta_mθm",{"_index":3260,"t":{"870":{"position":[[1114,13],[1145,13],[1299,13]]}}}],["m]5",{"_index":5266,"t":{"1657":{"position":[[1021,5]]}}}],["m][m][m",{"_index":5237,"t":{"1655":{"position":[[2012,9]]}}}],["m_e(\\tau_0)rt​=me​(τ0",{"_index":4752,"t":{"1455":{"position":[[90,23]]}}}],["m_i",{"_index":4507,"t":{"1387":{"position":[[137,5]]}}}],["m_{m=1",{"_index":3380,"t":{"895":{"position":[[539,10]]}}}],["m_{m=1}{im​}m=1m",{"_index":3372,"t":{"895":{"position":[[266,20]]}}}],["ma",{"_index":2551,"t":{"707":{"position":[[751,2]]},"1347":{"position":[[479,3]]},"1362":{"position":[[191,2]]},"1367":{"position":[[522,2]]}}}],["machan",{"_index":1240,"t":{"302":{"position":[[311,9]]}}}],["machin",{"_index":1420,"t":{"343":{"position":[[284,7]]},"670":{"position":[[1071,8]]},"1234":{"position":[[90,7]]},"1419":{"position":[[800,7]]}}}],["macro",{"_index":2012,"t":{"555":{"position":[[282,6]]},"1672":{"position":[[391,5]]}}}],["made",{"_index":4979,"t":{"1581":{"position":[[51,4]]},"1587":{"position":[[434,4]]}}}],["maf",{"_index":5368,"t":{"1672":{"position":[[400,5]]}}}],["magnitud",{"_index":250,"t":{"49":{"position":[[176,9],[476,9],[527,9],[838,9]]},"849":{"position":[[400,9]]},"851":{"position":[[446,9]]},"853":{"position":[[398,9],[1706,9],[2358,9],[2457,9]]},"868":{"position":[[4,9]]},"870":{"position":[[1570,9],[1775,9]]}}}],["mahabadi",{"_index":3592,"t":{"1002":{"position":[[653,9]]},"1004":{"position":[[63,8]]},"1084":{"position":[[251,8]]}}}],["main",{"_index":2441,"t":{"676":{"position":[[1605,4]]},"681":{"position":[[1804,4]]},"1479":{"position":[[32,4]]},"1499":{"position":[[130,4]]}}}],["main.22.pdf",{"_index":2240,"t":{"624":{"position":[[50,11]]}}}],["main.41.pdf",{"_index":958,"t":{"211":{"position":[[49,11]]}}}],["main.567.pdf",{"_index":2442,"t":{"679":{"position":[[50,12]]}}}],["main.758.pdf",{"_index":4771,"t":{"1464":{"position":[[50,12]]}}}],["main.884.pdf",{"_index":4351,"t":{"1343":{"position":[[50,12]]}}}],["maintain",{"_index":5017,"t":{"1587":{"position":[[300,10]]}}}],["major",{"_index":3969,"t":{"1149":{"position":[[656,8]]},"1736":{"position":[[965,8]]}}}],["make",{"_index":4704,"t":{"1440":{"position":[[514,7]]},"1442":{"position":[[682,7],[1551,6],[1768,6]]},"1449":{"position":[[379,6],[471,6]]},"1451":{"position":[[402,6],[702,6],[865,6]]},"1573":{"position":[[200,4]]},"1628":{"position":[[8,4]]},"1669":{"position":[[482,7]]}}}],["mallya",{"_index":3268,"t":{"873":{"position":[[896,6]]}}}],["mam_ama",{"_index":4725,"t":{"1445":{"position":[[58,8],[85,8]]}}}],["mamechan",{"_index":3413,"t":{"928":{"position":[[89,11]]}}}],["manag",{"_index":5055,"t":{"1602":{"position":[[15,6]]}}}],["mani",{"_index":1356,"t":{"324":{"position":[[297,4]]},"1095":{"position":[[132,4]]},"1427":{"position":[[663,4]]},"1644":{"position":[[287,4],[716,4]]},"1646":{"position":[[1337,4],[1443,4],[1909,4],[3144,4]]},"1649":{"position":[[0,4]]},"1653":{"position":[[529,4]]},"1665":{"position":[[991,4]]},"1689":{"position":[[12,4]]},"1790":{"position":[[0,4]]}}}],["manual",{"_index":2071,"t":{"592":{"position":[[334,6]]},"1093":{"position":[[503,6],[564,6]]},"1095":{"position":[[262,6],[298,6]]},"1109":{"position":[[540,6],[577,6],[652,6],[695,6]]},"1115":{"position":[[26,6],[54,6],[156,6],[196,6],[341,6],[413,6],[491,6],[538,6],[723,6],[943,6],[1000,6]]},"1117":{"position":[[323,6]]},"1126":{"position":[[1134,6]]},"1128":{"position":[[845,6]]},"1409":{"position":[[265,6]]},"1653":{"position":[[823,6]]},"1672":{"position":[[89,8]]},"1689":{"position":[[354,6]]}}}],["manut",{"_index":5475,"t":{"1728":{"position":[[0,7]]}}}],["map",{"_index":394,"t":{"88":{"position":[[418,3]]},"95":{"position":[[48,3],[139,3],[218,3],[300,3]]},"104":{"position":[[389,3]]},"296":{"position":[[53,7]]},"457":{"position":[[769,3]]},"696":{"position":[[688,3]]},"1505":{"position":[[322,4]]},"1525":{"position":[[87,4]]},"1659":{"position":[[20,7]]},"1728":{"position":[[212,7]]}}}],["marcey",{"_index":5009,"t":{"1587":{"position":[[136,6]]}}}],["marign",{"_index":4431,"t":{"1362":{"position":[[126,8]]}}}],["mark",{"_index":5162,"t":{"1646":{"position":[[1512,6]]},"1651":{"position":[[85,6],[169,6],[213,6],[256,6]]},"1788":{"position":[[487,7],[517,5]]}}}],["markdown",{"_index":37,"t":{"7":{"position":[[72,8]]},"9":{"position":[[30,8]]},"1593":{"position":[[9,8]]},"1610":{"position":[[4,8]]},"1614":{"position":[[30,8],[61,8],[83,8],[107,8],[177,8]]},"1616":{"position":[[20,8]]},"1618":{"position":[[0,8],[183,8],[200,8]]},"1620":{"position":[[8,8]]},"1622":{"position":[[8,8],[302,8]]},"1624":{"position":[[0,8]]},"1628":{"position":[[94,9]]}}}],["marker",{"_index":5334,"t":{"1665":{"position":[[341,7],[643,6],[706,6],[776,6]]},"1669":{"position":[[108,6],[310,6],[839,6],[876,6],[1062,6]]}}}],["markup",{"_index":5617,"t":{"1788":{"position":[[593,6]]}}}],["mask",{"_index":573,"t":{"118":{"position":[[47,7],[62,6]]},"124":{"position":[[243,4]]},"126":{"position":[[473,5]]},"130":{"position":[[117,5],[830,4]]},"140":{"position":[[542,4],[590,4],[653,4],[683,4]]},"143":{"position":[[173,5]]},"147":{"position":[[139,4]]},"153":{"position":[[334,4],[407,4],[548,4]]},"165":{"position":[[114,4],[683,5]]},"174":{"position":[[1377,5]]},"177":{"position":[[146,4],[173,4],[622,4],[696,4]]},"203":{"position":[[244,4],[275,4]]},"294":{"position":[[330,7]]},"302":{"position":[[776,7]]},"492":{"position":[[28,4]]},"500":{"position":[[567,4]]},"523":{"position":[[23,6]]},"531":{"position":[[1001,7]]},"594":{"position":[[169,6]]},"598":{"position":[[3423,4]]},"683":{"position":[[199,6]]},"795":{"position":[[1783,7]]},"847":{"position":[[637,7]]},"849":{"position":[[1300,7],[1549,4]]},"853":{"position":[[355,4]]},"855":{"position":[[489,7]]},"857":{"position":[[18,5],[72,7],[99,7],[303,7],[493,7]]},"861":{"position":[[1033,7]]},"866":{"position":[[328,4]]},"870":{"position":[[73,7],[109,7],[252,7],[1109,4],[1294,4]]},"873":{"position":[[50,7],[107,7],[183,7],[296,7],[454,7],[539,7],[1352,7],[1596,7],[1759,7]]},"1014":{"position":[[474,8],[518,6]]},"1019":{"position":[[137,9]]},"1099":{"position":[[486,6],[745,8],[816,8]]},"1105":{"position":[[176,8]]},"1107":{"position":[[639,6],[702,6]]},"1126":{"position":[[1355,6]]},"1132":{"position":[[155,6],[199,6]]},"1145":{"position":[[1003,6],[1023,6],[1068,4]]},"1471":{"position":[[48,6]]},"1485":{"position":[[93,4],[452,4]]},"1487":{"position":[[540,4]]},"1489":{"position":[[340,4]]},"1494":{"position":[[357,6]]},"1505":{"position":[[744,6],[873,7]]},"1646":{"position":[[774,6]]},"1657":{"position":[[1948,6],[2298,6],[2358,6]]},"1659":{"position":[[514,6]]},"1674":{"position":[[141,6]]},"1676":{"position":[[444,6]]},"1682":{"position":[[915,4]]},"1712":{"position":[[159,6]]},"1756":{"position":[[327,4]]},"1766":{"position":[[173,6]]}}}],["massiv",{"_index":1978,"t":{"539":{"position":[[315,7]]},"1232":{"position":[[145,7]]}}}],["match",{"_index":705,"t":{"153":{"position":[[212,8]]},"483":{"position":[[532,8]]},"496":{"position":[[248,8]]},"500":{"position":[[401,7],[469,8],[721,8],[816,7]]},"512":{"position":[[229,8]]},"515":{"position":[[300,5]]},"555":{"position":[[162,5]]},"628":{"position":[[1272,8]]},"630":{"position":[[2146,5]]},"646":{"position":[[113,5]]},"1449":{"position":[[326,5]]}}}],["math",{"_index":1532,"t":{"382":{"position":[[321,4]]},"384":{"position":[[948,4]]},"386":{"position":[[25,4]]},"391":{"position":[[8,4],[43,4],[74,4]]},"409":{"position":[[186,4]]},"483":{"position":[[832,4]]},"553":{"position":[[265,4]]},"561":{"position":[[185,4]]}}}],["mathbb{e}_{x",{"_index":4805,"t":{"1485":{"position":[[633,13]]},"1487":{"position":[[933,13]]}}}],["mathbb{r^e}xˉ∈r",{"_index":4390,"t":{"1352":{"position":[[615,17]]}}}],["mathbb{r}^dhi​∈rd",{"_index":4246,"t":{"1296":{"position":[[360,18]]}}}],["mathbb{r}^dl∈rd",{"_index":2146,"t":{"598":{"position":[[846,16]]}}}],["mathbb{r}^dp^j​∈rd",{"_index":3517,"t":{"988":{"position":[[553,19]]}}}],["mathbb{r}^duk​∈rl,vk​∈rd",{"_index":4137,"t":{"1242":{"position":[[345,25]]}}}],["mathbb{r}^dx^∈rd",{"_index":3515,"t":{"988":{"position":[[513,17]]}}}],["mathbb{r}^dxi​,zi​∈rd",{"_index":1280,"t":{"310":{"position":[[333,22]]}}}],["mathbb{r}^l",{"_index":4135,"t":{"1242":{"position":[[323,13]]}}}],["mathbb{r}^na∈rn",{"_index":3110,"t":{"853":{"position":[[182,16]]}}}],["mathbb{r}^nx∈rn",{"_index":3108,"t":{"853":{"position":[[146,16]]}}}],["mathbb{r}^{",{"_index":3661,"t":{"1065":{"position":[[244,13]]},"1067":{"position":[[323,13],[586,13]]},"1352":{"position":[[203,13]]}}}],["mathbb{r}^{(k+m",{"_index":3305,"t":{"891":{"position":[[796,17]]}}}],["mathbb{r}^{(l",{"_index":3668,"t":{"1065":{"position":[[586,14]]}}}],["mathbb{r}^{(m+1)\\tim",{"_index":3348,"t":{"893":{"position":[[1400,23]]}}}],["mathbb{r}^{(m+n",{"_index":4783,"t":{"1477":{"position":[[593,17]]}}}],["mathbb{r}^{(n",{"_index":453,"t":{"91":{"position":[[1735,14]]}}}],["mathbb{r}^{(p",{"_index":3901,"t":{"1128":{"position":[[1819,14]]}}}],["mathbb{r}^{1",{"_index":851,"t":{"174":{"position":[[1801,13]]},"893":{"position":[[317,13],[920,13],[2355,13]]},"895":{"position":[[302,13],[626,13]]}}}],["mathbb{r}^{100",{"_index":4212,"t":{"1255":{"position":[[160,15]]}}}],["mathbb{r}^{1024",{"_index":785,"t":{"170":{"position":[[1429,16]]}}}],["mathbb{r}^{\\frac{d_b}{r",{"_index":2278,"t":{"630":{"position":[[1763,25]]}}}],["mathbb{r}^{d",{"_index":2618,"t":{"733":{"position":[[278,13],[415,13]]},"789":{"position":[[549,13],[645,13],[982,13]]},"988":{"position":[[1199,13]]},"1218":{"position":[[161,13]]}}}],["mathbb{r}^{d\\tim",{"_index":4025,"t":{"1167":{"position":[[821,19]]}}}],["mathbb{r}^{d_1",{"_index":2757,"t":{"786":{"position":[[1801,15],[1901,15]]},"791":{"position":[[294,15],[394,15]]},"795":{"position":[[230,15]]}}}],["mathbb{r}^{d_\\text{hidden",{"_index":4462,"t":{"1384":{"position":[[685,27],[2348,27],[3272,27],[3503,27]]}}}],["mathbb{r}^{d_\\text{mid",{"_index":4465,"t":{"1384":{"position":[[794,24],[3378,24]]}}}],["mathbb{r}^{d_\\text{model",{"_index":1227,"t":{"300":{"position":[[1005,26],[1055,26],[1105,26]]}}}],["mathbb{r}^{d_b",{"_index":2263,"t":{"630":{"position":[[1270,15]]}}}],["mathbb{r}^{d_m",{"_index":2815,"t":{"789":{"position":[[1039,15]]}}}],["mathbb{r}^{d_{\\text{hidden",{"_index":4468,"t":{"1384":{"position":[[1351,29],[1483,29],[1671,29],[1985,29]]}}}],["mathbb{r}^{d_{\\text{mid",{"_index":4480,"t":{"1384":{"position":[[2101,26]]}}}],["mathbb{r}^{h",{"_index":404,"t":{"91":{"position":[[133,13]]}}}],["mathbb{r}^{k",{"_index":3295,"t":{"891":{"position":[[252,13]]},"895":{"position":[[963,13]]}}}],["mathbb{r}^{k+1}slk​∈rk+1",{"_index":3346,"t":{"893":{"position":[[1224,25]]}}}],["mathbb{r}^{l",{"_index":759,"t":{"170":{"position":[[462,13]]},"988":{"position":[[294,13]]},"1065":{"position":[[338,13]]},"1067":{"position":[[88,13]]},"1238":{"position":[[709,13]]},"1242":{"position":[[240,13]]},"1352":{"position":[[536,13]]}}}],["mathbb{r}^{l\\tim",{"_index":4374,"t":{"1350":{"position":[[553,19]]}}}],["mathbb{r}^{m",{"_index":3301,"t":{"891":{"position":[[578,13]]},"984":{"position":[[303,13]]},"988":{"position":[[353,13]]},"1067":{"position":[[188,13]]},"1167":{"position":[[897,13]]},"1218":{"position":[[235,13]]},"1477":{"position":[[468,13]]}}}],["mathbb{r}^{n",{"_index":408,"t":{"91":{"position":[[228,13],[1683,13]]},"174":{"position":[[1217,13]]},"789":{"position":[[164,13]]},"1128":{"position":[[1599,13]]},"1238":{"position":[[606,13]]},"1477":{"position":[[317,13]]}}}],["mathbb{r}^{n\\tim",{"_index":3105,"t":{"853":{"position":[[84,19],[600,19]]}}}],["mathbb{r}^{p",{"_index":3897,"t":{"1128":{"position":[[1682,13]]}}}],["mathbb{r}^{r",{"_index":2626,"t":{"733":{"position":[[458,13]]},"786":{"position":[[1853,13]]},"791":{"position":[[346,13]]},"795":{"position":[[279,13],[391,13]]},"988":{"position":[[1273,13]]},"1067":{"position":[[367,13]]}}}],["mathbb{r}^{t",{"_index":2148,"t":{"598":{"position":[[944,13]]}}}],["mathcal{",{"_index":2892,"t":{"797":{"position":[[787,12],[924,12],[977,12]]},"1244":{"position":[[865,11],[1464,11],[2220,14]]}}}],["mathcal{c}(\\mathcal{p",{"_index":2896,"t":{"797":{"position":[[952,24]]}}}],["mathcal{c}}e^{w_k",{"_index":4055,"t":{"1185":{"position":[[574,18]]}}}],["mathcal{e}^{(t",{"_index":2914,"t":{"797":{"position":[[1475,18]]}}}],["mathcal{e}l,",{"_index":4606,"t":{"1421":{"position":[[233,14]]}}}],["mathcal{e}}ρ∈rl×",{"_index":4604,"t":{"1421":{"position":[[198,18]]}}}],["mathcal{f}f∈f",{"_index":5175,"t":{"1651":{"position":[[500,14],[755,14]]},"1655":{"position":[[17,14]]}}}],["mathcal{f}j&f",{"_index":935,"t":{"191":{"position":[[160,14]]},"199":{"position":[[190,14]]}}}],["mathcal{g}_a",{"_index":4527,"t":{"1389":{"position":[[1561,13]]}}}],["mathcal{g}_l",{"_index":4535,"t":{"1389":{"position":[[2312,13]]}}}],["mathcal{g}}{\\max",{"_index":3504,"t":{"986":{"position":[[455,19]]}}}],["mathcal{i",{"_index":5172,"t":{"1651":{"position":[[379,11]]},"1657":{"position":[[2135,12]]}}}],["mathcal{l",{"_index":2971,"t":{"801":{"position":[[1088,11]]},"853":{"position":[[829,11]]},"861":{"position":[[720,11]]},"1099":{"position":[[2029,11]]},"1657":{"position":[[2758,11]]}}}],["mathcal{l}(\\mathcal{p}^{(t",{"_index":2913,"t":{"797":{"position":[[1444,30]]}}}],["mathcal{l}(x)}{\\parti",{"_index":4807,"t":{"1485":{"position":[[675,24]]},"1487":{"position":[[975,24]]}}}],["mathcal{l}[𝙼]_4",{"_index":5276,"t":{"1657":{"position":[[1541,18]]}}}],["mathcal{l}[𝙼]_5",{"_index":5278,"t":{"1657":{"position":[[1603,18]]}}}],["mathcal{l}\\sum_ie^2_i),sim(t1,t2)=cos(l1​i∑​ei1​,li∑​ei2",{"_index":4641,"t":{"1429":{"position":[[688,60]]}}}],["mathcal{l}_{\\text{c",{"_index":3218,"t":{"861":{"position":[[734,23]]}}}],["mathcal{l}_{\\text{indep}}(x",{"_index":5297,"t":{"1657":{"position":[[2880,29]]}}}],["mathcal{l}_{\\text{joint}}(x",{"_index":5296,"t":{"1657":{"position":[[2845,31],[2981,29]]}}}],["mathcal{l}_{\\text{kd",{"_index":3236,"t":{"861":{"position":[[1794,23]]}}}],["mathcal{l}_{dept",{"_index":3689,"t":{"1067":{"position":[[846,18]]}}}],["mathcal{l}_{hidden",{"_index":4183,"t":{"1244":{"position":[[2104,20]]}}}],["mathcal{l}_{logit",{"_index":4182,"t":{"1244":{"position":[[2081,20]]}}}],["mathcal{l}_{plm",{"_index":4181,"t":{"1244":{"position":[[2051,17]]}}}],["mathcal{l}_{plm}^klplm​=∑k∈∣s∣​lplmk",{"_index":4186,"t":{"1244":{"position":[[2235,38]]}}}],["mathcal{l}_{pt",{"_index":3672,"t":{"1065":{"position":[[714,16]]}}}],["mathcal{l}}{\\parti",{"_index":3141,"t":{"853":{"position":[[1546,21]]},"855":{"position":[[290,21],[580,21],[747,21]]}}}],["mathcal{m}(\\text{x",{"_index":3806,"t":{"1099":{"position":[[2041,22]]}}}],["mathcal{m}e∈m",{"_index":3769,"t":{"1099":{"position":[[190,14]]}}}],["mathcal{m}|∑i​∣mi​∣≪∣m",{"_index":4508,"t":{"1387":{"position":[[147,27]]}}}],["mathcal{n}(0,1)δ∼n(0,1",{"_index":4412,"t":{"1354":{"position":[[334,24]]}}}],["mathcal{p",{"_index":2891,"t":{"797":{"position":[[773,13]]}}}],["mathcal{q",{"_index":2895,"t":{"797":{"position":[[937,12],[990,12]]}}}],["mathcal{q})c(p,e,q",{"_index":2893,"t":{"797":{"position":[[800,20]]}}}],["mathcal{q}^{(t",{"_index":2915,"t":{"797":{"position":[[1494,19]]}}}],["mathcal{r}^dwc​∈rd",{"_index":1479,"t":{"358":{"position":[[503,19]]}}}],["mathcal{r}^{(l+n",{"_index":4128,"t":{"1238":{"position":[[995,18]]}}}],["mathcal{r}^{\\mathcal{l",{"_index":4603,"t":{"1421":{"position":[[166,24]]}}}],["mathcal{r}^{d",{"_index":1466,"t":{"358":{"position":[[132,14],[387,14]]}}}],["mathcal{s_k",{"_index":4160,"t":{"1244":{"position":[[901,14],[1500,14]]}}}],["mathcal{s}_1",{"_index":4099,"t":{"1236":{"position":[[57,14]]}}}],["mathcal{s}_2",{"_index":4100,"t":{"1236":{"position":[[72,14]]}}}],["mathcal{s}_k",{"_index":4101,"t":{"1236":{"position":[[94,13]]}}}],["mathcal{t",{"_index":2924,"t":{"797":{"position":[[1814,11]]}}}],["mathcal{t}(\\tilde{\\lambda}_k^{(t",{"_index":2927,"t":{"797":{"position":[[1876,36]]}}}],["mathcal{t}_1",{"_index":4104,"t":{"1236":{"position":[[179,14]]},"1246":{"position":[[941,14]]}}}],["mathcal{t}_2",{"_index":4105,"t":{"1236":{"position":[[194,14]]},"1246":{"position":[[956,14]]}}}],["mathcal{t}_\\mathcal{t",{"_index":4106,"t":{"1236":{"position":[[216,23]]}}}],["mathcal{t}_{\\mathcal{t",{"_index":4198,"t":{"1246":{"position":[[978,25]]}}}],["mathcal{v}[pi​]∈v",{"_index":3789,"t":{"1099":{"position":[[1190,18]]}}}],["mathcal{v}[𝙼]_1",{"_index":5269,"t":{"1657":{"position":[[1338,18]]}}}],["mathcal{v}[𝙼]_2",{"_index":5271,"t":{"1657":{"position":[[1413,18]]}}}],["mathcal{v}[𝙼]_3",{"_index":5273,"t":{"1657":{"position":[[1475,18]]}}}],["mathcal{v}_{f_{e_",{"_index":5218,"t":{"1655":{"position":[[948,21],[1876,20]]}}}],["mathcal{v}⊂v",{"_index":3619,"t":{"1019":{"position":[[157,13]]}}}],["mathcal{x",{"_index":5171,"t":{"1651":{"position":[[366,12]]},"1657":{"position":[[2809,12]]}}}],["mathcal{z",{"_index":2599,"t":{"723":{"position":[[529,12],[1222,12]]}}}],["mathcal{z}}{\\textup{search",{"_index":5426,"t":{"1704":{"position":[[527,29]]}}}],["mathemat",{"_index":2001,"t":{"553":{"position":[[102,12]]},"1770":{"position":[[487,12]]}}}],["matric",{"_index":1225,"t":{"300":{"position":[[942,8]]},"527":{"position":[[2295,8]]},"598":{"position":[[2653,8],[3291,8],[3630,8]]},"628":{"position":[[404,8]]},"630":{"position":[[1731,8]]},"633":{"position":[[953,8]]},"648":{"position":[[508,8]]},"688":{"position":[[609,8],[1063,8]]},"692":{"position":[[265,8]]},"696":{"position":[[624,8],[791,8],[828,8],[1113,8]]},"719":{"position":[[636,8],[1128,8],[1165,8]]},"733":{"position":[[56,8]]},"735":{"position":[[10,8]]},"757":{"position":[[10,8],[40,8],[299,8]]},"774":{"position":[[141,8]]},"784":{"position":[[312,8],[467,8]]},"786":{"position":[[1303,8],[1608,8],[2260,8],[2310,8],[2469,8],[2758,8],[2809,8],[2904,8],[3340,8],[3410,8],[3469,8],[3640,8],[3673,8],[3907,8],[4101,8]]},"791":{"position":[[17,8]]},"793":{"position":[[55,8]]},"795":{"position":[[19,8],[1349,8],[2027,8]]},"797":{"position":[[359,8],[2490,8]]},"803":{"position":[[89,8]]},"809":{"position":[[674,8],[794,8],[884,8]]},"841":{"position":[[181,8],[212,8]]},"843":{"position":[[124,8],[295,8]]},"873":{"position":[[775,8],[830,8],[1014,8]]},"881":{"position":[[152,8],[218,8]]},"994":{"position":[[142,8]]},"1060":{"position":[[888,8]]},"1062":{"position":[[1124,8],[1147,8]]},"1067":{"position":[[301,9],[448,8],[1423,8]]},"1070":{"position":[[1052,8]]},"1080":{"position":[[204,7],[468,8]]},"1111":{"position":[[958,6]]},"1172":{"position":[[37,7]]},"1384":{"position":[[1631,8],[2324,8],[3155,8],[3204,8],[3226,8],[3854,8]]}}}],["matrices/lay",{"_index":2773,"t":{"786":{"position":[[3066,15]]}}}],["matrix",{"_index":849,"t":{"174":{"position":[[1782,6],[1899,6]]},"298":{"position":[[272,6],[330,6],[369,6],[897,6]]},"306":{"position":[[311,6]]},"598":{"position":[[2810,6]]},"681":{"position":[[1556,6]]},"696":{"position":[[1174,6]]},"721":{"position":[[170,6],[237,6]]},"733":{"position":[[256,6]]},"739":{"position":[[27,6]]},"768":{"position":[[153,6]]},"772":{"position":[[107,6]]},"778":{"position":[[197,6],[357,6],[470,6]]},"780":{"position":[[255,6]]},"786":{"position":[[936,6],[1014,6],[1437,6],[1632,6],[2382,6],[3710,6],[3811,6],[3829,6],[4043,6]]},"791":{"position":[[859,6]]},"795":{"position":[[366,6],[1951,6]]},"797":{"position":[[56,6],[232,6]]},"799":{"position":[[150,6],[225,6]]},"803":{"position":[[408,6]]},"828":{"position":[[95,6]]},"841":{"position":[[64,6]]},"851":{"position":[[280,6]]},"853":{"position":[[122,6]]},"857":{"position":[[124,7],[241,6],[283,6],[430,6],[723,6],[814,6],[870,6],[909,6],[1500,6]]},"873":{"position":[[479,6],[1242,6]]},"1006":{"position":[[2155,6]]},"1062":{"position":[[1259,6]]},"1065":{"position":[[319,6],[392,6],[549,6],[853,6]]},"1067":{"position":[[69,6],[165,6],[247,6],[271,6],[1356,6]]},"1070":{"position":[[1831,6]]},"1128":{"position":[[1781,6]]},"1185":{"position":[[236,6]]},"1227":{"position":[[950,7],[967,6],[999,6],[1035,6],[1174,6]]},"1236":{"position":[[642,6]]},"1238":{"position":[[690,6]]},"1240":{"position":[[80,6],[123,6],[144,6],[202,6],[262,6],[338,6]]},"1242":{"position":[[444,6]]},"1244":{"position":[[557,6],[589,6]]},"1246":{"position":[[612,6],[651,6]]},"1248":{"position":[[297,6]]},"1270":{"position":[[339,6]]},"1285":{"position":[[197,6],[229,6]]},"1305":{"position":[[538,6]]},"1307":{"position":[[75,6],[185,6]]},"1384":{"position":[[1773,6],[3458,6]]},"1720":{"position":[[631,6]]}}}],["matter",{"_index":5092,"t":{"1618":{"position":[[57,7]]},"1714":{"position":[[465,8]]}}}],["mawp",{"_index":1544,"t":{"391":{"position":[[124,5]]},"399":{"position":[[236,5]]},"409":{"position":[[247,5]]}}}],["max",{"_index":1624,"t":{"441":{"position":[[266,4]]},"988":{"position":[[478,3]]},"1300":{"position":[[161,5]]},"1350":{"position":[[382,5],[708,5]]},"1455":{"position":[[718,3]]},"1477":{"position":[[804,5]]}}}],["max(0",{"_index":1248,"t":{"304":{"position":[[237,7]]}}}],["maxim",{"_index":4945,"t":{"1558":{"position":[[1387,8]]}}}],["maximize∑j=1lwjlog⁡p(yj∣x,y1:j−1),(1)\\textup{maxim",{"_index":629,"t":{"132":{"position":[[755,54]]}}}],["maximum",{"_index":700,"t":{"153":{"position":[[156,7]]},"310":{"position":[[831,7],[1252,7]]},"326":{"position":[[741,7]]},"1462":{"position":[[164,7]]}}}],["maxiup",{"_index":255,"t":{"49":{"position":[[218,6]]}}}],["max⁡c",{"_index":1442,"t":{"350":{"position":[[880,5]]}}}],["max⁡p",{"_index":3489,"t":{"984":{"position":[[566,5]]}}}],["max⁡ptarget,g",{"_index":3501,"t":{"986":{"position":[[380,13]]}}}],["max⁡θp,θϕ∑x,y∈tlog⁡pθ(y∣[p′;x]).\\begin{equ",{"_index":4030,"t":{"1167":{"position":[[1307,48]]}}}],["max⁡θp∑x,y∈tlog⁡pθ(y∣[p;x]).\\begin{equ",{"_index":4002,"t":{"1164":{"position":[[268,44]]}}}],["max⁡θ∑(x,y)∈z∑t=1∣y∣log⁡(pϕ0+△ϕ(θ)(yt∣x,y<t))(2)\\underset{\\theta}{\\max",{"_index":2608,"t":{"723":{"position":[[1134,71]]}}}],["max⁡θ∑x,y∈tlog⁡pθ(y∣x).\\begin{equ",{"_index":3997,"t":{"1162":{"position":[[227,39]]}}}],["max⁡ϕlog⁡p(y∣x;θ;ϕ)=max⁡ϕ∑yilog⁡p(yi,h<i;θ;ϕ)(2)\\underset{\\phi}{\\max",{"_index":5450,"t":{"1720":{"position":[[408,69]]}}}],["max⁡ϕ∑(x,y)∈z∑t=1∣y∣log⁡(pϕ(yt∣x,y<t))(1)\\underset{\\phi}{\\max",{"_index":2597,"t":{"723":{"position":[[450,62]]}}}],["mbconv",{"_index":175,"t":{"25":{"position":[[375,6]]},"33":{"position":[[124,6],[199,6],[229,6],[273,6],[303,6]]},"38":{"position":[[144,8],[159,7]]},"40":{"position":[[61,6],[83,6],[93,6]]},"76":{"position":[[167,6]]},"78":{"position":[[194,6],[212,6],[842,6],[860,6]]}}}],["mdaliti",{"_index":1043,"t":{"227":{"position":[[392,7]]}}}],["mdx",{"_index":66,"t":{"9":{"position":[[57,4]]},"1628":{"position":[[0,3]]}}}],["me!</button",{"_index":75,"t":{"9":{"position":[[178,12]]}}}],["mean",{"_index":1495,"t":{"370":{"position":[[29,4]]},"676":{"position":[[970,4]]},"801":{"position":[[765,4]]},"1070":{"position":[[1705,4]]},"1244":{"position":[[1357,4]]},"1778":{"position":[[952,4]]}}}],["measur",{"_index":4088,"t":{"1227":{"position":[[647,7]]},"1230":{"position":[[657,7]]},"1234":{"position":[[175,7]]},"1238":{"position":[[1214,7]]}}}],["mechan",{"_index":1139,"t":{"283":{"position":[[83,9]]},"285":{"position":[[270,9],[404,9]]},"287":{"position":[[421,9],[640,9]]},"527":{"position":[[1162,9]]},"656":{"position":[[53,9]]},"681":{"position":[[1196,9]]},"982":{"position":[[168,9]]},"1345":{"position":[[382,9]]},"1347":{"position":[[1335,9],[1954,9]]},"1352":{"position":[[159,9]]},"1364":{"position":[[7,9]]},"1377":{"position":[[400,9]]},"1379":{"position":[[841,9]]},"1389":{"position":[[741,10]]}}}],["median",{"_index":2091,"t":{"594":{"position":[[1351,6],[1481,6]]},"608":{"position":[[1003,6]]}}}],["mediat",{"_index":1628,"t":{"441":{"position":[[419,8]]}}}],["medic",{"_index":507,"t":{"102":{"position":[[310,8]]}}}],["medicin",{"_index":2003,"t":{"553":{"position":[[124,8]]}}}],["medium",{"_index":1811,"t":{"521":{"position":[[91,6]]},"523":{"position":[[573,6]]},"529":{"position":[[2811,6]]},"628":{"position":[[734,6]]},"763":{"position":[[54,6]]},"1024":{"position":[[91,6]]},"1070":{"position":[[1586,6]]},"1111":{"position":[[1797,6]]},"1113":{"position":[[143,6],[364,6]]},"1314":{"position":[[25,6]]}}}],["megatronlm2",{"_index":3853,"t":{"1109":{"position":[[1304,11]]}}}],["mem_em",{"_index":4726,"t":{"1445":{"position":[[122,8]]}}}],["memmemmem",{"_index":4735,"t":{"1447":{"position":[[436,9]]},"1451":{"position":[[238,9],[361,9]]},"1455":{"position":[[391,9],[661,9]]}}}],["memori",{"_index":1158,"t":{"287":{"position":[[571,6]]},"302":{"position":[[130,6]]},"598":{"position":[[51,6]]},"616":{"position":[[12,6],[77,6],[205,6]]},"628":{"position":[[468,6],[496,6],[1432,6]]},"644":{"position":[[87,6]]},"1008":{"position":[[390,6]]},"1060":{"position":[[417,6],[939,6]]},"1062":{"position":[[857,6],[1449,6],[1655,6]]},"1067":{"position":[[1149,6]]},"1070":{"position":[[1314,6]]},"1073":{"position":[[218,6]]},"1080":{"position":[[114,6],[237,6]]},"1087":{"position":[[72,6]]},"1230":{"position":[[413,6]]},"1360":{"position":[[295,7]]},"1440":{"position":[[327,6]]},"1442":{"position":[[1095,6],[1382,6],[1968,6]]},"1447":{"position":[[419,6]]},"1451":{"position":[[231,6],[637,6],[795,6]]},"1453":{"position":[[46,6],[216,6],[274,6],[293,6]]},"1455":{"position":[[572,6],[602,6]]},"1462":{"position":[[155,6],[286,6]]},"1468":{"position":[[55,6]]},"1782":{"position":[[485,6]]}}}],["mention",{"_index":5554,"t":{"1768":{"position":[[439,7]]}}}],["merker",{"_index":5342,"t":{"1665":{"position":[[673,6]]}}}],["messag",{"_index":4875,"t":{"1536":{"position":[[60,7],[97,7],[126,8],[205,8],[409,7]]}}}],["meta",{"_index":5529,"t":{"1738":{"position":[[754,4]]},"1782":{"position":[[375,4]]}}}],["metadata",{"_index":5040,"t":{"1595":{"position":[[69,8]]},"1618":{"position":[[24,8]]}}}],["metast",{"_index":1023,"t":{"215":{"position":[[2476,6]]}}}],["method",{"_index":154,"t":{"23":{"position":[[196,7]]},"47":{"position":[[431,6]]},"78":{"position":[[402,6]]},"376":{"position":[[106,6]]},"468":{"position":[[67,6],[176,6]]},"521":{"position":[[228,7]]},"529":{"position":[[2848,6]]},"531":{"position":[[1120,6]]},"567":{"position":[[766,6]]},"589":{"position":[[1648,6],[2021,6]]},"594":{"position":[[86,6]]},"598":{"position":[[584,6],[637,6],[3096,7]]},"614":{"position":[[130,6]]},"626":{"position":[[114,6]]},"628":{"position":[[128,7],[662,6],[1580,6]]},"630":{"position":[[25,6],[784,6]]},"633":{"position":[[1006,6]]},"635":{"position":[[14,6],[96,6]]},"638":{"position":[[68,7],[131,6]]},"644":{"position":[[4,6]]},"648":{"position":[[590,6]]},"650":{"position":[[34,6]]},"707":{"position":[[691,6]]},"709":{"position":[[309,6]]},"780":{"position":[[179,6]]},"809":{"position":[[657,6]]},"843":{"position":[[36,6]]},"847":{"position":[[153,6]]},"849":{"position":[[1088,6],[1397,6]]},"870":{"position":[[44,6]]},"875":{"position":[[182,6]]},"879":{"position":[[318,6]]},"885":{"position":[[92,6]]},"914":{"position":[[20,7]]},"934":{"position":[[534,6]]},"947":{"position":[[37,6]]},"979":{"position":[[152,7]]},"1126":{"position":[[1860,6]]},"1128":{"position":[[888,6]]},"1145":{"position":[[147,6]]},"1157":{"position":[[220,6]]},"1195":{"position":[[68,7]]},"1225":{"position":[[536,6]]},"1242":{"position":[[797,6]]},"1257":{"position":[[240,6],[339,6]]},"1264":{"position":[[147,6]]},"1347":{"position":[[1021,6]]},"1364":{"position":[[28,6]]},"1377":{"position":[[147,7],[201,6],[237,7]]},"1384":{"position":[[2601,8]]},"1387":{"position":[[305,6]]},"1391":{"position":[[32,7]]},"1393":{"position":[[642,8],[727,7],[925,7]]},"1401":{"position":[[388,7]]},"1407":{"position":[[68,6]]},"1409":{"position":[[1909,6]]},"1644":{"position":[[525,6],[578,6]]},"1665":{"position":[[686,7],[931,6],[1062,6]]},"1674":{"position":[[83,6]]},"1684":{"position":[[438,7]]},"1762":{"position":[[28,6]]},"1768":{"position":[[377,6]]},"1782":{"position":[[41,6]]},"1794":{"position":[[375,6]]}}}],["metric",{"_index":2011,"t":{"555":{"position":[[275,6]]},"793":{"position":[[155,6]]},"799":{"position":[[261,6]]},"801":{"position":[[252,6],[439,6],[2640,7],[2728,6]]},"823":{"position":[[157,8]]},"841":{"position":[[279,6]]},"843":{"position":[[227,6]]},"1070":{"position":[[738,7]]},"1151":{"position":[[326,6]]},"1153":{"position":[[422,6]]},"1266":{"position":[[179,6]]},"1270":{"position":[[199,8]]},"1429":{"position":[[480,7],[1189,6]]},"1672":{"position":[[408,6]]},"1680":{"position":[[303,6]]}}}],["meulder",{"_index":1011,"t":{"215":{"position":[[2258,8]]}}}],["mgsm",{"_index":2009,"t":{"553":{"position":[[258,4]]},"555":{"position":[[175,4]]},"561":{"position":[[200,4]]}}}],["mha",{"_index":2792,"t":{"789":{"position":[[104,5],[195,3]]},"791":{"position":[[737,3]]}}}],["mha(x)=concat(head1,…,headh)wo,head)i=softmax(xwqi(xwki)⊤/dn)xwvi,\\text{mha",{"_index":2795,"t":{"789":{"position":[[241,76]]}}}],["mi,jm_{i,j}mi,j",{"_index":3164,"t":{"855":{"position":[[502,16]]}}}],["michael",{"_index":3146,"t":{"853":{"position":[[1848,8]]},"861":{"position":[[70,8]]}}}],["michel",{"_index":1967,"t":{"531":{"position":[[1228,6]]}}}],["micro",{"_index":5366,"t":{"1672":{"position":[[368,5]]}}}],["middl",{"_index":1816,"t":{"523":{"position":[[771,7]]},"1702":{"position":[[612,7],[646,6]]},"1718":{"position":[[145,6],[193,6]]}}}],["midf1",{"_index":947,"t":{"193":{"position":[[207,5]]},"195":{"position":[[47,5]]}}}],["mif",{"_index":5367,"t":{"1672":{"position":[[377,5]]}}}],["mikolov",{"_index":2311,"t":{"658":{"position":[[846,8],[915,8]]}}}],["mim_imi",{"_index":4519,"t":{"1389":{"position":[[987,8],[1032,8]]}}}],["min",{"_index":1327,"t":{"317":{"position":[[277,4]]},"733":{"position":[[516,4]]},"795":{"position":[[515,4]]},"1099":{"position":[[2022,6]]}}}],["min(s,d)r≪min(s,d",{"_index":3683,"t":{"1067":{"position":[[419,19]]}}}],["mine",{"_index":1753,"t":{"500":{"position":[[901,6],[1156,6]]},"1095":{"position":[[419,6]]},"1718":{"position":[[39,6]]},"1720":{"position":[[1822,6]]}}}],["mini",{"_index":1746,"t":{"498":{"position":[[607,4],[662,4],[697,4]]},"801":{"position":[[1383,4]]},"1246":{"position":[[505,4]]}}}],["minibatch",{"_index":3479,"t":{"982":{"position":[[1030,9]]}}}],["minigpt",{"_index":3418,"t":{"934":{"position":[[327,7]]},"951":{"position":[[21,7]]},"959":{"position":[[113,7]]}}}],["minigpt4",{"_index":3443,"t":{"955":{"position":[[0,8]]}}}],["minim",{"_index":2066,"t":{"589":{"position":[[1179,7]]}}}],["minima",{"_index":3811,"t":{"1101":{"position":[[296,6]]},"1462":{"position":[[121,6]]}}}],["minut",{"_index":81,"t":{"11":{"position":[[41,8]]},"1581":{"position":[[141,8]]}}}],["mismatch",{"_index":2250,"t":{"628":{"position":[[1052,8]]},"630":{"position":[[363,8],[561,8]]},"650":{"position":[[103,8]]}}}],["miss",{"_index":5404,"t":{"1695":{"position":[[1042,6]]}}}],["mix",{"_index":637,"t":{"136":{"position":[[18,5]]},"138":{"position":[[303,6],[325,6],[340,6]]},"151":{"position":[[112,5]]},"244":{"position":[[239,5],[278,5]]},"589":{"position":[[1447,5],[2271,5]]},"592":{"position":[[168,5]]},"598":{"position":[[167,5],[190,5],[532,5],[646,5],[2555,5]]},"1084":{"position":[[1096,5]]},"1134":{"position":[[562,7]]},"1145":{"position":[[1908,6]]},"1259":{"position":[[43,6]]},"1419":{"position":[[614,6],[968,6]]},"1431":{"position":[[1247,6]]}}}],["mix&match",{"_index":178,"t":{"25":{"position":[[498,11]]},"27":{"position":[[258,9]]}}}],["mixprompt",{"_index":2458,"t":{"683":{"position":[[1087,9]]}}}],["mixtur",{"_index":1717,"t":{"483":{"position":[[437,8]]},"557":{"position":[[115,7]]},"559":{"position":[[23,7]]},"561":{"position":[[42,7]]},"589":{"position":[[1837,7]]},"594":{"position":[[267,7],[729,7]]},"600":{"position":[[210,7],[329,7]]},"602":{"position":[[116,7]]},"606":{"position":[[17,7]]},"977":{"position":[[141,7],[222,7]]},"979":{"position":[[320,8],[413,7]]},"1259":{"position":[[120,7]]},"1345":{"position":[[290,7]]},"1347":{"position":[[929,7],[1241,7],[1803,7]]},"1354":{"position":[[0,7]]},"1369":{"position":[[0,7],[298,7],[491,7],[669,7]]},"1377":{"position":[[581,7]]},"1379":{"position":[[1507,7]]},"1401":{"position":[[443,7],[522,7]]},"1415":{"position":[[341,7]]},"1419":{"position":[[579,9],[908,7],[1032,7]]},"1423":{"position":[[416,7],[707,7]]},"1431":{"position":[[1153,7],[1317,7],[3023,7]]}}}],["mixup",{"_index":267,"t":{"49":{"position":[[550,5]]},"53":{"position":[[334,5]]},"78":{"position":[[580,6],[760,5]]}}}],["mi}\\{m_i\\}{mi",{"_index":4505,"t":{"1387":{"position":[[90,16],[196,16]]}}}],["mi∈{a",{"_index":4514,"t":{"1389":{"position":[[837,6]]}}}],["mkdir",{"_index":5141,"t":{"1634":{"position":[[51,5]]}}}],["mlm",{"_index":2453,"t":{"683":{"position":[[221,5]]},"1113":{"position":[[506,3]]},"1471":{"position":[[70,5]]}}}],["mlp",{"_index":434,"t":{"91":{"position":[[1090,3],[1367,3],[1462,3],[2398,3]]},"93":{"position":[[40,3]]},"523":{"position":[[782,4]]},"527":{"position":[[1365,3],[3065,3]]},"529":{"position":[[1604,3]]},"633":{"position":[[707,3]]},"696":{"position":[[1556,3]]},"721":{"position":[[351,3]]},"735":{"position":[[94,3]]},"739":{"position":[[125,3],[227,3]]},"755":{"position":[[196,3]]},"912":{"position":[[132,3]]},"1031":{"position":[[41,3],[166,3]]},"1101":{"position":[[598,3]]},"1167":{"position":[[768,3],[1030,3]]},"1172":{"position":[[10,4]]},"1176":{"position":[[166,3]]},"1189":{"position":[[185,3]]},"1195":{"position":[[76,4],[466,3]]},"1208":{"position":[[11,3]]},"1210":{"position":[[42,3],[66,3]]},"1218":{"position":[[299,3]]},"1221":{"position":[[44,3],[316,3]]}}}],["mlpθ\\text{mlp}_\\thetamlp",{"_index":4310,"t":{"1307":{"position":[[136,26],[344,26]]}}}],["mmlu",{"_index":1979,"t":{"539":{"position":[[357,6]]},"553":{"position":[[95,4]]},"555":{"position":[[0,4]]},"561":{"position":[[147,4]]},"567":{"position":[[581,4]]}}}],["mmm",{"_index":1459,"t":{"354":{"position":[[284,3],[307,3]]},"457":{"position":[[1093,3],[1125,3]]},"527":{"position":[[514,3]]},"662":{"position":[[842,3],[1089,3]]},"686":{"position":[[322,3]]},"891":{"position":[[612,3]]},"895":{"position":[[334,3],[379,3]]},"984":{"position":[[352,3]]},"994":{"position":[[71,3]]},"1008":{"position":[[342,3]]},"1067":{"position":[[1085,3],[1107,3]]},"1070":{"position":[[1030,3]]},"1080":{"position":[[96,3]]},"1167":{"position":[[1024,3]]},"1172":{"position":[[154,3]]},"1218":{"position":[[293,3]]},"1477":{"position":[[519,3]]}}}],["mmota",{"_index":946,"t":{"193":{"position":[[199,5]]}}}],["mmotsa",{"_index":949,"t":{"195":{"position":[[31,7]]}}}],["mmotsp",{"_index":950,"t":{"195":{"position":[[39,7]]}}}],["mnli",{"_index":2371,"t":{"668":{"position":[[585,4]]},"676":{"position":[[120,4],[374,4],[510,4]]},"759":{"position":[[183,4]]},"833":{"position":[[74,5],[240,4]]},"839":{"position":[[361,4]]},"864":{"position":[[22,5]]},"866":{"position":[[436,4],[926,5]]},"870":{"position":[[661,4],[853,4],[1419,4]]},"873":{"position":[[637,4]]},"875":{"position":[[94,4]]},"877":{"position":[[353,4]]},"881":{"position":[[258,4]]},"997":{"position":[[279,5],[465,5],[527,6]]},"999":{"position":[[1217,4]]},"1006":{"position":[[2523,4],[2609,4]]},"1070":{"position":[[97,4],[1754,5]]},"1253":{"position":[[65,4],[207,5]]},"1395":{"position":[[125,5],[2315,8]]},"1419":{"position":[[444,4],[484,4]]},"1423":{"position":[[625,4]]},"1425":{"position":[[90,4]]},"1427":{"position":[[720,4],[793,4],[1112,5]]},"1429":{"position":[[1495,5]]},"1431":{"position":[[2114,4]]}}}],["mnlim_mm",{"_index":2401,"t":{"672":{"position":[[523,9],[739,9],[1211,9]]}}}],["modal",{"_index":748,"t":{"165":{"position":[[1861,10]]},"170":{"position":[[86,10]]},"219":{"position":[[29,5]]},"221":{"position":[[148,5],[428,5],[903,5]]},"225":{"position":[[172,5],[260,5],[442,5],[511,5]]},"227":{"position":[[221,8],[371,8],[424,8],[493,8],[860,8]]},"230":{"position":[[406,8]]},"232":{"position":[[41,8],[282,5],[383,5],[499,5]]},"234":{"position":[[6,5]]},"236":{"position":[[258,5],[456,5],[549,5]]},"258":{"position":[[20,8],[124,8]]},"277":{"position":[[62,5]]},"339":{"position":[[219,5]]},"434":{"position":[[141,8]]},"436":{"position":[[518,8],[1075,8],[1514,8],[1970,8]]},"441":{"position":[[390,5]]},"443":{"position":[[259,8]]},"447":{"position":[[48,8],[303,8]]},"455":{"position":[[1110,8]]},"468":{"position":[[125,5]]},"488":{"position":[[294,5]]},"496":{"position":[[153,5],[220,5]]},"500":{"position":[[91,10],[666,5]]},"502":{"position":[[109,5]]},"895":{"position":[[41,10],[861,5],[1189,5]]},"912":{"position":[[6,5]]},"914":{"position":[[159,5]]},"928":{"position":[[207,5]]},"932":{"position":[[656,5],[889,5]]},"934":{"position":[[296,5],[393,5],[686,5],[916,5],[1613,5],[2440,5]]},"940":{"position":[[6,5]]},"942":{"position":[[230,5]]},"949":{"position":[[68,5]]},"951":{"position":[[61,5],[468,5]]},"953":{"position":[[699,5]]},"955":{"position":[[261,5]]},"965":{"position":[[273,5]]},"967":{"position":[[69,5]]},"973":{"position":[[542,5]]},"1780":{"position":[[36,5]]}}}],["mode",{"_index":1596,"t":{"434":{"position":[[15,5]]},"533":{"position":[[119,4]]}}}],["model",{"_index":160,"t":{"25":{"position":[[111,5]]},"27":{"position":[[14,5]]},"38":{"position":[[317,5]]},"76":{"position":[[21,5]]},"95":{"position":[[75,5]]},"106":{"position":[[6,5]]},"149":{"position":[[149,5]]},"153":{"position":[[646,5]]},"155":{"position":[[83,5],[221,5],[360,5]]},"159":{"position":[[200,5],[258,5]]},"163":{"position":[[37,5]]},"165":{"position":[[2815,5]]},"213":{"position":[[101,5],[151,5],[411,5]]},"215":{"position":[[226,5],[946,5],[1109,5],[1298,5]]},"221":{"position":[[711,5]]},"225":{"position":[[40,5],[731,8],[759,8]]},"227":{"position":[[750,5]]},"244":{"position":[[35,5],[50,5]]},"283":{"position":[[236,6]]},"287":{"position":[[706,8],[864,5]]},"289":{"position":[[29,5],[330,5]]},"306":{"position":[[25,5]]},"319":{"position":[[198,5]]},"322":{"position":[[53,5],[165,5],[264,5],[299,5],[437,5],[482,5],[514,5]]},"324":{"position":[[562,5]]},"326":{"position":[[200,5],[713,5],[958,5]]},"328":{"position":[[64,5]]},"334":{"position":[[314,5]]},"354":{"position":[[18,5],[278,5],[319,5]]},"384":{"position":[[273,5],[1092,5]]},"399":{"position":[[16,5],[307,5]]},"405":{"position":[[4,5]]},"426":{"position":[[228,5]]},"430":{"position":[[227,5]]},"434":{"position":[[391,5]]},"436":{"position":[[547,8],[1408,5],[1446,5],[1732,5],[2001,8]]},"443":{"position":[[188,7],[443,5]]},"455":{"position":[[852,8]]},"457":{"position":[[1221,5]]},"475":{"position":[[241,5]]},"485":{"position":[[380,6],[435,5]]},"504":{"position":[[344,5]]},"508":{"position":[[16,5],[233,5]]},"510":{"position":[[187,5]]},"517":{"position":[[12,6],[149,5]]},"521":{"position":[[324,8]]},"523":{"position":[[39,5],[244,5],[281,5],[856,5],[927,5]]},"525":{"position":[[496,5],[516,5],[1052,5]]},"527":{"position":[[179,5],[271,5]]},"529":{"position":[[119,6],[701,6],[728,6]]},"531":{"position":[[69,5],[799,5],[1509,5]]},"537":{"position":[[149,5]]},"539":{"position":[[82,5],[593,6]]},"544":{"position":[[20,6]]},"567":{"position":[[331,5],[421,5],[452,8],[663,5],[715,5]]},"569":{"position":[[879,6]]},"571":{"position":[[107,5]]},"587":{"position":[[57,5],[590,5]]},"589":{"position":[[394,6],[447,6],[786,5],[1155,5],[1269,5],[1496,6],[1636,6],[1779,5]]},"592":{"position":[[56,5],[301,5]]},"594":{"position":[[67,5],[185,8]]},"598":{"position":[[2712,5],[2914,5],[3364,5],[3561,5]]},"602":{"position":[[208,8]]},"608":{"position":[[18,6]]},"612":{"position":[[79,5]]},"614":{"position":[[282,5]]},"616":{"position":[[27,5]]},"626":{"position":[[15,6],[399,5]]},"628":{"position":[[1221,5]]},"630":{"position":[[79,5],[223,5],[438,5],[715,5],[845,5],[1010,5],[1162,5],[1893,5],[1978,5],[2066,5],[2226,5]]},"633":{"position":[[129,5],[163,5],[215,5],[240,5],[287,5],[319,5],[337,5],[396,5]]},"642":{"position":[[160,5],[209,5],[288,5]]},"646":{"position":[[14,5],[145,5],[171,5],[252,5],[273,5],[354,5],[420,5],[471,5]]},"648":{"position":[[785,5]]},"650":{"position":[[142,5]]},"656":{"position":[[12,5],[119,5]]},"658":{"position":[[12,5],[283,5],[420,5],[465,5],[543,5],[982,5],[2405,5],[2544,5],[2981,5],[3198,5]]},"660":{"position":[[37,5],[818,5],[886,5]]},"662":{"position":[[1023,5]]},"666":{"position":[[43,5],[447,5],[525,5]]},"668":{"position":[[482,5]]},"670":{"position":[[559,5],[722,5],[788,5],[1151,5],[1279,5]]},"672":{"position":[[1301,5],[1362,5]]},"676":{"position":[[92,5]]},"679":{"position":[[78,5],[92,5],[195,6]]},"681":{"position":[[260,5]]},"683":{"position":[[21,7],[215,5],[791,5],[894,5]]},"688":{"position":[[659,5]]},"696":{"position":[[1712,5]]},"709":{"position":[[241,5]]},"717":{"position":[[91,5],[422,5]]},"719":{"position":[[201,5],[376,6],[436,5],[577,5],[812,5],[872,5],[1220,5]]},"723":{"position":[[829,5],[851,5]]},"727":{"position":[[159,5]]},"759":{"position":[[198,5],[221,5]]},"774":{"position":[[65,5]]},"780":{"position":[[116,5]]},"784":{"position":[[27,6],[109,5],[856,5]]},"786":{"position":[[444,5],[526,5],[567,5],[650,5],[810,5],[2437,6],[2853,5],[3872,6],[4410,6]]},"789":{"position":[[17,5]]},"799":{"position":[[282,5]]},"809":{"position":[[132,5],[225,5]]},"847":{"position":[[21,6],[495,5]]},"851":{"position":[[46,5]]},"855":{"position":[[40,5]]},"861":{"position":[[0,5],[1976,5],[1992,5]]},"866":{"position":[[11,5]]},"868":{"position":[[296,5]]},"870":{"position":[[714,5],[889,5],[2055,5],[2182,5]]},"879":{"position":[[14,5]]},"885":{"position":[[46,5],[132,5],[492,5],[603,5]]},"887":{"position":[[30,5],[111,5],[237,5],[968,5],[1030,5],[1165,5],[1196,6]]},"897":{"position":[[65,5],[114,5]]},"905":{"position":[[512,5]]},"914":{"position":[[39,6]]},"932":{"position":[[167,5],[289,5],[716,6]]},"934":{"position":[[31,5],[81,5],[151,5],[379,5],[494,5],[601,5],[669,5],[744,5],[1522,5],[2035,6],[2086,5],[2219,5],[2594,5]]},"955":{"position":[[29,5],[690,5]]},"961":{"position":[[37,5]]},"963":{"position":[[349,5]]},"965":{"position":[[40,5],[74,5],[189,6]]},"967":{"position":[[146,5],[468,5]]},"971":{"position":[[55,6]]},"973":{"position":[[200,5]]},"977":{"position":[[46,5]]},"992":{"position":[[1040,5]]},"999":{"position":[[277,5]]},"1006":{"position":[[1995,5]]},"1012":{"position":[[25,5],[210,5]]},"1014":{"position":[[106,5],[254,5],[608,5]]},"1019":{"position":[[825,5]]},"1024":{"position":[[44,5],[104,5]]},"1028":{"position":[[200,5],[511,5]]},"1039":{"position":[[38,5],[109,5]]},"1043":{"position":[[115,5]]},"1047":{"position":[[24,5]]},"1060":{"position":[[57,6],[158,5],[475,6]]},"1062":{"position":[[441,5]]},"1065":{"position":[[166,5],[529,5]]},"1070":{"position":[[810,5]]},"1080":{"position":[[284,5]]},"1087":{"position":[[211,5],[288,5],[312,5]]},"1091":{"position":[[25,5]]},"1093":{"position":[[131,5],[186,6],[265,6],[341,6],[556,5]]},"1095":{"position":[[110,5],[239,5],[454,5]]},"1105":{"position":[[241,5]]},"1107":{"position":[[655,6],[752,5],[867,6],[926,6]]},"1109":{"position":[[370,5],[464,5]]},"1111":{"position":[[917,6],[1025,6],[1142,5],[1461,5],[1720,5],[1927,6]]},"1113":{"position":[[35,5],[150,5],[577,5],[636,5],[684,5]]},"1117":{"position":[[79,5],[115,5],[412,5]]},"1120":{"position":[[75,5],[300,5]]},"1124":{"position":[[62,5],[308,5],[445,5],[567,5]]},"1126":{"position":[[75,5],[177,5],[224,5],[271,5],[336,5],[367,6],[549,5],[582,5],[635,5],[783,5],[875,5],[1163,5],[1260,5],[1703,5],[1771,5],[1815,5],[1945,5],[2375,5],[2490,5],[2629,5]]},"1128":{"position":[[123,8],[734,5]]},"1130":{"position":[[110,5]]},"1132":{"position":[[718,8],[785,5],[1189,5],[1664,5]]},"1134":{"position":[[7,5],[380,5]]},"1136":{"position":[[9,5],[120,5],[177,5],[372,5],[496,5]]},"1141":{"position":[[698,5]]},"1143":{"position":[[177,5],[731,5]]},"1145":{"position":[[660,5],[1098,5],[1240,5],[1401,5],[1477,5],[1732,5],[1938,5],[2007,5],[2283,5],[2398,5],[2491,5]]},"1147":{"position":[[519,5],[1051,5],[1148,5]]},"1149":{"position":[[0,5],[299,7]]},"1151":{"position":[[1952,5]]},"1153":{"position":[[135,5],[161,5],[480,5]]},"1159":{"position":[[21,6],[134,6],[195,5],[292,5],[331,6],[414,5],[483,8],[598,5],[996,5]]},"1162":{"position":[[168,5],[364,5]]},"1164":{"position":[[135,5],[175,5]]},"1167":{"position":[[1002,5]]},"1183":{"position":[[19,5]]},"1187":{"position":[[27,8]]},"1225":{"position":[[28,5],[101,5]]},"1227":{"position":[[31,6]]},"1232":{"position":[[28,5],[111,5]]},"1234":{"position":[[52,5]]},"1238":{"position":[[388,5]]},"1244":{"position":[[1128,5],[1333,5]]},"1257":{"position":[[50,5]]},"1268":{"position":[[34,5],[145,5],[224,5]]},"1289":{"position":[[46,6],[105,5]]},"1291":{"position":[[46,5],[1430,5]]},"1296":{"position":[[70,5]]},"1314":{"position":[[369,5],[517,5]]},"1347":{"position":[[72,5],[284,5]]},"1350":{"position":[[39,5],[254,5],[804,5]]},"1352":{"position":[[270,5],[575,5]]},"1354":{"position":[[269,5]]},"1357":{"position":[[201,6]]},"1367":{"position":[[201,5]]},"1369":{"position":[[21,5]]},"1377":{"position":[[32,5]]},"1379":{"position":[[21,6],[53,5],[154,5]]},"1384":{"position":[[2641,5]]},"1393":{"position":[[832,5]]},"1395":{"position":[[352,5],[2416,5]]},"1401":{"position":[[232,5]]},"1403":{"position":[[40,5]]},"1407":{"position":[[21,6],[409,5]]},"1409":{"position":[[220,8],[569,5],[606,5],[795,5],[918,5],[934,5],[1181,5],[1598,5]]},"1411":{"position":[[58,5],[214,6]]},"1413":{"position":[[88,5]]},"1415":{"position":[[128,5],[154,5],[249,5],[366,5]]},"1419":{"position":[[285,5]]},"1423":{"position":[[944,5],[968,5],[1033,5],[1144,5],[1300,5]]},"1434":{"position":[[264,5]]},"1436":{"position":[[60,5]]},"1445":{"position":[[30,5],[77,5],[147,5]]},"1447":{"position":[[293,5]]},"1449":{"position":[[236,5]]},"1451":{"position":[[22,5],[272,5]]},"1453":{"position":[[247,5]]},"1455":{"position":[[313,5],[497,5]]},"1466":{"position":[[44,6],[376,5],[628,5]]},"1468":{"position":[[1506,5]]},"1471":{"position":[[64,5],[216,5]]},"1475":{"position":[[385,5]]},"1477":{"position":[[875,5]]},"1485":{"position":[[472,5],[881,5]]},"1499":{"position":[[14,5],[246,5],[867,5]]},"1501":{"position":[[146,5]]},"1505":{"position":[[122,5]]},"1507":{"position":[[134,5]]},"1515":{"position":[[29,5]]},"1517":{"position":[[82,5]]},"1542":{"position":[[109,6]]},"1546":{"position":[[19,6],[193,5],[450,5]]},"1550":{"position":[[147,5],[207,5],[231,5]]},"1558":{"position":[[24,5],[457,8],[607,5],[1861,5]]},"1644":{"position":[[25,6]]},"1665":{"position":[[55,6]]},"1667":{"position":[[959,6]]},"1669":{"position":[[511,6],[1115,5]]},"1682":{"position":[[360,5],[464,5],[578,5]]},"1689":{"position":[[341,5]]},"1695":{"position":[[42,5],[224,5],[417,5]]},"1708":{"position":[[184,5]]},"1712":{"position":[[50,5]]},"1714":{"position":[[142,6],[489,6]]},"1782":{"position":[[360,5]]}}}],["model'",{"_index":3973,"t":{"1151":{"position":[[287,7]]}}}],["moder",{"_index":4772,"t":{"1466":{"position":[[156,8]]},"1468":{"position":[[1549,8]]},"1473":{"position":[[319,8]]},"1477":{"position":[[939,8]]},"1499":{"position":[[796,8]]},"1515":{"position":[[13,8]]}}}],["modif",{"_index":2057,"t":{"587":{"position":[[651,13]]},"602":{"position":[[703,13]]}}}],["modifi",{"_index":2140,"t":{"598":{"position":[[569,9]]},"1583":{"position":[[32,6]]},"1606":{"position":[[64,6]]},"1632":{"position":[[0,6]]},"1638":{"position":[[64,6]]}}}],["modil",{"_index":754,"t":{"170":{"position":[[22,6]]}}}],["modl",{"_index":3076,"t":{"841":{"position":[[401,5]]}}}],["modul",{"_index":749,"t":{"165":{"position":[[1962,6],[1987,6]]},"172":{"position":[[238,6],[308,6],[784,6]]},"434":{"position":[[350,6]]},"436":{"position":[[1340,6]]},"443":{"position":[[43,6]]},"483":{"position":[[281,7]]},"525":{"position":[[1103,7]]},"587":{"position":[[279,8]]},"626":{"position":[[273,6],[317,6]]},"628":{"position":[[204,7],[748,7],[1016,6],[1126,6],[1288,6],[1344,6],[1536,7]]},"630":{"position":[[92,6],[121,6],[180,6],[401,6],[456,6],[522,6],[755,6],[1930,7],[2018,6],[2086,6],[2176,7],[2210,6],[2281,6]]},"633":{"position":[[463,6],[695,6],[711,7],[776,6],[1050,6]]},"635":{"position":[[58,6],[140,6]]},"646":{"position":[[60,6],[226,7],[371,6]]},"648":{"position":[[334,6]]},"650":{"position":[[55,6],[76,6]]},"656":{"position":[[159,6]]},"658":{"position":[[1549,7],[2967,6]]},"660":{"position":[[264,6],[284,6],[367,6],[705,6],[748,6],[1078,6]]},"662":{"position":[[130,6],[1149,6],[1255,6],[1312,6],[1474,10]]},"670":{"position":[[990,6]]},"676":{"position":[[925,6],[1176,6]]},"681":{"position":[[376,6],[502,6]]},"683":{"position":[[671,6],[755,6]]},"692":{"position":[[423,6]]},"696":{"position":[[575,6]]},"698":{"position":[[35,6]]},"721":{"position":[[129,6],[326,6]]},"739":{"position":[[55,6],[129,6]]},"755":{"position":[[200,6]]},"770":{"position":[[15,6]]},"786":{"position":[[388,7],[417,7],[602,7],[2485,7],[2585,7],[2705,7],[3008,7],[3178,7]]},"789":{"position":[[780,6]]},"809":{"position":[[382,6],[395,6],[477,6],[496,6]]},"841":{"position":[[165,6],[308,6]]},"887":{"position":[[818,6]]},"938":{"position":[[116,6]]},"942":{"position":[[53,6]]},"955":{"position":[[267,6]]},"977":{"position":[[391,6]]},"979":{"position":[[737,6]]},"982":{"position":[[456,6]]},"988":{"position":[[118,6],[1852,6]]},"992":{"position":[[30,6],[421,6],[522,6]]},"994":{"position":[[120,6]]},"1167":{"position":[[755,7],[977,8]]},"1341":{"position":[[597,6]]},"1369":{"position":[[591,6]]}}}],["modular",{"_index":1609,"t":{"436":{"position":[[982,7]]},"977":{"position":[[748,7]]},"979":{"position":[[272,7],[980,7],[1781,7]]},"1006":{"position":[[1500,11]]}}}],["module.export",{"_index":5046,"t":{"1595":{"position":[[318,14]]},"1606":{"position":[[123,14]]},"1632":{"position":[[83,14]]},"1638":{"position":[[123,14]]}}}],["moe",{"_index":4577,"t":{"1401":{"position":[[541,5],[593,3],[715,3],[749,3],[811,3]]}}}],["moemori",{"_index":4749,"t":{"1453":{"position":[[101,7]]}}}],["molchanov",{"_index":1954,"t":{"531":{"position":[[465,9]]},"851":{"position":[[79,9]]}}}],["momentum",{"_index":289,"t":{"53":{"position":[[154,8],[181,8]]},"80":{"position":[[48,8]]},"498":{"position":[[580,8],[640,8],[754,8],[799,8]]},"500":{"position":[[929,8]]}}}],["mono",{"_index":1789,"t":{"517":{"position":[[132,4],[182,4]]}}}],["more",{"_index":1940,"t":{"531":{"position":[[271,4]]},"1395":{"position":[[1970,4]]},"1399":{"position":[[297,4]]},"1523":{"position":[[272,4]]},"1581":{"position":[[114,4],[136,4]]},"1628":{"position":[[32,4]]}}}],["morn",{"_index":5411,"t":{"1698":{"position":[[570,8]]}}}],["mos&vi",{"_index":893,"t":{"177":{"position":[[1276,7]]}}}],["mot",{"_index":736,"t":{"165":{"position":[[205,6],[251,7],[1484,4],[1489,5]]},"168":{"position":[[116,4],[121,4]]},"174":{"position":[[1423,4],[1428,4]]},"193":{"position":[[0,3]]},"195":{"position":[[0,3],[20,4]]}}}],["mota",{"_index":940,"t":{"193":{"position":[[123,7]]}}}],["mothod",{"_index":1695,"t":{"468":{"position":[[160,6]]}}}],["motiv",{"_index":4510,"t":{"1389":{"position":[[0,10]]}}}],["move",{"_index":299,"t":{"53":{"position":[[269,6]]},"801":{"position":[[2150,6]]},"814":{"position":[[531,6]]},"1153":{"position":[[486,6],[508,4]]}}}],["movement",{"_index":3081,"t":{"847":{"position":[[231,8]]},"849":{"position":[[598,8],[731,8],[1163,8],[1204,8],[1225,8]]},"851":{"position":[[748,8]]},"853":{"position":[[1205,8],[1732,8],[2497,8]]},"855":{"position":[[704,8],[889,8]]},"868":{"position":[[86,8]]},"870":{"position":[[215,8],[426,8],[680,8],[1472,8],[1594,8],[1610,8],[1887,8]]}}}],["movi",{"_index":3611,"t":{"1014":{"position":[[463,8]]},"1019":{"position":[[230,7]]},"1698":{"position":[[375,6]]},"1702":{"position":[[335,7],[381,6],[410,6],[439,7]]}}}],["mp",{"_index":3850,"t":{"1109":{"position":[[554,4],[683,3],[1175,2]]}}}],["mp+ft",{"_index":3852,"t":{"1109":{"position":[[1228,5]]},"1117":{"position":[[258,5],[288,5],[312,5]]}}}],["mprc",{"_index":3966,"t":{"1147":{"position":[[823,4]]}}}],["mpt",{"_index":3739,"t":{"1084":{"position":[[574,3],[677,3],[894,3]]},"1225":{"position":[[303,5]]},"1227":{"position":[[769,5],[1323,3],[1471,3],[1548,3]]},"1234":{"position":[[238,3]]},"1236":{"position":[[547,3]]},"1238":{"position":[[1415,3]]},"1240":{"position":[[0,3]]},"1246":{"position":[[884,3]]},"1250":{"position":[[23,3]]},"1253":{"position":[[0,3]]},"1257":{"position":[[0,3]]},"1259":{"position":[[99,3],[234,3],[299,3]]},"1262":{"position":[[14,3]]},"1264":{"position":[[122,3],[197,3]]},"1266":{"position":[[170,3]]},"1268":{"position":[[51,3],[75,3],[161,3]]},"1270":{"position":[[0,3],[315,3]]},"1273":{"position":[[25,3],[250,3]]},"1283":{"position":[[198,3],[248,3]]}}}],["mpˉ​i​=∑m=1m​pim​/m",{"_index":1463,"t":{"354":{"position":[[408,19]]}}}],["mrc",{"_index":2539,"t":{"701":{"position":[[71,4]]}}}],["mrpc",{"_index":2685,"t":{"759":{"position":[[160,5]]},"866":{"position":[[978,5],[1059,4]]},"997":{"position":[[459,5]]},"1070":{"position":[[123,4]]},"1147":{"position":[[892,5],[1035,4]]},"1253":{"position":[[201,5]]},"1427":{"position":[[1280,5]]},"1429":{"position":[[1570,5]]}}}],["mrpcnlu",{"_index":4538,"t":{"1393":{"position":[[105,9]]}}}],["mrqa",{"_index":3570,"t":{"997":{"position":[[218,4],[613,4]]},"999":{"position":[[786,4]]},"1002":{"position":[[387,4],[991,4]]},"1070":{"position":[[172,4]]},"1075":{"position":[[0,4]]},"1147":{"position":[[323,4]]},"1253":{"position":[[231,4]]},"1419":{"position":[[735,4]]}}}],["ms",{"_index":654,"t":{"143":{"position":[[31,2]]},"1077":{"position":[[21,2]]}}}],["msa",{"_index":466,"t":{"91":{"position":[[2185,5]]},"696":{"position":[[1610,3]]}}}],["msa(⋅)=softmax(qnewtknewd)vnewmsa(\\cdot",{"_index":2533,"t":{"696":{"position":[[1394,40]]}}}],["mscoco",{"_index":3703,"t":{"1070":{"position":[[361,6]]}}}],["mse",{"_index":4217,"t":{"1275":{"position":[[231,3]]}}}],["msrm_{sr}msr",{"_index":4728,"t":{"1445":{"position":[[222,13]]}}}],["mt",{"_index":3988,"t":{"1159":{"position":[[109,2]]}}}],["mtb",{"_index":5339,"t":{"1665":{"position":[[536,3]]},"1667":{"position":[[712,3]]}}}],["much",{"_index":4980,"t":{"1581":{"position":[[109,4]]},"1587":{"position":[[503,4]]}}}],["muffin",{"_index":1985,"t":{"544":{"position":[[139,6]]},"548":{"position":[[0,7]]},"557":{"position":[[81,7]]}}}],["multi",{"_index":436,"t":{"91":{"position":[[1339,5],[2164,5]]},"155":{"position":[[210,5]]},"157":{"position":[[166,5],[364,5]]},"159":{"position":[[182,5]]},"165":{"position":[[212,5]]},"174":{"position":[[284,5],[597,5]]},"195":{"position":[[63,5]]},"219":{"position":[[23,5]]},"221":{"position":[[142,5],[422,5],[897,5]]},"225":{"position":[[86,5],[166,5],[254,5],[436,5],[505,5]]},"232":{"position":[[276,5],[377,5],[493,5]]},"234":{"position":[[0,5]]},"236":{"position":[[252,5],[450,5]]},"262":{"position":[[203,5]]},"277":{"position":[[56,5]]},"287":{"position":[[315,5]]},"292":{"position":[[80,5]]},"294":{"position":[[139,5]]},"298":{"position":[[620,6]]},"300":{"position":[[429,5]]},"302":{"position":[[14,5]]},"328":{"position":[[123,5]]},"339":{"position":[[213,5]]},"362":{"position":[[78,5]]},"386":{"position":[[14,5],[217,5]]},"412":{"position":[[45,5]]},"426":{"position":[[4,5]]},"441":{"position":[[384,5]]},"468":{"position":[[119,5]]},"523":{"position":[[905,5]]},"539":{"position":[[323,5]]},"546":{"position":[[123,5]]},"557":{"position":[[123,5]]},"658":{"position":[[2472,5],[2513,5]]},"696":{"position":[[1574,5],[1645,5]]},"789":{"position":[[83,5]]},"885":{"position":[[486,5]]},"887":{"position":[[962,5],[1024,5]]},"893":{"position":[[2111,5]]},"895":{"position":[[221,5],[855,5],[1183,5]]},"912":{"position":[[0,5],[31,5]]},"914":{"position":[[153,5]]},"928":{"position":[[201,5]]},"932":{"position":[[650,5],[883,5]]},"934":{"position":[[290,5],[387,5],[680,5],[910,5],[1607,5],[2434,5]]},"940":{"position":[[0,5],[87,5]]},"942":{"position":[[224,5]]},"949":{"position":[[62,5]]},"951":{"position":[[55,5],[462,5]]},"953":{"position":[[693,5]]},"955":{"position":[[255,5]]},"965":{"position":[[267,5]]},"967":{"position":[[63,5]]},"973":{"position":[[331,5],[536,5]]},"977":{"position":[[6,5],[492,5]]},"979":{"position":[[280,5],[798,5],[988,5],[1327,5],[1740,5]]},"992":{"position":[[146,5],[1150,5]]},"999":{"position":[[224,5],[294,5],[453,5]]},"1002":{"position":[[295,5]]},"1006":{"position":[[1984,5]]},"1008":{"position":[[515,5]]},"1035":{"position":[[0,5],[92,5]]},"1045":{"position":[[0,5]]},"1049":{"position":[[327,5]]},"1054":{"position":[[50,5]]},"1062":{"position":[[680,6]]},"1070":{"position":[[563,5],[688,5]]},"1073":{"position":[[150,5]]},"1075":{"position":[[67,5]]},"1134":{"position":[[550,5]]},"1136":{"position":[[190,6],[239,5],[485,5]]},"1141":{"position":[[460,5]]},"1149":{"position":[[499,5]]},"1153":{"position":[[525,5]]},"1187":{"position":[[341,5]]},"1283":{"position":[[95,5]]},"1384":{"position":[[1128,5],[3172,5]]},"1389":{"position":[[208,5]]},"1395":{"position":[[2243,5]]},"1401":{"position":[[336,5]]},"1415":{"position":[[143,5],[355,5]]},"1419":{"position":[[568,5]]},"1423":{"position":[[1289,5]]},"1431":{"position":[[1142,5],[1306,5]]},"1449":{"position":[[553,5]]},"1451":{"position":[[382,5]]},"1473":{"position":[[648,5]]},"1655":{"position":[[2240,5]]},"1724":{"position":[[126,5]]},"1734":{"position":[[0,5]]},"1780":{"position":[[30,5]]},"1790":{"position":[[126,5]]}}}],["multihead(q,k,v)=concat(head1,…,headh)wowher",{"_index":1212,"t":{"300":{"position":[[570,45]]}}}],["multilingu",{"_index":5382,"t":{"1682":{"position":[[451,12]]}}}],["multimod",{"_index":1598,"t":{"434":{"position":[[185,10]]},"439":{"position":[[43,10]]},"443":{"position":[[137,11]]},"479":{"position":[[213,10]]},"502":{"position":[[76,10],[447,10]]}}}],["multinli",{"_index":3480,"t":{"984":{"position":[[3,9]]}}}],["multipl",{"_index":316,"t":{"58":{"position":[[184,8]]},"130":{"position":[[722,8]]},"140":{"position":[[627,8]]},"165":{"position":[[180,8]]},"193":{"position":[[89,8]]},"504":{"position":[[807,8]]},"550":{"position":[[194,8]]},"589":{"position":[[1880,8]]},"594":{"position":[[1253,8]]},"596":{"position":[[1219,8]]},"598":{"position":[[761,14],[917,14],[2542,8],[2687,14],[2790,14],[2817,14],[3315,14]]},"672":{"position":[[1095,14]]},"676":{"position":[[1633,14]]},"713":{"position":[[285,8]]},"719":{"position":[[3,8]]},"786":{"position":[[155,8]]},"979":{"position":[[426,8],[1264,8],[1762,8]]},"982":{"position":[[1200,8]]},"992":{"position":[[962,8],[992,8]]},"1004":{"position":[[416,8]]},"1006":{"position":[[795,8],[1235,8],[1426,8]]},"1008":{"position":[[54,8]]},"1062":{"position":[[629,8]]},"1145":{"position":[[2313,8]]},"1149":{"position":[[223,8]]},"1225":{"position":[[309,8],[468,14]]},"1227":{"position":[[568,8],[1192,14]]},"1232":{"position":[[36,8],[76,8]]},"1238":{"position":[[1157,8],[1285,8]]},"1240":{"position":[[356,14]]},"1285":{"position":[[38,8]]},"1345":{"position":[[337,8]]},"1347":{"position":[[1118,8],[1914,8]]},"1352":{"position":[[9,8]]},"1369":{"position":[[52,8],[574,8]]},"1371":{"position":[[107,8]]},"1389":{"position":[[677,8],[1120,8]]},"1602":{"position":[[22,8]]},"1657":{"position":[[1890,8]]},"1706":{"position":[[113,8]]},"1712":{"position":[[302,8]]},"1728":{"position":[[329,8],[685,8]]},"1736":{"position":[[58,8]]},"1768":{"position":[[489,8]]},"1772":{"position":[[163,8]]},"1774":{"position":[[231,8]]},"1790":{"position":[[244,8]]},"1794":{"position":[[900,8],[1062,8]]}}}],["multirc",{"_index":1647,"t":{"455":{"position":[[607,7]]},"633":{"position":[[48,7]]},"997":{"position":[[423,8]]},"1006":{"position":[[2501,8]]},"1070":{"position":[[147,7]]},"1111":{"position":[[148,7]]},"1113":{"position":[[89,7]]},"1181":{"position":[[71,8]]},"1253":{"position":[[146,8]]},"1429":{"position":[[1433,8]]},"1499":{"position":[[627,7]]}}}],["multitask",{"_index":2062,"t":{"589":{"position":[[418,9],[1486,9],[1827,9]]},"594":{"position":[[257,9],[710,9]]},"600":{"position":[[200,9],[319,9]]},"602":{"position":[[106,9]]},"727":{"position":[[258,9]]},"1225":{"position":[[204,9],[279,9]]},"1227":{"position":[[745,9],[778,9],[1351,9]]},"1232":{"position":[[0,9],[153,9],[251,9],[332,9]]},"1234":{"position":[[274,9]]},"1244":{"position":[[0,9]]},"1246":{"position":[[213,9],[380,9],[1036,9]]},"1281":{"position":[[64,9]]},"1285":{"position":[[0,9]]},"1431":{"position":[[3013,9]]},"1517":{"position":[[258,9]]}}}],["multiupl",{"_index":1201,"t":{"298":{"position":[[904,15]]}}}],["mutipl",{"_index":1546,"t":{"395":{"position":[[201,7]]},"1794":{"position":[[1044,7]]}}}],["mutli",{"_index":1083,"t":{"236":{"position":[[543,5]]}}}],["mutlipl",{"_index":956,"t":{"207":{"position":[[47,8]]},"992":{"position":[[53,8]]},"1724":{"position":[[417,8]]}}}],["mu}{\\sigma",{"_index":1864,"t":{"527":{"position":[[1721,12],[2068,12]]}}}],["myreactpag",{"_index":5083,"t":{"1612":{"position":[[159,13]]}}}],["m}p∈rd×m",{"_index":2462,"t":{"686":{"position":[[132,8]]}}}],["m}wdown​∈rd×m",{"_index":4026,"t":{"1167":{"position":[[841,13]]},"1218":{"position":[[182,13]]}}}],["m×d+(s+d)×rm",{"_index":3709,"t":{"1070":{"position":[[1104,12]]}}}],["m×d+d×+2d=2dm+2dm",{"_index":4080,"t":{"1218":{"position":[[422,17]]}}}],["m×dm",{"_index":3557,"t":{"994":{"position":[[43,4]]}}}],["mϕ[i])m_{\\phi}[i])mϕ​[i",{"_index":5460,"t":{"1720":{"position":[[894,25]]}}}],["mϕm_{\\phi}m",{"_index":5454,"t":{"1720":{"position":[[638,13],[933,13]]}}}],["m∈{0,1}n×n\\text{m",{"_index":3114,"t":{"853":{"position":[[293,18]]}}}],["m∣|\\mathcal{m}|∣m",{"_index":4504,"t":{"1387":{"position":[[5,19]]}}}],["m≪dm",{"_index":2348,"t":{"662":{"position":[[969,4]]}}}],["n",{"_index":247,"t":{"49":{"position":[[138,1]]},"165":{"position":[[1683,1],[2221,1]]},"174":{"position":[[631,1],[655,1]]},"205":{"position":[[147,1],[176,1]]},"310":{"position":[[1683,1],[1695,1]]},"797":{"position":[[2277,2]]},"861":{"position":[[245,1]]},"934":{"position":[[1441,1]]},"1060":{"position":[[649,1],[690,1],[694,1],[755,2]]},"1065":{"position":[[102,1]]},"1128":{"position":[[1836,2]]},"1167":{"position":[[653,1]]},"1540":{"position":[[80,1],[403,2],[447,2],[488,2]]},"1682":{"position":[[148,3]]}}}],["n(0,1)\\delta",{"_index":4410,"t":{"1354":{"position":[[314,14]]}}}],["n)\\omega(n)ω(n",{"_index":4871,"t":{"1531":{"position":[[72,17]]}}}],["n)\\theta(n)θ(n",{"_index":4872,"t":{"1531":{"position":[[132,17]]}}}],["n)o(nlogn",{"_index":4905,"t":{"1540":{"position":[[112,10]]}}}],["n/a",{"_index":5633,"t":{"1802":{"position":[[563,4],[861,5]]}}}],["n=32n",{"_index":3393,"t":{"905":{"position":[[216,5]]}}}],["n=6n",{"_index":1172,"t":{"292":{"position":[[10,4]]},"294":{"position":[[11,4]]}}}],["n=hw/p2n",{"_index":418,"t":{"91":{"position":[[362,8]]}}}],["n_{i",{"_index":1620,"t":{"441":{"position":[[193,7]]}}}],["n_{i=1}l=△​{xi​,yi​}i=1n",{"_index":3658,"t":{"1065":{"position":[[73,28]]}}}],["n_{k=1}e={λk​}k=1n",{"_index":2886,"t":{"797":{"position":[[661,23]]}}}],["n_{k=1}p={pk​}k=1n",{"_index":2884,"t":{"797":{"position":[[600,23]]}}}],["n_{k=1}q={qk​}k=1n",{"_index":2889,"t":{"797":{"position":[[716,22]]}}}],["na",{"_index":146,"t":{"23":{"position":[[42,5]]},"25":{"position":[[390,3]]},"27":{"position":[[388,5]]},"38":{"position":[[65,3]]},"44":{"position":[[72,3]]},"76":{"position":[[15,3]]},"78":{"position":[[941,3]]}}}],["nag",{"_index":4789,"t":{"1483":{"position":[[236,8]]}}}],["name",{"_index":725,"t":{"163":{"position":[[125,6]]},"165":{"position":[[348,5],[1422,5]]},"168":{"position":[[143,5]]},"170":{"position":[[242,5]]},"174":{"position":[[1756,4]]},"253":{"position":[[58,6]]},"515":{"position":[[219,4]]},"1014":{"position":[[1523,5]]},"1017":{"position":[[152,5]]},"1041":{"position":[[55,5]]},"1134":{"position":[[637,5]]},"1136":{"position":[[302,4]]},"1291":{"position":[[1019,6]]},"1496":{"position":[[126,4]]},"1587":{"position":[[125,5],[259,5]]},"1728":{"position":[[535,5]]},"1768":{"position":[[523,5],[556,5]]}}}],["narrativeqa",{"_index":5567,"t":{"1772":{"position":[[221,13]]}}}],["natur",{"_index":505,"t":{"102":{"position":[[274,7]]},"130":{"position":[[187,7]]},"213":{"position":[[19,7]]},"546":{"position":[[144,7]]},"594":{"position":[[810,7]]},"743":{"position":[[44,7]]},"784":{"position":[[761,7],[811,7]]},"812":{"position":[[158,7]]},"967":{"position":[[591,7]]},"997":{"position":[[674,7]]},"1012":{"position":[[125,7]]},"1014":{"position":[[368,7]]},"1019":{"position":[[487,7]]},"1060":{"position":[[1002,7]]},"1070":{"position":[[194,7]]},"1091":{"position":[[33,7]]},"1093":{"position":[[197,7],[276,7]]},"1130":{"position":[[389,7]]},"1132":{"position":[[860,7],[918,7],[1515,7],[1550,7]]},"1151":{"position":[[32,7]]},"1159":{"position":[[422,7]]},"1230":{"position":[[559,7]]},"1253":{"position":[[238,7]]},"1289":{"position":[[173,7]]},"1291":{"position":[[725,7]]},"1303":{"position":[[469,7]]},"1419":{"position":[[647,7],[843,7]]},"1434":{"position":[[306,7]]},"1554":{"position":[[172,7]]},"1644":{"position":[[146,7]]},"1646":{"position":[[1256,7]]},"1655":{"position":[[1257,7]]},"1702":{"position":[[688,7]]},"1714":{"position":[[352,7],[410,7]]}}}],["nature/sci",{"_index":3980,"t":{"1151":{"position":[[1905,16]]}}}],["navbar",{"_index":4991,"t":{"1583":{"position":[[93,6]]},"1606":{"position":[[157,7],[264,7]]},"1638":{"position":[[157,7],[257,7]]}}}],["navig",{"_index":127,"t":{"19":{"position":[[187,8]]},"1591":{"position":[[73,10]]},"1606":{"position":[[3,8]]},"1638":{"position":[[3,8]]}}}],["nd×n",{"_index":4078,"t":{"1218":{"position":[[363,4]]}}}],["near",{"_index":1068,"t":{"234":{"position":[[341,4]]},"660":{"position":[[849,4],[929,4]]},"662":{"position":[[1235,4]]}}}],["nearest",{"_index":3971,"t":{"1151":{"position":[[260,7],[456,7],[1291,7],[1397,7],[1585,7]]}}}],["necessari",{"_index":116,"t":{"17":{"position":[[350,9]]}}}],["need",{"_index":117,"t":{"17":{"position":[[377,4]]},"19":{"position":[[179,4]]},"455":{"position":[[13,4]]}}}],["neg",{"_index":1739,"t":{"498":{"position":[[95,8],[552,8]]},"500":{"position":[[827,8],[865,8],[892,8],[1016,8],[1048,8],[1145,8],[1166,8]]},"1466":{"position":[[261,8],[507,8]]},"1468":{"position":[[604,8],[654,8],[980,8],[1156,8],[1311,8]]},"1477":{"position":[[1100,8]]},"1483":{"position":[[62,8],[173,8],[327,8]]},"1485":{"position":[[24,8],[370,8],[946,8],[1142,8]]},"1487":{"position":[[85,8],[193,8],[510,8],[1114,8]]},"1505":{"position":[[48,8],[536,8],[589,8],[1090,8]]},"1515":{"position":[[211,8]]},"1517":{"position":[[9,8]]},"1521":{"position":[[193,8]]},"1646":{"position":[[1218,8]]},"1655":{"position":[[239,8]]},"1698":{"position":[[439,8]]},"1738":{"position":[[470,8]]}}}],["negat",{"_index":5547,"t":{"1762":{"position":[[473,9]]}}}],["negative\\n",{"_index":5630,"t":{"1802":{"position":[[500,10],[669,10]]}}}],["neighbor",{"_index":3972,"t":{"1151":{"position":[[268,9],[464,9],[1299,9],[1405,9],[1593,9]]}}}],["neighborhood",{"_index":3810,"t":{"1101":{"position":[[237,12]]}}}],["neo",{"_index":1709,"t":{"477":{"position":[[41,3]]}}}],["ner",{"_index":5485,"t":{"1728":{"position":[[560,5]]},"1768":{"position":[[719,3]]},"1794":{"position":[[533,4]]}}}],["nettest2013",{"_index":1354,"t":{"324":{"position":[[60,11]]}}}],["network",{"_index":149,"t":{"23":{"position":[[103,7]]},"78":{"position":[[497,7]]},"80":{"position":[[77,7]]},"116":{"position":[[565,7]]},"155":{"position":[[143,7],[171,7]]},"215":{"position":[[12,8]]},"221":{"position":[[302,7],[748,7]]},"287":{"position":[[578,8]]},"292":{"position":[[149,7]]},"298":{"position":[[797,7]]},"304":{"position":[[104,7]]},"310":{"position":[[423,7],[593,7],[789,7],[1518,7]]},"341":{"position":[[252,7]]},"451":{"position":[[118,7]]},"483":{"position":[[100,7]]},"523":{"position":[[662,7],[1008,7]]},"525":{"position":[[59,7],[204,7]]},"527":{"position":[[2498,7]]},"531":{"position":[[575,7],[893,8]]},"533":{"position":[[282,7]]},"598":{"position":[[1326,7],[1764,7],[1871,7],[3222,8]]},"630":{"position":[[1246,7],[1843,7]]},"658":{"position":[[113,7],[1019,7],[1236,7],[1529,7],[1594,7],[1656,8],[2204,7],[2255,7],[2659,7]]},"660":{"position":[[388,7],[501,7],[654,7],[766,7],[978,7],[1014,7]]},"662":{"position":[[1542,7]]},"664":{"position":[[238,7]]},"670":{"position":[[1031,7]]},"676":{"position":[[421,7]]},"713":{"position":[[261,7]]},"733":{"position":[[3,7]]},"786":{"position":[[2658,8]]},"849":{"position":[[313,7]]},"857":{"position":[[821,7]]},"895":{"position":[[426,7]]},"912":{"position":[[115,7]]},"914":{"position":[[135,7]]},"979":{"position":[[776,7]]},"1093":{"position":[[842,8]]},"1107":{"position":[[818,7]]},"1130":{"position":[[193,7]]},"1145":{"position":[[761,7]]},"1157":{"position":[[235,7]]},"1159":{"position":[[1340,7],[1539,7],[1619,7]]},"1167":{"position":[[12,7],[455,7]]},"1170":{"position":[[205,7]]},"1176":{"position":[[58,7],[115,7]]},"1178":{"position":[[74,7],[328,7],[505,7]]},"1185":{"position":[[695,7]]},"1187":{"position":[[497,7]]},"1195":{"position":[[394,7]]},"1197":{"position":[[319,7]]},"1208":{"position":[[100,7],[217,7]]},"1214":{"position":[[120,7]]},"1218":{"position":[[114,7],[412,7],[630,7]]},"1221":{"position":[[246,7]]},"1230":{"position":[[365,7]]},"1244":{"position":[[1713,8]]},"1303":{"position":[[1017,7]]},"1307":{"position":[[128,7]]},"1347":{"position":[[1162,7]]},"1369":{"position":[[65,8]]},"1384":{"position":[[147,7],[298,7],[1798,7],[2252,7]]},"1389":{"position":[[1181,7],[1427,7],[1985,7],[2229,7]]},"1401":{"position":[[615,9]]},"1468":{"position":[[704,7],[737,7],[773,7],[802,7]]},"1475":{"position":[[47,7],[78,7]]},"1489":{"position":[[56,7]]},"1665":{"position":[[173,8],[197,8]]},"1695":{"position":[[216,7],[258,7]]},"1720":{"position":[[844,7]]}}}],["netwrok",{"_index":3958,"t":{"1145":{"position":[[2159,7]]}}}],["neubig",{"_index":1968,"t":{"531":{"position":[[1239,6]]}}}],["neural",{"_index":143,"t":{"23":{"position":[[16,6]]},"27":{"position":[[361,6]]},"215":{"position":[[5,6]]},"287":{"position":[[37,6]]},"451":{"position":[[160,6]]},"455":{"position":[[76,6]]},"504":{"position":[[398,6]]},"658":{"position":[[1648,7]]},"670":{"position":[[912,6]]},"786":{"position":[[381,6],[595,6]]},"1093":{"position":[[835,6]]},"1296":{"position":[[54,6],[592,6]]},"1307":{"position":[[121,6]]},"1401":{"position":[[607,7]]},"1665":{"position":[[166,6],[190,6]]},"1667":{"position":[[59,6],[84,6],[106,6]]},"1695":{"position":[[209,6]]},"1718":{"position":[[376,6]]},"1720":{"position":[[837,6]]},"1794":{"position":[[357,6]]}}}],["neuro",{"_index":1536,"t":{"384":{"position":[[335,5]]}}}],["neutral",{"_index":3643,"t":{"1052":{"position":[[336,9]]},"1655":{"position":[[1323,12]]}}}],["new",{"_index":83,"t":{"13":{"position":[[26,3]]},"17":{"position":[[11,3]]},"138":{"position":[[500,3]]},"215":{"position":[[954,3]]},"384":{"position":[[421,3]]},"521":{"position":[[279,3]]},"525":{"position":[[807,3],[1482,3]]},"527":{"position":[[336,3],[1128,3]]},"533":{"position":[[439,3]]},"587":{"position":[[329,3],[521,3],[557,3],[612,3]]},"589":{"position":[[283,3],[1163,3]]},"592":{"position":[[64,3],[221,3],[276,3]]},"598":{"position":[[107,3],[2069,3]]},"600":{"position":[[288,3]]},"618":{"position":[[458,3]]},"656":{"position":[[115,3],[250,3]]},"658":{"position":[[261,3],[279,3],[564,3],[1218,3],[1545,3],[1742,3],[1834,3],[1888,3],[1969,3],[2078,3],[2277,3]]},"660":{"position":[[241,3],[306,3],[475,3],[532,3],[585,3]]},"662":{"position":[[1344,3]]},"670":{"position":[[1584,3]]},"679":{"position":[[100,3]]},"681":{"position":[[1594,3]]},"686":{"position":[[217,3]]},"688":{"position":[[151,3],[576,3]]},"694":{"position":[[238,3]]},"696":{"position":[[16,3],[97,3],[309,3],[1062,3],[1090,3],[1127,3],[1166,3],[1227,3],[1698,3]]},"707":{"position":[[231,3]]},"709":{"position":[[184,3]]},"711":{"position":[[166,3]]},"719":{"position":[[147,3]]},"801":{"position":[[248,3]]},"843":{"position":[[212,3]]},"847":{"position":[[633,3]]},"849":{"position":[[1296,3],[1526,3]]},"857":{"position":[[482,3]]},"870":{"position":[[1085,3],[2363,3]]},"885":{"position":[[385,3]]},"893":{"position":[[995,3]]},"938":{"position":[[229,3]]},"945":{"position":[[87,3]]},"979":{"position":[[632,3],[1063,3]]},"986":{"position":[[0,3],[574,3]]},"988":{"position":[[171,3]]},"994":{"position":[[17,3]]},"1004":{"position":[[309,3]]},"1006":{"position":[[580,3],[2011,3]]},"1008":{"position":[[4,3],[77,3]]},"1130":{"position":[[800,3]]},"1227":{"position":[[1133,3]]},"1264":{"position":[[49,3]]},"1323":{"position":[[351,3],[400,3]]},"1377":{"position":[[228,3]]},"1384":{"position":[[20,3],[2857,3]]},"1401":{"position":[[172,3]]},"1421":{"position":[[80,3]]},"1577":{"position":[[78,3]]},"1587":{"position":[[520,3]]},"1593":{"position":[[107,3]]},"1612":{"position":[[261,3]]},"1614":{"position":[[123,3]]}}}],["newli",{"_index":125,"t":{"19":{"position":[[141,5]]},"945":{"position":[[885,5]]},"949":{"position":[[548,5]]}}}],["newsqa",{"_index":3574,"t":{"997":{"position":[[703,6]]},"1006":{"position":[[1209,6]]},"1070":{"position":[[230,6]]},"1253":{"position":[[267,6]]}}}],["next",{"_index":722,"t":{"163":{"position":[[48,4]]},"236":{"position":[[14,4]]},"306":{"position":[[155,4]]},"510":{"position":[[220,4]]},"569":{"position":[[1056,4]]},"579":{"position":[[53,4]]},"606":{"position":[[186,4]]},"683":{"position":[[229,4]]},"688":{"position":[[204,4],[734,4]]},"1296":{"position":[[811,4]]},"1303":{"position":[[366,4]]}}}],["nfnet",{"_index":162,"t":{"25":{"position":[[121,6]]},"27":{"position":[[126,6]]}}}],["niv2",{"_index":1989,"t":{"544":{"position":[[177,4]]},"548":{"position":[[16,4]]},"557":{"position":[[97,4]]}}}],["nk<n",{"_index":1290,"t":{"310":{"position":[[1310,4]]}}}],["nk=1,…,n",{"_index":2875,"t":{"797":{"position":[[329,8],[1159,8]]}}}],["nk=n",{"_index":1301,"t":{"310":{"position":[[1741,4]]}}}],["nl",{"_index":3702,"t":{"1070":{"position":[[38,2]]},"1462":{"position":[[11,2]]}}}],["nlayern_\\text{layer}nlay",{"_index":4482,"t":{"1384":{"position":[[2197,27]]}}}],["nlg",{"_index":1006,"t":{"215":{"position":[[2082,3]]},"743":{"position":[[93,6]]},"786":{"position":[[4526,3]]},"805":{"position":[[115,3]]},"826":{"position":[[0,3]]},"833":{"position":[[216,3]]},"843":{"position":[[370,3]]},"1093":{"position":[[225,5]]},"1159":{"position":[[112,3]]},"1266":{"position":[[46,3],[127,3],[214,3],[258,3]]},"1289":{"position":[[201,5]]},"1291":{"position":[[527,3]]},"1303":{"position":[[246,3]]},"1384":{"position":[[2422,3]]},"1389":{"position":[[124,3]]},"1499":{"position":[[447,3]]}}}],["nli",{"_index":4228,"t":{"1283":{"position":[[141,3]]},"1419":{"position":[[674,6]]},"1429":{"position":[[1491,3],[1664,3]]}}}],["nlp",{"_index":373,"t":{"84":{"position":[[0,3]]},"86":{"position":[[262,3]]},"91":{"position":[[15,5]]},"118":{"position":[[0,3]]},"124":{"position":[[0,3]]},"246":{"position":[[294,3]]},"341":{"position":[[124,3]]},"436":{"position":[[355,3]]},"485":{"position":[[1517,3]]},"523":{"position":[[50,3]]},"533":{"position":[[213,3]]},"589":{"position":[[17,3]]},"656":{"position":[[32,3]]},"658":{"position":[[29,3],[626,3],[2870,3]]},"662":{"position":[[63,3]]},"683":{"position":[[110,3]]},"727":{"position":[[75,5]]},"784":{"position":[[80,3]]},"786":{"position":[[22,3],[133,3]]},"851":{"position":[[1092,3]]},"977":{"position":[[826,3]]},"979":{"position":[[120,3]]},"1022":{"position":[[39,3]]},"1060":{"position":[[1030,5]]},"1062":{"position":[[5,3],[1330,3],[1681,3]]},"1070":{"position":[[30,3],[56,3]]},"1084":{"position":[[347,3],[881,3]]},"1250":{"position":[[8,3]]},"1283":{"position":[[12,3]]},"1285":{"position":[[342,3]]},"1357":{"position":[[11,3]]},"1367":{"position":[[7,3]]},"1407":{"position":[[504,3]]},"1409":{"position":[[77,3],[1167,3]]},"1425":{"position":[[300,3]]},"1471":{"position":[[7,3]]},"1475":{"position":[[168,3]]},"1492":{"position":[[4,3]]},"1558":{"position":[[1260,3]]},"1563":{"position":[[79,3]]},"1565":{"position":[[124,3]]},"1644":{"position":[[58,3]]},"1646":{"position":[[12,3],[192,3]]},"1693":{"position":[[0,3]]},"1695":{"position":[[203,3],[334,3]]},"1698":{"position":[[0,3]]},"1770":{"position":[[114,3]]},"1778":{"position":[[14,3]]},"1780":{"position":[[6,3]]},"1782":{"position":[[1404,3],[1526,3]]},"1788":{"position":[[341,3]]}}}],["nlpedia",{"_index":5399,"t":{"1693":{"position":[[541,7]]}}}],["nlu",{"_index":961,"t":{"213":{"position":[[50,5],[311,3],[527,3]]},"215":{"position":[[200,3],[222,3],[942,3],[2142,3],[2397,3],[2469,3],[2586,3]]},"633":{"position":[[15,3]]},"681":{"position":[[7,3]]},"701":{"position":[[24,3]]},"707":{"position":[[421,3]]},"743":{"position":[[75,6]]},"763":{"position":[[7,3]]},"786":{"position":[[4426,3]]},"805":{"position":[[78,3]]},"812":{"position":[[50,3]]},"843":{"position":[[360,4]]},"997":{"position":[[337,3]]},"1012":{"position":[[156,5],[351,3],[471,3]]},"1014":{"position":[[24,3],[1049,3],[1118,3]]},"1017":{"position":[[0,3]]},"1019":{"position":[[478,3]]},"1026":{"position":[[37,3],[351,3]]},"1031":{"position":[[87,3]]},"1033":{"position":[[47,3]]},"1039":{"position":[[46,3]]},"1041":{"position":[[14,3]]},"1043":{"position":[[83,3]]},"1091":{"position":[[64,5]]},"1093":{"position":[[307,5],[434,3],[580,3],[931,3],[1210,3],[1630,3]]},"1101":{"position":[[1204,3]]},"1103":{"position":[[0,3],[77,3]]},"1111":{"position":[[53,3],[972,3]]},"1113":{"position":[[221,3],[644,3]]},"1115":{"position":[[1186,3]]},"1117":{"position":[[13,3]]},"1120":{"position":[[83,3],[237,3]]},"1126":{"position":[[2173,3]]},"1134":{"position":[[460,3]]},"1159":{"position":[[37,3]]},"1181":{"position":[[16,3]]},"1266":{"position":[[0,3],[208,3],[245,3]]},"1291":{"position":[[521,3]]},"1393":{"position":[[133,3]]},"1499":{"position":[[472,3]]}}}],["nmt",{"_index":1969,"t":{"531":{"position":[[1255,3]]}}}],["nn.embedding(n",{"_index":841,"t":{"174":{"position":[[830,15]]},"205":{"position":[[54,15]]}}}],["nnn",{"_index":839,"t":{"174":{"position":[[510,3],[966,3],[1488,3]]},"182":{"position":[[263,3]]},"310":{"position":[[1039,3]]},"362":{"position":[[125,3]]},"596":{"position":[[953,3],[987,3]]},"608":{"position":[[174,3],[493,3]]},"666":{"position":[[483,3],[543,3]]},"670":{"position":[[578,3]]},"686":{"position":[[348,3]]},"694":{"position":[[454,3]]},"797":{"position":[[338,3]]},"809":{"position":[[807,3]]},"853":{"position":[[2130,3]]},"861":{"position":[[343,3],[409,3]]},"866":{"position":[[571,3],[617,3],[902,3]]},"891":{"position":[[30,3]]},"934":{"position":[[1452,3]]},"994":{"position":[[294,3]]},"1128":{"position":[[1437,3]]},"1149":{"position":[[131,3],[274,3],[408,3]]},"1167":{"position":[[99,3]]},"1218":{"position":[[319,3]]},"1350":{"position":[[189,3]]},"1477":{"position":[[189,3]]},"1531":{"position":[[34,3]]},"1540":{"position":[[45,3],[364,3]]},"1657":{"position":[[2277,3]]}}}],["nocap",{"_index":1114,"t":{"249":{"position":[[78,6]]},"251":{"position":[[116,6]]}}}],["node.j",{"_index":88,"t":{"15":{"position":[[0,7],[48,8]]}}}],["nodel",{"_index":2745,"t":{"784":{"position":[[626,5]]}}}],["nogat",{"_index":4574,"t":{"1397":{"position":[[1484,6]]}}}],["nois",{"_index":1125,"t":{"260":{"position":[[92,5]]},"262":{"position":[[23,5],[83,5]]},"887":{"position":[[475,5]]},"1354":{"position":[[308,5]]}}}],["noisi",{"_index":542,"t":{"110":{"position":[[89,5]]},"221":{"position":[[959,5]]},"336":{"position":[[1434,5]]},"339":{"position":[[112,5]]}}}],["nomal",{"_index":229,"t":{"38":{"position":[[336,9]]}}}],["non",{"_index":216,"t":{"35":{"position":[[93,3]]},"91":{"position":[[1473,3]]},"153":{"position":[[152,3],[529,3]]},"159":{"position":[[584,3]]},"234":{"position":[[159,3]]},"267":{"position":[[76,3]]},"557":{"position":[[428,3]]},"563":{"position":[[60,3],[128,3],[227,3],[330,3],[387,3]]},"567":{"position":[[494,3]]},"575":{"position":[[45,3],[63,3],[149,3],[192,3],[281,3]]},"579":{"position":[[30,3]]},"988":{"position":[[1361,3]]},"999":{"position":[[1201,3]]},"1004":{"position":[[454,3]]},"1006":{"position":[[1347,3]]},"1128":{"position":[[862,3]]},"1143":{"position":[[637,3],[678,3]]},"1174":{"position":[[37,3],[90,3]]},"1195":{"position":[[445,4]]},"1462":{"position":[[103,3],[343,3]]},"1796":{"position":[[164,3]]}}}],["none",{"_index":5636,"t":{"1802":{"position":[[869,6]]}}}],["noninvas",{"_index":3761,"t":{"1097":{"position":[[48,13]]}}}],["nonlinear",{"_index":2168,"t":{"598":{"position":[[1879,12]]},"662":{"position":[[865,12]]},"755":{"position":[[109,12]]},"1384":{"position":[[875,9]]}}}],["norm",{"_index":291,"t":{"53":{"position":[[176,4]]},"527":{"position":[[1380,4]]},"531":{"position":[[1370,4]]},"696":{"position":[[1605,4]]},"778":{"position":[[288,4]]},"851":{"position":[[654,4]]},"932":{"position":[[236,6]]},"949":{"position":[[541,4]]},"988":{"position":[[1410,4],[1430,4]]},"994":{"position":[[159,4]]}}}],["normal",{"_index":165,"t":{"25":{"position":[[144,13]]},"91":{"position":[[2142,13]]},"104":{"position":[[248,13],[270,13]]},"189":{"position":[[113,10]]},"225":{"position":[[126,7]]},"292":{"position":[[208,13]]},"294":{"position":[[221,13]]},"319":{"position":[[102,9]]},"498":{"position":[[492,13]]},"555":{"position":[[256,10]]},"567":{"position":[[349,10]]},"569":{"position":[[412,13]]},"589":{"position":[[1934,13]]},"596":{"position":[[1404,13],[1435,13],[1556,13],[1597,10],[1684,10],[1941,10]]},"598":{"position":[[3699,13]]},"602":{"position":[[316,10]]},"620":{"position":[[204,13]]},"662":{"position":[[512,13],[706,13],[1354,13],[1404,13],[1596,13]]},"672":{"position":[[218,13],[1028,13]]},"676":{"position":[[1503,13]]},"774":{"position":[[1134,10]]},"776":{"position":[[34,10]]},"789":{"position":[[1115,13]]},"934":{"position":[[1799,14]]},"945":{"position":[[337,13]]},"961":{"position":[[164,13]]},"1174":{"position":[[4,13]]},"1244":{"position":[[1305,13]]},"1314":{"position":[[810,13]]},"1384":{"position":[[336,13],[930,13]]},"1389":{"position":[[1263,14]]},"1558":{"position":[[1078,13]]},"1657":{"position":[[509,6]]}}}],["nositi",{"_index":1404,"t":{"336":{"position":[[1521,6]]}}}],["notabl",{"_index":3986,"t":{"1157":{"position":[[406,8]]}}}],["notat",{"_index":2151,"t":{"598":{"position":[[1024,9]]},"1298":{"position":[[245,8]]}}}],["notin",{"_index":4307,"t":{"1305":{"position":[[1217,6]]}}}],["noun",{"_index":1639,"t":{"453":{"position":[[84,4]]}}}],["novel",{"_index":2067,"t":{"589":{"position":[[1716,6]]},"679":{"position":[[343,5]]},"681":{"position":[[1275,5]]},"696":{"position":[[391,5]]},"1407":{"position":[[651,5]]},"1409":{"position":[[1281,5],[1550,5]]},"1425":{"position":[[241,5],[502,5]]},"1429":{"position":[[327,5]]},"1436":{"position":[[277,5]]},"1515":{"position":[[104,5]]}}}],["now",{"_index":5023,"t":{"1587":{"position":[[537,3]]},"1593":{"position":[[123,3]]},"1600":{"position":[[70,3],[116,3]]},"1604":{"position":[[173,3]]},"1612":{"position":[[273,3]]},"1614":{"position":[[135,3]]},"1638":{"position":[[237,3]]}}}],["npm",{"_index":105,"t":{"17":{"position":[[151,3]]},"19":{"position":[[42,3],[220,3]]},"1599":{"position":[[32,3]]},"1600":{"position":[[36,3]]},"1604":{"position":[[39,3]]},"1636":{"position":[[38,3]]},"1640":{"position":[[39,3],[123,3]]}}}],["nr=b(0)/n",{"_index":3002,"t":{"803":{"position":[[453,9]]}}}],["nucleu",{"_index":644,"t":{"140":{"position":[[114,7]]}}}],["null",{"_index":5540,"t":{"1756":{"position":[[377,4]]}}}],["num",{"_index":1329,"t":{"317":{"position":[[290,5]]}}}],["num\\cdot",{"_index":1331,"t":{"317":{"position":[[308,8]]}}}],["number",{"_index":1336,"t":{"317":{"position":[[517,6]]},"537":{"position":[[120,6]]},"658":{"position":[[486,6]]},"753":{"position":[[291,6]]},"895":{"position":[[346,6]]},"934":{"position":[[1464,6]]},"1248":{"position":[[188,6],[361,6],[448,6]]},"1362":{"position":[[31,6],[76,6],[515,6]]},"1384":{"position":[[1260,6]]}}}],["nvidia",{"_index":1107,"t":{"244":{"position":[[473,6]]},"315":{"position":[[2,6]]},"612":{"position":[[461,6]]},"622":{"position":[[552,6]]},"705":{"position":[[56,6]]},"807":{"position":[[85,6]]}}}],["nzj=lj​(pij​,zj−1)j=2,3,…,n",{"_index":2518,"t":{"694":{"position":[[684,27]]}}}],["n}m∈{0,1}n×n",{"_index":3116,"t":{"853":{"position":[[333,12]]}}}],["n}s∈rn×n",{"_index":3121,"t":{"853":{"position":[[620,8]]}}}],["n}w∈rn×n",{"_index":3106,"t":{"853":{"position":[[104,8]]}}}],["n}x∈rd×n",{"_index":2464,"t":{"686":{"position":[[195,8]]}}}],["n∈{1,2,3,5,7,9,11,12}n",{"_index":2387,"t":{"670":{"position":[[619,22]]}}}],["o(k⋅n⋅d+n⋅d2)o(k",{"_index":1298,"t":{"310":{"position":[[1660,16]]}}}],["o(logk(n))o(log_k(n))o(logk​(n",{"_index":1295,"t":{"310":{"position":[[1474,32]]}}}],["o(min⁡(d1,d2)d1d2)o(\\min",{"_index":2863,"t":{"795":{"position":[[1245,24]]}}}],["o(n)o(n)o(n",{"_index":1286,"t":{"310":{"position":[[968,12]]},"1531":{"position":[[194,12],[328,12]]},"1533":{"position":[[58,12]]},"1540":{"position":[[140,12]]}}}],["o(n/k)o(n/k)o(n/k",{"_index":1293,"t":{"310":{"position":[[1409,18]]}}}],["o(n/r)o(n/r)o(n/r",{"_index":1288,"t":{"310":{"position":[[1272,18]]}}}],["o(nlog⁡n)o(n",{"_index":4904,"t":{"1540":{"position":[[94,12]]}}}],["obama",{"_index":4283,"t":{"1303":{"position":[[87,6]]}}}],["obj",{"_index":3845,"t":{"1107":{"position":[[889,4],[948,4]]}}}],["object",{"_index":200,"t":{"27":{"position":[[416,6]]},"124":{"position":[[275,6]]},"126":{"position":[[389,6],[886,6],[1054,6]]},"128":{"position":[[137,6]]},"130":{"position":[[33,6],[479,6],[513,6],[579,6],[731,6]]},"132":{"position":[[409,6]]},"143":{"position":[[102,6],[139,6],[391,6]]},"147":{"position":[[326,6]]},"149":{"position":[[132,6]]},"151":{"position":[[0,6]]},"153":{"position":[[0,6]]},"155":{"position":[[105,9],[685,6]]},"157":{"position":[[40,6],[203,6]]},"163":{"position":[[609,7],[743,6]]},"165":{"position":[[66,6],[189,6],[218,6],[487,6],[584,6],[613,6],[1049,6],[1127,6],[1437,7],[1688,6],[2162,6],[2299,6]]},"168":{"position":[[75,6],[594,6]]},"174":{"position":[[660,6],[701,6],[1120,6]]},"177":{"position":[[90,6],[736,6],[1007,6]]},"182":{"position":[[246,6]]},"185":{"position":[[73,6]]},"193":{"position":[[98,6]]},"197":{"position":[[69,6]]},"199":{"position":[[57,6]]},"203":{"position":[[345,6],[427,6]]},"205":{"position":[[155,6]]},"225":{"position":[[616,7],[639,6]]},"227":{"position":[[313,6]]},"230":{"position":[[244,6]]},"279":{"position":[[57,6]]},"339":{"position":[[555,6]]},"343":{"position":[[202,6]]},"453":{"position":[[104,6]]},"483":{"position":[[424,10],[451,10]]},"488":{"position":[[151,10],[374,9]]},"502":{"position":[[534,9]]},"523":{"position":[[103,9]]},"567":{"position":[[55,9],[253,9],[461,9]]},"569":{"position":[[1078,9]]},"577":{"position":[[80,10]]},"579":{"position":[[75,9]]},"594":{"position":[[194,9]]},"602":{"position":[[177,9]]},"723":{"position":[[16,9],[373,9]]},"797":{"position":[[857,9]]},"847":{"position":[[665,9]]},"853":{"position":[[1135,6]]},"870":{"position":[[745,9],[801,9]]},"877":{"position":[[9,9]]},"934":{"position":[[2395,6]]},"1093":{"position":[[94,10]]},"1109":{"position":[[628,6]]},"1132":{"position":[[78,9],[685,9],[1494,9]]},"1143":{"position":[[29,6],[101,9],[509,9],[1041,9]]},"1167":{"position":[[1194,9]]},"1300":{"position":[[122,9]]},"1305":{"position":[[911,9]]},"1350":{"position":[[294,9],[618,6]]},"1352":{"position":[[1059,9]]},"1558":{"position":[[1361,9]]},"1646":{"position":[[300,6],[513,10],[563,9],[649,9],[913,9]]},"1655":{"position":[[716,6],[1120,6]]},"1695":{"position":[[470,9],[510,9],[565,9],[882,6]]}}}],["object365",{"_index":870,"t":{"177":{"position":[[113,9],[134,9]]},"182":{"position":[[309,9]]}}}],["objective(ϕ)=e(x,y)∼dπϕrl[rθ(x,y)−βlog(πϕrl(i",{"_index":4946,"t":{"1558":{"position":[[1400,45]]}}}],["objects365dataset",{"_index":662,"t":{"143":{"position":[[370,17]]}}}],["occlus",{"_index":621,"t":{"130":{"position":[[1487,10]]}}}],["ocr",{"_index":1040,"t":{"225":{"position":[[590,3]]},"934":{"position":[[2067,3]]},"955":{"position":[[290,3],[413,3]]},"971":{"position":[[219,3]]}}}],["oder",{"_index":3083,"t":{"847":{"position":[[811,4]]}}}],["odot",{"_index":1862,"t":{"527":{"position":[[1691,5],[2031,5]]},"598":{"position":[[807,5],[894,7],[1046,5],[1640,5],[1678,5],[1798,5],[2862,5],[2877,5]]},"853":{"position":[[255,5]]}}}],["offer",{"_index":4981,"t":{"1581":{"position":[[122,6]]}}}],["offici",{"_index":4989,"t":{"1583":{"position":[[9,8]]}}}],["offset",{"_index":1184,"t":{"294":{"position":[[368,6]]},"308":{"position":[[750,6]]}}}],["offsit",{"_index":2299,"t":{"648":{"position":[[856,7]]}}}],["oiou",{"_index":914,"t":{"187":{"position":[[93,6]]}}}],["ok",{"_index":1686,"t":{"464":{"position":[[43,2]]},"471":{"position":[[53,3]]},"473":{"position":[[141,2]]},"1704":{"position":[[135,5]]}}}],["okvqa",{"_index":1605,"t":{"434":{"position":[[589,5]]},"464":{"position":[[74,5]]},"473":{"position":[[152,5]]},"475":{"position":[[167,5]]}}}],["omega",{"_index":4763,"t":{"1455":{"position":[[694,8]]}}}],["on",{"_index":1565,"t":{"399":{"position":[[593,3]]},"403":{"position":[[182,3]]},"539":{"position":[[399,3]]},"555":{"position":[[109,4]]},"561":{"position":[[389,3]]},"786":{"position":[[3570,4]]},"887":{"position":[[753,3]]},"1124":{"position":[[434,3]]},"1141":{"position":[[424,3]]},"1238":{"position":[[46,3]]},"1242":{"position":[[440,3]]},"1285":{"position":[[211,3]]},"1303":{"position":[[543,3]]},"1395":{"position":[[688,3]]},"1636":{"position":[[215,3]]},"1682":{"position":[[911,3]]}}}],["onc",{"_index":5150,"t":{"1640":{"position":[[117,5]]}}}],["onclick",{"_index":72,"t":{"9":{"position":[[131,11]]},"1628":{"position":[[269,11]]}}}],["onelin",{"_index":2306,"t":{"658":{"position":[[206,7]]}}}],["oneprompt",{"_index":4841,"t":{"1496":{"position":[[28,9]]}}}],["only(bert",{"_index":4074,"t":{"1214":{"position":[[204,10]]}}}],["ontonot",{"_index":5357,"t":{"1672":{"position":[[159,9],[171,9]]}}}],["ood",{"_index":1585,"t":{"424":{"position":[[391,5]]},"426":{"position":[[198,3]]}}}],["open",{"_index":134,"t":{"19":{"position":[[363,4]]},"246":{"position":[[419,4],[444,4]]},"488":{"position":[[46,4]]},"569":{"position":[[811,4]]},"932":{"position":[[60,4],[872,4]]},"934":{"position":[[899,4]]},"1310":{"position":[[164,4]]},"1646":{"position":[[2989,4]]},"1653":{"position":[[911,4]]},"1682":{"position":[[607,4]]}}}],["openai",{"_index":4912,"t":{"1544":{"position":[[120,6]]},"1552":{"position":[[13,6]]}}}],["openapi",{"_index":4924,"t":{"1552":{"position":[[307,7]]}}}],["openbookqa",{"_index":4226,"t":{"1283":{"position":[[112,11]]}}}],["opennr",{"_index":5346,"t":{"1665":{"position":[[1172,7]]}}}],["openprompt",{"_index":2543,"t":{"705":{"position":[[31,10]]},"1674":{"position":[[254,10]]}}}],["oper",{"_index":1285,"t":{"310":{"position":[[928,10],[994,10]]}}}],["opt",{"_index":1087,"t":{"239":{"position":[[161,3]]},"436":{"position":[[1719,3]]},"459":{"position":[[614,4]]},"466":{"position":[[316,3]]},"477":{"position":[[10,3]]},"479":{"position":[[62,3]]}}}],["optim",{"_index":286,"t":{"53":{"position":[[127,9]]},"78":{"position":[[258,7]]},"182":{"position":[[273,10]]},"244":{"position":[[0,9]]},"317":{"position":[[5,9]]},"341":{"position":[[181,12]]},"347":{"position":[[80,12]]},"529":{"position":[[130,13]]},"550":{"position":[[181,9],[321,7]]},"598":{"position":[[3529,12]]},"602":{"position":[[454,9]]},"626":{"position":[[503,12]]},"628":{"position":[[532,12],[884,12]]},"630":{"position":[[2343,12]]},"633":{"position":[[487,12]]},"648":{"position":[[619,12],[702,13]]},"650":{"position":[[231,12]]},"666":{"position":[[265,9]]},"668":{"position":[[548,7]]},"670":{"position":[[404,7],[527,7],[1515,7]]},"690":{"position":[[197,7],[362,7]]},"705":{"position":[[360,9]]},"709":{"position":[[1318,7]]},"713":{"position":[[90,7],[129,7]]},"719":{"position":[[990,9],[1066,9]]},"784":{"position":[[423,7]]},"821":{"position":[[417,9]]},"861":{"position":[[676,10]]},"866":{"position":[[347,9]]},"1012":{"position":[[479,9]]},"1014":{"position":[[178,9]]},"1062":{"position":[[914,12],[1297,10]]},"1065":{"position":[[872,10]]},"1087":{"position":[[243,12]]},"1093":{"position":[[891,7]]},"1101":{"position":[[275,9]]},"1107":{"position":[[613,7],[1080,9]]},"1111":{"position":[[1239,9]]},"1115":{"position":[[4,7],[135,7],[530,7]]},"1134":{"position":[[804,9]]},"1136":{"position":[[95,10]]},"1143":{"position":[[682,7]]},"1159":{"position":[[226,9]]},"1236":{"position":[[473,7]]},"1314":{"position":[[143,9]]},"1362":{"position":[[14,7],[486,7]]},"1384":{"position":[[1744,12]]},"1462":{"position":[[23,12],[56,12],[107,7]]},"1468":{"position":[[77,9]]},"1477":{"position":[[693,10],[1232,7]]},"1483":{"position":[[98,7]]},"1487":{"position":[[454,8]]},"1489":{"position":[[258,7]]},"1496":{"position":[[628,9]]},"1517":{"position":[[160,7]]},"1546":{"position":[[478,12]]},"1558":{"position":[[1128,12]]},"1730":{"position":[[42,7]]}}}],["optimis",{"_index":1100,"t":{"244":{"position":[[121,9]]}}}],["option",{"_index":2993,"t":{"801":{"position":[[2430,6]]},"1626":{"position":[[107,6],[199,6]]}}}],["oracl",{"_index":4672,"t":{"1431":{"position":[[1608,6],[2740,6]]}}}],["orang",{"_index":1664,"t":{"457":{"position":[[336,6]]},"1536":{"position":[[12,6],[506,6]]}}}],["order",{"_index":124,"t":{"19":{"position":[[117,5]]},"847":{"position":[[147,5],[257,5],[359,5],[410,5],[595,5],[725,5],[738,5],[764,5]]},"849":{"position":[[443,5],[700,5],[1082,5],[1439,5],[1619,5],[1709,5]]},"851":{"position":[[388,5],[402,5],[438,5],[534,5],[563,5],[845,5]]},"853":{"position":[[541,5]]},"855":{"position":[[17,5]]},"870":{"position":[[962,5],[1498,5],[1658,5],[1671,5],[1752,5]]},"879":{"position":[[194,5],[250,5],[312,5]]},"1651":{"position":[[720,5]]},"1738":{"position":[[501,8]]}}}],["organ",{"_index":5208,"t":{"1655":{"position":[[528,12],[580,12],[625,12]]}}}],["organization:par",{"_index":5164,"t":{"1646":{"position":[[1602,21]]}}}],["orient",{"_index":5553,"t":{"1768":{"position":[[392,8]]}}}],["origin",{"_index":992,"t":{"215":{"position":[[912,8]]},"523":{"position":[[235,8]]},"525":{"position":[[1114,8],[1181,8]]},"598":{"position":[[2905,8]]},"658":{"position":[[1902,8],[2093,8],[2246,8]]},"660":{"position":[[492,8],[601,8],[645,8],[757,8],[969,8]]},"662":{"position":[[789,8]]},"672":{"position":[[1353,8]]},"681":{"position":[[1646,8]]},"688":{"position":[[701,8],[1042,8]]},"696":{"position":[[585,8]]},"786":{"position":[[3820,8]]},"795":{"position":[[1942,8]]},"799":{"position":[[141,8]]},"849":{"position":[[295,8],[370,8],[563,8]]},"977":{"position":[[530,8]]},"986":{"position":[[697,8]]},"1008":{"position":[[152,8]]},"1014":{"position":[[811,8]]},"1099":{"position":[[1743,8]]},"1101":{"position":[[92,8]]},"1107":{"position":[[121,8],[409,8]]},"1109":{"position":[[568,8]]},"1143":{"position":[[565,9]]},"1145":{"position":[[1468,8]]},"1159":{"position":[[1634,8]]},"1178":{"position":[[390,8]]},"1185":{"position":[[346,8]]},"1189":{"position":[[149,8]]},"1195":{"position":[[564,8]]},"1197":{"position":[[339,8]]},"1230":{"position":[[92,8]]},"1357":{"position":[[141,8]]},"1364":{"position":[[391,8]]},"1384":{"position":[[1206,8],[3195,8],[3449,8]]},"1389":{"position":[[1699,8]]},"1393":{"position":[[453,8]]},"1468":{"position":[[764,8]]},"1489":{"position":[[47,8],[403,8]]},"1505":{"position":[[286,8]]},"1525":{"position":[[51,8]]},"1762":{"position":[[169,8]]}}}],["orthogon",{"_index":2782,"t":{"786":{"position":[[4090,10],[4182,13]]},"795":{"position":[[867,13],[1838,10]]},"839":{"position":[[227,10],[304,10],[479,10]]},"1062":{"position":[[1832,10]]},"1073":{"position":[[258,10]]}}}],["osft",{"_index":4079,"t":{"1218":{"position":[[368,4]]}}}],["osvaldo",{"_index":1582,"t":{"424":{"position":[[87,7]]}}}],["other",{"_index":3576,"t":{"997":{"position":[[721,7]]},"1070":{"position":[[237,6]]},"1253":{"position":[[285,6]]}}}],["oto_tot",{"_index":4732,"t":{"1447":{"position":[[203,8]]}}}],["otp",{"_index":1615,"t":{"436":{"position":[[2212,3]]}}}],["out",{"_index":1244,"t":{"302":{"position":[[784,3]]},"424":{"position":[[377,3]]},"550":{"position":[[341,3]]},"553":{"position":[[81,3]]},"575":{"position":[[259,3]]},"594":{"position":[[1000,3]]},"598":{"position":[[3018,3]]},"1147":{"position":[[395,3],[449,3],[494,3],[947,4]]},"1517":{"position":[[283,3]]}}}],["outperform",{"_index":4585,"t":{"1409":{"position":[[964,10]]}}}],["output",{"_index":520,"t":{"104":{"position":[[545,6]]},"124":{"position":[[586,6]]},"126":{"position":[[690,6],[1165,6],[1229,6]]},"130":{"position":[[19,6],[328,6],[451,6]]},"132":{"position":[[31,6],[439,6],[513,6],[552,6],[611,6]]},"140":{"position":[[573,6]]},"159":{"position":[[41,6]]},"215":{"position":[[1903,9]]},"225":{"position":[[151,6],[280,6]]},"285":{"position":[[84,6],[290,6],[430,6]]},"287":{"position":[[82,6],[794,6]]},"289":{"position":[[266,6]]},"292":{"position":[[460,6]]},"294":{"position":[[127,6],[340,6]]},"296":{"position":[[43,6],[99,6]]},"298":{"position":[[362,6]]},"300":{"position":[[344,6]]},"302":{"position":[[159,6],[459,6]]},"304":{"position":[[455,6]]},"306":{"position":[[136,6]]},"310":{"position":[[661,6],[812,6],[1195,6],[1354,6]]},"319":{"position":[[66,6]]},"326":{"position":[[111,6],[749,6]]},"384":{"position":[[481,6],[620,6],[755,7]]},"393":{"position":[[18,6]]},"494":{"position":[[116,6]]},"498":{"position":[[391,6]]},"500":{"position":[[631,6],[750,6]]},"527":{"position":[[1064,6],[1116,7]]},"531":{"position":[[1269,6],[1308,6]]},"596":{"position":[[1659,6]]},"608":{"position":[[814,6]]},"622":{"position":[[317,10]]},"662":{"position":[[497,6],[686,6]]},"698":{"position":[[205,6]]},"709":{"position":[[1866,6]]},"721":{"position":[[71,6]]},"733":{"position":[[688,6]]},"789":{"position":[[583,6]]},"807":{"position":[[196,6]]},"853":{"position":[[209,6]]},"861":{"position":[[2000,6]]},"887":{"position":[[304,6]]},"891":{"position":[[16,6]]},"893":{"position":[[2232,6]]},"905":{"position":[[67,6]]},"979":{"position":[[1427,6]]},"1097":{"position":[[120,6]]},"1099":{"position":[[393,6]]},"1101":{"position":[[1108,6]]},"1107":{"position":[[826,6]]},"1126":{"position":[[1375,6],[2025,6]]},"1128":{"position":[[78,6]]},"1130":{"position":[[470,6],[520,6],[607,6],[622,6]]},"1132":{"position":[[227,6],[469,6],[1064,6],[1295,6],[1540,6]]},"1145":{"position":[[1048,6],[1113,6]]},"1151":{"position":[[1456,6],[1492,6]]},"1159":{"position":[[557,6]]},"1162":{"position":[[124,6],[204,6]]},"1167":{"position":[[1275,6]]},"1187":{"position":[[113,6]]},"1244":{"position":[[698,6],[1136,6]]},"1291":{"position":[[804,6],[1061,6]]},"1294":{"position":[[22,6]]},"1303":{"position":[[404,6]]},"1354":{"position":[[277,6]]},"1369":{"position":[[27,6]]},"1384":{"position":[[355,6],[495,6]]},"1389":{"position":[[1051,6],[1289,6],[1316,6],[1536,6],[1915,6]]},"1445":{"position":[[100,6]]},"1449":{"position":[[56,6],[271,6],[577,6]]},"1453":{"position":[[255,6]]},"1462":{"position":[[423,6],[482,6]]},"1485":{"position":[[478,6],[995,6]]},"1544":{"position":[[207,6]]},"1546":{"position":[[423,6],[776,6]]},"1550":{"position":[[159,6]]},"1558":{"position":[[949,7]]},"1693":{"position":[[87,6],[301,6]]},"1698":{"position":[[54,6],[141,6],[195,6],[551,6]]},"1704":{"position":[[680,6],[723,6]]},"1706":{"position":[[45,6],[97,6],[138,6],[275,6]]},"1718":{"position":[[67,6],[1149,6]]},"1722":{"position":[[69,6]]},"1726":{"position":[[54,6],[75,6]]},"1728":{"position":[[236,6]]},"1730":{"position":[[206,6],[297,6]]},"1736":{"position":[[836,6],[1543,6]]}}}],["over",{"_index":990,"t":{"215":{"position":[[843,4],[1225,4]]},"531":{"position":[[192,4],[226,4]]},"569":{"position":[[51,4]]},"719":{"position":[[357,4]]},"921":{"position":[[57,4],[123,4]]},"988":{"position":[[1861,4]]},"1159":{"position":[[1092,5]]},"1468":{"position":[[718,4]]},"1475":{"position":[[28,4]]}}}],["overal",{"_index":913,"t":{"187":{"position":[[81,7]]},"191":{"position":[[271,7]]},"853":{"position":[[2136,7]]},"857":{"position":[[439,7]]},"873":{"position":[[924,7],[1105,7]]},"1702":{"position":[[359,8],[417,8]]}}}],["overfit",{"_index":2555,"t":{"709":{"position":[[473,11]]},"786":{"position":[[3577,11]]},"851":{"position":[[6,11]]},"1093":{"position":[[716,11]]},"1111":{"position":[[1553,11]]},"1115":{"position":[[834,11]]},"1120":{"position":[[143,11]]},"1147":{"position":[[165,11]]},"1153":{"position":[[385,11]]},"1326":{"position":[[222,11]]},"1379":{"position":[[444,11]]},"1501":{"position":[[378,11]]},"1558":{"position":[[365,7],[382,7]]}}}],["overhead",{"_index":2573,"t":{"719":{"position":[[959,8]]},"786":{"position":[[2161,8]]},"795":{"position":[[1464,8]]},"992":{"position":[[1054,8]]},"1291":{"position":[[1545,8]]},"1399":{"position":[[630,8]]}}}],["overleftarrow{h}_i",{"_index":3819,"t":{"1101":{"position":[[820,21]]}}}],["overline{i}^{(t",{"_index":2981,"t":{"801":{"position":[[1734,16]]}}}],["overline{i}^{(t)}(w_{ij",{"_index":2979,"t":{"801":{"position":[[1696,26],[1902,26],[2514,26]]}}}],["overline{u}^{(t",{"_index":2985,"t":{"801":{"position":[[1833,16]]}}}],["overline{u}^{(t)}(w_{ij",{"_index":2984,"t":{"801":{"position":[[1795,26],[2547,27]]}}}],["overparameter",{"_index":1956,"t":{"531":{"position":[[511,20]]},"847":{"position":[[37,16]]},"1172":{"position":[[205,20]]},"1210":{"position":[[11,20]]}}}],["overset{\\underset{\\mathrm{\\triangl",{"_index":3657,"t":{"1065":{"position":[[16,44]]}}}],["overview",{"_index":1422,"t":{"345":{"position":[[124,8]]}}}],["overwhelm",{"_index":1452,"t":{"352":{"position":[[810,9],[851,9]]}}}],["ovi",{"_index":896,"t":{"177":{"position":[[1300,5]]},"197":{"position":[[14,4]]}}}],["oxford",{"_index":498,"t":{"102":{"position":[[190,6]]}}}],["oxfordpet",{"_index":1508,"t":{"374":{"position":[[99,10]]}}}],["p",{"_index":232,"t":{"38":{"position":[[365,1]]},"189":{"position":[[168,3]]},"596":{"position":[[169,1],[597,1]]},"686":{"position":[[256,3]]},"688":{"position":[[184,3]]},"703":{"position":[[140,1]]},"707":{"position":[[141,1],[591,1]]},"786":{"position":[[3997,1]]},"795":{"position":[[169,1],[975,1]]},"901":{"position":[[63,1],[130,1]]},"905":{"position":[[401,2]]},"926":{"position":[[105,1]]},"984":{"position":[[639,3]]},"1012":{"position":[[457,1],[553,1]]},"1014":{"position":[[1440,1]]},"1019":{"position":[[437,1]]},"1022":{"position":[[24,1]]},"1026":{"position":[[24,1],[260,1],[401,1]]},"1028":{"position":[[24,1],[251,1],[348,1]]},"1033":{"position":[[16,1]]},"1035":{"position":[[105,1]]},"1037":{"position":[[106,1],[188,1]]},"1039":{"position":[[0,1],[173,2]]},"1041":{"position":[[0,1]]},"1047":{"position":[[10,1],[82,1],[132,1],[254,1],[357,1]]},"1049":{"position":[[15,1],[121,1],[168,1],[349,1]]},"1052":{"position":[[89,1]]},"1054":{"position":[[26,1]]},"1056":{"position":[[0,1],[146,1]]},"1065":{"position":[[747,1],[756,3]]},"1070":{"position":[[670,1]]},"1077":{"position":[[75,1]]},"1091":{"position":[[146,1],[356,1],[425,1]]},"1093":{"position":[[913,1],[1151,1],[1187,1],[1394,1],[1430,1],[1516,1],[1612,1],[1694,1]]},"1097":{"position":[[23,1]]},"1099":{"position":[[1414,1]]},"1101":{"position":[[433,1]]},"1103":{"position":[[60,1]]},"1107":{"position":[[838,1]]},"1109":{"position":[[21,1],[270,1],[379,1],[472,1],[719,1],[861,1],[898,1],[1021,1],[1120,1],[1247,1],[1342,1]]},"1111":{"position":[[0,1],[90,1],[1065,1],[1678,1],[1979,1]]},"1113":{"position":[[44,1],[161,1],[252,1],[344,1],[543,1]]},"1115":{"position":[[212,1],[563,1],[663,1],[924,1],[989,1],[1094,1],[1166,1]]},"1117":{"position":[[57,1],[150,1],[247,1],[271,1],[354,1],[390,1]]},"1120":{"position":[[7,1]]},"1145":{"position":[[1266,1],[1390,1]]},"1164":{"position":[[369,3]]},"1167":{"position":[[291,2]]},"1185":{"position":[[139,2]]},"1238":{"position":[[888,1],[914,2]]},"1242":{"position":[[645,3],[661,3]]},"1244":{"position":[[364,3],[925,1],[973,1]]},"1246":{"position":[[715,3]]},"1357":{"position":[[330,1]]},"1384":{"position":[[1861,2]]},"1389":{"position":[[844,2],[868,2],[883,2],[951,2]]},"1494":{"position":[[276,1],[307,1],[453,1],[472,1]]},"1499":{"position":[[183,1],[194,1],[339,1],[368,1],[396,1]]},"1634":{"position":[[58,1]]},"1720":{"position":[[2026,1]]},"1758":{"position":[[98,1]]}}}],["p'_1",{"_index":4011,"t":{"1167":{"position":[[296,6]]}}}],["p'_\\theta",{"_index":4314,"t":{"1307":{"position":[[249,10]]}}}],["p'_n",{"_index":4012,"t":{"1167":{"position":[[311,5]]}}}],["p([m]j​=wj,k​∣t(x",{"_index":5325,"t":{"1659":{"position":[[1002,21]]}}}],["p([𝙼]_j",{"_index":5283,"t":{"1657":{"position":[[2089,8],[2946,8]]},"1659":{"position":[[950,8]]}}}],["p([𝙼]j=wj,k∣t(x))\\begin{equ",{"_index":5320,"t":{"1659":{"position":[[878,34]]}}}],["p([𝙼]j=ϕj(yx)∣t(x))p([𝙼]_j",{"_index":5317,"t":{"1659":{"position":[[784,28]]}}}],["p(f_{fill}(x",{"_index":5427,"t":{"1704":{"position":[[559,14]]}}}],["p(feo(b,person)=false)p(f_{e_o}(b",{"_index":5247,"t":{"1657":{"position":[[261,34]]}}}],["p(fes(a,person)=true)p(f_{e_s}(a",{"_index":5245,"t":{"1657":{"position":[[172,33]]}}}],["p(fes,eo(a,′",{"_index":5239,"t":{"1657":{"position":[[43,13]]}}}],["p(ffill(x′,z);θ).(1)\\hat{z",{"_index":5424,"t":{"1704":{"position":[[481,27]]}}}],["p(ffill​(x′,z);θ).(1",{"_index":5429,"t":{"1704":{"position":[[608,21]]}}}],["p(i",{"_index":4402,"t":{"1352":{"position":[[1185,4]]}}}],["p(x)p(x)p(x",{"_index":5532,"t":{"1746":{"position":[[26,12]]}}}],["p(x;θ)p(x;\\theta)p(x",{"_index":5433,"t":{"1708":{"position":[[71,23]]}}}],["p(xt∣[x<t;xdiagnosis];θ)p(x_t",{"_index":5578,"t":{"1778":{"position":[[631,29]]}}}],["p(xt∣x<t;θ)p(x_t",{"_index":5575,"t":{"1778":{"position":[[531,16]]}}}],["p(y=c∣h)=ewch[cls]∑k∈cewkh[cls]p(i",{"_index":4051,"t":{"1185":{"position":[[493,34]]}}}],["p(y_i",{"_index":3690,"t":{"1067":{"position":[[881,5]]},"1720":{"position":[[540,6]]}}}],["p(y_i|x_i))^2,w=∣d∣1​i=1∑∣d∣​(▽w​logp(yi​∣xi​))2",{"_index":2271,"t":{"630":{"position":[[1493,49]]}}}],["p(y_j|x,y_{1:j",{"_index":632,"t":{"132":{"position":[[831,14]]}}}],["p(y_t",{"_index":1074,"t":{"236":{"position":[[191,5]]}}}],["p(y_t|\\text{x},y_{<t}).β(x,y)=t1​∑t=1t​logp(yt​∣x,y<t",{"_index":2125,"t":{"596":{"position":[[1798,56]]}}}],["p(y_{x}|x",{"_index":5301,"t":{"1657":{"position":[[3020,11]]}}}],["p(yi​∣xi",{"_index":4164,"t":{"1244":{"position":[[1056,9]]}}}],["p(yi∣xi",{"_index":4154,"t":{"1244":{"position":[[784,7]]}}}],["p(yj∣x,y1:j−1)p(y_j|x,y_{1:j",{"_index":642,"t":{"140":{"position":[[48,28]]}}}],["p(yt​∣y<t​,z",{"_index":1076,"t":{"236":{"position":[[221,13]]}}}],["p(yt∣y<t,z)l",{"_index":1072,"t":{"236":{"position":[[155,12]]}}}],["p(y|[p_",{"_index":4787,"t":{"1477":{"position":[[815,9]]}}}],["p(y|x",{"_index":5281,"t":{"1657":{"position":[[2060,6]]}}}],["p(y|x;\\theta;\\phi",{"_index":5451,"t":{"1720":{"position":[[483,18]]}}}],["p(y∣x)=∏j=1np([𝙼]j=ϕ(y)∣t(x))∑y~∈y∏j=1np([𝙼]j=ϕ(y~)∣t(x))\\begin{equ",{"_index":5280,"t":{"1657":{"position":[[1984,75]]}}}],["p(y∣x)=∑z∈para(z′)p(z∣x)p(y|x",{"_index":5493,"t":{"1730":{"position":[[332,30]]}}}],["p(y∣x)p(y|x)p(y∣x",{"_index":5392,"t":{"1693":{"position":[[106,18]]}}}],["p(y∣x;θ)p(y|x",{"_index":4116,"t":{"1238":{"position":[[242,14]]}}}],["p(y∣x;θ)p(y|x;\\theta)p(y∣x",{"_index":5407,"t":{"1698":{"position":[[73,29]]}}}],["p(z_t|f_{\\textup{prompt",{"_index":5517,"t":{"1736":{"position":[[1447,24]]}}}],["p(zt∣x,z<t):=1k∑ikp(zt∣fprompt",{"_index":5515,"t":{"1736":{"position":[[1366,31]]}}}],["p(z|f_{prompt",{"_index":5507,"t":{"1736":{"position":[[375,14]]}}}],["p(z∣x):=1k∑ikp(z∣fprompt,i(x))p(z|x",{"_index":5504,"t":{"1736":{"position":[[314,36]]}}}],["p(⋅;θ)p(\\cdot",{"_index":5421,"t":{"1704":{"position":[[395,13]]}}}],["p)(1",{"_index":4126,"t":{"1238":{"position":[[949,7]]}}}],["p)(1)\\mathcal{l}_{plm",{"_index":4124,"t":{"1238":{"position":[[847,24]]}}}],["p)(p,p",{"_index":417,"t":{"91":{"position":[[338,7]]}}}],["p,p)(p",{"_index":416,"t":{"91":{"position":[[329,8]]}}}],["p0p_0p0",{"_index":5634,"t":{"1802":{"position":[[596,8]]}}}],["p1",{"_index":3470,"t":{"982":{"position":[[320,4]]}}}],["p1,p2,…,pkp_1",{"_index":4391,"t":{"1352":{"position":[[691,14]]}}}],["p1,…,pn][p_1",{"_index":4007,"t":{"1167":{"position":[[121,14]]}}}],["p1,…,pt][p_1",{"_index":3481,"t":{"984":{"position":[[87,14]]}}}],["p100",{"_index":1150,"t":{"285":{"position":[[494,4]]},"315":{"position":[[9,4]]},"322":{"position":[[138,4]]}}}],["p1p_1p1",{"_index":5635,"t":{"1802":{"position":[[767,8]]}}}],["p2p_1",{"_index":3471,"t":{"982":{"position":[[325,7]]}}}],["p3",{"_index":2074,"t":{"594":{"position":[[443,4]]}}}],["p36",{"_index":3779,"t":{"1099":{"position":[[704,4]]}}}],["p;t]∈r(l+n)×d[p",{"_index":4127,"t":{"1238":{"position":[[970,17]]}}}],["p;wi]∈r(l+1s)×d[p;w_i",{"_index":3667,"t":{"1065":{"position":[[558,23]]}}}],["p;x",{"_index":3496,"t":{"984":{"position":[[676,9]]}}}],["p;x]).\\begin{equ",{"_index":3491,"t":{"984":{"position":[[579,23]]}}}],["p;x][p",{"_index":3487,"t":{"984":{"position":[[426,8]]}}}],["p<0.001p",{"_index":4676,"t":{"1431":{"position":[[1902,9],[1932,9],[1992,9]]}}}],["p<0.01p",{"_index":4678,"t":{"1431":{"position":[[1963,8]]}}}],["p<0.05p",{"_index":3006,"t":{"805":{"position":[[159,7]]}}}],["p=0.75",{"_index":3399,"t":{"905":{"position":[[414,6]]}}}],["p=0.75\\text{top",{"_index":3397,"t":{"905":{"position":[[385,15]]}}}],["p=[p1,…,pm]∈rm×dp",{"_index":3483,"t":{"984":{"position":[[261,17]]}}}],["p={p1,p2,…,,pn}p",{"_index":3885,"t":{"1128":{"position":[[648,16]]}}}],["p={p1​,p2​,…,,pn",{"_index":3888,"t":{"1128":{"position":[[693,20]]}}}],["p={pk}k=1n\\mathcal{p",{"_index":2883,"t":{"797":{"position":[[569,21]]}}}],["p>thi",{"_index":5087,"t":{"1612":{"position":[[216,7]]}}}],["p@1",{"_index":3749,"t":{"1091":{"position":[[249,5]]},"1120":{"position":[[202,5]]}}}],["p\\bold{p}p",{"_index":3777,"t":{"1099":{"position":[[595,10]]}}}],["p\\theta_pθp",{"_index":3889,"t":{"1128":{"position":[[1003,13],[1396,13]]},"1164":{"position":[[243,13]]},"1167":{"position":[[1088,13]]}}}],["p^1_i",{"_index":2504,"t":{"694":{"position":[[317,6]]}}}],["p^2",{"_index":409,"t":{"91":{"position":[[251,3],[1706,3]]}}}],["p^2_i",{"_index":2505,"t":{"694":{"position":[[324,6]]}}}],["p^=p∗∘wk=p∗∘(uk⨂vkt)(2)\\hat{p",{"_index":4142,"t":{"1242":{"position":[[612,30]]}}}],["p^\\hat{p}p",{"_index":3521,"t":{"988":{"position":[[769,11]]},"1242":{"position":[[583,11]]}}}],["p^\\top",{"_index":2858,"t":{"795":{"position":[[968,6]]}}}],["p^e=γ⋅pe\\begin{equ",{"_index":4791,"t":{"1485":{"position":[[126,24]]}}}],["p^j\\hat{p}_jp^j",{"_index":3537,"t":{"988":{"position":[[1527,16]]}}}],["p^j∈rd\\hat{p}_j",{"_index":3516,"t":{"988":{"position":[[533,15]]}}}],["p^k",{"_index":4156,"t":{"1244":{"position":[[820,6],[1097,7]]}}}],["p^k=p∗∘(uk⨂vkt)\\hat{p}_k",{"_index":4149,"t":{"1244":{"position":[[337,24]]}}}],["p^k∈r100×d\\hat{p}_k",{"_index":4211,"t":{"1255":{"position":[[136,19]]}}}],["p^n_i",{"_index":2506,"t":{"694":{"position":[[338,5]]}}}],["p^t=p∗∘(ut⨂vtt)\\hat{p}_t",{"_index":4194,"t":{"1246":{"position":[[688,24]]}}}],["p_",{"_index":3691,"t":{"1067":{"position":[[889,5]]},"1162":{"position":[[308,3]]},"1164":{"position":[[361,3]]}}}],["p_1",{"_index":3484,"t":{"984":{"position":[[281,5]]},"1128":{"position":[[670,4]]},"1477":{"position":[[440,4]]}}}],["p_2",{"_index":3886,"t":{"1128":{"position":[[675,4]]},"1352":{"position":[[706,4]]},"1477":{"position":[[445,4]]}}}],["p_2p1​,⋯,p2",{"_index":3472,"t":{"982":{"position":[[340,13]]}}}],["p_\\phi",{"_index":4371,"t":{"1350":{"position":[[393,6],[719,6]]}}}],["p_\\theta",{"_index":3493,"t":{"984":{"position":[[623,8]]},"986":{"position":[[475,8]]},"1167":{"position":[[1418,8]]},"1305":{"position":[[704,8]]},"1350":{"position":[[731,9]]}}}],["p_c",{"_index":1445,"t":{"350":{"position":[[925,3]]}}}],["p_c(x)\\cdot",{"_index":4403,"t":{"1352":{"position":[[1193,12]]}}}],["p_e",{"_index":4793,"t":{"1485":{"position":[[176,3]]}}}],["p_i",{"_index":4020,"t":{"1167":{"position":[[630,3]]}}}],["p_j",{"_index":3550,"t":{"990":{"position":[[205,4]]}}}],["p_j(x",{"_index":4394,"t":{"1352":{"position":[[830,6]]},"1354":{"position":[[431,6]]}}}],["p_k",{"_index":2488,"t":{"688":{"position":[[847,5]]},"797":{"position":[[274,3],[596,3]]}}}],["p_k^{(teacher",{"_index":4161,"t":{"1244":{"position":[[953,16]]}}}],["p_kp1​,p2​,…,pk",{"_index":4392,"t":{"1352":{"position":[[718,16]]}}}],["p_l",{"_index":3292,"t":{"891":{"position":[[175,3],[781,5]]},"893":{"position":[[617,5],[668,5]]},"895":{"position":[[934,3]]}}}],["p_l^v",{"_index":3386,"t":{"895":{"position":[[926,5]]}}}],["p_m",{"_index":3485,"t":{"984":{"position":[[294,4]]},"1477":{"position":[[457,3]]}}}],["p_n",{"_index":3887,"t":{"1128":{"position":[[689,3]]}}}],["p_n][p1​,…,pn",{"_index":4008,"t":{"1167":{"position":[[144,15]]}}}],["p_v",{"_index":2491,"t":{"688":{"position":[[914,5]]}}}],["p_{*i",{"_index":2851,"t":{"795":{"position":[[637,7]]}}}],["p_{\\phi",{"_index":4278,"t":{"1300":{"position":[[337,8]]}}}],["p_{\\phi_0",{"_index":2609,"t":{"723":{"position":[[1257,10]]}}}],["p_{\\phi}(i",{"_index":4275,"t":{"1300":{"position":[[255,11]]}}}],["p_{\\phi}(y_t",{"_index":2601,"t":{"723":{"position":[[564,13]]}}}],["p_{\\theta_2},\\dots,p_{\\theta_k}pθ1​​,pθ2​​,…,pθk",{"_index":4385,"t":{"1352":{"position":[[406,50]]}}}],["p_{\\theta_c",{"_index":4404,"t":{"1352":{"position":[[1206,13]]}}}],["p_{\\theta}(y_i",{"_index":1625,"t":{"441":{"position":[[271,14]]}}}],["p_{instanc",{"_index":3505,"t":{"986":{"position":[[491,14]]}}}],["p_{instance}(x",{"_index":3547,"t":{"990":{"position":[[151,15]]}}}],["p_{k,*i",{"_index":2877,"t":{"797":{"position":[[416,9]]}}}],["p_{t+1})ptarget",{"_index":3499,"t":{"986":{"position":[[62,18]]}}}],["p_{t+1})ptarget​(=pt+1",{"_index":3553,"t":{"990":{"position":[[503,26]]}}}],["p_{target",{"_index":3548,"t":{"990":{"position":[[169,10]]}}}],["p_{t}][p1​,…,pt",{"_index":3482,"t":{"984":{"position":[[109,17]]}}}],["pa",{"_index":5331,"t":{"1665":{"position":[[126,2]]}}}],["pack",{"_index":1997,"t":{"550":{"position":[[255,7]]}}}],["pad",{"_index":5126,"t":{"1628":{"position":[[230,8]]}}}],["pada",{"_index":5542,"t":{"1758":{"position":[[91,4]]}}}],["page",{"_index":136,"t":{"19":{"position":[[388,5]]},"1585":{"position":[[21,4],[68,5]]},"1591":{"position":[[24,5]]},"1610":{"position":[[64,5]]},"1612":{"position":[[265,4],[321,5]]},"1614":{"position":[[92,4],[116,4],[127,4],[186,5]]},"1620":{"position":[[121,6],[216,5]]},"1636":{"position":[[154,4]]}}}],["page.j",{"_index":5080,"t":{"1612":{"position":[[36,8],[64,7]]}}}],["page.md",{"_index":5090,"t":{"1614":{"position":[[39,8],[70,7]]},"1620":{"position":[[172,9]]}}}],["page</h1",{"_index":5086,"t":{"1612":{"position":[[206,9]]}}}],["page</p",{"_index":5088,"t":{"1612":{"position":[[235,8]]}}}],["page](./cr",{"_index":5098,"t":{"1620":{"position":[[155,14]]}}}],["page](/cr",{"_index":5097,"t":{"1620":{"position":[[105,13]]}}}],["pai",{"_index":1291,"t":{"310":{"position":[[1367,5]]}}}],["pair",{"_index":718,"t":{"159":{"position":[[408,6]]},"313":{"position":[[18,5],[76,4],[273,5]]},"336":{"position":[[60,4]]},"350":{"position":[[127,4]]},"393":{"position":[[25,4]]},"498":{"position":[[114,5]]},"500":{"position":[[800,4],[1083,5],[1175,5]]},"589":{"position":[[642,5],[946,5]]},"757":{"position":[[61,5]]},"905":{"position":[[74,5]]},"932":{"position":[[430,4]]},"934":{"position":[[993,5],[2133,4]]},"949":{"position":[[244,5]]},"951":{"position":[[104,5]]},"969":{"position":[[271,5]]},"973":{"position":[[111,5],[263,5]]},"1060":{"position":[[871,4]]},"1067":{"position":[[284,4],[1406,4]]},"1070":{"position":[[1838,5]]},"1080":{"position":[[451,4]]},"1084":{"position":[[202,4],[1153,4]]},"1270":{"position":[[155,5]]},"1384":{"position":[[265,4]]},"1427":{"position":[[68,5]]},"1429":{"position":[[895,4]]},"1712":{"position":[[279,4]]},"1766":{"position":[[412,4]]}}}],["palm",{"_index":1530,"t":{"382":{"position":[[293,4]]},"384":{"position":[[990,4]]},"397":{"position":[[74,4]]},"399":{"position":[[188,4],[334,4],[542,4],[562,4]]},"416":{"position":[[91,4]]},"424":{"position":[[270,4]]},"537":{"position":[[204,8],[219,6]]},"539":{"position":[[279,4],[378,4],[550,4]]},"550":{"position":[[4,5],[12,4]]},"553":{"position":[[5,4]]},"557":{"position":[[45,4]]},"559":{"position":[[77,4]]},"561":{"position":[[160,4],[249,4],[308,4],[408,4]]},"565":{"position":[[159,4],[232,4],[244,4]]},"567":{"position":[[104,4],[166,4],[211,4],[237,4],[298,4],[658,4]]},"569":{"position":[[603,4],[615,4],[646,4],[693,4],[735,4],[1026,4],[1141,4]]},"577":{"position":[[54,4],[292,6]]},"579":{"position":[[132,4],[234,4]]},"581":{"position":[[91,4]]},"583":{"position":[[36,4]]},"681":{"position":[[68,4]]},"683":{"position":[[333,4]]}}}],["pan",{"_index":1014,"t":{"215":{"position":[[2283,4]]}}}],["panda",{"_index":4097,"t":{"1234":{"position":[[156,5]]}}}],["pang",{"_index":1019,"t":{"215":{"position":[[2345,5]]}}}],["paper",{"_index":1516,"t":{"380":{"position":[[106,5]]},"1070":{"position":[[729,6]]}}}],["para",{"_index":5490,"t":{"1730":{"position":[[246,4]]}}}],["paradigm",{"_index":729,"t":{"163":{"position":[[324,8]]},"563":{"position":[[315,8]]},"587":{"position":[[377,8]]},"932":{"position":[[481,8]]},"949":{"position":[[216,8]]},"1093":{"position":[[376,9]]},"1117":{"position":[[45,8],[480,8]]},"1695":{"position":[[397,8]]},"1708":{"position":[[387,8]]}}}],["paragraph",{"_index":2313,"t":{"658":{"position":[[899,9]]},"674":{"position":[[188,9]]}}}],["parallel",{"_index":1232,"t":{"300":{"position":[[1204,8]]}}}],["parallel_1dim(b)1​∥b0​−bf​∥1",{"_index":1912,"t":{"529":{"position":[[1290,30]]}}}],["param",{"_index":215,"t":{"33":{"position":[[336,6]]}}}],["paramet",{"_index":204,"t":{"27":{"position":[[506,9]]},"38":{"position":[[369,9]]},"165":{"position":[[2821,9]]},"215":{"position":[[820,9],[1141,9],[1529,9]]},"221":{"position":[[756,9]]},"227":{"position":[[139,9]]},"244":{"position":[[56,10],[140,9]]},"300":{"position":[[932,9]]},"304":{"position":[[373,10]]},"350":{"position":[[767,9]]},"358":{"position":[[227,9],[1157,9]]},"388":{"position":[[38,9]]},"428":{"position":[[249,9]]},"473":{"position":[[5,9]]},"504":{"position":[[405,10],[720,9]]},"510":{"position":[[193,9]]},"523":{"position":[[287,9],[437,10],[469,9],[508,9],[524,9],[604,9],[830,9],[862,9],[957,9]]},"525":{"position":[[522,9],[645,9],[940,9],[1123,10],[1190,10],[1305,9],[1449,9],[1486,9]]},"527":{"position":[[65,10],[283,9],[314,9],[358,9],[434,9],[1132,9],[2506,10],[2699,9],[2716,9],[2749,9],[3004,9]]},"529":{"position":[[370,9],[571,9],[676,9],[890,10],[1143,10],[1170,9],[1851,9]]},"531":{"position":[[44,9],[276,9],[1552,9]]},"533":{"position":[[124,9],[174,9],[232,9]]},"583":{"position":[[53,9]]},"587":{"position":[[226,9],[350,9],[561,9]]},"589":{"position":[[175,9],[287,9],[1218,9],[1293,9],[1344,9],[1697,9],[2067,9]]},"594":{"position":[[535,9]]},"598":{"position":[[84,9],[2073,9],[3148,9],[3462,9],[3620,9],[3713,9],[3825,9],[3861,9]]},"600":{"position":[[292,9],[421,9]]},"602":{"position":[[167,9]]},"608":{"position":[[178,9]]},"612":{"position":[[17,9]]},"614":{"position":[[55,9]]},"616":{"position":[[33,9]]},"622":{"position":[[67,9],[247,9]]},"630":{"position":[[1204,9]]},"633":{"position":[[408,9]]},"640":{"position":[[344,9],[371,9],[451,9]]},"642":{"position":[[168,9],[217,9],[296,9]]},"644":{"position":[[13,9]]},"648":{"position":[[16,9],[93,9],[429,9],[536,9],[897,9]]},"656":{"position":[[220,10],[274,9],[296,9],[387,9],[443,9],[515,9]]},"658":{"position":[[504,9],[1285,9],[1334,9],[1406,9],[1468,10],[1620,9],[1852,10],[1911,9],[2014,9],[2057,9],[2343,9],[2749,9],[2804,9],[2876,9],[3054,9]]},"660":{"position":[[310,9],[730,9]]},"662":{"position":[[728,9],[1003,9],[1029,9],[1099,9],[1223,9],[1368,9],[1524,10],[1552,9],[1610,9]]},"664":{"position":[[29,9],[127,9]]},"666":{"position":[[531,9],[574,9]]},"668":{"position":[[20,9]]},"670":{"position":[[1415,9],[1588,9],[1628,9]]},"672":{"position":[[15,9],[64,9],[232,10],[617,9],[697,9],[853,9],[1044,9],[1134,9],[1257,9]]},"674":{"position":[[628,9],[696,10],[772,10]]},"679":{"position":[[130,9]]},"681":{"position":[[139,9],[180,9],[315,9],[649,9],[960,9]]},"683":{"position":[[411,9],[484,9],[523,9],[602,9],[821,9],[882,9]]},"686":{"position":[[51,9]]},"688":{"position":[[665,9]]},"692":{"position":[[105,9]]},"707":{"position":[[480,9],[620,9]]},"709":{"position":[[1544,9],[2079,9],[2562,9]]},"717":{"position":[[199,9],[278,9]]},"719":{"position":[[229,9],[1051,9]]},"723":{"position":[[696,9],[741,9],[883,9],[931,9],[1014,9]]},"727":{"position":[[32,10],[169,9],[374,9]]},"733":{"position":[[613,9]]},"739":{"position":[[149,9]]},"741":{"position":[[71,9],[303,9]]},"751":{"position":[[116,9]]},"753":{"position":[[158,9]]},"757":{"position":[[134,9]]},"765":{"position":[[11,9]]},"770":{"position":[[125,9],[197,9],[246,9]]},"780":{"position":[[122,9]]},"784":{"position":[[121,9],[376,9],[500,9],[696,9]]},"786":{"position":[[101,9],[314,9],[495,9],[767,9],[878,9],[1221,9],[2125,9],[2563,9],[2836,9],[2935,9],[2974,10],[3023,9],[3191,9],[3354,9],[4645,9]]},"791":{"position":[[801,9]]},"797":{"position":[[555,9]]},"799":{"position":[[270,9]]},"801":{"position":[[49,10],[836,9],[1183,9],[1201,9],[1240,9]]},"803":{"position":[[36,9],[687,9]]},"809":{"position":[[138,9],[181,9],[535,9],[618,9],[753,9]]},"814":{"position":[[22,9],[93,10],[120,9],[538,10]]},"816":{"position":[[80,9],[139,9]]},"821":{"position":[[4,9],[56,9],[87,9]]},"823":{"position":[[39,10],[230,9]]},"830":{"position":[[43,9],[74,9]]},"841":{"position":[[426,9],[488,9]]},"843":{"position":[[4,9],[78,9],[264,9]]},"847":{"position":[[862,9]]},"849":{"position":[[108,9],[130,9],[1462,9],[1530,9]]},"857":{"position":[[835,9]]},"870":{"position":[[933,9],[1031,9],[1089,10],[1265,9],[2154,9],[2367,9]]},"885":{"position":[[190,9]]},"887":{"position":[[622,10],[673,9],[1239,9]]},"899":{"position":[[162,9]]},"905":{"position":[[204,9]]},"909":{"position":[[49,10],[98,10]]},"914":{"position":[[90,9]]},"917":{"position":[[47,9]]},"921":{"position":[[209,9]]},"928":{"position":[[21,9]]},"932":{"position":[[128,9],[226,9],[505,9],[856,9]]},"934":{"position":[[255,9],[455,9],[1592,9],[1689,9],[1846,9],[1947,9],[1985,9],[2225,9],[2526,9]]},"938":{"position":[[32,9]]},"945":{"position":[[116,9],[137,9],[415,9],[897,9],[968,9]]},"947":{"position":[[17,9],[134,9],[208,9]]},"949":{"position":[[347,9]]},"961":{"position":[[218,9],[264,9]]},"963":{"position":[[224,9]]},"973":{"position":[[6,9]]},"977":{"position":[[17,9],[581,9],[635,9]]},"979":{"position":[[252,9],[872,9],[899,9],[1628,9]]},"982":{"position":[[43,9],[83,9],[984,10],[1129,9]]},"988":{"position":[[1332,9]]},"992":{"position":[[605,9]]},"994":{"position":[[246,9],[339,9],[616,9],[680,10],[727,9]]},"1002":{"position":[[121,9],[204,9],[415,9],[555,9]]},"1006":{"position":[[410,9],[913,9]]},"1008":{"position":[[273,9]]},"1012":{"position":[[431,9]]},"1014":{"position":[[112,9],[151,10],[260,9],[344,9],[614,9],[920,9],[1466,9],[1641,9]]},"1024":{"position":[[30,9]]},"1028":{"position":[[161,10],[389,10],[457,9]]},"1039":{"position":[[217,10],[260,9],[286,9]]},"1047":{"position":[[414,10]]},"1052":{"position":[[119,9]]},"1054":{"position":[[215,9]]},"1056":{"position":[[60,11],[119,9]]},"1060":{"position":[[104,9],[218,9],[260,9],[1158,9]]},"1062":{"position":[[62,9],[117,9],[183,9],[334,9],[385,9]]},"1065":{"position":[[447,9]]},"1067":{"position":[[980,10]]},"1070":{"position":[[457,9],[789,10],[879,9],[913,10],[954,10],[1093,10],[1188,10],[1300,9]]},"1073":{"position":[[43,10]]},"1075":{"position":[[113,9]]},"1087":{"position":[[154,10]]},"1093":{"position":[[1015,10]]},"1101":{"position":[[252,9]]},"1105":{"position":[[249,9]]},"1109":{"position":[[759,9],[837,9],[1049,9]]},"1117":{"position":[[420,9]]},"1124":{"position":[[339,9]]},"1126":{"position":[[230,9],[954,10],[1266,9],[1409,9],[2160,10],[2196,10],[2305,10]]},"1128":{"position":[[601,9],[992,10],[1657,9],[1949,10]]},"1130":{"position":[[695,9],[804,10]]},"1134":{"position":[[342,9],[855,9]]},"1136":{"position":[[446,9]]},"1145":{"position":[[91,9],[137,9],[214,9],[236,9],[479,9],[885,9],[974,9],[1442,9],[1749,9],[2197,9],[2260,9]]},"1149":{"position":[[319,9]]},"1153":{"position":[[291,9],[342,9]]},"1157":{"position":[[73,11],[116,9]]},"1159":{"position":[[201,10],[321,9],[891,9]]},"1162":{"position":[[57,10],[370,9]]},"1164":{"position":[[141,9],[181,10],[233,9],[466,9]]},"1167":{"position":[[1123,10],[1163,10]]},"1172":{"position":[[118,9],[245,9]]},"1176":{"position":[[174,9]]},"1178":{"position":[[104,9]]},"1187":{"position":[[507,9]]},"1197":{"position":[[454,9]]},"1201":{"position":[[26,9]]},"1208":{"position":[[265,10]]},"1218":{"position":[[41,9],[380,10],[492,9],[580,9],[664,9]]},"1225":{"position":[[583,9]]},"1227":{"position":[[321,9],[1426,9],[1533,9]]},"1230":{"position":[[53,9],[375,9]]},"1232":{"position":[[219,9],[298,9]]},"1238":{"position":[[27,9],[189,9],[348,9],[394,9],[1118,9],[1376,9]]},"1242":{"position":[[103,10]]},"1244":{"position":[[620,10]]},"1248":{"position":[[169,10],[343,9],[476,9]]},"1250":{"position":[[111,9]]},"1255":{"position":[[48,10]]},"1257":{"position":[[56,10],[319,9]]},"1262":{"position":[[20,9],[88,9],[201,9]]},"1268":{"position":[[172,9],[208,9]]},"1285":{"position":[[379,9],[449,9]]},"1289":{"position":[[116,9],[269,9],[525,9]]},"1291":{"position":[[129,9],[180,9],[254,10],[278,9],[352,9],[384,9],[589,9],[628,9],[1347,9],[1392,9],[1568,9]]},"1300":{"position":[[28,9]]},"1303":{"position":[[12,9]]},"1305":{"position":[[435,9],[950,10],[976,10],[1008,10],[1040,10]]},"1307":{"position":[[312,10],[373,9],[492,10]]},"1317":{"position":[[21,9],[143,9],[230,9],[502,9]]},"1319":{"position":[[11,9],[52,9]]},"1321":{"position":[[338,9]]},"1323":{"position":[[665,9]]},"1326":{"position":[[31,9]]},"1328":{"position":[[94,9]]},"1341":{"position":[[29,9],[137,9],[367,9],[432,9],[695,9],[951,9],[1091,9],[1122,9]]},"1345":{"position":[[45,9]]},"1347":{"position":[[38,9],[125,9]]},"1350":{"position":[[810,9]]},"1367":{"position":[[118,9]]},"1369":{"position":[[141,9],[448,9],[630,9]]},"1373":{"position":[[55,9],[172,11],[229,11],[272,9]]},"1377":{"position":[[3,9],[68,9]]},"1379":{"position":[[59,9],[125,9],[211,9],[276,9],[300,9],[365,9],[924,9]]},"1382":{"position":[[49,9],[110,9]]},"1384":{"position":[[34,9],[968,9],[2533,10],[2647,9],[2671,10]]},"1395":{"position":[[786,9],[1090,10],[1677,10],[1730,9],[1985,9],[2699,9],[3071,9]]},"1399":{"position":[[20,9],[75,9],[114,9],[216,9],[252,9],[302,9],[445,9]]},"1401":{"position":[[0,9],[125,10],[186,9],[245,9],[317,9]]},"1403":{"position":[[11,9]]},"1409":{"position":[[439,9]]},"1413":{"position":[[58,9]]},"1421":{"position":[[84,10]]},"1423":{"position":[[1219,9]]},"1429":{"position":[[39,9]]},"1434":{"position":[[156,9]]},"1442":{"position":[[1990,9]]},"1466":{"position":[[540,9]]},"1468":{"position":[[104,9],[141,9],[249,9],[411,9],[1341,9]]},"1471":{"position":[[180,9],[224,9]]},"1473":{"position":[[590,9],[628,9]]},"1477":{"position":[[162,9]]},"1489":{"position":[[280,9]]},"1494":{"position":[[104,9]]},"1507":{"position":[[27,9],[67,9],[105,9],[167,9],[258,9],[315,9]]},"1515":{"position":[[251,9]]},"1536":{"position":[[41,9]]},"1546":{"position":[[541,9]]},"1646":{"position":[[421,10]]},"1667":{"position":[[762,10],[799,9]]},"1698":{"position":[[156,9]]},"1708":{"position":[[497,9]]},"1720":{"position":[[2358,9]]},"1748":{"position":[[154,9],[186,9],[226,9]]},"1750":{"position":[[44,9],[358,9]]},"1762":{"position":[[117,9]]},"1782":{"position":[[2092,9]]}}}],["parameter",{"_index":1939,"t":{"531":{"position":[[197,17],[231,13]]},"719":{"position":[[362,13]]},"784":{"position":[[611,12]]},"786":{"position":[[1641,12],[4261,16]]},"795":{"position":[[85,12],[1398,16]]},"809":{"position":[[707,12]]},"843":{"position":[[196,12]]},"1128":{"position":[[393,12],[783,12],[944,12]]},"1147":{"position":[[1179,12]]},"1162":{"position":[[189,12]]},"1296":{"position":[[25,13]]},"1305":{"position":[[591,14]]},"1350":{"position":[[89,12],[584,12]]},"1352":{"position":[[235,12],[503,12]]},"1384":{"position":[[3026,12]]},"1442":{"position":[[2016,12]]},"1468":{"position":[[723,13]]},"1475":{"position":[[33,13]]}}}],["parameter/perform",{"_index":2400,"t":{"672":{"position":[[300,21]]},"674":{"position":[[129,21]]}}}],["parameterzi",{"_index":4050,"t":{"1185":{"position":[[432,12]]}}}],["parametr",{"_index":2566,"t":{"713":{"position":[[250,10]]}}}],["paramt",{"_index":3955,"t":{"1145":{"position":[[1695,8]]}}}],["paraphas",{"_index":5492,"t":{"1730":{"position":[[266,10]]}}}],["paraphras",{"_index":3022,"t":{"812":{"position":[[137,10]]},"979":{"position":[[1915,10]]},"997":{"position":[[64,10],[898,10]]},"1006":{"position":[[2482,12]]},"1147":{"position":[[260,10],[738,10]]},"1393":{"position":[[88,10]]},"1429":{"position":[[1557,12]]},"1718":{"position":[[241,12],[284,10],[439,10],[470,10]]},"1730":{"position":[[105,12],[159,12],[481,11]]},"1764":{"position":[[129,12],[263,12]]},"1766":{"position":[[466,10]]},"1782":{"position":[[932,12]]},"1802":{"position":[[1169,12]]}}}],["paraphrasing/semant",{"_index":4594,"t":{"1419":{"position":[[681,21]]}}}],["parent",{"_index":5169,"t":{"1651":{"position":[[275,8],[630,6],[671,6],[1099,6],[1216,6],[1349,6]]},"1655":{"position":[[1457,6],[1520,6],[1577,6]]},"1657":{"position":[[57,6],[103,6],[150,6]]}}}],["pareto",{"_index":4332,"t":{"1317":{"position":[[457,6]]}}}],["pari",{"_index":1738,"t":{"498":{"position":[[83,5]]},"723":{"position":[[169,5]]},"1560":{"position":[[519,5]]}}}],["pars",{"_index":1359,"t":{"326":{"position":[[55,7]]},"1764":{"position":[[9,7],[94,7]]}}}],["parser",{"_index":1637,"t":{"453":{"position":[[14,6]]}}}],["part",{"_index":1480,"t":{"358":{"position":[[637,5]]}}}],["parti",{"_index":3914,"t":{"1132":{"position":[[325,5],[426,5]]}}}],["partial",{"_index":2446,"t":{"681":{"position":[[353,7],[393,7]]},"683":{"position":[[648,7],[694,7]]},"853":{"position":[[841,10]]}}}],["particularli",{"_index":5101,"t":{"1622":{"position":[[250,12]]}}}],["pass",{"_index":1080,"t":{"236":{"position":[[405,4]]},"733":{"position":[[759,4]]},"791":{"position":[[119,4]]},"1149":{"position":[[430,4]]}}}],["pass@1",{"_index":4708,"t":{"1440":{"position":[[619,6]]}}}],["past",{"_index":4252,"t":{"1296":{"position":[[638,4]]}}}],["patch",{"_index":389,"t":{"88":{"position":[[240,5]]},"91":{"position":[[189,5],[575,5],[795,5],[1183,5],[1856,5]]},"95":{"position":[[11,5],[88,5],[150,5],[172,5],[307,5]]},"97":{"position":[[244,5]]},"104":{"position":[[80,5],[127,5],[164,5],[183,5],[415,5]]},"116":{"position":[[450,5],[532,5]]},"118":{"position":[[69,5]]},"120":{"position":[[0,5]]},"232":{"position":[[25,5]]},"457":{"position":[[911,5],[995,7]]}}}],["path",{"_index":1282,"t":{"310":{"position":[[462,4],[637,4],[712,4],[839,4],[1260,4],[1554,4]]},"426":{"position":[[520,4]]},"1303":{"position":[[1053,5]]},"1620":{"position":[[48,5],[71,6]]},"1622":{"position":[[60,5]]},"1718":{"position":[[220,4]]}}}],["pattern",{"_index":1682,"t":{"461":{"position":[[52,8]]},"692":{"position":[[359,7]]},"696":{"position":[[313,7],[1066,8]]},"709":{"position":[[1463,7]]},"1006":{"position":[[2247,8]]}}}],["paw",{"_index":3579,"t":{"997":{"position":[[873,4]]},"1002":{"position":[[493,4]]},"1006":{"position":[[2362,4]]},"1070":{"position":[[270,4]]},"1253":{"position":[[324,4]]}}}],["pc(2)\\hat{i",{"_index":1443,"t":{"350":{"position":[[886,12]]}}}],["pc(x)⋅pθc;x]),\\begin{equ",{"_index":4400,"t":{"1352":{"position":[[1115,31]]}}}],["pc=exp⁡(<fctext,fimage>/τ)∑j=1cexp⁡(<fjtext,fimage>/τ)(1)p_c",{"_index":1431,"t":{"350":{"position":[[491,60]]}}}],["pc=exp⁡(<g(vc),fimage>/τ)∑j=1cexp⁡(<g(vj),fimage>/τ)(4)p_c",{"_index":1486,"t":{"358":{"position":[[908,58]]}}}],["pca",{"_index":1057,"t":{"227":{"position":[[805,3]]}}}],["pc​(2",{"_index":1447,"t":{"350":{"position":[[949,6]]}}}],["pc​(x)⋅pθc​​;x",{"_index":4406,"t":{"1352":{"position":[[1260,20]]}}}],["pdrop=0.1p_{drop",{"_index":1339,"t":{"319":{"position":[[206,17]]},"322":{"position":[[395,17]]}}}],["pe(po",{"_index":1261,"t":{"308":{"position":[[399,7],[456,7]]}}}],["pe(pos,2i)=sin(pos/100002i/dmodel)pe(pos,2i+1)=cos(pos/100002i/dmodel)\\begin{align",{"_index":1260,"t":{"308":{"position":[[314,84]]}}}],["pe;xe]∈r(m+n)×e[p_",{"_index":4782,"t":{"1477":{"position":[[562,21]]}}}],["pe;xe]∈r(p+n)×e[p_",{"_index":3899,"t":{"1128":{"position":[[1788,21]]}}}],["pe={p1,p2,…,pm}∈rm×ep_",{"_index":4780,"t":{"1477":{"position":[[411,23]]}}}],["pefl",{"_index":3651,"t":{"1060":{"position":[[1196,6]]}}}],["peft",{"_index":2049,"t":{"587":{"position":[[258,6],[407,4],[419,4],[525,4]]},"589":{"position":[[1250,6],[1411,4],[1473,4],[1510,4],[1581,4],[1643,4],[2016,4]]},"592":{"position":[[0,4]]},"594":{"position":[[81,4]]},"596":{"position":[[0,4]]},"598":{"position":[[29,4],[217,4],[579,4],[632,4],[690,4],[3118,4],[3818,4]]},"622":{"position":[[152,4]]},"626":{"position":[[109,4],[225,4],[268,4],[312,4],[533,4],[554,4]]},"628":{"position":[[123,4],[459,4],[593,4],[657,4],[743,4],[977,4],[1011,4],[1157,4],[1180,4],[1283,4],[1339,4],[1415,4],[1486,4],[1531,4],[1632,4]]},"630":{"position":[[20,4],[87,4],[116,4],[175,4],[283,4],[451,4],[517,4],[643,4],[750,4],[1925,4],[2047,4],[2081,4],[2205,4],[2276,4],[2359,4]]},"633":{"position":[[458,4],[546,4],[1045,4]]},"635":{"position":[[53,4],[135,4]]},"638":{"position":[[63,4]]},"640":{"position":[[333,4]]},"644":{"position":[[54,4],[204,4],[339,4]]},"646":{"position":[[28,4],[55,4],[201,4],[366,4]]},"648":{"position":[[169,4],[585,4]]},"650":{"position":[[29,4],[50,4],[71,4],[205,4]]},"725":{"position":[[9,4]]},"786":{"position":[[3226,4]]},"973":{"position":[[574,4]]},"979":{"position":[[60,4],[147,4],[823,4]]},"997":{"position":[[557,4]]},"1008":{"position":[[8,4]]},"1060":{"position":[[136,6],[188,4],[1073,4]]},"1062":{"position":[[170,4],[239,4],[413,4],[1353,4],[1709,4],[1809,4]]},"1070":{"position":[[610,4]]},"1073":{"position":[[91,4]]},"1075":{"position":[[25,4]]},"1077":{"position":[[48,4]]},"1084":{"position":[[462,4],[584,4],[916,4]]},"1087":{"position":[[46,4]]},"1157":{"position":[[21,4],[93,4]]},"1189":{"position":[[61,4],[265,4]]},"1191":{"position":[[83,4],[94,4]]},"1197":{"position":[[21,4],[288,4]]},"1347":{"position":[[194,4]]},"1407":{"position":[[63,4]]},"1434":{"position":[[3,4]]},"1468":{"position":[[344,4]]}}}],["peft/ipet",{"_index":3864,"t":{"1115":{"position":[[42,9]]}}}],["pellentesqu",{"_index":21,"t":{"3":{"position":[[177,12],[356,12],[535,12],[714,12],[893,12],[1072,12],[1251,12],[1430,12],[1609,12],[1788,12],[1967,12],[2146,12],[2325,12],[2504,12],[2683,12],[2862,12]]},"5":{"position":[[57,12]]}}}],["pelt",{"_index":4443,"t":{"1377":{"position":[[45,6],[142,4],[232,4],[323,4],[446,4],[576,4]]},"1379":{"position":[[167,6],[190,4],[437,4],[541,4],[579,4],[664,4],[686,4],[975,4],[1110,4],[1236,4],[1498,4],[1559,4],[1611,4],[1680,4],[1721,4]]},"1384":{"position":[[2619,4]]},"1387":{"position":[[82,4],[276,4]]},"1389":{"position":[[30,4],[77,4],[157,4],[286,4],[323,4],[373,4],[440,4],[686,4],[2430,4]]},"1393":{"position":[[678,4],[722,4]]},"1395":{"position":[[1229,4]]},"1397":{"position":[[657,4],[976,4],[1028,4],[1251,4],[1416,4]]},"1399":{"position":[[97,4],[474,4],[548,4]]},"1401":{"position":[[165,4],[383,4]]},"1403":{"position":[[53,6],[98,4],[300,4]]}}}],["penalti",{"_index":1348,"t":{"322":{"position":[[570,7]]},"786":{"position":[[4244,7]]}}}],["penn",{"_index":1362,"t":{"326":{"position":[[237,4]]},"1672":{"position":[[270,4]]}}}],["pep_ep",{"_index":3903,"t":{"1128":{"position":[[1960,8]]},"1477":{"position":[[682,8]]}}}],["pepos+kpe_{po",{"_index":1272,"t":{"308":{"position":[[766,14]]}}}],["pepospe_{pos}pepo",{"_index":1274,"t":{"308":{"position":[[796,19]]}}}],["per",{"_index":2072,"t":{"592":{"position":[[351,3]]},"602":{"position":[[667,3]]},"608":{"position":[[138,3],[256,3],[298,3],[445,3]]},"1028":{"position":[[430,3]]},"1126":{"position":[[83,3]]},"1397":{"position":[[194,3]]},"1429":{"position":[[843,3]]},"1431":{"position":[[2453,3]]}}}],["per:city_of_death",{"_index":5501,"t":{"1730":{"position":[[1322,17]]}}}],["percept",{"_index":721,"t":{"163":{"position":[[26,10],[98,10],[284,10]]},"165":{"position":[[786,10],[823,10],[1188,10],[1262,10],[1359,10],[2521,10],[2624,10],[2849,10]]},"168":{"position":[[36,10],[394,10]]},"174":{"position":[[727,10]]},"177":{"position":[[32,10]]},"209":{"position":[[56,10]]},"221":{"position":[[201,10]]}}}],["perceptron",{"_index":2535,"t":{"696":{"position":[[1586,10]]}}}],["perez",{"_index":2355,"t":{"662":{"position":[[1447,6]]}}}],["perfor",{"_index":4446,"t":{"1379":{"position":[[248,10]]}}}],["perform",{"_index":1901,"t":{"529":{"position":[[444,11],[779,10]]},"531":{"position":[[5,11]]},"709":{"position":[[2310,11]]},"786":{"position":[[2859,11]]},"799":{"position":[[288,11]]},"979":{"position":[[933,11]]},"1002":{"position":[[51,11]]},"1093":{"position":[[613,10]]},"1109":{"position":[[8,12]]},"1153":{"position":[[109,11],[561,10]]},"1332":{"position":[[94,12]]},"1377":{"position":[[537,11]]},"1384":{"position":[[2577,11]]},"1389":{"position":[[623,11]]},"1397":{"position":[[13,12],[139,11],[319,11],[350,11],[790,11],[921,11],[1114,12],[1194,11],[1392,11],[1508,11]]},"1403":{"position":[[262,11]]},"1417":{"position":[[43,11]]},"1423":{"position":[[28,11]]},"1455":{"position":[[200,11]]},"1485":{"position":[[887,11]]},"1505":{"position":[[959,11]]}}}],["performacnc",{"_index":4583,"t":{"1409":{"position":[[44,12]]}}}],["period",{"_index":1999,"t":{"550":{"position":[[353,8]]}}}],["perplex",{"_index":1343,"t":{"319":{"position":[[353,10]]}}}],["persist",{"_index":4743,"t":{"1451":{"position":[[220,10],[784,10]]}}}],["person",{"_index":657,"t":{"143":{"position":[[179,6]]},"149":{"position":[[4,6]]},"159":{"position":[[801,6]]},"170":{"position":[[280,8]]},"531":{"position":[[1328,11]]},"1339":{"position":[[4,15]]},"1651":{"position":[[574,9],[597,6]]},"1655":{"position":[[1751,6],[1919,6],[2045,6]]},"1728":{"position":[[576,9]]}}}],["person,city,death",{"_index":5502,"t":{"1730":{"position":[[1346,19]]}}}],["person:par",{"_index":5163,"t":{"1646":{"position":[[1575,15]]},"1651":{"position":[[103,15],[1018,15]]}}}],["perturb",{"_index":4409,"t":{"1354":{"position":[[228,12]]},"1364":{"position":[[83,13]]}}}],["pet",{"_index":500,"t":{"102":{"position":[[202,5],[284,5]]},"1111":{"position":[[1904,3],[1963,3]]},"1115":{"position":[[717,3],[964,3],[970,3]]}}}],["pet/ipet",{"_index":3865,"t":{"1115":{"position":[[1141,8]]}}}],["petaflops/",{"_index":4970,"t":{"1570":{"position":[[286,11],[338,11]]}}}],["petl",{"_index":3652,"t":{"1062":{"position":[[505,4],[870,4],[1718,4]]},"1070":{"position":[[1736,4]]},"1073":{"position":[[251,4]]},"1084":{"position":[[88,4],[413,4],[772,4],[802,4]]}}}],["pe∈rp×ep_",{"_index":3896,"t":{"1128":{"position":[[1667,10]]}}}],["pf",{"_index":3614,"t":{"1014":{"position":[[1033,2],[1127,2]]},"1037":{"position":[[37,2]]},"1056":{"position":[[37,2]]}}}],["pfeiffer",{"_index":3018,"t":{"809":{"position":[[450,10]]},"823":{"position":[[207,8]]},"1395":{"position":[[638,8]]},"1399":{"position":[[380,8]]}}}],["phi",{"_index":2604,"t":{"723":{"position":[[722,6],[778,9],[964,4],[981,4],[1104,6]]},"774":{"position":[[817,8],[912,6]]},"1176":{"position":[[66,6]]},"1296":{"position":[[0,6]]},"1300":{"position":[[38,6]]},"1305":{"position":[[987,6]]},"1350":{"position":[[80,6],[820,6]]},"1384":{"position":[[572,4],[866,6],[1883,4],[3924,6]]},"1659":{"position":[[37,6]]}}}],["phi(\\cdot",{"_index":4016,"t":{"1167":{"position":[[403,19],[463,19],[517,19],[705,19]]},"1178":{"position":[[82,19],[336,19]]}}}],["phi(\\theta",{"_index":2610,"t":{"723":{"position":[[1280,13]]}}}],["phi(\\tilde{y})|t(x",{"_index":5286,"t":{"1657":{"position":[[2172,22]]}}}],["phi(p)p′=φ(p",{"_index":4043,"t":{"1178":{"position":[[448,14]]}}}],["phi(p_1",{"_index":4013,"t":{"1167":{"position":[[319,11]]}}}],["phi(p_i",{"_index":4019,"t":{"1167":{"position":[[606,9],[618,9]]}}}],["phi(p_n",{"_index":4014,"t":{"1167":{"position":[[339,11]]}}}],["phi(y)|t(x))}{\\sum_{\\tilde{i",{"_index":5284,"t":{"1657":{"position":[[2100,30]]}}}],["phi_0|∣θ∣≪∣ϕ0",{"_index":2607,"t":{"723":{"position":[[1069,18]]}}}],["phi_j(y_x)|t(x))p([m]j​=ϕj​(yx​)∣t(x",{"_index":5318,"t":{"1659":{"position":[[815,39]]}}}],["phi_j(y_{x})|t(x",{"_index":5300,"t":{"1657":{"position":[[2957,20]]}}}],["phi_w(x)ψw,v0​​(x)≈ϕw​(x",{"_index":2328,"t":{"658":{"position":[[2153,26]]}}}],["phiϕ0",{"_index":2596,"t":{"723":{"position":[[439,10]]}}}],["phoeb",{"_index":1581,"t":{"424":{"position":[[67,6]]}}}],["photo",{"_index":1120,"t":{"253":{"position":[[40,5]]},"336":{"position":[[233,5]]},"341":{"position":[[52,5]]},"350":{"position":[[85,5]]},"356":{"position":[[38,5]]},"368":{"position":[[211,5]]}}}],["php",{"_index":1779,"t":{"515":{"position":[[120,4]]}}}],["phrasal/sententi",{"_index":5473,"t":{"1724":{"position":[[368,18]]}}}],["phrase",{"_index":5600,"t":{"1782":{"position":[[1928,7]]}}}],["pi)=ϕ(pi)+pi",{"_index":4017,"t":{"1167":{"position":[[566,14]]}}}],["pi={pi1,pi2,…,pin}p_i",{"_index":2503,"t":{"694":{"position":[[290,21]]}}}],["pi][\\text{p}_i][pi",{"_index":3783,"t":{"1099":{"position":[[967,21],[1425,21]]}}}],["pi]∈v[\\text{p}_i",{"_index":3788,"t":{"1099":{"position":[[1167,18]]}}}],["pi^{sft}(i",{"_index":4953,"t":{"1558":{"position":[[1603,11]]}}}],["pi_\\theta",{"_index":4729,"t":{"1447":{"position":[[130,15]]}}}],["pica",{"_index":1610,"t":{"436":{"position":[[1122,4],[1626,4]]},"445":{"position":[[180,4]]},"468":{"position":[[30,4],[193,5]]},"471":{"position":[[39,4],[80,4]]},"477":{"position":[[139,4]]}}}],["pick",{"_index":5168,"t":{"1646":{"position":[[2961,6]]}}}],["pictur",{"_index":1109,"t":{"246":{"position":[[103,7]]},"457":{"position":[[1058,7]]}}}],["pidx\\text{p}_{\\text{idx}}pidx",{"_index":4293,"t":{"1305":{"position":[[253,30],[545,30]]}}}],["pidx∣|\\text{p}_{\\text{idx}}|∣pidx",{"_index":4294,"t":{"1305":{"position":[[312,36]]}}}],["pidx∣×dim(hi)|\\text{p}_{\\text{idx",{"_index":4295,"t":{"1305":{"position":[[459,37]]}}}],["piec",{"_index":1313,"t":{"313":{"position":[[233,5]]},"703":{"position":[[232,5]]},"1468":{"position":[[1203,5]]},"1483":{"position":[[245,6],[270,5],[343,6]]},"1487":{"position":[[101,6],[137,6],[209,6],[226,5],[319,6],[427,5],[501,5],[526,6],[793,6],[837,5],[1090,5],[1183,6],[1212,5]]},"1496":{"position":[[330,6]]},"1505":{"position":[[397,6],[806,6],[859,6]]},"1509":{"position":[[35,5],[210,5]]},"1515":{"position":[[177,5]]},"1521":{"position":[[45,6]]},"1525":{"position":[[154,5]]}}}],["piep_{i_e}pi",{"_index":4812,"t":{"1487":{"position":[[297,15]]}}}],["pijp^j_ipij",{"_index":2508,"t":{"694":{"position":[[374,12]]}}}],["pimp^m_ipim",{"_index":1460,"t":{"354":{"position":[[331,12]]}}}],["pinstance(x)=ptarget+∑j=1t+1ajpj.\\begin{equ",{"_index":3546,"t":{"990":{"position":[[101,49]]}}}],["pinstance;x]).\\begin{equ",{"_index":3502,"t":{"986":{"position":[[401,31]]}}}],["pinstancep_{instance}pinst",{"_index":3477,"t":{"982":{"position":[[682,31],[719,31],[827,31]]},"986":{"position":[[256,31],[634,31]]},"992":{"position":[[800,31],[841,31]]}}}],["pinstance​;x",{"_index":3507,"t":{"986":{"position":[[548,18]]}}}],["pip_ipi",{"_index":2501,"t":{"692":{"position":[[157,9]]},"1485":{"position":[[82,8],[527,8]]}}}],["pipelin",{"_index":1423,"t":{"347":{"position":[[597,8]]},"992":{"position":[[1171,8]]}}}],["pix2seq",{"_index":658,"t":{"143":{"position":[[241,7]]},"145":{"position":[[0,7],[86,7]]}}}],["pixel",{"_index":577,"t":{"124":{"position":[[166,5]]},"126":{"position":[[823,5]]},"128":{"position":[[27,5]]}}}],["pi​={pi1​,pi2​,…,pin",{"_index":2507,"t":{"694":{"position":[[344,24]]}}}],["pj(x)=[softmax(lμ(x",{"_index":4413,"t":{"1354":{"position":[[380,21]]}}}],["pj(x)=[softmax(lμ(xˉ))]j⋅\\begin{equ",{"_index":4393,"t":{"1352":{"position":[[788,41]]}}}],["pj=1zexp⁡(zj/t)p_j",{"_index":4166,"t":{"1244":{"position":[[1198,18]]}}}],["pj∈rm×dp_j",{"_index":3512,"t":{"988":{"position":[[338,10]]}}}],["pk(t)p^{(t)}_kpk(t",{"_index":2903,"t":{"797":{"position":[[1173,21]]}}}],["pk(teacher))∣∣p(yi∣xi",{"_index":4155,"t":{"1244":{"position":[[794,23]]}}}],["pk(teacher)p_k^{(teacher)}pk(teach",{"_index":4148,"t":{"1244":{"position":[[273,38]]}}}],["pk(teacher)​)∣∣p(yi​∣xi",{"_index":4165,"t":{"1244":{"position":[[1068,26]]}}}],["pk,∗ip_{k",{"_index":2962,"t":{"801":{"position":[[720,10]]}}}],["pk=hkp∗p_k",{"_index":2497,"t":{"690":{"position":[[271,10]]}}}],["pkkvp^{kv}_kpkkv",{"_index":2525,"t":{"696":{"position":[[733,17]]}}}],["pkp_kpk",{"_index":2494,"t":{"688":{"position":[[1003,8]]},"692":{"position":[[291,8]]},"1384":{"position":[[1640,9]]},"1389":{"position":[[1765,10]]}}}],["pkp_{k}pk",{"_index":4131,"t":{"1242":{"position":[[191,10]]}}}],["pkqkp^{qk}_kpkqk",{"_index":2523,"t":{"696":{"position":[[539,17]]}}}],["pl",{"_index":1773,"t":{"515":{"position":[[79,3]]}}}],["pl;tl;tl",{"_index":3318,"t":{"893":{"position":[[500,10],[525,10]]}}}],["pl;tl][p_l",{"_index":3308,"t":{"893":{"position":[[231,12]]}}}],["pl;tl]∈r(k+m)×c\\begin{equ",{"_index":3303,"t":{"891":{"position":[[748,32]]}}}],["plain",{"_index":4922,"t":{"1552":{"position":[[205,5]]}}}],["plan",{"_index":2030,"t":{"569":{"position":[[85,8],[161,8]]},"579":{"position":[[192,8]]}}}],["platform",{"_index":1797,"t":{"517":{"position":[[443,9]]}}}],["platon",{"_index":2974,"t":{"801":{"position":[[1294,8],[1521,8]]}}}],["play",{"_index":1601,"t":{"434":{"position":[[345,4]]},"436":{"position":[[1335,4],[1923,4]]},"990":{"position":[[662,4]]},"1587":{"position":[[469,4]]}}}],["playground",{"_index":4966,"t":{"1560":{"position":[[452,10]]}}}],["pleas",{"_index":1675,"t":{"459":{"position":[[130,7]]},"1581":{"position":[[230,6]]}}}],["plet",{"_index":4447,"t":{"1379":{"position":[[623,4]]},"1672":{"position":[[205,4],[304,4]]},"1674":{"position":[[41,4],[63,4],[182,4],[295,7]]},"1676":{"position":[[69,4],[209,4],[476,4]]}}}],["plic",{"_index":1199,"t":{"298":{"position":[[627,10]]}}}],["plm",{"_index":964,"t":{"213":{"position":[[157,6]]},"215":{"position":[[672,4],[726,4],[1036,4],[1555,4],[1625,5],[1874,5]]},"679":{"position":[[202,6],[317,4],[587,4]]},"681":{"position":[[0,4],[76,4],[114,4],[1018,4],[1256,4]]},"683":{"position":[[29,3],[371,3],[551,4]]},"686":{"position":[[16,4]]},"705":{"position":[[131,4]]},"784":{"position":[[34,6]]},"786":{"position":[[11,4],[126,4],[296,3],[369,3]]},"847":{"position":[[28,6],[162,3],[282,3],[429,3],[550,3]]},"849":{"position":[[8,4],[200,3],[539,3],[896,3],[1003,3],[1144,3],[1279,3],[1418,3]]},"851":{"position":[[0,3],[410,3],[1018,3]]},"853":{"position":[[31,3],[360,4]]},"855":{"position":[[66,3]]},"868":{"position":[[235,3]]},"879":{"position":[[83,3],[176,3]]},"1159":{"position":[[28,6]]},"1162":{"position":[[18,4]]},"1164":{"position":[[203,4],[459,4]]},"1178":{"position":[[608,4]]},"1187":{"position":[[309,3]]},"1227":{"position":[[38,6],[125,3],[315,3],[381,3]]},"1230":{"position":[[101,3]]},"1238":{"position":[[479,3],[1102,4]]},"1244":{"position":[[1835,4]]},"1367":{"position":[[0,4],[59,3]]},"1379":{"position":[[28,6],[288,3],[1466,3]]},"1382":{"position":[[0,3],[163,3]]},"1384":{"position":[[9,3],[107,3]]},"1387":{"position":[[27,3]]},"1389":{"position":[[167,3],[657,4]]},"1397":{"position":[[1037,7]]},"1401":{"position":[[30,5],[67,3],[290,3]]},"1407":{"position":[[28,6],[150,4]]},"1409":{"position":[[6,4],[249,4]]},"1411":{"position":[[370,4]]},"1466":{"position":[[51,6]]},"1468":{"position":[[0,4],[834,4]]},"1471":{"position":[[0,4],[165,4]]},"1473":{"position":[[270,4]]},"1475":{"position":[[301,3]]},"1481":{"position":[[32,3]]},"1494":{"position":[[221,4],[364,3]]},"1644":{"position":[[32,6]]},"1646":{"position":[[0,4],[153,4],[336,4],[1167,4],[3307,4]]},"1657":{"position":[[2457,4]]},"1665":{"position":[[234,4],[457,4],[482,4]]},"1667":{"position":[[183,3],[306,4],[336,4],[351,3],[463,3],[567,4],[863,3],[1026,3]]},"1669":{"position":[[26,4]]},"1676":{"position":[[291,3],[317,3],[604,3]]},"1684":{"position":[[289,4],[361,3],[488,3]]},"1686":{"position":[[262,4],[309,4]]}}}],["plm'",{"_index":5157,"t":{"1646":{"position":[[415,5]]}}}],["plms'",{"_index":5158,"t":{"1646":{"position":[[579,6]]}}}],["plp_lpl",{"_index":3307,"t":{"891":{"position":[[859,8]]}}}],["plug",{"_index":1600,"t":{"434":{"position":[[336,4]]},"436":{"position":[[1326,4],[1914,4]]},"628":{"position":[[1359,4]]},"630":{"position":[[195,4],[204,4],[430,4]]},"633":{"position":[[982,4]]},"635":{"position":[[75,4]]},"640":{"position":[[405,4]]},"644":{"position":[[444,4]]},"646":{"position":[[394,8]]},"887":{"position":[[869,4]]},"934":{"position":[[2155,8]]}}}],["plugin",{"_index":34,"t":{"7":{"position":[[53,7]]},"1634":{"position":[[79,6],[144,6],[210,6]]}}}],["plv=pl+repeat(ip)∈rk×c\\begin{equ",{"_index":3385,"t":{"895":{"position":[[887,38]]}}}],["plvp_l^vplv",{"_index":3389,"t":{"895":{"position":[[1029,12]]}}}],["pl}l=1l",{"_index":3291,"t":{"891":{"position":[[164,10]]}}}],["pl​;tl​;tl",{"_index":3328,"t":{"893":{"position":[[735,13],[765,13]]}}}],["pl∈rk×cp_l",{"_index":3294,"t":{"891":{"position":[[237,10]]}}}],["pm",{"_index":2406,"t":{"672":{"position":[[768,3],[886,3],[966,3]]}}}],["pml",{"_index":1000,"t":{"215":{"position":[[1318,4]]},"1665":{"position":[[269,4]]}}}],["pnormp_{norm}pnorm",{"_index":922,"t":{"189":{"position":[[134,21]]}}}],["po",{"_index":1638,"t":{"453":{"position":[[49,3]]},"529":{"position":[[2350,3]]}}}],["point",{"_index":709,"t":{"155":{"position":[[489,5]]},"174":{"position":[[532,6],[646,6]]},"283":{"position":[[205,6]]},"289":{"position":[[467,5]]},"310":{"position":[[1774,5]]},"322":{"position":[[733,5]]},"376":{"position":[[182,5]]},"473":{"position":[[51,5]]},"475":{"position":[[151,5]]},"672":{"position":[[1073,5]]},"1117":{"position":[[98,6],[126,6]]},"1157":{"position":[[443,6]]},"1159":{"position":[[1777,6]]},"1195":{"position":[[211,6],[245,6]]},"1197":{"position":[[164,6]]},"1199":{"position":[[455,6]]},"1201":{"position":[[167,6]]},"1203":{"position":[[222,6]]},"1205":{"position":[[208,6]]},"1214":{"position":[[90,6]]},"1379":{"position":[[1322,6]]},"1395":{"position":[[157,6]]},"1423":{"position":[[230,5]]},"1720":{"position":[[1674,5]]}}}],["pointer",{"_index":5129,"t":{"1628":{"position":[[255,10]]}}}],["polici",{"_index":4715,"t":{"1442":{"position":[[1140,6],[1951,6]]},"1447":{"position":[[76,6],[123,6]]},"1462":{"position":[[16,6],[49,6]]},"1550":{"position":[[46,6],[242,6],[286,6]]},"1558":{"position":[[1815,6]]}}}],["polit",{"_index":5484,"t":{"1728":{"position":[[507,12]]}}}],["polygon",{"_index":608,"t":{"130":{"position":[[842,7],[891,7],[968,7],[985,7]]},"140":{"position":[[497,7],[580,9]]},"147":{"position":[[0,7]]}}}],["pomrpt",{"_index":2546,"t":{"705":{"position":[[205,7]]},"979":{"position":[[403,7]]}}}],["pool",{"_index":227,"t":{"38":{"position":[[242,7]]},"174":{"position":[[924,7],[1943,7]]},"205":{"position":[[189,4]]},"594":{"position":[[427,4]]},"988":{"position":[[482,4]]},"1429":{"position":[[553,6]]}}}],["portion",{"_index":1822,"t":{"525":{"position":[[540,7]]}}}],["posit",{"_index":435,"t":{"91":{"position":[[1123,8],[1142,8],[1162,8],[1213,8],[1254,8],[1918,10]]},"93":{"position":[[205,8],[227,8],[262,8]]},"97":{"position":[[330,8],[376,8]]},"116":{"position":[[393,8],[429,8],[506,8]]},"230":{"position":[[485,10]]},"285":{"position":[[110,9],[178,8]]},"287":{"position":[[89,8],[270,9]]},"292":{"position":[[106,8]]},"294":{"position":[[276,8],[298,8],[379,8],[414,8]]},"300":{"position":[[492,8]]},"302":{"position":[[193,8],[225,9]]},"304":{"position":[[340,8]]},"308":{"position":[[149,10],[178,10],[284,10],[613,9],[641,10],[901,10]]},"310":{"position":[[683,9],[819,8],[899,8],[1202,8],[1533,9]]},"319":{"position":[[155,10]]},"324":{"position":[[528,10]]},"498":{"position":[[64,8]]},"500":{"position":[[807,8],[1074,8]]},"598":{"position":[[1299,8],[1417,8],[1737,8],[3195,8]]},"709":{"position":[[1617,10],[1648,8]]},"859":{"position":[[255,8]]},"1107":{"position":[[806,8]]},"1111":{"position":[[1113,8]]},"1187":{"position":[[374,8]]},"1409":{"position":[[1461,8]]},"1427":{"position":[[167,8],[1202,8]]},"1431":{"position":[[1851,8]]},"1468":{"position":[[935,8],[1251,8]]},"1505":{"position":[[37,8],[71,8],[465,8]]},"1515":{"position":[[193,8]]},"1595":{"position":[[113,9]]},"1646":{"position":[[781,8],[1206,8]]},"1655":{"position":[[227,8]]},"1657":{"position":[[1955,9],[2305,9],[2365,8]]},"1659":{"position":[[521,8]]},"1665":{"position":[[722,8]]},"1674":{"position":[[148,8]]},"1676":{"position":[[451,8]]},"1698":{"position":[[428,10]]},"1738":{"position":[[460,9]]},"1802":{"position":[[373,8],[396,8]]}}}],["positive\\n",{"_index":5632,"t":{"1802":{"position":[[545,10],[714,10]]}}}],["pospospo",{"_index":1268,"t":{"308":{"position":[[601,9]]}}}],["possibl",{"_index":2089,"t":{"594":{"position":[[1095,8]]},"596":{"position":[[1179,8],[1457,8]]},"608":{"position":[[805,8],[851,8]]},"1427":{"position":[[45,8]]},"1595":{"position":[[247,8]]},"1608":{"position":[[6,8]]}}}],["post",{"_index":4,"t":{"3":{"position":[[40,5],[92,4]]},"7":{"position":[[182,4],[291,4],[339,4]]},"9":{"position":[[5,5],[116,6]]},"1585":{"position":[[40,5]]},"1587":{"position":[[450,5],[495,4],[529,4]]}}}],["power",{"_index":33,"t":{"7":{"position":[[33,7]]},"9":{"position":[[74,5]]},"428":{"position":[[230,5]]},"608":{"position":[[568,5]]},"1006":{"position":[[0,5]]}}}],["powershel",{"_index":111,"t":{"17":{"position":[[244,11]]}}}],["ppo",{"_index":4917,"t":{"1546":{"position":[[474,3],[965,3]]},"1550":{"position":[[218,3],[260,3]]},"1552":{"position":[[554,3]]},"1558":{"position":[[1216,3],[1227,3],[1285,3],[1332,3],[1986,3],[2055,3],[2096,3]]},"1570":{"position":[[320,3]]}}}],["ppp",{"_index":2493,"t":{"688":{"position":[[977,3],[1149,3]]},"786":{"position":[[4110,3],[4170,3]]},"795":{"position":[[778,3],[855,3]]},"1065":{"position":[[469,3],[860,3]]},"1128":{"position":[[491,3],[927,3],[1720,3]]},"1130":{"position":[[755,3]]},"1164":{"position":[[107,3]]},"1167":{"position":[[184,3]]},"1178":{"position":[[49,3]]},"1238":{"position":[[815,3]]},"1384":{"position":[[1780,3]]}}}],["ppt",{"_index":4961,"t":{"1558":{"position":[[2007,3]]}}}],["pqp_qpq",{"_index":2502,"t":{"692":{"position":[[281,9]]}}}],["pqqkp^{qk}_qpqqk",{"_index":2522,"t":{"696":{"position":[[519,17]]}}}],["practic",{"_index":1613,"t":{"436":{"position":[[1659,9]]}}}],["prasanna",{"_index":1963,"t":{"531":{"position":[[743,8]]}}}],["pre",{"_index":431,"t":{"91":{"position":[[959,3],[1058,3]]},"97":{"position":[[20,3],[188,3],[316,3],[362,3]]},"112":{"position":[[43,3],[137,3]]},"114":{"position":[[95,3],[134,3],[185,3],[219,3],[274,3],[310,3]]},"120":{"position":[[117,3],[239,3]]},"213":{"position":[[130,3]]},"215":{"position":[[1562,3]]},"221":{"position":[[725,3]]},"227":{"position":[[16,3]]},"242":{"position":[[119,3]]},"269":{"position":[[19,3],[68,3]]},"275":{"position":[[10,3],[44,3]]},"306":{"position":[[261,3]]},"339":{"position":[[225,3]]},"407":{"position":[[27,3]]},"521":{"position":[[116,3]]},"523":{"position":[[115,3],[996,3]]},"525":{"position":[[39,3],[340,3],[728,3],[838,3],[1040,3]]},"529":{"position":[[167,3]]},"531":{"position":[[97,3],[781,3],[1490,3]]},"533":{"position":[[43,3],[256,3],[374,3]]},"567":{"position":[[637,3],[700,3]]},"577":{"position":[[67,3]]},"579":{"position":[[0,3]]},"581":{"position":[[132,3]]},"587":{"position":[[36,3]]},"589":{"position":[[0,3],[78,3],[158,3],[825,3],[1257,3]]},"594":{"position":[[55,3],[206,3]]},"600":{"position":[[40,3],[343,3],[478,3]]},"602":{"position":[[127,3]]},"620":{"position":[[137,3]]},"648":{"position":[[73,3]]},"656":{"position":[[0,3]]},"658":{"position":[[0,3],[806,3],[1007,3],[1517,3],[2030,3]]},"660":{"position":[[376,3]]},"666":{"position":[[7,3],[513,3]]},"668":{"position":[[48,3]]},"670":{"position":[[963,3]]},"679":{"position":[[174,3]]},"683":{"position":[[0,3],[381,3]]},"688":{"position":[[647,3]]},"696":{"position":[[142,3]]},"717":{"position":[[79,3]]},"719":{"position":[[189,3],[548,3],[800,3]]},"721":{"position":[[218,3]]},"723":{"position":[[75,3],[334,3],[817,3]]},"733":{"position":[[124,3],[237,3]]},"759":{"position":[[60,3],[209,3]]},"768":{"position":[[56,3]]},"774":{"position":[[53,3]]},"784":{"position":[[6,3],[97,3],[215,3],[293,3],[844,3]]},"786":{"position":[[836,3],[917,3],[2425,3]]},"791":{"position":[[32,3]]},"795":{"position":[[0,3]]},"809":{"position":[[92,3],[213,3]]},"821":{"position":[[75,3]]},"823":{"position":[[27,3]]},"830":{"position":[[62,3]]},"847":{"position":[[0,3]]},"849":{"position":[[924,3]]},"853":{"position":[[2308,3],[2398,3]]},"885":{"position":[[437,3],[591,3]]},"887":{"position":[[633,3],[1281,3]]},"891":{"position":[[59,3]]},"893":{"position":[[2019,3],[2550,3]]},"895":{"position":[[181,3]]},"899":{"position":[[0,3]]},"905":{"position":[[254,3]]},"921":{"position":[[28,3]]},"924":{"position":[[50,3]]},"928":{"position":[[176,3]]},"940":{"position":[[47,3]]},"945":{"position":[[468,3]]},"955":{"position":[[491,3],[623,3]]},"973":{"position":[[153,3]]},"977":{"position":[[81,3],[717,3]]},"979":{"position":[[525,3],[948,3],[1233,3]]},"982":{"position":[[367,3]]},"986":{"position":[[731,3]]},"1006":{"position":[[534,3]]},"1012":{"position":[[198,3]]},"1014":{"position":[[0,3],[323,3],[500,3],[1258,3]]},"1019":{"position":[[456,3]]},"1039":{"position":[[26,3]]},"1062":{"position":[[559,3]]},"1084":{"position":[[224,3]]},"1093":{"position":[[8,3],[110,3],[1033,3],[1527,3],[1667,3],[1813,3]]},"1097":{"position":[[69,3]]},"1099":{"position":[[0,3],[153,3],[419,3]]},"1101":{"position":[[122,3],[1070,3]]},"1105":{"position":[[43,3],[229,3],[272,3]]},"1109":{"position":[[301,3],[1032,3]]},"1111":{"position":[[1130,3],[1449,3]]},"1115":{"position":[[379,3]]},"1120":{"position":[[63,3],[349,3]]},"1126":{"position":[[63,3],[570,3],[1511,3],[1759,3]]},"1132":{"position":[[90,3],[345,3],[672,3],[829,3],[1001,3],[1236,3],[1397,3],[1822,3]]},"1134":{"position":[[15,3]]},"1141":{"position":[[275,3]]},"1143":{"position":[[16,3],[164,3],[578,3],[1053,3]]},"1145":{"position":[[1546,3],[2147,3]]},"1149":{"position":[[206,3]]},"1153":{"position":[[23,3],[468,3]]},"1159":{"position":[[0,3]]},"1212":{"position":[[157,3]]},"1225":{"position":[[16,3]]},"1227":{"position":[[609,3]]},"1238":{"position":[[7,3]]},"1246":{"position":[[139,3]]},"1266":{"position":[[92,3]]},"1268":{"position":[[22,3]]},"1289":{"position":[[25,3]]},"1291":{"position":[[25,3],[332,3],[436,3]]},"1300":{"position":[[16,3]]},"1303":{"position":[[611,3]]},"1332":{"position":[[418,3]]},"1341":{"position":[[355,3],[493,3],[743,3]]},"1357":{"position":[[237,3]]},"1379":{"position":[[0,3]]},"1384":{"position":[[2659,3],[2682,4],[2800,4]]},"1407":{"position":[[0,3]]},"1411":{"position":[[64,3]]},"1419":{"position":[[293,3]]},"1442":{"position":[[915,3]]},"1449":{"position":[[428,3]]},"1466":{"position":[[23,3]]},"1494":{"position":[[92,3]]},"1496":{"position":[[149,3]]},"1644":{"position":[[4,3]]},"1646":{"position":[[270,3],[365,3]]},"1667":{"position":[[718,3],[1009,3]]},"1669":{"position":[[490,3]]},"1682":{"position":[[424,3],[566,3],[753,3],[806,3]]},"1684":{"position":[[337,3],[448,3],[582,3]]},"1693":{"position":[[360,3]]},"1695":{"position":[[373,3],[441,3],[534,3],[617,3],[668,3],[763,4],[792,4],[831,3]]},"1708":{"position":[[49,3]]},"1712":{"position":[[194,3]]},"1720":{"position":[[654,3],[964,3]]},"1724":{"position":[[51,3]]},"1748":{"position":[[53,3]]},"1752":{"position":[[35,3]]}}}],["pre][prompt",{"_index":3826,"t":{"1101":{"position":[[1257,13]]}}}],["precis",{"_index":921,"t":{"189":{"position":[[124,9],[158,9]]},"244":{"position":[[245,9],[284,9],[308,9]]},"614":{"position":[[74,9]]}}}],["precision@0.5",{"_index":912,"t":{"187":{"position":[[65,13]]}}}],["predict",{"_index":481,"t":{"97":{"position":[[86,10]]},"130":{"position":[[1048,10]]},"174":{"position":[[460,10],[1295,11],[1315,10]]},"227":{"position":[[474,9]]},"306":{"position":[[145,9]]},"350":{"position":[[835,10]]},"485":{"position":[[1029,7]]},"531":{"position":[[1170,9]]},"569":{"position":[[1067,10]]},"579":{"position":[[64,10]]},"606":{"position":[[196,10]]},"608":{"position":[[783,10]]},"683":{"position":[[243,10]]},"698":{"position":[[105,11]]},"859":{"position":[[245,9]]},"1028":{"position":[[206,10],[517,10]]},"1113":{"position":[[510,10]]},"1298":{"position":[[171,7]]},"1382":{"position":[[20,10]]},"1384":{"position":[[952,10]]},"1401":{"position":[[261,10]]},"1646":{"position":[[829,9],[958,10]]},"1695":{"position":[[816,8],[854,7]]}}}],["prefix",{"_index":1041,"t":{"225":{"position":[[743,6]]},"510":{"position":[[61,6]]},"577":{"position":[[121,6]]},"598":{"position":[[452,6],[3545,6]]},"626":{"position":[[85,6]]},"628":{"position":[[250,6]]},"630":{"position":[[266,6],[1954,6]]},"633":{"position":[[788,6]]},"635":{"position":[[0,6]]},"638":{"position":[[117,6]]},"640":{"position":[[147,6],[271,6]]},"648":{"position":[[381,6]]},"719":{"position":[[1281,6]]},"729":{"position":[[12,6]]},"735":{"position":[[105,6]]},"751":{"position":[[69,11],[218,6]]},"753":{"position":[[0,6]]},"765":{"position":[[108,7],[146,6]]},"786":{"position":[[613,6],[703,6]]},"791":{"position":[[937,6]]},"891":{"position":[[736,6]]},"899":{"position":[[72,6]]},"938":{"position":[[217,6]]},"977":{"position":[[99,6]]},"982":{"position":[[1063,6],[1104,6]]},"1012":{"position":[[518,7]]},"1014":{"position":[[1195,7]]},"1028":{"position":[[328,6]]},"1124":{"position":[[499,6]]},"1126":{"position":[[1191,7],[1321,6],[1869,7],[1999,8]]},"1132":{"position":[[1528,6]]},"1134":{"position":[[241,6]]},"1136":{"position":[[319,6]]},"1145":{"position":[[256,6],[321,6],[608,6],[729,6],[774,6],[823,6],[850,6]]},"1230":{"position":[[227,6]]},"1289":{"position":[[231,6],[250,6],[343,6],[401,6],[444,6],[545,6]]},"1291":{"position":[[964,6],[1118,6],[1186,6],[1203,6],[1255,6],[1275,6],[1318,6],[1491,6]]},"1303":{"position":[[937,6]]},"1305":{"position":[[0,6],[36,6],[131,6],[286,6],[351,6],[400,6],[1001,6],[1259,6]]},"1307":{"position":[[513,6]]},"1312":{"position":[[33,6]]},"1314":{"position":[[267,6],[355,6],[415,6],[576,6],[657,6]]},"1317":{"position":[[44,6],[197,6],[266,6],[377,6],[423,6],[541,6],[601,6]]},"1319":{"position":[[23,6],[74,6],[139,6]]},"1321":{"position":[[40,6],[286,6],[386,6],[487,6],[587,6]]},"1323":{"position":[[492,6],[594,6]]},"1326":{"position":[[7,6],[58,6],[151,6]]},"1328":{"position":[[430,6]]},"1330":{"position":[[286,6],[326,6]]},"1332":{"position":[[4,6],[409,6],[479,6]]},"1334":{"position":[[50,6],[180,6],[270,6]]},"1337":{"position":[[11,6],[173,6]]},"1339":{"position":[[26,6],[45,6],[137,6],[195,6],[365,6]]},"1341":{"position":[[52,6],[202,6],[318,6],[454,6],[484,6],[653,6],[727,6],[1011,6],[1061,6]]},"1379":{"position":[[1018,6]]},"1384":{"position":[[77,6],[1075,6],[1090,6],[1273,6],[1624,6],[1766,6],[2317,6],[2403,6],[2492,6],[3877,6]]},"1389":{"position":[[87,6],[192,6],[967,6],[1672,7],[1750,6],[1860,6],[1873,6]]},"1393":{"position":[[683,7],[963,6]]},"1395":{"position":[[1349,6],[1364,6],[1637,6],[1746,6],[2009,6],[2108,6],[2172,6],[2279,6],[2347,6]]},"1419":{"position":[[250,7]]},"1494":{"position":[[489,6],[593,7],[607,6]]},"1499":{"position":[[168,6],[431,6]]},"1702":{"position":[[653,6]]},"1712":{"position":[[18,6],[112,6],[251,6]]},"1714":{"position":[[263,6]]},"1720":{"position":[[291,6],[305,6],[875,6],[1004,6],[1339,6]]},"1724":{"position":[[190,6]]},"1746":{"position":[[72,6]]},"1754":{"position":[[154,6]]},"1774":{"position":[[61,6],[447,6],[552,6]]},"1776":{"position":[[142,6]]}}}],["prefix;x;y][\\text{prefix",{"_index":4339,"t":{"1330":{"position":[[81,27]]}}}],["prepend",{"_index":994,"t":{"215":{"position":[[1049,9]]},"681":{"position":[[864,7],[1565,7]]},"686":{"position":[[206,7]]},"688":{"position":[[136,7],[1074,7]]},"979":{"position":[[378,9]]},"982":{"position":[[804,7]]},"984":{"position":[[400,7]]},"1126":{"position":[[1297,9],[1595,7]]},"1128":{"position":[[509,7]]},"1132":{"position":[[1386,7]]},"1145":{"position":[[311,9],[428,7],[1806,9]]},"1367":{"position":[[257,7]]},"1421":{"position":[[127,7]]}}}],["preprocess",{"_index":3924,"t":{"1132":{"position":[[969,13]]}}}],["pretrain",{"_index":663,"t":{"143":{"position":[[414,10],[678,8]]},"159":{"position":[[420,11]]},"177":{"position":[[43,11],[125,8],[487,10]]},"182":{"position":[[319,11]]},"221":{"position":[[0,11]]},"225":{"position":[[377,10]]},"227":{"position":[[189,11],[734,10]]},"230":{"position":[[358,10],[474,10]]},"232":{"position":[[345,10]]},"239":{"position":[[92,10]]},"277":{"position":[[22,11]]},"339":{"position":[[157,11]]},"341":{"position":[[0,10]]},"343":{"position":[[353,11]]},"347":{"position":[[105,10]]},"352":{"position":[[0,10],[315,11]]},"384":{"position":[[262,10]]},"439":{"position":[[94,11]]},"441":{"position":[[396,11]]},"445":{"position":[[77,11]]},"447":{"position":[[198,11]]},"455":{"position":[[132,10],[1004,11]]},"468":{"position":[[131,11]]},"483":{"position":[[230,11],[380,8],[412,11],[553,11]]},"485":{"position":[[41,8],[165,11],[851,9],[1057,8],[1205,8],[1270,10]]},"488":{"position":[[142,8],[205,11],[249,8],[266,11],[346,8],[365,8]]},"496":{"position":[[39,8]]},"502":{"position":[[489,8]]},"504":{"position":[[8,11],[99,10],[140,11],[432,8]]},"506":{"position":[[0,11]]},"515":{"position":[[46,11],[525,10],[656,8],[773,8]]},"517":{"position":[[28,8]]},"557":{"position":[[322,11]]},"567":{"position":[[192,11],[282,11]]},"569":{"position":[[1041,11]]},"600":{"position":[[390,11]]},"681":{"position":[[602,8]]},"967":{"position":[[197,11]]},"999":{"position":[[1019,11]]},"1227":{"position":[[11,10]]},"1255":{"position":[[68,10]]},"1341":{"position":[[18,10],[116,11]]},"1468":{"position":[[7,8]]},"1546":{"position":[[971,11]]},"1550":{"position":[[74,10]]},"1558":{"position":[[4,10],[1300,11],[1901,11],[1966,11]]},"1570":{"position":[[256,11]]},"1693":{"position":[[480,10],[549,8]]},"1704":{"position":[[381,10]]},"1708":{"position":[[105,10]]},"1720":{"position":[[184,10],[2344,10]]},"1750":{"position":[[25,10],[153,10]]},"1754":{"position":[[122,10]]},"1756":{"position":[[25,11]]},"1758":{"position":[[19,10],[115,11]]},"1762":{"position":[[444,10]]},"1764":{"position":[[234,10]]},"1766":{"position":[[180,10]]},"1770":{"position":[[406,10],[539,10]]},"1772":{"position":[[390,10],[467,10]]},"1774":{"position":[[95,10],[474,10],[571,10]]},"1776":{"position":[[54,10],[110,11]]},"1778":{"position":[[837,10]]},"1780":{"position":[[149,10]]},"1782":{"position":[[616,10],[2139,10],[2402,10],[2469,10]]},"1786":{"position":[[73,10]]},"1792":{"position":[[123,8]]},"1796":{"position":[[324,10]]},"1800":{"position":[[28,8],[55,10],[103,11]]},"1802":{"position":[[66,10],[160,10],[246,10],[900,10]]}}}],["previou",{"_index":1239,"t":{"302":{"position":[[98,8]]}}}],["previous/next",{"_index":5035,"t":{"1591":{"position":[[59,13]]}}}],["primari",{"_index":2343,"t":{"662":{"position":[[345,7]]}}}],["prime",{"_index":3870,"t":{"1126":{"position":[[421,9]]}}}],["prior",{"_index":766,"t":{"170":{"position":[[839,5],[912,5],[969,5],[2265,6]]},"1132":{"position":[[1153,6]]},"1644":{"position":[[392,5]]},"1646":{"position":[[2028,5],[2218,5],[2243,5],[2578,5],[2597,5],[3254,5]]},"1651":{"position":[[131,5]]},"1676":{"position":[[523,5]]},"1686":{"position":[[317,5]]},"1689":{"position":[[143,5]]}}}],["prior])annot",{"_index":797,"t":{"170":{"position":[[2009,17]]}}}],["prior])​express",{"_index":810,"t":{"170":{"position":[[2373,18]]}}}],["prioriti",{"_index":2943,"t":{"797":{"position":[[2469,8]]}}}],["prismer",{"_index":1026,"t":{"219":{"position":[[63,7],[111,7],[226,7],[325,7]]},"221":{"position":[[455,7],[806,7],[933,7]]},"225":{"position":[[0,7],[312,7],[688,7],[704,7]]},"227":{"position":[[0,7]]},"236":{"position":[[4,7]]},"239":{"position":[[0,7]]},"251":{"position":[[6,7],[171,7]]},"253":{"position":[[244,7]]},"255":{"position":[[4,7]]},"262":{"position":[[11,9],[135,7]]},"267":{"position":[[180,8]]},"271":{"position":[[11,7]]},"273":{"position":[[61,7]]},"275":{"position":[[56,7]]},"277":{"position":[[12,7],[160,7]]},"279":{"position":[[0,7]]}}}],["prismerz",{"_index":1085,"t":{"239":{"position":[[54,8]]}}}],["privaci",{"_index":4348,"t":{"1337":{"position":[[60,7]]}}}],["proabil",{"_index":2118,"t":{"596":{"position":[[1262,10]]}}}],["probabl",{"_index":1451,"t":{"352":{"position":[[520,13]]},"569":{"position":[[433,11],[549,11]]},"594":{"position":[[1131,13]]},"596":{"position":[[354,11],[416,11],[1699,11],[1956,11]]},"622":{"position":[[303,11]]},"819":{"position":[[162,11]]},"1128":{"position":[[93,11],[1912,11]]},"1238":{"position":[[230,11]]},"1244":{"position":[[705,11]]},"1352":{"position":[[679,11],[764,11],[941,11],[1017,11],[1295,11]]},"1657":{"position":[[31,11],[2529,11],[2562,11]]}}}],["probe",{"_index":3747,"t":{"1091":{"position":[[187,7]]},"1093":{"position":[[1238,7],[1768,7]]},"1103":{"position":[[25,7]]},"1105":{"position":[[10,7]]},"1107":{"position":[[997,7]]},"1109":{"position":[[943,7]]},"1714":{"position":[[210,7]]},"1762":{"position":[[8,7],[430,7],[633,7]]}}}],["problem",{"_index":342,"t":{"78":{"position":[[0,8]]},"168":{"position":[[444,7]]},"382":{"position":[[331,7]]},"384":{"position":[[958,7]]},"386":{"position":[[35,7]]},"391":{"position":[[18,8],[53,8],[84,8],[115,8],[147,8]]},"403":{"position":[[202,7]]},"409":{"position":[[196,9]]},"428":{"position":[[166,9]]},"561":{"position":[[190,7]]},"819":{"position":[[116,7]]},"1126":{"position":[[2615,8]]},"1494":{"position":[[338,7]]},"1589":{"position":[[0,7]]},"1653":{"position":[[916,7]]},"1665":{"position":[[1002,7]]}}}],["process",{"_index":1828,"t":{"525":{"position":[[757,7],[797,7],[851,7]]},"531":{"position":[[124,8]]},"626":{"position":[[373,7]]},"784":{"position":[[778,11]]},"1060":{"position":[[1019,10]]},"1230":{"position":[[576,12]]},"1367":{"position":[[494,7]]},"1517":{"position":[[200,7]]}}}],["processd",{"_index":1820,"t":{"525":{"position":[[384,8]]}}}],["prod^n_{j=1}p([𝙼]_j",{"_index":5285,"t":{"1657":{"position":[[2148,21]]}}}],["product",{"_index":1188,"t":{"298":{"position":[[32,7],[169,7],[612,7],[656,7],[868,7],[1080,7],[1132,7],[1216,7]]},"302":{"position":[[713,7]]},"324":{"position":[[391,7]]},"988":{"position":[[1566,7]]},"1242":{"position":[[747,7]]},"1246":{"position":[[669,7]]},"1285":{"position":[[247,7]]},"1599":{"position":[[20,11]]},"1600":{"position":[[10,10]]}}}],["proejction",{"_index":3375,"t":{"895":{"position":[[415,10]]}}}],["profici",{"_index":3444,"t":{"955":{"position":[[363,11]]}}}],["program",{"_index":1588,"t":{"428":{"position":[[77,8]]},"483":{"position":[[837,11]]},"1126":{"position":[[1057,7]]},"1442":{"position":[[690,11],[1021,13],[1682,11],[1833,11]]},"1449":{"position":[[480,11]]}}}],["progress",{"_index":152,"t":{"23":{"position":[[149,11]]},"25":{"position":[[466,11],[553,11]]},"27":{"position":[[207,11],[235,11]]},"44":{"position":[[7,11]]},"47":{"position":[[404,11]]},"49":{"position":[[19,11]]},"53":{"position":[[348,11]]},"72":{"position":[[0,11]]},"78":{"position":[[412,11]]},"1347":{"position":[[496,11]]}}}],["progressivel",{"_index":341,"t":{"76":{"position":[[47,12]]}}}],["project",{"_index":102,"t":{"17":{"position":[[116,7]]},"91":{"position":[[517,10],[558,10]]},"95":{"position":[[104,10],[239,10],[338,10]]},"116":{"position":[[416,10]]},"234":{"position":[[191,10],[269,10]]},"300":{"position":[[122,11],[225,7],[253,9],[398,7],[918,11]]},"628":{"position":[[1115,10]]},"630":{"position":[[390,10],[909,11],[2007,10]]},"646":{"position":[[124,7],[134,10],[160,10],[215,10]]},"662":{"position":[[439,10],[614,10],[849,10],[903,10],[1206,10]]},"721":{"position":[[159,10]]},"733":{"position":[[198,10]]},"778":{"position":[[128,7]]},"789":{"position":[[590,10],[713,10]]},"791":{"position":[[757,11]]},"809":{"position":[[845,10]]},"893":{"position":[[455,10],[2248,10]]},"912":{"position":[[104,10]]},"914":{"position":[[124,10]]},"934":{"position":[[1009,10]]},"940":{"position":[[127,10]]},"942":{"position":[[69,10]]},"949":{"position":[[406,10]]},"953":{"position":[[218,10]]},"988":{"position":[[633,7],[869,10],[1321,10]]},"994":{"position":[[131,10],[270,10]]},"1145":{"position":[[1090,7]]},"1159":{"position":[[1663,11]]},"1167":{"position":[[235,7],[780,10],[860,10]]},"1172":{"position":[[26,10]]},"1178":{"position":[[379,7],[424,11],[519,9]]},"1195":{"position":[[593,7]]},"1218":{"position":[[127,10],[205,10]]},"1221":{"position":[[508,11],[554,11],[669,11]]},"1384":{"position":[[254,10],[1424,11],[3591,10]]},"1604":{"position":[[30,8]]}}}],["promda",{"_index":1022,"t":{"215":{"position":[[2374,9],[2517,10],[2642,10]]}}}],["promnpt",{"_index":1407,"t":{"336":{"position":[[1942,7]]}}}],["promp",{"_index":2510,"t":{"694":{"position":[[447,6]]}}}],["prompt",{"_index":110,"t":{"17":{"position":[[236,7]]},"124":{"position":[[520,6],[562,6]]},"126":{"position":[[1129,6],[1174,6]]},"132":{"position":[[481,6],[539,6],[625,6],[659,6],[968,6]]},"140":{"position":[[16,6]]},"147":{"position":[[117,6],[317,6]]},"159":{"position":[[25,8],[733,6]]},"163":{"position":[[349,6]]},"165":{"position":[[1387,6],[1430,6],[1518,6],[1567,6],[1614,6],[1667,6],[1723,6],[1797,6],[1854,6],[1944,6],[2015,6],[2254,6],[2644,6]]},"168":{"position":[[151,6],[227,6],[299,6],[342,6],[413,6],[548,6],[572,6]]},"170":{"position":[[4,6],[39,6],[120,6],[430,6],[1297,6],[1469,6],[1897,6]]},"172":{"position":[[0,6],[154,6],[200,6],[388,6]]},"174":{"position":[[14,6],[234,6],[894,6],[1143,6],[1543,6],[1594,6],[1681,6],[1964,6],[2357,6],[2580,6]]},"179":{"position":[[206,6]]},"203":{"position":[[18,6],[146,6],[385,6]]},"205":{"position":[[196,6],[262,6]]},"209":{"position":[[10,6]]},"213":{"position":[[70,6],[183,6]]},"215":{"position":[[989,6],[1025,6],[1171,6],[1267,6],[1390,7],[1412,6],[1522,6]]},"246":{"position":[[122,6]]},"273":{"position":[[117,9]]},"334":{"position":[[103,6],[149,6],[417,6],[466,6],[520,6],[577,6]]},"336":{"position":[[193,6],[255,6],[284,6],[330,6],[370,6],[571,6],[591,6],[905,6],[1034,6],[1109,6],[1123,6],[1488,6],[1561,6],[1602,6],[1686,6],[1764,6],[1866,6]]},"341":{"position":[[38,6],[86,6],[98,6],[130,6],[174,6],[203,6]]},"343":{"position":[[368,9],[477,6],[620,6]]},"345":{"position":[[30,6],[186,6]]},"347":{"position":[[58,6],[396,6],[423,6],[536,6],[550,6]]},"350":{"position":[[108,6]]},"354":{"position":[[556,6]]},"356":{"position":[[63,6],[89,6],[125,6],[164,6],[217,6],[263,6]]},"358":{"position":[[52,6],[96,6],[361,6],[572,6],[1383,6]]},"360":{"position":[[0,6]]},"362":{"position":[[33,6],[84,6],[147,6],[206,6]]},"368":{"position":[[41,6],[96,6],[110,6],[157,6],[229,6],[283,6]]},"370":{"position":[[0,6],[111,6]]},"376":{"position":[[76,6],[139,6]]},"378":{"position":[[18,6],[45,6]]},"382":{"position":[[122,9],[305,9]]},"384":{"position":[[363,9],[508,8],[653,9],[782,9],[849,9],[933,9],[1011,9],[1042,6]]},"386":{"position":[[149,9],[448,9]]},"388":{"position":[[57,9]]},"393":{"position":[[68,9]]},"395":{"position":[[24,9]]},"399":{"position":[[4,9],[114,9],[281,9],[379,9]]},"401":{"position":[[4,9],[27,9]]},"403":{"position":[[4,9],[106,9],[256,9]]},"407":{"position":[[4,9],[76,9]]},"409":{"position":[[52,9],[345,9],[426,9],[479,9],[585,9]]},"416":{"position":[[38,9],[61,9],[112,9]]},"418":{"position":[[4,9]]},"424":{"position":[[286,9],[410,9],[486,9]]},"426":{"position":[[36,9],[254,9],[314,9],[352,9]]},"428":{"position":[[215,9],[269,6],[306,9]]},"430":{"position":[[4,9]]},"434":{"position":[[363,6],[460,6]]},"436":{"position":[[1178,6]]},"441":{"position":[[115,6]]},"447":{"position":[[645,6]]},"455":{"position":[[943,6],[960,6],[1080,6]]},"457":{"position":[[467,6],[1048,6]]},"459":{"position":[[96,6],[203,6],[415,6],[638,6],[713,6]]},"461":{"position":[[45,6]]},"466":{"position":[[20,6]]},"471":{"position":[[106,6]]},"479":{"position":[[97,6]]},"537":{"position":[[226,6]]},"539":{"position":[[600,10]]},"555":{"position":[[44,9],[75,9],[146,9],[198,9],[220,9]]},"561":{"position":[[89,9]]},"563":{"position":[[305,9]]},"587":{"position":[[288,6]]},"589":{"position":[[549,8],[617,9],[924,8],[1009,6],[1810,6]]},"594":{"position":[[435,7],[450,6],[473,8],[486,8],[1289,6],[1333,6]]},"598":{"position":[[436,6],[3348,6],[3397,6],[3982,6]]},"600":{"position":[[3,6],[20,6]]},"602":{"position":[[544,6]]},"618":{"position":[[350,6]]},"628":{"position":[[290,6]]},"633":{"position":[[870,6]]},"679":{"position":[[158,6],[274,6],[359,6],[389,6],[415,6],[520,7],[630,6]]},"681":{"position":[[721,6],[846,7],[878,6],[941,6],[1067,6],[1143,6],[1291,6],[1320,6],[1349,6],[1373,6],[1427,6],[1476,6],[1499,6],[1585,6],[1661,6],[1777,6],[1829,6],[1848,6],[1898,6],[1929,6],[2009,6]]},"683":{"position":[[836,6],[937,6],[996,6],[1056,6],[1150,6],[1169,6],[1201,6]]},"686":{"position":[[0,6],[85,7],[96,6],[148,6],[328,6],[411,7]]},"688":{"position":[[0,6],[46,6],[77,7],[96,6],[113,6],[947,6],[963,6],[995,7],[1020,7],[1125,7],[1141,7]]},"690":{"position":[[55,6],[86,7],[104,6],[113,6],[139,6],[167,6],[176,6],[205,7],[241,7],[339,6],[387,6],[413,6],[442,7],[462,7],[515,6],[524,6],[571,7],[595,7],[639,7],[672,7],[709,7],[735,7],[799,7],[819,7],[861,7],[877,7],[925,7]]},"692":{"position":[[14,6],[149,7],[234,6],[315,6]]},"694":{"position":[[5,6],[33,7],[110,7],[280,7]]},"696":{"position":[[6,7],[407,7],[434,7],[454,7],[474,7],[509,7],[652,7],[723,7],[870,7],[986,7],[1141,7],[1205,7],[1688,7]]},"701":{"position":[[3,6]]},"703":{"position":[[5,6],[70,6],[94,6],[129,7],[181,7],[244,7],[274,6]]},"705":{"position":[[10,6],[236,7],[278,7]]},"707":{"position":[[31,6],[70,6],[183,6],[210,6],[281,6],[529,6],[551,6],[677,6],[792,6]]},"709":{"position":[[234,6],[402,6],[499,6],[569,8],[582,6],[608,6],[686,7],[707,7],[728,7],[761,7],[792,7],[834,7],[872,6],[911,7],[948,7],[998,7],[1027,6],[1075,6],[1122,6],[1166,6],[1326,6],[1381,6],[1506,7],[1610,6],[1641,6],[1690,6],[1808,6],[1882,6],[1919,6],[1967,7],[2018,6],[2107,6],[2372,6],[2396,6],[2452,6],[2485,6],[2531,6],[2606,6]]},"711":{"position":[[6,6],[32,6],[65,6],[102,6],[152,6],[170,7]]},"713":{"position":[[32,6],[81,6],[137,6],[226,7]]},"786":{"position":[[629,6]]},"859":{"position":[[104,6]]},"885":{"position":[[278,7]]},"887":{"position":[[404,7],[466,6],[696,6],[1078,7]]},"891":{"position":[[151,7],[229,7],[303,6],[361,6],[695,6]]},"893":{"position":[[11,7],[1267,7],[1303,6],[1579,6],[1967,6],[2472,7]]},"895":{"position":[[672,7],[816,6],[867,6],[1099,6]]},"897":{"position":[[44,6]]},"899":{"position":[[63,6]]},"901":{"position":[[144,6]]},"905":{"position":[[275,6],[313,6]]},"934":{"position":[[635,7],[834,6],[1099,7],[1310,7],[1355,7],[1404,6]]},"938":{"position":[[191,6],[317,6]]},"942":{"position":[[135,6]]},"945":{"position":[[57,6],[167,6]]},"947":{"position":[[87,6]]},"949":{"position":[[509,7]]},"953":{"position":[[52,7],[73,7],[141,6],[275,6],[339,6],[415,7],[499,7]]},"961":{"position":[[66,7],[111,7],[121,6]]},"967":{"position":[[31,7],[269,6]]},"969":{"position":[[34,6]]},"977":{"position":[[131,7],[233,6],[338,6],[354,6],[412,6],[443,6],[551,7],[734,6],[796,6],[856,6]]},"979":{"position":[[332,6],[544,7],[643,6],[665,7],[682,6],[965,7],[1249,7],[1471,6]]},"982":{"position":[[67,7],[103,6],[213,6],[229,6],[260,7],[312,7],[404,6],[543,7],[612,7],[634,6],[675,6],[1053,6],[1088,7],[1221,7]]},"984":{"position":[[54,6],[80,6],[143,6],[252,6],[358,6],[391,6],[537,6]]},"986":{"position":[[26,6],[148,7],[170,6],[248,7],[332,6],[583,6],[687,7]]},"988":{"position":[[16,6],[50,7],[78,6],[161,7],[182,6],[199,7],[331,6],[439,6],[618,6],[668,6],[695,7],[1589,6]]},"990":{"position":[[29,6],[70,6],[368,7],[471,6],[644,6]]},"992":{"position":[[74,7],[258,6],[272,6],[340,6],[369,6],[388,6],[673,7],[696,6],[775,6],[908,6],[930,6],[978,6]]},"994":{"position":[[36,6],[77,6],[465,6],[551,6]]},"997":{"position":[[266,6]]},"999":{"position":[[50,6],[119,7],[151,6],[424,6],[897,6],[1051,6],[1083,6],[1145,6],[1229,6],[1258,6]]},"1002":{"position":[[623,6],[695,6],[728,6],[863,6],[884,6]]},"1006":{"position":[[194,6],[220,6],[320,6],[553,7],[639,6],[700,6],[782,6],[861,6],[906,6],[942,6],[968,6],[1000,6],[1102,6],[1251,6],[1310,6],[1368,6],[1440,7],[1539,8],[1717,6],[1770,6],[1925,6],[2182,6],[2600,6],[2621,6],[2871,6]]},"1008":{"position":[[68,6],[95,6],[135,6],[326,6],[348,6],[428,6],[468,6],[503,6]]},"1012":{"position":[[0,6],[65,6],[173,6],[237,6],[328,6],[504,6],[539,8]]},"1014":{"position":[[311,9],[385,6],[486,6],[574,9],[652,9],[699,6],[729,7],[775,9],[856,7],[890,9],[986,9],[1181,6],[1216,8],[1297,6],[1312,6]]},"1019":{"position":[[94,9],[110,6],[413,7],[504,7],[536,7],[779,6]]},"1022":{"position":[[0,7]]},"1024":{"position":[[0,7]]},"1026":{"position":[[0,7],[236,7],[381,6]]},"1028":{"position":[[0,7],[48,6],[270,6],[319,6],[502,6]]},"1033":{"position":[[0,6],[67,6],[135,6],[191,6]]},"1035":{"position":[[60,7]]},"1039":{"position":[[137,7],[251,6]]},"1045":{"position":[[155,6]]},"1047":{"position":[[58,7],[230,7],[297,7]]},"1049":{"position":[[97,7],[144,7],[273,6]]},"1054":{"position":[[0,7],[73,6],[98,6],[142,6],[227,7],[325,6]]},"1060":{"position":[[31,6],[83,6],[299,6],[809,6],[840,6],[862,6]]},"1062":{"position":[[96,6],[273,6],[549,7],[577,7],[619,7],[1030,6],[1074,6],[1096,6],[1227,6],[1583,6]]},"1065":{"position":[[312,6],[462,6],[846,6]]},"1067":{"position":[[30,7],[62,6],[158,6],[240,6],[1349,6]]},"1070":{"position":[[494,6],[1813,6],[1872,7]]},"1080":{"position":[[82,6],[146,6],[186,6],[305,6],[407,6]]},"1084":{"position":[[184,6],[1122,6]]},"1087":{"position":[[370,9]]},"1091":{"position":[[122,6],[367,6]]},"1093":{"position":[[510,6],[571,6],[624,6],[689,6],[746,6],[792,7],[877,7],[969,6],[1060,6],[1081,6],[1099,6],[1266,6]]},"1095":{"position":[[269,6],[305,6],[364,7],[494,6]]},"1097":{"position":[[9,6]]},"1099":{"position":[[588,6],[754,6],[825,6],[952,6],[1148,7],[1798,7],[1875,6]]},"1101":{"position":[[11,7],[325,6],[381,6],[505,6],[1021,7],[1241,6]]},"1105":{"position":[[198,6]]},"1107":{"position":[[319,6],[349,6],[574,6],[593,6],[962,6]]},"1109":{"position":[[129,6],[168,6],[206,6],[547,6],[584,6],[659,6],[702,6],[741,6],[1081,6]]},"1111":{"position":[[76,6],[1084,6],[1153,6],[1628,6]]},"1113":{"position":[[493,6]]},"1115":{"position":[[33,8],[61,6],[115,6],[163,6],[203,6],[244,6],[313,6],[348,6],[396,6],[420,6],[498,6],[545,6],[593,6],[730,6],[950,6],[1007,6],[1024,6]]},"1117":{"position":[[330,6],[375,6],[448,6]]},"1120":{"position":[[44,6],[121,6]]},"1124":{"position":[[6,6],[81,6],[131,6],[149,6],[355,6],[547,6],[627,6]]},"1126":{"position":[[407,6],[457,6],[495,6],[693,6],[770,6],[978,6],[1141,6],[1480,6],[1610,6],[1689,6],[1926,6],[2253,6],[2431,6],[2461,6],[2586,6],[2647,6]]},"1128":{"position":[[406,9],[635,6],[804,6],[818,6],[904,6],[920,6],[978,6],[1043,6],[1099,6],[1131,6],[1170,6],[1648,6],[1726,6],[1743,6],[1942,6]]},"1130":{"position":[[0,6],[95,6],[177,6],[461,6],[554,6],[670,6],[761,6],[775,6]]},"1132":{"position":[[749,6],[1104,6],[1625,6],[1747,6]]},"1134":{"position":[[227,6],[404,6],[510,6],[704,6]]},"1136":{"position":[[356,6],[416,6],[514,6],[589,6],[611,6],[636,6],[682,6]]},"1139":{"position":[[62,6],[104,6],[142,6],[223,6]]},"1141":{"position":[[49,6],[415,6],[504,6],[526,6],[568,6],[818,6]]},"1143":{"position":[[38,6],[113,6],[938,6]]},"1145":{"position":[[11,7],[156,6],[395,6],[445,6],[786,6],[813,6],[967,6],[1155,6],[1220,6],[1297,6],[1353,6],[1430,6],[1502,6],[1519,6],[1592,6],[1609,6],[1632,6],[2053,6],[2517,6]]},"1147":{"position":[[14,6],[67,6],[186,6],[478,6],[666,6],[1021,6]]},"1149":{"position":[[190,6],[281,6],[342,6],[464,6],[529,6],[588,6],[711,6],[742,6]]},"1151":{"position":[[7,6],[117,6],[216,6],[242,6],[365,6],[432,6],[1009,6],[1155,6],[1228,6],[1388,6],[1438,6],[1483,6],[1552,6],[1611,6],[1639,6],[1660,6],[1779,6],[1822,6],[1934,6]]},"1153":{"position":[[0,6],[216,6],[572,6]]},"1157":{"position":[[0,6],[49,7],[151,6],[180,6],[282,6],[326,6],[389,6],[426,6],[462,6],[508,6]]},"1159":{"position":[[375,6],[439,7],[581,7],[637,6],[676,7],[708,6],[735,6],[760,7],[801,7],[909,6],[1113,6],[1214,6],[1267,6],[1311,6],[1378,6],[1423,6],[1457,6],[1472,6],[1643,6],[1760,6],[1805,6],[1937,6],[1975,6]]},"1164":{"position":[[0,6],[100,6],[226,6],[425,6],[509,7]]},"1167":{"position":[[51,6],[166,6],[541,6],[1070,6],[1227,6]]},"1170":{"position":[[35,6],[138,6]]},"1172":{"position":[[190,6]]},"1176":{"position":[[93,6]]},"1178":{"position":[[31,6],[144,6],[215,7],[251,6],[359,6],[399,6],[529,6]]},"1185":{"position":[[22,6],[217,6],[645,6]]},"1187":{"position":[[202,6],[458,6]]},"1189":{"position":[[9,6],[33,6],[107,6],[158,6],[242,6]]},"1191":{"position":[[3,6],[28,6]]},"1195":{"position":[[9,6],[28,6],[147,6],[279,6],[337,6],[472,6]]},"1197":{"position":[[39,6],[101,6],[138,6],[348,6],[438,6]]},"1199":{"position":[[33,6],[70,6],[129,7],[156,6],[272,6],[332,6],[366,6]]},"1201":{"position":[[0,6],[19,6],[197,6],[232,6],[265,6]]},"1203":{"position":[[135,7],[160,6]]},"1205":{"position":[[9,6],[28,6],[85,6],[113,6],[132,6]]},"1208":{"position":[[2,6]]},"1212":{"position":[[9,6],[34,6],[89,6],[208,6],[280,6]]},"1214":{"position":[[58,6],[135,6]]},"1218":{"position":[[9,6],[77,6],[325,6],[373,6],[522,6]]},"1221":{"position":[[13,6],[28,6],[72,6],[167,6],[183,6],[404,6],[609,6],[640,6]]},"1225":{"position":[[0,6],[65,6],[184,6],[289,6],[339,6],[395,6],[459,6]]},"1227":{"position":[[250,6],[290,6],[410,6],[548,6],[597,6],[621,6],[698,6],[755,6],[843,6],[860,6],[935,6],[942,7],[1028,6],[1065,6],[1090,6],[1167,6],[1269,6],[1361,6],[1419,6]]},"1230":{"position":[[127,6],[160,6],[214,7],[337,6],[435,6],[466,6],[541,6],[607,6],[674,6],[712,6],[734,6],[779,6],[875,6]]},"1232":{"position":[[342,6]]},"1234":{"position":[[253,6]]},"1236":{"position":[[322,6],[396,6],[635,6]]},"1238":{"position":[[374,6],[432,6],[453,8],[683,6],[1181,6],[1238,6]]},"1240":{"position":[[73,6],[116,6],[209,7],[331,6]]},"1242":{"position":[[0,6],[184,6],[280,6],[523,6],[576,6],[758,6]]},"1244":{"position":[[37,6],[132,6],[175,6],[217,6],[266,6],[330,6],[437,7],[550,6],[582,6],[1907,6],[1937,7]]},"1246":{"position":[[41,6],[100,7],[118,6],[298,6],[589,6],[605,6],[644,6]]},"1248":{"position":[[23,6],[51,6]]},"1255":{"position":[[0,6],[112,6]]},"1257":{"position":[[119,6],[147,6],[224,6],[256,7],[282,7]]},"1259":{"position":[[134,6],[247,6]]},"1266":{"position":[[16,6],[113,6]]},"1270":{"position":[[15,6],[68,6],[192,6],[248,6]]},"1273":{"position":[[64,6],[83,6],[121,6],[188,6],[202,6],[256,6],[377,6],[453,6],[484,6],[538,6],[584,6]]},"1275":{"position":[[0,6],[197,6],[247,6]]},"1277":{"position":[[27,6],[65,6]]},"1279":{"position":[[31,6]]},"1285":{"position":[[10,6],[82,6],[157,6],[174,6],[190,6]]},"1289":{"position":[[359,9]]},"1291":{"position":[[706,9],[928,9]]},"1303":{"position":[[0,9],[918,6]]},"1328":{"position":[[252,6],[291,6],[401,9]]},"1345":{"position":[[0,6],[97,7],[164,6],[223,7],[251,7],[301,8],[357,7],[434,7]]},"1347":{"position":[[0,6],[95,7],[229,6],[307,7],[398,7],[450,6],[532,6],[607,6],[681,6],[852,7],[889,7],[940,8],[988,7],[1007,6],[1039,6],[1062,6],[1138,7],[1352,6],[1436,7],[1510,6],[1576,6],[1691,6],[1776,6],[1814,8],[1832,6],[1928,7],[1980,7],[2028,7]]},"1350":{"position":[[446,6],[503,6],[602,6],[862,6]]},"1352":{"position":[[29,6],[44,6],[133,6],[309,6],[361,6],[659,6],[747,6],[960,6],[992,6],[1008,6],[1315,6],[1334,6],[1376,6]]},"1354":{"position":[[126,6],[168,6]]},"1357":{"position":[[315,6],[381,6],[451,6],[569,6]]},"1360":{"position":[[179,6],[223,6],[236,6]]},"1362":{"position":[[5,6],[60,6],[103,6],[226,6],[268,6],[342,6],[433,6],[463,6],[499,6]]},"1364":{"position":[[109,6],[189,6],[280,6],[293,6],[556,6]]},"1367":{"position":[[164,6],[247,7],[328,6],[427,7],[542,6],[563,6],[652,6],[690,6],[744,6]]},"1369":{"position":[[711,6]]},"1371":{"position":[[11,6],[52,6],[121,6],[165,6],[218,6]]},"1373":{"position":[[10,6],[67,6],[136,6],[150,6],[199,6],[291,6],[331,6]]},"1384":{"position":[[2447,6]]},"1395":{"position":[[1615,6]]},"1407":{"position":[[112,6],[176,7],[209,6],[235,6],[303,6],[332,6],[361,6],[553,6],[600,7]]},"1409":{"position":[[168,6],[277,7],[349,6],[400,7],[479,6],[590,6],[686,6],[736,6],[765,6],[811,6],[994,7],[1099,6],[1206,6],[1248,7],[1375,7],[1556,6],[1624,6],[1740,6],[1804,7]]},"1411":{"position":[[17,6],[85,6],[130,6],[191,6],[244,6],[262,6],[329,6],[425,6]]},"1415":{"position":[[23,6],[69,6],[107,6],[168,6]]},"1419":{"position":[[25,6],[201,6],[332,6],[424,6]]},"1421":{"position":[[59,6],[144,6],[250,6],[533,6],[550,6]]},"1423":{"position":[[57,6],[109,6],[127,6],[200,6],[316,6],[447,6],[546,6],[1005,6],[1115,6]]},"1425":{"position":[[0,6],[18,6],[377,6]]},"1427":{"position":[[356,6],[412,6],[451,6],[510,6],[620,6],[677,6],[896,6]]},"1429":{"position":[[16,6],[32,6],[68,7],[173,7],[280,6],[529,6],[797,6],[882,6],[1839,7]]},"1431":{"position":[[143,6],[170,6],[214,6],[234,6],[260,6],[382,7],[440,7],[553,6],[607,6],[628,6],[676,6],[765,7],[858,6],[895,6],[1169,7],[1337,6],[1364,6],[1396,6],[1497,6],[1560,6],[2128,6],[2391,6],[2554,6],[2676,6],[2810,6],[2942,6]]},"1434":{"position":[[18,6],[101,6],[180,6],[296,7]]},"1436":{"position":[[7,6],[44,6],[133,6],[174,6]]},"1447":{"position":[[47,8]]},"1466":{"position":[[0,6],[84,7],[114,6],[227,6],[362,6],[516,6],[560,6]]},"1468":{"position":[[170,6],[221,6],[242,6],[312,6],[532,6],[585,6],[663,6],[882,6],[906,6],[944,6],[989,6],[1265,7],[1320,6],[1373,6],[1521,6],[1658,6]]},"1473":{"position":[[27,6],[60,6],[251,6],[294,6],[384,6],[438,6],[464,6],[535,7]]},"1477":{"position":[[25,6],[104,6],[147,6],[394,6],[530,6],[552,7],[664,6],[896,6],[1026,6],[1077,6],[1245,7]]},"1479":{"position":[[52,6]]},"1481":{"position":[[13,6],[54,6],[70,6],[119,6],[171,6],[250,7]]},"1483":{"position":[[42,6],[71,6],[111,6],[182,6],[220,6],[299,6],[336,6]]},"1485":{"position":[[8,6],[33,6],[62,6],[340,6],[379,6],[514,6],[836,6],[980,6],[1013,6],[1070,6],[1133,6],[1151,6]]},"1487":{"position":[[27,6],[54,6],[94,6],[202,6],[265,6],[486,6],[519,6],[749,6],[810,6],[1167,6]]},"1489":{"position":[[36,8],[69,7],[211,6],[271,6],[292,6],[328,6],[382,6],[435,6]]},"1492":{"position":[[170,6]]},"1494":{"position":[[152,6],[198,6],[375,6],[402,9],[436,6]]},"1496":{"position":[[4,6],[550,6]]},"1499":{"position":[[30,6],[153,6],[218,6],[352,6],[756,6]]},"1501":{"position":[[139,6],[220,6],[323,6],[414,6]]},"1505":{"position":[[57,7],[80,6],[146,6],[381,6],[478,6],[510,6],[545,7],[555,6],[598,6],[633,6],[662,6],[681,8],[755,6],[790,6],[825,6],[888,6],[1007,6],[1023,6],[1040,6],[1099,6],[1125,6],[1147,6],[1156,6]]},"1507":{"position":[[10,6],[86,6],[234,6],[296,6]]},"1509":{"position":[[174,6],[259,7],[273,6]]},"1511":{"position":[[0,6],[49,6],[105,6],[206,6],[232,6]]},"1513":{"position":[[5,6],[60,6],[144,6],[162,7],[186,6],[199,6],[548,6],[566,6]]},"1515":{"position":[[40,6],[202,6],[220,6]]},"1517":{"position":[[18,6],[322,6]]},"1521":{"position":[[16,6],[32,6],[87,6],[133,6],[202,6]]},"1523":{"position":[[96,6],[111,6],[134,6],[208,6],[231,6],[263,6],[317,6]]},"1525":{"position":[[139,6]]},"1536":{"position":[[53,6],[90,6],[119,6],[198,6],[402,6]]},"1544":{"position":[[111,6],[137,6]]},"1552":{"position":[[35,6],[87,6],[144,6],[185,6],[367,6]]},"1554":{"position":[[74,6],[92,6]]},"1558":{"position":[[511,6],[921,6]]},"1573":{"position":[[167,6]]},"1575":{"position":[[37,6]]},"1579":{"position":[[147,6]]},"1644":{"position":[[78,6],[103,6],[223,6],[246,7],[323,7],[453,7],[488,7],[511,6],[565,6],[599,7],[781,6],[821,6]]},"1646":{"position":[[680,6],[711,6],[1240,6],[1701,7],[1745,7],[1812,6],[1834,6],[1862,7],[1952,6],[2124,6],[2159,7],[2178,6],[2391,7],[2406,7],[2564,6],[2690,6],[2775,7],[2862,7],[2874,7],[2972,7],[3010,7],[3222,6]]},"1649":{"position":[[42,7],[123,7],[192,7]]},"1651":{"position":[[860,6],[1644,7]]},"1653":{"position":[[684,7],[834,7],[1019,6]]},"1655":{"position":[[41,6],[66,6],[87,6],[752,6],[1171,6],[1652,6],[2283,7]]},"1657":{"position":[[387,7],[424,7],[457,7],[567,7],[619,7],[638,6],[1078,7]]},"1665":{"position":[[558,6],[755,6],[1037,6],[1135,7]]},"1669":{"position":[[16,7],[82,7],[243,6],[413,6]]},"1674":{"position":[[70,6],[204,7]]},"1676":{"position":[[301,6],[588,6]]},"1682":{"position":[[838,6]]},"1684":{"position":[[143,6],[163,6],[273,6],[425,6],[600,6],[835,6]]},"1686":{"position":[[4,6],[134,6],[238,6],[412,6]]},"1689":{"position":[[52,6],[103,7],[127,7],[166,6],[198,7],[430,6]]},"1693":{"position":[[17,6],[130,6],[223,6],[385,9],[459,9],[495,6]]},"1695":{"position":[[804,7],[842,7],[944,6],[988,6],[1107,6],[1173,6],[1224,6],[1236,6]]},"1700":{"position":[[50,6],[94,9]]},"1702":{"position":[[49,6],[63,9],[586,6],[637,6],[660,6]]},"1704":{"position":[[209,6],[299,6],[318,6],[334,6],[361,6],[434,6]]},"1708":{"position":[[14,9],[119,6],[164,6],[267,6],[450,6],[483,7]]},"1710":{"position":[[0,6],[61,9],[192,6]]},"1712":{"position":[[9,6],[25,6],[119,6],[182,6],[242,6],[258,6],[324,6]]},"1714":{"position":[[9,6],[270,6]]},"1716":{"position":[[64,6],[130,6],[147,6],[225,6],[256,6],[286,6]]},"1718":{"position":[[9,6],[32,6],[234,6],[259,6],[274,6],[317,6],[383,6],[575,6],[647,6],[676,6],[815,6],[1014,6],[1166,6],[1200,6]]},"1720":{"position":[[11,6],[80,9],[1045,6],[1450,6],[1466,6],[1485,6],[1505,6],[1578,6],[1815,6],[1847,6],[1919,6],[1954,6],[1982,6],[2051,6],[2097,6],[2123,6],[2208,6]]},"1724":{"position":[[153,6],[197,6]]},"1732":{"position":[[99,6]]},"1734":{"position":[[6,6],[31,6]]},"1736":{"position":[[0,6],[40,6],[67,6],[85,6],[106,6],[129,6],[145,6],[196,6],[297,6],[484,6],[513,6],[676,6],[743,6],[787,6],[856,6],[944,6],[1011,6],[1243,6],[1302,6],[1563,6]]},"1738":{"position":[[0,6],[119,6],[200,6],[552,6],[629,6],[670,6],[716,9],[740,6],[759,6],[784,6],[871,6],[906,6]]},"1740":{"position":[[0,6],[80,6],[224,6],[258,6]]},"1742":{"position":[[49,6],[74,6],[106,6],[122,7],[143,7],[262,6],[308,6],[349,6]]},"1744":{"position":[[0,6]]},"1746":{"position":[[79,6],[344,6]]},"1748":{"position":[[0,6],[69,7],[176,6],[207,6]]},"1750":{"position":[[95,6],[338,6]]},"1752":{"position":[[12,9],[24,6],[95,6],[163,9],[175,6],[221,9],[422,6]]},"1754":{"position":[[9,6],[25,6],[96,6],[170,6],[214,9],[282,9],[388,7],[403,6]]},"1756":{"position":[[6,6],[80,6],[253,6],[286,6],[382,6],[523,6]]},"1758":{"position":[[49,6],[153,6]]},"1762":{"position":[[18,9],[160,6],[379,6]]},"1764":{"position":[[224,6]]},"1766":{"position":[[69,9],[85,6],[136,6],[153,6],[241,6],[251,6],[294,6],[349,6],[392,6],[543,6]]},"1768":{"position":[[0,6],[131,6],[182,9],[255,6],[401,6],[498,6],[602,6]]},"1772":{"position":[[301,9]]},"1774":{"position":[[47,9],[68,6],[151,6],[249,6],[283,6],[343,6],[418,6],[559,6]]},"1776":{"position":[[22,6],[149,6]]},"1778":{"position":[[0,9]]},"1780":{"position":[[12,6],[57,9],[76,6],[255,7]]},"1782":{"position":[[0,6],[186,6],[261,6],[547,6],[780,6],[1012,6],[1234,6],[1346,6],[1496,9],[1974,6],[2181,6],[2219,6],[2248,6],[2306,6],[2445,6],[2504,6],[2549,6],[2642,6],[2916,6],[3191,6],[3287,6]]},"1784":{"position":[[0,6]]},"1786":{"position":[[14,6],[92,6]]},"1788":{"position":[[45,6],[177,6],[238,6],[301,9],[525,6],[621,6]]},"1790":{"position":[[388,6]]},"1792":{"position":[[0,7]]},"1794":{"position":[[0,6],[20,6],[42,6],[260,6],[385,6],[431,6],[544,6],[620,7],[654,6],[680,6],[827,6],[886,6],[916,6],[939,6],[981,6],[1071,6],[1092,6]]},"1796":{"position":[[15,6],[68,6],[370,6]]},"1798":{"position":[[0,6],[26,6],[91,7],[131,6],[206,6]]},"1800":{"position":[[0,9],[155,6]]},"1802":{"position":[[229,6],[364,6],[457,6],[626,6],[1218,6]]}}}],["prompt+lm",{"_index":5541,"t":{"1758":{"position":[[0,9]]},"1774":{"position":[[519,9]]},"1782":{"position":[[2190,9]]}}}],["promptda",{"_index":962,"t":{"213":{"position":[[107,10],[278,8],[436,8],[465,8]]},"215":{"position":[[1304,10]]}}}],["promptl",{"_index":4863,"t":{"1505":{"position":[[919,7]]}}}],["promptless",{"_index":5533,"t":{"1750":{"position":[[0,10]]}}}],["promt",{"_index":5471,"t":{"1722":{"position":[[0,5]]}}}],["promtpt",{"_index":4928,"t":{"1554":{"position":[[34,7]]}}}],["propag",{"_index":997,"t":{"215":{"position":[[1087,9]]},"358":{"position":[[1316,9]]},"531":{"position":[[1206,11]]},"1303":{"position":[[826,10]]}}}],["proper",{"_index":1385,"t":{"334":{"position":[[96,6]]},"336":{"position":[[277,6]]},"341":{"position":[[79,6]]},"356":{"position":[[82,6]]},"1708":{"position":[[157,6]]}}}],["properti",{"_index":1819,"t":{"525":{"position":[[294,11]]}}}],["proport",{"_index":4214,"t":{"1259":{"position":[[30,12]]},"1419":{"position":[[955,12]]},"1431":{"position":[[1234,12]]}}}],["propos",{"_index":747,"t":{"165":{"position":[[1695,9],[1740,9],[2235,9],[2280,9]]},"174":{"position":[[1509,9],[1531,9],[1620,9],[2554,8]]},"870":{"position":[[100,8]]},"953":{"position":[[655,8]]}}}],["prototyp",{"_index":3954,"t":{"1145":{"position":[[1639,9]]}}}],["prt",{"_index":5167,"t":{"1646":{"position":[[2944,3]]},"1651":{"position":[[776,3]]}}}],["prune",{"_index":1833,"t":{"525":{"position":[[1153,7],[1438,7],[1555,7]]},"529":{"position":[[288,7],[337,7],[401,7],[550,7],[610,7]]},"531":{"position":[[568,6]]},"630":{"position":[[776,7],[877,7],[1136,7]]},"648":{"position":[[778,6]]},"703":{"position":[[254,7]]},"709":{"position":[[2422,7],[2538,7]]},"786":{"position":[[964,7],[1032,7],[1148,7],[1260,7],[2280,7]]},"795":{"position":[[1501,7],[1539,5],[1613,7],[1632,6]]},"797":{"position":[[1671,7]]},"801":{"position":[[194,7]]},"807":{"position":[[503,6]]},"835":{"position":[[41,7],[245,7],[304,7]]},"847":{"position":[[67,7],[240,7],[288,7],[365,7],[416,7],[501,7],[601,7]]},"849":{"position":[[211,7],[285,7],[410,7],[499,7],[607,7],[740,7],[883,7],[1102,7],[1130,7],[1172,7],[1187,7],[1213,7],[1596,7]]},"851":{"position":[[52,7],[327,7],[414,7],[456,7],[518,7],[542,7],[757,7],[866,7]]},"853":{"position":[[216,7],[380,7],[408,7],[1214,7],[1716,7],[1741,7],[1840,7],[2144,7],[2176,7],[2214,7],[2368,7],[2467,7],[2506,7]]},"855":{"position":[[23,7],[46,7],[72,7]]},"857":{"position":[[44,7],[704,7],[795,7]]},"861":{"position":[[8,7]]},"866":{"position":[[3,7],[61,7],[1030,7]]},"868":{"position":[[14,7],[95,7]]},"870":{"position":[[36,7],[193,7],[224,7],[435,7],[689,7],[1226,7],[1481,7],[1580,7],[1619,7],[1785,7],[1896,7]]},"873":{"position":[[80,7]]},"875":{"position":[[174,7]]},"879":{"position":[[20,7],[62,7],[121,7],[202,7],[256,7]]},"881":{"position":[[13,7],[48,7],[103,7],[197,7]]},"1230":{"position":[[75,7]]},"1347":{"position":[[459,7]]},"1384":{"position":[[3062,7]]},"1466":{"position":[[468,7]]},"1468":{"position":[[1101,7],[1226,7]]},"1477":{"position":[[1217,7]]},"1479":{"position":[[90,7]]},"1481":{"position":[[284,7]]},"1483":{"position":[[24,7],[163,7],[282,7],[365,7]]},"1485":{"position":[[1186,7]]},"1487":{"position":[[12,7],[238,7],[1224,7]]},"1489":{"position":[[107,7],[196,7],[364,7]]},"1496":{"position":[[340,7],[538,6]]},"1505":{"position":[[24,7],[193,7],[297,6],[406,7],[1212,7]]},"1507":{"position":[[221,7]]},"1509":{"position":[[12,7],[47,7],[72,7],[130,7],[156,7],[222,7],[316,7],[366,7]]},"1513":{"position":[[664,7]]},"1515":{"position":[[134,7]]},"1517":{"position":[[63,8],[75,6]]},"1525":{"position":[[62,6]]},"1730":{"position":[[507,5],[562,6],[1019,6],[1137,7]]}}}],["prunin",{"_index":2281,"t":{"630":{"position":[[1865,9]]}}}],["pr⁡(y∣x)\\pr",{"_index":3878,"t":{"1128":{"position":[[132,11]]}}}],["pr⁡θ(y∣[p;x])\\pr_\\theta",{"_index":3883,"t":{"1128":{"position":[[548,23]]}}}],["pr⁡θ(y∣x)\\pr_\\theta",{"_index":3881,"t":{"1128":{"position":[[255,19]]}}}],["pr⁡θ;θp(y∣[p;x])\\pr_{\\theta;\\theta_p}(y|[p;x])prθ;θp​​(y∣[p;x",{"_index":3890,"t":{"1128":{"position":[[1271,63]]}}}],["ps\\text{p}_sp",{"_index":3243,"t":{"861":{"position":[[1932,15]]}}}],["pseudo",{"_index":977,"t":{"215":{"position":[[320,6]]},"336":{"position":[[983,6],[1008,6],[1360,6],[1404,6],[1440,6],[1584,6],[1791,6]]},"343":{"position":[[83,6],[119,6],[429,6]]},"345":{"position":[[151,6]]},"347":{"position":[[32,6],[173,6],[219,6],[469,6]]},"352":{"position":[[77,6],[399,6],[536,6],[654,6]]},"354":{"position":[[194,6],[227,6],[477,6],[586,6]]},"358":{"position":[[30,6],[656,6],[1220,6]]},"366":{"position":[[118,6],[296,6]]},"368":{"position":[[76,6],[171,6]]},"376":{"position":[[231,6]]},"1099":{"position":[[1449,6]]}}}],["pseudocod",{"_index":4870,"t":{"1529":{"position":[[94,10]]}}}],["psp_sp",{"_index":3699,"t":{"1067":{"position":[[1363,8]]}}}],["psrp^{s_r}psr",{"_index":4669,"t":{"1431":{"position":[[1097,14]]}}}],["ps∈rm×d;p_",{"_index":3676,"t":{"1067":{"position":[[172,11]]}}}],["pt",{"_index":3581,"t":{"999":{"position":[[40,2]]},"1002":{"position":[[159,3]]},"1006":{"position":[[123,2]]},"1014":{"position":[[713,4],[874,2],[981,2]]},"1024":{"position":[[61,2],[130,2]]},"1026":{"position":[[89,2]]},"1047":{"position":[[333,2]]},"1052":{"position":[[3,2]]},"1060":{"position":[[97,4],[180,2],[968,2]]},"1062":{"position":[[234,2],[313,2],[425,2],[1423,2],[1599,2]]},"1065":{"position":[[297,2]]},"1067":{"position":[[1287,2]]},"1070":{"position":[[482,2],[939,2]]},"1073":{"position":[[122,2],[179,2]]},"1075":{"position":[[40,2],[93,2],[129,2]]},"1080":{"position":[[345,2]]},"1082":{"position":[[169,2],[260,2]]},"1084":{"position":[[27,2],[522,2],[525,5],[673,3],[697,2],[748,2]]},"1087":{"position":[[27,2]]},"1189":{"position":[[172,4],[177,2],[208,2]]},"1227":{"position":[[264,4],[376,2],[1337,2]]},"1238":{"position":[[657,2],[1081,2]]},"1257":{"position":[[133,4]]},"1262":{"position":[[134,2]]},"1264":{"position":[[128,2],[227,2]]},"1266":{"position":[[189,2]]},"1268":{"position":[[112,2]]}}}],["pt+1",{"_index":3500,"t":{"986":{"position":[[81,6]]}}}],["pt+1)p_{target",{"_index":3498,"t":{"986":{"position":[[43,18]]}}}],["pt\\text{p}_tpt",{"_index":3244,"t":{"861":{"position":[[1950,15]]}}}],["ptarget",{"_index":3497,"t":{"986":{"position":[[33,9]]}}}],["ptarget(=pt+1)p_{target",{"_index":3552,"t":{"990":{"position":[[478,24]]}}}],["ptargetp_{target}ptarget",{"_index":3473,"t":{"982":{"position":[[411,25],[888,25]]},"986":{"position":[[590,25]]},"990":{"position":[[302,25],[681,25]]}}}],["ptb",{"_index":1926,"t":{"529":{"position":[[2346,3]]}}}],["ptint",{"_index":5387,"t":{"1682":{"position":[[924,7]]},"1684":{"position":[[71,5],[724,5],[747,5]]}}}],["ptr",{"_index":5152,"t":{"1644":{"position":[[543,8],[593,3],[765,3]]},"1646":{"position":[[1966,5],[2199,3],[3054,3],[3194,3]]},"1649":{"position":[[138,3]]},"1651":{"position":[[0,3]]},"1657":{"position":[[2592,3]]},"1665":{"position":[[39,3],[1095,3],[1151,3]]},"1667":{"position":[[0,3],[905,3],[1161,3]]},"1669":{"position":[[98,3],[140,3],[187,3],[800,3],[954,3],[1038,3]]},"1674":{"position":[[176,3],[233,3]]},"1676":{"position":[[19,3],[76,3],[216,3],[470,3]]},"1682":{"position":[[313,3],[829,3],[894,3]]},"1684":{"position":[[23,3],[79,3],[124,3],[740,3]]},"1686":{"position":[[105,3],[159,3],[208,3],[232,3],[383,3]]},"1689":{"position":[[77,5],[332,3]]},"1720":{"position":[[2233,5],[2391,3]]}}}],["ptx",{"_index":3721,"t":{"1082":{"position":[[7,3]]},"1558":{"position":[[1336,3],[2011,3],[2059,3]]},"1570":{"position":[[324,4]]}}}],["public",{"_index":2073,"t":{"594":{"position":[[420,6],[1384,6]]},"618":{"position":[[178,6]]},"666":{"position":[[0,6]]},"999":{"position":[[652,6]]},"1134":{"position":[[77,6]]}}}],["publicli",{"_index":3009,"t":{"807":{"position":[[29,8]]}}}],["publish",{"_index":3705,"t":{"1070":{"position":[[719,9]]}}}],["punct",{"_index":5354,"t":{"1669":{"position":[[846,7],[883,7],[1069,7]]}}}],["purpos",{"_index":3983,"t":{"1153":{"position":[[258,7]]}}}],["pv",{"_index":235,"t":{"38":{"position":[[440,2]]}}}],["pv=hvp∗p_v",{"_index":2499,"t":{"690":{"position":[[301,10]]}}}],["pvkvp^{kv}_vpvkv",{"_index":2526,"t":{"696":{"position":[[753,17]]}}}],["pvp_vpv",{"_index":2495,"t":{"688":{"position":[[1028,8]]},"692":{"position":[[302,8]]},"1389":{"position":[[1776,9]]}}}],["pv∈rdhidden×lp_v",{"_index":4473,"t":{"1384":{"position":[[1650,16]]}}}],["pyramid",{"_index":775,"t":{"170":{"position":[[1157,7]]}}}],["python",{"_index":1774,"t":{"515":{"position":[[83,8]]}}}],["pytorch",{"_index":3008,"t":{"807":{"position":[[4,7]]}}}],["pˉi=∑m=1mpim/m\\bar{p}_i",{"_index":1461,"t":{"354":{"position":[[362,23]]}}}],["pˉi\\bar{p}_ipˉ​i",{"_index":1464,"t":{"354":{"position":[[437,17],[500,17]]}}}],["pθ(i",{"_index":3490,"t":{"984":{"position":[[572,4]]},"986":{"position":[[394,4]]}}}],["pθ1,pθ2,…,pθkp_{\\theta_1",{"_index":4384,"t":{"1352":{"position":[[379,26]]}}}],["pθ[i:0]=mlpθ(pθ′[i,:])p_\\theta",{"_index":4311,"t":{"1307":{"position":[[192,30]]}}}],["pθp_\\thetap",{"_index":4302,"t":{"1305":{"position":[[1082,13],[1168,13],[1354,13]]},"1307":{"position":[[0,13],[391,13],[520,15]]},"1350":{"position":[[512,13]]}}}],["pθp_θp",{"_index":3996,"t":{"1162":{"position":[[152,8]]}}}],["pθ​(i",{"_index":3495,"t":{"984":{"position":[[668,5]]},"986":{"position":[[540,5]]}}}],["pθ′p'_\\thetap",{"_index":4309,"t":{"1307":{"position":[[82,18],[325,16]]}}}],["pθ′p_\\theta'p",{"_index":4316,"t":{"1307":{"position":[[407,16]]}}}],["pλq\\triangl",{"_index":2779,"t":{"786":{"position":[[3980,14]]}}}],["pϕ(i",{"_index":4237,"t":{"1296":{"position":[[76,4]]},"1298":{"position":[[0,4]]}}}],["pϕ(y∣x)p\\phi(y|x)pϕ(y∣x",{"_index":2586,"t":{"723":{"position":[[103,24]]}}}],["pϕ(y∣x)p_\\phi",{"_index":4364,"t":{"1350":{"position":[[45,13]]}}}],["pϕ(zi+1",{"_index":4257,"t":{"1296":{"position":[[823,7]]}}}],["pϕp_\\phip",{"_index":4368,"t":{"1350":{"position":[[260,11]]}}}],["pϕp_{\\phi}p",{"_index":4270,"t":{"1300":{"position":[[58,13]]}}}],["p′=[p1′,…,pn′]=[φ(p1),…,φ(pn)],\\begin{equ",{"_index":4010,"t":{"1167":{"position":[[243,47]]}}}],["p′=wup⊤ϕ(wdown⊤p),\\begin{equ",{"_index":4475,"t":{"1384":{"position":[[1826,34]]}}}],["p′=φ(p)p",{"_index":4042,"t":{"1178":{"position":[[436,9]]}}}],["p′p'p",{"_index":4009,"t":{"1167":{"position":[[226,6],[1234,6]]},"1178":{"position":[[547,6],[587,6]]},"1185":{"position":[[187,6]]},"1187":{"position":[[219,6]]}}}],["p∈rd1×rp",{"_index":2837,"t":{"795":{"position":[[217,8]]}}}],["p∈rd×mp",{"_index":2460,"t":{"686":{"position":[[109,7]]}}}],["p∈rl×dp",{"_index":3663,"t":{"1065":{"position":[[326,7]]},"1067":{"position":[[76,7]]},"1238":{"position":[[697,7]]}}}],["p∗p^*p",{"_index":2496,"t":{"690":{"position":[[213,7]]},"1242":{"position":[[530,7],[848,7]]},"1244":{"position":[[82,7],[447,7],[596,7]]},"1246":{"position":[[766,8],[830,8],[1071,7]]}}}],["p∗∈rl×dp",{"_index":4132,"t":{"1242":{"position":[[225,10]]}}}],["q",{"_index":2479,"t":{"688":{"position":[[536,2],[693,1]]},"795":{"position":[[179,2]]},"1384":{"position":[[3649,1]]}}}],["q&a",{"_index":3965,"t":{"1147":{"position":[[792,3]]}}}],["q)sim(v,q",{"_index":1668,"t":{"457":{"position":[[644,10],[873,10]]}}}],["q,k,v,o,u,d}\\{q,k,v,o,u,d\\}{q,k,v,o,u,d",{"_index":3200,"t":{"857":{"position":[[1408,41]]}}}],["q:/\"\"a",{"_index":1992,"t":{"548":{"position":[[149,8]]}}}],["q=(wq⊤+αwup⊤wdown⊤)hin\\begin{equ",{"_index":4500,"t":{"1384":{"position":[[3610,38]]}}}],["q=hqx,knew=hkxnew,vnew=hvxnewq",{"_index":2473,"t":{"688":{"position":[[421,30]]}}}],["q={qk}k=1n\\mathcal{q",{"_index":2887,"t":{"797":{"position":[[685,21]]}}}],["q^e=ζ⋅qe\\hat{q}_",{"_index":4818,"t":{"1487":{"position":[[574,17]]}}}],["q^j,a^j}j=1u",{"_index":1651,"t":{"455":{"position":[[688,15]]}}}],["q^{m",{"_index":1841,"t":{"527":{"position":[[716,5],[1281,5]]}}}],["q_eq^​e​=ζ⋅q",{"_index":4820,"t":{"1487":{"position":[[606,14]]}}}],["q_k",{"_index":2888,"t":{"797":{"position":[[712,3]]}}}],["q_k)l(p,e,q)=c(p,e,q)+γ∑k=1n​r(pk​,qk",{"_index":2899,"t":{"797":{"position":[[1032,39]]}}}],["q_k△k​=pk​λk​qk",{"_index":2872,"t":{"797":{"position":[[288,16]]}}}],["q_l",{"_index":3320,"t":{"893":{"position":[[554,3],[895,3]]}}}],["q_{1_e",{"_index":4814,"t":{"1487":{"position":[[359,8]]}}}],["q_{2_e",{"_index":4815,"t":{"1487":{"position":[[368,8]]}}}],["q_{i",{"_index":2853,"t":{"795":{"position":[[658,6]]}}}],["q_{k,i",{"_index":2879,"t":{"797":{"position":[[441,8]]}}}],["q_{k_e}\\}qe​={q1e​​,q2e​​,…,qk",{"_index":4816,"t":{"1487":{"position":[[384,34]]}}}],["qa",{"_index":1611,"t":{"436":{"position":[[1165,2],[1467,2],[1491,2],[1541,2],[1585,2],[1902,2],[2087,2]]},"445":{"position":[[437,2]]},"447":{"position":[[221,2],[438,2],[736,2],[767,2]]},"455":{"position":[[66,2],[294,2],[573,2],[821,2],[911,2],[940,2],[995,2]]},"457":{"position":[[13,2]]},"459":{"position":[[67,2],[282,2]]},"553":{"position":[[214,2]]},"622":{"position":[[635,2]]},"786":{"position":[[4439,2]]},"805":{"position":[[90,2]]},"819":{"position":[[14,2]]},"843":{"position":[[365,2]]},"901":{"position":[[21,2]]},"924":{"position":[[104,2]]},"934":{"position":[[888,2]]},"997":{"position":[[651,2]]},"999":{"position":[[1205,2],[1239,2]]},"1006":{"position":[[1852,2],[1915,2]]},"1008":{"position":[[576,2]]},"1049":{"position":[[63,2],[82,2],[305,2]]},"1147":{"position":[[255,2],[315,2],[348,2]]},"1283":{"position":[[108,3]]},"1419":{"position":[[544,2],[761,5]]},"1429":{"position":[[1407,2]]},"1772":{"position":[[19,4],[84,2],[110,2],[179,2],[218,2],[420,2],[502,2],[531,2]]},"1782":{"position":[[988,2],[1214,2],[1370,2],[1537,2]]},"1802":{"position":[[148,2]]}}}],["qe={q1e,q2e,…,qke}q_",{"_index":4813,"t":{"1487":{"position":[[332,21]]}}}],["qin",{"_index":3092,"t":{"851":{"position":[[208,3],[260,3]]},"1347":{"position":[[339,3]]}}}],["qk(t)q_k^{(t)}qk(t",{"_index":2905,"t":{"797":{"position":[[1224,20]]}}}],["qk,i∗q_{k,i*}qk,i",{"_index":2964,"t":{"801":{"position":[[743,19]]}}}],["ql=linearq",{"_index":3315,"t":{"893":{"position":[[471,11]]}}}],["qlq_lql",{"_index":3330,"t":{"893":{"position":[[807,8]]}}}],["qm,ℓ(x)=wqm,ℓx+bm,ℓqkm,ℓ(x)=wqm,ℓx+bm,ℓqvm,ℓ(x)=wqm,ℓx+bm,ℓq\\begin{align",{"_index":1840,"t":{"527":{"position":[[641,74]]}}}],["qnli",{"_index":3254,"t":{"866":{"position":[[944,4]]},"997":{"position":[[285,5],[476,4],[547,6]]},"1070":{"position":[[106,4]]},"1253":{"position":[[70,4],[218,4]]},"1393":{"position":[[115,5]]},"1429":{"position":[[1675,4]]}}}],["qq^\\top",{"_index":2860,"t":{"795":{"position":[[1013,7]]}}}],["qqa",{"_index":3246,"t":{"864":{"position":[[28,4]]}}}],["qqp",{"_index":3251,"t":{"866":{"position":[[443,3],[932,4]]},"870":{"position":[[668,3]]},"997":{"position":[[291,4],[471,4],[534,4]]},"1006":{"position":[[2386,3],[2423,3]]},"1070":{"position":[[102,3],[1760,4]]},"1147":{"position":[[780,3],[885,4],[994,3]]},"1253":{"position":[[75,3],[213,4]]},"1395":{"position":[[1545,4],[1865,3],[2593,3]]},"1397":{"position":[[622,3]]},"1429":{"position":[[1578,4]]}}}],["qqq",{"_index":1192,"t":{"298":{"position":[[279,3]]},"447":{"position":[[669,3],[816,3]]},"457":{"position":[[603,3]]},"786":{"position":[[4116,3],[4176,3]]},"795":{"position":[[784,3],[861,3]]},"1384":{"position":[[1590,4]]}}}],["qquad",{"_index":877,"t":{"177":{"position":[[401,6],[919,6],[1563,6]]}}}],["quad",{"_index":2517,"t":{"694":{"position":[[661,5]]},"789":{"position":[[379,5]]}}}],["quadrat",{"_index":3646,"t":{"1060":{"position":[[365,9],[516,9]]},"1062":{"position":[[795,9]]},"1067":{"position":[[1241,9]]}}}],["qualiti",{"_index":969,"t":{"213":{"position":[[323,7]]},"215":{"position":[[56,7]]},"260":{"position":[[115,7]]},"934":{"position":[[2259,7]]},"945":{"position":[[816,7]]},"951":{"position":[[47,7],[381,7]]},"963":{"position":[[19,7],[516,7]]},"1109":{"position":[[1167,7]]},"1126":{"position":[[855,7],[883,7],[1719,7],[2545,7]]},"1143":{"position":[[52,7]]},"1153":{"position":[[414,7]]},"1317":{"position":[[489,7]]},"1425":{"position":[[633,7]]}}}],["quantif",{"_index":2977,"t":{"801":{"position":[[1568,14]]}}}],["quantifi",{"_index":2944,"t":{"799":{"position":[[18,8],[315,8]]},"801":{"position":[[74,8],[144,8],[325,8],[2293,8]]}}}],["quantit",{"_index":3400,"t":{"905":{"position":[[454,12]]},"907":{"position":[[88,12]]}}}],["quantiz",{"_index":602,"t":{"130":{"position":[[547,10]]},"143":{"position":[[601,12]]},"149":{"position":[[318,9]]},"851":{"position":[[227,12]]}}}],["queri",{"_index":727,"t":{"163":{"position":[[179,5]]},"165":{"position":[[1210,7],[2109,5]]},"174":{"position":[[174,5],[667,7],[708,7],[771,5],[822,7],[879,7],[1127,7]]},"182":{"position":[[253,7]]},"205":{"position":[[12,5],[46,7],[114,7],[162,7],[181,5],[254,7],[312,7]]},"232":{"position":[[363,5],[445,5],[531,7]]},"296":{"position":[[21,5],[69,6]]},"298":{"position":[[95,7],[157,5],[258,7]]},"300":{"position":[[56,7],[185,8],[263,8]]},"302":{"position":[[90,5],[410,7]]},"336":{"position":[[707,5]]},"341":{"position":[[372,5]]},"500":{"position":[[377,5],[1113,5]]},"523":{"position":[[760,8]]},"527":{"position":[[591,5],[3050,5]]},"529":{"position":[[1552,7]]},"679":{"position":[[501,6]]},"681":{"position":[[1457,6],[1910,6]]},"688":{"position":[[580,6],[687,5]]},"692":{"position":[[246,6]]},"696":{"position":[[444,5],[499,5],[594,5],[642,5],[964,5],[1094,6],[1183,5]]},"705":{"position":[[183,5],[256,5]]},"709":{"position":[[697,5],[739,5],[926,5],[1053,5],[1371,5],[1996,5]]},"711":{"position":[[133,6]]},"743":{"position":[[113,9]]},"789":{"position":[[694,6]]},"791":{"position":[[743,5]]},"809":{"position":[[831,5]]},"893":{"position":[[415,8]]},"1014":{"position":[[404,5]]},"1384":{"position":[[1584,5],[3579,5]]},"1782":{"position":[[882,5],[910,5],[1036,5],[1163,5],[1324,5]]}}}],["query/key/value/output",{"_index":2576,"t":{"721":{"position":[[136,22]]}}}],["question",{"_index":591,"t":{"126":{"position":[[286,8]]},"221":{"position":[[117,8],[875,8]]},"287":{"position":[[676,8]]},"434":{"position":[[72,8],[421,8]]},"436":{"position":[[209,8],[558,8],[1426,8],[1604,8]]},"439":{"position":[[18,8],[254,8]]},"445":{"position":[[302,8]]},"447":{"position":[[660,8],[807,8]]},"449":{"position":[[79,8],[124,8]]},"451":{"position":[[79,8],[98,8],[171,8]]},"453":{"position":[[60,8]]},"455":{"position":[[83,8],[115,8],[648,8],[670,8]]},"457":{"position":[[26,8],[77,8],[181,8],[373,8],[419,8],[541,8],[594,8],[720,8],[1306,8],[1380,8]]},"459":{"position":[[3,8],[19,8],[159,8],[296,10],[404,8],[438,10],[652,8],[668,8],[821,8]]},"464":{"position":[[16,9],[63,8],[99,9],[120,8]]},"466":{"position":[[0,8],[68,8],[87,8],[262,8]]},"471":{"position":[[158,8]]},"473":{"position":[[184,8]]},"479":{"position":[[16,8]]},"553":{"position":[[150,8]]},"569":{"position":[[116,8]]},"658":{"position":[[163,8]]},"664":{"position":[[182,8]]},"674":{"position":[[167,8]]},"784":{"position":[[790,8]]},"969":{"position":[[193,8]]},"997":{"position":[[106,8],[593,8],[682,10]]},"1014":{"position":[[1502,8]]},"1017":{"position":[[190,8]]},"1041":{"position":[[92,8]]},"1049":{"position":[[241,8]]},"1070":{"position":[[202,9],[301,8]]},"1111":{"position":[[129,8]]},"1117":{"position":[[209,9]]},"1130":{"position":[[342,9]]},"1234":{"position":[[111,8]]},"1253":{"position":[[246,10]]},"1419":{"position":[[742,8]]},"1527":{"position":[[77,8]]},"1554":{"position":[[113,9]]},"1714":{"position":[[176,8],[305,9]]},"1724":{"position":[[433,8]]},"1728":{"position":[[345,8],[701,8]]},"1772":{"position":[[0,8],[56,8],[359,8]]},"1782":{"position":[[1415,8],[1476,8]]}}}],["question]\\textup{[question]}[quest",{"_index":1679,"t":{"459":{"position":[[307,39],[449,40]]}}}],["questiuon",{"_index":2338,"t":{"658":{"position":[[3125,9]]}}}],["queu",{"_index":1749,"t":{"498":{"position":[[721,7]]}}}],["queue",{"_index":1754,"t":{"500":{"position":[[953,5],[1136,5]]}}}],["qustion",{"_index":1702,"t":{"473":{"position":[[83,7]]},"963":{"position":[[567,8]]}}}],["q∈rr×d2q",{"_index":2839,"t":{"795":{"position":[[266,8]]}}}],["q△=pλq",{"_index":2780,"t":{"786":{"position":[[4007,6]]}}}],["r",{"_index":697,"t":{"153":{"position":[[55,1],[119,1],[144,1],[353,1],[457,1],[553,1]]},"165":{"position":[[507,2],[1536,1]]},"168":{"position":[[206,1]]},"177":{"position":[[1308,1]]},"199":{"position":[[32,1]]},"735":{"position":[[56,1]]},"755":{"position":[[548,1],[552,1]]},"857":{"position":[[1091,1]]},"988":{"position":[[1220,2],[1223,2],[1297,2]]},"994":{"position":[[198,1],[202,1]]},"1558":{"position":[[673,3],[862,4]]}}}],["r(\\text{s})}{\\parti",{"_index":3229,"t":{"861":{"position":[[1379,21]]}}}],["r(p,q",{"_index":2857,"t":{"795":{"position":[[950,6]]}}}],["r(p,q)=∥p⊤p−i∥f2=∥qq⊤−i∥f2.\\begin{equ",{"_index":2856,"t":{"795":{"position":[[906,43]]}}}],["r(p_k",{"_index":2898,"t":{"797":{"position":[[1025,6]]}}}],["r(s)=∑i,jσ(si,j)r(",{"_index":3194,"t":{"857":{"position":[[1182,20]]}}}],["r(s)r(\\text{s})r(",{"_index":3223,"t":{"861":{"position":[[900,19]]}}}],["r(s)∂si,j=∂σ(si,j)∂si,j\\frac{\\parti",{"_index":3228,"t":{"861":{"position":[[1340,38]]}}}],["r0r_0r0",{"_index":4753,"t":{"1455":{"position":[[128,8],[278,8]]}}}],["r101x1",{"_index":551,"t":{"114":{"position":[[72,7]]}}}],["r152x1",{"_index":552,"t":{"114":{"position":[[80,7]]}}}],["r152x2",{"_index":553,"t":{"114":{"position":[[88,6],[119,7]]}}}],["r200x3",{"_index":555,"t":{"114":{"position":[[127,6]]}}}],["r50",{"_index":562,"t":{"114":{"position":[[297,3]]}}}],["r50+vit",{"_index":561,"t":{"114":{"position":[[243,7]]}}}],["r50x1",{"_index":549,"t":{"114":{"position":[[59,6]]}}}],["r50x2",{"_index":550,"t":{"114":{"position":[[66,5]]}}}],["r=1,2,…,48r",{"_index":4660,"t":{"1431":{"position":[[496,12]]}}}],["r=16r",{"_index":2288,"t":{"633":{"position":[[369,5]]},"642":{"position":[[322,5]]}}}],["r=1kαrρsr\\sum^k_{r=1}\\alpha_r\\rho^{s_r}∑r=1k​αr​ρsr",{"_index":4662,"t":{"1431":{"position":[[773,53]]}}}],["r=1r",{"_index":2725,"t":{"774":{"position":[[1186,4]]}}}],["r=4r",{"_index":2652,"t":{"741":{"position":[[205,4]]},"770":{"position":[[178,4]]},"778":{"position":[[648,4]]}}}],["r=64r",{"_index":2727,"t":{"776":{"position":[[0,5]]}}}],["r=8r",{"_index":2687,"t":{"770":{"position":[[89,4]]},"786":{"position":[[2091,4]]}}}],["r=b(0)/nr",{"_index":3000,"t":{"803":{"position":[[431,9]]}}}],["r=sim(esr,et)∑l=1ksim(esl,et),\\alpha_r",{"_index":4664,"t":{"1431":{"position":[[943,39]]}}}],["r>0r",{"_index":3695,"t":{"1067":{"position":[[1113,4]]}}}],["r\\alpha_rαr",{"_index":4663,"t":{"1431":{"position":[[920,13]]}}}],["r\\frac{\\alpha}{r}r",{"_index":2640,"t":{"733":{"position":[[953,21]]}}}],["r\\lambda_rλr",{"_index":3224,"t":{"861":{"position":[[922,14],[1168,14]]},"866":{"position":[[415,14]]}}}],["r^{d\\time",{"_index":2461,"t":{"686":{"position":[[121,10],[184,10],[267,10]]}}}],["r_0",{"_index":4757,"t":{"1455":{"position":[[339,3]]}}}],["r_{\\theta",{"_index":4936,"t":{"1558":{"position":[[778,11]]}}}],["r_{\\theta}(x",{"_index":4938,"t":{"1558":{"position":[[803,13]]}}}],["race",{"_index":5566,"t":{"1772":{"position":[[182,6]]}}}],["raffel",{"_index":2454,"t":{"683":{"position":[[309,7]]},"1132":{"position":[[653,7]]},"1415":{"position":[[226,6]]},"1419":{"position":[[227,7],[923,6]]},"1421":{"position":[[434,6]]},"1431":{"position":[[1203,6]]},"1494":{"position":[[39,7]]}}}],["raft",{"_index":2059,"t":{"587":{"position":[[702,4]]},"589":{"position":[[2222,4]]},"594":{"position":[[931,4],[975,4]]},"618":{"position":[[71,4],[82,4],[136,4]]},"622":{"position":[[394,4]]}}}],["rainbow",{"_index":4595,"t":{"1419":{"position":[[767,7]]}}}],["rajpurkar",{"_index":1934,"t":{"529":{"position":[[2668,10]]}}}],["rand",{"_index":1906,"t":{"529":{"position":[[1011,6],[1107,6]]},"919":{"position":[[112,4],[234,4]]}}}],["randag",{"_index":303,"t":{"53":{"position":[[323,10]]}}}],["randaug",{"_index":265,"t":{"49":{"position":[[497,11]]},"78":{"position":[[567,12],[748,11]]}}}],["random",{"_index":1491,"t":{"362":{"position":[[132,6]]},"660":{"position":[[552,6]]},"668":{"position":[[433,6]]},"709":{"position":[[134,6]]},"733":{"position":[[191,6],[867,6]]},"778":{"position":[[350,6],[463,6]]},"791":{"position":[[482,6]]},"795":{"position":[[831,6]]},"919":{"position":[[164,6]]},"1067":{"position":[[708,6]]},"1101":{"position":[[162,6]]},"1111":{"position":[[840,6]]},"1130":{"position":[[48,6]]},"1141":{"position":[[86,6]]},"1143":{"position":[[954,6]]},"1151":{"position":[[1090,6],[1326,6]]},"1201":{"position":[[112,6],[308,6]]},"1332":{"position":[[66,6],[285,6],[371,6]]},"1334":{"position":[[22,6],[242,6]]},"1369":{"position":[[383,8]]},"1393":{"position":[[515,6]]},"1427":{"position":[[545,6]]},"1501":{"position":[[61,6]]},"1505":{"position":[[818,6],[1000,6],[1140,6]]},"1513":{"position":[[326,6],[432,6]]},"1665":{"position":[[1525,6]]},"1669":{"position":[[767,6]]},"1674":{"position":[[719,6]]}}}],["randomli",{"_index":1970,"t":{"531":{"position":[[1390,8]]},"1037":{"position":[[139,8]]}}}],["rang",{"_index":1281,"t":{"310":{"position":[[439,5],[479,5],[729,5]]}}}],["rangle⟨i",{"_index":3919,"t":{"1132":{"position":[[445,10],[529,10]]}}}],["rangle⟨x",{"_index":3917,"t":{"1132":{"position":[[404,10],[492,10]]}}}],["rangle⟨z",{"_index":3922,"t":{"1132":{"position":[[558,11]]}}}],["rank",{"_index":2036,"t":{"569":{"position":[[453,4]]},"594":{"position":[[1061,5],[1203,4]]},"596":{"position":[[436,4],[1022,4],[1131,7],[1278,7],[1371,4]]},"598":{"position":[[3286,4],[3645,4]]},"608":{"position":[[718,4]]},"628":{"position":[[387,4]]},"633":{"position":[[936,4]]},"648":{"position":[[491,4]]},"717":{"position":[[54,4],[144,4],[449,4]]},"719":{"position":[[482,5],[511,4],[617,4],[725,4],[737,4],[1123,4]]},"733":{"position":[[75,4],[322,4],[488,4]]},"735":{"position":[[49,4],[58,4]]},"757":{"position":[[21,4]]},"768":{"position":[[125,4]]},"770":{"position":[[377,4]]},"772":{"position":[[149,5]]},"776":{"position":[[140,5]]},"780":{"position":[[283,4]]},"786":{"position":[[1627,4],[2008,4],[2403,4],[3287,4],[3421,4],[3486,4],[3630,4],[3682,4],[3777,4]]},"793":{"position":[[119,4]]},"795":{"position":[[1137,4],[1516,4],[1988,4]]},"799":{"position":[[232,4]]},"803":{"position":[[0,4],[13,4],[106,4],[424,4]]},"809":{"position":[[768,4]]},"814":{"position":[[233,4]]},"821":{"position":[[239,4],[312,4]]},"835":{"position":[[52,4]]},"841":{"position":[[83,4],[359,4]]},"857":{"position":[[349,7],[847,7]]},"947":{"position":[[274,4]]},"949":{"position":[[591,4]]},"1060":{"position":[[883,4]]},"1062":{"position":[[1119,4],[1142,4]]},"1067":{"position":[[296,4],[397,4],[443,4],[1418,4]]},"1070":{"position":[[1047,4],[1826,4]]},"1080":{"position":[[199,4],[463,4]]},"1084":{"position":[[197,4],[1148,4]]},"1087":{"position":[[192,5]]},"1225":{"position":[[487,4]]},"1227":{"position":[[980,4],[1187,4]]},"1240":{"position":[[183,4],[351,4]]},"1242":{"position":[[435,4],[792,4],[899,4]]},"1246":{"position":[[639,4]]},"1285":{"position":[[206,4]]},"1384":{"position":[[3150,4]]},"1393":{"position":[[1054,4]]},"1431":{"position":[[455,4],[491,4]]}}}],["rank/svd",{"_index":3057,"t":{"828":{"position":[[31,8]]}}}],["rare",{"_index":5549,"t":{"1762":{"position":[[562,4]]}}}],["rasley",{"_index":1806,"t":{"517":{"position":[[1091,7]]}}}],["rate",{"_index":254,"t":{"49":{"position":[[210,4],[225,4]]},"53":{"position":[[303,4]]},"153":{"position":[[725,4]]},"317":{"position":[[135,4],[488,4]]},"322":{"position":[[390,4]]},"326":{"position":[[627,4]]},"372":{"position":[[35,4]]},"550":{"position":[[78,5]]},"602":{"position":[[388,4]]},"666":{"position":[[299,4]]},"668":{"position":[[136,4]]},"670":{"position":[[181,4]]},"674":{"position":[[281,4],[433,4]]},"797":{"position":[[1596,4]]},"807":{"position":[[271,4]]},"814":{"position":[[612,4]]},"821":{"position":[[436,4]]},"853":{"position":[[1153,4],[1701,4]]},"866":{"position":[[368,4],[758,4]]},"875":{"position":[[203,4]]},"999":{"position":[[962,4]]},"1060":{"position":[[922,4]]},"1062":{"position":[[1285,4]]},"1067":{"position":[[1312,5],[1383,4],[1453,4]]},"1084":{"position":[[974,5],[1006,4],[1042,4],[1078,4],[1111,5],[1138,5],[1166,5],[1202,4]]},"1087":{"position":[[180,4]]},"1107":{"position":[[1063,4]]},"1111":{"position":[[1221,4],[1384,4]]},"1134":{"position":[[727,4]]},"1136":{"position":[[73,4]]},"1157":{"position":[[501,4]]},"1199":{"position":[[16,4],[95,4],[181,4],[322,4]]},"1212":{"position":[[274,5]]},"1246":{"position":[[874,4]]},"1314":{"position":[[196,4],[260,4],[347,4]]},"1496":{"position":[[256,4]]},"1558":{"position":[[268,4]]},"1665":{"position":[[1289,4]]},"1674":{"position":[[353,4]]},"1682":{"position":[[179,4]]}}}],["rate/prompt",{"_index":3994,"t":{"1159":{"position":[[1834,11]]}}}],["ratio",{"_index":4834,"t":{"1487":{"position":[[1155,5]]},"1517":{"position":[[180,5]]}}}],["rational",{"_index":1537,"t":{"384":{"position":[[545,9]]},"428":{"position":[[99,9]]}}}],["raw",{"_index":5396,"t":{"1693":{"position":[[349,3]]},"1695":{"position":[[113,3]]}}}],["rcnn",{"_index":706,"t":{"153":{"position":[[339,4],[412,4]]}}}],["rd1×d2\\triangl",{"_index":2756,"t":{"786":{"position":[[1779,17]]},"791":{"position":[[272,17]]}}}],["rdhidden×l\\in",{"_index":4484,"t":{"1384":{"position":[[2333,14]]}}}],["re",{"_index":739,"t":{"165":{"position":[[464,6],[1531,4]]},"168":{"position":[[200,3]]},"177":{"position":[[783,3]]},"187":{"position":[[6,3],[55,3]]},"242":{"position":[[132,2]]},"658":{"position":[[2669,2]]},"668":{"position":[[448,2]]},"1496":{"position":[[559,2]]},"1505":{"position":[[935,2]]},"1665":{"position":[[629,4]]}}}],["react",{"_index":68,"t":{"9":{"position":[[83,5]]},"1447":{"position":[[244,5]]},"1610":{"position":[[16,5]]},"1612":{"position":[[30,5],[58,5],[79,5],[90,8],[200,5],[229,5],[315,5]]},"1628":{"position":[[70,5]]}}}],["read",{"_index":1039,"t":{"225":{"position":[[579,8]]},"287":{"position":[[431,7]]},"1583":{"position":[[0,4]]},"1600":{"position":[[196,5]]}}}],["readi",{"_index":132,"t":{"19":{"position":[[314,5]]}}}],["real",{"_index":496,"t":{"102":{"position":[[172,4]]},"589":{"position":[[2188,4]]},"594":{"position":[[1023,5]]},"608":{"position":[[522,4]]},"618":{"position":[[34,4],[89,4],[462,4]]},"658":{"position":[[775,4]]},"1164":{"position":[[444,4]]},"1802":{"position":[[611,4]]}}}],["realtoxicityprompt",{"_index":4918,"t":{"1546":{"position":[[712,18]]},"1560":{"position":[[493,19]]}}}],["reason",{"_index":1521,"t":{"382":{"position":[[32,9],[77,9],[146,9],[225,9]]},"384":{"position":[[101,9],[168,9],[196,9],[794,9],[903,9]]},"386":{"position":[[399,9]]},"388":{"position":[[16,9]]},"409":{"position":[[566,9]]},"418":{"position":[[37,9]]},"426":{"position":[[62,9],[151,9],[291,9],[418,11],[510,9],[573,9]]},"428":{"position":[[37,9]]},"430":{"position":[[22,9],[104,9],[137,9],[160,9]]},"459":{"position":[[138,6]]},"546":{"position":[[112,10],[133,10]]},"553":{"position":[[30,9]]},"569":{"position":[[41,9],[74,10],[150,10]]},"579":{"position":[[181,10]]},"885":{"position":[[554,9]]},"887":{"position":[[1036,9]]},"928":{"position":[[213,9]]},"932":{"position":[[662,9]]},"934":{"position":[[413,9],[876,9]]},"940":{"position":[[12,9]]},"951":{"position":[[474,9]]},"953":{"position":[[705,9]]},"955":{"position":[[353,9]]},"969":{"position":[[147,9]]},"997":{"position":[[138,9]]},"1109":{"position":[[954,9]]},"1111":{"position":[[210,9]]},"1283":{"position":[[159,9]]},"1419":{"position":[[789,10]]},"1427":{"position":[[1072,9]]},"1429":{"position":[[1597,9]]},"1440":{"position":[[539,10]]},"1442":{"position":[[704,9],[1604,9],[1799,9]]},"1449":{"position":[[250,9]]},"1770":{"position":[[102,9],[500,9]]}}}],["reberta",{"_index":3289,"t":{"887":{"position":[[1355,7]]}}}],["rebuffi",{"_index":2310,"t":{"658":{"position":[[728,8]]}}}],["rec",{"_index":738,"t":{"165":{"position":[[423,6],[1525,5]]},"168":{"position":[[195,4]]},"177":{"position":[[777,3]]},"187":{"position":[[0,3],[49,3]]},"701":{"position":[[76,4]]}}}],["receni",{"_index":5628,"t":{"1802":{"position":[[311,6]]}}}],["recept",{"_index":571,"t":{"116":{"position":[[717,9],[897,9],[913,9]]}}}],["recip",{"_index":2058,"t":{"587":{"position":[[684,6]]},"589":{"position":[[1751,6],[2140,6]]},"592":{"position":[[249,6],[267,6]]},"596":{"position":[[2574,6]]},"600":{"position":[[530,6]]},"602":{"position":[[11,6],[621,6],[726,6]]},"604":{"position":[[6,6],[108,6]]},"616":{"position":[[241,6]]},"622":{"position":[[10,6],[87,6]]}}}],["recogmnit",{"_index":1416,"t":{"339":{"position":[[635,12]]}}}],["recognit",{"_index":1028,"t":{"221":{"position":[[164,12]]},"225":{"position":[[624,12]]},"334":{"position":[[235,11]]},"336":{"position":[[477,11],[864,11]]},"339":{"position":[[603,12]]},"343":{"position":[[250,12],[270,11]]},"352":{"position":[[253,11]]},"1014":{"position":[[1536,11]]},"1017":{"position":[[165,11]]},"1041":{"position":[[68,12]]},"1724":{"position":[[335,11]]},"1728":{"position":[[315,11],[548,11]]},"1768":{"position":[[536,11]]}}}],["recommend",{"_index":93,"t":{"15":{"position":[[65,11]]}}}],["recongnit",{"_index":1490,"t":{"360":{"position":[[244,12]]}}}],["reconstruct",{"_index":3911,"t":{"1132":{"position":[[169,14]]}}}],["record",{"_index":2287,"t":{"633":{"position":[[68,6]]},"640":{"position":[[108,6],[300,6]]},"997":{"position":[[310,6]]},"1006":{"position":[[1810,6]]},"1070":{"position":[[1780,6]]},"1111":{"position":[[67,6]]},"1181":{"position":[[80,7]]},"1253":{"position":[[91,6]]},"1427":{"position":[[827,6],[1234,6]]},"1429":{"position":[[1418,6],[1773,6]]},"1527":{"position":[[31,6],[68,6]]}}}],["recoveri",{"_index":5622,"t":{"1796":{"position":[[95,8]]}}}],["recurr",{"_index":1160,"t":{"287":{"position":[[606,10],[620,9]]},"308":{"position":[[7,10]]},"310":{"position":[[162,9],[950,9],[1083,9],[1595,9]]},"328":{"position":[[104,9],[185,9]]},"1305":{"position":[[373,10]]},"1665":{"position":[[156,9]]},"1667":{"position":[[49,9]]}}}],["reduct",{"_index":2260,"t":{"630":{"position":[[1035,9]]},"633":{"position":[[352,9]]},"642":{"position":[[0,9]]},"1431":{"position":[[1772,9],[2156,9],[2620,9]]}}}],["redund",{"_index":2834,"t":{"793":{"position":[[169,9]]}}}],["reed",{"_index":1948,"t":{"531":{"position":[[380,5]]}}}],["ref",{"_index":897,"t":{"177":{"position":[[1314,4]]},"199":{"position":[[0,3],[18,3]]},"201":{"position":[[66,3]]}}}],["refactor",{"_index":5619,"t":{"1794":{"position":[[336,8]]}}}],["refcoco",{"_index":880,"t":{"177":{"position":[[570,8],[579,8]]},"187":{"position":[[12,8],[21,8]]},"201":{"position":[[44,8]]}}}],["refcoco/g",{"_index":887,"t":{"177":{"position":[[1210,12]]}}}],["refcocog",{"_index":881,"t":{"177":{"position":[[590,8]]},"187":{"position":[[32,8]]}}}],["refer",{"_index":366,"t":{"78":{"position":[[901,5]]},"163":{"position":[[673,10]]},"165":{"position":[[388,9],[430,9],[471,9],[1543,9],[1888,9],[1913,9]]},"170":{"position":[[601,9],[992,9]]},"174":{"position":[[522,9],[636,9]]},"177":{"position":[[1352,9]]},"1111":{"position":[[182,9]]},"1622":{"position":[[69,9],[187,9]]}}}],["reflect",{"_index":4699,"t":{"1440":{"position":[[300,10]]},"1442":{"position":[[458,10],[657,10],[759,10],[2046,10],[2074,10]]},"1445":{"position":[[136,10]]},"1451":{"position":[[11,10],[89,11],[261,10],[771,10]]},"1453":{"position":[[236,10]]},"1455":{"position":[[302,10],[486,10]]}}}],["reflexion",{"_index":4698,"t":{"1440":{"position":[[187,9],[259,9],[378,9]]},"1442":{"position":[[294,9],[620,9],[1128,9],[1928,9],[2221,9]]},"1449":{"position":[[0,9]]},"1453":{"position":[[0,9],[370,9]]},"1455":{"position":[[590,9]]},"1462":{"position":[[274,9]]}}}],["reflxion",{"_index":4764,"t":{"1462":{"position":[[0,8]]}}}],["reformul",{"_index":5586,"t":{"1782":{"position":[[888,13],[1042,13],[1169,13],[1330,13],[1384,13]]}}}],["region",{"_index":593,"t":{"126":{"position":[[485,7]]},"130":{"position":[[129,7]]},"147":{"position":[[362,6],[404,6]]},"149":{"position":[[39,6],[69,6],[122,6],[168,6]]},"155":{"position":[[517,6]]},"170":{"position":[[929,6]]},"191":{"position":[[62,6]]},"199":{"position":[[92,6]]}}}],["regress",{"_index":539,"t":{"108":{"position":[[135,10]]},"225":{"position":[[213,10]]},"289":{"position":[[343,10]]},"302":{"position":[[674,10]]},"466":{"position":[[412,12]]},"485":{"position":[[1016,12]]},"494":{"position":[[15,10]]},"1712":{"position":[[91,10]]}}}],["regular",{"_index":41,"t":{"7":{"position":[[123,7]]},"23":{"position":[[222,14]]},"33":{"position":[[44,7],[170,7]]},"47":{"position":[[72,14],[123,14],[170,14],[322,14],[351,14],[458,14]]},"53":{"position":[[308,14]]},"74":{"position":[[20,14]]},"78":{"position":[[315,14],[378,14],[452,14],[536,14],[639,14],[725,14]]},"108":{"position":[[109,11]]},"112":{"position":[[176,14]]},"319":{"position":[[16,14]]},"786":{"position":[[4198,12]]},"795":{"position":[[891,11]]},"797":{"position":[[826,14],[1091,14]]},"814":{"position":[[431,14]]},"839":{"position":[[238,14],[315,14],[490,14]]},"851":{"position":[[606,14],[659,14]]},"857":{"position":[[1286,14]]},"861":{"position":[[957,14],[1096,14],[1125,14]]},"866":{"position":[[378,14]]},"868":{"position":[[48,14]]},"877":{"position":[[21,14],[68,14]]},"1246":{"position":[[806,7]]},"1620":{"position":[[0,7]]},"1622":{"position":[[0,7]]}}}],["reinforc",{"_index":4697,"t":{"1440":{"position":[[57,13]]},"1445":{"position":[[197,13]]},"1558":{"position":[[1096,13]]}}}],["rel",{"_index":4675,"t":{"1431":{"position":[[1757,8]]},"1620":{"position":[[57,8]]},"1622":{"position":[[204,8]]}}}],["relat",{"_index":96,"t":{"15":{"position":[[101,7]]},"483":{"position":[[718,7],[891,7]]},"1107":{"position":[[64,9]]},"1151":{"position":[[968,7]]},"1232":{"position":[[45,7]]},"1305":{"position":[[384,8]]},"1644":{"position":[[643,8]]},"1646":{"position":[[1476,8],[1540,9],[1566,8],[1593,8],[2297,8],[2469,10],[3070,8]]},"1651":{"position":[[39,8],[967,8],[1608,7]]},"1653":{"position":[[735,8]]},"1655":{"position":[[395,8],[1367,8]]},"1657":{"position":[[543,7]]},"1663":{"position":[[7,8],[86,8],[114,8]]},"1665":{"position":[[0,8],[75,8],[243,8],[609,8],[785,8],[947,8],[1117,8]]},"1669":{"position":[[196,8]]},"1676":{"position":[[127,8]]},"1684":{"position":[[201,7],[686,8],[771,8]]},"1689":{"position":[[257,8]]},"1718":{"position":[[1084,8]]},"1720":{"position":[[2446,8]]},"1724":{"position":[[301,8]]},"1740":{"position":[[97,8]]},"1768":{"position":[[50,8],[97,8]]},"1782":{"position":[[1890,8]]},"1788":{"position":[[381,10]]},"1794":{"position":[[581,8]]}}}],["relationship",{"_index":4632,"t":{"1427":{"position":[[1042,13]]},"1429":{"position":[[1129,14],[1322,13]]}}}],["releas",{"_index":5056,"t":{"1604":{"position":[[0,7]]}}}],["relev",{"_index":1655,"t":{"457":{"position":[[35,8]]},"1718":{"position":[[873,8]]}}}],["relfexion",{"_index":4734,"t":{"1447":{"position":[[301,9]]},"1451":{"position":[[109,9]]}}}],["reload",{"_index":139,"t":{"19":{"position":[[424,7]]}}}],["relu",{"_index":1067,"t":{"234":{"position":[[225,4]]},"304":{"position":[[154,4]]},"789":{"position":[[830,4]]},"1101":{"position":[[573,4]]},"1174":{"position":[[54,4]]}}}],["remain",{"_index":3077,"t":{"841":{"position":[[416,9],[478,9]]},"847":{"position":[[299,9]]},"849":{"position":[[1260,9]]},"851":{"position":[[723,9]]},"855":{"position":[[640,9]]},"861":{"position":[[470,9],[1497,9]]},"866":{"position":[[85,9],[512,10],[705,9]]},"870":{"position":[[350,9],[390,9],[630,9],[831,9],[1183,9],[1332,9],[1392,9],[1443,9],[1529,9],[1862,9],[2117,9]]},"873":{"position":[[406,9],[488,9],[615,9],[657,9],[733,9],[813,9],[1187,9],[1421,9],[1507,9],[1567,9],[1628,9],[1711,9]]},"875":{"position":[[125,9]]},"877":{"position":[[219,9],[296,9],[331,9],[406,9],[483,9]]},"879":{"position":[[488,9]]},"881":{"position":[[268,9],[355,9]]}}}],["remov",{"_index":364,"t":{"78":{"position":[[867,6]]},"855":{"position":[[840,7]]},"861":{"position":[[533,7],[1531,7]]}}}],["reparameter",{"_index":3632,"t":{"1031":{"position":[[48,18]]},"1145":{"position":[[857,14],[902,14]]},"1157":{"position":[[302,14]]},"1159":{"position":[[1243,18],[1407,15],[1520,18]]},"1167":{"position":[[69,18],[201,15],[489,18],[1104,18],[1206,15]]},"1170":{"position":[[186,18]]},"1176":{"position":[[39,18]]},"1178":{"position":[[55,18],[128,15],[235,15],[312,15],[486,18]]},"1185":{"position":[[196,15],[676,18]]},"1187":{"position":[[186,15],[478,18]]},"1189":{"position":[[40,18],[86,18],[189,18]]},"1195":{"position":[[49,18],[375,18]]},"1197":{"position":[[300,18]]},"1199":{"position":[[292,18]]},"1208":{"position":[[38,18],[81,18],[198,18]]},"1212":{"position":[[62,18]]},"1214":{"position":[[101,18]]},"1218":{"position":[[95,18],[393,18],[611,18]]},"1221":{"position":[[48,18],[227,18],[326,18],[616,18]]},"1307":{"position":[[169,15],[473,18]]},"1341":{"position":[[892,18]]},"1384":{"position":[[1811,14]]}}}],["reparameterization",{"_index":3993,"t":{"1159":{"position":[[1599,19]]}}}],["replac",{"_index":352,"t":{"78":{"position":[[186,7],[834,7]]}}}],["report",{"_index":1902,"t":{"529":{"position":[[456,6],[1831,6]]},"633":{"position":[[98,6]]},"709":{"position":[[282,6]]},"828":{"position":[[126,6]]},"866":{"position":[[106,6],[729,6]]},"870":{"position":[[514,6],[2137,6]]},"1357":{"position":[[628,6],[687,6]]},"1362":{"position":[[449,6]]},"1393":{"position":[[539,6],[604,6]]},"1417":{"position":[[114,6]]},"1421":{"position":[[688,6]]},"1431":{"position":[[1451,6]]},"1492":{"position":[[226,6]]},"1501":{"position":[[187,6]]},"1511":{"position":[[186,6]]},"1581":{"position":[[237,6]]}}}],["repositori",{"_index":1781,"t":{"515":{"position":[[208,10]]}}}],["represent",{"_index":534,"t":{"108":{"position":[[38,14]]},"116":{"position":[[36,14],[68,14],[143,14],[270,14],[456,14]]},"132":{"position":[[165,14],[196,14],[320,14]]},"165":{"position":[[2463,15]]},"172":{"position":[[347,15]]},"174":{"position":[[21,15],[942,14]]},"287":{"position":[[114,14],[389,14],[528,14],[801,14]]},"289":{"position":[[81,15],[163,15]]},"300":{"position":[[458,14]]},"310":{"position":[[7,15],[1045,14]]},"336":{"position":[[598,14],[1041,14],[1130,14],[1495,14],[1609,14],[1873,14]]},"339":{"position":[[37,14],[523,14]]},"343":{"position":[[484,14],[627,14]]},"345":{"position":[[193,14]]},"347":{"position":[[65,14],[403,14],[430,14],[557,14]]},"350":{"position":[[147,14]]},"354":{"position":[[563,14]]},"356":{"position":[[270,14]]},"358":{"position":[[59,14],[103,14],[579,14],[1390,14]]},"360":{"position":[[7,14]]},"362":{"position":[[91,14],[154,14],[213,14]]},"368":{"position":[[290,14]]},"370":{"position":[[7,14],[118,14]]},"436":{"position":[[626,14]]},"445":{"position":[[13,14],[45,14]]},"479":{"position":[[224,14]]},"485":{"position":[[1131,14]]},"488":{"position":[[441,14]]},"498":{"position":[[22,15],[290,14],[440,15],[842,14]]},"500":{"position":[[148,15],[281,14],[347,14],[684,14]]},"515":{"position":[[678,14]]},"525":{"position":[[95,15]]},"696":{"position":[[944,14]]},"891":{"position":[[476,14]]},"1070":{"position":[[1371,14],[1475,14]]},"1126":{"position":[[93,14]]},"1128":{"position":[[716,15]]},"1130":{"position":[[7,14],[249,14]]},"1141":{"position":[[379,14]]},"1145":{"position":[[452,14],[558,15],[1879,14],[1972,14],[2457,14],[2552,14]]},"1147":{"position":[[74,14],[103,14]]},"1151":{"position":[[378,14],[1030,14],[1667,14]]},"1159":{"position":[[1553,14]]},"1170":{"position":[[219,14]]},"1185":{"position":[[381,14]]},"1303":{"position":[[1068,15]]},"1347":{"position":[[1403,14],[1893,14]]},"1350":{"position":[[112,14]]},"1352":{"position":[[107,14]]},"1389":{"position":[[1728,14]]},"1429":{"position":[[560,15]]},"1471":{"position":[[87,14]]},"1720":{"position":[[1394,14]]},"1730":{"position":[[832,14]]},"1754":{"position":[[344,14]]},"1762":{"position":[[70,14]]},"1764":{"position":[[39,14]]}}}],["requir",{"_index":2070,"t":{"592":{"position":[[21,11]]}}}],["resampl",{"_index":1062,"t":{"232":{"position":[[110,9],[140,9]]},"239":{"position":[[21,9]]},"267":{"position":[[0,9],[110,9],[132,9],[234,9]]}}}],["rescal",{"_index":2142,"t":{"598":{"position":[[782,10],[1178,9],[1279,9],[1363,9]]},"622":{"position":[[201,8]]}}}],["residu",{"_index":439,"t":{"91":{"position":[[1428,8],[2200,8]]},"234":{"position":[[284,8]]},"265":{"position":[[51,8]]},"292":{"position":[[171,8],[385,8]]},"294":{"position":[[193,8]]},"319":{"position":[[34,8]]},"326":{"position":[[608,9]]},"633":{"position":[[732,8]]},"683":{"position":[[968,8]]},"703":{"position":[[303,8]]},"755":{"position":[[17,8]]},"789":{"position":[[1082,8]]},"809":{"position":[[415,8]]},"1157":{"position":[[142,8],[250,8],[317,8]]},"1159":{"position":[[1234,8],[1302,8],[1350,8],[1796,8],[1928,8]]},"1167":{"position":[[425,8]]},"1170":{"position":[[4,8],[26,8],[111,8],[264,8]]},"1189":{"position":[[0,8],[77,8],[233,8]]},"1195":{"position":[[0,8],[138,8],[328,8],[404,8]]},"1197":{"position":[[129,8],[429,8]]},"1199":{"position":[[24,8],[283,8],[391,8]]},"1201":{"position":[[188,8],[256,8]]},"1203":{"position":[[151,8]]},"1205":{"position":[[104,8]]},"1212":{"position":[[0,8],[53,8]]},"1218":{"position":[[0,8],[513,8]]},"1221":{"position":[[4,8],[158,8],[257,8],[600,8]]},"1341":{"position":[[627,8]]},"1384":{"position":[[308,8]]},"1389":{"position":[[1212,8]]},"1558":{"position":[[279,8]]}}}],["resili",{"_index":3877,"t":{"1126":{"position":[[2344,10]]}}}],["resiz",{"_index":194,"t":{"27":{"position":[[247,8]]}}}],["resnet",{"_index":187,"t":{"27":{"position":[[67,7]]},"86":{"position":[[131,6],[331,6]]},"99":{"position":[[0,7]]},"104":{"position":[[214,6],[319,6]]},"106":{"position":[[20,6]]},"112":{"position":[[80,6],[412,6]]},"114":{"position":[[50,8]]},"182":{"position":[[18,6]]},"201":{"position":[[7,6]]},"339":{"position":[[380,7]]},"354":{"position":[[32,6],[43,6],[67,6],[81,6]]},"366":{"position":[[0,6],[151,6],[370,6]]},"376":{"position":[[199,6]]},"1167":{"position":[[738,6],[959,7]]},"1221":{"position":[[574,9]]}}}],["resnet50",{"_index":519,"t":{"104":{"position":[[455,8],[474,8]]}}}],["resnet50x16",{"_index":1492,"t":{"366":{"position":[[175,12]]}}}],["resnet50x4",{"_index":1456,"t":{"354":{"position":[[55,11]]},"366":{"position":[[163,11]]}}}],["resnet50x64",{"_index":1493,"t":{"366":{"position":[[188,12]]}}}],["resnetst",{"_index":188,"t":{"27":{"position":[[75,9]]},"55":{"position":[[88,8]]}}}],["resolut",{"_index":495,"t":{"102":{"position":[[97,10]]},"287":{"position":[[285,10]]},"594":{"position":[[866,10]]},"1111":{"position":[[192,10]]}}}],["resourc",{"_index":306,"t":{"55":{"position":[[26,8]]},"213":{"position":[[10,8]]},"215":{"position":[[191,8],[624,8],[1191,8],[1475,8]]},"709":{"position":[[15,8],[63,8]]},"977":{"position":[[659,8]]},"979":{"position":[[167,8]]},"984":{"position":[[34,8]]},"1073":{"position":[[225,9]]},"1080":{"position":[[244,8]]},"1143":{"position":[[555,9]]},"1384":{"position":[[1046,8]]},"1393":{"position":[[261,8],[619,8]]},"1395":{"position":[[390,8],[1940,8]]},"1397":{"position":[[4,8],[586,8],[1105,8],[1221,8],[1452,8]]},"1425":{"position":[[197,8]]},"1427":{"position":[[231,8]]},"1468":{"position":[[1428,8],[1443,8]]},"1492":{"position":[[16,8],[31,8]]},"1501":{"position":[[14,8]]}}}],["respect",{"_index":5068,"t":{"1608":{"position":[[47,10]]}}}],["respons",{"_index":2035,"t":{"569":{"position":[[386,8]]},"891":{"position":[[662,8],[963,8]]},"893":{"position":[[2583,8]]},"895":{"position":[[1150,8]]},"907":{"position":[[34,8]]},"940":{"position":[[321,8]]},"949":{"position":[[42,8]]},"963":{"position":[[507,8]]},"1558":{"position":[[520,8]]},"1682":{"position":[[537,8]]}}}],["resprompt",{"_index":2542,"t":{"703":{"position":[[262,9]]}}}],["result",{"_index":1920,"t":{"529":{"position":[[1823,7]]},"589":{"position":[[132,7]]},"638":{"position":[[89,6]]},"640":{"position":[[77,7],[260,7]]},"648":{"position":[[248,6]]},"650":{"position":[[259,6]]},"709":{"position":[[0,7]]},"786":{"position":[[3801,9]]},"803":{"position":[[616,9]]},"841":{"position":[[73,9]]},"1117":{"position":[[178,7]]},"1499":{"position":[[135,7]]},"1505":{"position":[[905,7]]},"1620":{"position":[[182,7]]}}}],["ret",{"_index":3597,"t":{"1002":{"position":[[980,4]]}}}],["retacr",{"_index":5330,"t":{"1663":{"position":[[219,8]]},"1669":{"position":[[1026,8]]},"1686":{"position":[[36,8]]}}}],["retain",{"_index":2750,"t":{"786":{"position":[[1189,9]]}}}],["retriev",{"_index":728,"t":{"163":{"position":[[314,9]]},"165":{"position":[[1636,9]]},"168":{"position":[[434,9],[615,9]]},"172":{"position":[[337,9]]},"174":{"position":[[2563,9]]},"236":{"position":[[507,9]]},"483":{"position":[[864,9]]},"485":{"position":[[337,9]]},"508":{"position":[[202,9]]},"512":{"position":[[111,9],[199,9]]},"515":{"position":[[834,9]]},"1105":{"position":[[26,9]]},"1234":{"position":[[141,9]]},"1407":{"position":[[714,9]]},"1409":{"position":[[1513,9],[1899,9]]},"1425":{"position":[[553,9]]},"1431":{"position":[[2289,10]]},"1436":{"position":[[318,9]]},"1682":{"position":[[521,9]]}}}],["retun",{"_index":2642,"t":{"733":{"position":[[1134,8]]}}}],["return",{"_index":5084,"t":{"1612":{"position":[[175,6]]},"1624":{"position":[[139,6],[247,6]]}}}],["revers",{"_index":4862,"t":{"1505":{"position":[[715,8],[981,8]]}}}],["reward",{"_index":233,"t":{"38":{"position":[[405,6]]},"1442":{"position":[[1241,6]]},"1449":{"position":[[142,6],[195,6],[351,6],[502,6]]},"1451":{"position":[[184,6],[328,7]]},"1455":{"position":[[175,6]]},"1546":{"position":[[443,6]]},"1550":{"position":[[140,6],[200,6],[224,6]]},"1558":{"position":[[450,6],[543,6],[600,6],[1939,6]]}}}],["rewind",{"_index":4356,"t":{"1347":{"position":[[469,9]]},"1468":{"position":[[1291,9]]},"1479":{"position":[[98,9]]},"1489":{"position":[[136,9],[236,9]]},"1496":{"position":[[517,9]]},"1505":{"position":[[834,6]]},"1513":{"position":[[618,9],[674,9]]},"1517":{"position":[[101,9]]}}}],["rewrit",{"_index":5441,"t":{"1718":{"position":[[390,8]]}}}],["re×k\\mu",{"_index":4379,"t":{"1352":{"position":[[189,9]]}}}],["rgb",{"_index":564,"t":{"116":{"position":[[305,3]]},"225":{"position":[[74,3],[160,3]]},"230":{"position":[[342,3],[434,3]]},"239":{"position":[[34,3]]},"262":{"position":[[65,3]]},"267":{"position":[[144,3],[198,3]]}}}],["rhoncu",{"_index":26,"t":{"3":{"position":[[227,7],[406,7],[585,7],[764,7],[943,7],[1122,7],[1301,7],[1480,7],[1659,7],[1838,7],[2017,7],[2196,7],[2375,7],[2554,7],[2733,7],[2912,7]]},"5":{"position":[[107,7]]}}}],["rh×w×c\\mathbb{r}^{h",{"_index":1045,"t":{"227":{"position":[[512,19]]}}}],["rich",{"_index":588,"t":{"126":{"position":[[214,4]]},"979":{"position":[[184,4]]},"1427":{"position":[[151,4]]},"1644":{"position":[[41,4]]},"1646":{"position":[[160,4]]},"1667":{"position":[[267,4]]}}}],["right",{"_index":831,"t":{"172":{"position":[[609,7]]},"358":{"position":[[630,6]]},"598":{"position":[[1664,6]]},"774":{"position":[[118,5]]},"795":{"position":[[981,6],[1025,6]]},"801":{"position":[[1100,6],[1929,6]]},"853":{"position":[[753,6],[861,6],[876,6],[1577,6]]},"855":{"position":[[322,6]]},"857":{"position":[[1064,6],[1118,6]]},"895":{"position":[[552,7]]},"1305":{"position":[[1301,5]]},"1712":{"position":[[141,5]]}}}],["right.fp​=⎩⎨⎧​enclref​enclref​merge(encvref​[templ",{"_index":809,"t":{"170":{"position":[[2317,55]]}}}],["right.w=⎩⎨⎧​fp′​[i",{"_index":862,"t":{"174":{"position":[[2254,21]]}}}],["rightarrow",{"_index":3430,"t":{"945":{"position":[[612,11]]},"1006":{"position":[[2342,13],[2372,13]]},"1427":{"position":[[725,13],[798,13],[834,13],[1164,13],[1241,13],[1266,13],[1290,13]]},"1651":{"position":[[1270,11]]}}}],["rightward",{"_index":4287,"t":{"1303":{"position":[[867,9]]}}}],["rl",{"_index":4722,"t":{"1442":{"position":[[2208,2]]},"1447":{"position":[[89,2]]},"1453":{"position":[[175,2]]},"1558":{"position":[[1119,4],[1347,2],[1812,2]]},"1579":{"position":[[36,2]]}}}],["rl\\pi^{rl}_\\phiπϕrl",{"_index":4958,"t":{"1558":{"position":[[1783,22]]}}}],["rlhf",{"_index":4914,"t":{"1546":{"position":[[315,4],[844,4],[876,4],[1109,4]]},"1552":{"position":[[519,4]]},"1565":{"position":[[97,4]]},"1567":{"position":[[14,4]]},"1570":{"position":[[128,4]]}}}],["rl×d=m×d+(s+d)×r",{"_index":3694,"t":{"1067":{"position":[[1060,16]]}}}],["rl×e\\rho",{"_index":4602,"t":{"1421":{"position":[[151,10]]}}}],["rl×e\\theta",{"_index":4373,"t":{"1350":{"position":[[536,12]]}}}],["rm",{"_index":4916,"t":{"1546":{"position":[[456,4],[469,2]]},"1550":{"position":[[255,2]]},"1552":{"position":[[457,2],[494,2]]},"1558":{"position":[[305,2],[413,2],[466,4],[570,2],[584,2],[937,2],[1048,2],[1073,2],[1194,2]]}}}],["rmsprop",{"_index":285,"t":{"53":{"position":[[119,7]]},"80":{"position":[[57,7]]}}}],["rm×d+(s+d)×r",{"_index":3710,"t":{"1070":{"position":[[1143,12]]}}}],["rnn",{"_index":1138,"t":{"283":{"position":[[52,4]]},"285":{"position":[[0,3],[19,3],[356,3],[379,3]]},"287":{"position":[[766,3]]},"326":{"position":[[175,3],[933,3]]}}}],["roberta",{"_index":1086,"t":{"239":{"position":[[128,7]]},"683":{"position":[[160,7]]},"717":{"position":[[322,8]]},"743":{"position":[[0,8]]},"759":{"position":[[0,7],[72,7],[94,7]]},"866":{"position":[[686,7],[840,7]]},"885":{"position":[[615,9]]},"901":{"position":[[0,7]]},"1043":{"position":[[19,7]]},"1471":{"position":[[38,7]]},"1750":{"position":[[136,7]]}}}],["roberta_bas",{"_index":5380,"t":{"1682":{"position":[[72,12],[372,12]]}}}],["robertabase_\\text{base}bas",{"_index":1898,"t":{"529":{"position":[[237,28],[790,29],[2430,28]]}}}],["robertabase_{base}bas",{"_index":1089,"t":{"239":{"position":[[250,23]]}}}],["robertalarge_{large}larg",{"_index":1091,"t":{"239":{"position":[[295,26]]},"924":{"position":[[118,26]]},"1665":{"position":[[367,26],[1233,26]]},"1667":{"position":[[189,26],[355,26]]}}}],["robot",{"_index":5377,"t":{"1680":{"position":[[276,5]]}}}],["robust",{"_index":1405,"t":{"336":{"position":[[1530,6]]},"409":{"position":[[32,10],[539,10],[617,6]]},"426":{"position":[[117,6]]},"676":{"position":[[895,10],[1117,6],[1194,10]]},"1124":{"position":[[604,10]]},"1126":{"position":[[2555,10]]},"1143":{"position":[[652,6]]},"1145":{"position":[[683,10],[953,6]]},"1147":{"position":[[220,10],[710,10]]},"1157":{"position":[[537,6]]}}}],["role",{"_index":3636,"t":{"1041":{"position":[[122,4]]},"1045":{"position":[[84,4]]},"1762":{"position":[[496,4]]}}}],["roug",{"_index":3058,"t":{"828":{"position":[[107,5]]},"1310":{"position":[[236,5],[245,5],[255,5]]}}}],["rout",{"_index":4383,"t":{"1352":{"position":[[318,7],[671,7],[756,7],[969,7],[1001,6]]},"1364":{"position":[[20,7],[181,7],[229,7],[316,7],[347,7]]},"1369":{"position":[[171,7],[246,7],[392,7],[564,7]]},"1371":{"position":[[134,7]]}}}],["router",{"_index":4381,"t":{"1352":{"position":[[263,6],[568,6]]},"1354":{"position":[[221,6],[262,6]]},"1364":{"position":[[61,6],[143,6],[452,6],[477,6],[576,6]]}}}],["routerperturb",{"_index":4436,"t":{"1364":{"position":[[410,18],[484,18],[583,18]]}}}],["row",{"_index":2272,"t":{"630":{"position":[[1597,4]]},"791":{"position":[[604,4]]},"947":{"position":[[270,3]]},"1307":{"position":[[426,4]]}}}],["row/col",{"_index":1907,"t":{"529":{"position":[[1114,8]]}}}],["rpompt",{"_index":4064,"t":{"1199":{"position":[[400,6]]}}}],["rr\\mathbb{r}^rrr",{"_index":2855,"t":{"795":{"position":[[720,16]]}}}],["rrr",{"_index":1287,"t":{"310":{"position":[[1223,3]]},"457":{"position":[[921,3]]},"630":{"position":[[1052,3]]},"642":{"position":[[17,3],[63,3],[97,3]]},"721":{"position":[[335,3]]},"733":{"position":[[493,3],[1015,3],[1104,3]]},"768":{"position":[[130,3]]},"772":{"position":[[11,3]]},"778":{"position":[[66,3],[326,3]]},"786":{"position":[[2013,3],[2408,3]]},"809":{"position":[[773,3]]},"814":{"position":[[238,3]]},"821":{"position":[[244,3]]},"877":{"position":[[88,3],[147,3],[194,3],[271,3],[369,3],[441,3]]},"994":{"position":[[264,3]]},"1067":{"position":[[1091,3]]},"1070":{"position":[[1061,3]]},"1431":{"position":[[485,3]]}}}],["rr×r\\lambda",{"_index":2841,"t":{"795":{"position":[[373,13]]}}}],["rss",{"_index":5001,"t":{"1585":{"position":[[91,3]]}}}],["rstrip",{"_index":4877,"t":{"1536":{"position":[[285,8]]}}}],["rt",{"_index":1018,"t":{"215":{"position":[[2342,2]]}}}],["rt=me(τ0)r_t",{"_index":4751,"t":{"1455":{"position":[[75,12]]}}}],["rte",{"_index":1915,"t":{"529":{"position":[[1424,3]]},"594":{"position":[[849,4]]},"628":{"position":[[431,3],[646,3]]},"633":{"position":[[56,3]]},"640":{"position":[[103,4]]},"642":{"position":[[37,3]]},"646":{"position":[[319,4]]},"668":{"position":[[599,3]]},"701":{"position":[[81,4]]},"709":{"position":[[357,3],[1256,3],[1361,3]]},"759":{"position":[[166,3]]},"816":{"position":[[178,3]]},"835":{"position":[[213,3]]},"866":{"position":[[984,4]]},"997":{"position":[[442,4]]},"1004":{"position":[[41,5]]},"1006":{"position":[[1679,3],[1794,3],[1857,3],[2530,3]]},"1031":{"position":[[145,3]]},"1052":{"position":[[268,3]]},"1054":{"position":[[301,3]]},"1070":{"position":[[128,3]]},"1101":{"position":[[1226,3]]},"1111":{"position":[[175,3]]},"1113":{"position":[[392,3]]},"1115":{"position":[[1073,3]]},"1181":{"position":[[88,4]]},"1208":{"position":[[168,4]]},"1253":{"position":[[183,4]]},"1393":{"position":[[121,4]]},"1395":{"position":[[2308,4]]},"1429":{"position":[[1516,5]]},"1431":{"position":[[1988,3]]},"1499":{"position":[[615,4]]},"1501":{"position":[[262,3]]}}}],["rtr_trt",{"_index":4754,"t":{"1455":{"position":[[142,8]]}}}],["rubi",{"_index":1776,"t":{"515":{"position":[[98,5]]}}}],["ruder",{"_index":2317,"t":{"658":{"position":[[1153,6]]},"676":{"position":[[677,6]]},"1126":{"position":[[322,6]]}}}],["rul",{"_index":5250,"t":{"1657":{"position":[[539,3]]}}}],["rule",{"_index":987,"t":{"215":{"position":[[517,5]]},"1644":{"position":[[410,5],[438,5],[537,5],[837,5]]},"1646":{"position":[[1941,5],[2021,4],[2144,5],[2819,5],[2889,5]]},"1649":{"position":[[177,5]]},"1651":{"position":[[726,5],[907,5],[1553,5],[1603,4]]},"1653":{"position":[[28,4],[94,5],[426,5],[517,5],[627,5],[895,5],[971,5],[1008,4]]},"1655":{"position":[[2137,5]]},"1684":{"position":[[823,5],[864,5]]},"1686":{"position":[[428,5]]},"1689":{"position":[[71,5],[89,4]]},"1720":{"position":[[2227,5]]}}}],["run",{"_index":103,"t":{"17":{"position":[[134,3],[385,3]]},"19":{"position":[[0,3],[46,3],[224,3]]},"668":{"position":[[451,3]]},"1379":{"position":[[1230,5]]},"1391":{"position":[[44,4]]},"1431":{"position":[[228,3]]},"1599":{"position":[[36,3]]},"1600":{"position":[[40,3]]},"1604":{"position":[[43,3]]},"1636":{"position":[[42,3]]},"1640":{"position":[[43,3],[127,3]]}}}],["r}a∈rs×r",{"_index":3679,"t":{"1067":{"position":[[344,8]]}}}],["r}b∈rd1​×r",{"_index":2762,"t":{"786":{"position":[[1924,11]]},"791":{"position":[[417,11]]}}}],["r}b∈rd×r",{"_index":2624,"t":{"733":{"position":[[436,9]]}}}],["r}p∈rd1​×r",{"_index":2838,"t":{"795":{"position":[[253,10]]}}}],["r}st={sk,i(t)​}1≤k≤n,1≤i≤r",{"_index":2941,"t":{"797":{"position":[[2294,27]]}}}],["r}{λi​}1≤i≤r",{"_index":2846,"t":{"795":{"position":[[480,13]]}}}],["r}λ∈rr×r",{"_index":2842,"t":{"795":{"position":[[412,8]]}}}],["rθ(x,y)r_\\theta(x",{"_index":4941,"t":{"1558":{"position":[[889,18]]}}}],["r∣θ∣=2×l^lora​×dmodel​×r",{"_index":2681,"t":{"757":{"position":[[226,24]]}}}],["r≪dmodelr",{"_index":2646,"t":{"741":{"position":[[107,9]]}}}],["r≪min⁡(d,k)r",{"_index":2628,"t":{"733":{"position":[[499,12]]}}}],["r≪min⁡(d1,d2)r",{"_index":2847,"t":{"795":{"position":[[496,14]]}}}],["r≪min⁡(s,d)r",{"_index":3682,"t":{"1067":{"position":[[402,12]]}}}],["r≪{d1,d2}r",{"_index":2763,"t":{"786":{"position":[[1936,10]]},"791":{"position":[[429,10]]}}}],["r≪{d1​,d2",{"_index":2766,"t":{"786":{"position":[[1963,13]]},"791":{"position":[[456,13]]}}}],["s",{"_index":228,"t":{"38":{"position":[[332,1]]},"40":{"position":[[18,1]]},"42":{"position":[[30,1],[139,1]]},"870":{"position":[[131,2],[152,1],[381,1],[566,1],[609,1],[657,1],[864,1],[1741,1],[1844,1],[1943,1]]},"945":{"position":[[628,1],[707,1]]},"1067":{"position":[[1045,2],[1207,1]]},"1070":{"position":[[1128,2]]},"1538":{"position":[[36,1],[212,1],[282,1]]}}}],["s(\\lambda",{"_index":2953,"t":{"801":{"position":[[525,9]]}}}],["s(p_{k,ji",{"_index":2957,"t":{"801":{"position":[[576,11]]}}}],["s(q_{k,ij",{"_index":2960,"t":{"801":{"position":[[621,12]]}}}],["s(t)(wij)=i‾(t)(wij)⋅u‾(t)(wij).\\begin{equ",{"_index":2994,"t":{"801":{"position":[[2447,48]]}}}],["s(⋅)l\\text{s}^l_{(\\cdot)}s(⋅)l",{"_index":3198,"t":{"857":{"position":[[1306,31]]}}}],["s(⋅)s(\\cdot)",{"_index":2966,"t":{"801":{"position":[[862,16],[930,16],[2405,16]]},"837":{"position":[[146,16]]}}}],["s0",{"_index":260,"t":{"49":{"position":[[341,2]]}}}],["s1>.<s_1>.<s1",{"_index":5159,"t":{"1646":{"position":[[1022,18]]}}}],["s1><s_1><s1",{"_index":5161,"t":{"1646":{"position":[[1133,14]]}}}],["s=finswt",{"_index":865,"t":{"174":{"position":[[2423,9]]}}}],["s=s18=262,144\\mathcal{",{"_index":4609,"t":{"1421":{"position":[[466,24]]}}}],["s={s1,s2,…,sk}\\pmb{\\mathcal{",{"_index":4098,"t":{"1236":{"position":[[20,31]]}}}],["s={s1,…,sk}\\mathcal{",{"_index":4187,"t":{"1246":{"position":[[152,22]]}}}],["s={s1​,…,sk",{"_index":4190,"t":{"1246":{"position":[[194,15]]}}}],["s[1",{"_index":4902,"t":{"1538":{"position":[[601,5],[634,4]]}}}],["s[5",{"_index":4899,"t":{"1538":{"position":[[548,5],[626,5]]}}}],["s[5]=a[0]+a[1]+a[2]+a[3]+a[4]+a[5]s[1]=a[0]+a[1]s[5]−s[1]=a[2]+a[3]+a[4]+a[5]\\begin{align",{"_index":4898,"t":{"1538":{"position":[[456,91]]}}}],["s[i",{"_index":4892,"t":{"1538":{"position":[[316,3],[411,3]]}}}],["s[i]=a[0]+a[1]+⋯a[i−1]+a[i]s[i",{"_index":4878,"t":{"1538":{"position":[[41,31]]}}}],["s[i]=s[i−1]+a[i]s[i",{"_index":4891,"t":{"1538":{"position":[[293,20]]}}}],["s[j]−s[i−1]s[j",{"_index":4894,"t":{"1538":{"position":[[393,15]]}}}],["s\\alpha_sα",{"_index":3144,"t":{"853":{"position":[[1663,13]]}}}],["s\\mathcal{s}",{"_index":4109,"t":{"1236":{"position":[[329,13]]},"1242":{"position":[[38,13]]},"1244":{"position":[[18,13]]},"1246":{"position":[[452,13]]},"1421":{"position":[[342,13],[387,13]]}}}],["s\\pmb{\\mathcal{s}}ss",{"_index":4110,"t":{"1236":{"position":[[360,20],[581,20]]}}}],["s\\pmb{\\phi_\\mathcal{s}}ϕs​ϕ",{"_index":4112,"t":{"1236":{"position":[[649,30]]}}}],["s\\rho^sρ",{"_index":4657,"t":{"1431":{"position":[[390,10]]}}}],["s\\text{s}",{"_index":3137,"t":{"853":{"position":[[1275,10],[1299,10],[1415,10],[1679,10],[2263,10]]},"855":{"position":[[153,10]]},"857":{"position":[[0,10],[230,10],[1273,10]]},"861":{"position":[[1077,10]]}}}],["s^g_l",{"_index":3355,"t":{"893":{"position":[[1787,5]]}}}],["s^l_{(\\cdot",{"_index":3190,"t":{"857":{"position":[[1050,13]]}}}],["s^{(t)}(w_{ij",{"_index":2995,"t":{"801":{"position":[[2496,15]]}}}],["s^{(t)}_{i,j",{"_index":3124,"t":{"853":{"position":[[714,13],[1487,13]]},"855":{"position":[[223,13]]}}}],["s^{18",{"_index":4610,"t":{"1421":{"position":[[493,6]]}}}],["s^{l'}_{(\\cdot",{"_index":3192,"t":{"857":{"position":[[1101,16]]}}}],["s^{t",{"_index":2934,"t":{"797":{"position":[[2036,6]]}}}],["s^{t}_{k,i",{"_index":2931,"t":{"797":{"position":[[1982,12]]}}}],["s_1",{"_index":4188,"t":{"1246":{"position":[[177,6]]}}}],["s_k^{(t",{"_index":2925,"t":{"797":{"position":[[1852,11]]}}}],["s_k^{(t)})_{ii",{"_index":2928,"t":{"797":{"position":[[1913,15]]}}}],["s_l",{"_index":3333,"t":{"893":{"position":[[889,3],[1144,3]]}}}],["s_l^g",{"_index":3365,"t":{"893":{"position":[[2339,6]]}}}],["s_l^k",{"_index":3342,"t":{"893":{"position":[[1150,7]]}}}],["s_l^{m+1}]^t",{"_index":3343,"t":{"893":{"position":[[1158,12]]}}}],["s_{i,j})}{\\parti",{"_index":3231,"t":{"861":{"position":[[1432,19]]}}}],["s_{i,j}}=\\frac{\\parti",{"_index":3230,"t":{"861":{"position":[[1401,23]]}}}],["s_{i,j}}∂si,j​∂r(s)​=∂si,j​∂σ(si,j",{"_index":3232,"t":{"861":{"position":[[1452,37]]}}}],["s_{k,i",{"_index":2952,"t":{"801":{"position":[[515,7]]}}}],["s_{k,i}^{(t",{"_index":2940,"t":{"797":{"position":[[2245,13]]}}}],["sacl",{"_index":965,"t":{"213":{"position":[[172,5]]},"225":{"position":[[365,5]]},"912":{"position":[[37,5]]}}}],["sad",{"_index":5480,"t":{"1728":{"position":[[458,10]]}}}],["salienc",{"_index":4860,"t":{"1505":{"position":[[313,8]]},"1525":{"position":[[78,8]]}}}],["salient",{"_index":1663,"t":{"457":{"position":[[328,7]]}}}],["same",{"_index":1258,"t":{"306":{"position":[[299,4]]},"610":{"position":[[339,4]]},"786":{"position":[[1074,4]]},"1389":{"position":[[52,4]]},"1429":{"position":[[1823,4]]},"1636":{"position":[[231,4]]},"1778":{"position":[[961,4]]}}}],["sampl",{"_index":645,"t":{"140":{"position":[[122,8]]},"215":{"position":[[800,6]]},"227":{"position":[[844,8]]},"249":{"position":[[136,7]]},"336":{"position":[[765,6]]},"347":{"position":[[498,6]]},"352":{"position":[[65,6],[173,6],[443,6],[765,6]]},"368":{"position":[[271,6]]},"498":{"position":[[561,7]]},"500":{"position":[[186,6]]},"502":{"position":[[150,6],[293,6]]},"569":{"position":[[343,8]]},"630":{"position":[[1583,7]]},"801":{"position":[[1376,6],[1397,6],[1431,8]]},"851":{"position":[[711,8]]},"999":{"position":[[835,6]]},"1014":{"position":[[441,6]]},"1082":{"position":[[116,7]]},"1095":{"position":[[174,6]]},"1111":{"position":[[847,6]]},"1141":{"position":[[158,7],[584,7]]},"1151":{"position":[[1344,7]]},"1201":{"position":[[70,7],[340,7],[410,8]]},"1246":{"position":[[337,8],[390,7],[495,7]]},"1257":{"position":[[188,6]]},"1259":{"position":[[71,8]]},"1281":{"position":[[16,8]]},"1321":{"position":[[135,6]]},"1389":{"position":[[493,6]]},"1393":{"position":[[368,8],[383,6]]},"1397":{"position":[[66,6],[257,6],[416,6],[552,6],[1151,7]]},"1421":{"position":[[576,7]]},"1496":{"position":[[305,7]]},"1513":{"position":[[293,6],[343,7],[387,7]]},"1676":{"position":[[194,6]]},"1704":{"position":[[695,8]]},"1718":{"position":[[617,6],[800,6]]},"1720":{"position":[[1772,6],[2331,6]]},"1738":{"position":[[298,6],[479,6],[494,6]]}}}],["samsum",{"_index":2658,"t":{"743":{"position":[[123,6]]}}}],["sang",{"_index":1010,"t":{"215":{"position":[[2246,4]]}}}],["sanh",{"_index":3085,"t":{"849":{"position":[[615,5],[1625,5]]},"851":{"position":[[765,5]]},"853":{"position":[[1222,5],[2338,5]]},"861":{"position":[[990,5]]},"868":{"position":[[103,5]]},"873":{"position":[[874,8]]}}}],["satellit",{"_index":508,"t":{"102":{"position":[[319,9]]}}}],["save",{"_index":1133,"t":{"269":{"position":[[182,4]]}}}],["saycan",{"_index":1575,"t":{"412":{"position":[[173,6]]},"414":{"position":[[139,6]]}}}],["sbu",{"_index":1094,"t":{"242":{"position":[[63,3]]},"255":{"position":[[125,3]]}}}],["sc",{"_index":2019,"t":{"561":{"position":[[214,2],[262,2],[375,2]]}}}],["sca",{"_index":1790,"t":{"517":{"position":[[202,6]]}}}],["scail",{"_index":147,"t":{"23":{"position":[[50,9]]},"25":{"position":[[346,8],[396,8]]},"35":{"position":[[26,8],[219,8]]},"44":{"position":[[78,8]]},"76":{"position":[[27,8]]},"78":{"position":[[227,8],[949,8]]},"120":{"position":[[263,8]]},"298":{"position":[[693,8]]},"537":{"position":[[107,8],[136,8]]}}}],["scalar",{"_index":3995,"t":{"1162":{"position":[[131,6]]},"1384":{"position":[[3815,6]]},"1442":{"position":[[342,6],[1224,6]]},"1451":{"position":[[321,6]]},"1455":{"position":[[168,6]]},"1558":{"position":[[536,6],[942,6]]}}}],["scale",{"_index":219,"t":{"35":{"position":[[167,5]]},"42":{"position":[[34,5]]},"145":{"position":[[162,5]]},"174":{"position":[[290,5],[603,5]]},"189":{"position":[[11,5]]},"215":{"position":[[45,5]]},"221":{"position":[[489,5]]},"298":{"position":[[21,6],[1039,7],[1258,7]]},"302":{"position":[[702,6]]},"399":{"position":[[22,5]]},"426":{"position":[[234,7],[271,7],[333,7]]},"428":{"position":[[239,5]]},"430":{"position":[[188,7],[233,7]]},"483":{"position":[[590,5]]},"539":{"position":[[63,7]]},"557":{"position":[[31,7]]},"567":{"position":[[721,5]]},"573":{"position":[[82,7]]},"648":{"position":[[314,5]]},"670":{"position":[[834,5]]},"676":{"position":[[884,5],[1005,5],[1139,5]]},"679":{"position":[[598,5]]},"709":{"position":[[2322,5]]},"733":{"position":[[996,7],[1075,7],[1094,7]]},"807":{"position":[[156,7],[353,7]]},"841":{"position":[[466,7]]},"849":{"position":[[21,5],[102,5]]},"895":{"position":[[227,5],[340,5],[383,5]]},"932":{"position":[[250,5]]},"934":{"position":[[1827,5]]},"940":{"position":[[93,5]]},"945":{"position":[[434,5],[544,5],[754,5]]},"947":{"position":[[144,5],[218,5]]},"949":{"position":[[567,5]]},"977":{"position":[[257,5]]},"979":{"position":[[473,5]]},"997":{"position":[[29,5]]},"1006":{"position":[[9,6]]},"1008":{"position":[[179,5]]},"1024":{"position":[[50,5]]},"1026":{"position":[[342,6]]},"1047":{"position":[[30,6],[102,6],[154,6],[195,6],[287,5],[374,5]]},"1095":{"position":[[104,5]]},"1126":{"position":[[2571,5]]},"1134":{"position":[[865,7]]},"1136":{"position":[[341,5]]},"1153":{"position":[[167,5]]},"1159":{"position":[[60,7],[128,5]]},"1268":{"position":[[230,7]]},"1354":{"position":[[292,6]]},"1357":{"position":[[273,7]]},"1389":{"position":[[1602,7],[2079,7]]},"1395":{"position":[[2853,7],[2937,7]]},"1407":{"position":[[522,5]]},"1409":{"position":[[1696,5]]},"1466":{"position":[[173,6],[406,5],[634,6]]},"1468":{"position":[[319,5],[1367,5],[1512,5],[1558,5],[1632,5]]},"1473":{"position":[[328,5]]},"1477":{"position":[[881,5],[948,5]]},"1499":{"position":[[20,6],[252,6],[805,6],[873,6]]},"1505":{"position":[[128,6]]},"1515":{"position":[[22,6]]},"1646":{"position":[[32,5]]},"1667":{"position":[[240,5]]},"1672":{"position":[[83,5]]},"1682":{"position":[[445,5]]},"1684":{"position":[[188,5]]}}}],["scaleai",{"_index":4930,"t":{"1556":{"position":[[9,7]]}}}],["scali",{"_index":2612,"t":{"725":{"position":[[84,6]]},"961":{"position":[[206,6]]}}}],["scalil",{"_index":218,"t":{"35":{"position":[[105,9]]}}}],["scalin",{"_index":4587,"t":{"1409":{"position":[[1640,9]]}}}],["scenario",{"_index":2552,"t":{"709":{"position":[[24,9]]},"1501":{"position":[[23,9]]}}}],["schedul",{"_index":1995,"t":{"550":{"position":[[160,8]]},"602":{"position":[[420,8]]},"803":{"position":[[262,9],[597,8]]},"853":{"position":[[2053,9]]},"861":{"position":[[59,10]]},"866":{"position":[[558,10],[780,10],[821,10],[866,10],[889,10]]},"1314":{"position":[[201,9]]}}}],["schedular",{"_index":1500,"t":{"372":{"position":[[40,9]]}}}],["schema",{"_index":5372,"t":{"1676":{"position":[[514,6]]}}}],["scheme",{"_index":647,"t":{"140":{"position":[[256,6]]}}}],["schick",{"_index":2553,"t":{"709":{"position":[[91,7]]},"1130":{"position":[[417,6]]}}}],["schütze",{"_index":2554,"t":{"709":{"position":[[103,8]]},"1130":{"position":[[428,8]]}}}],["scienc",{"_index":3979,"t":{"1151":{"position":[[1835,9]]}}}],["scienceqa",{"_index":3285,"t":{"885":{"position":[[519,9]]},"887":{"position":[[1095,9]]},"912":{"position":[[213,9]]},"914":{"position":[[48,9]]},"917":{"position":[[65,9]]},"928":{"position":[[233,9]]},"940":{"position":[[338,9]]}}}],["scieneceqa",{"_index":3367,"t":{"895":{"position":[[80,10]]}}}],["scientif",{"_index":3981,"t":{"1151":{"position":[[1993,11]]}}}],["scitail",{"_index":3577,"t":{"997":{"position":[[789,7]]},"1002":{"position":[[483,7]]},"1004":{"position":[[106,7]]},"1006":{"position":[[2708,7]]},"1070":{"position":[[262,7]]},"1084":{"position":[[609,7]]},"1253":{"position":[[314,7]]},"1264":{"position":[[92,7]]}}}],["scolor",{"_index":4702,"t":{"1440":{"position":[[397,7]]}}}],["score",{"_index":933,"t":{"191":{"position":[[136,5],[279,5]]},"193":{"position":[[143,5]]},"199":{"position":[[166,5]]},"319":{"position":[[394,5]]},"336":{"position":[[1396,5]]},"347":{"position":[[248,5],[357,5]]},"352":{"position":[[152,5],[646,5]]},"457":{"position":[[830,6]]},"500":{"position":[[1000,5]]},"512":{"position":[[238,5]]},"525":{"position":[[1511,5]]},"567":{"position":[[592,5]]},"569":{"position":[[445,5],[461,5],[502,5]]},"596":{"position":[[1485,5]]},"630":{"position":[[1677,5]]},"633":{"position":[[90,5]]},"668":{"position":[[506,5]]},"784":{"position":[[489,5]]},"797":{"position":[[171,5],[549,5],[1618,5],[2350,5],[2533,5]]},"801":{"position":[[11,7],[1368,5]]},"828":{"position":[[119,6]]},"837":{"position":[[22,5],[116,5],[255,5]]},"843":{"position":[[65,7]]},"853":{"position":[[575,5],[1067,5],[1268,6],[1408,6],[2389,6]]},"855":{"position":[[146,6]]},"857":{"position":[[337,6],[447,5],[1385,6],[1520,6]]},"859":{"position":[[270,5]]},"861":{"position":[[521,6],[1255,6],[1522,6]]},"893":{"position":[[839,6],[1287,5]]},"963":{"position":[[553,5]]},"986":{"position":[[132,6]]},"988":{"position":[[804,5]]},"1006":{"position":[[721,5]]},"1143":{"position":[[843,5]]},"1244":{"position":[[1293,5]]},"1423":{"position":[[1271,5],[1383,5]]},"1427":{"position":[[773,5],[936,5]]},"1431":{"position":[[1445,5]]},"1445":{"position":[[109,5]]},"1449":{"position":[[149,5],[593,7]]},"1455":{"position":[[122,5]]},"1485":{"position":[[424,5],[444,5],[549,5],[862,5],[925,5],[1056,5],[1122,5]]},"1487":{"position":[[856,5],[1076,5]]},"1499":{"position":[[300,5],[689,5]]},"1501":{"position":[[312,5]]},"1505":{"position":[[278,5],[370,5],[784,5]]},"1521":{"position":[[67,6],[113,5],[163,5]]},"1525":{"position":[[44,6],[128,5]]},"1558":{"position":[[308,5],[416,5]]},"1704":{"position":[[5,5],[26,5],[672,5]]},"1706":{"position":[[12,5]]},"1718":{"position":[[1021,7]]}}}],["scratch",{"_index":3904,"t":{"1130":{"position":[[73,7]]},"1665":{"position":[[67,7]]},"1667":{"position":[[147,7]]}}}],["se",{"_index":248,"t":{"49":{"position":[[151,2]]}}}],["seamlessli",{"_index":5064,"t":{"1606":{"position":[[12,10]]},"1638":{"position":[[12,10]]}}}],["search",{"_index":198,"t":{"27":{"position":[[381,6]]},"38":{"position":[[94,6],[292,6],[398,6]]},"140":{"position":[[147,6]]},"246":{"position":[[52,6],[287,6]]},"324":{"position":[[117,6]]},"326":{"position":[[639,6],[833,6]]},"670":{"position":[[1048,6]]},"690":{"position":[[745,6]]},"705":{"position":[[343,6]]},"713":{"position":[[158,9]]},"828":{"position":[[197,6]]},"870":{"position":[[2253,9]]},"912":{"position":[[164,6]]},"955":{"position":[[296,6],[699,6]]},"1093":{"position":[[1106,9],[1273,9]]},"1095":{"position":[[312,9],[372,9],[435,9]]},"1107":{"position":[[326,9]]},"1109":{"position":[[136,9]]},"1111":{"position":[[1279,6]]},"1126":{"position":[[1114,6]]},"1128":{"position":[[852,6],[881,6]]},"1314":{"position":[[750,6]]},"1425":{"position":[[596,6]]},"1431":{"position":[[1596,6]]},"1496":{"position":[[503,6]]},"1583":{"position":[[171,6]]},"1704":{"position":[[632,6],[657,6]]},"1706":{"position":[[257,8]]},"1718":{"position":[[506,6],[538,6]]},"1730":{"position":[[70,6],[91,6],[518,6],[1026,6],[1119,6]]},"1762":{"position":[[297,6]]},"1782":{"position":[[1193,6]]}}}],["searchqa",{"_index":3575,"t":{"997":{"position":[[712,8]]},"1070":{"position":[[221,8]]},"1253":{"position":[[276,8]]}}}],["second",{"_index":1892,"t":{"527":{"position":[[3058,6]]},"1240":{"position":[[41,6]]},"1397":{"position":[[119,6],[307,6],[1362,6]]}}}],["second_do",{"_index":789,"t":{"170":{"position":[[1641,11]]}}}],["section",{"_index":1836,"t":{"525":{"position":[[1539,7]]},"610":{"position":[[317,7]]},"676":{"position":[[1679,7]]},"709":{"position":[[967,8],[2514,7]]},"801":{"position":[[2671,7]]},"835":{"position":[[0,7]]},"877":{"position":[[251,7]]},"992":{"position":[[305,7]]},"1026":{"position":[[209,8]]},"1126":{"position":[[2040,7],[2114,7],[2239,7],[2405,7]]},"1170":{"position":[[93,8]]},"1172":{"position":[[171,12]]},"1176":{"position":[[144,8]]},"1708":{"position":[[201,7],[352,7],[396,7],[522,7]]}}}],["sectiopn",{"_index":2087,"t":{"594":{"position":[[955,8]]}}}],["see",{"_index":5096,"t":{"1620":{"position":[[84,3],[134,3],[196,3]]}}}],["seed",{"_index":1562,"t":{"397":{"position":[[154,4],[195,4],[211,4]]},"668":{"position":[[440,4]]},"709":{"position":[[141,4]]},"776":{"position":[[21,4]]},"1259":{"position":[[346,4],[418,4]]},"1393":{"position":[[522,4]]},"1427":{"position":[[552,5]]},"1501":{"position":[[68,4]]},"1665":{"position":[[1532,5]]},"1669":{"position":[[774,5]]},"1674":{"position":[[726,4]]},"1682":{"position":[[289,5]]},"1718":{"position":[[254,4]]},"1754":{"position":[[383,4]]}}}],["seen",{"_index":936,"t":{"191":{"position":[[234,4]]},"1323":{"position":[[226,5],[268,4]]}}}],["segment",{"_index":202,"t":{"27":{"position":[[434,12]]},"120":{"position":[[169,12]]},"124":{"position":[[302,13]]},"126":{"position":[[445,12],[460,12],[913,13]]},"128":{"position":[[163,12]]},"130":{"position":[[89,12],[104,12],[790,12]]},"140":{"position":[[480,12]]},"143":{"position":[[160,12]]},"151":{"position":[[27,13]]},"153":{"position":[[366,12]]},"155":{"position":[[713,12]]},"157":{"position":[[67,13],[286,12]]},"159":{"position":[[826,12]]},"163":{"position":[[637,14],[710,13]]},"165":{"position":[[93,12],[238,12],[274,12],[451,12],[494,12],[620,12],[1465,13]]},"168":{"position":[[102,13]]},"177":{"position":[[763,13]]},"185":{"position":[[101,12]]},"221":{"position":[[643,9]]},"225":{"position":[[134,12]]},"227":{"position":[[328,12]]},"275":{"position":[[22,12]]},"339":{"position":[[582,13]]},"343":{"position":[[229,13]]}}}],["select",{"_index":1683,"t":{"461":{"position":[[71,9]]},"1665":{"position":[[921,9]]},"1682":{"position":[[546,9]]},"1738":{"position":[[305,9]]},"1768":{"position":[[367,9]]}}}],["self",{"_index":377,"t":{"86":{"position":[[25,4]]},"88":{"position":[[47,4],[87,4],[126,4],[197,4],[276,4],[386,4],[424,4],[464,4],[501,4]]},"91":{"position":[[1350,4]]},"93":{"position":[[59,4]]},"116":{"position":[[601,4],[749,4]]},"118":{"position":[[12,4],[83,4],[107,4]]},"120":{"position":[[204,4]]},"174":{"position":[[307,4]]},"215":{"position":[[357,4]]},"232":{"position":[[0,4],[239,4]]},"287":{"position":[[346,4],[824,4]]},"289":{"position":[[450,4]]},"292":{"position":[[91,4]]},"294":{"position":[[254,4]]},"302":{"position":[[339,4],[368,4],[537,4],[619,4]]},"310":{"position":[[197,4],[356,4],[873,4],[1158,4],[1757,4],[1820,4]]},"336":{"position":[[1068,4],[1191,4],[1234,4]]},"343":{"position":[[0,4],[164,4],[449,4],[512,4]]},"345":{"position":[[167,4]]},"352":{"position":[[96,4],[493,4]]},"498":{"position":[[259,4]]},"500":{"position":[[235,4],[266,4],[552,4]]},"504":{"position":[[476,4]]},"527":{"position":[[518,4],[544,4]]},"561":{"position":[[101,5]]},"598":{"position":[[1216,4],[2171,5],[3178,4]]},"600":{"position":[[153,4]]},"633":{"position":[[680,4]]},"662":{"position":[[1469,4]]},"681":{"position":[[1181,4],[1529,4],[1938,4]]},"696":{"position":[[1656,4]]},"721":{"position":[[114,4]]},"739":{"position":[[40,4]]},"755":{"position":[[0,4]]},"786":{"position":[[2690,4]]},"809":{"position":[[367,4]]},"857":{"position":[[578,4],[625,4]]},"885":{"position":[[103,4]]},"1060":{"position":[[600,4]]},"1132":{"position":[[1453,4]]},"1187":{"position":[[354,4]]},"1442":{"position":[[453,4],[652,4],[999,4],[1040,4],[1446,4],[2041,4],[2069,4]]},"1445":{"position":[[131,4],[155,4]]},"1451":{"position":[[6,4],[84,4],[256,4],[766,4]]},"1453":{"position":[[231,4]]},"1455":{"position":[[297,4],[481,4]]},"1682":{"position":[[673,4]]},"1778":{"position":[[163,4],[267,4],[284,4],[314,4],[350,4],[582,4]]}}}],["semant",{"_index":676,"t":{"147":{"position":[[130,8]]},"225":{"position":[[547,8]]},"227":{"position":[[680,8]]},"230":{"position":[[194,8]]},"275":{"position":[[84,8],[115,8]]},"339":{"position":[[573,8]]},"343":{"position":[[220,8]]},"891":{"position":[[452,9]]},"893":{"position":[[1623,9]]},"940":{"position":[[158,9]]},"1041":{"position":[[113,8]]},"1045":{"position":[[75,8]]},"1151":{"position":[[482,8],[1113,8]]},"1409":{"position":[[1340,8],[1777,8]]},"1425":{"position":[[436,8]]},"1427":{"position":[[1033,8]]},"1429":{"position":[[212,8],[1522,8]]},"1442":{"position":[[480,10]]},"1449":{"position":[[160,8]]},"1646":{"position":[[60,9],[1531,8],[2340,9],[2480,9]]},"1651":{"position":[[284,9],[891,9]]},"1655":{"position":[[2165,9]]},"1762":{"position":[[487,8],[517,8]]},"1764":{"position":[[0,8],[85,8]]}}}],["semi",{"_index":540,"t":{"110":{"position":[[69,4]]},"213":{"position":[[395,4]]},"326":{"position":[[433,4],[514,4],[797,4]]},"343":{"position":[[20,4]]},"352":{"position":[[112,4]]}}}],["sens",{"_index":2084,"t":{"594":{"position":[[901,5]]},"1111":{"position":[[225,5]]},"1113":{"position":[[465,5]]}}}],["sensit",{"_index":2948,"t":{"801":{"position":[[60,11],[95,11],[281,11],[949,11],[1313,11],[1478,11],[1532,11],[2180,11],[2693,11]]},"837":{"position":[[63,11],[165,11]]},"1115":{"position":[[16,9]]},"1762":{"position":[[501,11]]}}}],["sentenc",{"_index":972,"t":{"215":{"position":[[131,8]]},"287":{"position":[[519,8]]},"313":{"position":[[9,8],[264,8]]},"326":{"position":[[275,9],[365,9]]},"529":{"position":[[2311,8]]},"594":{"position":[[752,8]]},"658":{"position":[[869,8]]},"683":{"position":[[234,8]]},"812":{"position":[[91,8]]},"951":{"position":[[304,9]]},"1099":{"position":[[499,8],[540,8]]},"1303":{"position":[[203,8],[547,10]]},"1419":{"position":[[491,8]]},"1427":{"position":[[1020,9]]},"1646":{"position":[[2331,8]]},"1651":{"position":[[69,8],[154,8],[241,8]]},"1655":{"position":[[216,8],[428,8]]},"1659":{"position":[[485,8]]},"1665":{"position":[[594,8]]},"1724":{"position":[[166,8]]},"1778":{"position":[[937,9]]},"1782":{"position":[[1939,9]]}}}],["sentencepiec",{"_index":3941,"t":{"1141":{"position":[[206,13]]}}}],["sentiment",{"_index":3568,"t":{"997":{"position":[[86,9]]},"1014":{"position":[[416,9]]},"1393":{"position":[[45,9]]},"1419":{"position":[[715,9]]},"1429":{"position":[[1450,9]]},"1644":{"position":[[119,9]]},"1655":{"position":[[167,9]]},"1698":{"position":[[328,9]]},"1702":{"position":[[280,9]]},"1802":{"position":[[489,10],[534,10],[568,13],[658,10],[703,10],[741,12]]}}}],["sentinel",{"_index":3910,"t":{"1132":{"position":[[133,8],[241,8],[264,8],[888,8],[1023,8],[1055,8],[1328,8],[1375,8]]},"1143":{"position":[[140,8],[185,8],[247,8]]}}}],["separ",{"_index":1297,"t":{"310":{"position":[[1631,9]]},"600":{"position":[[183,8]]},"893":{"position":[[1920,8]]},"1095":{"position":[[445,8]]},"1738":{"position":[[681,9]]}}}],["seq2seq",{"_index":1734,"t":{"494":{"position":[[133,7]]},"506":{"position":[[50,7]]},"508":{"position":[[69,7]]},"1772":{"position":[[382,7],[459,7]]},"1776":{"position":[[65,7]]},"1778":{"position":[[188,7]]},"1782":{"position":[[2131,7]]}}}],["sequenc",{"_index":401,"t":{"91":{"position":[[46,8],[197,8],[425,8],[1295,8]]},"95":{"position":[[23,8],[199,8]]},"97":{"position":[[282,8]]},"104":{"position":[[146,8],[434,8],[518,8]]},"120":{"position":[[63,8]]},"124":{"position":[[175,8]]},"126":{"position":[[832,8],[1156,8]]},"130":{"position":[[217,8],[405,8]]},"132":{"position":[[22,8],[84,8],[251,8]]},"134":{"position":[[15,8]]},"136":{"position":[[30,8]]},"138":{"position":[[104,8]]},"140":{"position":[[636,8]]},"145":{"position":[[18,8]]},"149":{"position":[[328,8]]},"159":{"position":[[64,8],[603,8]]},"174":{"position":[[1912,8]]},"215":{"position":[[157,8]]},"225":{"position":[[189,8],[301,8]]},"283":{"position":[[4,8]]},"285":{"position":[[91,9],[226,8]]},"287":{"position":[[378,8],[589,8],[749,8]]},"289":{"position":[[7,8],[103,8],[179,8],[273,8]]},"302":{"position":[[210,8],[257,8],[269,8]]},"306":{"position":[[3,8]]},"308":{"position":[[41,8],[64,8],[1011,8]]},"310":{"position":[[43,8],[102,8],[237,8],[248,8],[508,8],[668,9],[1023,8],[1118,8],[1181,8]]},"313":{"position":[[281,8]]},"326":{"position":[[179,8],[191,8],[937,8],[949,8]]},"328":{"position":[[42,8]]},"494":{"position":[[87,8],[168,8],[218,8]]},"500":{"position":[[428,8]]},"502":{"position":[[187,8],[322,8]]},"510":{"position":[[50,8]]},"550":{"position":[[229,8],[293,8]]},"596":{"position":[[238,8],[278,8],[769,8],[820,8],[976,8],[1195,8],[1666,8]]},"598":{"position":[[510,8],[1001,8],[2495,8]]},"602":{"position":[[466,8]]},"608":{"position":[[891,8],[1010,8]]},"612":{"position":[[98,8]]},"633":{"position":[[142,8],[154,8]]},"644":{"position":[[125,8],[260,8]]},"666":{"position":[[115,8]]},"686":{"position":[[163,8],[360,8]]},"688":{"position":[[155,8]]},"692":{"position":[[203,8]]},"694":{"position":[[156,8]]},"719":{"position":[[286,8]]},"723":{"position":[[307,8]]},"729":{"position":[[86,8],[141,8]]},"735":{"position":[[140,8]]},"759":{"position":[[144,8]]},"780":{"position":[[83,8]]},"789":{"position":[[143,8]]},"819":{"position":[[98,8]]},"984":{"position":[[227,8],[503,8]]},"988":{"position":[[393,8]]},"1008":{"position":[[594,8]]},"1012":{"position":[[260,8]]},"1014":{"position":[[820,8],[955,8],[1556,8]]},"1017":{"position":[[99,8],[129,8]]},"1019":{"position":[[262,8],[641,8]]},"1026":{"position":[[62,8],[108,8],[152,8],[288,8]]},"1028":{"position":[[73,8],[129,8]]},"1033":{"position":[[162,8]]},"1037":{"position":[[73,8]]},"1060":{"position":[[334,9],[543,8],[629,8],[737,8]]},"1062":{"position":[[707,8],[760,8],[1553,8]]},"1065":{"position":[[282,8]]},"1067":{"position":[[1181,8]]},"1099":{"position":[[62,8]]},"1128":{"position":[[330,8]]},"1145":{"position":[[328,8],[1776,8]]},"1151":{"position":[[1756,8]]},"1164":{"position":[[83,8]]},"1167":{"position":[[190,8],[217,8]]},"1185":{"position":[[0,8]]},"1187":{"position":[[149,8]]},"1238":{"position":[[547,8]]},"1244":{"position":[[1772,8]]},"1289":{"position":[[331,8]]},"1291":{"position":[[1175,8],[1300,8]]},"1294":{"position":[[41,8]]},"1296":{"position":[[244,8]]},"1305":{"position":[[303,8]]},"1330":{"position":[[0,8]]},"1347":{"position":[[640,8],[762,8]]},"1350":{"position":[[18,8],[30,8],[193,8],[231,8]]},"1369":{"position":[[227,8]]},"1384":{"position":[[1215,8]]},"1421":{"position":[[116,8]]},"1477":{"position":[[649,8]]},"1728":{"position":[[186,8]]},"1736":{"position":[[1340,8]]},"1768":{"position":[[306,8]]},"1782":{"position":[[2817,8]]}}}],["sequenti",{"_index":1284,"t":{"310":{"position":[[917,10],[983,10]]},"1151":{"position":[[1684,10]]},"1440":{"position":[[493,11]]},"1442":{"position":[[1574,10]]}}}],["seri",{"_index":1522,"t":{"382":{"position":[[49,6]]}}}],["serial",{"_index":2345,"t":{"662":{"position":[[557,6]]}}}],["serv",{"_index":130,"t":{"19":{"position":[[274,6]]},"1124":{"position":[[413,5]]},"1126":{"position":[[1833,7]]},"1153":{"position":[[444,7],[536,7]]},"1291":{"position":[[1102,6]]},"1600":{"position":[[44,5],[74,6]]}}}],["server",{"_index":119,"t":{"19":{"position":[[20,7],[306,7]]}}}],["set",{"_index":988,"t":{"215":{"position":[[633,7]]},"324":{"position":[[96,3],[269,7]]},"326":{"position":[[449,7],[530,7],[580,3]]},"483":{"position":[[250,3]]},"488":{"position":[[333,5]]},"523":{"position":[[479,3]]},"525":{"position":[[655,3]]},"529":{"position":[[429,3],[440,3],[513,3],[597,3],[2599,3]]},"531":{"position":[[54,3],[594,7]]},"587":{"position":[[366,3]]},"589":{"position":[[297,3],[1678,3]]},"592":{"position":[[447,8]]},"594":{"position":[[1009,3],[1421,3],[1439,3]]},"596":{"position":[[2391,7]]},"598":{"position":[[1161,3],[1967,3],[3942,7]]},"602":{"position":[[746,4],[774,7]]},"610":{"position":[[364,3]]},"618":{"position":[[170,3],[258,3],[270,3]]},"630":{"position":[[1740,3]]},"658":{"position":[[214,7],[1229,3]]},"666":{"position":[[428,3]]},"668":{"position":[[468,3]]},"670":{"position":[[767,3],[1523,3]]},"674":{"position":[[100,3]]},"676":{"position":[[85,3]]},"681":{"position":[[1488,3]]},"694":{"position":[[74,3]]},"709":{"position":[[72,7],[197,3],[228,3]]},"711":{"position":[[178,3]]},"723":{"position":[[706,3],[1024,3]]},"784":{"position":[[943,7]]},"786":{"position":[[4589,7]]},"789":{"position":[[763,3]]},"797":{"position":[[565,3]]},"816":{"position":[[11,7],[55,3]]},"823":{"position":[[12,8]]},"861":{"position":[[641,7],[1655,7]]},"938":{"position":[[198,3]]},"965":{"position":[[54,3]]},"988":{"position":[[58,3]]},"992":{"position":[[279,3]]},"1045":{"position":[[67,4]]},"1070":{"position":[[1671,3]]},"1107":{"position":[[443,3],[462,3],[473,3]]},"1111":{"position":[[712,3],[880,3]]},"1134":{"position":[[494,3]]},"1136":{"position":[[549,3]]},"1157":{"position":[[556,8]]},"1159":{"position":[[1962,8]]},"1242":{"position":[[825,3]]},"1259":{"position":[[434,3]]},"1291":{"position":[[394,3]]},"1305":{"position":[[961,3]]},"1341":{"position":[[442,3]]},"1357":{"position":[[75,3],[118,3],[129,3],[156,3],[191,3]]},"1364":{"position":[[400,7]]},"1393":{"position":[[401,3],[425,3],[474,3],[485,3],[561,3],[589,3]]},"1397":{"position":[[100,3]]},"1401":{"position":[[625,3]]},"1417":{"position":[[26,3],[101,3]]},"1419":{"position":[[89,3]]},"1425":{"position":[[178,3]]},"1431":{"position":[[177,3]]},"1468":{"position":[[853,3]]},"1475":{"position":[[191,3]]},"1483":{"position":[[118,3]]},"1492":{"position":[[150,3],[220,3]]},"1496":{"position":[[590,3]]},"1501":{"position":[[93,3]]},"1646":{"position":[[742,3],[952,3],[996,3],[1099,3]]},"1651":{"position":[[439,3],[826,3]]},"1655":{"position":[[119,3],[781,3],[1200,3],[1681,3]]},"1657":{"position":[[1131,3],[2404,3]]},"1663":{"position":[[176,3],[192,3],[203,3],[286,3]]},"1665":{"position":[[1475,3]]},"1669":{"position":[[555,7],[582,3],[592,3],[683,3]]},"1676":{"position":[[165,3]]},"1689":{"position":[[234,3]]},"1698":{"position":[[285,3],[390,3]]},"1714":{"position":[[592,7]]},"1730":{"position":[[277,3]]},"1746":{"position":[[151,7]]},"1802":{"position":[[1201,3]]}}}],["setenc",{"_index":1379,"t":{"326":{"position":[[988,8]]}}}],["setiment",{"_index":5160,"t":{"1646":{"position":[[1064,8]]}}}],["setup",{"_index":368,"t":{"80":{"position":[[0,5]]},"475":{"position":[[290,5]]},"1159":{"position":[[1149,5]]},"1357":{"position":[[374,6]]},"1377":{"position":[[366,5]]},"1379":{"position":[[1191,5]]},"1393":{"position":[[5,6],[203,6]]},"1395":{"position":[[908,5],[2973,5]]}}}],["setups(zero/few",{"_index":1975,"t":{"537":{"position":[[233,15]]}}}],["sever",{"_index":5341,"t":{"1665":{"position":[[665,7]]}}}],["sf",{"_index":1987,"t":{"544":{"position":[[161,2]]},"548":{"position":[[11,2]]},"557":{"position":[[92,2]]}}}],["sft",{"_index":4915,"t":{"1546":{"position":[[407,5]]},"1552":{"position":[[422,3],[439,3]]},"1558":{"position":[[159,5],[324,3],[335,3],[471,3],[1149,3],[1233,3],[2080,3]]},"1570":{"position":[[309,3]]}}}],["sft+rlhf",{"_index":4975,"t":{"1577":{"position":[[18,13]]}}}],["sft\\pi^{sft}πsft",{"_index":4959,"t":{"1558":{"position":[[1822,17]]}}}],["sgd",{"_index":529,"t":{"106":{"position":[[141,3]]},"372":{"position":[[0,3]]},"1101":{"position":[[214,5]]}}}],["shalev",{"_index":1921,"t":{"529":{"position":[[2196,7]]}}}],["shallow",{"_index":1727,"t":{"485":{"position":[[1348,8],[1426,7]]},"504":{"position":[[253,8]]},"1157":{"position":[[227,7]]},"1159":{"position":[[1332,7]]},"1167":{"position":[[4,7],[447,7]]}}}],["shape",{"_index":5435,"t":{"1710":{"position":[[184,5]]},"1720":{"position":[[1865,5]]},"1722":{"position":[[110,5]]},"1724":{"position":[[216,5]]}}}],["shard",{"_index":1099,"t":{"244":{"position":[[41,8]]}}}],["share",{"_index":597,"t":{"126":{"position":[[994,6],[1032,6]]},"656":{"position":[[306,7]]},"658":{"position":[[343,7],[2742,6]]},"719":{"position":[[865,6]]},"953":{"position":[[397,6]]},"982":{"position":[[1167,6]]},"997":{"position":[[623,6]]},"999":{"position":[[498,6]]},"1035":{"position":[[42,6]]},"1070":{"position":[[182,6]]},"1075":{"position":[[10,6]]},"1124":{"position":[[403,7]]},"1149":{"position":[[334,7]]},"1159":{"position":[[1513,6]]},"1170":{"position":[[179,6]]},"1176":{"position":[[32,6],[159,6],[218,7]]},"1208":{"position":[[73,7],[190,7]]},"1225":{"position":[[452,6]]},"1227":{"position":[[853,6],[960,6],[1021,6],[1160,6]]},"1230":{"position":[[868,6]]},"1232":{"position":[[229,7]]},"1236":{"position":[[609,6]]},"1240":{"position":[[137,6],[151,7],[324,6]]},"1242":{"position":[[65,7],[273,6],[516,6]]},"1244":{"position":[[65,6],[543,6],[575,6],[1900,6]]},"1246":{"position":[[291,6],[598,6]]},"1248":{"position":[[44,6]]},"1259":{"position":[[240,6]]},"1270":{"position":[[61,6],[225,6]]},"1273":{"position":[[135,6],[288,6]]},"1279":{"position":[[24,6],[59,6],[164,6]]},"1285":{"position":[[183,6],[272,6]]},"1339":{"position":[[153,6],[261,6]]},"1421":{"position":[[137,6]]},"1794":{"position":[[834,7],[946,7]]}}}],["shared/specif",{"_index":4130,"t":{"1240":{"position":[[246,15]]}}}],["sharegpt",{"_index":3448,"t":{"959":{"position":[[177,8]]}}}],["shazeer",{"_index":4360,"t":{"1347":{"position":[[1260,8]]},"1401":{"position":[[568,7]]}}}],["shelf",{"_index":1539,"t":{"386":{"position":[[479,5]]},"436":{"position":[[965,5],[1284,5],[2106,5]]},"447":{"position":[[884,5]]},"453":{"position":[[8,5]]},"483":{"position":[[643,5]]},"504":{"position":[[93,5]]}}}],["shen",{"_index":3091,"t":{"851":{"position":[[185,8],[240,5]]}}}],["shi",{"_index":3735,"t":{"1084":{"position":[[313,3]]}}}],["shift",{"_index":3876,"t":{"1126":{"position":[[2332,6],[2609,5]]},"1147":{"position":[[209,5],[607,5],[699,5]]},"1517":{"position":[[305,6]]}}}],["shin",{"_index":3871,"t":{"1126":{"position":[[1026,5]]}}}],["shop",{"_index":4234,"t":{"1291":{"position":[[1051,6]]}}}],["short",{"_index":586,"t":{"124":{"position":[[514,5]]},"951":{"position":[[188,5]]},"1345":{"position":[[212,5],[346,5]]},"1347":{"position":[[878,5],[977,5],[1028,5],[1127,5],[1425,5],[1499,5],[1765,5],[1969,5]]},"1352":{"position":[[18,5]]},"1360":{"position":[[168,5]]},"1369":{"position":[[705,5]]},"1371":{"position":[[0,5],[154,5]]},"1453":{"position":[[23,5],[83,5],[205,5]]}}}],["short.1.pdf",{"_index":1808,"t":{"519":{"position":[[48,11]]}}}],["shorter",{"_index":2119,"t":{"596":{"position":[[1296,7]]},"1060":{"position":[[849,7]]},"1062":{"position":[[1083,7],[1214,7]]},"1067":{"position":[[140,7],[1167,7],[1331,7]]},"1347":{"position":[[2015,7]]}}}],["shot",{"_index":533,"t":{"108":{"position":[[4,4],[207,4]]},"112":{"position":[[374,4]]},"219":{"position":[[376,4]]},"251":{"position":[[30,4]]},"253":{"position":[[4,4],[231,4],[277,4],[344,4]]},"273":{"position":[[5,4],[101,4]]},"334":{"position":[[258,5],[268,4],[651,4],[666,4]]},"336":{"position":[[687,4],[1976,4],[1990,4]]},"341":{"position":[[437,4]]},"376":{"position":[[296,4]]},"384":{"position":[[393,4],[648,4],[777,4]]},"386":{"position":[[144,4],[443,4]]},"393":{"position":[[63,4]]},"395":{"position":[[19,4],[113,4]]},"409":{"position":[[75,4]]},"414":{"position":[[38,4],[117,4]]},"426":{"position":[[441,4]]},"434":{"position":[[49,4],[102,4],[310,4],[602,4]]},"436":{"position":[[256,4],[435,4],[1235,4],[1302,4],[1650,4],[1674,4],[1813,4],[2123,4],[2259,4],[2321,4]]},"443":{"position":[[153,4]]},"445":{"position":[[170,4],[292,4],[338,4]]},"447":{"position":[[11,4],[411,4],[486,4],[561,4],[917,4]]},"451":{"position":[[207,4]]},"461":{"position":[[8,4],[19,4]]},"466":{"position":[[480,4]]},"468":{"position":[[62,4],[155,4],[171,4]]},"471":{"position":[[15,4],[187,4]]},"475":{"position":[[46,4],[285,4]]},"477":{"position":[[91,4],[134,4]]},"483":{"position":[[759,5]]},"485":{"position":[[1611,5]]},"537":{"position":[[249,5]]},"539":{"position":[[403,4],[460,5],[470,4]]},"544":{"position":[[36,4]]},"548":{"position":[[129,4]]},"555":{"position":[[11,6],[29,5],[114,5],[183,5]]},"559":{"position":[[231,4]]},"561":{"position":[[393,4]]},"565":{"position":[[78,4],[256,4]]},"569":{"position":[[243,4],[267,4],[321,4],[677,4],[756,4],[827,4],[1113,4]]},"571":{"position":[[120,5],[131,4]]},"587":{"position":[[4,4],[396,4]]},"589":{"position":[[462,4],[612,4],[2203,4]]},"592":{"position":[[442,4]]},"594":{"position":[[307,4],[585,4],[1040,4]]},"596":{"position":[[25,4],[2386,4]]},"598":{"position":[[4,4],[125,4],[3033,4],[3937,4]]},"600":{"position":[[74,4]]},"602":{"position":[[760,4]]},"604":{"position":[[61,4]]},"606":{"position":[[71,4],[107,4],[119,4],[165,4],[240,4],[313,4],[387,4],[415,4]]},"608":{"position":[[53,4],[705,4],[939,4]]},"610":{"position":[[16,4],[209,4]]},"612":{"position":[[253,4],[367,4]]},"618":{"position":[[4,4]]},"622":{"position":[[24,4],[98,4],[489,4],[700,4]]},"973":{"position":[[176,4],[216,4],[414,4]]},"979":{"position":[[1566,4],[1601,6]]},"1004":{"position":[[121,4],[390,4]]},"1039":{"position":[[330,4]]},"1060":{"position":[[1141,4]]},"1062":{"position":[[1739,4]]},"1070":{"position":[[1634,4],[1695,4]]},"1084":{"position":[[4,4],[36,4],[142,4],[361,4],[444,4],[706,4],[755,4]]},"1091":{"position":[[440,4]]},"1093":{"position":[[1315,4],[1456,4],[1709,4],[1782,4]]},"1095":{"position":[[137,4]]},"1111":{"position":[[277,4],[430,4],[454,4],[937,4],[1045,4],[1590,4],[1811,4],[1947,4],[1972,4]]},"1115":{"position":[[84,4],[269,4],[519,4],[648,4],[691,4],[1040,4],[1181,4]]},"1124":{"position":[[278,4]]},"1126":{"position":[[382,4],[920,4],[1684,4]]},"1130":{"position":[[360,4]]},"1132":{"position":[[1760,4]]},"1136":{"position":[[567,4]]},"1145":{"position":[[1771,4]]},"1147":{"position":[[291,4],[976,4]]},"1153":{"position":[[192,4]]},"1157":{"position":[[551,4]]},"1159":{"position":[[618,4],[1957,4]]},"1227":{"position":[[1592,4]]},"1232":{"position":[[187,4],[198,4]]},"1250":{"position":[[84,4]]},"1259":{"position":[[378,4],[392,4]]},"1264":{"position":[[106,4],[161,4]]},"1395":{"position":[[1610,4]]},"1409":{"position":[[326,4]]},"1501":{"position":[[131,4],[354,4]]},"1552":{"position":[[257,4]]},"1669":{"position":[[445,4],[529,4],[550,4],[964,4]]},"1674":{"position":[[540,4],[568,5],[576,5],[584,5],[592,5],[601,4],[649,4]]},"1682":{"position":[[126,4],[136,4]]},"1693":{"position":[[436,4]]},"1714":{"position":[[157,4],[323,4],[384,4],[509,4],[578,4]]},"1720":{"position":[[1300,4]]},"1730":{"position":[[1073,4]]},"1738":{"position":[[222,4],[340,4]]},"1746":{"position":[[5,4],[137,4],[208,4],[407,4]]},"1752":{"position":[[322,4]]},"1754":{"position":[[256,4],[323,4]]},"1756":{"position":[[114,4],[494,4]]},"1764":{"position":[[80,4]]},"1766":{"position":[[373,4],[574,4]]},"1774":{"position":[[321,4],[372,4]]},"1780":{"position":[[203,4]]},"1782":{"position":[[300,4],[578,4]]},"1798":{"position":[[74,4],[173,4]]}}}],["showcas",{"_index":4998,"t":{"1583":{"position":[[218,8]]}}}],["shwartz",{"_index":1922,"t":{"529":{"position":[[2204,7]]}}}],["si",{"_index":258,"t":{"49":{"position":[[301,2]]}}}],["si,j(t)=−αswi,j∑t<t(∂l∂wi,j′)(t)\\begin{equ",{"_index":3160,"t":{"855":{"position":[[174,48]]}}}],["si,j(t)=−αs∑t<t(∂l∂wi,j)(t)wi,j(t)\\begin{equ",{"_index":3139,"t":{"853":{"position":[[1436,50]]}}}],["si,j(t)=∣wi,j(t)∣=∣wi,j−αw∑t<t(∂l∂wi,j)(t)∣\\begin{equ",{"_index":3122,"t":{"853":{"position":[[639,59]]}}}],["si,j<0s_{i,j",{"_index":3226,"t":{"861":{"position":[[1276,13]]}}}],["si,js_{i,j}si,j",{"_index":3165,"t":{"855":{"position":[[524,16]]},"861":{"position":[[1305,16]]}}}],["si,jts^{t}_{i,j}si,jt",{"_index":3132,"t":{"853":{"position":[[975,22]]}}}],["side",{"_index":2298,"t":{"648":{"position":[[727,4]]},"1070":{"position":[[1284,4]]},"1230":{"position":[[360,4]]},"1384":{"position":[[3072,4]]}}}],["sidebar",{"_index":5034,"t":{"1591":{"position":[[51,7]]},"1595":{"position":[[35,7],[95,7],[271,7]]}}}],["sidebar_label",{"_index":5041,"t":{"1595":{"position":[[141,14]]}}}],["sidebar_posit",{"_index":5043,"t":{"1595":{"position":[[162,17]]}}}],["sidebars.j",{"_index":5045,"t":{"1595":{"position":[[293,12],[306,11]]}}}],["sidetun",{"_index":2456,"t":{"683":{"position":[[764,10]]}}}],["sigma",{"_index":3197,"t":{"857":{"position":[[1259,8]]},"861":{"position":[[1425,6]]}}}],["sigmoid",{"_index":3196,"t":{"857":{"position":[[1251,7]]},"1389":{"position":[[1389,7]]}}}],["signal",{"_index":993,"t":{"215":{"position":[[967,6]]},"221":{"position":[[578,7],[619,7]]},"225":{"position":[[448,7]]},"227":{"position":[[255,8],[304,8],[689,6]]},"267":{"position":[[164,6]]},"310":{"position":[[622,7]]},"500":{"position":[[368,6]]},"893":{"position":[[2523,7]]},"979":{"position":[[1984,6]]},"1124":{"position":[[205,7]]},"1126":{"position":[[1667,7]]},"1440":{"position":[[280,6],[464,6],[682,7]]},"1442":{"position":[[500,6],[1076,6]]},"1451":{"position":[[191,7],[429,6],[833,6]]},"1782":{"position":[[1734,6],[2072,7]]}}}],["significantli",{"_index":4612,"t":{"1423":{"position":[[5,13]]}}}],["silu",{"_index":3534,"t":{"988":{"position":[[1380,4]]}}}],["sim",{"_index":4411,"t":{"1354":{"position":[[329,4]]},"1485":{"position":[[647,4]]},"1487":{"position":[[947,4]]},"1558":{"position":[[757,4],[1528,4],[1640,4]]}}}],["sim(es,et)sim(e^",{"_index":4655,"t":{"1431":{"position":[[325,18]]}}}],["sim(t1,t2)=1l2∑i∑jcos⁡(ej1,ej2),sim(t^1",{"_index":4647,"t":{"1429":{"position":[[961,40]]}}}],["sim(t1,t2)=cos⁡(1l∑iei1,l∑iei2),sim(t^1",{"_index":4638,"t":{"1429":{"position":[[601,40]]}}}],["sim(v,q)\\textup{sim}(v",{"_index":1667,"t":{"457":{"position":[[620,23],[849,23]]}}}],["simiar",{"_index":2251,"t":{"628":{"position":[[1505,9]]},"893":{"position":[[1052,11]]},"1409":{"position":[[1444,9],[1877,9]]}}}],["similar",{"_index":929,"t":{"191":{"position":[[69,10]]},"199":{"position":[[99,10]]},"350":{"position":[[817,10]]},"436":{"position":[[1638,7]]},"500":{"position":[[989,10]]},"628":{"position":[[778,10]]},"774":{"position":[[460,10],[1145,10]]},"776":{"position":[[54,10]]},"812":{"position":[[124,10]]},"979":{"position":[[1366,12],[1883,12]]},"1060":{"position":[[670,10]]},"1151":{"position":[[315,10],[755,7]]},"1227":{"position":[[636,10]]},"1230":{"position":[[646,10]]},"1234":{"position":[[164,10]]},"1238":{"position":[[1203,10]]},"1270":{"position":[[171,10],[328,10]]},"1393":{"position":[[73,10]]},"1419":{"position":[[703,11]]},"1425":{"position":[[409,7],[484,10]]},"1429":{"position":[[407,10],[464,10],[500,10],[587,10],[832,10],[868,10],[947,10],[1160,10],[1228,10],[1364,10],[1531,10],[1730,10],[1876,10]]},"1431":{"position":[[314,10],[1645,10],[1725,10],[1813,10],[2089,10],[2179,10],[2232,11],[2478,10],[2531,10]]},"1436":{"position":[[214,10],[242,10]]},"1762":{"position":[[526,10]]}}}],["simpl",{"_index":337,"t":{"63":{"position":[[198,6]]},"287":{"position":[[660,6]]},"587":{"position":[[677,6]]},"799":{"position":[[254,6]]},"1017":{"position":[[20,6]]},"1442":{"position":[[881,6]]},"1597":{"position":[[85,6]]},"1646":{"position":[[2764,6]]},"1649":{"position":[[83,6]]}}}],["simpli",{"_index":35,"t":{"7":{"position":[[61,6]]},"1236":{"position":[[352,7]]}}}],["simplic",{"_index":2645,"t":{"739":{"position":[[136,10]]}}}],["simplifi",{"_index":5386,"t":{"1682":{"position":[[900,10]]}}}],["simvlm",{"_index":1119,"t":{"251":{"position":[[146,6]]}}}],["sin(po",{"_index":1263,"t":{"308":{"position":[[414,7]]}}}],["singal",{"_index":3414,"t":{"928":{"position":[[148,6]]}}}],["singl",{"_index":212,"t":{"33":{"position":[[163,6]]},"126":{"position":[[987,6]]},"140":{"position":[[669,6]]},"143":{"position":[[551,6]]},"153":{"position":[[674,6]]},"155":{"position":[[50,6],[71,6],[353,6]]},"159":{"position":[[794,6]]},"165":{"position":[[577,6]]},"170":{"position":[[1760,7]]},"230":{"position":[[142,6]]},"283":{"position":[[228,7]]},"298":{"position":[[762,6]]},"300":{"position":[[66,6],[528,6],[1384,6]]},"310":{"position":[[1317,6]]},"322":{"position":[[292,6],[475,6]]},"324":{"position":[[240,6]]},"376":{"position":[[211,6]]},"384":{"position":[[1085,6]]},"397":{"position":[[244,6]]},"483":{"position":[[157,6]]},"550":{"position":[[222,6]]},"589":{"position":[[308,6],[658,6],[779,6]]},"598":{"position":[[2590,6]]},"608":{"position":[[1041,6]]},"610":{"position":[[79,6]]},"612":{"position":[[281,6],[407,6],[454,6]]},"614":{"position":[[67,6]]},"616":{"position":[[250,6]]},"622":{"position":[[545,6]]},"658":{"position":[[3179,7]]},"670":{"position":[[900,6]]},"676":{"position":[[235,6],[295,6]]},"801":{"position":[[114,6],[881,6]]},"812":{"position":[[84,6]]},"959":{"position":[[23,6]]},"979":{"position":[[1218,6]]},"999":{"position":[[270,6]]},"1006":{"position":[[775,6],[847,6],[1303,6]]},"1014":{"position":[[626,6]]},"1049":{"position":[[260,6]]},"1082":{"position":[[0,6]]},"1107":{"position":[[30,6]]},"1126":{"position":[[1752,6]]},"1128":{"position":[[215,6],[1774,6]]},"1139":{"position":[[158,6],[210,6]]},"1145":{"position":[[438,6],[1106,6]]},"1149":{"position":[[704,6]]},"1225":{"position":[[375,6]]},"1227":{"position":[[836,6]]},"1230":{"position":[[861,6]]},"1232":{"position":[[21,6]]},"1236":{"position":[[310,6],[384,6],[628,6]]},"1240":{"position":[[61,6]]},"1244":{"position":[[1893,6]]},"1246":{"position":[[27,6],[284,6]]},"1248":{"position":[[137,6],[290,6]]},"1270":{"position":[[265,7]]},"1285":{"position":[[137,6]]},"1303":{"position":[[189,6]]},"1345":{"position":[[417,6]]},"1364":{"position":[[324,8]]},"1377":{"position":[[591,6]]},"1379":{"position":[[1517,6]]},"1389":{"position":[[433,6]]},"1409":{"position":[[299,6]]},"1411":{"position":[[356,6],[406,6]]},"1419":{"position":[[113,6],[362,6],[460,6]]},"1423":{"position":[[641,6]]},"1442":{"position":[[1642,6]]},"1659":{"position":[[61,6],[357,6]]},"1706":{"position":[[162,6]]},"1730":{"position":[[643,6]]},"1734":{"position":[[24,6]]},"1736":{"position":[[549,6]]},"1790":{"position":[[349,6]]},"1794":{"position":[[851,6]]},"1802":{"position":[[963,6]]}}}],["singluar",{"_index":2783,"t":{"786":{"position":[[4328,8]]},"793":{"position":[[66,8],[179,8]]}}}],["singular",{"_index":2701,"t":{"774":{"position":[[78,8],[124,8],[273,8],[376,8],[759,8]]},"776":{"position":[[205,8]]},"778":{"position":[[181,8],[330,8],[557,8]]},"784":{"position":[[549,8],[664,8]]},"786":{"position":[[3744,8],[4063,8],[4147,8],[4355,8]]},"795":{"position":[[51,8],[340,8],[423,8],[564,8],[1205,8],[1765,8],[1794,8],[1906,8]]},"797":{"position":[[184,8],[1646,8],[2397,8],[2437,8]]},"799":{"position":[[114,8]]},"801":{"position":[[390,8]]},"803":{"position":[[123,8]]},"807":{"position":[[479,8]]},"843":{"position":[[156,8],[241,8]]},"1084":{"position":[[1024,8],[1060,8]]}}}],["sinl",{"_index":707,"t":{"155":{"position":[[165,5]]}}}],["sinusodi",{"_index":1358,"t":{"324":{"position":[[498,10]]}}}],["sis_isi",{"_index":3070,"t":{"837":{"position":[[189,8]]}}}],["sit",{"_index":16,"t":{"3":{"position":[[138,3],[290,3],[317,3],[469,3],[496,3],[648,3],[675,3],[827,3],[854,3],[1006,3],[1033,3],[1185,3],[1212,3],[1364,3],[1391,3],[1543,3],[1570,3],[1722,3],[1749,3],[1901,3],[1928,3],[2080,3],[2107,3],[2259,3],[2286,3],[2438,3],[2465,3],[2617,3],[2644,3],[2796,3],[2823,3],[2975,3]]},"5":{"position":[[18,3],[170,3]]}}}],["site",{"_index":84,"t":{"13":{"position":[[30,5]]},"17":{"position":[[26,4]]},"19":{"position":[[166,5],[419,4]]},"1583":{"position":[[44,4]]},"1597":{"position":[[23,4],[77,4]]},"1599":{"position":[[11,4]]},"1636":{"position":[[11,4],[82,4]]},"1640":{"position":[[11,4],[82,4]]}}}],["situat",{"_index":1001,"t":{"215":{"position":[[1484,9]]}}}],["size",{"_index":10,"t":{"3":{"position":[[97,4]]},"38":{"position":[[379,4]]},"63":{"position":[[130,4]]},"78":{"position":[[50,4],[93,4],[300,4],[359,4],[522,4],[617,4],[921,4]]},"97":{"position":[[250,4]]},"106":{"position":[[104,4],[151,4]]},"246":{"position":[[37,4],[380,5],[402,4]]},"265":{"position":[[261,4]]},"304":{"position":[[409,4]]},"310":{"position":[[1218,4]]},"322":{"position":[[556,4]]},"372":{"position":[[68,4]]},"529":{"position":[[2528,4],[2603,4]]},"537":{"position":[[155,4]]},"539":{"position":[[88,4]]},"550":{"position":[[90,5]]},"600":{"position":[[369,4]]},"602":{"position":[[483,4]]},"612":{"position":[[117,4]]},"640":{"position":[[320,4]]},"644":{"position":[[153,4],[288,4]]},"660":{"position":[[824,4]]},"662":{"position":[[427,4],[636,4]]},"666":{"position":[[388,4]]},"668":{"position":[[282,4],[351,4],[367,4],[564,4],[610,4]]},"670":{"position":[[153,4],[429,4]]},"672":{"position":[[8,4],[133,4],[817,4],[1396,4]]},"674":{"position":[[684,4]]},"676":{"position":[[143,4],[1234,4],[1273,4]]},"821":{"position":[[403,4]]},"828":{"position":[[166,4],[213,4]]},"866":{"position":[[488,4],[742,4]]},"881":{"position":[[227,4]]},"905":{"position":[[160,4]]},"1024":{"position":[[98,5]]},"1070":{"position":[[993,4]]},"1111":{"position":[[1417,4]]},"1124":{"position":[[314,4]]},"1126":{"position":[[555,4]]},"1134":{"position":[[386,4],[741,4]]},"1136":{"position":[[402,4]]},"1141":{"position":[[704,4]]},"1145":{"position":[[666,4]]},"1167":{"position":[[1047,4]]},"1218":{"position":[[314,4]]},"1314":{"position":[[245,5],[305,4],[647,4],[903,4]]},"1321":{"position":[[249,4]]},"1341":{"position":[[1178,4]]},"1379":{"position":[[1216,6]]},"1384":{"position":[[229,4],[385,4],[436,4]]},"1387":{"position":[[0,4]]},"1391":{"position":[[22,5]]},"1393":{"position":[[280,4],[1011,4]]},"1395":{"position":[[17,4],[240,4],[539,4],[822,4],[1198,4],[1297,4]]},"1409":{"position":[[801,4],[924,4]]},"1419":{"position":[[1066,4]]},"1421":{"position":[[276,4]]},"1423":{"position":[[974,6],[1025,4],[1196,4]]},"1431":{"position":[[2202,5]]},"1496":{"position":[[271,4]]},"1665":{"position":[[1446,4]]},"1674":{"position":[[466,4]]},"1682":{"position":[[110,4]]},"1714":{"position":[[455,4]]}}}],["sk(t)s_k^{(t)}sk(t",{"_index":2919,"t":{"797":{"position":[[1624,21]]}}}],["sk,i=s(λk,i)+1d1∑j=1d1s(pk,ji)+1d2∑j=1d2s(qk,ij),\\begin{equ",{"_index":2951,"t":{"801":{"position":[[449,65]]}}}],["sk,i=λk,is_{k,i",{"_index":2945,"t":{"799":{"position":[[52,16]]}}}],["sk,is_{k,i}sk,i",{"_index":2965,"t":{"801":{"position":[[788,16]]}}}],["sk,i∗s_{k,i*}sk,i",{"_index":2882,"t":{"797":{"position":[[516,19]]}}}],["sk\\mathcal{s}_ksk",{"_index":4147,"t":{"1242":{"position":[[917,18]]}}}],["skip",{"_index":2344,"t":{"662":{"position":[[464,4],[588,4],[655,4],[1166,4],[1182,4]]},"1167":{"position":[[27,4]]},"1195":{"position":[[450,4],[501,4]]},"1208":{"position":[[17,4]]},"1221":{"position":[[297,4],[386,4],[455,4]]}}}],["sl=[slk;slm+1]t\\begin{equ",{"_index":3341,"t":{"893":{"position":[[1112,31]]}}}],["sl=qlklt/c∈r1×(k+m+1)\\begin{equ",{"_index":3332,"t":{"893":{"position":[[851,37]]}}}],["slg=[softmax(slk)⋅gl",{"_index":3353,"t":{"893":{"position":[[1732,21]]}}}],["slide",{"_index":4765,"t":{"1462":{"position":[[184,7]]}}}],["slks_l^kslk",{"_index":3352,"t":{"893":{"position":[[1518,12]]}}}],["slk∈rk+1s^k_l",{"_index":3345,"t":{"893":{"position":[[1206,13]]}}}],["slm",{"_index":2241,"t":{"626":{"position":[[257,4],[293,4]]},"628":{"position":[[613,4],[816,4],[984,3],[999,3],[1141,4],[1451,4],[1520,3]]},"630":{"position":[[39,3],[245,3],[483,3]]},"633":{"position":[[448,3],[1015,3]]},"635":{"position":[[23,3],[105,3]]},"638":{"position":[[12,4]]},"640":{"position":[[20,4],[219,4]]},"642":{"position":[[180,3]]},"646":{"position":[[43,3],[380,3]]},"650":{"position":[[44,3]]}}}],["slm+1∈r(m+1)×1s_l^{m+1",{"_index":3347,"t":{"893":{"position":[[1372,23]]}}}],["slot",{"_index":5394,"t":{"1693":{"position":[[206,6]]},"1702":{"position":[[149,4],[195,4],[235,4],[262,4]]},"1718":{"position":[[1156,4]]}}}],["slow",{"_index":345,"t":{"78":{"position":[[58,4],[125,4]]},"1242":{"position":[[834,6]]}}}],["sls_lsl",{"_index":3340,"t":{"893":{"position":[[1077,8]]}}}],["slug",{"_index":5005,"t":{"1587":{"position":[[80,5]]},"1618":{"position":[[155,5]]}}}],["sm+s<l+",{"_index":3698,"t":{"1067":{"position":[[1215,9]]}}}],["small",{"_index":347,"t":{"78":{"position":[[81,5],[288,5],[510,5]]},"213":{"position":[[166,5]]},"215":{"position":[[530,5],[775,5],[1334,5]]},"298":{"position":[[960,5],[1184,5]]},"326":{"position":[[208,5]]},"504":{"position":[[646,5]]},"521":{"position":[[82,5]]},"523":{"position":[[564,5]]},"525":{"position":[[534,5],[950,5],[1299,5]]},"527":{"position":[[277,5]]},"529":{"position":[[2802,5]]},"533":{"position":[[184,5]]},"587":{"position":[[360,5]]},"589":{"position":[[1287,5]]},"592":{"position":[[7,5]]},"628":{"position":[[184,5]]},"633":{"position":[[209,5],[281,5],[756,5]]},"648":{"position":[[308,5]]},"658":{"position":[[480,5],[2784,5]]},"660":{"position":[[724,5]]},"674":{"position":[[752,5]]},"696":{"position":[[618,5]]},"698":{"position":[[29,5]]},"707":{"position":[[375,5]]},"786":{"position":[[375,5],[589,5],[2254,5]]},"791":{"position":[[11,5]]},"809":{"position":[[668,5]]},"866":{"position":[[965,5]]},"977":{"position":[[93,5]]},"982":{"position":[[37,5]]},"1070":{"position":[[1532,5],[1567,5]]},"1080":{"position":[[175,5]]},"1082":{"position":[[152,5]]},"1101":{"position":[[231,5]]},"1111":{"position":[[901,6],[1009,6],[1429,5],[1911,6]]},"1134":{"position":[[54,7]]},"1136":{"position":[[652,5]]},"1143":{"position":[[725,5]]},"1145":{"position":[[1946,5],[2109,5]]},"1255":{"position":[[224,5]]},"1341":{"position":[[1005,5]]},"1352":{"position":[[250,5]]},"1393":{"position":[[344,5]]},"1409":{"position":[[535,5]]},"1411":{"position":[[309,5]]},"1413":{"position":[[0,6]]},"1466":{"position":[[167,5],[400,5]]},"1468":{"position":[[1361,5]]},"1477":{"position":[[931,5]]},"1485":{"position":[[937,5]]},"1487":{"position":[[1105,5]]},"1494":{"position":[[547,5]]},"1499":{"position":[[788,5]]},"1515":{"position":[[6,6],[245,5]]},"1600":{"position":[[185,5]]},"1714":{"position":[[474,5]]}}}],["smaller",{"_index":1731,"t":{"488":{"position":[[325,7]]},"529":{"position":[[735,8],[2725,7]]},"606":{"position":[[338,7]]},"662":{"position":[[824,7]]},"672":{"position":[[40,7]]},"719":{"position":[[1111,7]]},"786":{"position":[[1600,7]]},"979":{"position":[[1509,7]]},"1047":{"position":[[94,7],[146,7]]},"1067":{"position":[[222,7]]},"1141":{"position":[[690,7]]},"1159":{"position":[[988,7]]},"1291":{"position":[[376,7]]},"1307":{"position":[[67,7]]},"1321":{"position":[[330,7]]},"1466":{"position":[[620,7]]}}}],["smallest",{"_index":2778,"t":{"786":{"position":[[3735,8]]},"795":{"position":[[1897,8]]}}}],["sml",{"_index":2282,"t":{"630":{"position":[[1914,3]]},"642":{"position":[[229,3]]}}}],["smooth",{"_index":545,"t":{"112":{"position":[[226,9]]},"319":{"position":[[249,10],[277,9]]},"801":{"position":[[1544,9],[2171,8]]},"1244":{"position":[[1158,10]]}}}],["smop",{"_index":4352,"t":{"1345":{"position":[[277,4],[464,4]]},"1347":{"position":[[916,4],[1321,4],[1528,4],[1790,4],[1863,4],[2008,4]]},"1352":{"position":[[0,4],[1052,4]]},"1354":{"position":[[202,4]]},"1357":{"position":[[23,4],[297,4],[476,4]]},"1360":{"position":[[11,4],[33,4],[108,4],[402,4]]},"1362":{"position":[[456,4]]},"1367":{"position":[[715,4]]},"1369":{"position":[[611,4]]},"1371":{"position":[[86,4],[211,4]]},"1373":{"position":[[32,4],[216,4],[249,4],[311,4]]}}}],["smp",{"_index":3082,"t":{"847":{"position":[[509,5],[617,3],[713,3],[775,3],[826,3]]},"855":{"position":[[54,5]]},"870":{"position":[[27,3],[90,4],[126,4],[141,3],[148,3],[156,3],[234,3],[279,3],[377,3],[445,3],[554,3],[562,3],[597,3],[605,3],[653,3],[860,3],[1729,3],[1737,3],[1840,3],[1848,3],[1939,3],[1947,3]]},"875":{"position":[[76,3]]},"877":{"position":[[185,3],[360,3]]},"879":{"position":[[28,5]]},"881":{"position":[[31,3],[78,3],[137,3]]}}}],["snippet",{"_index":1742,"t":{"498":{"position":[[235,7]]},"500":{"position":[[38,7]]},"508":{"position":[[135,8]]}}}],["socher",{"_index":1016,"t":{"215":{"position":[[2318,7]]}}}],["socialiqa",{"_index":1650,"t":{"455":{"position":[[636,9]]}}}],["soft",{"_index":966,"t":{"213":{"position":[[178,4]]},"215":{"position":[[1020,4],[1385,4],[1407,4]]},"681":{"position":[[841,4]]},"870":{"position":[[421,4],[675,4],[1605,4],[1882,4]]},"938":{"position":[[186,4]]},"977":{"position":[[126,4],[729,4]]},"979":{"position":[[398,4],[507,4],[960,4],[1244,4]]},"982":{"position":[[538,4]]},"986":{"position":[[21,4],[243,4]]},"988":{"position":[[326,4],[690,4]]},"990":{"position":[[24,4]]},"994":{"position":[[31,4],[546,4]]},"1006":{"position":[[1363,4],[1435,4]]},"1008":{"position":[[63,4],[498,4]]},"1012":{"position":[[534,4]]},"1014":{"position":[[1211,4]]},"1060":{"position":[[13,4],[294,4],[835,4],[857,4]]},"1062":{"position":[[544,4],[1069,4],[1091,4],[1222,4],[1578,4]]},"1065":{"position":[[457,4],[841,4]]},"1067":{"position":[[25,4]]},"1070":{"position":[[1808,4],[1867,4]]},"1080":{"position":[[77,4],[141,4],[181,4],[300,4],[402,4]]},"1084":{"position":[[179,4],[1117,4]]},"1124":{"position":[[76,4],[144,4],[542,4]]},"1126":{"position":[[1605,4],[2426,4]]},"1128":{"position":[[1643,4]]},"1130":{"position":[[172,4]]},"1145":{"position":[[1514,4],[1528,4]]},"1151":{"position":[[211,4]]},"1157":{"position":[[44,4],[277,4]]},"1159":{"position":[[755,4],[796,4],[1373,4]]},"1164":{"position":[[95,4],[221,4],[504,4]]},"1167":{"position":[[46,4],[1222,4]]},"1185":{"position":[[212,4]]},"1212":{"position":[[84,4]]},"1225":{"position":[[179,4]]},"1227":{"position":[[592,4],[930,4],[1085,4]]},"1230":{"position":[[155,4]]},"1236":{"position":[[317,4],[391,4]]},"1238":{"position":[[447,5]]},"1240":{"position":[[68,4]]},"1242":{"position":[[179,4]]},"1248":{"position":[[18,4]]},"1345":{"position":[[92,4],[218,4],[246,4],[352,4],[429,4]]},"1347":{"position":[[90,4],[302,4],[393,4],[445,4],[676,4],[847,4],[884,4],[983,4],[1034,4],[1057,4],[1133,4],[1431,4],[1505,4],[1771,4],[1827,4],[1923,4],[1975,4],[2023,4]]},"1350":{"position":[[498,4]]},"1352":{"position":[[24,4],[128,4],[304,4],[356,4],[654,4],[955,4],[987,4]]},"1354":{"position":[[163,4]]},"1357":{"position":[[446,4]]},"1360":{"position":[[174,4],[218,4]]},"1362":{"position":[[0,4],[98,4],[221,4],[263,4],[337,4],[428,4],[494,4]]},"1364":{"position":[[275,4],[551,4]]},"1367":{"position":[[241,5],[323,4],[558,4],[685,4]]},"1371":{"position":[[6,4],[116,4],[160,4]]},"1373":{"position":[[131,4],[194,4]]},"1407":{"position":[[171,4],[204,4]]},"1409":{"position":[[395,4],[681,4],[989,4]]},"1434":{"position":[[291,4]]},"1466":{"position":[[79,4]]},"1468":{"position":[[216,4],[307,4],[1260,4]]},"1473":{"position":[[246,4]]},"1477":{"position":[[99,4],[142,4],[389,4],[525,4],[547,4],[1021,4],[1072,4],[1240,4]]},"1481":{"position":[[8,4],[49,4],[166,4],[245,4]]},"1483":{"position":[[106,4]]},"1485":{"position":[[57,4],[335,4],[509,4],[831,4],[975,4]]},"1487":{"position":[[22,4],[49,4],[260,4],[481,4],[744,4]]},"1489":{"position":[[206,4],[266,4],[323,4],[430,4]]},"1494":{"position":[[397,4]]},"1496":{"position":[[545,4]]},"1513":{"position":[[0,4]]},"1646":{"position":[[1829,4],[1857,4],[2857,4],[3037,4]]},"1720":{"position":[[1713,4],[1914,4]]},"1732":{"position":[[25,4]]},"1796":{"position":[[63,4]]}}}],["softmax",{"_index":318,"t":{"58":{"position":[[208,7]]},"298":{"position":[[211,7],[1155,7]]},"302":{"position":[[736,7]]},"306":{"position":[[210,7],[265,7]]},"531":{"position":[[1276,7]]},"596":{"position":[[1873,7]]},"893":{"position":[[787,7],[1685,7],[1929,7]]},"988":{"position":[[1598,7],[1799,7]]},"1185":{"position":[[471,7]]},"1364":{"position":[[173,7]]}}}],["softmax(\\frac{\\textcolor{red}{q^t_{new}k_{new}}}{\\sqrt{d}})\\textcolor{red}{v_{new}}msa(⋅)=softmax(d​qnewt​knew​​)vnew",{"_index":2534,"t":{"696":{"position":[[1437,118]]}}}],["softmax(\\frac{q^tk_{new}}{\\sqrt{d}})v_{new}attn([p,x])=softmax(d​qtknew​​)vnew",{"_index":2472,"t":{"688":{"position":[[341,79]]}}}],["softmax(q(lk⊙kt)dk)(lv⊙v)\\begin{equ",{"_index":2159,"t":{"598":{"position":[[1564,41]]}}}],["softmax(slm+1)]t\\begin{equ",{"_index":3354,"t":{"893":{"position":[[1754,32]]}}}],["softmax(slm+1​)]t",{"_index":3360,"t":{"893":{"position":[[1900,19]]}}}],["softmov",{"_index":3225,"t":{"861":{"position":[[977,12]]}}}],["solut",{"_index":343,"t":{"78":{"position":[[9,9]]},"395":{"position":[[237,8]]},"424":{"position":[[335,8]]},"1164":{"position":[[486,8]]},"1449":{"position":[[289,8]]}}}],["solv",{"_index":1569,"t":{"409":{"position":[[180,5]]},"428":{"position":[[133,5]]}}}],["sopta",{"_index":3756,"t":{"1093":{"position":[[1260,5]]}}}],["sot",{"_index":741,"t":{"165":{"position":[[600,6],[1574,5]]},"168":{"position":[[263,3]]},"189":{"position":[[71,3]]}}}],["sot&vo",{"_index":888,"t":{"177":{"position":[[1223,7],[1339,7]]}}}],["sota",{"_index":150,"t":{"23":{"position":[[114,4]]},"84":{"position":[[108,4]]},"86":{"position":[[153,4]]},"110":{"position":[[26,4]]},"159":{"position":[[362,4]]},"185":{"position":[[68,4]]},"189":{"position":[[64,4]]},"193":{"position":[[56,4]]},"197":{"position":[[25,4]]},"213":{"position":[[390,4]]},"215":{"position":[[23,4]]},"219":{"position":[[335,4]]},"225":{"position":[[325,4]]},"283":{"position":[[184,4]]},"285":{"position":[[517,4]]},"322":{"position":[[110,4],[323,4]]},"326":{"position":[[224,4]]},"328":{"position":[[316,4]]},"382":{"position":[[354,4]]},"384":{"position":[[1034,4]]},"388":{"position":[[129,5]]},"399":{"position":[[367,4]]},"483":{"position":[[907,4]]},"485":{"position":[[672,4],[989,4],[1689,4]]},"561":{"position":[[137,4],[227,4],[275,4],[315,4],[424,4]]},"587":{"position":[[781,4]]},"589":{"position":[[269,4]]},"618":{"position":[[399,4]]},"656":{"position":[[405,4]]},"658":{"position":[[185,4],[3237,4]]},"662":{"position":[[69,4]]},"670":{"position":[[762,4]]},"679":{"position":[[571,4]]},"681":{"position":[[1728,4],[2059,4]]},"703":{"position":[[0,4]]},"786":{"position":[[4677,4]]},"809":{"position":[[652,4]]},"816":{"position":[[197,4]]},"826":{"position":[[12,4]]},"849":{"position":[[1591,4]]},"879":{"position":[[353,4]]},"979":{"position":[[1530,4]]},"999":{"position":[[219,4]]},"1060":{"position":[[1068,4]]},"1062":{"position":[[1348,4],[1704,4]]},"1070":{"position":[[605,4]]},"1073":{"position":[[86,4]]},"1077":{"position":[[43,4]]},"1084":{"position":[[457,4]]},"1087":{"position":[[41,4]]},"1091":{"position":[[462,4]]},"1093":{"position":[[1474,4],[1800,4]]},"1109":{"position":[[1365,4]]},"1115":{"position":[[105,4],[625,4],[696,4]]},"1120":{"position":[[327,4]]},"1227":{"position":[[1264,4]]},"1262":{"position":[[56,4]]},"1268":{"position":[[167,4]]},"1409":{"position":[[369,4]]},"1440":{"position":[[640,4]]},"1442":{"position":[[2304,4]]}}}],["sourc",{"_index":1308,"t":{"313":{"position":[[125,6],[332,6]]},"494":{"position":[[80,6],[211,6]]},"510":{"position":[[43,6]]},"977":{"position":[[263,6],[347,6],[405,6],[544,6],[789,6]]},"979":{"position":[[479,6],[537,6],[554,6],[658,6],[1075,6],[1170,6]]},"982":{"position":[[10,6],[60,6],[206,6],[287,6],[305,6],[605,6]]},"984":{"position":[[73,6],[136,6],[155,6],[245,6]]},"986":{"position":[[141,6],[680,6]]},"988":{"position":[[43,6],[154,6],[432,6]]},"990":{"position":[[567,7],[637,6]]},"992":{"position":[[666,6]]},"997":{"position":[[4,6],[186,6],[259,6],[494,6],[729,6]]},"999":{"position":[[144,6],[417,6],[1003,6],[1076,6],[1222,6],[1251,6]]},"1002":{"position":[[922,6]]},"1004":{"position":[[425,6]]},"1006":{"position":[[546,6],[693,6],[854,6],[899,6],[935,6],[984,6],[1244,6],[1532,6],[1568,6],[1617,6],[1705,6],[1758,6],[1918,6],[2114,6],[2303,6],[2614,6],[2864,6]]},"1008":{"position":[[26,6]]},"1062":{"position":[[528,6],[599,6]]},"1070":{"position":[[71,6],[1789,6],[1846,6]]},"1084":{"position":[[209,6]]},"1197":{"position":[[209,6]]},"1212":{"position":[[141,6]]},"1225":{"position":[[332,6]]},"1227":{"position":[[577,6]]},"1230":{"position":[[727,6],[772,6]]},"1232":{"position":[[85,6]]},"1234":{"position":[[189,6]]},"1236":{"position":[[7,6],[485,6]]},"1238":{"position":[[1166,6]]},"1240":{"position":[[25,6],[99,6]]},"1242":{"position":[[26,6],[554,6],[813,6]]},"1244":{"position":[[168,6],[241,6],[1930,6],[2280,6]]},"1246":{"position":[[34,6],[74,6]]},"1253":{"position":[[48,6]]},"1257":{"position":[[249,6]]},"1259":{"position":[[0,6],[105,6],[305,6]]},"1264":{"position":[[247,6]]},"1266":{"position":[[73,6],[231,6]]},"1273":{"position":[[29,6],[114,6],[410,6],[531,6]]},"1279":{"position":[[0,6]]},"1283":{"position":[[32,6],[58,6]]},"1285":{"position":[[47,6],[75,6]]},"1407":{"position":[[289,6],[690,6]]},"1409":{"position":[[722,6],[1087,6],[1132,6],[1266,6],[1489,6]]},"1411":{"position":[[123,6],[176,6]]},"1415":{"position":[[328,6]]},"1419":{"position":[[49,6],[95,6],[467,6],[896,6]]},"1421":{"position":[[43,6],[526,6]]},"1423":{"position":[[409,6],[440,6],[539,6],[648,6],[700,6],[859,6]]},"1425":{"position":[[50,6],[141,6],[166,6],[528,6],[584,6]]},"1427":{"position":[[3,6],[54,6],[84,6],[131,6],[331,6],[378,6],[889,6],[978,6],[1094,6],[1122,6]]},"1431":{"position":[[89,6],[131,6],[163,6],[194,6],[253,6],[375,6],[433,6],[546,6],[600,6],[758,6],[1183,6],[1330,6],[1553,6],[1691,6],[2121,6],[2309,6],[2384,6],[2547,6],[2669,6],[2803,6]]},"1436":{"position":[[263,6]]},"1473":{"position":[[424,6]]},"1513":{"position":[[116,6],[536,6]]},"1523":{"position":[[11,6],[66,6]]}}}],["space",{"_index":221,"t":{"38":{"position":[[101,5],[130,5],[299,5]]},"116":{"position":[[671,5]]},"339":{"position":[[474,5]]},"436":{"position":[[641,5]]},"498":{"position":[[48,5]]},"523":{"position":[[534,5]]},"614":{"position":[[111,5],[261,5],[401,5]]},"630":{"position":[[1346,5]]},"670":{"position":[[1039,5]]},"690":{"position":[[752,5]]},"803":{"position":[[697,5]]},"940":{"position":[[189,5]]},"988":{"position":[[625,5],[715,5]]},"1017":{"position":[[54,5]]},"1093":{"position":[[960,5]]},"1117":{"position":[[455,5]]},"1120":{"position":[[30,5]]},"1126":{"position":[[1104,5]]},"1128":{"position":[[1555,5]]},"1151":{"position":[[174,5],[1077,5]]},"1227":{"position":[[867,5]]},"1409":{"position":[[1349,5],[1786,5]]},"1425":{"position":[[450,5],[603,5]]},"1429":{"position":[[221,5]]},"1449":{"position":[[169,5]]},"1477":{"position":[[373,5]]},"1494":{"position":[[427,5]]},"1702":{"position":[[740,5]]},"1722":{"position":[[42,5]]},"1724":{"position":[[264,5],[396,5]]},"1726":{"position":[[11,5],[82,5]]},"1728":{"position":[[24,5],[100,6],[116,5],[276,6]]},"1730":{"position":[[128,5],[186,5],[576,5],[1033,5],[1126,5]]},"1766":{"position":[[607,5]]},"1768":{"position":[[220,5],[844,5]]},"1790":{"position":[[63,5]]}}}],["spacif",{"_index":5595,"t":{"1782":{"position":[[1773,14]]}}}],["span",{"_index":1718,"t":{"483":{"position":[[485,4]]},"485":{"position":[[928,4]]},"490":{"position":[[103,4]]},"577":{"position":[[103,4],[133,4]]},"674":{"position":[[219,4]]},"676":{"position":[[203,4]]},"819":{"position":[[146,4]]},"1132":{"position":[[62,4],[162,4],[811,4],[953,4],[1213,4],[1310,4]]},"1143":{"position":[[85,4],[341,4],[487,4],[690,4],[1025,4]]},"1628":{"position":[[154,5],[364,7]]},"1724":{"position":[[116,4],[138,5],[250,4]]},"1728":{"position":[[166,5]]},"1730":{"position":[[1381,4]]},"1742":{"position":[[197,4],[218,4],[280,4],[295,4]]},"1768":{"position":[[658,4],[734,4]]},"1794":{"position":[[511,4],[576,4]]}}}],["spanbert",{"_index":5336,"t":{"1665":{"position":[[509,9]]},"1667":{"position":[[701,8]]}}}],["sparisti",{"_index":3088,"t":{"849":{"position":[[1484,8]]}}}],["spariti",{"_index":3208,"t":{"861":{"position":[[114,7]]}}}],["spars",{"_index":387,"t":{"88":{"position":[[150,6]]},"521":{"position":[[15,6],[208,6]]},"525":{"position":[[1258,6]]},"531":{"position":[[886,6]]},"587":{"position":[[303,6]]},"786":{"position":[[1007,6],[1296,6],[2303,6]]},"849":{"position":[[324,6]]},"873":{"position":[[856,6]]},"1230":{"position":[[107,6]]},"1345":{"position":[[282,7]]},"1347":{"position":[[921,7],[1226,8],[1457,6],[1795,7],[1990,8]]},"1369":{"position":[[283,8]]},"1489":{"position":[[7,6]]}}}],["sparsiti",{"_index":3080,"t":{"847":{"position":[[183,8],[525,8],[682,8],[785,8]]},"849":{"position":[[786,8],[1563,8],[1649,8],[1683,8]]},"851":{"position":[[1054,8]]},"853":{"position":[[1793,8],[1870,8],[2044,8],[2121,8],[2430,8],[2485,8]]},"857":{"position":[[460,8],[879,8],[943,8],[1461,8]]},"861":{"position":[[50,8],[368,8],[389,8],[423,8],[1057,8],[1196,8]]},"864":{"position":[[71,8]]},"866":{"position":[[497,8],[549,8],[596,8],[771,8],[880,8],[1074,8]]},"870":{"position":[[15,8],[307,8],[1067,8],[1556,8],[1692,8],[1762,8],[1959,8],[2236,8],[2293,8]]},"873":{"position":[[141,8],[932,8],[1322,8],[1381,8]]},"877":{"position":[[101,8],[128,8]]},"879":{"position":[[341,8],[428,8]]},"881":{"position":[[143,8],[175,8]]},"1505":{"position":[[208,11]]}}}],["special",{"_index":506,"t":{"102":{"position":[[296,11]]},"434":{"position":[[706,10],[733,11]]},"436":{"position":[[806,10]]},"498":{"position":[[341,7]]},"529":{"position":[[901,9]]},"666":{"position":[[140,7]]},"751":{"position":[[16,7]]},"765":{"position":[[94,7]]},"859":{"position":[[378,7]]},"1128":{"position":[[1147,7],[1202,7]]},"1185":{"position":[[258,7]]},"1626":{"position":[[17,7]]}}}],["specif",{"_index":575,"t":{"120":{"position":[[20,8]]},"126":{"position":[[1110,8]]},"159":{"position":[[249,8]]},"207":{"position":[[88,8]]},"215":{"position":[[415,8]]},"326":{"position":[[86,8],[876,8]]},"388":{"position":[[91,8]]},"399":{"position":[[298,8]]},"483":{"position":[[30,8]]},"500":{"position":[[392,8]]},"523":{"position":[[137,8]]},"525":{"position":[[124,8],[228,8],[1084,8],[1208,8]]},"527":{"position":[[108,8],[383,8]]},"587":{"position":[[632,8]]},"598":{"position":[[878,8],[3238,8],[3388,8],[3593,8]]},"628":{"position":[[195,8],[224,8],[271,8],[625,8],[833,8],[911,8]]},"630":{"position":[[50,8],[2380,8]]},"633":{"position":[[767,8]]},"648":{"position":[[325,8],[353,8]]},"658":{"position":[[1843,8],[2795,8],[3045,8]]},"668":{"position":[[391,8]]},"672":{"position":[[608,8],[644,8]]},"683":{"position":[[812,8]]},"686":{"position":[[76,8]]},"692":{"position":[[375,8],[391,8]]},"694":{"position":[[206,8]]},"696":{"position":[[284,8]]},"698":{"position":[[45,8],[72,8]]},"719":{"position":[[220,8]]},"723":{"position":[[922,8]]},"733":{"position":[[96,8]]},"786":{"position":[[2576,8],[3518,8]]},"801":{"position":[[901,8]]},"859":{"position":[[5,8],[133,8]]},"866":{"position":[[52,8],[118,8],[275,8]]},"870":{"position":[[988,8]]},"875":{"position":[[9,8],[261,8]]},"879":{"position":[[53,8]]},"982":{"position":[[975,8]]},"990":{"position":[[336,8],[462,8]]},"999":{"position":[[541,8]]},"1006":{"position":[[1093,8]]},"1008":{"position":[[86,8]]},"1028":{"position":[[380,8]]},"1039":{"position":[[208,8]]},"1047":{"position":[[405,8]]},"1126":{"position":[[115,8],[2016,8],[2151,8]]},"1134":{"position":[[333,8]]},"1136":{"position":[[437,8]]},"1145":{"position":[[82,8],[205,8],[1185,8],[2188,8],[2342,13]]},"1151":{"position":[[1960,8]]},"1153":{"position":[[367,8]]},"1178":{"position":[[206,8]]},"1218":{"position":[[655,8]]},"1225":{"position":[[323,8],[574,8]]},"1227":{"position":[[95,8],[401,8],[990,8],[1410,8]]},"1230":{"position":[[307,8]]},"1232":{"position":[[210,8]]},"1236":{"position":[[752,8]]},"1240":{"position":[[193,8]]},"1242":{"position":[[126,8],[394,8],[416,8],[946,8]]},"1244":{"position":[[478,8],[611,8]]},"1246":{"position":[[626,8]]},"1248":{"position":[[90,8]]},"1259":{"position":[[272,8],[317,8]]},"1270":{"position":[[239,8]]},"1273":{"position":[[149,8]]},"1279":{"position":[[97,8],[126,8]]},"1285":{"position":[[66,8],[220,8],[440,8]]},"1289":{"position":[[312,8]]},"1291":{"position":[[480,8],[580,8],[1158,8],[1482,8]]},"1317":{"position":[[12,8]]},"1347":{"position":[[384,8]]},"1362":{"position":[[524,8]]},"1367":{"position":[[418,8]]},"1369":{"position":[[185,8]]},"1384":{"position":[[1165,8],[2524,8],[2740,8],[3778,8]]},"1389":{"position":[[479,8]]},"1395":{"position":[[1249,8],[2294,8]]},"1401":{"position":[[308,8]]},"1407":{"position":[[162,8]]},"1409":{"position":[[546,8]]},"1411":{"position":[[320,8]]},"1423":{"position":[[1210,8]]},"1429":{"position":[[0,8],[83,8]]},"1434":{"position":[[147,8]]},"1455":{"position":[[191,8]]},"1494":{"position":[[569,8]]},"1640":{"position":[[22,8]]},"1646":{"position":[[121,8],[439,8],[504,8],[2266,8],[2794,8]]},"1657":{"position":[[448,8]]},"1665":{"position":[[1126,8]]},"1667":{"position":[[413,8],[741,8],[839,8],[1041,8],[1172,8]]},"1674":{"position":[[195,8]]},"1684":{"position":[[301,8],[377,8],[504,8]]},"1689":{"position":[[118,8]]},"1695":{"position":[[33,8],[461,8],[1126,8]]},"1720":{"position":[[348,8]]},"1796":{"position":[[239,8]]}}}],["specifc",{"_index":2747,"t":{"786":{"position":[[487,7]]},"849":{"position":[[1330,7]]}}}],["speciifc",{"_index":1813,"t":{"521":{"position":[[288,8]]}}}],["speech",{"_index":1419,"t":{"343":{"position":[[243,6]]}}}],["speed",{"_index":145,"t":{"23":{"position":[[36,5]]},"78":{"position":[[654,5]]},"1082":{"position":[[44,5]]}}}],["spin",{"_index":1657,"t":{"457":{"position":[[206,8]]}}}],["split",{"_index":910,"t":{"185":{"position":[[46,5]]},"999":{"position":[[664,5]]}}}],["sport",{"_index":1574,"t":{"412":{"position":[[125,6]]},"1323":{"position":[[358,6]]}}}],["spot",{"_index":3582,"t":{"999":{"position":[[106,5]]},"1002":{"position":[[163,4],[838,4]]},"1004":{"position":[[207,4]]},"1006":{"position":[[874,4]]},"1070":{"position":[[586,5]]},"1084":{"position":[[531,4]]},"1130":{"position":[[284,4]]},"1189":{"position":[[287,4]]},"1197":{"position":[[255,4]]},"1199":{"position":[[145,6]]},"1230":{"position":[[512,5],[639,4]]},"1257":{"position":[[202,4]]},"1264":{"position":[[133,4]]},"1270":{"position":[[308,4]]},"1407":{"position":[[198,5],[473,4]]},"1409":{"position":[[675,5],[1589,4]]},"1411":{"position":[[42,4],[451,4]]},"1415":{"position":[[0,4],[317,4]]},"1423":{"position":[[0,4],[185,4],[368,4],[397,4],[914,4],[1251,4],[1328,4]]},"1434":{"position":[[41,4]]},"1473":{"position":[[417,4]]},"1513":{"position":[[26,4]]},"1523":{"position":[[189,4]]}}}],["sql",{"_index":2657,"t":{"743":{"position":[[108,4]]},"1462":{"position":[[251,3]]}}}],["sqrt{c",{"_index":3335,"t":{"893":{"position":[[907,8]]}}}],["sqrt{d_n})xw_{vi,}mha(x)=concat(head1​,…,headh​)wo​,head)i=softmax(xwqi​(xwki​)⊤/dn​​)xwvi",{"_index":2799,"t":{"789":{"position":[[440,93]]}}}],["squad",{"_index":1932,"t":{"529":{"position":[[2634,5]]},"658":{"position":[[3108,5]]},"664":{"position":[[176,5]]},"674":{"position":[[57,5],[83,5],[744,5]]},"864":{"position":[[33,5]]},"866":{"position":[[168,5],[459,5]]},"870":{"position":[[576,5],[1426,5]]},"875":{"position":[[101,5]]},"877":{"position":[[202,5]]},"887":{"position":[[1368,5]]},"901":{"position":[[15,5]]},"924":{"position":[[149,5]]},"926":{"position":[[55,5]]},"984":{"position":[[13,5]]},"997":{"position":[[303,6]]},"999":{"position":[[1245,5]]},"1006":{"position":[[1802,5]]},"1049":{"position":[[180,5],[215,5]]},"1070":{"position":[[1772,5]]},"1147":{"position":[[433,5]]},"1253":{"position":[[85,5]]},"1419":{"position":[[452,5],[536,5]]},"1423":{"position":[[633,5]]},"1427":{"position":[[1260,5]]},"1429":{"position":[[1410,7],[1642,5],[1682,5]]},"1546":{"position":[[899,6]]},"1772":{"position":[[113,7]]}}}],["squad2.0",{"_index":1646,"t":{"455":{"position":[[598,8]]},"786":{"position":[[4657,8]]}}}],["squadv1",{"_index":2784,"t":{"786":{"position":[[4442,9]]},"805":{"position":[[93,8]]},"819":{"position":[[17,8]]}}}],["squadv2",{"_index":2785,"t":{"786":{"position":[[4452,8]]},"805":{"position":[[104,8]]},"819":{"position":[[28,8]]},"833":{"position":[[83,8],[247,7],[311,7]]}}}],["squar",{"_index":538,"t":{"108":{"position":[[127,7]]},"234":{"position":[[217,7]]},"1244":{"position":[[1362,7]]}}}],["sr0sr_0sr0",{"_index":4759,"t":{"1455":{"position":[[372,11]]}}}],["sr\\rho^{s_r}ρsr",{"_index":4659,"t":{"1431":{"position":[[462,17]]}}}],["src/components/hellodocusaurus.j",{"_index":5111,"t":{"1624":{"position":[[184,33]]}}}],["src/page",{"_index":5071,"t":{"1610":{"position":[[31,9]]}}}],["src/pages/foo.md",{"_index":5075,"t":{"1610":{"position":[[107,16]]}}}],["src/pages/foo/bar.j",{"_index":5077,"t":{"1610":{"position":[[145,20]]}}}],["src/pages/index.j",{"_index":5073,"t":{"1610":{"position":[[70,18]]}}}],["src/pages/mi",{"_index":5079,"t":{"1612":{"position":[[17,12],[45,12]]},"1614":{"position":[[17,12],[48,12]]}}}],["srtsr_tsrt",{"_index":4760,"t":{"1455":{"position":[[406,11],[647,11]]}}}],["ss={s1​,s2​,…,sk",{"_index":4102,"t":{"1236":{"position":[[108,20]]}}}],["ssf",{"_index":3437,"t":{"947":{"position":[[106,3],[124,3]]}}}],["sss",{"_index":864,"t":{"174":{"position":[[2370,3]]},"873":{"position":[[471,3],[556,3],[841,3],[1462,3],[1478,3]]},"945":{"position":[[550,3]]}}}],["sst",{"_index":1015,"t":{"215":{"position":[[2312,3]]},"835":{"position":[[205,4]]},"839":{"position":[[353,3]]},"997":{"position":[[296,3],[483,3],[539,3]]},"1006":{"position":[[2356,3]]},"1052":{"position":[[261,3]]},"1070":{"position":[[111,3],[1765,3]]},"1253":{"position":[[79,3],[225,3]]},"1393":{"position":[[64,4]]},"1395":{"position":[[1516,3]]},"1429":{"position":[[1478,3]]}}}],["sst2",{"_index":3253,"t":{"866":{"position":[[937,4]]},"1395":{"position":[[1845,5]]}}}],["st",{"_index":2686,"t":{"759":{"position":[[172,3]]},"866":{"position":[[989,3]]},"1070":{"position":[[117,3]]},"1084":{"position":[[536,5]]},"1253":{"position":[[194,3]]},"1395":{"position":[[117,3],[1269,3],[1857,3],[1914,4],[2585,3]]},"1427":{"position":[[1178,3]]},"1429":{"position":[[1542,4]]},"1431":{"position":[[1896,3]]}}}],["st,0otherwise,\\begin{equ",{"_index":2922,"t":{"797":{"position":[[1763,30]]}}}],["st,otherwis",{"_index":2938,"t":{"797":{"position":[[2194,16]]}}}],["st={sk,i(t)}1≤k≤n,1≤i≤rs^{t",{"_index":2939,"t":{"797":{"position":[[2211,28]]}}}],["stabil",{"_index":1768,"t":{"504":{"position":[[751,9]]},"1423":{"position":[[44,9]]}}}],["stack",{"_index":1169,"t":{"289":{"position":[[442,7]]},"292":{"position":[[34,5]]},"294":{"position":[[35,5],[119,5],[246,5]]},"308":{"position":[[135,6]]},"319":{"position":[[134,6]]},"789":{"position":[[29,7]]}}}],["stage",{"_index":222,"t":{"38":{"position":[[109,5]]},"49":{"position":[[260,5],[273,5]]},"78":{"position":[[169,6],[245,5],[275,6],[821,5],[895,5]]},"104":{"position":[[466,5],[485,5],[534,6]]},"153":{"position":[[31,5]]},"244":{"position":[[170,5],[190,5]]},"517":{"position":[[1083,5],[1271,5]]},"630":{"position":[[12,5]]},"967":{"position":[[725,5]]},"1132":{"position":[[1794,5]]},"1240":{"position":[[48,5]]},"1411":{"position":[[115,5]]},"1479":{"position":[[37,6]]},"1505":{"position":[[841,5]]},"1513":{"position":[[628,5]]}}}],["staight",{"_index":3100,"t":{"851":{"position":[[786,7]]},"853":{"position":[[1323,7]]}}}],["standalon",{"_index":5072,"t":{"1610":{"position":[[53,10]]}}}],["standard",{"_index":517,"t":{"104":{"position":[[286,12]]},"339":{"position":[[427,8]]},"384":{"position":[[924,8],[1002,8]]},"393":{"position":[[50,8]]},"409":{"position":[[470,8]]},"416":{"position":[[29,8]]},"424":{"position":[[401,8]]},"426":{"position":[[245,8]]},"567":{"position":[[434,8]]},"602":{"position":[[190,8]]},"618":{"position":[[341,8]]},"662":{"position":[[82,8]]},"703":{"position":[[44,8]]},"1070":{"position":[[1712,8]]},"1134":{"position":[[653,8]]},"1136":{"position":[[0,8]]},"1238":{"position":[[168,8]]},"1255":{"position":[[16,8]]},"1415":{"position":[[184,8]]},"1494":{"position":[[18,8]]}}}],["standfordcar",{"_index":1510,"t":{"374":{"position":[[117,13]]}}}],["standord",{"_index":3390,"t":{"905":{"position":[[0,8]]}}}],["stanford",{"_index":3286,"t":{"887":{"position":[[63,8]]},"934":{"position":[[51,8]]}}}],["starbuck",{"_index":4232,"t":{"1291":{"position":[[1026,9],[1091,10]]}}}],["start",{"_index":82,"t":{"13":{"position":[[4,7]]},"19":{"position":[[50,5],[228,5]]},"866":{"position":[[220,8]]},"1636":{"position":[[0,5],[46,5],[146,7]]},"1720":{"position":[[1665,8]]}}}],["start_index",{"_index":4907,"t":{"1540":{"position":[[316,11],[413,12],[426,14]]}}}],["state",{"_index":1101,"t":{"244":{"position":[[131,6]]},"285":{"position":[[139,5]]},"628":{"position":[[336,6]]},"630":{"position":[[166,5]]},"719":{"position":[[1076,6]]},"741":{"position":[[86,6]]},"859":{"position":[[424,5]]},"1014":{"position":[[188,6]]},"1159":{"position":[[236,6]]},"1244":{"position":[[1348,6],[1731,6],[1799,6]]},"1259":{"position":[[191,6]]},"1275":{"position":[[73,5],[146,6],[362,5]]},"1384":{"position":[[222,6]]},"1447":{"position":[[8,5]]}}}],["static",{"_index":840,"t":{"174":{"position":[[815,6]]},"205":{"position":[[39,6],[305,6]]},"847":{"position":[[488,6]]},"855":{"position":[[33,6]]},"879":{"position":[[7,6]]},"934":{"position":[[1337,6]]},"961":{"position":[[48,6]]},"1395":{"position":[[2820,6]]},"1597":{"position":[[16,6],[92,6]]},"1599":{"position":[[50,6]]},"1622":{"position":[[93,6]]}}}],["static/img/docusaurus.png",{"_index":5099,"t":{"1622":{"position":[[110,28]]}}}],["statu",{"_index":4741,"t":{"1451":{"position":[[159,6]]}}}],["stem",{"_index":1061,"t":{"230":{"position":[[395,4]]}}}],["step",{"_index":230,"t":{"38":{"position":[[355,4]]},"49":{"position":[[145,5]]},"63":{"position":[[171,5]]},"315":{"position":[[54,5],[83,4],[110,5]]},"317":{"position":[[326,7],[468,5],[512,4],[571,5]]},"382":{"position":[[42,4]]},"384":{"position":[[308,5]]},"386":{"position":[[20,4],[75,5],[223,4],[243,4]]},"399":{"position":[[597,4]]},"403":{"position":[[186,4],[197,4]]},"405":{"position":[[228,5]]},"426":{"position":[[10,4]]},"428":{"position":[[67,4],[184,4],[192,4]]},"498":{"position":[[834,4]]},"550":{"position":[[116,4],[329,4],[393,4]]},"559":{"position":[[209,4],[217,5]]},"565":{"position":[[179,4],[187,5]]},"567":{"position":[[274,4]]},"569":{"position":[[214,4],[222,6],[489,4]]},"600":{"position":[[384,5]]},"602":{"position":[[432,4],[494,5]]},"606":{"position":[[191,4]]},"612":{"position":[[130,5]]},"795":{"position":[[1129,4],[2008,4]]},"797":{"position":[[1125,4],[1274,4],[2384,4]]},"803":{"position":[[482,5]]},"807":{"position":[[432,5]]},"853":{"position":[[1004,5],[1900,4],[2152,5]]},"861":{"position":[[34,4],[105,4],[347,5],[413,5],[461,4]]},"866":{"position":[[628,5],[1038,5]]},"873":{"position":[[256,4]]},"1062":{"position":[[896,5],[927,4]]},"1132":{"position":[[1898,5]]},"1134":{"position":[[166,5],[695,5]]},"1143":{"position":[[475,5],[597,7]]},"1296":{"position":[[318,4],[469,4],[531,4]]},"1417":{"position":[[65,4]]},"1421":{"position":[[337,4],[625,5]]},"1427":{"position":[[370,4],[524,5]]},"1429":{"position":[[262,5]]},"1442":{"position":[[1649,4]]},"1451":{"position":[[388,4]]},"1492":{"position":[[161,5]]},"1665":{"position":[[1367,5]]},"1674":{"position":[[421,5]]}}}],["step\\_",{"_index":1328,"t":{"317":{"position":[[282,7]]}}}],["stepswarmup_step",{"_index":1335,"t":{"317":{"position":[[441,17]]}}}],["stochast",{"_index":2906,"t":{"797":{"position":[[1254,10]]},"801":{"position":[[1420,10]]},"1101":{"position":[[186,10]]},"1246":{"position":[[320,10]]},"1259":{"position":[[55,10]]},"1281":{"position":[[0,10]]},"1364":{"position":[[218,10]]},"1369":{"position":[[372,10],[553,10]]}}}],["stop",{"_index":1351,"t":{"322":{"position":[[646,4]]},"1111":{"position":[[1578,4]]},"1134":{"position":[[752,8]]},"1496":{"position":[[603,8]]}}}],["storag",{"_index":2069,"t":{"592":{"position":[[13,7],[135,7]]},"598":{"position":[[41,7]]},"614":{"position":[[13,7]]},"1153":{"position":[[434,7]]}}}],["strategi",{"_index":4597,"t":{"1419":{"position":[[975,8]]},"1708":{"position":[[472,10]]}}}],["strategyqa",{"_index":1571,"t":{"412":{"position":[[34,10]]},"414":{"position":[[7,10]]}}}],["stream",{"_index":2308,"t":{"658":{"position":[[241,7],[2637,6]]}}}],["street",{"_index":5362,"t":{"1672":{"position":[[248,6]]}}}],["stride",{"_index":242,"t":{"40":{"position":[[155,6]]},"78":{"position":[[874,6]]}}}],["string",{"_index":2090,"t":{"594":{"position":[[1110,7]]},"1141":{"position":[[372,6]]},"1143":{"position":[[908,6]]},"1702":{"position":[[167,6]]}}}],["strong",{"_index":694,"t":{"153":{"position":[[22,6]]},"326":{"position":[[120,6]]},"604":{"position":[[50,6]]}}}],["stronger",{"_index":357,"t":{"78":{"position":[[369,8],[630,8]]},"934":{"position":[[2189,8]]},"1136":{"position":[[476,8]]}}}],["stroy",{"_index":2077,"t":{"594":{"position":[[788,5]]}}}],["struct",{"_index":4776,"t":{"1468":{"position":[[1092,8]]}}}],["structur",{"_index":510,"t":{"102":{"position":[[337,10]]},"326":{"position":[[127,10]]},"424":{"position":[[344,9]]},"795":{"position":[[1490,10]]},"857":{"position":[[52,9]]},"881":{"position":[[37,10]]},"1151":{"position":[[1695,9]]},"1466":{"position":[[457,10]]},"1477":{"position":[[1206,10]]},"1479":{"position":[[79,10]]},"1481":{"position":[[273,10]]},"1483":{"position":[[13,10]]},"1489":{"position":[[185,10]]},"1505":{"position":[[13,10],[762,10],[1201,10]]},"1507":{"position":[[210,10]]},"1509":{"position":[[280,10],[355,10]]},"1515":{"position":[[123,10]]},"1517":{"position":[[52,10]]},"1653":{"position":[[35,10],[70,10],[143,10],[928,10]]},"1676":{"position":[[390,10]]},"1684":{"position":[[706,9]]},"1788":{"position":[[316,10],[392,9]]}}}],["stsb",{"_index":3572,"t":{"997":{"position":[[453,5]]}}}],["student",{"_index":543,"t":{"110":{"position":[[95,7]]},"861":{"position":[[1968,7]]},"1244":{"position":[[322,7],[429,7],[678,7],[1120,7],[1705,7],[1922,7]]},"1275":{"position":[[189,7]]}}}],["studi",{"_index":1127,"t":{"265":{"position":[[24,5]]},"267":{"position":[[26,5]]},"466":{"position":[[342,5]]},"681":{"position":[[1758,5]]},"709":{"position":[[644,5]]},"979":{"position":[[1707,7]]},"1006":{"position":[[466,8]]},"1255":{"position":[[211,5]]},"1407":{"position":[[528,5]]},"1409":{"position":[[1715,5]]},"1423":{"position":[[265,5]]}}}],["style",{"_index":5122,"t":{"1628":{"position":[[160,8]]},"1646":{"position":[[907,5]]},"1782":{"position":[[1743,5]]}}}],["stype",{"_index":5156,"t":{"1646":{"position":[[352,5]]}}}],["sub",{"_index":354,"t":{"78":{"position":[[254,3]]},"165":{"position":[[30,3],[837,3],[2699,3]]},"221":{"position":[[298,3]]},"292":{"position":[[64,3],[159,3],[227,3],[375,3],[428,3]]},"294":{"position":[[73,3],[95,3],[181,3]]},"304":{"position":[[10,3]]},"319":{"position":[[54,3]]},"662":{"position":[[353,3],[452,3],[485,3],[537,3]]},"784":{"position":[[419,3]]},"1093":{"position":[[887,3]]},"1107":{"position":[[609,3],[881,4],[940,4]]},"1115":{"position":[[0,3],[131,3]]},"1236":{"position":[[469,3]]},"1321":{"position":[[131,3]]},"1347":{"position":[[1158,3]]},"1369":{"position":[[61,3]]},"1468":{"position":[[700,3],[798,3]]},"1487":{"position":[[1163,3]]},"1505":{"position":[[474,3],[751,3]]},"1509":{"position":[[269,3]]},"1644":{"position":[[449,3],[484,3]]},"1646":{"position":[[2070,3],[2120,3],[2155,3],[2387,3],[2771,3],[2968,3],[3006,3]]},"1649":{"position":[[90,3],[119,3],[188,3]]},"1651":{"position":[[856,3],[1640,3]]},"1653":{"position":[[8,3],[680,3],[830,3]]},"1655":{"position":[[37,3],[83,3],[748,3],[1167,3],[1648,3],[2279,3]]},"1657":{"position":[[383,3],[420,3],[563,3],[615,3],[1074,3]]},"1669":{"position":[[78,3],[239,3]]},"1689":{"position":[[99,3],[194,3]]},"1720":{"position":[[2279,3]]},"1730":{"position":[[38,3]]},"1740":{"position":[[220,3]]},"1742":{"position":[[118,3],[139,3]]},"1794":{"position":[[427,3]]}}}],["sub)set",{"_index":4489,"t":{"1384":{"position":[[2861,8]]}}}],["subject",{"_index":3844,"t":{"1107":{"position":[[676,7]]},"1109":{"position":[[613,7]]},"1651":{"position":[[1438,7]]},"1655":{"position":[[690,7]]}}}],["sublayer(x)\\text{sublayer}(x)sublayer(x",{"_index":1177,"t":{"292":{"position":[[332,40]]}}}],["submiss",{"_index":4619,"t":{"1423":{"position":[[1421,11]]}}}],["submodeul",{"_index":4444,"t":{"1377":{"position":[[332,10]]}}}],["submodul",{"_index":2791,"t":{"789":{"position":[[65,10]]},"1377":{"position":[[496,10]]},"1379":{"position":[[693,9],[733,9],[809,9],[882,9],[912,9],[1306,9],[1398,9],[1618,9],[1650,9]]},"1387":{"position":[[179,9],[254,10]]},"1389":{"position":[[332,10],[509,9],[606,9],[752,9],[827,9],[1084,9],[1102,9],[1199,9],[1618,9],[1887,9]]},"1395":{"position":[[2552,9]]},"1397":{"position":[[773,9],[884,10],[1377,9]]},"1399":{"position":[[646,9]]},"1401":{"position":[[736,10]]},"1403":{"position":[[105,10],[144,10],[212,10],[244,10]]}}}],["subnetwork",{"_index":1965,"t":{"531":{"position":[[854,10]]},"849":{"position":[[331,10],[905,10],[948,10],[987,10],[1024,10]]},"851":{"position":[[972,10]]},"868":{"position":[[244,11]]},"870":{"position":[[1161,11]]},"879":{"position":[[437,11],[470,11]]},"1126":{"position":[[1382,10]]},"1475":{"position":[[108,10],[135,10]]},"1489":{"position":[[14,11]]}}}],["suboptim",{"_index":1715,"t":{"483":{"position":[[189,10]]}}}],["subpar",{"_index":5629,"t":{"1802":{"position":[[474,6],[643,6]]}}}],["subsequ",{"_index":1183,"t":{"294":{"position":[[287,10]]},"633":{"position":[[721,10]]},"891":{"position":[[941,10]]},"1289":{"position":[[379,10]]},"1303":{"position":[[847,10]]},"1440":{"position":[[341,10]]}}}],["subset",{"_index":1681,"t":{"459":{"position":[[687,6]]},"483":{"position":[[177,6]]},"521":{"position":[[63,6]]},"523":{"position":[[297,6]]},"525":{"position":[[956,6]]},"527":{"position":[[2534,6],[3014,6]]},"529":{"position":[[1180,6],[2656,6]]},"589":{"position":[[1337,6]]},"598":{"position":[[3472,6]]},"1107":{"position":[[240,6]]},"1111":{"position":[[487,7]]},"1341":{"position":[[1115,6]]},"1345":{"position":[[318,6]]},"1347":{"position":[[1100,6]]},"1352":{"position":[[58,6]]},"1393":{"position":[[359,6]]},"1401":{"position":[[238,6]]}}}],["subspac",{"_index":1211,"t":{"300":{"position":[[473,9]]},"598":{"position":[[3517,8]]},"733":{"position":[[178,8]]},"774":{"position":[[296,8],[395,8],[451,8],[865,8],[1118,8]]},"776":{"position":[[45,8]]},"778":{"position":[[82,8]]},"1242":{"position":[[904,8]]}}}],["subspan",{"_index":3950,"t":{"1143":{"position":[[884,7]]}}}],["success",{"_index":918,"t":{"189":{"position":[[92,7]]},"1451":{"position":[[151,7]]}}}],["success/fail",{"_index":4742,"t":{"1451":{"position":[[166,14]]}}}],["such",{"_index":48,"t":{"7":{"position":[[225,4]]},"9":{"position":[[49,4]]},"1776":{"position":[[174,5]]}}}],["sum",{"_index":1186,"t":{"296":{"position":[[117,3]]},"990":{"position":[[88,3]]},"1067":{"position":[[478,3]]},"1364":{"position":[[127,3]]},"1540":{"position":[[397,3],[406,3],[441,3],[463,3],[481,3],[504,3]]}}}],["sum^c_{j=1",{"_index":1436,"t":{"350":{"position":[[606,12]]},"358":{"position":[[1015,12]]}}}],["sum^k_i",{"_index":5506,"t":{"1736":{"position":[[366,8],[1438,8]]}}}],["sum^l_{j=1}w_j",{"_index":630,"t":{"132":{"position":[[810,15]]}}}],["sum^l_{l'=1",{"_index":3191,"t":{"857":{"position":[[1075,15]]}}}],["sum^m_{k=1",{"_index":5322,"t":{"1659":{"position":[[925,12]]}}}],["sum^m_{m=1}p^m_i",{"_index":1462,"t":{"354":{"position":[[388,17]]}}}],["sum^n_{k=1",{"_index":2897,"t":{"797":{"position":[[1012,12]]}}}],["sum^n_{n=1",{"_index":2131,"t":{"596":{"position":[[2140,12]]}}}],["sum^t_{t=1",{"_index":1073,"t":{"236":{"position":[[172,13]]}}}],["sum^{d_1}_{j=1",{"_index":2956,"t":{"801":{"position":[[559,16]]}}}],["sum^{d_2}_{j=1",{"_index":2959,"t":{"801":{"position":[[604,16]]}}}],["sum^{t+1}_{j",{"_index":3549,"t":{"990":{"position":[[182,13]]}}}],["sum^{t^{(n)}}_{t=1",{"_index":2109,"t":{"596":{"position":[[566,20]]}}}],["sum_i",{"_index":3673,"t":{"1065":{"position":[[735,6]]},"1067":{"position":[[869,6]]},"1238":{"position":[[876,6]]}}}],["sum_t",{"_index":2096,"t":{"596":{"position":[[157,6]]}}}],["sum_{(x,i",{"_index":2598,"t":{"723":{"position":[[513,11],[1206,11]]}}}],["sum_{(x_i",{"_index":4159,"t":{"1244":{"position":[[880,11],[1479,11]]}}}],["sum_{i",{"_index":4276,"t":{"1300":{"position":[[297,7]]}}}],["sum_{i,j}\\sigma(s_{i,j})r(s)=∑i,j​σ(si,j",{"_index":3195,"t":{"857":{"position":[[1205,43]]}}}],["sum_{i=0}^{l",{"_index":859,"t":{"174":{"position":[[2182,14]]}}}],["sum_{j=1}^{n",{"_index":5299,"t":{"1657":{"position":[[2926,14]]}}}],["sum_{k",{"_index":4158,"t":{"1244":{"position":[[853,7],[1452,7],[2208,7]]}}}],["sum_{t<t",{"_index":3128,"t":{"853":{"position":[[795,10],[1513,10]]},"855":{"position":[[257,10]]}}}],["sum_{t=1}^{|i",{"_index":2600,"t":{"723":{"position":[[542,16],[1235,16]]}}}],["sum_{x",{"_index":4033,"t":{"1167":{"position":[[1395,8]]},"1657":{"position":[[2797,7]]}}}],["sum_{x,i",{"_index":3999,"t":{"1162":{"position":[[286,9]]},"1164":{"position":[[339,9]]}}}],["sum_{z",{"_index":5494,"t":{"1730":{"position":[[365,7]]}}}],["summar",{"_index":1155,"t":{"287":{"position":[[466,14]]},"502":{"position":[[430,13]]},"508":{"position":[[52,13]]},"622":{"position":[[619,13]]},"743":{"position":[[144,14]]},"1008":{"position":[[620,15]]},"1291":{"position":[[81,14]]},"1294":{"position":[[185,13]]},"1303":{"position":[[509,10]]},"1310":{"position":[[185,13]]},"1314":{"position":[[49,13],[503,13],[768,13],[874,13]]},"1321":{"position":[[16,13]]},"1323":{"position":[[16,13],[301,13],[473,13]]},"1326":{"position":[[89,14]]},"1332":{"position":[[180,13]]},"1409":{"position":[[1536,13]]},"1419":{"position":[[821,13]]},"1554":{"position":[[139,14]]},"1695":{"position":[[639,13]]}}}],["summari",{"_index":0,"t":{"3":{"position":[[12,7]]},"1294":{"position":[[226,7]]},"1455":{"position":[[364,7]]}}}],["sun397",{"_index":1509,"t":{"374":{"position":[[110,6]]}}}],["sung",{"_index":2256,"t":{"630":{"position":[[811,5]]},"648":{"position":[[739,5]]},"1002":{"position":[[710,4]]}}}],["super",{"_index":2060,"t":{"587":{"position":[[751,5]]},"868":{"position":[[178,5],[216,5]]}}}],["superglu",{"_index":2093,"t":{"594":{"position":[[1405,10]]},"626":{"position":[[463,9]]},"628":{"position":[[1380,9],[1602,9]]},"633":{"position":[[0,9]]},"640":{"position":[[47,9]]},"650":{"position":[[168,9]]},"679":{"position":[[551,9]]},"681":{"position":[[1705,9],[2026,9]]},"690":{"position":[[12,9]]},"701":{"position":[[35,9]]},"705":{"position":[[86,9]]},"711":{"position":[[261,9]]},"761":{"position":[[38,9]]},"997":{"position":[[206,9],[326,10],[371,9]]},"1002":{"position":[[22,9],[101,9]]},"1006":{"position":[[88,9]]},"1017":{"position":[[81,9]]},"1041":{"position":[[31,9]]},"1047":{"position":[[45,9]]},"1070":{"position":[[137,9]]},"1073":{"position":[[14,9]]},"1084":{"position":[[645,9]]},"1091":{"position":[[275,9],[445,9]]},"1093":{"position":[[1301,9],[1461,9],[1787,9]]},"1101":{"position":[[1189,9]]},"1103":{"position":[[35,9]]},"1111":{"position":[[16,9],[35,9],[438,9],[475,9]]},"1115":{"position":[[70,9],[634,9],[677,9]]},"1120":{"position":[[211,9],[314,9]]},"1134":{"position":[[433,9],[523,9],[572,9]]},"1136":{"position":[[535,9]]},"1145":{"position":[[926,9],[1371,9]]},"1149":{"position":[[562,9]]},"1153":{"position":[[91,9]]},"1157":{"position":[[376,9]]},"1159":{"position":[[1719,9]]},"1181":{"position":[[0,9]]},"1197":{"position":[[4,9],[64,9]]},"1199":{"position":[[218,9]]},"1201":{"position":[[150,9]]},"1208":{"position":[[132,9]]},"1212":{"position":[[195,9]]},"1214":{"position":[[68,9]]},"1221":{"position":[[114,9]]},"1227":{"position":[[1297,9]]},"1253":{"position":[[134,9]]},"1268":{"position":[[4,9]]},"1275":{"position":[[97,9],[324,9]]},"1279":{"position":[[201,10]]},"1281":{"position":[[31,9]]},"1347":{"position":[[1549,9],[1630,9]]},"1357":{"position":[[41,9]]},"1362":{"position":[[293,9]]},"1364":{"position":[[367,9]]},"1407":{"position":[[384,9]]},"1409":{"position":[[838,9]]},"1417":{"position":[[7,9]]},"1419":{"position":[[636,10]]},"1423":{"position":[[89,9],[172,9],[470,9],[576,9],[596,9],[1356,9]]},"1425":{"position":[[108,9]]},"1466":{"position":[[592,9]]},"1468":{"position":[[1456,9]]},"1492":{"position":[[43,9],[73,9]]},"1496":{"position":[[58,9]]},"1499":{"position":[[118,9]]},"1509":{"position":[[107,9]]},"1515":{"position":[[230,9]]},"1527":{"position":[[0,9]]}}}],["supert",{"_index":3265,"t":{"870":{"position":[[2266,6],[2332,6]]}}}],["superviesd",{"_index":5401,"t":{"1695":{"position":[[352,10]]}}}],["supervis",{"_index":541,"t":{"110":{"position":[[74,10]]},"118":{"position":[[17,11],[88,11],[112,11],[167,10]]},"120":{"position":[[209,10],[228,10]]},"174":{"position":[[2506,9]]},"213":{"position":[[400,10]]},"326":{"position":[[438,10],[519,10],[802,10]]},"336":{"position":[[404,10],[692,11]]},"343":{"position":[[25,10]]},"345":{"position":[[59,10]]},"352":{"position":[[117,10]]},"376":{"position":[[95,10]]},"378":{"position":[[133,10]]},"475":{"position":[[230,10]]},"523":{"position":[[146,10]]},"600":{"position":[[158,10]]},"1039":{"position":[[346,10]]},"1052":{"position":[[64,10]]},"1091":{"position":[[300,10]]},"1111":{"position":[[260,10],[294,10],[1181,10]]},"1132":{"position":[[1458,10]]},"1419":{"position":[[369,10],[401,10]]},"1544":{"position":[[179,10]]},"1546":{"position":[[386,10]]},"1550":{"position":[[35,10],[93,10],[275,10]]},"1558":{"position":[[136,10],[165,10],[1842,10]]},"1674":{"position":[[497,10],[614,10]]},"1682":{"position":[[678,10]]},"1693":{"position":[[50,10]]},"1695":{"position":[[6,10]]},"1698":{"position":[[9,10]]},"1700":{"position":[[0,10]]},"1754":{"position":[[77,11]]},"1782":{"position":[[2685,10],[2754,10],[2934,10],[3019,10]]}}}],["supplementari",{"_index":2527,"t":{"696":{"position":[[814,13]]}}}],["support",{"_index":58,"t":{"7":{"position":[[361,8]]},"9":{"position":[[11,7]]},"1616":{"position":[[11,8]]},"1620":{"position":[[27,10]]},"1622":{"position":[[28,10]]},"1624":{"position":[[25,9]]},"1632":{"position":[[35,7]]}}}],["suppress",{"_index":701,"t":{"153":{"position":[[164,11]]}}}],["surfac",{"_index":1034,"t":{"225":{"position":[[118,7]]},"227":{"position":[[271,8],[645,7]]}}}],["svamp",{"_index":1540,"t":{"391":{"position":[[27,5]]}}}],["svd",{"_index":2702,"t":{"774":{"position":[[107,5]]},"784":{"position":[[578,5],[729,3]]},"786":{"position":[[3719,3],[3921,3],[3947,3],[4022,3],[4280,3]]},"793":{"position":[[21,3]]},"795":{"position":[[1194,3],[1369,3],[1427,3]]},"797":{"position":[[4,3]]},"839":{"position":[[25,3],[119,3],[141,3],[402,3],[475,3]]},"843":{"position":[[185,5]]}}}],["sw",{"_index":234,"t":{"38":{"position":[[435,2]]},"195":{"position":[[58,2]]}}}],["swag",{"_index":2076,"t":{"594":{"position":[[781,4]]}}}],["sweep",{"_index":2360,"t":{"666":{"position":[[408,5]]},"668":{"position":[[118,5]]},"670":{"position":[[193,6],[335,6]]},"672":{"position":[[263,5]]},"674":{"position":[[265,6],[417,6]]}}}],["swin",{"_index":1414,"t":{"339":{"position":[[395,4]]}}}],["switch",{"_index":944,"t":{"193":{"position":[[167,8]]},"719":{"position":[[949,9]]},"1369":{"position":[[330,6]]}}}],["symbol",{"_index":1146,"t":{"285":{"position":[[103,6]]},"289":{"position":[[74,6],[259,6],[374,7]]},"310":{"position":[[0,6]]},"382":{"position":[[216,8]]},"384":{"position":[[92,8],[341,8],[894,8]]},"386":{"position":[[390,8]]},"418":{"position":[[28,8]]},"426":{"position":[[183,8]]},"430":{"position":[[87,8]]},"561":{"position":[[336,8]]}}}],["syntact",{"_index":5155,"t":{"1646":{"position":[[70,9]]}}}],["syntax",{"_index":5104,"t":{"1624":{"position":[[40,6]]},"1626":{"position":[[25,6]]}}}],["sys.stdin.readlin",{"_index":4876,"t":{"1536":{"position":[[176,21],[314,21],[374,20],[466,20]]}}}],["system",{"_index":791,"t":{"170":{"position":[[1694,7],[1869,7]]},"483":{"position":[[164,6]]},"531":{"position":[[1259,6]]},"934":{"position":[[2071,7],[2575,7]]},"955":{"position":[[321,6],[427,6],[561,6],[660,6],[724,6],[795,6]]},"959":{"position":[[225,6]]},"963":{"position":[[285,6]]},"965":{"position":[[320,6]]},"973":{"position":[[53,6],[385,6]]},"1585":{"position":[[80,7]]},"1782":{"position":[[1217,6]]}}}],["systemat",{"_index":4588,"t":{"1409":{"position":[[1704,10]]}}}],["sébastien",{"_index":5015,"t":{"1587":{"position":[[265,9]]}}}],["s∈rn×n\\text{",{"_index":3120,"t":{"853":{"position":[[581,14]]}}}],["t",{"_index":2056,"t":{"587":{"position":[[603,1],[694,1]]},"589":{"position":[[2134,1]]},"594":{"position":[[943,1]]},"602":{"position":[[5,1]]},"604":{"position":[[0,1]]},"606":{"position":[[45,1],[249,1],[371,1]]},"608":{"position":[[0,1]]},"610":{"position":[[66,1],[485,1]]},"612":{"position":[[0,1],[324,1],[425,1]]},"614":{"position":[[0,1]]},"616":{"position":[[51,1],[235,1]]},"618":{"position":[[49,1],[301,1],[384,1],[434,1]]},"620":{"position":[[0,1],[38,1]]},"622":{"position":[[4,1],[120,1],[267,1],[382,1],[477,1],[664,1]]},"853":{"position":[[868,7],[1584,7]]},"855":{"position":[[329,7]]},"861":{"position":[[241,1]]},"1070":{"position":[[748,1]]},"1162":{"position":[[300,2]]},"1164":{"position":[[353,2]]},"1167":{"position":[[1410,2]]},"1238":{"position":[[988,2]]}}}],["t(x",{"_index":5255,"t":{"1657":{"position":[[774,4]]}}}],["t(x)=[tfes(x);tfes,eo(x);tfeo(x)]=‘‘x",{"_index":5252,"t":{"1657":{"position":[[664,37]]}}}],["t(x)t(x)t(x",{"_index":5288,"t":{"1657":{"position":[[2283,12]]}}}],["t(⋅)t(\\cdot)t",{"_index":5316,"t":{"1659":{"position":[[747,16]]}}}],["t0",{"_index":1986,"t":{"544":{"position":[[158,2]]},"548":{"position":[[8,2]]},"557":{"position":[[89,2]]},"587":{"position":[[587,2]]},"589":{"position":[[1776,2]]},"594":{"position":[[111,2],[118,2],[383,2],[521,2],[555,3],[565,4],[575,2],[681,2]]},"598":{"position":[[3061,2]]},"600":{"position":[[304,2]]},"602":{"position":[[30,2],[97,2]]},"604":{"position":[[15,2],[34,2]]},"606":{"position":[[3,2],[61,2],[93,3],[174,3],[379,2]]},"608":{"position":[[319,2]]},"612":{"position":[[433,2]]},"614":{"position":[[374,2],[491,2]]},"620":{"position":[[17,2],[32,2]]}}}],["t0:vt=vf+(v0−vf)(1−t−t0n△t)3t_0",{"_index":3149,"t":{"853":{"position":[[1905,32]]}}}],["t1t^1t1",{"_index":4634,"t":{"1429":{"position":[[388,8]]}}}],["t2t^2t2",{"_index":4635,"t":{"1429":{"position":[[397,7]]}}}],["t5",{"_index":1643,"t":{"455":{"position":[[143,2]]},"468":{"position":[[95,3]]},"485":{"position":[[915,2]]},"504":{"position":[[217,2],[335,2]]},"517":{"position":[[63,2]]},"537":{"position":[[213,3]]},"539":{"position":[[448,2],[485,2],[500,2],[509,2]]},"541":{"position":[[152,3]]},"550":{"position":[[0,3],[248,4]]},"567":{"position":[[138,2],[402,2],[489,2],[573,2]]},"577":{"position":[[44,3]]},"589":{"position":[[1796,2]]},"594":{"position":[[123,2],[282,2]]},"606":{"position":[[403,2]]},"608":{"position":[[324,2]]},"626":{"position":[[450,2]]},"628":{"position":[[12,2],[1368,2],[1590,2]]},"633":{"position":[[169,2],[251,2],[260,2],[270,2],[296,2],[304,2]]},"640":{"position":[[10,2],[25,2],[208,2],[224,2]]},"644":{"position":[[246,2]]},"646":{"position":[[299,2],[386,2]]},"683":{"position":[[306,2]]},"690":{"position":[[34,2]]},"703":{"position":[[41,2]]},"705":{"position":[[140,2],[149,2],[159,2]]},"707":{"position":[[92,2],[364,2]]},"786":{"position":[[73,2]]},"994":{"position":[[636,2]]},"999":{"position":[[623,2]]},"1006":{"position":[[276,2],[287,2],[430,2]]},"1070":{"position":[[802,2],[1236,2],[1388,2],[1511,2],[1529,2],[1545,2]]},"1080":{"position":[[34,4],[281,2]]},"1082":{"position":[[149,2],[239,2]]},"1124":{"position":[[303,2]]},"1126":{"position":[[940,2]]},"1128":{"position":[[0,2],[234,2],[1512,2]]},"1132":{"position":[[36,2],[107,2],[844,2],[948,2],[1186,2],[1248,2],[1448,2],[1694,2]]},"1134":{"position":[[27,2],[153,2]]},"1136":{"position":[[30,2],[234,2],[649,2],[695,2]]},"1141":{"position":[[201,2]]},"1143":{"position":[[80,2],[575,2]]},"1145":{"position":[[646,2]]},"1149":{"position":[[604,2]]},"1157":{"position":[[342,2],[352,2],[415,2]]},"1159":{"position":[[1687,2],[1697,2],[1746,2]]},"1183":{"position":[[16,2],[79,2],[96,2]]},"1187":{"position":[[0,2],[321,2]]},"1197":{"position":[[82,2]]},"1199":{"position":[[250,2]]},"1203":{"position":[[113,2]]},"1205":{"position":[[47,2]]},"1214":{"position":[[37,2]]},"1227":{"position":[[1309,2]]},"1255":{"position":[[79,2],[221,2],[238,2]]},"1259":{"position":[[159,2]]},"1266":{"position":[[104,2]]},"1268":{"position":[[142,2]]},"1347":{"position":[[1653,2],[1670,2],[2043,2],[2053,2]]},"1357":{"position":[[263,2]]},"1360":{"position":[[68,2],[88,2],[202,2]]},"1367":{"position":[[34,2]]},"1373":{"position":[[111,2]]},"1409":{"position":[[852,2],[869,2],[1178,2]]},"1413":{"position":[[73,2]]},"1419":{"position":[[282,2],[589,2]]},"1423":{"position":[[72,2],[1497,2]]},"1427":{"position":[[320,2]]},"1471":{"position":[[153,2]]},"1477":{"position":[[0,2],[277,2]]},"1494":{"position":[[13,2]]},"1496":{"position":[[161,2]]},"1499":{"position":[[265,2],[275,2],[283,2],[514,2],[554,2],[594,2]]},"1511":{"position":[[91,2]]},"1718":{"position":[[705,2],[761,2],[851,2]]},"1772":{"position":[[401,2],[482,4]]},"1802":{"position":[[185,3]]}}}],["t5+lm",{"_index":2197,"t":{"606":{"position":[[152,5]]}}}],["t5.1.1",{"_index":3927,"t":{"1134":{"position":[[84,6]]}}}],["t5/gpt",{"_index":3720,"t":{"1080":{"position":[[435,6]]}}}],["t5b",{"_index":4060,"t":{"1195":{"position":[[196,4],[236,3]]},"1201":{"position":[[245,3]]}}}],["t5l",{"_index":4061,"t":{"1195":{"position":[[201,3]]}}}],["t=100\\triangle_t",{"_index":3015,"t":{"807":{"position":[[444,17]]}}}],["t=[t1,t2,…,tn]∈rn×dt",{"_index":4118,"t":{"1238":{"position":[[556,20]]}}}],["t={[p0:i],x,[pi+1:m],y}t",{"_index":3784,"t":{"1099":{"position":[[1001,24]]}}}],["t={[p0:i​],x,[pi+1:m​],i",{"_index":3787,"t":{"1099":{"position":[[1087,27]]}}}],["t={t1,t2,…,tt}\\pmb{\\mathcal{t",{"_index":4103,"t":{"1236":{"position":[[142,31]]},"1246":{"position":[[904,31]]}}}],["t={x,i",{"_index":5173,"t":{"1651":{"position":[[391,9]]}}}],["t={x,y}\\mathcal{t",{"_index":5170,"t":{"1651":{"position":[[342,18]]}}}],["t\\mathcal{t}t",{"_index":3659,"t":{"1065":{"position":[[118,13]]},"1238":{"position":[[1331,13]]},"1246":{"position":[[1081,13]]},"1651":{"position":[[1579,13]]}}}],["t\\pmb{\\mathcal{t}}tt",{"_index":4113,"t":{"1236":{"position":[[688,20]]},"1238":{"position":[[62,20],[290,20]]}}}],["t\\tau_tτt",{"_index":4762,"t":{"1455":{"position":[[539,11]]}}}],["t\\triangl",{"_index":3157,"t":{"853":{"position":[[2158,11]]}}}],["t\\triangle_t△t",{"_index":3014,"t":{"807":{"position":[[415,16]]}}}],["t^2",{"_index":4639,"t":{"1429":{"position":[[642,4],[1002,4]]}}}],["t_0}{n",{"_index":3154,"t":{"853":{"position":[[1973,6]]}}}],["t_1",{"_index":4119,"t":{"1238":{"position":[[579,5]]}}}],["t_2",{"_index":4120,"t":{"1238":{"position":[[585,4]]}}}],["t_l",{"_index":3304,"t":{"891":{"position":[[787,4]]},"893":{"position":[[579,4],[623,4],[628,4],[674,4],[679,4]]}}}],["t_l][pl​;tl",{"_index":3309,"t":{"893":{"position":[[244,13]]}}}],["t_l^o",{"_index":3363,"t":{"893":{"position":[[2315,5]]}}}],["t_n",{"_index":4121,"t":{"1238":{"position":[[597,4]]}}}],["t_{f_{e_",{"_index":5216,"t":{"1655":{"position":[[897,11],[1816,10]]}}}],["t_{f_{e_o}}(x",{"_index":5258,"t":{"1657":{"position":[[818,15]]}}}],["t_{f_{e_s,e_o}}(x",{"_index":5257,"t":{"1657":{"position":[[798,19]]}}}],["t_{f_{e_s}}(x",{"_index":5256,"t":{"1657":{"position":[[781,16]]}}}],["tabl",{"_index":512,"t":{"104":{"position":[[0,5]]},"110":{"position":[[135,5]]},"157":{"position":[[408,5]]},"308":{"position":[[961,6]]},"310":{"position":[[859,5]]},"322":{"position":[[59,6],[651,5]]},"515":{"position":[[480,5]]},"529":{"position":[[309,6],[385,5],[708,6],[858,5],[1154,6],[1660,5]]},"608":{"position":[[671,5]]},"618":{"position":[[371,5]]},"640":{"position":[[0,5],[198,5]]},"670":{"position":[[1227,5]]},"676":{"position":[[856,6]]},"690":{"position":[[480,5]]},"709":{"position":[[272,5],[2468,5]]},"727":{"position":[[500,5]]},"765":{"position":[[26,5]]},"770":{"position":[[233,6]]},"776":{"position":[[241,5]]},"778":{"position":[[421,5]]},"835":{"position":[[184,5]]},"837":{"position":[[94,5]]},"839":{"position":[[341,5]]},"870":{"position":[[0,5],[287,5],[477,5],[2102,5]]},"873":{"position":[[0,5],[575,5]]},"875":{"position":[[66,5]]},"877":{"position":[[57,5]]},"909":{"position":[[0,5]]},"919":{"position":[[146,5]]},"963":{"position":[[106,5]]},"1002":{"position":[[0,5],[250,5],[364,5],[954,5]]},"1004":{"position":[[0,5],[338,5]]},"1006":{"position":[[1023,5]]},"1026":{"position":[[224,5]]},"1037":{"position":[[212,5]]},"1047":{"position":[[0,5]]},"1049":{"position":[[0,5]]},"1084":{"position":[[628,5]]},"1107":{"position":[[544,5]]},"1109":{"position":[[802,6]]},"1115":{"position":[[230,6],[437,5],[914,5]]},"1117":{"position":[[0,5]]},"1128":{"position":[[752,5]]},"1147":{"position":[[468,5],[984,5]]},"1149":{"position":[[677,5]]},"1195":{"position":[[258,5]]},"1197":{"position":[[117,5],[276,5]]},"1248":{"position":[[455,5]]},"1250":{"position":[[67,6],[89,6]]},"1262":{"position":[[0,5],[68,5],[126,5]]},"1264":{"position":[[114,5],[189,5]]},"1266":{"position":[[162,5]]},"1283":{"position":[[172,5]]},"1289":{"position":[[460,5]]},"1291":{"position":[[1007,5],[1582,5]]},"1294":{"position":[[105,5],[145,5]]},"1303":{"position":[[534,5]]},"1310":{"position":[[0,5],[176,5]]},"1312":{"position":[[0,5]]},"1314":{"position":[[0,5],[721,5],[827,5]]},"1317":{"position":[[60,5],[255,5],[573,5],[625,5]]},"1319":{"position":[[106,5],[155,5],[214,5],[265,5],[300,5],[348,5]]},"1321":{"position":[[0,5],[457,5]]},"1323":{"position":[[0,5],[139,5],[171,5],[457,5],[508,5],[518,5],[637,5]]},"1326":{"position":[[111,5]]},"1328":{"position":[[154,5]]},"1330":{"position":[[255,5]]},"1360":{"position":[[0,5]]},"1362":{"position":[[45,5]]},"1364":{"position":[[333,5]]},"1379":{"position":[[526,6]]},"1397":{"position":[[741,5],[1127,5]]},"1399":{"position":[[0,5]]},"1431":{"position":[[2354,5]]},"1468":{"position":[[1484,6]]},"1499":{"position":[[87,5],[97,5],[488,5]]},"1501":{"position":[[194,5]]},"1507":{"position":[[48,5]]},"1509":{"position":[[92,5]]},"1511":{"position":[[175,5]]},"1513":{"position":[[369,5],[581,5]]},"1523":{"position":[[343,5],[379,5]]},"1653":{"position":[[707,5]]},"1665":{"position":[[1022,5],[1106,5]]},"1667":{"position":[[19,5]]},"1669":{"position":[[0,5],[788,5]]},"1672":{"position":[[0,5]]},"1674":{"position":[[165,5]]},"1676":{"position":[[0,5],[113,5]]},"1680":{"position":[[0,5]]},"1684":{"position":[[0,5]]},"1702":{"position":[[544,5]]},"1704":{"position":[[372,5]]},"1788":{"position":[[374,6]]}}}],["tacr",{"_index":5327,"t":{"1663":{"position":[[63,6],[143,6],[230,6],[249,6]]},"1667":{"position":[[973,6]]}}}],["tacrev",{"_index":5329,"t":{"1663":{"position":[[134,6]]}}}],["tag",{"_index":59,"t":{"7":{"position":[[370,4]]},"529":{"position":[[2354,7]]},"1014":{"position":[[1565,7]]},"1026":{"position":[[71,7],[117,7],[297,7]]},"1585":{"position":[[76,3]]},"1587":{"position":[[386,5]]},"1653":{"position":[[197,3],[444,4]]},"1768":{"position":[[587,7]]},"1782":{"position":[[1801,4]]}}}],["tag{1",{"_index":3431,"t":{"945":{"position":[[660,7]]}}}],["tag{1}lplm​=−i∑​logp(yi​∣xi",{"_index":4125,"t":{"1238":{"position":[[917,29]]}}}],["tag{1}maximizej=1∑l​wj​logp(yj​∣x,y1:j−1​),(1",{"_index":633,"t":{"132":{"position":[[851,47]]}}}],["tag{1}pc​=∑j=1c​exp(<fjtext​,fimage>/τ)exp(<fctext​,fimage>/τ)​(1",{"_index":1438,"t":{"350":{"position":[[662,67]]}}}],["tag{1}z^=z∈zsearch",{"_index":5428,"t":{"1704":{"position":[[587,20]]}}}],["tag{1}ϕmax​(x,y)∈z∑​t=1∑∣y∣​log(pϕ​(yt​∣x,y<t​))(1",{"_index":2603,"t":{"723":{"position":[[592,52]]}}}],["tag{2",{"_index":3434,"t":{"945":{"position":[[727,7]]}}}],["tag{2}p^=p∗∘wk​=p∗∘(uk​⨂vkt​)(2",{"_index":4145,"t":{"1242":{"position":[[694,33]]}}}],["tag{2}y^​=cargmax",{"_index":1446,"t":{"350":{"position":[[929,19]]}}}],["tag{2}θmax​(x,y)∈z∑​t=1∑∣y∣​log(pϕ0​+△ϕ(θ)​(yt​∣x,y<t​))(2",{"_index":2611,"t":{"723":{"position":[[1313,60]]}}}],["tag{3}h=w0​x+△wx=w0​x+bax(3",{"_index":2639,"t":{"733":{"position":[[831,29]]}}}],["tag{3}llogit​=k∈s∣∑​(xi​,yi​)∈sk​∑​kl",{"_index":4163,"t":{"1244":{"position":[[1015,38]]}}}],["tag{3}vc​=[v,wc​],(3",{"_index":1477,"t":{"358":{"position":[[467,22]]}}}],["tag{4}lhidden​=k∈s∣∑​(xi​,yi​)∈sk",{"_index":4175,"t":{"1244":{"position":[[1557,37]]}}}],["tag{4}pc​=∑j=1c​exp(<g(vj​),fimage>/τ)exp(<g(vc​),fimage>/τ)​(4",{"_index":1489,"t":{"358":{"position":[[1066,65]]}}}],["tag{4}ϕ(ar=8​,ar=64​,i,j)=min(i,j)∣∣uar=8​i⊤​uar=64​j​∣∣f2​​∈[0,1](4",{"_index":2719,"t":{"774":{"position":[[642,70]]}}}],["tag{5}ltotal​=lplm​+λ(llogits​+lhidden​)(5",{"_index":4184,"t":{"1244":{"position":[[2127,44]]}}}],["tail",{"_index":5448,"t":{"1718":{"position":[[1093,6]]}}}],["tak",{"_index":3555,"t":{"992":{"position":[[69,4]]}}}],["take",{"_index":4982,"t":{"1581":{"position":[[150,4]]},"1626":{"position":[[128,4],[206,4]]}}}],["taken",{"_index":1641,"t":{"453":{"position":[[120,5],[178,5]]}}}],["tanh",{"_index":2440,"t":{"676":{"position":[[1541,4]]}}}],["target",{"_index":476,"t":{"91":{"position":[[2495,6]]},"108":{"position":[[83,6]]},"163":{"position":[[155,6]]},"165":{"position":[[656,6]]},"170":{"position":[[562,6],[832,6],[905,6],[922,6],[962,6]]},"313":{"position":[[132,6],[354,6]]},"334":{"position":[[358,6]]},"336":{"position":[[510,6],[815,6],[965,6]]},"341":{"position":[[328,6],[533,6]]},"343":{"position":[[409,6]]},"345":{"position":[[78,6],[133,6]]},"347":{"position":[[137,6]]},"350":{"position":[[52,6]]},"352":{"position":[[35,6],[337,6]]},"356":{"position":[[315,6]]},"358":{"position":[[284,6]]},"360":{"position":[[38,6]]},"441":{"position":[[88,6],[157,6]]},"494":{"position":[[109,6]]},"529":{"position":[[2826,9]]},"550":{"position":[[280,6]]},"589":{"position":[[34,6],[200,6],[635,6],[939,6]]},"596":{"position":[[271,6],[762,6],[813,6],[969,6],[1188,6]]},"608":{"position":[[860,6],[987,6]]},"610":{"position":[[98,6]]},"723":{"position":[[162,6]]},"803":{"position":[[320,6]]},"847":{"position":[[518,6]]},"853":{"position":[[1786,6],[2114,6]]},"861":{"position":[[361,6]]},"866":{"position":[[1067,6]]},"953":{"position":[[623,6]]},"977":{"position":[[316,6],[431,6]]},"979":{"position":[[26,6],[615,6],[636,6],[675,6],[1085,6]]},"982":{"position":[[132,6],[183,6],[222,6],[380,6],[397,6],[622,6],[1209,6]]},"984":{"position":[[183,6],[496,6]]},"986":{"position":[[4,6],[158,6],[199,6]]},"988":{"position":[[175,6]]},"990":{"position":[[450,6]]},"992":{"position":[[62,6],[126,6],[246,6],[357,6],[470,6],[540,6],[684,6],[763,6],[971,6],[1001,6],[1120,6]]},"994":{"position":[[301,6]]},"997":{"position":[[164,6],[389,6],[575,6]]},"999":{"position":[[43,6],[112,6],[481,6],[1133,6]]},"1002":{"position":[[872,6]]},"1006":{"position":[[521,6],[627,6],[956,6],[993,6],[1081,6],[1113,7],[2123,6],[2170,6],[2544,6],[2588,6],[2738,6],[2782,9]]},"1014":{"position":[[88,6]]},"1062":{"position":[[638,6]]},"1065":{"position":[[106,6],[638,8]]},"1070":{"position":[[487,6]]},"1084":{"position":[[161,6]]},"1099":{"position":[[367,6],[632,6],[809,6],[845,6]]},"1107":{"position":[[799,6]]},"1130":{"position":[[567,6]]},"1132":{"position":[[220,6],[462,6],[926,6],[1014,6],[1366,6],[1417,6]]},"1143":{"position":[[227,6]]},"1187":{"position":[[410,6]]},"1225":{"position":[[420,6]]},"1227":{"position":[[662,6],[800,6],[1556,6]]},"1230":{"position":[[695,6],[824,6]]},"1232":{"position":[[122,6]]},"1234":{"position":[[204,6]]},"1236":{"position":[[129,6]]},"1238":{"position":[[50,6],[277,6],[1224,6],[1318,6]]},"1240":{"position":[[300,6],[394,6]]},"1244":{"position":[[1870,6]]},"1246":{"position":[[0,6],[523,6],[546,6],[582,6],[891,6]]},"1248":{"position":[[144,6],[312,6],[435,6]]},"1253":{"position":[[117,6]]},"1257":{"position":[[140,6],[275,6]]},"1259":{"position":[[211,6],[260,6]]},"1264":{"position":[[262,6]]},"1266":{"position":[[39,6]]},"1270":{"position":[[83,6],[138,6]]},"1273":{"position":[[307,6]]},"1279":{"position":[[10,6],[235,6]]},"1283":{"position":[[208,6]]},"1285":{"position":[[291,6],[353,6]]},"1407":{"position":[[318,6],[657,6]]},"1409":{"position":[[751,6],[1065,6],[1141,6],[1287,6]]},"1411":{"position":[[0,6],[78,6],[227,6],[292,6],[388,6]]},"1415":{"position":[[93,6],[285,6]]},"1421":{"position":[[52,6]]},"1423":{"position":[[677,6],[886,6]]},"1425":{"position":[[247,6],[508,6]]},"1427":{"position":[[23,6],[61,6],[101,6],[213,6],[437,6],[464,6],[490,6],[695,6],[860,6],[913,6],[1131,6]]},"1429":{"position":[[333,6]]},"1431":{"position":[[65,6],[109,6],[621,6],[658,6],[851,6],[873,6],[1277,6],[1389,6],[1423,6],[1467,6],[1531,6],[1700,6],[1741,6],[1879,6],[2300,8],[2364,6],[2497,6],[2637,6],[2923,6]]},"1436":{"position":[[283,6]]},"1442":{"position":[[1296,8]]},"1473":{"position":[[452,6]]},"1477":{"position":[[998,6]]},"1481":{"position":[[209,6]]},"1494":{"position":[[120,6],[318,6]]},"1513":{"position":[[172,6],[559,6]]},"1523":{"position":[[25,6],[120,6],[161,6],[217,6]]},"1695":{"position":[[52,6]]},"1736":{"position":[[829,6]]}}}],["target\\phi_{target}ϕtarget",{"_index":3478,"t":{"982":{"position":[[995,28]]}}}],["task",{"_index":374,"t":{"84":{"position":[[4,4]]},"97":{"position":[[47,4]]},"102":{"position":[[230,4]]},"118":{"position":[[4,4]]},"124":{"position":[[81,4],[154,4],[268,4],[364,4],[427,4],[459,4],[500,4],[529,4],[579,4],[609,4]]},"126":{"position":[[4,4],[110,4],[149,4],[202,4],[358,4],[532,5],[637,4],[678,4],[735,4],[813,4],[880,5],[979,4],[1093,4],[1143,4],[1199,4],[1222,4]]},"128":{"position":[[20,4],[39,5],[92,4],[122,4]]},"130":{"position":[[6,4],[236,4],[315,4],[1582,4]]},"132":{"position":[[355,4],[426,4],[476,4],[502,4]]},"134":{"position":[[2,4],[50,4]]},"136":{"position":[[6,4],[81,4]]},"138":{"position":[[11,4],[51,4],[131,4],[172,4],[351,4],[415,4],[444,4],[467,4],[504,4],[532,4]]},"140":{"position":[[186,4],[217,4],[313,4],[328,4]]},"143":{"position":[[75,4],[461,4]]},"151":{"position":[[161,4]]},"153":{"position":[[229,4],[290,4],[469,4],[611,4],[681,4]]},"155":{"position":[[57,4],[78,4],[132,4],[196,4],[216,4],[230,4],[293,4],[343,4],[401,4],[614,4],[838,4],[862,4],[924,4],[948,4],[1019,4]]},"157":{"position":[[131,4],[172,4],[220,4],[356,4],[370,4]]},"159":{"position":[[8,4],[36,4],[96,4],[164,4],[188,4],[244,4],[898,4],[950,4]]},"163":{"position":[[109,4],[218,4],[295,4],[410,5],[604,4],[668,4],[759,4],[792,4]]},"165":{"position":[[34,5],[59,4],[354,4],[365,4],[733,5],[841,5],[932,4],[994,4],[1199,5],[1273,5],[1373,5],[1594,5],[2368,4],[2435,4],[2532,5],[2703,5],[2758,4],[2783,5],[2860,5]]},"168":{"position":[[47,5],[334,5],[405,5]]},"170":{"position":[[210,5],[368,5],[520,5]]},"174":{"position":[[61,5],[738,5],[1734,5],[1881,5],[2632,5]]},"177":{"position":[[1023,5],[1126,5]]},"179":{"position":[[16,5]]},"205":{"position":[[89,4],[293,5]]},"207":{"position":[[3,5],[13,6],[35,5],[56,5],[82,5]]},"209":{"position":[[67,5]]},"213":{"position":[[56,4]]},"215":{"position":[[176,4],[204,4],[1512,4]]},"236":{"position":[[570,4]]},"253":{"position":[[112,4]]},"262":{"position":[[209,4]]},"269":{"position":[[210,4]]},"283":{"position":[[124,4],[260,4]]},"285":{"position":[[332,4]]},"287":{"position":[[549,4],[715,4]]},"310":{"position":[[530,5],[1134,5]]},"322":{"position":[[27,4],[250,4],[348,4]]},"326":{"position":[[17,5],[63,5],[79,4],[871,4]]},"328":{"position":[[162,5],[308,4]]},"334":{"position":[[247,4]]},"336":{"position":[[151,4],[489,4],[876,4],[1923,4]]},"352":{"position":[[265,4]]},"382":{"position":[[235,4]]},"384":{"position":[[118,4],[425,4],[804,4],[1125,4],[1184,4]]},"386":{"position":[[7,4],[412,4]]},"388":{"position":[[77,4],[86,4]]},"399":{"position":[[293,4],[360,4]]},"414":{"position":[[83,4]]},"416":{"position":[[3,4],[150,4]]},"420":{"position":[[9,4]]},"422":{"position":[[33,5]]},"424":{"position":[[366,5],[424,4]]},"426":{"position":[[301,4],[381,4]]},"430":{"position":[[170,4]]},"434":{"position":[[34,4],[163,4],[319,4]]},"436":{"position":[[34,4],[334,4],[359,4],[467,4],[581,4],[1097,4],[1544,4],[1554,4],[2019,4]]},"441":{"position":[[40,4],[128,4]]},"447":{"position":[[136,4],[171,4],[231,4],[389,4],[507,4],[582,4],[770,4]]},"455":{"position":[[824,4],[870,4],[1022,4],[1030,4]]},"477":{"position":[[100,4]]},"483":{"position":[[147,4],[223,4],[324,4],[565,5],[874,4],[899,4]]},"485":{"position":[[74,4],[127,4],[177,4],[267,4],[363,4],[417,4],[505,4],[802,4],[893,4],[978,4]]},"488":{"position":[[32,4]]},"490":{"position":[[124,4]]},"494":{"position":[[268,4]]},"496":{"position":[[206,5],[269,4]]},"498":{"position":[[2,5],[177,4],[197,4]]},"500":{"position":[[2,4],[387,4],[730,4]]},"502":{"position":[[2,4],[480,5]]},"506":{"position":[[69,5],[88,5],[116,5],[132,4]]},"508":{"position":[[88,4]]},"510":{"position":[[246,4]]},"512":{"position":[[24,5],[104,4],[121,4],[209,4]]},"515":{"position":[[261,5],[814,4]]},"521":{"position":[[283,4]]},"523":{"position":[[54,4],[132,4],[315,5],[421,4],[454,5],[486,5],[911,4]]},"525":{"position":[[119,4],[223,4],[251,4],[306,4],[352,4],[419,4],[591,4],[664,4],[978,5],[1079,4],[1136,4],[1203,4],[1282,4],[1333,4],[1343,4],[1506,4],[1597,4]]},"527":{"position":[[103,4],[197,4],[340,4],[378,4]]},"529":{"position":[[86,4],[531,5],[1428,4],[2289,6],[2301,4]]},"531":{"position":[[910,4]]},"533":{"position":[[74,4],[217,4],[443,4]]},"537":{"position":[[47,4],[130,5]]},"539":{"position":[[74,4],[294,6],[329,4],[542,4]]},"544":{"position":[[83,4],[101,4],[150,7],[169,7],[188,6],[214,4]]},"546":{"position":[[52,4]]},"550":{"position":[[345,5]]},"553":{"position":[[40,4],[85,4],[138,4],[197,4]]},"557":{"position":[[20,4],[129,4],[211,4],[241,5],[275,4]]},"559":{"position":[[188,4]]},"563":{"position":[[136,4],[276,4],[294,4]]},"571":{"position":[[45,4]]},"573":{"position":[[51,4],[114,4],[160,4],[173,4]]},"575":{"position":[[53,4],[118,4],[263,4]]},"583":{"position":[[84,4],[176,4]]},"587":{"position":[[126,4],[333,4],[616,5],[627,4],[733,5]]},"589":{"position":[[41,4],[218,4],[315,4],[349,4],[592,4],[801,4],[1167,4],[1453,4],[1730,4],[1896,5],[2277,4]]},"592":{"position":[[68,4],[174,4],[225,4],[280,4],[355,4]]},"594":{"position":[[374,4],[744,4],[1269,5]]},"596":{"position":[[1235,5]]},"598":{"position":[[111,4],[173,4],[196,4],[335,4],[538,4],[652,4],[873,4],[2514,4],[2561,4],[2597,4],[3022,4],[3233,4],[3383,4],[3588,4]]},"600":{"position":[[79,5],[169,5],[192,4]]},"602":{"position":[[56,4]]},"604":{"position":[[94,4]]},"614":{"position":[[318,4]]},"618":{"position":[[126,4],[473,4]]},"622":{"position":[[606,5],[652,4]]},"626":{"position":[[242,4]]},"628":{"position":[[190,4],[219,4],[266,4],[620,4],[650,4],[828,4],[906,4],[950,4],[957,4],[1476,4],[1500,4]]},"630":{"position":[[45,4],[306,4],[2375,4]]},"633":{"position":[[19,4],[762,4]]},"638":{"position":[[109,4]]},"640":{"position":[[57,5],[184,4]]},"646":{"position":[[334,4]]},"648":{"position":[[61,4],[320,4],[348,4],[771,4],[934,4]]},"656":{"position":[[83,4],[100,4],[199,4],[254,4],[348,4],[376,4],[431,4]]},"658":{"position":[[33,4],[222,6],[265,4],[332,4],[371,4],[473,4],[524,4],[568,4],[1066,4],[1208,4],[1258,4],[1391,4],[1838,4],[1892,4],[2336,4],[2416,4],[2478,4],[2519,4],[2565,4],[2644,4],[2686,4],[2725,4],[2790,4],[2824,4],[2934,4],[3040,4]]},"660":{"position":[[18,4],[85,4],[130,4],[191,4],[349,4],[409,4],[680,4],[799,4]]},"662":{"position":[[56,4],[991,4],[1334,4]]},"664":{"position":[[19,4],[169,4]]},"666":{"position":[[489,4]]},"668":{"position":[[339,4]]},"670":{"position":[[59,4],[748,4],[907,4],[1057,4],[1110,4],[1571,4],[1612,4]]},"672":{"position":[[289,4],[399,4],[517,5],[603,4],[639,4]]},"674":{"position":[[35,4]]},"676":{"position":[[750,4],[779,4],[1212,4],[1318,4]]},"679":{"position":[[104,4]]},"681":{"position":[[11,4],[208,4],[1598,4],[2042,4]]},"683":{"position":[[114,4],[254,4],[460,4],[807,4]]},"686":{"position":[[34,4],[71,4],[456,4]]},"690":{"position":[[26,4]]},"692":{"position":[[370,4],[400,4]]},"694":{"position":[[201,4],[242,4]]},"696":{"position":[[20,4],[279,4],[1702,4]]},"698":{"position":[[13,4],[54,4],[67,4]]},"701":{"position":[[28,4]]},"707":{"position":[[425,4]]},"709":{"position":[[155,4],[370,4],[1290,4],[1408,4],[1451,4],[2202,4],[2586,4]]},"713":{"position":[[202,4],[212,4],[294,4]]},"717":{"position":[[179,4]]},"719":{"position":[[49,4],[151,4],[181,4],[215,4],[823,4],[918,4],[944,4]]},"723":{"position":[[147,4],[681,4],[917,4]]},"733":{"position":[[105,4]]},"737":{"position":[[14,4]]},"739":{"position":[[256,4]]},"741":{"position":[[384,4]]},"743":{"position":[[36,4]]},"759":{"position":[[18,4],[121,4]]},"784":{"position":[[54,5],[164,5]]},"786":{"position":[[164,5],[201,5],[237,4],[405,4],[464,5],[482,4],[3513,4],[4403,4],[4553,4]]},"812":{"position":[[115,6],[148,5],[185,5]]},"819":{"position":[[90,4]]},"826":{"position":[[4,5]]},"833":{"position":[[161,4],[220,4]]},"841":{"position":[[394,4]]},"843":{"position":[[374,4]]},"847":{"position":[[459,4],[567,4]]},"849":{"position":[[74,4],[158,4],[521,4],[1325,4],[1516,4]]},"851":{"position":[[1127,4],[1243,4]]},"859":{"position":[[0,4],[128,4]]},"861":{"position":[[868,4]]},"866":{"position":[[47,4],[113,4],[270,4],[506,5],[605,5],[655,5],[919,6],[971,6]]},"870":{"position":[[300,4],[983,4],[1053,4],[2216,4],[2348,4]]},"875":{"position":[[4,4],[256,4]]},"879":{"position":[[48,4],[100,4]]},"885":{"position":[[583,4]]},"895":{"position":[[1227,4]]},"897":{"position":[[101,4]]},"901":{"position":[[24,4],[212,5]]},"924":{"position":[[107,4]]},"934":{"position":[[891,4],[1222,4]]},"947":{"position":[[169,4]]},"955":{"position":[[774,4]]},"977":{"position":[[12,4],[70,5],[158,5],[270,5],[323,4],[438,4],[498,4],[518,5],[668,5],[681,4]]},"979":{"position":[[33,4],[82,4],[124,5],[176,5],[215,4],[286,4],[435,4],[486,5],[561,5],[572,5],[622,4],[749,5],[804,4],[994,4],[1018,5],[1067,5],[1092,4],[1117,4],[1177,4],[1189,4],[1273,4],[1333,4],[1361,4],[1410,6],[1746,4],[1771,5],[1862,5],[1945,4]]},"982":{"position":[[17,5],[139,4],[190,4],[294,5],[387,4],[629,4],[962,5],[970,4],[1216,4]]},"984":{"position":[[162,4],[190,5]]},"986":{"position":[[11,4],[165,4],[206,4],[578,4],[723,5]]},"990":{"position":[[281,4],[331,4],[390,5],[457,4],[575,5]]},"992":{"position":[[133,5],[152,4],[182,4],[217,4],[253,4],[364,4],[477,4],[499,4],[547,4],[588,4],[691,4],[770,4],[1008,5],[1127,4],[1156,4]]},"994":{"position":[[2,4],[308,5],[329,4],[715,4]]},"997":{"position":[[11,5],[171,5],[193,6],[360,5],[381,5],[501,4],[582,5],[630,4],[736,5],[748,5]]},"999":{"position":[[132,4],[230,4],[262,4],[300,5],[459,4],[488,4],[536,4],[1010,5],[1140,4],[1208,5]]},"1002":{"position":[[34,4],[192,4],[301,4],[851,4],[879,4],[929,5]]},"1004":{"position":[[313,5],[432,5]]},"1006":{"position":[[584,4],[634,4],[804,5],[963,4],[1088,4],[1460,4],[1575,5],[1624,5],[1712,4],[1765,4],[1990,4],[2015,4],[2130,4],[2177,4],[2262,5],[2310,4],[2397,4],[2432,4],[2463,5],[2551,5],[2595,4],[2658,4],[2745,4],[2797,4],[2810,4]]},"1008":{"position":[[33,5],[81,4],[199,4],[241,4],[521,4],[640,4],[672,4]]},"1012":{"position":[[91,4],[278,4]]},"1014":{"position":[[28,5],[95,4],[244,4],[882,4],[973,4],[1053,4],[1363,4],[1573,4],[1589,4],[1624,4],[1707,4]]},"1017":{"position":[[4,4],[42,5],[117,5]]},"1019":{"position":[[814,4]]},"1026":{"position":[[79,4],[168,4],[305,4],[355,4]]},"1028":{"position":[[375,4],[434,4]]},"1031":{"position":[[104,4]]},"1033":{"position":[[51,4],[123,4],[180,4]]},"1035":{"position":[[6,4],[25,5],[73,4],[98,4]]},"1039":{"position":[[50,4],[203,4]]},"1043":{"position":[[87,4]]},"1045":{"position":[[6,4],[19,4]]},"1047":{"position":[[167,4],[400,4]]},"1049":{"position":[[37,4],[66,4],[85,4],[319,4],[333,4]]},"1056":{"position":[[72,4]]},"1060":{"position":[[150,5],[1059,5]]},"1062":{"position":[[9,5],[29,4],[434,4],[535,5],[606,5],[645,5],[687,4],[1339,5]]},"1065":{"position":[[113,4]]},"1070":{"position":[[13,6],[41,5],[60,6],[189,4],[287,6],[320,4],[356,4],[431,4],[569,4],[694,4],[827,5],[1208,5],[1796,5],[1853,5]]},"1073":{"position":[[156,4]]},"1075":{"position":[[17,4],[73,4]]},"1077":{"position":[[8,5]]},"1080":{"position":[[9,5]]},"1084":{"position":[[41,5],[147,5],[168,4],[216,5],[351,5],[449,4],[711,5],[885,5]]},"1091":{"position":[[70,4]]},"1093":{"position":[[438,4],[1555,4]]},"1095":{"position":[[74,4]]},"1101":{"position":[[1208,4],[1230,4]]},"1107":{"position":[[1005,4]]},"1111":{"position":[[57,4],[119,4],[497,4],[976,4],[997,4]]},"1113":{"position":[[59,4],[69,4],[266,4],[307,4],[376,4],[402,4],[438,4],[486,4],[648,4]]},"1115":{"position":[[98,4],[1045,4],[1086,4],[1190,4]]},"1117":{"position":[[165,4]]},"1124":{"position":[[34,4]]},"1126":{"position":[[22,4],[110,4],[510,4],[623,4],[672,4],[731,4],[850,4],[1234,4],[1542,4],[1794,4],[2011,4],[2146,4],[2264,4]]},"1128":{"position":[[36,4]]},"1130":{"position":[[313,4]]},"1132":{"position":[[187,4],[1271,4],[1616,4]]},"1134":{"position":[[328,4],[464,4],[533,4],[556,5],[617,4],[632,4]]},"1136":{"position":[[162,4],[197,5],[245,4],[277,4],[297,4],[432,4],[491,4]]},"1141":{"position":[[357,4]]},"1143":{"position":[[792,4]]},"1145":{"position":[[77,4],[200,4],[553,4],[936,4],[1180,4],[1843,4],[1874,4],[1967,4],[2048,4],[2183,4],[2337,4]]},"1147":{"position":[[249,5],[759,5],[784,4],[828,4],[934,4],[963,4],[1211,4]]},"1149":{"position":[[66,4],[267,4],[505,7],[572,4],[691,4]]},"1151":{"position":[[16,4]]},"1153":{"position":[[51,4],[104,4],[409,4],[531,4]]},"1159":{"position":[[41,4],[271,4],[466,5],[492,5],[1729,4]]},"1162":{"position":[[11,4],[97,4]]},"1167":{"position":[[1063,4]]},"1178":{"position":[[201,4]]},"1181":{"position":[[20,5]]},"1187":{"position":[[10,5],[36,4],[69,4]]},"1197":{"position":[[74,4],[216,4]]},"1203":{"position":[[75,4]]},"1208":{"position":[[142,4]]},"1212":{"position":[[148,4]]},"1218":{"position":[[650,4]]},"1225":{"position":[[38,4],[130,4],[227,4],[318,4],[427,4],[569,4]]},"1227":{"position":[[58,4],[90,4],[190,4],[396,4],[527,5],[584,5],[669,4],[807,4],[883,4],[923,4],[985,4],[1137,4],[1235,4],[1405,4],[1509,4],[1563,4]]},"1230":{"position":[[193,4],[302,4],[597,4],[702,4],[831,4]]},"1232":{"position":[[53,5],[92,5],[129,4]]},"1234":{"position":[[28,4],[196,4],[211,4],[300,4],[314,4]]},"1236":{"position":[[14,5],[136,5],[271,4],[492,4],[604,4],[747,4]]},"1238":{"position":[[57,4],[284,5],[1054,4],[1173,5],[1231,4],[1325,5]]},"1240":{"position":[[106,4],[132,4],[170,6],[188,4],[241,4],[401,4]]},"1242":{"position":[[33,4],[93,4],[121,4],[169,4],[298,5],[375,4],[389,4],[411,4],[561,4],[571,4],[820,4],[941,4]]},"1244":{"position":[[94,4],[248,4],[473,4],[526,4],[606,4],[2287,5],[2302,4]]},"1246":{"position":[[7,5],[81,5],[331,5],[364,4],[476,5],[553,4],[621,4],[814,4],[898,5]]},"1248":{"position":[[2,4],[85,4],[151,4],[319,4],[442,5]]},"1253":{"position":[[55,4],[124,4],[345,4]]},"1257":{"position":[[82,4]]},"1259":{"position":[[66,4],[112,5],[267,4],[312,4]]},"1264":{"position":[[53,5],[254,4],[269,4]]},"1266":{"position":[[4,4],[50,4],[80,4],[131,4],[238,4],[249,4],[262,4]]},"1268":{"position":[[14,4]]},"1270":{"position":[[35,4],[56,4],[90,4],[145,4],[220,4],[234,4],[352,4],[374,4]]},"1273":{"position":[[130,4],[144,4],[325,4],[342,4],[417,4]]},"1279":{"position":[[17,4],[54,4],[92,4],[121,4],[159,4]]},"1281":{"position":[[11,4]]},"1283":{"position":[[16,4],[39,4],[65,4],[186,4],[237,4]]},"1285":{"position":[[54,4],[61,4],[169,4],[215,4],[298,4],[371,4],[435,4]]},"1289":{"position":[[66,4],[135,4],[207,5],[307,4]]},"1291":{"position":[[70,4],[162,4],[475,4],[575,4],[742,4],[770,4],[799,4],[983,4],[1153,4],[1416,4],[1477,4],[1529,4]]},"1303":{"position":[[250,4],[297,4],[331,4],[399,4],[486,4],[575,4]]},"1310":{"position":[[14,4],[199,4]]},"1312":{"position":[[25,4]]},"1314":{"position":[[63,4],[735,4],[782,4]]},"1317":{"position":[[7,4]]},"1332":{"position":[[209,4]]},"1334":{"position":[[96,4]]},"1337":{"position":[[39,4],[139,4]]},"1339":{"position":[[351,4]]},"1341":{"position":[[937,4]]},"1347":{"position":[[1563,4],[1644,5]]},"1357":{"position":[[0,6],[15,4],[55,5]]},"1362":{"position":[[303,4],[314,4],[533,4]]},"1364":{"position":[[377,4]]},"1367":{"position":[[11,4]]},"1377":{"position":[[161,4],[187,4],[247,4],[361,4],[522,4]]},"1379":{"position":[[46,4],[468,4],[552,4],[586,4],[719,4],[864,4],[1201,5],[1377,4],[1639,4]]},"1382":{"position":[[215,4]]},"1384":{"position":[[1160,4],[2519,4],[2735,4],[3773,4]]},"1387":{"position":[[314,4]]},"1389":{"position":[[57,4],[128,4],[472,4],[589,4],[1005,4]]},"1391":{"position":[[7,5]]},"1393":{"position":[[0,4],[99,5],[137,4],[275,4]]},"1395":{"position":[[42,5],[75,4],[106,4],[218,4],[342,4],[449,4],[623,4],[1258,4],[1486,4],[1806,5],[1820,5],[1890,5],[1909,4],[2040,4],[2124,4],[2303,4],[2493,4],[2785,5],[2961,4]]},"1397":{"position":[[198,4],[277,5],[291,5],[428,5],[442,5],[626,4],[764,4],[1344,4],[1495,4]]},"1401":{"position":[[51,4],[303,4]]},"1403":{"position":[[123,4]]},"1407":{"position":[[48,4],[132,4],[157,4],[296,4],[325,4],[353,4],[508,4],[543,4],[595,4],[610,4],[637,5],[664,4],[697,4]]},"1409":{"position":[[204,4],[229,4],[291,4],[514,4],[541,4],[729,4],[758,4],[788,4],[1012,4],[1072,4],[1094,4],[1148,4],[1199,4],[1243,4],[1273,5],[1294,4],[1333,4],[1370,4],[1385,4],[1408,4],[1429,4],[1496,5],[1667,4],[1729,5],[1770,4],[1799,4],[1814,4],[1849,4],[1862,4]]},"1411":{"position":[[7,4],[183,5],[234,4],[299,4],[315,4],[349,4],[395,5]]},"1415":{"position":[[100,4],[149,4],[292,4],[335,5],[361,4]]},"1419":{"position":[[102,5],[142,6],[309,4],[389,6],[412,4],[474,4],[521,4],[547,4],[574,4],[887,5],[903,4]]},"1423":{"position":[[606,4],[684,4],[720,4],[866,4],[893,4],[1205,4],[1295,4]]},"1425":{"position":[[57,4],[118,4],[148,4],[173,4],[234,4],[254,4],[304,4],[328,4],[372,4],[386,4],[417,5],[445,4],[469,4],[515,4],[535,4],[591,4]]},"1427":{"position":[[91,4],[108,4],[138,5],[220,4],[240,5],[295,4],[338,4],[385,4],[444,4],[497,4],[588,5],[702,4],[867,4],[920,5],[985,5],[1101,4],[1138,4],[1193,4]]},"1429":{"position":[[9,4],[78,4],[121,4],[168,4],[183,4],[207,4],[239,4],[340,4],[350,4],[383,4],[428,4],[1100,4],[1124,4],[1203,4],[1294,4],[1317,4],[1375,4],[1668,4],[1706,4],[1744,4],[1828,4],[1854,4]]},"1431":{"position":[[4,4],[26,4],[72,4],[96,4],[116,4],[138,4],[201,4],[272,4],[283,4],[665,4],[880,4],[1119,4],[1148,4],[1190,4],[1312,4],[1430,4],[1474,4],[1538,4],[1640,4],[1660,4],[1707,4],[1748,4],[1798,4],[1826,4],[1886,4],[2028,4],[2174,4],[2208,4],[2316,5],[2326,4],[2371,4],[2504,4],[2516,4],[2644,4],[2930,4]]},"1434":{"position":[[142,4],[217,4],[339,4]]},"1436":{"position":[[98,4],[169,4],[183,4],[206,4],[237,4],[270,4],[290,4]]},"1440":{"position":[[488,4]]},"1442":{"position":[[714,4],[1558,4],[1614,4],[1694,4],[1750,4],[1775,4],[1809,4],[1845,4]]},"1449":{"position":[[117,4],[260,4],[386,4],[492,4],[615,4]]},"1455":{"position":[[186,4]]},"1466":{"position":[[254,4],[602,4]]},"1468":{"position":[[520,4],[548,4],[1499,4],[1691,4]]},"1471":{"position":[[11,4],[287,4]]},"1473":{"position":[[105,4],[431,4],[459,4],[611,4],[654,4]]},"1475":{"position":[[238,4]]},"1477":{"position":[[45,4],[1005,4],[1093,4]]},"1481":{"position":[[101,4],[216,4]]},"1487":{"position":[[157,4]]},"1494":{"position":[[127,4],[239,4],[325,4],[564,4]]},"1496":{"position":[[105,4],[121,4]]},"1499":{"position":[[238,5],[451,4],[526,5],[569,4],[907,4]]},"1501":{"position":[[47,4]]},"1505":{"position":[[115,4],[257,4]]},"1509":{"position":[[117,4]]},"1513":{"position":[[40,4],[123,4],[179,4],[479,4],[520,4],[543,4],[637,4]]},"1521":{"position":[[7,4]]},"1523":{"position":[[18,4],[32,4],[73,4],[127,4],[168,4],[224,4],[283,5]]},"1525":{"position":[[24,4]]},"1527":{"position":[[38,4],[53,4]]},"1552":{"position":[[227,4]]},"1554":{"position":[[3,4],[189,4]]},"1558":{"position":[[91,4]]},"1644":{"position":[[62,4],[201,5],[385,4],[469,4],[742,5]]},"1646":{"position":[[116,4],[196,4],[358,4],[434,4],[499,4],[609,4],[894,4],[1314,5],[1355,5],[1469,4],[2005,4],[2034,4],[2063,4],[2074,5],[2102,4],[2249,4],[2275,5],[2542,5],[2603,4],[2803,5],[3170,4],[3260,4],[3296,5]]},"1649":{"position":[[26,5],[73,4],[94,5],[158,4]]},"1651":{"position":[[337,4],[407,4],[920,4],[1574,4]]},"1653":{"position":[[0,5],[12,5],[118,5],[555,4],[661,5],[878,5]]},"1655":{"position":[[2124,5],[2192,5]]},"1657":{"position":[[443,4],[2546,4]]},"1667":{"position":[[408,4],[501,5],[736,4],[834,4],[1036,4],[1088,4],[1167,4]]},"1678":{"position":[[8,4]]},"1682":{"position":[[556,4],[659,4]]},"1684":{"position":[[296,4],[372,4]]},"1686":{"position":[[323,4]]},"1689":{"position":[[42,4],[113,4],[149,4]]},"1695":{"position":[[28,4],[59,4],[456,4],[706,4],[924,4],[1121,4],[1209,4]]},"1702":{"position":[[805,4]]},"1708":{"position":[[147,4],[293,4]]},"1710":{"position":[[41,4],[125,4]]},"1712":{"position":[[43,4],[76,4],[207,4]]},"1714":{"position":[[218,4],[236,4],[566,4]]},"1716":{"position":[[28,4],[111,4]]},"1718":{"position":[[994,4],[1051,4]]},"1720":{"position":[[31,4],[234,4],[343,4],[1286,4],[1360,4],[2470,4]]},"1724":{"position":[[224,4],[455,4]]},"1728":{"position":[[383,4],[566,4],[720,4]]},"1736":{"position":[[181,4],[663,4],[998,4],[1292,4]]},"1740":{"position":[[117,4]]},"1746":{"position":[[111,4],[302,4],[333,4],[391,4]]},"1748":{"position":[[21,4]]},"1750":{"position":[[82,4]]},"1754":{"position":[[62,4]]},"1756":{"position":[[457,4],[589,4],[628,4]]},"1764":{"position":[[107,4]]},"1766":{"position":[[21,5]]},"1768":{"position":[[37,4],[171,4],[387,4],[595,4]]},"1772":{"position":[[423,4],[505,4]]},"1774":{"position":[[511,4]]},"1776":{"position":[[122,4]]},"1778":{"position":[[18,4],[32,4]]},"1782":{"position":[[121,4],[400,4],[991,4],[1379,4],[1408,4],[1451,4],[1530,4],[1983,4],[2389,4],[2459,4],[2538,4],[3277,4]]},"1784":{"position":[[28,4]]},"1788":{"position":[[0,5],[108,4],[157,4],[345,4]]},"1790":{"position":[[26,5],[118,5],[276,5]]},"1794":{"position":[[449,4],[524,4],[598,4],[858,5],[970,4],[1052,4]]},"1796":{"position":[[119,4],[234,4]]},"1802":{"position":[[151,4]]}}}],["task=θpr",{"_index":4490,"t":{"1384":{"position":[[2872,10]]},"1389":{"position":[[2237,10]]}}}],["task\\delta_\\text{task}δtask",{"_index":4488,"t":{"1384":{"position":[[2761,29],[2994,29]]}}}],["tast",{"_index":3840,"t":{"1107":{"position":[[258,7]]}}}],["tau",{"_index":1435,"t":{"350":{"position":[[596,4],[653,4],[734,6]]},"358":{"position":[[1006,5],[1058,5],[1136,6]]},"1248":{"position":[[426,6]]}}}],["tau_0",{"_index":4756,"t":{"1455":{"position":[[331,7]]}}}],["tavor",{"_index":1005,"t":{"215":{"position":[[1811,5],[2160,5]]}}}],["taylor",{"_index":3095,"t":{"851":{"position":[[569,6]]}}}],["tdec",{"_index":1763,"t":{"502":{"position":[[334,6]]}}}],["teacher",{"_index":3245,"t":{"861":{"position":[[1984,7]]},"870":{"position":[[706,7]]},"1244":{"position":[[258,7],[688,7],[1110,7],[1325,7],[1695,7]]},"1246":{"position":[[92,7]]},"1275":{"position":[[179,7]]}}}],["techiqu",{"_index":2302,"t":{"648":{"position":[[1030,9]]}}}],["technolog",{"_index":3976,"t":{"1151":{"position":[[520,11],[534,10],[547,12],[562,13],[578,15],[594,10],[610,10],[626,12],[644,13],[663,12],[676,13],[692,10],[705,12],[720,13],[736,13],[1845,10]]}}}],["telsa",{"_index":4328,"t":{"1314":{"position":[[525,5]]}}}],["temperatur",{"_index":1439,"t":{"350":{"position":[[755,11]]},"358":{"position":[[1145,11]]},"569":{"position":[[331,11]]},"905":{"position":[[365,11]]},"988":{"position":[[1807,11]]},"1244":{"position":[[1179,11]]}}}],["templat",{"_index":100,"t":{"17":{"position":[[49,9],[71,8]]},"451":{"position":[[149,8]]},"541":{"position":[[48,8]]},"548":{"position":[[54,8],[110,8],[134,8]]},"594":{"position":[[457,9],[1296,8],[1340,8]]},"602":{"position":[[551,8]]},"1099":{"position":[[652,8],[709,8],[924,8],[1470,8]]},"1101":{"position":[[1248,8]]},"1107":{"position":[[897,8]]},"1581":{"position":[[84,9]]},"1646":{"position":[[720,8],[862,8],[1013,8],[1392,9],[1632,8],[2720,8]]},"1651":{"position":[[782,8]]},"1655":{"position":[[97,8],[759,8],[1178,8],[1659,8]]},"1657":{"position":[[645,8],[1879,8]]},"1659":{"position":[[738,8]]},"1665":{"position":[[814,8],[1076,8]]},"1674":{"position":[[125,8]]},"1686":{"position":[[165,8]]},"1689":{"position":[[212,8]]},"1702":{"position":[[123,8],[343,8],[677,8]]},"1708":{"position":[[126,8],[251,8]]},"1710":{"position":[[7,8],[139,8]]},"1712":{"position":[[331,8]]},"1714":{"position":[[35,8],[116,8],[610,8]]},"1716":{"position":[[7,8],[185,8]]},"1718":{"position":[[86,8],[168,8],[422,8],[722,8],[734,8],[766,8],[967,8],[1103,8],[1119,8]]},"1720":{"position":[[127,8],[173,8],[1111,8],[1562,8],[1635,8],[1718,8],[1741,8],[1793,8],[1854,8],[1888,8],[1961,8],[1989,8],[2170,8],[2254,8],[2283,9],[2298,8],[2397,8]]},"1730":{"position":[[1160,8]]},"1736":{"position":[[1149,8],[1224,8]]},"1738":{"position":[[928,8]]},"1756":{"position":[[187,8],[334,8],[422,8],[536,8]]},"1762":{"position":[[249,8],[288,8],[346,8]]},"1766":{"position":[[258,8],[581,8]]},"1768":{"position":[[408,8],[420,8],[704,8],[751,8],[822,8]]},"1774":{"position":[[306,8]]},"1778":{"position":[[905,8]]},"1782":{"position":[[193,8]]},"1788":{"position":[[420,8],[711,8],[746,8],[781,8],[842,8]]},"1794":{"position":[[1099,8]]}}}],["tempor",{"_index":27,"t":{"3":{"position":[[241,6],[420,6],[599,6],[778,6],[957,6],[1136,6],[1315,6],[1494,6],[1673,6],[1852,6],[2031,6],[2210,6],[2389,6],[2568,6],[2747,6],[2926,6]]},"5":{"position":[[121,6]]}}}],["tensor",{"_index":1047,"t":{"227":{"position":[[557,6]]},"1099":{"position":[[1713,7]]}}}],["tensorflow",{"_index":2392,"t":{"670":{"position":[[942,10]]}}}],["term",{"_index":1810,"t":{"521":{"position":[[51,5]]},"523":{"position":[[689,4],[792,6],[1024,5]]},"527":{"position":[[17,4],[95,5],[352,5],[2610,5],[2621,5],[2861,5]]},"529":{"position":[[1443,4],[1791,4]]},"531":{"position":[[943,6],[955,5],[1039,4],[1137,4]]},"533":{"position":[[427,4]]},"589":{"position":[[1959,4]]},"596":{"position":[[75,5]]},"681":{"position":[[526,5]]},"683":{"position":[[716,5]]},"801":{"position":[[2316,4]]},"855":{"position":[[497,4]]},"857":{"position":[[1301,4]]},"861":{"position":[[972,4],[1111,4],[1140,4]]},"866":{"position":[[393,4]]},"877":{"position":[[36,4],[83,4]]},"1401":{"position":[[283,6]]},"1442":{"position":[[1090,4]]},"1453":{"position":[[29,4],[41,4],[96,4],[211,4],[269,4]]},"1462":{"position":[[150,4]]}}}],["termin",{"_index":112,"t":{"17":{"position":[[256,9],[290,8]]},"19":{"position":[[200,8]]}}}],["terribl",{"_index":3202,"t":{"859":{"position":[[210,10]]},"1646":{"position":[[1113,11],[1188,10]]}}}],["tesla",{"_index":2544,"t":{"705":{"position":[[63,5]]}}}],["test",{"_index":908,"t":{"185":{"position":[[37,4]]},"249":{"position":[[71,4]]},"360":{"position":[[158,4]]},"436":{"position":[[1591,4]]},"464":{"position":[[34,4],[58,4],[115,4]]},"529":{"position":[[435,4],[2252,4]]},"594":{"position":[[1004,4],[1371,4],[1416,4]]},"618":{"position":[[165,4],[265,4]]},"999":{"position":[[659,4]]},"1105":{"position":[[135,4]]},"1107":{"position":[[468,4]]},"1120":{"position":[[158,4]]},"1323":{"position":[[114,4]]},"1357":{"position":[[70,4],[124,4]]},"1393":{"position":[[480,4]]},"1397":{"position":[[95,4]]},"1442":{"position":[[1599,4],[1677,4]]},"1600":{"position":[[0,4]]},"1663":{"position":[[198,4],[281,4]]},"1669":{"position":[[678,4],[904,7]]}}}],["testset",{"_index":4837,"t":{"1492":{"position":[[83,7]]}}}],["text",{"_index":622,"t":{"130":{"position":[[1558,4]]},"140":{"position":[[814,4]]},"143":{"position":[[575,4]]},"159":{"position":[[403,4]]},"165":{"position":[[1898,4]]},"182":{"position":[[90,4]]},"225":{"position":[[573,5]]},"227":{"position":[[349,4],[758,4]]},"236":{"position":[[308,4],[502,4]]},"246":{"position":[[137,4]]},"334":{"position":[[110,5]]},"336":{"position":[[55,4],[96,4]]},"339":{"position":[[17,4],[124,4],[296,4],[335,4],[412,4],[457,4]]},"341":{"position":[[267,4]]},"343":{"position":[[345,4],[595,4]]},"350":{"position":[[220,4]]},"358":{"position":[[812,4],[1274,4],[1329,4],[1440,4]]},"360":{"position":[[106,4]]},"436":{"position":[[766,4]]},"439":{"position":[[89,4]]},"455":{"position":[[350,4],[405,4]]},"457":{"position":[[515,4],[1072,4]]},"459":{"position":[[123,4]]},"466":{"position":[[136,4]]},"483":{"position":[[522,4],[851,4]]},"485":{"position":[[324,4],[1119,4]]},"488":{"position":[[313,4]]},"490":{"position":[[89,4]]},"496":{"position":[[14,4],[59,4]]},"498":{"position":[[10,4],[73,4],[104,4],[223,4],[420,4]]},"500":{"position":[[26,4],[79,4],[342,4],[459,4],[650,4],[790,4]]},"502":{"position":[[38,4],[61,4],[145,4],[368,4]]},"512":{"position":[[186,4],[219,4]]},"515":{"position":[[515,4],[801,4],[821,4]]},"529":{"position":[[592,4]]},"594":{"position":[[142,4],[495,4],[503,4]]},"600":{"position":[[136,4]]},"602":{"position":[[591,4],[599,4]]},"658":{"position":[[82,4],[130,4],[2914,4],[3214,4]]},"660":{"position":[[32,4]]},"664":{"position":[[14,4]]},"670":{"position":[[39,4],[120,4],[975,4]]},"688":{"position":[[217,4],[710,4]]},"694":{"position":[[91,4],[180,4],[756,4],[932,4]]},"705":{"position":[[101,4],[109,4]]},"887":{"position":[[986,4]]},"895":{"position":[[0,4]]},"932":{"position":[[425,4],[535,4],[605,4]]},"934":{"position":[[988,4],[1172,4],[1505,4],[2128,4],[2356,4]]},"940":{"position":[[294,4]]},"949":{"position":[[133,4],[239,4],[376,4],[625,4]]},"951":{"position":[[99,4],[420,4]]},"955":{"position":[[58,4],[236,4],[685,4]]},"967":{"position":[[192,4],[710,4]]},"969":{"position":[[266,4]]},"971":{"position":[[261,4]]},"973":{"position":[[106,4],[258,4]]},"1019":{"position":[[203,4]]},"1065":{"position":[[197,4]]},"1070":{"position":[[1398,4],[1443,4]]},"1091":{"position":[[237,4]]},"1093":{"position":[[25,4]]},"1107":{"position":[[85,7]]},"1120":{"position":[[169,4]]},"1126":{"position":[[293,4],[452,4],[817,4],[1556,4]]},"1128":{"position":[[5,4],[13,4],[43,4]]},"1130":{"position":[[216,4],[365,4]]},"1132":{"position":[[118,4],[234,4],[285,4],[628,4],[874,4],[1290,4],[1523,4],[1558,4],[1735,4]]},"1134":{"position":[[595,4],[603,4]]},"1136":{"position":[[314,4]]},"1162":{"position":[[113,4]]},"1164":{"position":[[119,4]]},"1167":{"position":[[1253,4]]},"1178":{"position":[[159,4],[568,4]]},"1185":{"position":[[311,4]]},"1187":{"position":[[168,4]]},"1289":{"position":[[469,4]]},"1291":{"position":[[1070,4],[1591,5]]},"1294":{"position":[[114,4],[164,4]]},"1310":{"position":[[9,4]]},"1312":{"position":[[9,4]]},"1314":{"position":[[9,4],[730,4],[836,4]]},"1317":{"position":[[69,4],[634,4]]},"1319":{"position":[[115,4],[164,4],[223,4],[274,4],[357,4]]},"1321":{"position":[[9,4]]},"1323":{"position":[[9,4],[148,4],[232,4],[466,4]]},"1326":{"position":[[120,4]]},"1332":{"position":[[196,4],[204,4]]},"1409":{"position":[[272,4]]},"1440":{"position":[[311,4]]},"1442":{"position":[[91,4]]},"1445":{"position":[[38,4]]},"1447":{"position":[[22,4],[324,4]]},"1477":{"position":[[5,4],[13,4],[52,4]]},"1496":{"position":[[78,4],[86,4]]},"1552":{"position":[[30,4]]},"1618":{"position":[[209,4]]},"1646":{"position":[[1502,4]]},"1651":{"position":[[317,4]]},"1672":{"position":[[263,4]]},"1689":{"position":[[22,4]]},"1693":{"position":[[353,4]]},"1695":{"position":[[634,4]]},"1698":{"position":[[45,5],[126,4],[245,4],[268,4],[493,4]]},"1702":{"position":[[214,4],[250,4]]},"1704":{"position":[[34,4]]},"1712":{"position":[[274,4]]},"1714":{"position":[[328,4],[389,4],[528,4],[550,4]]},"1718":{"position":[[113,4]]},"1728":{"position":[[285,4],[416,4]]},"1736":{"position":[[647,4],[1265,4]]},"1742":{"position":[[192,4]]},"1746":{"position":[[21,4]]},"1766":{"position":[[202,4],[407,4],[509,4]]},"1768":{"position":[[639,4],[729,4]]},"1772":{"position":[[430,4]]},"1774":{"position":[[0,4],[397,4]]},"1778":{"position":[[387,4]]},"1782":{"position":[[1471,4],[1686,4],[2040,4],[2319,4],[2427,4],[2486,4],[2606,4],[2812,4]]},"1788":{"position":[[69,4],[143,4],[570,4],[588,4]]},"1790":{"position":[[284,4],[370,4]]}}}],["text/cod",{"_index":1757,"t":{"500":{"position":[[1126,9]]},"512":{"position":[[66,9]]}}}],["textbook",{"_index":3964,"t":{"1147":{"position":[[653,12]]}}}],["textbookqa",{"_index":3960,"t":{"1147":{"position":[[546,10],[640,10]]}}}],["textcolor{blue}{l_1}(\\textcolor{red}{p^1_i",{"_index":2512,"t":{"694":{"position":[[513,45]]}}}],["textcolor{blue}{l_j}(\\textcolor{red}{p^j_i",{"_index":2515,"t":{"694":{"position":[[606,45]]}}}],["textcolor{blue}{ln",{"_index":2530,"t":{"696":{"position":[[1318,20]]}}}],["textcolor{blue}{mlp",{"_index":2529,"t":{"696":{"position":[[1294,21]]}}}],["textcolor{red}{head}(z^n)y=head(zn",{"_index":2537,"t":{"698":{"position":[[136,36]]}}}],["textcolor{red}{msa",{"_index":2531,"t":{"696":{"position":[[1341,20]]}}}],["textual",{"_index":1156,"t":{"287":{"position":[[481,7]]},"451":{"position":[[254,7]]},"455":{"position":[[58,7],[286,7],[565,7]]},"457":{"position":[[586,7]]},"955":{"position":[[571,7]]},"971":{"position":[[74,7]]},"1111":{"position":[[156,7]]},"1695":{"position":[[936,7]]},"1702":{"position":[[159,7]]},"1738":{"position":[[809,7]]},"1756":{"position":[[179,7]]}}}],["textup{annot",{"_index":807,"t":{"170":{"position":[[2277,18]]}}}],["textup{bi",{"_index":825,"t":{"172":{"position":[[519,10]]}}}],["textup{categori",{"_index":803,"t":{"170":{"position":[[2162,16]]},"174":{"position":[[2146,17]]}}}],["textup{enc}_\\textup{v}^{\\textup{ref",{"_index":805,"t":{"170":{"position":[[2207,39]]}}}],["textup{enc}_l^{\\textup{ref",{"_index":801,"t":{"170":{"position":[[2067,29],[2130,29]]}}}],["textup{express",{"_index":802,"t":{"170":{"position":[[2099,18]]}}}],["textup{expression/annot",{"_index":861,"t":{"174":{"position":[[2211,30]]}}}],["textup{ins}}w^ts=fins​wt",{"_index":867,"t":{"174":{"position":[[2439,25]]}}}],["textup{ln}(z^0_l)y=ln(zl0",{"_index":475,"t":{"91":{"position":[[2441,28]]}}}],["textup{merg",{"_index":804,"t":{"170":{"position":[[2191,15]]}}}],["textup{mlp}(\\textup{ln}(z'_\\varrho",{"_index":471,"t":{"91":{"position":[[2287,37]]}}}],["textup{msa}(\\textup{ln}(z_{\\varrho",{"_index":462,"t":{"91":{"position":[[1992,35]]}}}],["textup{para}(z')}p(z|x)p(y∣x)=∑z∈para(z′)​p(z∣x",{"_index":5495,"t":{"1730":{"position":[[377,49]]}}}],["textup{templ",{"_index":806,"t":{"170":{"position":[[2247,17]]}}}],["text{",{"_index":5242,"t":{"1657":{"position":[[95,7],[1434,16]]}}}],["text{\"person:par",{"_index":5190,"t":{"1651":{"position":[[1282,22]]}}}],["text{'",{"_index":5227,"t":{"1655":{"position":[[1511,8],[1908,10]]}}}],["text{a",{"_index":4516,"t":{"1389":{"position":[[857,10]]}}}],["text{attention}(q",{"_index":1195,"t":{"298":{"position":[[433,19]]}}}],["text{attention}(qw^q_i",{"_index":1220,"t":{"300":{"position":[[779,24]]}}}],["text{born",{"_index":5275,"t":{"1657":{"position":[[1517,20]]}}}],["text{concat",{"_index":3379,"t":{"895":{"position":[[516,13]]}}}],["text{concat}(\\text{head}_1",{"_index":1215,"t":{"300":{"position":[[689,28]]},"789":{"position":[[324,28]]}}}],["text{dim}(h_i)∣pidx​∣×dim(hi",{"_index":4296,"t":{"1305":{"position":[[504,31]]}}}],["text{dropout}&({\\color{blue}{w^\\ell_{m3",{"_index":1870,"t":{"527":{"position":[[1886,44]]}}}],["text{dropout}(&{\\color{blue}{w^\\ell_{m1",{"_index":1857,"t":{"527":{"position":[[1551,44]]}}}],["text{false})p(feo​​(b,person)=fals",{"_index":5248,"t":{"1657":{"position":[[313,37]]}}}],["text{ffn}(x",{"_index":1247,"t":{"304":{"position":[[221,13]]}}}],["text{gelu}&({\\color{blue}{w^\\ell_{m2",{"_index":1867,"t":{"527":{"position":[[1782,41]]}}}],["text{head})i",{"_index":2797,"t":{"789":{"position":[[385,13]]}}}],["text{head}_h",{"_index":1216,"t":{"300":{"position":[[725,14]]}}}],["text{head}_h)w_o",{"_index":2796,"t":{"789":{"position":[[360,18]]}}}],["text{head}_i",{"_index":1219,"t":{"300":{"position":[[762,13]]}}}],["text{i",{"_index":2123,"t":{"596":{"position":[[1757,9],[2127,10]]},"797":{"position":[[1995,8]]},"1099":{"position":[[2064,10]]}}}],["text{if",{"_index":4298,"t":{"1305":{"position":[[723,9]]}}}],["text{in",{"_index":5277,"t":{"1657":{"position":[[1580,14]]}}}],["text{infix",{"_index":4342,"t":{"1330":{"position":[[195,13]]}}}],["text{init}(0",{"_index":3432,"t":{"945":{"position":[[690,16]]}}}],["text{init}(1",{"_index":3433,"t":{"945":{"position":[[711,15]]}}}],["text{linear}_k",{"_index":3323,"t":{"893":{"position":[[598,15]]}}}],["text{linear}_o",{"_index":3364,"t":{"893":{"position":[[2323,15]]}}}],["text{linear}_q",{"_index":3321,"t":{"893":{"position":[[560,15]]}}}],["text{linear}_v",{"_index":3325,"t":{"893":{"position":[[649,15]]}}}],["text{lm}_{\\phi",{"_index":4254,"t":{"1296":{"position":[[719,16]]}}}],["text{lm}_{\\phi}(z_i",{"_index":4300,"t":{"1305":{"position":[[764,21]]}}}],["text{lstm}(h_{i:m",{"_index":3821,"t":{"1101":{"position":[[888,22]]}}}],["text{mlp}([\\overrightarrow{h}_i",{"_index":3818,"t":{"1101":{"position":[[781,32]]}}}],["text{mlp}([\\text{lstm}(h_{0:i",{"_index":3820,"t":{"1101":{"position":[[849,32]]}}}],["text{mlp}_\\theta",{"_index":4313,"t":{"1307":{"position":[[231,17]]}}}],["text{multihead}(q,k,v",{"_index":1214,"t":{"300":{"position":[[662,23]]}}}],["text{m})\\text{x}a=(w⊙m)x",{"_index":3113,"t":{"853":{"position":[[261,25]]}}}],["text{o.w",{"_index":3213,"t":{"861":{"position":[[256,11]]}}}],["text{of",{"_index":2933,"t":{"797":{"position":[[2025,10]]}}}],["text{organ",{"_index":5270,"t":{"1657":{"position":[[1380,24],[1645,24]]}}}],["text{otherwis",{"_index":2935,"t":{"797":{"position":[[2050,17]]},"1305":{"position":[[797,17]]}}}],["text{out}^\\el",{"_index":1872,"t":{"527":{"position":[[1981,15]]}}}],["text{par",{"_index":5274,"t":{"1657":{"position":[[1496,20]]}}}],["text{person",{"_index":5185,"t":{"1651":{"position":[[1170,14],[1250,14]]},"1655":{"position":[[565,12]]},"1657":{"position":[[206,14],[296,14],[1359,20],[1624,20]]}}}],["text{person}\",``\\text{organ",{"_index":5219,"t":{"1655":{"position":[[975,40]]}}}],["text{prefix",{"_index":4289,"t":{"1305":{"position":[[67,15],[170,15],[189,15]]}}}],["text{project",{"_index":3378,"t":{"895":{"position":[[491,17]]}}}],["text{p}_s||\\text{p}_t",{"_index":3238,"t":{"861":{"position":[[1834,24]]}}}],["text{p}_{0:i",{"_index":3785,"t":{"1099":{"position":[[1031,17]]}}}],["text{p}_{\\text{idx",{"_index":4299,"t":{"1305":{"position":[[739,21]]}}}],["text{p}_{\\text{idx}}i∈/pidx",{"_index":4308,"t":{"1305":{"position":[[1224,29]]}}}],["text{p}_{\\text{idx}}i∈pidx",{"_index":4304,"t":{"1305":{"position":[[1123,28]]}}}],["text{p}_{i+1:m}],\\text{i",{"_index":3786,"t":{"1099":{"position":[[1059,27]]}}}],["text{relu}(xw_{fi",{"_index":2809,"t":{"789":{"position":[[893,19]]}}}],["text{repeat}(i_p",{"_index":3387,"t":{"895":{"position":[[940,18]]}}}],["text{softmax}(\\frac{qk^t}{\\sqrt{d_k}})v",{"_index":1196,"t":{"298":{"position":[[461,40]]}}}],["text{softmax}(l_\\mu",{"_index":4395,"t":{"1352":{"position":[[839,21]]}}}],["text{softmax}(l_\\mu(\\bar{x",{"_index":4415,"t":{"1354":{"position":[[440,31]]}}}],["text{softmax}(s_l^k",{"_index":3356,"t":{"893":{"position":[[1795,22]]}}}],["text{softmax}(s_l^{m+1})]^t",{"_index":3358,"t":{"893":{"position":[[1832,28]]}}}],["text{softmax}(w_{\\phi",{"_index":4260,"t":{"1296":{"position":[[889,23]]}}}],["text{softmax}(xw_{qi}(xw_{ki})^\\top",{"_index":2798,"t":{"789":{"position":[[401,36]]}}}],["text{softmax}\\left",{"_index":2160,"t":{"598":{"position":[[1606,19]]}}}],["text{sublayer}(x))layernorm(x+sublayer(x",{"_index":1176,"t":{"292":{"position":[[288,43]]}}}],["text{th",{"_index":5217,"t":{"1655":{"position":[[917,10]]},"1657":{"position":[[888,10]]}}}],["text{the}[𝙼]_1",{"_index":5259,"t":{"1657":{"position":[[848,16]]}}}],["text{top}_v(\\text{s})m=topv​(",{"_index":3118,"t":{"853":{"position":[[469,32]]},"857":{"position":[[152,32]]}}}],["text{true})p(fes​,eo​​(a,′",{"_index":5243,"t":{"1657":{"position":[[121,28]]}}}],["text{true})p(fes​​(a,person)=tru",{"_index":5246,"t":{"1657":{"position":[[223,35]]}}}],["text{w",{"_index":3112,"t":{"853":{"position":[[245,9]]}}}],["text{wa",{"_index":5272,"t":{"1657":{"position":[[1451,15],[1562,17]]}}}],["text{wher",{"_index":1218,"t":{"300":{"position":[[747,12]]},"945":{"position":[[671,12]]}}}],["text{with",{"_index":2926,"t":{"797":{"position":[[1864,11]]}}}],["text{wx}a=wx",{"_index":3103,"t":{"853":{"position":[[15,13]]}}}],["text{x",{"_index":2098,"t":{"596":{"position":[[178,9]]},"945":{"position":[[603,8],[645,8]]},"1099":{"position":[[1049,9]]}}}],["text{x}_{\\text{idx}}i∈xidx",{"_index":4267,"t":{"1298":{"position":[[290,28]]}}}],["text{y}))}{\\exp(\\beta(\\text{x",{"_index":2130,"t":{"596":{"position":[[2094,32]]}}}],["text{y}_{\\text{idx",{"_index":4277,"t":{"1300":{"position":[[309,22]]}}}],["text{y}_{\\text{idx}}i∈yidx",{"_index":4269,"t":{"1298":{"position":[[363,28]]}}}],["tf(⋅)t_f(\\cdot)tf",{"_index":5179,"t":{"1651":{"position":[[791,21]]}}}],["tfes,eo=‘‘x",{"_index":5231,"t":{"1655":{"position":[[1705,11]]}}}],["tfes=‘‘x",{"_index":5213,"t":{"1655":{"position":[[805,8]]}}}],["tft_ftf",{"_index":3005,"t":{"803":{"position":[[644,8]]}}}],["th",{"_index":1429,"t":{"350":{"position":[[350,2]]},"354":{"position":[[311,2]]},"358":{"position":[[876,2]]},"596":{"position":[[991,2]]},"791":{"position":[[601,2],[635,2],[716,2]]},"795":{"position":[[561,2]]},"797":{"position":[[505,2],[1122,2],[2381,2]]},"891":{"position":[[518,2]]},"893":{"position":[[211,2],[280,2],[370,2],[2211,2]]},"895":{"position":[[837,2]]},"1242":{"position":[[166,2],[551,2]]},"1244":{"position":[[238,2],[1742,2]]},"1296":{"position":[[548,2]]},"1352":{"position":[[744,2]]}}}],["thank",{"_index":3912,"t":{"1132":{"position":[[290,6],[380,6]]}}}],["the[m]1​[m]2​[m]3​[m]4",{"_index":5265,"t":{"1657":{"position":[[993,23]]}}}],["the[𝙼]1[𝙼]2[𝙼]3[𝙼]4",{"_index":5253,"t":{"1657":{"position":[[702,23]]}}}],["theme/layout",{"_index":5081,"t":{"1612":{"position":[[118,16]]}}}],["themeconfig",{"_index":4993,"t":{"1583":{"position":[[122,11]]},"1606":{"position":[[142,12]]},"1638":{"position":[[142,12]]}}}],["theta",{"_index":1627,"t":{"441":{"position":[[330,8]]},"527":{"position":[[2517,8]]},"723":{"position":[[986,16],[1028,8],[1119,8]]},"982":{"position":[[763,8]]},"984":{"position":[[455,8]]},"986":{"position":[[709,8]]},"1065":{"position":[[172,8],[766,8]]},"1067":{"position":[[902,7]]},"1128":{"position":[[382,8],[611,8],[772,8],[933,8]]},"1238":{"position":[[37,8],[404,8],[906,7]]},"1244":{"position":[[945,7],[992,7]]},"1305":{"position":[[576,9],[1019,8]]},"1558":{"position":[[962,8]]},"1698":{"position":[[166,8]]},"1704":{"position":[[578,8]]},"1720":{"position":[[676,8]]}}}],["theta)p",{"_index":5422,"t":{"1704":{"position":[[409,14]]}}}],["theta)p(xt​∣x<t",{"_index":5577,"t":{"1778":{"position":[[558,20]]}}}],["theta)p(y∣x",{"_index":4117,"t":{"1238":{"position":[[257,15]]}}}],["theta_\\phi}{\\max",{"_index":4032,"t":{"1167":{"position":[[1376,18]]}}}],["theta_\\text{pr",{"_index":4492,"t":{"1384":{"position":[[2917,16]]},"1389":{"position":[[2284,16]]}}}],["theta_{\\phi",{"_index":4029,"t":{"1167":{"position":[[1134,18]]}}}],["thing",{"_index":5582,"t":{"1778":{"position":[[966,6]]}}}],["think",{"_index":2017,"t":{"559":{"position":[[203,5]]},"565":{"position":[[173,5]]},"569":{"position":[[208,5]]}}}],["third",{"_index":1182,"t":{"294":{"position":[[89,5]]},"1389":{"position":[[2211,5]]}}}],["thor",{"_index":4439,"t":{"1369":{"position":[[407,4]]}}}],["thought",{"_index":1519,"t":{"382":{"position":[[9,7],[114,7]]},"384":{"position":[[746,8],[841,7]]},"537":{"position":[[183,7]]},"539":{"position":[[162,8]]},"583":{"position":[[103,7]]},"1447":{"position":[[234,7]]}}}],["three",{"_index":362,"t":{"78":{"position":[[710,5]]},"555":{"position":[[22,6]]},"873":{"position":[[1008,5]]},"1384":{"position":[[1411,5]]}}}],["threshold",{"_index":1403,"t":{"336":{"position":[[1178,9],[1335,9]]},"347":{"position":[[333,9]]},"352":{"position":[[139,9],[465,9],[576,9]]},"861":{"position":[[1020,12]]},"873":{"position":[[94,12]]}}}],["through",{"_index":131,"t":{"19":{"position":[[284,7]]},"851":{"position":[[794,7]]},"853":{"position":[[1331,7]]},"1591":{"position":[[40,8]]}}}],["ti\\mathcal{t}_",{"_index":4108,"t":{"1236":{"position":[[276,18]]}}}],["ti\\pmb{\\mathcal{t}}_itti",{"_index":4111,"t":{"1236":{"position":[[413,25]]}}}],["ticket",{"_index":1958,"t":{"531":{"position":[[680,6]]},"849":{"position":[[818,6],[1045,6]]},"851":{"position":[[918,6],[992,7],[1076,7],[1107,6],[1181,7]]},"868":{"position":[[184,6],[222,6]]},"879":{"position":[[376,6]]},"1466":{"position":[[339,7]]},"1468":{"position":[[481,7],[820,6],[846,6],[867,7],[968,7],[1012,7],[1041,7],[1063,7],[1121,7]]},"1475":{"position":[[8,6],[156,6],[184,6],[205,6],[229,6],[315,6],[363,6]]},"1477":{"position":[[1139,6]]},"1505":{"position":[[443,6]]},"1525":{"position":[[180,6]]}}}],["tight",{"_index":3974,"t":{"1151":{"position":[[476,5]]}}}],["tilde{\\lambda}^{t}_{k,ii",{"_index":2930,"t":{"797":{"position":[[1953,26]]}}}],["tilde{\\lambda}_k^{(t",{"_index":2909,"t":{"797":{"position":[[1369,23],[1826,25]]}}}],["tile",{"_index":1056,"t":{"227":{"position":[[778,6]]}}}],["time",{"_index":231,"t":{"38":{"position":[[360,4]]},"91":{"position":[[147,6],[156,6],[242,6],[1697,6],[1755,6]]},"97":{"position":[[120,6]]},"170":{"position":[[476,6],[778,6],[1191,6],[1215,6],[1236,6],[1254,6],[1368,6],[1446,6]]},"174":{"position":[[1231,6],[1815,6]]},"227":{"position":[[532,6],[541,6]]},"300":{"position":[[1032,6],[1082,6],[1132,6]]},"358":{"position":[[147,6],[402,6]]},"598":{"position":[[958,6]]},"608":{"position":[[1083,6]]},"610":{"position":[[140,6]]},"630":{"position":[[1286,6],[1789,6]]},"721":{"position":[[404,6]]},"733":{"position":[[292,6],[429,6],[472,6]]},"751":{"position":[[167,6]]},"753":{"position":[[204,6],[221,6]]},"755":{"position":[[514,6],[524,6],[541,6],[571,6],[591,6]]},"757":{"position":[[180,6],[202,6],[219,6]]},"786":{"position":[[1817,6],[1867,6],[1917,6]]},"789":{"position":[[178,6],[563,6],[659,6],[996,6],[1055,6]]},"791":{"position":[[310,6],[360,6],[410,6]]},"795":{"position":[[246,6],[293,6],[405,6]]},"821":{"position":[[449,6]]},"873":{"position":[[366,5]]},"891":{"position":[[266,6],[592,6],[814,6]]},"893":{"position":[[331,6],[934,6],[2369,6]]},"895":{"position":[[316,6],[640,6],[977,6]]},"984":{"position":[[317,6]]},"988":{"position":[[308,6],[367,6],[1213,6],[1287,6]]},"992":{"position":[[1035,4]]},"994":{"position":[[48,6],[191,6],[204,6],[378,6]]},"1060":{"position":[[410,4],[948,4]]},"1062":{"position":[[850,4],[1442,4],[1648,4]]},"1065":{"position":[[258,6],[352,6],[607,6]]},"1067":{"position":[[102,6],[202,6],[337,6],[381,6],[600,6],[1021,6],[1034,6],[1053,6]]},"1070":{"position":[[970,6],[1117,6],[1136,6]]},"1073":{"position":[[207,4]]},"1087":{"position":[[65,4]]},"1128":{"position":[[1613,6],[1696,6],[1839,6]]},"1134":{"position":[[114,8]]},"1164":{"position":[[580,4]]},"1167":{"position":[[911,6]]},"1218":{"position":[[175,6],[249,6],[356,6],[440,6],[453,6]]},"1238":{"position":[[620,6],[723,6],[1014,6]]},"1242":{"position":[[254,6]]},"1248":{"position":[[63,6],[115,6],[211,6],[226,6],[270,6],[385,6],[400,6]]},"1255":{"position":[[176,6]]},"1296":{"position":[[313,4],[464,4],[526,4]]},"1305":{"position":[[497,6]]},"1352":{"position":[[217,6],[550,6]]},"1360":{"position":[[272,5]]},"1384":{"position":[[713,6],[819,6],[1381,6],[1513,6],[1701,6],[2015,6],[2128,6],[2376,6],[3300,6],[3403,6],[3531,6]]},"1399":{"position":[[51,4],[563,4],[786,4]]},"1421":{"position":[[191,6]]},"1447":{"position":[[102,4]]},"1451":{"position":[[680,4]]},"1453":{"position":[[67,4]]},"1477":{"position":[[331,6],[482,6],[611,6]]},"1636":{"position":[[236,5]]},"1657":{"position":[[1938,4]]},"1669":{"position":[[274,4]]}}}],["timestep",{"_index":5459,"t":{"1720":{"position":[[816,8],[864,8]]}}}],["tine",{"_index":1108,"t":{"246":{"position":[[72,6]]},"1384":{"position":[[1023,6]]}}}],["tini",{"_index":2055,"t":{"587":{"position":[[552,4]]}}}],["tip",{"_index":67,"t":{"9":{"position":[[62,3]]},"334":{"position":[[198,3],[671,3]]},"336":{"position":[[442,3],[669,3],[1995,3]]},"341":{"position":[[354,3]]},"376":{"position":[[120,3],[311,3]]},"378":{"position":[[118,3]]},"1536":{"position":[[0,3]]},"1626":{"position":[[68,6],[78,3],[170,3]]}}}],["tit_iti",{"_index":3003,"t":{"803":{"position":[[473,8]]},"891":{"position":[[725,8],[980,8]]}}}],["titan",{"_index":4323,"t":{"1314":{"position":[[377,5],[401,5]]}}}],["titl",{"_index":5007,"t":{"1587":{"position":[[96,6],[143,6],[282,6]]},"1618":{"position":[[93,6],[112,5]]}}}],["title=\"src/components/hellodocusaurus.j",{"_index":5107,"t":{"1624":{"position":[[68,41]]}}}],["ti∈rm×ct_i",{"_index":3300,"t":{"891":{"position":[[563,10]]}}}],["tjong",{"_index":1008,"t":{"215":{"position":[[2235,6]]}}}],["tka",{"_index":601,"t":{"130":{"position":[[432,4]]},"287":{"position":[[502,4]]}}}],["tl",{"_index":3316,"t":{"893":{"position":[[483,2],[715,3]]}}}],["tlo=linearo(slgvl)∈r1×c\\begin{equ",{"_index":3362,"t":{"893":{"position":[[2275,39]]}}}],["tlt_ltl",{"_index":3338,"t":{"893":{"position":[[1004,8],[1312,8],[2046,8]]}}}],["tl∈r1×ct_l",{"_index":3312,"t":{"893":{"position":[[302,10]]}}}],["tnl",{"_index":916,"t":{"189":{"position":[[55,3]]}}}],["today",{"_index":5406,"t":{"1695":{"position":[[1057,6]]}}}],["toek",{"_index":5499,"t":{"1730":{"position":[[657,4]]}}}],["toke",{"_index":4867,"t":{"1509":{"position":[[197,4]]}}}],["token",{"_index":398,"t":{"91":{"position":[[25,5],[748,5],[771,5]]},"124":{"position":[[410,5]]},"130":{"position":[[705,5],[1498,6],[1531,5],[1563,5]]},"132":{"position":[[446,5],[577,5],[632,5]]},"140":{"position":[[243,12],[289,13],[803,5]]},"143":{"position":[[580,6]]},"145":{"position":[[59,5]]},"225":{"position":[[293,5]]},"236":{"position":[[19,5]]},"246":{"position":[[223,5]]},"306":{"position":[[45,6],[160,5]]},"313":{"position":[[116,6],[252,5],[339,6],[361,6]]},"326":{"position":[[485,6],[546,6]]},"405":{"position":[[47,8]]},"441":{"position":[[95,5],[164,5]]},"459":{"position":[[567,5]]},"498":{"position":[[349,5]]},"500":{"position":[[409,5],[507,5],[592,5]]},"502":{"position":[[205,5],[341,5]]},"515":{"position":[[171,6],[385,9]]},"529":{"position":[[2277,5],[2334,5]]},"550":{"position":[[302,5]]},"567":{"position":[[184,5]]},"569":{"position":[[1061,5]]},"579":{"position":[[58,5]]},"596":{"position":[[780,6],[1324,5],[1500,5]]},"608":{"position":[[142,6],[260,5],[302,5],[400,5],[449,5],[881,9],[1108,5]]},"614":{"position":[[139,9]]},"628":{"position":[[297,6]]},"666":{"position":[[132,5],[164,6],[176,5]]},"683":{"position":[[859,5]]},"686":{"position":[[103,5],[335,5]]},"688":{"position":[[120,5],[222,5],[715,5],[970,6]]},"694":{"position":[[96,5],[185,5],[761,6],[937,5]]},"696":{"position":[[241,6],[669,5],[886,6]]},"703":{"position":[[218,5]]},"707":{"position":[[217,5]]},"723":{"position":[[301,5]]},"751":{"position":[[6,5],[24,5]]},"765":{"position":[[102,5]]},"786":{"position":[[710,6]]},"819":{"position":[[131,5]]},"859":{"position":[[54,5],[154,5],[221,5],[386,5],[470,5]]},"866":{"position":[[193,5]]},"885":{"position":[[324,5]]},"887":{"position":[[432,5],[1058,6]]},"891":{"position":[[628,6],[704,5]]},"893":{"position":[[51,5],[378,5],[406,6],[1034,6],[1459,6]]},"895":{"position":[[718,5]]},"901":{"position":[[151,5]]},"932":{"position":[[333,5]]},"938":{"position":[[209,5],[329,5]]},"953":{"position":[[319,6],[574,5]]},"988":{"position":[[729,6]]},"1008":{"position":[[355,6],[370,5]]},"1014":{"position":[[525,5]]},"1017":{"position":[[123,5]]},"1019":{"position":[[117,6]]},"1026":{"position":[[135,5]]},"1028":{"position":[[335,6]]},"1037":{"position":[[130,5]]},"1060":{"position":[[306,6]]},"1065":{"position":[[428,6]]},"1070":{"position":[[844,6],[1023,6]]},"1099":{"position":[[54,5],[374,5],[458,6],[549,5],[959,5],[1456,6]]},"1101":{"position":[[1174,6],[1314,5],[1329,5],[1373,6]]},"1107":{"position":[[37,5],[709,5],[969,6],[1025,5]]},"1126":{"position":[[1586,6]]},"1128":{"position":[[324,5],[484,6],[642,5],[825,5],[1106,6],[1155,6],[1210,6],[1444,6],[1524,5]]},"1130":{"position":[[102,5],[534,5],[574,6],[729,5]]},"1132":{"position":[[142,6],[897,7]]},"1134":{"position":[[218,6],[269,5]]},"1139":{"position":[[165,5],[217,5],[257,5]]},"1141":{"position":[[242,5],[428,5],[466,5],[476,5],[533,5],[839,5],[886,5]]},"1143":{"position":[[149,5]]},"1145":{"position":[[1030,5],[1816,5]]},"1151":{"position":[[142,5],[249,5],[372,5],[439,5],[1235,5],[1283,5],[1618,6]]},"1159":{"position":[[1085,6],[1479,5]]},"1164":{"position":[[64,5]]},"1167":{"position":[[114,6],[548,5]]},"1170":{"position":[[145,5]]},"1172":{"position":[[197,5]]},"1176":{"position":[[14,5]]},"1185":{"position":[[45,5],[266,6],[277,12],[365,5]]},"1187":{"position":[[141,5],[332,6],[417,5]]},"1195":{"position":[[107,6],[120,6],[186,6],[226,6],[273,5]]},"1197":{"position":[[94,6]]},"1199":{"position":[[265,6]]},"1201":{"position":[[225,6]]},"1203":{"position":[[128,6]]},"1205":{"position":[[76,6],[172,6]]},"1214":{"position":[[51,6]]},"1218":{"position":[[332,6]]},"1238":{"position":[[515,5]]},"1289":{"position":[[390,6],[419,7]]},"1291":{"position":[[1293,6]]},"1294":{"position":[[35,5]]},"1296":{"position":[[816,6]]},"1303":{"position":[[371,5],[711,5],[858,5]]},"1328":{"position":[[9,6]]},"1345":{"position":[[109,6]]},"1347":{"position":[[709,6]]},"1350":{"position":[[215,5]]},"1357":{"position":[[458,6]]},"1360":{"position":[[359,5]]},"1362":{"position":[[410,5]]},"1367":{"position":[[225,5]]},"1369":{"position":[[194,6]]},"1384":{"position":[[209,5]]},"1389":{"position":[[1708,6]]},"1421":{"position":[[318,6],[557,5],[599,6]]},"1429":{"position":[[522,6],[536,6],[804,6],[847,5],[889,5],[1182,6]]},"1431":{"position":[[2457,5]]},"1466":{"position":[[234,6],[523,6]]},"1468":{"position":[[539,6],[592,6],[670,6],[951,6],[996,6],[1141,5],[1165,6],[1327,6]]},"1473":{"position":[[34,6],[137,6],[144,6],[186,6]]},"1477":{"position":[[111,5],[154,5],[202,5],[285,5],[1033,6],[1084,6]]},"1481":{"position":[[20,6],[178,6]]},"1483":{"position":[[49,6],[78,6],[151,5],[189,6],[227,6],[306,5]]},"1485":{"position":[[15,6],[40,5],[69,5],[347,5],[386,6],[405,5],[521,5],[843,5],[873,5],[987,5],[1158,5],[1174,5]]},"1487":{"position":[[0,5],[34,5],[61,5],[184,5],[272,5],[493,5],[756,5],[817,5],[1053,5],[1174,6],[1198,5]]},"1496":{"position":[[289,5],[324,5]]},"1505":{"position":[[388,6],[797,6],[850,6]]},"1509":{"position":[[0,5]]},"1511":{"position":[[263,6],[347,6]]},"1515":{"position":[[163,5]]},"1517":{"position":[[25,5]]},"1521":{"position":[[23,6],[39,5],[94,5],[140,5]]},"1525":{"position":[[146,5]]},"1646":{"position":[[1819,6]]},"1657":{"position":[[1911,6]]},"1702":{"position":[[705,5]]},"1718":{"position":[[743,5],[775,5]]},"1720":{"position":[[2104,5],[2192,5],[2406,5],[2421,5],[2437,5]]},"1724":{"position":[[43,5],[84,5],[132,5]]},"1728":{"position":[[180,5]]},"1730":{"position":[[809,5],[926,5]]},"1732":{"position":[[37,5],[106,5],[137,5],[169,5]]},"1736":{"position":[[556,5]]},"1738":{"position":[[691,5]]},"1768":{"position":[[320,5],[649,5],[665,5]]},"1774":{"position":[[454,5]]},"1782":{"position":[[1749,5]]},"1790":{"position":[[132,5]]},"1794":{"position":[[498,5]]},"1802":{"position":[[331,5]]}}}],["token/text",{"_index":5472,"t":{"1724":{"position":[[239,10]]}}}],["tokens][hyp]?[prompt",{"_index":3827,"t":{"1101":{"position":[[1271,20]]}}}],["tokens][mask",{"_index":3828,"t":{"1101":{"position":[[1292,14]]}}}],["tokensequ",{"_index":598,"t":{"128":{"position":[[71,13]]}}}],["toolkit",{"_index":5347,"t":{"1665":{"position":[[1180,7]]},"1674":{"position":[[265,7]]}}}],["toothbrush",{"_index":757,"t":{"170":{"position":[[302,11]]}}}],["top",{"_index":1036,"t":{"225":{"position":[[408,3]]},"336":{"position":[[1272,3],[1829,3]]},"347":{"position":[[315,3]]},"352":{"position":[[774,3]]},"368":{"position":[[254,3]]},"457":{"position":[[972,3],[1187,3]]},"504":{"position":[[603,3]]},"525":{"position":[[190,3]]},"618":{"position":[[360,3]]},"660":{"position":[[589,3]]},"670":{"position":[[574,3]]},"672":{"position":[[183,3],[554,3],[712,3]]},"676":{"position":[[483,3],[578,3],[621,3],[690,3],[735,3],[788,3]]},"698":{"position":[[193,3]]},"774":{"position":[[265,3],[368,3],[751,3]]},"778":{"position":[[322,3],[553,3]]},"786":{"position":[[2738,3]]},"797":{"position":[[1751,3],[2011,3],[2182,3]]},"841":{"position":[[107,3],[192,3]]},"853":{"position":[[507,3]]},"873":{"position":[[264,3]]},"905":{"position":[[381,3]]},"999":{"position":[[80,3],[1092,3]]},"1065":{"position":[[481,3]]},"1070":{"position":[[511,3]]},"1151":{"position":[[450,3]]},"1195":{"position":[[585,5]]},"1227":{"position":[[719,4]]},"1257":{"position":[[164,3]]},"1262":{"position":[[8,5]]},"1312":{"position":[[92,3]]},"1364":{"position":[[137,3],[434,3]]},"1382":{"position":[[6,3]]},"1431":{"position":[[584,3],[592,3],[725,3],[750,3],[1134,3],[1161,3],[2433,3],[2654,3],[2714,3],[2833,3],[2883,3],[2984,3],[3005,3],[3086,3]]},"1618":{"position":[[40,3]]},"1730":{"position":[[918,3],[990,3]]},"1800":{"position":[[72,3]]}}}],["top2",{"_index":4330,"t":{"1317":{"position":[[130,5]]}}}],["topic",{"_index":4225,"t":{"1283":{"position":[[73,5]]},"1289":{"position":[[628,6]]},"1323":{"position":[[39,5],[124,5],[177,5]]},"1655":{"position":[[323,5],[369,6]]},"1728":{"position":[[478,6]]}}}],["topv\\text{top}_vtopv",{"_index":3176,"t":{"857":{"position":[[191,21]]}}}],["total",{"_index":2341,"t":{"660":{"position":[[812,5]]},"786":{"position":[[2958,5]]},"803":{"position":[[100,5],[117,5]]},"821":{"position":[[69,5],[306,5]]},"823":{"position":[[21,5]]},"830":{"position":[[56,5]]},"934":{"position":[[1458,5]]},"963":{"position":[[547,5]]},"1151":{"position":[[801,7],[863,7],[927,7]]},"1157":{"position":[[67,5]]},"1159":{"position":[[885,5]]},"1187":{"position":[[232,5]]},"1218":{"position":[[25,5]]},"1244":{"position":[[1966,5]]},"1248":{"position":[[182,5],[355,5]]},"1352":{"position":[[1328,5]]},"1373":{"position":[[4,5]]},"1379":{"position":[[294,5]]}}}],["totext",{"_index":3923,"t":{"1132":{"position":[[633,6]]}}}],["toward",{"_index":2831,"t":{"791":{"position":[[774,8]]}}}],["town",{"_index":5306,"t":{"1659":{"position":[[212,6]]}}}],["toxic",{"_index":4911,"t":{"1544":{"position":[[23,5]]},"1546":{"position":[[672,8],[738,8],[770,5]]},"1560":{"position":[[535,8]]},"1565":{"position":[[60,8]]},"1573":{"position":[[184,6],[337,5]]}}}],["toy",{"_index":1576,"t":{"420":{"position":[[5,3]]},"424":{"position":[[361,4]]}}}],["tpu",{"_index":1608,"t":{"436":{"position":[[747,3]]},"475":{"position":[[93,3]]},"479":{"position":[[184,3]]},"666":{"position":[[371,4]]}}}],["tpuv3",{"_index":544,"t":{"110":{"position":[[110,5]]}}}],["tra",{"_index":3946,"t":{"1143":{"position":[[168,6]]}}}],["track",{"_index":735,"t":{"163":{"position":[[750,8]]},"165":{"position":[[196,8],[225,8],[591,8]]},"177":{"position":[[1014,8]]},"193":{"position":[[105,8]]}}}],["trackingnet",{"_index":891,"t":{"177":{"position":[[1248,11]]},"189":{"position":[[41,11]]}}}],["trade",{"_index":2318,"t":{"658":{"position":[[1364,5]]},"662":{"position":[[1121,5]]},"672":{"position":[[101,5],[322,5]]},"674":{"position":[[151,5]]},"709":{"position":[[2328,5],[2626,5]]},"719":{"position":[[318,5]]},"1341":{"position":[[1183,5]]}}}],["tradeoff",{"_index":5153,"t":{"1644":{"position":[[624,8]]}}}],["tradit",{"_index":2467,"t":{"688":{"position":[[28,11]]},"1099":{"position":[[1127,11]]},"1132":{"position":[[697,11]]},"1153":{"position":[[123,11]]}}}],["train",{"_index":193,"t":{"27":{"position":[[158,8],[219,8],[495,8]]},"38":{"position":[[50,8],[346,8]]},"44":{"position":[[57,8]]},"76":{"position":[[0,8]]},"78":{"position":[[19,8],[282,5],[487,5],[667,8],[926,8]]},"91":{"position":[[963,8],[1062,8]]},"97":{"position":[[24,8],[192,8],[320,7],[366,7]]},"102":{"position":[[0,5]]},"106":{"position":[[0,5]]},"112":{"position":[[47,5],[141,5]]},"114":{"position":[[99,5],[138,5],[189,5],[223,5],[278,5],[314,5]]},"120":{"position":[[121,5],[243,8]]},"177":{"position":[[472,8],[983,8]]},"213":{"position":[[134,7]]},"215":{"position":[[72,8],[336,8],[362,8],[536,8],[781,8],[958,8],[1348,8],[1566,8]]},"221":{"position":[[729,7]]},"227":{"position":[[20,7]]},"249":{"position":[[127,8]]},"269":{"position":[[23,8],[72,7]]},"275":{"position":[[14,5],[48,5]]},"313":{"position":[[306,8]]},"317":{"position":[[459,8]]},"319":{"position":[[0,8],[260,8]]},"326":{"position":[[266,8]]},"336":{"position":[[1073,8],[1196,8],[1239,8]]},"339":{"position":[[229,8]]},"343":{"position":[[5,8],[169,8],[454,8],[517,8]]},"345":{"position":[[172,8]]},"352":{"position":[[101,8],[498,8]]},"358":{"position":[[1171,8]]},"384":{"position":[[565,8]]},"407":{"position":[[31,8]]},"409":{"position":[[156,10]]},"434":{"position":[[515,8]]},"436":{"position":[[1062,8],[1774,8],[2071,8]]},"475":{"position":[[26,8]]},"498":{"position":[[825,8]]},"504":{"position":[[742,8]]},"517":{"position":[[82,5]]},"521":{"position":[[98,8],[120,7],[333,8]]},"523":{"position":[[119,8],[580,8],[1000,7]]},"525":{"position":[[43,7],[344,7],[732,7],[842,8],[1044,7]]},"529":{"position":[[171,7],[2142,5],[2235,8],[2536,8],[2590,8],[2757,8]]},"531":{"position":[[101,8],[785,7],[1494,7]]},"533":{"position":[[47,7],[260,7],[378,7]]},"550":{"position":[[203,8]]},"567":{"position":[[46,8],[641,8],[704,8]]},"569":{"position":[[860,9]]},"577":{"position":[[71,8]]},"579":{"position":[[4,7]]},"581":{"position":[[136,8]]},"587":{"position":[[40,7],[88,8],[148,8],[179,8]]},"589":{"position":[[4,7],[82,7],[162,7],[759,8],[829,8],[1261,7]]},"594":{"position":[[59,7],[210,8],[362,8],[386,8],[720,8]]},"596":{"position":[[1157,8],[1579,8],[2347,8]]},"598":{"position":[[130,8],[4109,8]]},"600":{"position":[[44,8],[347,8],[482,8]]},"602":{"position":[[131,8],[500,8]]},"606":{"position":[[8,8]]},"608":{"position":[[273,8],[479,8]]},"612":{"position":[[42,8],[136,8],[330,8]]},"616":{"position":[[93,8]]},"618":{"position":[[199,8]]},"620":{"position":[[141,8],[186,8]]},"630":{"position":[[3,8]]},"648":{"position":[[77,7]]},"656":{"position":[[4,7]]},"658":{"position":[[4,7],[810,8],[1011,7],[1398,7],[1521,7],[2034,8],[2672,8]]},"660":{"position":[[380,7]]},"666":{"position":[[11,7],[517,7]]},"668":{"position":[[52,7]]},"670":{"position":[[967,7]]},"674":{"position":[[247,7]]},"676":{"position":[[50,7]]},"679":{"position":[[178,7]]},"683":{"position":[[4,7],[385,8]]},"688":{"position":[[651,7]]},"696":{"position":[[146,8]]},"709":{"position":[[188,8],[219,8]]},"717":{"position":[[83,7]]},"719":{"position":[[193,7],[552,7],[804,7]]},"721":{"position":[[222,7]]},"723":{"position":[[7,8],[79,7],[338,7],[821,7]]},"733":{"position":[[128,7],[241,7],[538,8],[931,8]]},"759":{"position":[[64,7],[213,7]]},"761":{"position":[[19,8]]},"768":{"position":[[60,7]]},"774":{"position":[[57,7]]},"784":{"position":[[10,7],[101,7],[219,7],[297,7],[848,7]]},"786":{"position":[[840,7],[921,7],[1406,8],[2152,8],[2429,7],[4217,8]]},"791":{"position":[[36,7],[527,8]]},"795":{"position":[[4,7],[804,8]]},"797":{"position":[[149,8],[739,8],[848,8]]},"799":{"position":[[170,8]]},"801":{"position":[[30,8],[1454,8]]},"803":{"position":[[221,8],[500,8]]},"809":{"position":[[96,7],[217,7]]},"821":{"position":[[79,7]]},"823":{"position":[[31,7]]},"830":{"position":[[66,7]]},"847":{"position":[[4,7],[656,8]]},"849":{"position":[[665,8],[775,8],[928,7]]},"853":{"position":[[1891,8],[2194,8],[2312,7],[2402,7]]},"873":{"position":[[130,8],[247,8],[357,8]]},"877":{"position":[[0,8]]},"879":{"position":[[404,8]]},"885":{"position":[[441,7],[595,7]]},"887":{"position":[[272,8],[637,7],[1285,7]]},"891":{"position":[[63,7]]},"893":{"position":[[33,8],[2023,7],[2554,7]]},"895":{"position":[[185,7]]},"899":{"position":[[4,7]]},"905":{"position":[[258,7]]},"921":{"position":[[32,7]]},"924":{"position":[[54,7]]},"928":{"position":[[180,7]]},"932":{"position":[[472,8],[750,8]]},"934":{"position":[[1569,8],[1707,8],[2458,8],[2544,8]]},"940":{"position":[[51,7]]},"945":{"position":[[472,7]]},"949":{"position":[[207,8]]},"951":{"position":[[6,8]]},"953":{"position":[[670,8]]},"955":{"position":[[495,7]]},"961":{"position":[[230,8]]},"965":{"position":[[155,8]]},"967":{"position":[[348,8]]},"973":{"position":[[88,8],[157,7]]},"977":{"position":[[85,7],[503,8],[721,7]]},"979":{"position":[[529,5],[952,7]]},"982":{"position":[[371,8]]},"986":{"position":[[735,8]]},"992":{"position":[[0,9],[552,8]]},"1006":{"position":[[538,7]]},"1012":{"position":[[80,8],[202,7]]},"1014":{"position":[[4,7],[206,8],[327,7],[504,7],[586,8],[834,8],[1262,7],[1686,8]]},"1019":{"position":[[460,7]]},"1039":{"position":[[30,7]]},"1045":{"position":[[58,8]]},"1062":{"position":[[563,8],[661,8],[887,8],[1433,8],[1616,8]]},"1065":{"position":[[143,8]]},"1067":{"position":[[731,8]]},"1070":{"position":[[1662,8]]},"1073":{"position":[[198,8]]},"1080":{"position":[[103,8]]},"1084":{"position":[[228,8],[1207,8]]},"1087":{"position":[[217,8],[294,8]]},"1093":{"position":[[12,8],[85,8],[114,7],[1037,7],[1531,7],[1671,7],[1817,8]]},"1095":{"position":[[401,8]]},"1097":{"position":[[73,7]]},"1099":{"position":[[4,7],[157,7],[423,8]]},"1101":{"position":[[21,8],[126,8],[1031,8],[1074,8]]},"1105":{"position":[[47,8],[233,7],[276,8]]},"1107":{"position":[[300,8],[434,8],[453,8],[1043,8]]},"1109":{"position":[[305,8],[1036,7]]},"1111":{"position":[[871,8],[1134,7],[1453,7],[1526,8]]},"1115":{"position":[[383,7]]},"1120":{"position":[[67,7],[353,8]]},"1126":{"position":[[67,7],[574,7],[1065,8],[1515,7],[1632,8],[1763,7]]},"1130":{"position":[[81,8]]},"1132":{"position":[[94,8],[349,8],[676,8],[833,8],[1005,8],[1240,7],[1401,8],[1469,8],[1826,8]]},"1134":{"position":[[19,7]]},"1141":{"position":[[279,8]]},"1143":{"position":[[20,8],[546,8],[582,8],[1057,8]]},"1145":{"position":[[1550,7],[2151,7]]},"1147":{"position":[[1163,8]]},"1149":{"position":[[210,7]]},"1153":{"position":[[27,7],[472,7]]},"1159":{"position":[[4,7],[850,8],[1068,8],[1884,8]]},"1164":{"position":[[517,8]]},"1167":{"position":[[1185,8]]},"1178":{"position":[[0,8]]},"1208":{"position":[[257,7]]},"1212":{"position":[[161,5]]},"1225":{"position":[[20,7]]},"1227":{"position":[[613,7]]},"1230":{"position":[[404,8]]},"1238":{"position":[[11,7],[88,8],[1190,8]]},"1240":{"position":[[32,8]]},"1244":{"position":[[1947,8]]},"1246":{"position":[[50,8],[143,8],[223,8]]},"1248":{"position":[[249,8]]},"1259":{"position":[[7,8],[425,8]]},"1264":{"position":[[4,8]]},"1266":{"position":[[96,7]]},"1268":{"position":[[26,7]]},"1273":{"position":[[36,8],[429,8]]},"1281":{"position":[[74,8]]},"1289":{"position":[[29,7],[610,8]]},"1291":{"position":[[29,7],[336,7],[440,7]]},"1300":{"position":[[20,7]]},"1303":{"position":[[615,7]]},"1305":{"position":[[902,8]]},"1307":{"position":[[453,8]]},"1314":{"position":[[126,8]]},"1321":{"position":[[56,8]]},"1323":{"position":[[103,8],[195,8]]},"1326":{"position":[[163,8],[206,8]]},"1332":{"position":[[422,7]]},"1341":{"position":[[154,8],[359,7],[497,7],[747,7]]},"1345":{"position":[[186,8],[487,8]]},"1347":{"position":[[508,8],[548,8],[773,8],[954,8],[1597,8],[1739,8]]},"1354":{"position":[[60,8],[209,8],[251,8]]},"1357":{"position":[[150,5],[172,5]]},"1360":{"position":[[120,8],[263,8],[286,8]]},"1367":{"position":[[485,8]]},"1371":{"position":[[28,8],[177,8]]},"1377":{"position":[[104,8]]},"1379":{"position":[[4,7],[414,8]]},"1382":{"position":[[195,8]]},"1384":{"position":[[2262,8],[2663,7],[2724,8],[2842,8],[2934,8]]},"1389":{"position":[[103,8],[2301,8]]},"1393":{"position":[[217,8],[350,8],[392,8],[552,8]]},"1395":{"position":[[3,8],[226,8],[1283,8],[1460,8]]},"1397":{"position":[[57,8],[543,8],[1142,8]]},"1399":{"position":[[410,8]]},"1401":{"position":[[223,8]]},"1407":{"position":[[4,7]]},"1411":{"position":[[106,8]]},"1419":{"position":[[0,8],[56,8],[297,5]]},"1427":{"position":[[251,8]]},"1429":{"position":[[268,8]]},"1466":{"position":[[27,7],[219,7]]},"1481":{"position":[[237,7]]},"1483":{"position":[[34,7]]},"1485":{"position":[[0,7],[795,8]]},"1492":{"position":[[141,8]]},"1494":{"position":[[96,7]]},"1496":{"position":[[153,7],[562,5]]},"1501":{"position":[[84,8]]},"1505":{"position":[[938,5]]},"1509":{"position":[[251,7]]},"1517":{"position":[[148,8],[191,8]]},"1542":{"position":[[91,8]]},"1558":{"position":[[1853,7]]},"1644":{"position":[[8,7]]},"1646":{"position":[[274,8],[369,8]]},"1657":{"position":[[2604,8]]},"1663":{"position":[[167,8],[266,9]]},"1667":{"position":[[722,8],[1013,8]]},"1669":{"position":[[355,8],[494,7],[573,8],[614,8],[811,8],[893,8]]},"1674":{"position":[[677,8]]},"1676":{"position":[[185,8]]},"1682":{"position":[[428,8],[570,7],[689,8],[757,8],[810,8]]},"1684":{"position":[[341,8],[452,8],[586,8]]},"1693":{"position":[[364,7]]},"1695":{"position":[[377,5],[445,6],[538,8],[621,7],[672,7],[768,5],[797,6],[835,6],[1135,8]]},"1708":{"position":[[53,7],[463,8]]},"1712":{"position":[[198,8]]},"1718":{"position":[[46,8],[608,8],[791,8]]},"1720":{"position":[[658,7],[968,7],[1763,8],[2322,8]]},"1724":{"position":[[55,7]]},"1748":{"position":[[57,7]]},"1752":{"position":[[39,7]]}}}],["train/infer",{"_index":3654,"t":{"1062":{"position":[[834,15]]}}}],["trainabl",{"_index":967,"t":{"213":{"position":[[194,9]]},"271":{"position":[[27,9]]},"504":{"position":[[686,9]]},"525":{"position":[[1069,9],[1289,9]]},"529":{"position":[[561,9],[666,9]]},"628":{"position":[[280,9],[394,9]]},"633":{"position":[[849,9],[943,9]]},"648":{"position":[[498,9]]},"656":{"position":[[210,9]]},"672":{"position":[[687,9],[843,9],[1124,9]]},"707":{"position":[[610,9]]},"709":{"position":[[782,9],[1534,9],[2069,9],[2552,9]]},"717":{"position":[[134,9],[189,9],[268,9]]},"719":{"position":[[1155,9]]},"733":{"position":[[603,9]]},"751":{"position":[[106,9]]},"753":{"position":[[148,9]]},"755":{"position":[[734,9]]},"757":{"position":[[51,9],[124,9]]},"786":{"position":[[693,9],[2115,9],[2553,9],[2826,9],[2964,9],[4635,9]]},"801":{"position":[[1173,9]]},"809":{"position":[[525,9],[743,9]]},"814":{"position":[[83,9]]},"821":{"position":[[46,9]]},"830":{"position":[[33,9]]},"849":{"position":[[1452,9]]},"870":{"position":[[1021,9]]},"979":{"position":[[388,9]]},"994":{"position":[[21,9]]},"1006":{"position":[[1071,9]]},"1014":{"position":[[1631,9]]},"1019":{"position":[[515,9],[547,9]]},"1031":{"position":[[11,9]]},"1060":{"position":[[3,9],[208,9]]},"1062":{"position":[[252,9],[324,9],[375,9],[1059,9]]},"1065":{"position":[[302,9]]},"1067":{"position":[[52,9],[148,9],[230,9],[684,10],[970,9],[1339,9]]},"1070":{"position":[[869,9],[944,9],[1083,9],[1178,9],[1418,9]]},"1073":{"position":[[33,9]]},"1075":{"position":[[103,9]]},"1091":{"position":[[101,9]]},"1099":{"position":[[1693,9]]},"1126":{"position":[[1399,9]]},"1172":{"position":[[108,9]]},"1185":{"position":[[12,9]]},"1218":{"position":[[31,9],[67,9],[570,9]]},"1230":{"position":[[17,9]]},"1248":{"position":[[466,9]]},"1300":{"position":[[74,9]]},"1305":{"position":[[940,9],[1030,9],[1072,9]]},"1307":{"position":[[302,9]]},"1326":{"position":[[21,9]]},"1330":{"position":[[13,9],[52,9],[138,9]]},"1341":{"position":[[587,9],[1081,9]]},"1347":{"position":[[115,9]]},"1373":{"position":[[262,9]]},"1377":{"position":[[58,9]]},"1379":{"position":[[201,9]]},"1384":{"position":[[24,9],[158,9],[1174,9],[1242,9],[3136,9],[3844,9]]},"1389":{"position":[[892,9]]},"1395":{"position":[[1080,9],[1667,9],[1720,9],[1975,9],[2689,9],[3061,9]]},"1399":{"position":[[10,9],[104,9],[206,9]]},"1401":{"position":[[115,9],[176,9],[672,9]]},"1468":{"position":[[94,9]]},"1473":{"position":[[193,10]]}}}],["trainable\\textcolor{red}{\\text{trainable}}train",{"_index":2520,"t":{"694":{"position":[[801,51]]}}}],["traind",{"_index":4421,"t":{"1357":{"position":[[241,7]]}}}],["trained+glδtask\\theta_\\text{task",{"_index":4534,"t":{"1389":{"position":[[2248,33]]}}}],["trained+δtask\\theta_\\text{task",{"_index":4491,"t":{"1384":{"position":[[2883,31]]}}}],["trained\\theta_\\text{pr",{"_index":4486,"t":{"1384":{"position":[[2687,23],[2805,23]]}}}],["trained}θpr",{"_index":4487,"t":{"1384":{"position":[[2711,12],[2829,12]]}}}],["trained​+gl​δtask",{"_index":4536,"t":{"1389":{"position":[[2356,18]]}}}],["trained​+δtask",{"_index":4494,"t":{"1384":{"position":[[2975,15]]}}}],["trainer",{"_index":3723,"t":{"1082":{"position":[[69,7]]},"1577":{"position":[[103,7]]}}}],["trainig",{"_index":3445,"t":{"955":{"position":[[627,7]]}}}],["training/infer",{"_index":3647,"t":{"1060":{"position":[[391,18]]},"1395":{"position":[[2216,18]]},"1399":{"position":[[32,18]]}}}],["trainng",{"_index":4589,"t":{"1411":{"position":[[68,7]]}}}],["trajectori",{"_index":4736,"t":{"1449":{"position":[[91,10]]},"1451":{"position":[[207,10]]},"1453":{"position":[[184,10]]},"1455":{"position":[[35,10]]}}}],["tranasf",{"_index":1384,"t":{"334":{"position":[[63,9]]}}}],["trane",{"_index":4006,"t":{"1164":{"position":[[572,7]]}}}],["transduct",{"_index":1137,"t":{"283":{"position":[[13,12]]},"287":{"position":[[851,12]]},"289":{"position":[[16,12]]},"306":{"position":[[12,12]]},"310":{"position":[[257,12],[517,12]]},"328":{"position":[[51,12]]}}}],["transer",{"_index":4779,"t":{"1475":{"position":[[256,14]]},"1513":{"position":[[100,7]]}}}],["transfer",{"_index":383,"t":{"86":{"position":[[490,8]]},"102":{"position":[[116,8],[133,8],[262,8]]},"104":{"position":[[337,8]]},"112":{"position":[[451,8],[513,8]]},"334":{"position":[[395,8]]},"336":{"position":[[165,8],[383,8],[1847,8]]},"345":{"position":[[11,8]]},"352":{"position":[[272,8]]},"356":{"position":[[12,8]]},"358":{"position":[[11,8]]},"362":{"position":[[10,8]]},"378":{"position":[[77,8]]},"485":{"position":[[81,8],[861,8]]},"525":{"position":[[17,8]]},"527":{"position":[[2952,8]]},"531":{"position":[[585,8],[919,8]]},"533":{"position":[[451,8]]},"626":{"position":[[333,12]]},"628":{"position":[[853,8]]},"648":{"position":[[962,8]]},"656":{"position":[[44,8],[172,8],[367,8]]},"658":{"position":[[18,8],[433,8],[638,8],[672,8],[764,8],[1125,8],[1180,8],[1708,8]]},"664":{"position":[[49,8]]},"668":{"position":[[94,8]]},"727":{"position":[[53,8],[189,8]]},"791":{"position":[[821,8]]},"849":{"position":[[48,11],[174,8]]},"851":{"position":[[1134,8]]},"855":{"position":[[96,12]]},"977":{"position":[[180,8],[775,8]]},"979":{"position":[[494,12],[1535,8],[1789,8],[1968,8]]},"984":{"position":[[198,8]]},"999":{"position":[[862,8],[1034,12]]},"1004":{"position":[[321,12],[473,12]]},"1006":{"position":[[822,12],[1375,8],[1477,12],[1878,8]]},"1008":{"position":[[246,8],[536,8],[723,12]]},"1060":{"position":[[1178,8]]},"1070":{"position":[[552,8],[1331,8]]},"1073":{"position":[[130,8]]},"1075":{"position":[[56,8]]},"1084":{"position":[[105,8],[847,8]]},"1095":{"position":[[38,15]]},"1124":{"position":[[590,8]]},"1132":{"position":[[595,8]]},"1147":{"position":[[303,8],[768,8],[898,8]]},"1153":{"position":[[204,8]]},"1197":{"position":[[221,8]]},"1225":{"position":[[382,12]]},"1227":{"position":[[341,8],[535,12],[820,8],[1144,8],[1276,8],[1368,8]]},"1230":{"position":[[475,15],[522,15]]},"1232":{"position":[[136,8],[349,8]]},"1234":{"position":[[71,8],[218,8],[260,8]]},"1236":{"position":[[721,8]]},"1238":{"position":[[1273,11],[1348,8]]},"1244":{"position":[[566,8],[1882,8]]},"1246":{"position":[[16,8]]},"1257":{"position":[[231,8]]},"1266":{"position":[[153,8],[280,8]]},"1273":{"position":[[53,8]]},"1279":{"position":[[40,8]]},"1285":{"position":[[144,12],[305,8],[399,8]]},"1367":{"position":[[579,8]]},"1407":{"position":[[216,8],[248,8],[560,8],[677,12]]},"1409":{"position":[[693,8],[1020,15],[1213,8],[1303,8],[1470,8],[1569,8],[1672,15],[1747,8]]},"1411":{"position":[[413,11]]},"1419":{"position":[[32,8]]},"1423":{"position":[[116,8],[323,8],[827,8]]},"1425":{"position":[[7,8],[126,8],[263,8],[348,15]]},"1427":{"position":[[116,8],[176,8],[300,15],[627,9],[684,8],[1000,8],[1211,8]]},"1429":{"position":[[1787,15]]},"1431":{"position":[[31,15],[1665,16],[1831,15],[2250,15]]},"1434":{"position":[[224,8],[356,15]]},"1436":{"position":[[23,8],[103,15],[140,8]]},"1473":{"position":[[397,8]]},"1513":{"position":[[12,8],[45,8],[254,8],[484,8],[503,8],[525,8],[607,8],[642,8]]},"1523":{"position":[[52,8],[366,8]]},"1646":{"position":[[537,8]]}}}],["transfor",{"_index":627,"t":{"132":{"position":[[222,10]]}}}],["transform",{"_index":170,"t":{"25":{"position":[[202,11]]},"84":{"position":[[12,11],[82,11],[132,11]]},"86":{"position":[[190,11],[278,11],[351,11]]},"88":{"position":[[0,11],[157,12],[635,11]]},"91":{"position":[[3,11],[400,11],[437,11],[882,11],[1319,11],[2108,11]]},"93":{"position":[[118,11]]},"95":{"position":[[253,11]]},"114":{"position":[[2,12]]},"116":{"position":[[167,11],[247,11]]},"120":{"position":[[83,11]]},"126":{"position":[[63,11]]},"132":{"position":[[268,11]]},"143":{"position":[[262,11],[292,11]]},"153":{"position":[[70,11],[490,11],[622,11]]},"165":{"position":[[2146,11]]},"174":{"position":[[199,11],[571,11]]},"182":{"position":[[158,11]]},"225":{"position":[[28,11]]},"227":{"position":[[85,11],[566,12]]},"230":{"position":[[446,11]]},"234":{"position":[[70,11]]},"265":{"position":[[133,11]]},"283":{"position":[[100,11],[243,11]]},"285":{"position":[[468,11]]},"287":{"position":[[211,11],[735,11]]},"289":{"position":[[395,11]]},"302":{"position":[[0,11]]},"304":{"position":[[131,15],[319,15]]},"306":{"position":[[193,14],[280,14]]},"322":{"position":[[41,11],[362,11]]},"324":{"position":[[0,11]]},"326":{"position":[[0,11],[342,11],[970,11]]},"328":{"position":[[7,11],[171,11]]},"339":{"position":[[400,11],[436,12]]},"457":{"position":[[799,11]]},"498":{"position":[[371,11]]},"527":{"position":[[45,11]]},"533":{"position":[[55,12],[386,11]]},"594":{"position":[[237,11]]},"598":{"position":[[1132,11],[1894,11],[1998,11]]},"608":{"position":[[106,11],[206,11]]},"628":{"position":[[161,11],[309,11]]},"630":{"position":[[1690,11]]},"633":{"position":[[618,11],[660,11],[805,11],[894,11]]},"648":{"position":[[287,11],[397,11],[449,11]]},"658":{"position":[[101,11]]},"662":{"position":[[0,11],[91,11],[295,11],[317,11]]},"666":{"position":[[24,11]]},"681":{"position":[[1508,11]]},"688":{"position":[[261,11]]},"692":{"position":[[30,11],[169,11]]},"694":{"position":[[122,11],[403,11]]},"696":{"position":[[1616,11]]},"703":{"position":[[156,11]]},"717":{"position":[[114,11]]},"721":{"position":[[0,11],[43,11],[339,11]]},"727":{"position":[[83,11],[426,11]]},"731":{"position":[[6,11]]},"739":{"position":[[0,11]]},"741":{"position":[[34,11]]},"753":{"position":[[55,11],[272,11]]},"759":{"position":[[45,12]]},"768":{"position":[[68,11]]},"789":{"position":[[5,11],[806,15]]},"797":{"position":[[29,11]]},"807":{"position":[[59,12]]},"809":{"position":[[278,11]]},"857":{"position":[[541,11]]},"885":{"position":[[299,11]]},"887":{"position":[[363,11]]},"891":{"position":[[40,11],[206,11],[329,11],[370,11],[899,11]]},"893":{"position":[[123,11],[2488,11]]},"895":{"position":[[768,11]]},"899":{"position":[[27,11]]},"905":{"position":[[231,11]]},"917":{"position":[[0,11]]},"934":{"position":[[1474,11]]},"938":{"position":[[152,11]]},"940":{"position":[[227,11]]},"945":{"position":[[371,11]]},"953":{"position":[[353,11],[515,11]]},"961":{"position":[[3,11]]},"1039":{"position":[[272,11]]},"1054":{"position":[[241,11]]},"1060":{"position":[[351,11],[586,11]]},"1062":{"position":[[781,11]]},"1067":{"position":[[1227,11]]},"1107":{"position":[[781,11]]},"1128":{"position":[[361,11]]},"1132":{"position":[[640,12],[1800,14]]},"1145":{"position":[[276,11],[591,11],[1825,11],[2022,11]]},"1185":{"position":[[454,14]]},"1291":{"position":[[819,11]]},"1303":{"position":[[794,11]]},"1314":{"position":[[108,12]]},"1328":{"position":[[131,11]]},"1339":{"position":[[268,11]]},"1341":{"position":[[385,11]]},"1369":{"position":[[337,12]]},"1384":{"position":[[115,11],[1108,11],[1294,11],[2227,11]]},"1389":{"position":[[807,11],[2000,11]]},"1395":{"position":[[668,11]]},"1468":{"position":[[367,11]]},"1494":{"position":[[618,11]]},"1665":{"position":[[1157,12]]},"1674":{"position":[[239,12]]}}}],["transformation/token",{"_index":600,"t":{"130":{"position":[[357,27]]}}}],["transformer'",{"_index":3648,"t":{"1060":{"position":[[502,13]]}}}],["translat",{"_index":1374,"t":{"326":{"position":[[701,11]]},"328":{"position":[[150,11],[296,11]]},"1234":{"position":[[98,12]]},"1419":{"position":[[808,12]]},"1630":{"position":[[6,9]]},"1634":{"position":[[181,9]]},"1636":{"position":[[162,11]]},"1702":{"position":[[474,11]]},"1714":{"position":[[196,11]]},"1730":{"position":[[437,11]]}}}],["transprompt",{"_index":4094,"t":{"1230":{"position":[[498,13]]}}}],["traslat",{"_index":1421,"t":{"343":{"position":[[292,10]]}}}],["trasnform",{"_index":3957,"t":{"1145":{"position":[[1952,11]]}}}],["tre",{"_index":3843,"t":{"1107":{"position":[[418,3]]}}}],["tree",{"_index":5616,"t":{"1788":{"position":[[361,5]]}}}],["treebank",{"_index":1363,"t":{"326":{"position":[[242,8]]},"1672":{"position":[[275,8]]}}}],["trend",{"_index":3171,"t":{"855":{"position":[[713,8],[898,8]]}}}],["tresnet",{"_index":189,"t":{"27":{"position":[[85,8]]}}}],["trex",{"_index":3778,"t":{"1099":{"position":[[699,4]]},"1107":{"position":[[135,4]]}}}],["tri",{"_index":85,"t":{"13":{"position":[[39,3]]},"1006":{"position":[[2677,3]]}}}],["trial",{"_index":4701,"t":{"1440":{"position":[[352,5]]},"1442":{"position":[[638,6]]},"1451":{"position":[[37,6],[653,5],[752,6]]},"1453":{"position":[[342,5]]},"1455":{"position":[[6,5],[153,5],[232,5],[420,5],[634,5]]}}}],["triangl",{"_index":2595,"t":{"723":{"position":[[429,9],[710,11],[763,14],[946,17],[971,9],[1092,11],[1270,9]]},"733":{"position":[[358,9],[805,9]]},"786":{"position":[[993,11],[1042,11],[1113,11],[1417,11],[1453,11],[1581,11],[1702,9],[2389,11],[3966,11],[4122,11]]},"791":{"position":[[187,9]]},"795":{"position":[[147,9],[315,11],[790,11],[1174,11]]},"853":{"position":[[1980,9]]},"1067":{"position":[[557,9]]}}}],["triangledown_{\\lambda_k",{"_index":2912,"t":{"797":{"position":[[1418,25]]}}}],["triangledown_{w_{ij",{"_index":2970,"t":{"801":{"position":[[1065,22]]}}}],["trick",{"_index":4346,"t":{"1332":{"position":[[351,5]]},"1334":{"position":[[372,5]]}}}],["trillion",{"_index":3760,"t":{"1095":{"position":[[95,8]]}}}],["tripl",{"_index":3832,"t":{"1105":{"position":[[115,6],[148,6]]},"1107":{"position":[[93,7],[266,7]]},"1782":{"position":[[1899,7]]}}}],["triplet",{"_index":2849,"t":{"795":{"position":[[596,7]]},"797":{"position":[[508,7],[2328,8]]},"799":{"position":[[3,7]]},"801":{"position":[[214,8],[300,8],[351,8]]},"807":{"position":[[510,8]]},"837":{"position":[[38,7]]}}}],["trnasfer",{"_index":1417,"t":{"341":{"position":[[501,8]]}}}],["trnasform",{"_index":386,"t":{"86":{"position":[[779,11]]}}}],["true",{"_index":3642,"t":{"1052":{"position":[[285,6],[318,7]]},"1704":{"position":[[343,4]]},"1798":{"position":[[164,4]]}}}],["true\"/\"fals",{"_index":3992,"t":{"1159":{"position":[[522,14]]}}}],["truncat",{"_index":7,"t":{"3":{"position":[[57,8]]},"786":{"position":[[3761,8]]},"795":{"position":[[1924,10]]}}}],["truth",{"_index":685,"t":{"149":{"position":[[86,5]]},"436":{"position":[[203,5]]},"1546":{"position":[[632,12]]},"1669":{"position":[[388,5]]},"1796":{"position":[[133,5]]}}}],["truthfulqa",{"_index":4965,"t":{"1560":{"position":[[419,10]]}}}],["tt={t1​,t2​,…,tt",{"_index":4107,"t":{"1236":{"position":[[240,20]]},"1246":{"position":[[1004,20]]}}}],["tt\\mathcal{t}_ttt",{"_index":4193,"t":{"1246":{"position":[[558,18]]}}}],["ttt",{"_index":1078,"t":{"236":{"position":[[299,3]]},"285":{"position":[[187,3]]},"598":{"position":[[997,3]]},"797":{"position":[[1118,3],[2377,3]]},"853":{"position":[[1000,3]]},"861":{"position":[[101,3]]},"873":{"position":[[124,3]]},"984":{"position":[[22,3]]},"988":{"position":[[1793,3]]},"1099":{"position":[[661,3],[933,3],[1217,3]]},"1162":{"position":[[102,4]]},"1244":{"position":[[1191,3]]},"1431":{"position":[[277,3],[670,3],[885,3]]},"1447":{"position":[[107,3]]},"1451":{"position":[[685,3]]},"1455":{"position":[[159,3],[426,3],[640,3]]}}}],["tuin",{"_index":1812,"t":{"521":{"position":[[220,7]]},"1570":{"position":[[409,7]]}}}],["tunabl",{"_index":3425,"t":{"934":{"position":[[1874,7]]},"1028":{"position":[[153,7],[367,7]]},"1126":{"position":[[1578,7]]},"1227":{"position":[[271,7],[1525,7]]},"1248":{"position":[[161,7],[335,7]]},"1468":{"position":[[403,7]]},"1477":{"position":[[91,7]]},"1507":{"position":[[59,7],[250,7]]},"1720":{"position":[[2000,7],[2373,7]]}}}],["tune",{"_index":208,"t":{"31":{"position":[[207,6]]},"63":{"position":[[73,6]]},"91":{"position":[[979,6],[1099,6]]},"93":{"position":[[191,6]]},"97":{"position":[[59,6],[217,4],[308,4]]},"106":{"position":[[136,4]]},"108":{"position":[[166,6]]},"112":{"position":[[349,6]]},"215":{"position":[[738,6],[835,7],[996,6],[1115,6],[1178,6],[1216,6],[1369,6],[1400,6],[1441,6]]},"219":{"position":[[363,6]]},"244":{"position":[[92,6]]},"249":{"position":[[44,6]]},"251":{"position":[[55,6]]},"253":{"position":[[263,6]]},"269":{"position":[[39,6],[222,6]]},"326":{"position":[[885,6]]},"428":{"position":[[276,7]]},"483":{"position":[[682,6],[789,6]]},"485":{"position":[[1545,6],[1642,6]]},"504":{"position":[[566,6]]},"521":{"position":[[159,6],[270,6]]},"523":{"position":[[169,6],[226,6],[368,6],[415,5],[624,6],[701,6],[806,6],[921,5],[1041,6]]},"525":{"position":[[5,6],[318,6],[377,6],[454,6],[490,5],[750,6],[790,6],[1399,6]]},"527":{"position":[[27,7],[173,5],[300,6],[2909,6],[2930,6],[3028,6],[3176,6],[3196,6]]},"529":{"position":[[1194,6],[1365,5],[1803,6],[1975,6],[2125,6],[2841,6]]},"531":{"position":[[27,6],[117,6],[539,6],[1020,6],[1298,6],[1477,6]]},"533":{"position":[[94,6],[109,6],[360,6],[405,6]]},"539":{"position":[[584,6]]},"563":{"position":[[363,6]]},"567":{"position":[[230,6]]},"587":{"position":[[251,6],[295,7],[641,6]]},"589":{"position":[[245,6],[260,6],[361,6],[992,6],[1243,6],[1320,6],[1389,6],[1526,6],[1852,6],[2110,6]]},"592":{"position":[[341,6]]},"594":{"position":[[32,6],[292,6],[651,6]]},"596":{"position":[[35,6],[2401,6]]},"598":{"position":[[443,6],[459,6],[3054,6],[3355,6],[3552,6],[3684,6],[3786,6],[3963,6],[3989,6],[4008,6]]},"600":{"position":[[10,6],[92,6],[467,6],[498,6]]},"602":{"position":[[694,6]]},"612":{"position":[[443,6]]},"618":{"position":[[276,6]]},"622":{"position":[[220,6]]},"626":{"position":[[36,6],[77,7],[92,6],[524,6]]},"628":{"position":[[65,6],[113,6],[152,6],[257,6],[448,6]]},"630":{"position":[[106,6],[234,7],[273,6],[804,6],[1961,7],[2100,6],[2118,6]]},"633":{"position":[[534,6],[602,7],[635,6],[650,7],[795,7],[975,6],[999,6]]},"635":{"position":[[7,6],[89,6]]},"638":{"position":[[54,6],[124,6]]},"640":{"position":[[128,6],[154,6],[278,6]]},"644":{"position":[[45,6],[175,6],[310,6]]},"648":{"position":[[5,6],[36,7],[151,6],[205,6],[228,6],[278,6],[388,6],[732,6],[864,6]]},"650":{"position":[[196,6]]},"656":{"position":[[23,6],[470,6],[506,6]]},"658":{"position":[[688,6],[998,6],[1076,6],[1099,6],[1196,6],[1276,6],[1322,6],[1436,6],[1450,6],[1571,6],[1877,6],[1956,6],[2192,6],[2463,6],[2593,6],[2896,6],[3019,5],[3080,6],[3170,6]]},"660":{"position":[[43,6],[297,6],[455,6],[575,6],[636,6]]},"662":{"position":[[31,6]]},"664":{"position":[[90,6],[118,6],[229,6]]},"666":{"position":[[468,6],[504,6],[561,6]]},"668":{"position":[[374,6],[534,6],[649,6]]},"670":{"position":[[385,6],[514,6],[595,6],[1180,7],[1202,7],[1218,6],[1343,6],[1361,6],[1388,6],[1448,6],[1506,6]]},"672":{"position":[[205,6],[245,6],[366,6],[443,6],[567,6],[665,6],[729,6],[832,6],[939,6],[1056,6],[1248,6],[1320,6]]},"674":{"position":[[112,6],[234,6],[657,6],[726,6]]},"676":{"position":[[646,6],[805,6],[828,6]]},"679":{"position":[[116,6],[165,6],[366,6],[396,6],[422,6],[456,6],[611,6]]},"681":{"position":[[126,6],[223,5],[300,6],[335,6],[361,6],[401,6],[489,6],[693,6],[728,6],[892,6],[948,6],[985,6],[1037,6],[1074,6],[1118,6],[1150,6],[1298,6],[1327,6],[1434,6],[1698,6],[1980,6],[2016,6]]},"683":{"position":[[440,6],[475,6],[543,7],[627,6],[656,6],[702,6],[843,7],[944,6],[1003,6],[1208,6]]},"686":{"position":[[7,6],[468,6]]},"688":{"position":[[7,6],[103,6],[954,6]]},"690":{"position":[[62,7],[120,6],[183,6],[261,6],[353,6],[394,6],[427,6],[531,6],[620,6],[784,6],[940,6]]},"692":{"position":[[21,6],[329,6]]},"694":{"position":[[12,6]]},"696":{"position":[[113,6],[184,6],[1010,6]]},"698":{"position":[[95,6]]},"701":{"position":[[10,6]]},"703":{"position":[[12,6],[32,6],[63,6],[77,6],[101,7],[142,6],[281,6]]},"705":{"position":[[17,6]]},"707":{"position":[[38,6],[143,6],[190,6],[341,6],[593,6],[665,6],[684,6],[780,6],[799,6]]},"709":{"position":[[409,6],[423,6],[506,6],[520,6],[1926,6]]},"711":{"position":[[13,6],[39,6],[221,6]]},"713":{"position":[[39,6],[53,6]]},"717":{"position":[[24,6],[233,6]]},"719":{"position":[[82,6],[1214,5],[1288,6]]},"723":{"position":[[324,6],[655,6],[845,5]]},"729":{"position":[[19,6]]},"733":{"position":[[1053,6]]},"735":{"position":[[112,6]]},"753":{"position":[[17,6]]},"763":{"position":[[24,6]]},"765":{"position":[[126,6],[159,6]]},"780":{"position":[[11,6],[204,6]]},"784":{"position":[[67,6],[138,6],[192,6],[408,6]]},"786":{"position":[[5,5],[226,6],[307,6],[432,6],[553,6],[620,6],[636,6],[737,6],[1520,6],[1982,6],[2182,6],[2222,6],[2451,6],[2610,6],[2680,6],[3126,8],[3323,6],[3859,6],[4617,6]]},"791":{"position":[[929,7],[944,6],[978,6]]},"803":{"position":[[200,6],[664,6]]},"805":{"position":[[50,6]]},"807":{"position":[[316,6]]},"809":{"position":[[31,6],[78,6],[206,6],[254,6],[269,6],[643,6],[736,6]]},"812":{"position":[[37,6]]},"819":{"position":[[76,6]]},"823":{"position":[[100,6]]},"826":{"position":[[61,6]]},"830":{"position":[[20,6]]},"833":{"position":[[52,6]]},"839":{"position":[[171,6],[390,6],[428,6]]},"841":{"position":[[24,6]]},"843":{"position":[[29,6]]},"847":{"position":[[324,6],[383,6],[438,6],[837,6]]},"849":{"position":[[758,6],[966,6],[981,5],[1120,6],[1360,6]]},"853":{"position":[[1163,6],[2229,6],[2293,5]]},"859":{"position":[[111,6]]},"866":{"position":[[340,6]]},"868":{"position":[[169,6],[281,6]]},"870":{"position":[[900,6],[2066,6],[2193,6]]},"875":{"position":[[238,6]]},"879":{"position":[[136,6],[164,6],[234,6],[284,6],[521,6]]},"881":{"position":[[89,6],[293,6]]},"885":{"position":[[65,6],[235,6],[630,6]]},"887":{"position":[[124,6],[256,6],[767,6],[1264,6],[1304,6]]},"891":{"position":[[118,6],[497,6]]},"893":{"position":[[78,6]]},"895":{"position":[[1172,6]]},"899":{"position":[[204,6]]},"901":{"position":[[65,6],[121,6],[132,6]]},"905":{"position":[[132,6]]},"909":{"position":[[173,6]]},"921":{"position":[[11,6]]},"924":{"position":[[78,6]]},"926":{"position":[[107,6]]},"934":{"position":[[164,6],[280,6],[704,6],[1759,6],[2245,6],[2343,6]]},"938":{"position":[[57,6]]},"942":{"position":[[93,6]]},"945":{"position":[[212,6],[260,6],[802,6]]},"947":{"position":[[5,6],[59,6],[94,6],[246,6],[328,6]]},"953":{"position":[[23,6],[616,6]]},"955":{"position":[[132,6]]},"963":{"position":[[5,6],[200,6]]},"967":{"position":[[115,6]]},"973":{"position":[[46,6],[591,6]]},"977":{"position":[[52,6],[240,7],[615,6],[863,6]]},"979":{"position":[[17,6],[291,6],[339,7],[814,6],[852,6],[1478,6]]},"982":{"position":[[110,6],[270,6],[1070,6],[1096,7],[1111,8]]},"984":{"position":[[61,6]]},"992":{"position":[[937,6],[1085,6]]},"994":{"position":[[472,6],[524,6]]},"1002":{"position":[[630,7],[702,7],[735,6]]},"1006":{"position":[[201,6],[227,6],[327,6]]},"1008":{"position":[[333,6],[435,6]]},"1012":{"position":[[7,6],[180,6],[244,6],[335,6],[406,6],[425,5],[459,6],[511,6],[526,7],[555,6],[588,6]]},"1014":{"position":[[74,6],[669,6],[706,6],[739,6],[1074,6],[1188,6],[1203,7],[1319,6],[1388,6],[1442,6],[1602,6],[1672,6]]},"1019":{"position":[[421,7],[439,7],[786,6]]},"1022":{"position":[[8,7],[26,7]]},"1024":{"position":[[8,7]]},"1026":{"position":[[8,7],[26,7],[244,7],[262,7],[388,6],[403,6]]},"1028":{"position":[[8,7],[26,7],[253,6],[277,6],[350,6]]},"1033":{"position":[[18,6]]},"1035":{"position":[[107,6]]},"1037":{"position":[[108,6],[190,6]]},"1039":{"position":[[2,6],[145,7],[176,7],[186,6]]},"1041":{"position":[[2,6]]},"1047":{"position":[[12,6],[66,7],[84,7],[134,6],[238,7],[256,7],[305,7],[359,6]]},"1049":{"position":[[17,6],[105,7],[123,7],[152,7],[170,7],[280,6],[351,6]]},"1052":{"position":[[91,6],[148,6]]},"1054":{"position":[[8,7],[28,6]]},"1056":{"position":[[2,6],[148,6]]},"1060":{"position":[[90,6],[129,6],[816,6],[1090,6]]},"1062":{"position":[[1037,6]]},"1070":{"position":[[406,6],[467,6],[672,6],[1289,6]]},"1077":{"position":[[77,6]]},"1084":{"position":[[486,6]]},"1091":{"position":[[10,6],[148,6],[358,6],[427,6]]},"1093":{"position":[[424,6],[915,6],[1153,6],[1189,6],[1327,6],[1396,6],[1432,6],[1518,6],[1578,6],[1614,6],[1696,6],[1721,6]]},"1095":{"position":[[86,6],[147,6],[167,6],[250,6]]},"1097":{"position":[[25,6]]},"1099":{"position":[[1416,6]]},"1101":{"position":[[435,6]]},"1103":{"position":[[62,6]]},"1107":{"position":[[840,6]]},"1109":{"position":[[23,6],[187,6],[272,6],[289,7],[381,6],[395,6],[474,6],[502,6],[599,6],[676,6],[721,6],[849,6],[863,6],[900,6],[1023,6],[1122,6],[1194,6],[1249,6],[1344,6]]},"1111":{"position":[[2,6],[92,6],[378,6],[1067,6],[1483,6],[1680,6],[1981,7]]},"1113":{"position":[[46,6],[163,6],[254,6],[346,6],[545,6]]},"1115":{"position":[[214,6],[565,6],[665,6],[742,6],[819,6],[926,6],[991,6],[1096,6],[1168,6]]},"1117":{"position":[[32,6],[59,6],[152,6],[249,6],[273,6],[356,6],[392,6],[406,5],[432,6],[473,6],[498,6]]},"1120":{"position":[[9,6]]},"1124":{"position":[[13,6],[223,6],[362,6],[506,6]]},"1126":{"position":[[32,6],[183,6],[196,7],[242,6],[282,6],[342,6],[474,6],[869,5],[934,5],[1169,6],[1199,7],[1278,6],[1487,6],[1709,6],[1877,7],[1933,6],[1951,6],[2468,6],[2496,6],[2593,6],[2635,6]]},"1128":{"position":[[911,6],[1138,6]]},"1130":{"position":[[789,6]]},"1132":{"position":[[756,6],[1080,6],[1632,6]]},"1134":{"position":[[248,6],[304,6]]},"1136":{"position":[[15,6],[126,6],[170,6],[183,6],[250,6],[287,6],[363,6],[378,6],[423,6],[502,6],[596,6],[643,5],[689,5]]},"1143":{"position":[[45,6],[945,6]]},"1145":{"position":[[163,6],[263,6],[402,6],[615,6],[736,6],[793,6],[830,6],[1162,6],[1227,6],[1246,6],[1268,6],[1392,6],[1407,6],[2289,6],[2524,6]]},"1147":{"position":[[21,6],[193,6],[485,6],[525,6],[673,6],[1057,6],[1154,6]]},"1149":{"position":[[197,6]]},"1151":{"position":[[124,6],[1277,5]]},"1153":{"position":[[7,6],[141,6],[223,6]]},"1157":{"position":[[7,6],[37,6],[158,6],[187,6],[333,6],[396,6],[433,6]]},"1159":{"position":[[182,6],[286,5],[361,6],[715,6],[916,6],[943,6],[1274,6],[1318,6],[1767,6],[1812,6],[1944,6],[1982,6]]},"1162":{"position":[[77,4]]},"1164":{"position":[[7,6],[21,6],[432,6],[543,6]]},"1189":{"position":[[16,6],[114,6],[165,6],[226,6],[249,6]]},"1191":{"position":[[10,6],[35,6]]},"1195":{"position":[[16,6],[35,6],[154,6],[344,6],[479,6]]},"1197":{"position":[[46,6],[145,6],[355,6],[445,6]]},"1199":{"position":[[40,6],[77,6],[137,7],[163,6],[339,6],[373,6],[407,6]]},"1201":{"position":[[7,6],[204,6],[272,6]]},"1203":{"position":[[167,6]]},"1205":{"position":[[35,6],[120,6]]},"1212":{"position":[[16,6],[215,6]]},"1214":{"position":[[9,6],[142,6]]},"1218":{"position":[[16,6],[529,6]]},"1221":{"position":[[20,7],[35,6],[79,6],[174,6],[190,6]]},"1225":{"position":[[7,6],[296,6],[604,6]]},"1227":{"position":[[257,6],[762,6],[1072,6]]},"1230":{"position":[[134,6],[234,6],[269,6],[395,6],[548,6],[614,6]]},"1238":{"position":[[381,6]]},"1244":{"position":[[224,6]]},"1246":{"position":[[125,6]]},"1255":{"position":[[7,6]]},"1257":{"position":[[104,6],[126,6]]},"1285":{"position":[[17,6],[325,6],[461,6]]},"1289":{"position":[[5,6],[238,6],[257,6],[451,6],[552,6]]},"1291":{"position":[[5,6],[321,6],[400,6],[427,6],[512,6],[971,6],[1125,6],[1424,5]]},"1303":{"position":[[944,6]]},"1305":{"position":[[7,6]]},"1312":{"position":[[40,6],[74,6],[110,6],[135,6]]},"1314":{"position":[[422,6],[476,6],[583,6],[597,6],[664,6],[698,6]]},"1317":{"position":[[51,6],[204,6],[221,6],[273,6],[332,6],[356,6],[384,6],[430,6],[447,6],[548,6],[608,6]]},"1319":{"position":[[30,6],[81,6],[146,6]]},"1321":{"position":[[47,6],[293,6],[393,6],[407,6],[494,6],[508,6],[542,6],[594,6]]},"1323":{"position":[[499,6],[585,6],[601,6]]},"1328":{"position":[[437,6]]},"1330":{"position":[[241,6],[277,6],[293,6],[333,6],[386,6]]},"1332":{"position":[[486,6]]},"1334":{"position":[[57,6],[74,6],[187,6],[201,6],[277,6],[296,6]]},"1337":{"position":[[18,6],[180,6]]},"1339":{"position":[[33,6],[144,6],[252,6]]},"1341":{"position":[[5,6],[59,6],[76,6],[209,6],[226,6],[325,6],[342,6],[446,7],[461,6],[565,6],[660,6],[677,6],[734,6],[784,6],[856,6],[1068,6],[1221,6]]},"1345":{"position":[[7,6],[26,6],[171,6]]},"1347":{"position":[[7,6],[29,6],[105,6],[153,6],[236,6],[539,6],[614,6],[1014,6],[1359,6],[1583,6],[1698,6]]},"1350":{"position":[[10,7],[282,6],[453,7],[609,6],[869,6]]},"1357":{"position":[[322,7],[332,6],[351,6],[388,6]]},"1360":{"position":[[243,6],[337,6]]},"1362":{"position":[[470,6]]},"1364":{"position":[[196,6],[300,6]]},"1367":{"position":[[73,6],[143,6],[171,6],[287,6],[549,6],[659,6],[751,6]]},"1369":{"position":[[473,6],[655,6]]},"1371":{"position":[[225,6]]},"1373":{"position":[[74,6],[157,6],[338,6]]},"1377":{"position":[[38,6],[85,6],[480,6]]},"1379":{"position":[[87,6],[160,6],[228,6],[382,6],[481,6],[1025,6],[1343,7],[1712,6]]},"1382":{"position":[[67,6],[91,6],[120,6],[176,6],[228,6]]},"1384":{"position":[[84,6],[1001,6],[1082,7],[1097,6],[2410,6],[2454,6],[2631,6],[3077,6],[3884,6]]},"1387":{"position":[[65,6]]},"1389":{"position":[[94,6],[199,6],[974,7],[1680,6],[1880,6]]},"1393":{"position":[[669,6],[691,7]]},"1395":{"position":[[253,6],[299,6],[409,6],[1356,7],[1371,6],[1446,6],[1622,6],[1644,6],[2016,6],[2115,6],[2286,7],[2354,6]]},"1397":{"position":[[696,6],[1285,6]]},"1399":{"position":[[63,6],[184,6],[486,6]]},"1401":{"position":[[20,6]]},"1403":{"position":[[46,6],[203,6]]},"1407":{"position":[[119,6],[368,6],[415,6],[433,7]]},"1409":{"position":[[125,6],[379,6],[486,6],[597,6],[612,6],[818,6],[940,6],[1604,6],[1631,6]]},"1411":{"position":[[24,6],[92,6],[137,6],[269,6]]},"1415":{"position":[[30,7],[76,6],[134,6],[160,7],[175,6],[198,6],[255,6],[304,6],[372,6]]},"1421":{"position":[[66,6],[356,6],[540,6]]},"1423":{"position":[[64,7],[134,6],[207,6],[281,6],[353,6],[454,6],[553,6],[950,6],[1012,6],[1039,6],[1122,6],[1150,6],[1306,6],[1491,5]]},"1425":{"position":[[25,6]]},"1427":{"position":[[363,6],[517,6]]},"1429":{"position":[[23,6]]},"1431":{"position":[[221,6],[683,6],[902,6],[1344,6],[1504,7],[2949,6]]},"1434":{"position":[[25,6],[108,6],[187,6],[270,6]]},"1436":{"position":[[14,6],[51,6],[66,6]]},"1440":{"position":[[106,6]]},"1466":{"position":[[7,6],[121,6],[138,6],[369,6]]},"1468":{"position":[[132,6],[177,6],[294,6],[428,6],[889,6],[1528,6],[1589,6],[1665,6],[1704,6]]},"1471":{"position":[[209,6],[302,6]]},"1473":{"position":[[67,6],[260,6],[301,6],[343,6],[678,6]]},"1477":{"position":[[32,6],[671,6],[903,6],[966,6]]},"1479":{"position":[[59,6]]},"1481":{"position":[[63,6],[77,6],[126,6],[227,6]]},"1489":{"position":[[299,6],[389,6]]},"1492":{"position":[[177,6]]},"1494":{"position":[[5,7],[32,6],[145,6],[159,7],[205,6],[278,7],[309,6],[455,6],[496,7]]},"1499":{"position":[[37,6],[59,6],[160,7],[175,7],[185,6],[225,6],[359,6],[370,6],[438,6],[540,6],[582,6],[705,6],[763,6],[777,6]]},"1501":{"position":[[154,6],[227,6],[330,6],[421,6]]},"1505":{"position":[[153,6],[517,6],[562,6],[640,6],[669,6],[1047,6],[1163,6]]},"1507":{"position":[[17,6],[93,6],[145,6],[180,6],[241,6],[303,6],[342,6]]},"1509":{"position":[[181,6]]},"1511":{"position":[[239,6]]},"1515":{"position":[[47,6],[61,6]]},"1544":{"position":[[195,4],[269,4]]},"1546":{"position":[[209,4],[274,4],[402,4],[886,6],[1119,6]]},"1550":{"position":[[121,6],[306,6]]},"1552":{"position":[[407,6],[529,6]]},"1558":{"position":[[152,6],[213,6],[1246,6],[2161,6]]},"1565":{"position":[[107,6]]},"1567":{"position":[[24,6]]},"1644":{"position":[[85,6],[110,6],[518,6],[788,6],[828,6]]},"1646":{"position":[[142,6],[214,6],[290,6],[402,6],[524,6],[687,6],[1247,6],[1959,6],[2185,6],[3213,6],[3229,6]]},"1653":{"position":[[1026,6]]},"1657":{"position":[[2464,6]]},"1665":{"position":[[227,6],[281,6],[329,6],[565,6],[1055,6]]},"1667":{"position":[[474,6],[631,6],[816,6],[1147,6]]},"1674":{"position":[[32,6],[634,6]]},"1676":{"position":[[103,6],[235,6]]},"1682":{"position":[[252,6],[400,6],[650,6],[773,6],[845,6]]},"1684":{"position":[[106,6],[130,6],[170,6],[280,6],[607,6]]},"1686":{"position":[[11,6],[141,6],[419,6]]},"1689":{"position":[[59,6],[173,6],[421,6],[437,6]]},"1695":{"position":[[392,4],[497,4],[554,6],[732,6],[783,5]]},"1720":{"position":[[298,6],[312,6],[1140,6],[1417,6],[1933,6],[2028,6],[2215,6]]},"1748":{"position":[[137,6],[166,6],[238,6]]},"1750":{"position":[[16,6],[370,6]]},"1752":{"position":[[0,6],[151,6],[209,6]]},"1754":{"position":[[16,6],[161,6],[177,6],[202,6],[270,6]]},"1756":{"position":[[16,6],[58,6]]},"1758":{"position":[[10,6],[100,6]]},"1766":{"position":[[359,6]]},"1768":{"position":[[141,6]]},"1774":{"position":[[353,6],[425,6],[529,6]]},"1780":{"position":[[67,6]]},"1782":{"position":[[606,6],[2205,6],[2266,6]]},"1796":{"position":[[75,6]]},"1798":{"position":[[64,5]]}}}],["tuningv2",{"_index":4840,"t":{"1494":{"position":[[474,8]]},"1499":{"position":[[196,8],[341,8],[398,8]]}}}],["tuniong",{"_index":4036,"t":{"1170":{"position":[[42,7]]}}}],["tupl",{"_index":649,"t":{"140":{"position":[[396,5]]}}}],["turbin",{"_index":1662,"t":{"457":{"position":[[284,7]]}}}],["turn",{"_index":3446,"t":{"959":{"position":[[30,4]]},"973":{"position":[[337,4]]}}}],["tutori",{"_index":4988,"t":{"1581":{"position":[[220,9]]},"1595":{"position":[[401,11],[420,10]]}}}],["tutorialsidebar",{"_index":5047,"t":{"1595":{"position":[[337,16]]}}}],["two",{"_index":1181,"t":{"294":{"position":[[69,3]]},"304":{"position":[[120,3],[418,3]]},"306":{"position":[[238,3]]},"310":{"position":[[800,3],[1529,3]]},"403":{"position":[[193,3]]},"523":{"position":[[740,3]]},"662":{"position":[[341,3],[553,3]]},"789":{"position":[[61,3],[795,3]]},"791":{"position":[[7,3]]},"809":{"position":[[301,3],[664,3]]},"819":{"position":[[10,3]]},"823":{"position":[[153,3]]},"837":{"position":[[274,3]]},"839":{"position":[[8,3]]},"1067":{"position":[[120,3],[1308,3]]},"1093":{"position":[[372,3]]},"1101":{"position":[[588,3]]},"1172":{"position":[[0,3]]},"1384":{"position":[[1620,3],[3222,3]]},"1509":{"position":[[62,3],[144,3],[343,3]]},"1513":{"position":[[289,3]]},"1646":{"position":[[2383,3]]},"1651":{"position":[[81,3],[165,3],[209,3],[252,3]]},"1778":{"position":[[933,3]]}}}],["tydiqa",{"_index":1981,"t":{"539":{"position":[[390,6]]},"553":{"position":[[205,6]]},"555":{"position":[[102,6]]},"561":{"position":[[398,6]]}}}],["typ",{"_index":5344,"t":{"1665":{"position":[[772,3]]},"1669":{"position":[[104,3],[306,3],[835,3],[872,3],[1058,3]]}}}],["type",{"_index":109,"t":{"17":{"position":[[205,4]]},"78":{"position":[[716,5]]},"529":{"position":[[2012,4]]},"1045":{"position":[[24,4]]},"1291":{"position":[[1038,5]]},"1429":{"position":[[1749,4]]},"1440":{"position":[[721,4]]},"1595":{"position":[[376,5]]},"1606":{"position":[[178,5]]},"1638":{"position":[[178,5]]},"1644":{"position":[[675,6]]},"1646":{"position":[[2359,5],[2437,5],[2505,6],[3102,6]]},"1651":{"position":[[1453,5]]},"1653":{"position":[[767,6]]},"1655":{"position":[[268,6],[305,5],[662,4]]},"1659":{"position":[[112,6],[132,4],[328,5],[345,5]]},"1663":{"position":[[123,5]]},"1665":{"position":[[838,5]]},"1669":{"position":[[205,4],[289,4],[401,5],[921,6]]},"1672":{"position":[[68,5],[131,5],[153,5]]},"1674":{"position":[[7,6],[190,4],[663,4]]},"1676":{"position":[[262,6],[382,5],[509,4],[618,4]]},"1684":{"position":[[663,5],[678,5],[695,5],[804,6]]},"1689":{"position":[[289,6]]}}}],["typolog",{"_index":2008,"t":{"553":{"position":[[232,13]]}}}],["t})^3t0​:vt=vf​+(v0​−vf​)(1−n△tt−t0​​)3",{"_index":3155,"t":{"853":{"position":[[1990,39]]}}}],["t△t",{"_index":3158,"t":{"853":{"position":[[2170,3]]}}}],["u",{"_index":1974,"t":{"537":{"position":[[217,1]]},"550":{"position":[[10,1]]},"567":{"position":[[296,1],[656,1]]},"577":{"position":[[290,1]]}}}],["u,vu",{"_index":2735,"t":{"778":{"position":[[303,5]]}}}],["u/vu/vu/v",{"_index":2730,"t":{"778":{"position":[[140,9]]}}}],["u^{i\\top}_{a_{r=8",{"_index":2715,"t":{"774":{"position":[[574,19]]}}}],["u^{j}_{a_{r=64",{"_index":2716,"t":{"774":{"position":[[594,16]]}}}],["u_k",{"_index":4139,"t":{"1242":{"position":[[466,3],[671,4]]},"1244":{"position":[[374,4]]}}}],["u_t",{"_index":4195,"t":{"1246":{"position":[[725,4]]}}}],["u_{j=1}{a^}j=1u",{"_index":1636,"t":{"451":{"position":[[36,19]]}}}],["u_{j=1}{q^​j​,a^j​}j=1u",{"_index":1654,"t":{"455":{"position":[[725,27]]}}}],["uar=64u_{a_{r=64}}uar=64",{"_index":2705,"t":{"774":{"position":[[176,26],[308,26]]}}}],["uar=8i⊤u^{i\\top}_{a_{r=8}}uar=8​i",{"_index":2720,"t":{"774":{"position":[[713,35]]}}}],["uar=8u_{a_{r=8}}uar=8",{"_index":2704,"t":{"774":{"position":[[150,23],[211,23],[783,23]]}}}],["uber",{"_index":5200,"t":{"1653":{"position":[[469,6]]}}}],["ucf101",{"_index":1511,"t":{"374":{"position":[[131,6]]}}}],["uk",{"_index":4337,"t":{"1323":{"position":[[416,3]]}}}],["uku_kuk",{"_index":4151,"t":{"1244":{"position":[[631,8]]}}}],["uk∈rl,vk∈rdu_k",{"_index":4134,"t":{"1242":{"position":[[304,14]]}}}],["ul2",{"_index":1559,"t":{"397":{"position":[[95,3]]},"567":{"position":[[249,3],[623,3],[686,3]]}}}],["ul2r",{"_index":2045,"t":{"577":{"position":[[265,4]]}}}],["ultrici",{"_index":24,"t":{"3":{"position":[[210,10],[389,10],[568,10],[747,10],[926,10],[1105,10],[1284,10],[1463,10],[1642,10],[1821,10],[2000,10],[2179,10],[2358,10],[2537,10],[2716,10],[2895,10]]},"5":{"position":[[90,10]]}}}],["unansw",{"_index":5503,"t":{"1736":{"position":[[29,10]]}}}],["unanswer",{"_index":3641,"t":{"1049":{"position":[[228,12]]}}}],["unari",{"_index":5202,"t":{"1655":{"position":[[144,9],[198,5],[280,5],[343,5],[2083,5],[2208,5]]}}}],["unbalanc",{"_index":245,"t":{"47":{"position":[[112,10],[159,10]]}}}],["uncas",{"_index":3247,"t":{"866":{"position":[[32,7],[676,7],[807,7]]}}}],["uncertainli",{"_index":2976,"t":{"801":{"position":[[1556,11],[2304,11]]},"837":{"position":[[77,11]]}}}],["unclear",{"_index":4986,"t":{"1581":{"position":[[195,7]]}}}],["unconfid",{"_index":1449,"t":{"352":{"position":[[431,11]]}}}],["unconstrain",{"_index":5476,"t":{"1728":{"position":[[86,13]]}}}],["underli",{"_index":3468,"t":{"979":{"position":[[1350,10],[1872,10]]}}}],["underset{\\mu,\\theta_c}{\\arg\\max}\\log",{"_index":4401,"t":{"1352":{"position":[[1147,37]]}}}],["underset{\\phi}{\\arg",{"_index":4370,"t":{"1350":{"position":[[361,20],[687,20]]}}}],["underset{\\phi}{\\max",{"_index":4274,"t":{"1300":{"position":[[227,22],[275,21]]}}}],["underset{\\phi}{\\max}\\sum_{y_i}\\log",{"_index":5452,"t":{"1720":{"position":[[504,35]]}}}],["underset{\\theta_p",{"_index":4031,"t":{"1167":{"position":[[1356,19]]}}}],["underset{\\theta_p}{\\max",{"_index":4003,"t":{"1164":{"position":[[313,25]]}}}],["underset{c}{\\argmax",{"_index":1444,"t":{"350":{"position":[[901,21]]}}}],["underset{h}{\\text{arg",{"_index":3805,"t":{"1099":{"position":[[1998,23]]}}}],["underset{p_e}{\\arg",{"_index":4786,"t":{"1477":{"position":[[784,19]]}}}],["underset{p_{target",{"_index":3503,"t":{"986":{"position":[[433,21]]}}}],["underset{p}{\\max",{"_index":3492,"t":{"984":{"position":[[603,19]]}}}],["underset{z",{"_index":5425,"t":{"1704":{"position":[[511,11]]}}}],["underset{θ}{\\max",{"_index":3998,"t":{"1162":{"position":[[267,18]]}}}],["understad",{"_index":1725,"t":{"485":{"position":[[350,12],[492,12]]}}}],["understand",{"_index":960,"t":{"213":{"position":[[36,13]]},"412":{"position":[[94,13],[132,13]]},"485":{"position":[[240,13],[566,13]]},"488":{"position":[[5,13]]},"496":{"position":[[159,13]]},"498":{"position":[[163,13]]},"506":{"position":[[96,13]]},"512":{"position":[[10,13]]},"539":{"position":[[343,13]]},"589":{"position":[[695,14]]},"743":{"position":[[61,13]]},"895":{"position":[[1195,13]]},"932":{"position":[[778,13]]},"949":{"position":[[74,13],[630,13]]},"951":{"position":[[215,13]]},"955":{"position":[[176,13]]},"965":{"position":[[279,13]]},"969":{"position":[[336,13]]},"971":{"position":[[7,13]]},"973":{"position":[[446,13]]},"1012":{"position":[[142,13]]},"1091":{"position":[[50,13]]},"1093":{"position":[[293,13]]},"1145":{"position":[[2368,13]]},"1153":{"position":[[277,13]]},"1762":{"position":[[542,13],[572,13]]}}}],["undetstand",{"_index":3753,"t":{"1093":{"position":[[467,13]]}}}],["unembed",{"_index":4931,"t":{"1558":{"position":[[483,11]]}}}],["unext",{"_index":869,"t":{"174":{"position":[[2689,5]]}}}],["unfil",{"_index":5393,"t":{"1693":{"position":[[194,11]]}}}],["unfreez",{"_index":3428,"t":{"945":{"position":[[360,10]]}}}],["unfrozen",{"_index":3442,"t":{"949":{"position":[[532,8]]}}}],["unidirect",{"_index":3750,"t":{"1093":{"position":[[162,14],[541,14]]},"1107":{"position":[[728,14],[911,14]]},"1109":{"position":[[355,14],[432,15],[1258,14]]},"1111":{"position":[[1705,14]]},"1113":{"position":[[669,14]]}}}],["unieplt",{"_index":4511,"t":{"1389":{"position":[[390,7]]}}}],["unifi",{"_index":599,"t":{"130":{"position":[[337,7]]},"791":{"position":[[785,7]]},"1132":{"position":[[620,7]]},"1389":{"position":[[365,7]]},"1403":{"position":[[75,7]]}}}],["unifiedqav2",{"_index":1632,"t":{"445":{"position":[[449,11]]}}}],["uniform",{"_index":217,"t":{"35":{"position":[[97,7]]},"529":{"position":[[1018,8]]},"1151":{"position":[[1333,7]]},"1201":{"position":[[119,7],[315,7]]},"1513":{"position":[[333,7],[439,7]]},"1736":{"position":[[274,7]]}}}],["unifpelt",{"_index":4573,"t":{"1397":{"position":[[814,8]]}}}],["unilm",{"_index":3752,"t":{"1093":{"position":[[399,6]]}}}],["unimod",{"_index":1729,"t":{"488":{"position":[[111,8],[196,8]]},"490":{"position":[[20,8]]},"515":{"position":[[491,8]]}}}],["unimport",{"_index":2746,"t":{"784":{"position":[[643,11]]},"786":{"position":[[1201,11],[4316,11]]},"847":{"position":[[77,11]]},"849":{"position":[[230,11]]},"851":{"position":[[341,11]]}}}],["uninext",{"_index":723,"t":{"163":{"position":[[66,7]]},"165":{"position":[[1327,7],[2421,7],[2745,7]]},"168":{"position":[[514,7]]},"174":{"position":[[110,7]]},"177":{"position":[[55,7],[535,7],[726,7],[1058,7]]},"179":{"position":[[28,7]]},"185":{"position":[[0,7]]},"193":{"position":[[63,7]]},"197":{"position":[[32,7]]},"209":{"position":[[0,7],[81,7]]}}}],["unipelt",{"_index":4092,"t":{"1230":{"position":[[241,7]]},"1377":{"position":[[306,7],[426,7]]},"1379":{"position":[[671,7],[1129,7],[1271,7],[1688,7]]},"1384":{"position":[[3116,7]]},"1389":{"position":[[416,7],[454,7],[571,7],[2378,7]]},"1393":{"position":[[654,7],[741,7],[756,7]]},"1395":{"position":[[1107,7],[1130,7],[2066,7],[2542,7]]},"1397":{"position":[[26,7],[42,7],[212,7],[228,7],[386,7],[451,7],[473,7],[517,7],[572,7],[681,7],[716,7],[752,7],[830,7],[868,7],[949,7],[1002,8],[1176,7],[1332,7],[1476,7],[1560,8]]},"1399":{"position":[[169,7],[603,7]]},"1401":{"position":[[403,7],[463,7],[705,7],[726,7],[783,7]]},"1403":{"position":[[168,7],[179,7]]}}}],["uniqu",{"_index":3909,"t":{"1132":{"position":[[126,6]]}}}],["unit",{"_index":4071,"t":{"1210":{"position":[[155,4]]}}}],["unitari",{"_index":2703,"t":{"774":{"position":[[133,7]]}}}],["unitest",{"_index":4714,"t":{"1442":{"position":[[1012,8]]}}}],["unitext",{"_index":731,"t":{"163":{"position":[[577,7]]}}}],["univers",{"_index":720,"t":{"163":{"position":[[7,9]]},"165":{"position":[[2605,9]]},"1126":{"position":[[251,10]]}}}],["unixcod",{"_index":1726,"t":{"485":{"position":[[624,9]]}}}],["unlab",{"_index":1418,"t":{"343":{"position":[[62,9]]}}}],["unlabel",{"_index":968,"t":{"213":{"position":[[221,9],[358,9],[484,9]]},"215":{"position":[[291,9],[424,9]]},"347":{"position":[[155,9],[488,9]]},"352":{"position":[[55,9]]},"589":{"position":[[665,9]]},"594":{"position":[[132,9]]},"600":{"position":[[126,9]]},"608":{"position":[[760,9]]},"1111":{"position":[[580,9]]},"1667":{"position":[[246,9]]},"1736":{"position":[[579,9],[1185,9]]}}}],["unlikelihood",{"_index":2068,"t":{"589":{"position":[[1912,12]]},"602":{"position":[[268,12]]},"608":{"position":[[736,12]]},"620":{"position":[[173,12]]}}}],["unlock",{"_index":3424,"t":{"934":{"position":[[1858,9]]}}}],["unmask",{"_index":3776,"t":{"1099":{"position":[[449,8]]}}}],["unmatch",{"_index":1751,"t":{"500":{"position":[[836,11]]}}}],["unnatur",{"_index":3925,"t":{"1132":{"position":[[1043,11]]}}}],["unorun",{"_index":4835,"t":{"1489":{"position":[[26,9]]}}}],["unprun",{"_index":4836,"t":{"1489":{"position":[[117,8]]}}}],["unrealist",{"_index":2232,"t":{"618":{"position":[[225,15]]}}}],["unreleas",{"_index":5063,"t":{"1604":{"position":[[316,10]]}}}],["unseen",{"_index":937,"t":{"191":{"position":[[241,6]]},"537":{"position":[[40,6]]},"544":{"position":[[94,6]]},"546":{"position":[[45,6]]},"563":{"position":[[269,6]]},"565":{"position":[[122,6]]},"575":{"position":[[38,6]]},"587":{"position":[[119,6],[726,6]]},"589":{"position":[[1723,6]]},"594":{"position":[[1016,6]]},"1289":{"position":[[621,6]]},"1323":{"position":[[32,6],[255,6],[284,6]]},"1341":{"position":[[166,6]]}}}],["unstructur",{"_index":2751,"t":{"786":{"position":[[1283,12],[2290,12]]},"801":{"position":[[181,12]]},"881":{"position":[[0,12]]}}}],["unsupervis",{"_index":1389,"t":{"334":{"position":[[453,12],[496,12]]},"336":{"position":[[1740,12]]},"354":{"position":[[543,12]]},"378":{"position":[[5,12]]},"589":{"position":[[405,12]]},"658":{"position":[[56,12]]},"1419":{"position":[[120,12]]},"1423":{"position":[[526,12]]},"1695":{"position":[[1182,12]]}}}],["up",{"_index":173,"t":{"25":{"position":[[355,3]]},"35":{"position":[[35,2],[173,2]]},"42":{"position":[[40,2]]},"78":{"position":[[236,2],[660,2]]},"234":{"position":[[266,2]]},"372":{"position":[[78,2]]},"483":{"position":[[596,2]]},"803":{"position":[[497,2]]},"988":{"position":[[866,2]]},"1087":{"position":[[35,3]]},"1159":{"position":[[68,2]]},"1167":{"position":[[857,2]]},"1172":{"position":[[15,2]]},"1218":{"position":[[202,2]]},"1573":{"position":[[205,2]]}}}],["upcom",{"_index":5062,"t":{"1604":{"position":[[306,9]]}}}],["updat",{"_index":2050,"t":{"587":{"position":[[310,7]]},"589":{"position":[[1187,7],[1305,6],[1368,6]]},"598":{"position":[[3160,6],[3835,6]]},"612":{"position":[[8,8]]},"640":{"position":[[461,8]]},"644":{"position":[[23,8]]},"681":{"position":[[165,6]]},"721":{"position":[[296,6]]},"733":{"position":[[578,6]]},"772":{"position":[[100,6]]},"784":{"position":[[249,6],[338,7],[601,7],[655,6]]},"786":{"position":[[869,6],[986,6],[1168,7]]},"791":{"position":[[66,6]]},"795":{"position":[[42,6]]},"797":{"position":[[1245,6]]},"809":{"position":[[159,7],[697,7]]},"843":{"position":[[147,6]]},"853":{"position":[[1010,6]]},"945":{"position":[[147,6]]},"961":{"position":[[241,6]]},"963":{"position":[[181,8]]},"977":{"position":[[645,8]]},"1014":{"position":[[126,6],[866,7]]},"1062":{"position":[[1236,7]]},"1115":{"position":[[617,7]]},"1128":{"position":[[1023,6],[1232,6],[1422,6],[1971,6]]},"1145":{"position":[[576,6]]},"1185":{"position":[[714,6]]},"1225":{"position":[[492,7]]},"1227":{"position":[[1207,7]]},"1230":{"position":[[114,6]]},"1240":{"position":[[371,6]]},"1291":{"position":[[141,6],[1404,6]]},"1300":{"position":[[146,6]]},"1307":{"position":[[22,6]]},"1317":{"position":[[33,6],[162,6]]},"1341":{"position":[[963,6],[1020,6]]},"1395":{"position":[[3096,6]]},"1487":{"position":[[444,7]]},"1608":{"position":[[102,7],[157,7]]}}}],["upl",{"_index":1390,"t":{"334":{"position":[[482,5],[564,3],[643,3]]},"336":{"position":[[840,3],[947,3],[1722,3]]},"341":{"position":[[489,3]]},"343":{"position":[[398,3],[563,3]]},"345":{"position":[[0,3],[118,3]]},"347":{"position":[[26,3]]},"356":{"position":[[295,3]]},"366":{"position":[[30,3],[273,4],[334,4],[345,3]]},"376":{"position":[[133,3]]},"378":{"position":[[34,3]]}}}],["upper",{"_index":4572,"t":{"1397":{"position":[[728,5]]}}}],["upward",{"_index":1587,"t":{"426":{"position":[[326,6]]},"1303":{"position":[[837,6]]}}}],["upweight",{"_index":4509,"t":{"1387":{"position":[[224,12]]},"1389":{"position":[[525,12]]}}}],["upwork",{"_index":4929,"t":{"1556":{"position":[[0,6]]}}}],["urban",{"_index":1945,"t":{"531":{"position":[[346,5]]},"1659":{"position":[[201,7]]}}}],["url",{"_index":5011,"t":{"1587":{"position":[[177,4],[311,4]]},"1618":{"position":[[172,3]]},"1620":{"position":[[44,3]]}}}],["us",{"_index":5,"t":{"3":{"position":[[46,3]]},"7":{"position":[[446,3]]},"9":{"position":[[66,3]]},"17":{"position":[[31,5]]},"78":{"position":[[706,3]]},"457":{"position":[[247,4]]},"1367":{"position":[[403,5]]},"1620":{"position":[[38,5]]},"1622":{"position":[[47,3],[263,6],[317,5]]},"1626":{"position":[[82,3],[174,3]]},"1628":{"position":[[60,5]]},"1636":{"position":[[211,3]]},"1682":{"position":[[407,3]]}}}],["usag",{"_index":2206,"t":{"608":{"position":[[574,5]]},"616":{"position":[[19,5],[84,5],[212,5]]},"1060":{"position":[[424,5]]}}}],["user",{"_index":4347,"t":{"1337":{"position":[[55,4]]},"1552":{"position":[[294,4]]}}}],["utu_tut",{"_index":4197,"t":{"1246":{"position":[[775,9],[839,9]]}}}],["u‾(t)\\overline{u}^{(t)}u(t",{"_index":2991,"t":{"801":{"position":[[2192,27],[2364,27]]}}}],["u⊤wv⊤u^{\\top}wv^{\\top}u⊤wv",{"_index":2729,"t":{"778":{"position":[[93,27]]}}}],["u⊤wv⊤∣∣f||u^{\\top}wv^{\\top}||_f∣∣u⊤wv⊤∣∣f",{"_index":2732,"t":{"778":{"position":[[212,44],[371,44]]}}}],["v",{"_index":239,"t":{"38":{"position":[[463,1]]},"298":{"position":[[456,2]]},"358":{"position":[[457,3]]},"598":{"position":[[1684,2]]},"857":{"position":[[1125,3]]},"1589":{"position":[[286,1]]}}}],["v%v\\%v",{"_index":3177,"t":{"857":{"position":[[253,7]]},"873":{"position":[[268,7]]}}}],["v(⋅)l=r(s(⋅)l)l∑l′=1lr(s(⋅)l′)v\\begin{equ",{"_index":3187,"t":{"857":{"position":[[970,47]]}}}],["v(⋅)lv^l_{(\\cdot)}v(⋅)l",{"_index":3186,"t":{"857":{"position":[[916,24]]}}}],["v.",{"_index":3849,"t":{"1109":{"position":[[279,4]]}}}],["v0v_0v0",{"_index":2324,"t":{"658":{"position":[[2067,8]]},"853":{"position":[[2082,8]]}}}],["v1.0",{"_index":1933,"t":{"529":{"position":[[2640,4]]}}}],["v1.1",{"_index":2416,"t":{"674":{"position":[[63,4]]},"887":{"position":[[1374,4]]},"926":{"position":[[61,4]]}}}],["v100",{"_index":2545,"t":{"705":{"position":[[69,4]]},"807":{"position":[[92,4]]},"1314":{"position":[[531,4]]}}}],["v2",{"_index":2540,"t":{"703":{"position":[[149,2]]},"707":{"position":[[150,2],[600,2]]},"901":{"position":[[72,2],[139,2]]},"926":{"position":[[114,2]]},"932":{"position":[[189,2],[839,2]]},"934":{"position":[[557,2],[1382,2],[2113,2]]},"942":{"position":[[213,2]]},"945":{"position":[[526,2],[952,2]]},"949":{"position":[[22,2],[119,2]]},"951":{"position":[[371,2]]},"953":{"position":[[299,2]]},"955":{"position":[[91,2]]},"959":{"position":[[14,2]]},"963":{"position":[[64,2],[139,2],[542,2]]},"965":{"position":[[100,2],[218,2]]},"967":{"position":[[377,2],[514,2],[586,2]]},"971":{"position":[[141,2]]},"973":{"position":[[76,2]]},"1012":{"position":[[466,2],[562,2]]},"1014":{"position":[[1449,2]]},"1026":{"position":[[410,2]]},"1028":{"position":[[260,2],[357,2]]},"1033":{"position":[[25,2]]},"1035":{"position":[[114,2]]},"1037":{"position":[[115,2],[197,2]]},"1039":{"position":[[9,2]]},"1041":{"position":[[9,2]]},"1047":{"position":[[19,2],[141,2],[366,2]]},"1049":{"position":[[24,3],[358,2]]},"1052":{"position":[[98,2]]},"1054":{"position":[[35,2]]},"1056":{"position":[[9,2],[155,2]]},"1111":{"position":[[1845,2]]}}}],["v2.0",{"_index":3290,"t":{"887":{"position":[[1381,4]]},"926":{"position":[[68,4]]}}}],["v[𝙼]1={‘‘person’’,‘‘organization’’,…},v[𝙼]2={‘‘’s’’,‘‘was’’,…},v[𝙼]3={‘‘parent’’,‘‘born’’,…},l[𝙼]4={‘‘was’’,‘‘in’’,…},l[𝙼]5={‘‘person’’,‘‘organization’’,…}.\\begin{equ",{"_index":5268,"t":{"1657":{"position":[[1145,177]]}}}],["v[𝙼]\\mathcal{v}_{[𝙼]}v[m",{"_index":5292,"t":{"1657":{"position":[[2408,28]]}}}],["v\\mathcal{v}v",{"_index":3617,"t":{"1019":{"position":[[32,13]]},"1099":{"position":[[909,14],[1763,13]]}}}],["v\\subset",{"_index":3618,"t":{"1019":{"position":[[147,9]]}}}],["v]vnew​=[pv​,v",{"_index":2492,"t":{"688":{"position":[[920,15]]}}}],["v^l_{(\\cdot",{"_index":3188,"t":{"857":{"position":[[1018,13]]}}}],["v^t",{"_index":3150,"t":{"853":{"position":[[1938,3]]}}}],["v^{1",{"_index":1853,"t":{"527":{"position":[[1264,5]]}}}],["v^{m",{"_index":1848,"t":{"527":{"position":[[880,5],[1307,5]]}}}],["v_0",{"_index":3152,"t":{"853":{"position":[[1950,4]]}}}],["v_0}(x",{"_index":2326,"t":{"658":{"position":[[2137,7]]}}}],["v_c",{"_index":1482,"t":{"358":{"position":[[778,3]]},"360":{"position":[[72,3]]}}}],["v_f",{"_index":3151,"t":{"853":{"position":[[1944,3],[1957,4]]},"861":{"position":[[211,3],[217,3],[250,3]]}}}],["v_fvt​=vf",{"_index":3216,"t":{"861":{"position":[[443,10]]}}}],["v_k",{"_index":4136,"t":{"1242":{"position":[[337,3]]}}}],["v_k^t",{"_index":4144,"t":{"1242":{"position":[[687,6]]}}}],["v_k^t)p^k​=p∗∘(uk​⨂vkt",{"_index":4150,"t":{"1244":{"position":[[390,24]]}}}],["v_k^twk​=uk​⨂vkt",{"_index":4141,"t":{"1242":{"position":[[481,17]]}}}],["v_l",{"_index":3324,"t":{"893":{"position":[[643,3],[2346,4]]}}}],["v_t",{"_index":3211,"t":{"861":{"position":[[183,3]]}}}],["v_t^t)p^t​=p∗∘(ut​⨂vtt",{"_index":4196,"t":{"1246":{"position":[[741,24]]}}}],["v_{new",{"_index":2477,"t":{"688":{"position":[[482,7]]}}}],["val2017",{"_index":907,"t":{"185":{"position":[[15,7]]}}}],["valid",{"_index":1115,"t":{"249":{"position":[[85,11]]},"464":{"position":[[88,10]]},"529":{"position":[[502,10]]},"594":{"position":[[982,10],[1428,10]]},"602":{"position":[[735,10]]},"618":{"position":[[152,10],[247,10]]},"666":{"position":[[417,10]]},"668":{"position":[[457,10]]},"672":{"position":[[788,10],[906,10]]},"674":{"position":[[89,10]]},"676":{"position":[[74,10]]},"1357":{"position":[[180,10]]},"1417":{"position":[[90,10]]},"1421":{"position":[[650,10]]},"1427":{"position":[[390,10]]},"1492":{"position":[[209,10]]},"1669":{"position":[[642,10]]}}}],["valu",{"_index":256,"t":{"49":{"position":[[230,5]]},"232":{"position":[[555,5]]},"296":{"position":[[33,5],[81,5],[124,6],[133,5]]},"298":{"position":[[132,6],[228,6],[320,6],[966,6],[1107,6]]},"300":{"position":[[48,7],[201,6],[279,6],[351,6]]},"302":{"position":[[143,5],[401,6]]},"319":{"position":[[287,5]]},"324":{"position":[[198,5]]},"527":{"position":[[599,5]]},"529":{"position":[[1342,6],[1371,6]]},"531":{"position":[[1161,6]]},"598":{"position":[[1271,5]]},"610":{"position":[[383,5]]},"633":{"position":[[841,5]]},"658":{"position":[[780,6]]},"670":{"position":[[412,5]]},"679":{"position":[[514,5]]},"681":{"position":[[1367,5],[1470,5],[1923,5]]},"683":{"position":[[1163,5]]},"688":{"position":[[71,5],[593,5],[1014,5],[1057,5],[1119,5]]},"690":{"position":[[80,5],[98,5],[133,5],[161,5],[235,5],[333,5],[376,5],[407,5],[456,5],[509,5],[589,5],[633,5],[666,5],[703,5],[729,5],[813,5],[855,5]]},"692":{"position":[[259,5]]},"696":{"position":[[468,5],[717,5],[785,5],[864,5],[980,5],[1107,5],[1199,5]]},"705":{"position":[[199,5],[272,5]]},"709":{"position":[[722,5],[755,5],[942,5],[1069,5],[2012,5],[2101,5]]},"711":{"position":[[96,5],[146,5]]},"774":{"position":[[87,5]]},"776":{"position":[[214,5]]},"784":{"position":[[558,5],[673,5]]},"786":{"position":[[3753,5],[4072,6],[4337,6]]},"789":{"position":[[707,5]]},"791":{"position":[[751,5]]},"793":{"position":[[75,5],[188,6]]},"795":{"position":[[60,5],[432,6],[573,5],[1214,6],[1774,6],[1915,6]]},"797":{"position":[[193,6],[1655,6],[2406,6],[2446,6]]},"799":{"position":[[123,6]]},"801":{"position":[[399,5]]},"803":{"position":[[132,6]]},"807":{"position":[[488,6]]},"809":{"position":[[839,5]]},"814":{"position":[[587,5]]},"843":{"position":[[165,5],[250,6]]},"849":{"position":[[486,5],[552,5],[572,5],[654,5]]},"851":{"position":[[505,5]]},"853":{"position":[[443,5],[1186,6],[1760,5],[2320,5],[2410,5]]},"855":{"position":[[820,5]]},"893":{"position":[[431,6]]},"1141":{"position":[[19,5]]},"1352":{"position":[[1029,5],[1307,5]]},"1354":{"position":[[284,5]]},"1384":{"position":[[1605,5]]},"1440":{"position":[[405,5]]},"1442":{"position":[[1150,5]]},"1449":{"position":[[187,5]]},"1485":{"position":[[327,5]]},"1487":{"position":[[736,5]]},"1489":{"position":[[309,5],[345,6]]},"1558":{"position":[[1177,5]]},"1573":{"position":[[60,5]]}}}],["valuabl",{"_index":4740,"t":{"1451":{"position":[[49,8]]}}}],["valuy",{"_index":1203,"t":{"298":{"position":[[1017,7]]}}}],["vanila",{"_index":5369,"t":{"1674":{"position":[[20,6]]}}}],["vanilia",{"_index":5333,"t":{"1665":{"position":[[316,7]]}}}],["vanilla",{"_index":2290,"t":{"633":{"position":[[610,7]]},"638":{"position":[[41,7]]},"644":{"position":[[162,7],[297,7]]},"648":{"position":[[215,7]]},"703":{"position":[[86,7]]},"887":{"position":[[499,7]]},"893":{"position":[[145,7]]},"1060":{"position":[[960,7]]},"1062":{"position":[[1415,7]]},"1067":{"position":[[1279,7]]},"1070":{"position":[[474,7],[931,7]]},"1073":{"position":[[114,7]]},"1075":{"position":[[32,7]]},"1080":{"position":[[337,7]]},"1082":{"position":[[161,7],[252,7]]},"1084":{"position":[[19,7],[514,7],[665,7],[689,7]]},"1087":{"position":[[19,7]]},"1227":{"position":[[1329,7]]},"1238":{"position":[[1073,7]]},"1246":{"position":[[110,7]]},"1248":{"position":[[10,7]]},"1257":{"position":[[111,7]]},"1264":{"position":[[219,7]]},"1415":{"position":[[61,7]]},"1423":{"position":[[192,7]]},"1494":{"position":[[190,7]]},"1499":{"position":[[210,7]]},"1505":{"position":[[138,7],[654,7]]},"1509":{"position":[[166,7]]},"1644":{"position":[[771,7]]},"1646":{"position":[[3200,7]]},"1667":{"position":[[175,7],[343,7]]},"1676":{"position":[[90,7],[222,7]]},"1682":{"position":[[387,7]]},"1684":{"position":[[93,7]]},"1689":{"position":[[408,7]]}}}],["variabl",{"_index":1275,"t":{"310":{"position":[[27,8]]},"405":{"position":[[170,8]]},"670":{"position":[[1188,8],[1434,8],[1492,8]]},"1006":{"position":[[1523,8]]},"1485":{"position":[[98,8],[457,9]]},"1487":{"position":[[545,8]]},"1655":{"position":[[2246,8]]}}}],["varianc",{"_index":3952,"t":{"1143":{"position":[[961,8],[996,8]]},"1332":{"position":[[112,8]]},"1393":{"position":[[495,8]]},"1395":{"position":[[1586,8],[2662,8]]}}}],["variant",{"_index":2565,"t":{"709":{"position":[[2289,8]]},"801":{"position":[[2705,7]]},"837":{"position":[[126,8],[278,8]]}}}],["variat",{"_index":2866,"t":{"795":{"position":[[1968,9]]},"801":{"position":[[2278,9]]}}}],["varrho",{"_index":464,"t":{"91":{"position":[[2051,7],[2345,7]]}}}],["vaswani",{"_index":2157,"t":{"598":{"position":[[1499,7]]}}}],["vc=[v,wc],(3)v_c",{"_index":1475,"t":{"358":{"position":[[438,16]]}}}],["vc}c=1c",{"_index":1481,"t":{"358":{"position":[[767,10]]},"360":{"position":[[61,10]]}}}],["vc∈rd×(l+1)v_c",{"_index":1473,"t":{"358":{"position":[[368,14]]}}}],["vecotr",{"_index":2177,"t":{"598":{"position":[[2298,7]]},"1244":{"position":[[487,7]]},"1248":{"position":[[99,7]]}}}],["vector",{"_index":422,"t":{"91":{"position":[[471,6],[606,6],[623,6],[1286,6]]},"108":{"position":[[90,6]]},"213":{"position":[[204,7]]},"215":{"position":[[1070,8]]},"296":{"position":[[92,6]]},"306":{"position":[[87,6]]},"447":{"position":[[336,6]]},"525":{"position":[[1228,6],[1249,6]]},"527":{"position":[[368,7],[2379,7],[2526,7]]},"529":{"position":[[1219,6]]},"587":{"position":[[493,6]]},"589":{"position":[[2002,7]]},"598":{"position":[[476,7],[738,6],[887,6],[1188,6],[1289,6],[1373,6],[1960,6],[2519,6],[3602,7]]},"610":{"position":[[389,7]]},"614":{"position":[[339,7]]},"622":{"position":[[171,7]]},"630":{"position":[[1323,7],[1381,6]]},"633":{"position":[[877,7]]},"658":{"position":[[797,6],[832,6]]},"686":{"position":[[392,6]]},"694":{"position":[[67,6]]},"733":{"position":[[695,7]]},"749":{"position":[[5,7]]},"774":{"position":[[282,7],[385,7],[768,7]]},"778":{"position":[[190,6],[339,7]]},"786":{"position":[[4156,7],[4364,7]]},"795":{"position":[[349,7],[581,7],[739,6],[1803,7]]},"801":{"position":[[407,7]]},"809":{"position":[[239,7]]},"977":{"position":[[116,7]]},"1060":{"position":[[38,7]]},"1062":{"position":[[280,6]]},"1070":{"position":[[501,7]]},"1151":{"position":[[356,6],[1097,6]]},"1225":{"position":[[72,6],[191,7]]},"1227":{"position":[[297,7],[417,7],[555,7]]},"1230":{"position":[[167,7]]},"1238":{"position":[[439,7]]},"1242":{"position":[[403,7],[425,7]]},"1244":{"position":[[1763,6]]},"1255":{"position":[[119,7]]},"1257":{"position":[[154,7]]},"1259":{"position":[[281,6]]},"1270":{"position":[[273,6]]},"1277":{"position":[[34,7]]},"1279":{"position":[[106,7],[135,7]]},"1289":{"position":[[321,7]]},"1291":{"position":[[1167,7]]},"1296":{"position":[[338,6],[570,6]]},"1341":{"position":[[636,7]]},"1384":{"position":[[1184,7],[1252,7]]},"1389":{"position":[[1757,7]]},"1442":{"position":[[1234,6]]},"1462":{"position":[[216,6]]},"1485":{"position":[[75,6]]},"1487":{"position":[[290,6]]},"1494":{"position":[[578,6]]},"1702":{"position":[[783,7]]},"1720":{"position":[[357,6]]}}}],["vec{1}+\\delta))]_j",{"_index":4416,"t":{"1354":{"position":[[480,21]]}}}],["verb",{"_index":1642,"t":{"453":{"position":[[142,4]]}}}],["verbal",{"_index":3635,"t":{"1037":{"position":[[0,11]]},"1052":{"position":[[20,10],[354,10]]},"1130":{"position":[[439,13]]},"1442":{"position":[[371,6],[1908,8]]},"1445":{"position":[[190,6]]},"1451":{"position":[[77,6]]},"1455":{"position":[[435,6]]},"1730":{"position":[[681,10]]}}}],["veri",{"_index":1,"t":{"3":{"position":[[25,4]]},"78":{"position":[[33,4]]},"310":{"position":[[1108,4]]},"523":{"position":[[428,4]]},"698":{"position":[[24,4]]},"870":{"position":[[1682,4]]},"1600":{"position":[[180,4]]}}}],["verifi",{"_index":1568,"t":{"409":{"position":[[167,9]]}}}],["versatil",{"_index":2614,"t":{"727":{"position":[[129,9]]}}}],["version",{"_index":89,"t":{"15":{"position":[[8,7]]},"1134":{"position":[[189,7]]},"1581":{"position":[[165,10]]},"1591":{"position":[[84,10]]},"1602":{"position":[[31,8]]},"1604":{"position":[[10,7],[184,9],[237,7]]},"1606":{"position":[[30,9],[46,7],[231,7]]},"1608":{"position":[[23,9]]}}}],["versioned_docs/vers",{"_index":5058,"t":{"1604":{"position":[[106,22]]},"1608":{"position":[[66,22]]}}}],["versions.json",{"_index":5059,"t":{"1604":{"position":[[137,13]]}}}],["vf\\mathcal{v}_fvf",{"_index":5180,"t":{"1651":{"position":[[830,18]]}}}],["vfv_fvf",{"_index":3156,"t":{"853":{"position":[[2093,8]]},"861":{"position":[[377,8],[1222,8],[1577,8]]}}}],["vi",{"_index":737,"t":{"165":{"position":[[287,5],[1479,4]]},"168":{"position":[[128,3]]},"174":{"position":[[1435,3]]},"197":{"position":[[8,3]]},"201":{"position":[[92,3]]},"203":{"position":[[364,3]]},"205":{"position":[[85,3]]}}}],["via",{"_index":2615,"t":{"727":{"position":[[165,3]]},"1427":{"position":[[616,3]]},"1431":{"position":[[2322,3]]}}}],["video",{"_index":734,"t":{"163":{"position":[[731,5]]},"165":{"position":[[259,5],[481,5],[607,5]]},"177":{"position":[[965,5],[1040,5]]},"339":{"position":[[616,5]]},"940":{"position":[[35,5]]}}}],["view",{"_index":12,"t":{"3":{"position":[[114,5]]},"19":{"position":[[331,4]]},"215":{"position":[[1913,4],[1979,4]]},"791":{"position":[[793,4]]}}}],["violenc",{"_index":5574,"t":{"1778":{"position":[[401,9]]}}}],["violent",{"_index":4974,"t":{"1573":{"position":[[191,8]]}}}],["virtual",{"_index":2457,"t":{"683":{"position":[[851,7]]},"1065":{"position":[[420,7]]},"1070":{"position":[[836,7],[1015,7]]},"1164":{"position":[[56,7]]},"1167":{"position":[[106,7]]},"1176":{"position":[[6,7]]},"1289":{"position":[[410,8]]},"1291":{"position":[[1284,8]]},"1328":{"position":[[0,8]]},"1720":{"position":[[2429,7]]}}}],["vis19",{"_index":895,"t":{"177":{"position":[[1293,6]]}}}],["vision",{"_index":375,"t":{"84":{"position":[[59,6],[125,6]]},"124":{"position":[[44,6],[74,6],[138,6]]},"126":{"position":[[317,6],[351,6],[585,6],[873,6]]},"128":{"position":[[13,6]]},"132":{"position":[[348,6]]},"143":{"position":[[255,6]]},"159":{"position":[[89,6],[193,6]]},"163":{"position":[[652,6]]},"172":{"position":[[703,6]]},"219":{"position":[[3,6],[90,6],[271,6]]},"221":{"position":[[74,6],[514,7],[571,6],[612,6],[670,6],[686,6]]},"225":{"position":[[59,6],[388,6],[467,6],[771,6]]},"227":{"position":[[61,6],[248,6],[297,6]]},"230":{"position":[[369,6]]},"232":{"position":[[217,6]]},"234":{"position":[[43,6],[457,6],[479,6]]},"236":{"position":[[235,6]]},"239":{"position":[[75,6]]},"253":{"position":[[417,6]]},"334":{"position":[[298,6]]},"339":{"position":[[141,6],[319,6],[363,6]]},"358":{"position":[[702,6]]},"366":{"position":[[76,6],[242,6]]},"436":{"position":[[18,6],[496,6],[608,6],[667,6],[820,6],[1392,6]]},"468":{"position":[[238,6]]},"531":{"position":[[1502,6]]},"887":{"position":[[1178,6]]},"895":{"position":[[1123,6]]},"897":{"position":[[83,6]]},"934":{"position":[[728,6],[1034,6]]},"953":{"position":[[0,6]]},"965":{"position":[[58,6],[170,6]]},"969":{"position":[[329,6]]},"1060":{"position":[[1038,6]]}}}],["visual",{"_index":590,"t":{"126":{"position":[[279,6]]},"153":{"position":[[742,6]]},"165":{"position":[[1923,6]]},"170":{"position":[[546,6],[611,6],[1002,6]]},"172":{"position":[[31,6],[102,6],[182,6]]},"174":{"position":[[5,6],[1150,6]]},"177":{"position":[[1362,6]]},"182":{"position":[[57,6]]},"203":{"position":[[0,6]]},"221":{"position":[[110,6],[868,6]]},"225":{"position":[[665,6]]},"236":{"position":[[520,6]]},"242":{"position":[[20,6]]},"249":{"position":[[113,6]]},"330":{"position":[[10,14]]},"334":{"position":[[12,6]]},"336":{"position":[[21,6]]},"339":{"position":[[30,6]]},"350":{"position":[[415,6]]},"354":{"position":[[11,6]]},"358":{"position":[[722,6]]},"360":{"position":[[206,6]]},"434":{"position":[[65,6]]},"436":{"position":[[1949,6]]},"443":{"position":[[57,6],[202,6],[352,6],[436,6]]},"447":{"position":[[94,6]]},"457":{"position":[[1423,6]]},"895":{"position":[[143,6],[193,6],[1063,6]]},"912":{"position":[[72,6]]},"932":{"position":[[26,6],[71,6],[148,6],[326,6],[385,6]]},"934":{"position":[[406,6],[475,6],[607,6],[650,6],[869,6],[1002,6],[1071,6],[1259,6],[1303,6],[1397,6],[1723,6],[2324,6]]},"940":{"position":[[59,6],[99,6],[151,6],[210,6],[301,6]]},"942":{"position":[[62,6],[113,6]]},"947":{"position":[[80,6]]},"949":{"position":[[399,6]]},"953":{"position":[[45,6],[134,6],[163,6],[211,6],[312,6],[492,6]]},"955":{"position":[[22,6],[346,6],[437,6],[503,6],[525,6]]},"959":{"position":[[140,6]]},"961":{"position":[[104,6]]},"967":{"position":[[41,6],[449,6]]},"969":{"position":[[96,6]]},"971":{"position":[[0,6],[41,6],[160,6]]},"973":{"position":[[26,6],[181,6],[221,6],[512,6]]},"1070":{"position":[[294,6],[1364,6],[1428,6],[1468,6]]},"1720":{"position":[[1250,6],[1270,6]]}}}],["visualtextu",{"_index":3368,"t":{"895":{"position":[[100,13]]},"912":{"position":[[244,13]]}}}],["vit",{"_index":169,"t":{"25":{"position":[[198,3],[733,3]]},"60":{"position":[[31,3]]},"84":{"position":[[144,5]]},"88":{"position":[[301,3]]},"93":{"position":[[34,3]]},"97":{"position":[[6,3],[443,3]]},"99":{"position":[[8,4]]},"104":{"position":[[43,3],[104,3],[396,3]]},"106":{"position":[[176,3],[192,3]]},"110":{"position":[[0,3],[11,3]]},"112":{"position":[[533,3]]},"114":{"position":[[158,3],[301,3],[355,3],[399,3],[414,3]]},"116":{"position":[[0,3],[294,3],[382,3]]},"118":{"position":[[55,3],[100,3],[129,3]]},"120":{"position":[[186,3],[257,3]]},"143":{"position":[[274,4]]},"182":{"position":[[46,3]]},"230":{"position":[[128,3]]},"239":{"position":[[237,3],[282,3]]},"253":{"position":[[359,3],[367,3]]},"339":{"position":[[388,3]]},"354":{"position":[[94,3],[104,3],[114,3]]},"366":{"position":[[201,3],[211,3],[222,3]]},"885":{"position":[[609,5]]},"887":{"position":[[1293,3]]},"899":{"position":[[12,3],[143,3]]},"924":{"position":[[62,3]]}}}],["vit/deit",{"_index":339,"t":{"65":{"position":[[81,8]]}}}],["viusal",{"_index":837,"t":{"174":{"position":[[247,6]]}}}],["vkv_kvk",{"_index":4152,"t":{"1244":{"position":[[642,8]]}}}],["vl",{"_index":1693,"t":{"468":{"position":[[92,2]]},"1060":{"position":[[1054,4]]},"1062":{"position":[[1336,2],[1687,2]]},"1070":{"position":[[284,2],[1205,2]]},"1077":{"position":[[5,2]]}}}],["vl=linearv",{"_index":3319,"t":{"893":{"position":[[511,13]]}}}],["vlkd",{"_index":1694,"t":{"468":{"position":[[109,4]]}}}],["vlm",{"_index":1081,"t":{"236":{"position":[[421,4]]},"249":{"position":[[152,4]]},"334":{"position":[[320,6],[389,3]]},"336":{"position":[[886,3],[1287,3],[1711,3],[1734,3]]},"339":{"position":[[0,3],[313,3]]},"341":{"position":[[11,3],[495,3]]},"343":{"position":[[327,3]]},"347":{"position":[[116,3],[266,3]]},"468":{"position":[[103,3]]}}}],["vl​=linearv",{"_index":3329,"t":{"893":{"position":[[749,15]]}}}],["vnew=[pv,v]v_{new",{"_index":2490,"t":{"688":{"position":[[893,18]]}}}],["vnewv_{new}vnew",{"_index":2481,"t":{"688":{"position":[[557,16]]}}}],["vo",{"_index":740,"t":{"165":{"position":[[510,4],[633,5],[1538,4],[1580,4]]},"168":{"position":[[208,3],[269,3]]},"177":{"position":[[1270,5],[1310,3],[1327,4]]},"191":{"position":[[0,3],[27,3],[191,3]]},"199":{"position":[[12,3],[34,3],[81,3]]},"201":{"position":[[61,4],[78,3]]}}}],["vocab",{"_index":3943,"t":{"1141":{"position":[[592,5]]},"1147":{"position":[[136,5]]},"1151":{"position":[[1352,5]]}}}],["vocabulari",{"_index":623,"t":{"130":{"position":[[1599,10]]},"143":{"position":[[558,10]]},"163":{"position":[[424,12]]},"165":{"position":[[1077,12]]},"174":{"position":[[2650,12]]},"313":{"position":[[139,10],[239,10]]},"326":{"position":[[494,10],[555,10]]},"531":{"position":[[1315,10]]},"999":{"position":[[84,12],[1096,12],[1176,12]]},"1019":{"position":[[19,10]]},"1065":{"position":[[485,12]]},"1070":{"position":[[515,12]]},"1099":{"position":[[896,10],[1752,10]]},"1107":{"position":[[160,10],[190,10]]},"1128":{"position":[[1085,10]]},"1130":{"position":[[116,10]]},"1141":{"position":[[166,10],[220,10],[262,10]]},"1151":{"position":[[295,10],[335,10]]},"1201":{"position":[[348,10]]},"1257":{"position":[[168,12]]},"1296":{"position":[[1024,10]]},"1421":{"position":[[584,10]]},"1473":{"position":[[158,13]]},"1496":{"position":[[313,10]]},"1513":{"position":[[351,10],[395,10]]},"1669":{"position":[[33,10]]},"1724":{"position":[[68,10],[98,10]]},"1730":{"position":[[998,10]]},"1766":{"position":[[629,10]]}}}],["vocalbulari",{"_index":4065,"t":{"1201":{"position":[[78,11]]}}}],["vote",{"_index":3970,"t":{"1149":{"position":[[665,6]]},"1736":{"position":[[974,6]]}}}],["vpt",{"_index":3409,"t":{"926":{"position":[[15,3]]}}}],["vq2^22a",{"_index":1698,"t":{"468":{"position":[[289,7]]}}}],["vqa",{"_index":1110,"t":{"246":{"position":[[172,3]]},"271":{"position":[[74,4]]},"434":{"position":[[91,5],[134,3],[315,3],[630,3],[840,3]]},"436":{"position":[[0,3],[47,3],[142,3],[261,3],[288,3],[440,3],[463,3],[917,3],[990,3],[1307,3],[1818,3],[2012,3],[2128,3],[2264,3],[2326,3]]},"439":{"position":[[0,3],[108,3],[171,3]]},"441":{"position":[[364,3],[428,3]]},"447":{"position":[[16,3],[227,3],[296,3],[922,3]]},"449":{"position":[[0,3]]},"451":{"position":[[234,3]]},"455":{"position":[[22,3],[863,3],[1018,3]]},"461":{"position":[[24,3]]},"464":{"position":[[46,3]]},"466":{"position":[[485,3]]},"468":{"position":[[3,3]]},"471":{"position":[[57,3],[141,3]]},"473":{"position":[[39,3],[144,3],[241,3]]},"477":{"position":[[96,3]]},"914":{"position":[[16,3]]},"1070":{"position":[[325,3]]},"1077":{"position":[[14,4],[60,3]]}}}],["vqav2",{"_index":1116,"t":{"249":{"position":[[97,5]]},"255":{"position":[[166,5]]},"434":{"position":[[553,5]]},"436":{"position":[[2282,5]]},"464":{"position":[[0,5]]},"475":{"position":[[71,5]]}}}],["vram",{"_index":2649,"t":{"741":{"position":[[152,4],[177,4]]}}}],["vri",{"_index":2353,"t":{"662":{"position":[[1422,5]]}}}],["vs",{"_index":1826,"t":{"525":{"position":[[690,3],[834,3]]},"1002":{"position":[[63,3]]},"1227":{"position":[[1443,2]]},"1397":{"position":[[724,3],[1557,2]]},"1570":{"position":[[329,2]]},"1768":{"position":[[240,2]]}}}],["vt=vfv_t",{"_index":3215,"t":{"861":{"position":[[432,8]]}}}],["vt={vf−vf(1−tn)3t<nvfo.w.\\begin{equ",{"_index":3210,"t":{"861":{"position":[[141,41]]}}}],["vtab",{"_index":504,"t":{"102":{"position":[[235,4]]},"110":{"position":[[158,4]]},"887":{"position":[[1330,4]]},"899":{"position":[[179,4]]},"924":{"position":[[85,4]]}}}],["vtav",{"_index":502,"t":{"102":{"position":[[219,4]]}}}],["vtv_tvt",{"_index":3209,"t":{"861":{"position":[[122,8],[1211,8],[1566,8]]},"1246":{"position":[[785,8],[849,8]]}}}],["vu",{"_index":4437,"t":{"1367":{"position":[[596,3]]},"1473":{"position":[[367,3]]}}}],["vu,v",{"_index":2736,"t":{"778":{"position":[[309,4]]}}}],["vvv",{"_index":1193,"t":{"298":{"position":[[343,3]]},"358":{"position":[[594,3],[1405,3]]},"360":{"position":[[22,3]]},"457":{"position":[[580,3]]},"658":{"position":[[1863,3],[2186,3]]},"853":{"position":[[511,3],[1885,3]]},"1384":{"position":[[1611,3],[1734,3]]},"1389":{"position":[[1721,4]]}}}],["vw^v_i",{"_index":1222,"t":{"300":{"position":[[812,7]]}}}],["v∈rd×lv",{"_index":1465,"t":{"358":{"position":[[120,7]]}}}],["v∣≪∣w∣|v",{"_index":2331,"t":{"658":{"position":[[2300,10]]}}}],["w",{"_index":237,"t":{"38":{"position":[[452,1]]},"91":{"position":[[154,1]]},"227":{"position":[[539,1],[586,2]]},"598":{"position":[[2868,1],[2883,2]]},"733":{"position":[[368,1],[654,1],[917,1]]},"786":{"position":[[1688,1]]},"795":{"position":[[133,1]]},"945":{"position":[[595,1],[636,2]]},"1067":{"position":[[760,1]]}}}],["w'_i",{"_index":3686,"t":{"1067":{"position":[[544,4],[895,6]]}}}],["w'_{i,j",{"_index":3167,"t":{"855":{"position":[[602,9]]}}}],["w'_{i,j}}−∂wi,j′​∂l",{"_index":3173,"t":{"855":{"position":[[769,20]]}}}],["w(0)w^{(0)}w(0",{"_index":2749,"t":{"786":{"position":[[943,15],[1056,15],[1762,16]]},"791":{"position":[[255,16]]}}}],["w(x)\\phi_w(x)ϕw​(x",{"_index":2320,"t":{"658":{"position":[[1665,20],[1719,20]]}}}],["w(⋅)lw^l_{(\\cdot)}w(⋅)l",{"_index":3199,"t":{"857":{"position":[[1347,24]]}}}],["w(⋅){\\color{blue}{w^{(\\cdot)}}}w",{"_index":1888,"t":{"527":{"position":[[2759,35]]}}}],["w(⋅)ℓ,(⋅){\\color{blue}{w^{\\ell,(\\cdot)}_{(\\cdot)}}}w",{"_index":1878,"t":{"527":{"position":[[2315,61]]}}}],["w)(h,w",{"_index":414,"t":{"91":{"position":[[297,7]]}}}],["w,v(x)\\psi_{w,v}(x)ψw,v​(x",{"_index":2323,"t":{"658":{"position":[[1982,28]]}}}],["w,v0(x)≈ϕw(x)\\psi_{w",{"_index":2325,"t":{"658":{"position":[[2114,22]]}}}],["w,v\\psi_{w,v}ψw,v",{"_index":2329,"t":{"658":{"position":[[2218,19]]}}}],["w/o",{"_index":4432,"t":{"1364":{"position":[[78,4]]}}}],["w0+△w=w0+baw_0",{"_index":2620,"t":{"733":{"position":[[341,14]]}}}],["w0w_0w0",{"_index":2630,"t":{"733":{"position":[[549,8],[628,8]]}}}],["w0∈rd×kw_0",{"_index":2617,"t":{"733":{"position":[[263,10]]}}}],["w=1∣d∣∑i=1∣d∣(▽wlog⁡p(yi∣xi))2,w",{"_index":2269,"t":{"630":{"position":[[1407,32]]}}}],["w=ba\\triangl",{"_index":2631,"t":{"733":{"position":[[639,14],[902,14]]},"1067":{"position":[[745,14]]}}}],["w=w(0)+△=w(0)+ba,\\begin{equ",{"_index":2752,"t":{"786":{"position":[[1654,33]]}}}],["w=w(0)+△=w(0)+pλq,\\begin{equ",{"_index":2835,"t":{"795":{"position":[[98,34]]}}}],["w={fp′[i",{"_index":855,"t":{"174":{"position":[[2005,10]]}}}],["w\\phi_wϕw",{"_index":2330,"t":{"658":{"position":[[2263,11]]}}}],["w\\text{w}w",{"_index":3159,"t":{"853":{"position":[[2250,10]]},"855":{"position":[[115,10]]}}}],["w\\triangl",{"_index":2581,"t":{"721":{"position":[[305,11]]},"733":{"position":[[978,11]]},"768":{"position":[[160,11]]},"770":{"position":[[395,11]]},"772":{"position":[[114,11]]},"778":{"position":[[4,11],[48,11],[152,11],[445,11],[507,11],[587,11]]},"780":{"position":[[265,11]]}}}],["w^\\top_\\text{down}h_{fn",{"_index":4459,"t":{"1384":{"position":[[577,27]]}}}],["w^\\top_\\text{down}p",{"_index":4476,"t":{"1384":{"position":[[1888,22]]}}}],["w^\\top_\\text{up",{"_index":4458,"t":{"1384":{"position":[[555,16],[1866,16]]}}}],["w^\\top_\\text{up}w^\\top_\\text{down})h_\\text{in",{"_index":4502,"t":{"1384":{"position":[[3672,46]]}}}],["w^\\top_q",{"_index":4501,"t":{"1384":{"position":[[3653,9]]}}}],["w^\\top_{down}(\\hat{x",{"_index":3524,"t":{"988":{"position":[[986,22]]}}}],["w^\\top_{}up(nonlinear(h_{down",{"_index":3526,"t":{"988":{"position":[[1022,32]]}}}],["w^o",{"_index":1217,"t":{"300":{"position":[[740,3]]}}}],["w^{(0",{"_index":2753,"t":{"786":{"position":[[1692,7],[1714,7]]},"795":{"position":[[137,7],[159,7]]}}}],["w^{(0)}h=w(0",{"_index":2818,"t":{"791":{"position":[[87,13]]}}}],["w^{(0)}x",{"_index":2820,"t":{"791":{"position":[[176,8],[201,8]]}}}],["w^{(t)}_{i,j",{"_index":3125,"t":{"853":{"position":[[739,13]]}}}],["w_0",{"_index":2621,"t":{"733":{"position":[[372,3]]}}}],["w_0x",{"_index":2636,"t":{"733":{"position":[[798,4],[820,4]]}}}],["w_0xh=w0​x",{"_index":2634,"t":{"733":{"position":[[735,10]]}}}],["w_1",{"_index":2166,"t":{"598":{"position":[[1811,4]]}}}],["w_c",{"_index":1476,"t":{"358":{"position":[[461,5]]}}}],["w_i",{"_index":3674,"t":{"1065":{"position":[[760,5]]},"1067":{"position":[[551,3],[567,3],[573,3]]}}}],["w_i^k",{"_index":1229,"t":{"300":{"position":[[1045,5]]}}}],["w_i^v",{"_index":1230,"t":{"300":{"position":[[1095,5]]}}}],["w_jϕj​(yx​)=wj",{"_index":5310,"t":{"1659":{"position":[[606,15]]}}}],["w_k",{"_index":2868,"t":{"797":{"position":[[80,4]]},"809":{"position":[[920,4]]},"1242":{"position":[[655,3]]}}}],["w_k△wk",{"_index":2694,"t":{"770":{"position":[[295,7]]}}}],["w_q",{"_index":2696,"t":{"772":{"position":[[53,4]]}}}],["w_q△wq",{"_index":2692,"t":{"770":{"position":[[271,7]]},"774":{"position":[[1022,8],[1093,8]]},"776":{"position":[[92,7],[173,7]]}}}],["w_v",{"_index":2697,"t":{"772":{"position":[[58,3]]},"797":{"position":[[85,4]]},"809":{"position":[[925,4]]}}}],["w_v△wv",{"_index":2723,"t":{"774":{"position":[[997,7],[1068,7]]},"776":{"position":[[115,7]]}}}],["w_{f1}wq​,wk​,wv​,wf1",{"_index":2869,"t":{"797":{"position":[[90,22]]}}}],["w_{f_1",{"_index":3020,"t":{"809":{"position":[[930,8]]}}}],["w_{f_2}wq​,wk​,wv​,wf1​​,wf2",{"_index":3021,"t":{"809":{"position":[[939,31]]}}}],["w_{i,j",{"_index":3126,"t":{"853":{"position":[[776,7],[852,8],[1568,8]]},"855":{"position":[[249,7],[312,9]]}}}],["w_{i,j}^{(t",{"_index":3142,"t":{"853":{"position":[[1592,13]]}}}],["w_{i,j}wi,j′​=wi,j",{"_index":3170,"t":{"855":{"position":[[678,19]]}}}],["w_{ij",{"_index":2969,"t":{"801":{"position":[[1058,6]]}}}],["w_{j,1",{"_index":5312,"t":{"1659":{"position":[[667,8]]}}}],["w_{j,2",{"_index":5313,"t":{"1659":{"position":[[676,8]]}}}],["w_{j,k}|t(x",{"_index":5323,"t":{"1659":{"position":[[961,13]]}}}],["w_{j,m",{"_index":5314,"t":{"1659":{"position":[[688,7]]}}}],["w_{ki",{"_index":2803,"t":{"789":{"position":[[626,7]]}}}],["w_{vi",{"_index":2804,"t":{"789":{"position":[[634,6]]}}}],["wall",{"_index":5361,"t":{"1672":{"position":[[243,4]]}}}],["wang",{"_index":973,"t":{"215":{"position":[[270,4],[2483,5]]},"531":{"position":[[1082,4]]},"851":{"position":[[165,4]]},"1084":{"position":[[293,4]]},"1362":{"position":[[370,5]]},"1364":{"position":[[255,4]]},"1367":{"position":[[631,4]]},"1369":{"position":[[418,4]]}}}],["want",{"_index":62,"t":{"7":{"position":[[401,4]]}}}],["warm",{"_index":1501,"t":{"372":{"position":[[73,4]]},"803":{"position":[[492,4]]}}}],["warmup",{"_index":2195,"t":{"602":{"position":[[437,6]]},"861":{"position":[[27,6]]},"905":{"position":[[139,6]]},"1665":{"position":[[1385,6]]},"1674":{"position":[[436,6]]}}}],["warmup\\_",{"_index":1332,"t":{"317":{"position":[[317,8]]}}}],["warmup_steps=4000warmup\\_",{"_index":1337,"t":{"317":{"position":[[545,25]]}}}],["warmup_stepswarmup\\_",{"_index":1334,"t":{"317":{"position":[[420,20]]}}}],["warp",{"_index":3872,"t":{"1126":{"position":[[1331,6],[1899,5]]},"1145":{"position":[[960,4]]}}}],["was\",‘‘wa",{"_index":5234,"t":{"1655":{"position":[[1758,10],[2052,10]]}}}],["was,b)=tru",{"_index":5244,"t":{"1657":{"position":[[157,12]]}}}],["was,b)=true)p(f_{e_",{"_index":5240,"t":{"1657":{"position":[[64,21]]}}}],["was,b)∧feo(b,person)→\"person:parent\"\\begin{align",{"_index":5183,"t":{"1651":{"position":[[1106,50]]}}}],["was,b)∧feo​​(b,person)→\"person:par",{"_index":5192,"t":{"1651":{"position":[[1356,39]]}}}],["was|wa",{"_index":5225,"t":{"1655":{"position":[[1464,7],[1527,7],[1584,7]]}}}],["was}\",``\\text{wa",{"_index":5235,"t":{"1655":{"position":[[1926,17]]}}}],["wayward",{"_index":3520,"t":{"988":{"position":[[675,12]]}}}],["wb∈rdbr×dlrw_b",{"_index":2277,"t":{"630":{"position":[[1744,14]]}}}],["wc∈rdw_c",{"_index":1478,"t":{"358":{"position":[[490,8]]}}}],["wdlw^l_dwdl",{"_index":3185,"t":{"857":{"position":[[752,12]]}}}],["wdownw_{\\text{down}}wdown",{"_index":4040,"t":{"1172":{"position":[[68,26]]}}}],["wdownw_{down}wdown",{"_index":2283,"t":{"630":{"position":[[2025,19]]}}}],["wdown∈rdhidden×dmidw_\\text{down",{"_index":4478,"t":{"1384":{"position":[[1948,32],[3235,32]]}}}],["wdown∈rdhidden×dmidw_{\\text{down",{"_index":4461,"t":{"1384":{"position":[[646,34]]}}}],["wdown∈rd×mw_{\\text{down",{"_index":4024,"t":{"1167":{"position":[[791,25]]}}}],["wdown∈rd×mw_{down",{"_index":4075,"t":{"1218":{"position":[[138,18]]}}}],["wdown∈rd×r(r<d)w_{down",{"_index":3530,"t":{"988":{"position":[[1171,23]]}}}],["wdw_dwd",{"_index":3271,"t":{"873":{"position":[[1658,8]]}}}],["weak",{"_index":355,"t":{"78":{"position":[[310,4],[531,4]]}}}],["weaqa",{"_index":1699,"t":{"468":{"position":[[299,5]]}}}],["web",{"_index":1031,"t":{"221":{"position":[[485,3]]},"225":{"position":[[361,3]]},"242":{"position":[[34,3],[91,3]]},"1788":{"position":[[566,3]]}}}],["webnlg",{"_index":4209,"t":{"1253":{"position":[[372,6]]},"1266":{"position":[[144,6]]},"1310":{"position":[[55,6],[125,6]]},"1323":{"position":[[158,6]]}}}],["websit",{"_index":108,"t":{"17":{"position":[[181,7]]},"19":{"position":[[34,7],[254,7]]}}}],["wedg",{"_index":5186,"t":{"1651":{"position":[[1185,6],[1232,6]]}}}],["week",{"_index":3915,"t":{"1132":{"position":[[336,5],[456,5]]}}}],["wei",{"_index":981,"t":{"215":{"position":[[442,3]]}}}],["weigh",{"_index":4686,"t":{"1431":{"position":[[2722,7]]}}}],["weight",{"_index":236,"t":{"38":{"position":[[445,6]]},"53":{"position":[[195,6]]},"80":{"position":[[30,6]]},"106":{"position":[[114,6]]},"112":{"position":[[199,6]]},"116":{"position":[[651,6]]},"132":{"position":[[583,9]]},"138":{"position":[[200,9],[482,9],[511,9],[542,6]]},"149":{"position":[[396,6]]},"151":{"position":[[118,9],[140,6]]},"155":{"position":[[151,6],[179,6],[635,9],[729,6],[751,6],[800,6],[875,9],[962,9],[1048,6]]},"174":{"position":[[1775,6],[1892,6]]},"177":{"position":[[498,6]]},"182":{"position":[[296,6]]},"227":{"position":[[209,6],[443,6]]},"234":{"position":[[351,7]]},"244":{"position":[[16,6]]},"287":{"position":[[261,8]]},"296":{"position":[[108,8],[145,6]]},"298":{"position":[[240,6]]},"306":{"position":[[304,6],[350,7]]},"341":{"position":[[388,6]]},"358":{"position":[[1462,6]]},"510":{"position":[[139,6]]},"533":{"position":[[268,6]]},"598":{"position":[[2646,6]]},"628":{"position":[[373,7]]},"630":{"position":[[1374,6],[1724,6]]},"633":{"position":[[915,8]]},"648":{"position":[[478,6]]},"652":{"position":[[0,7]]},"658":{"position":[[1029,6],[1046,6],[1222,6]]},"660":{"position":[[511,6],[610,6]]},"676":{"position":[[932,6]]},"705":{"position":[[375,6]]},"717":{"position":[[97,7]]},"719":{"position":[[455,6],[560,7],[1183,7]]},"721":{"position":[[230,6]]},"723":{"position":[[346,6]]},"733":{"position":[[49,6],[249,6]]},"735":{"position":[[3,6]]},"739":{"position":[[20,6],[193,6]]},"757":{"position":[[3,6],[292,6]]},"770":{"position":[[68,6],[157,6]]},"780":{"position":[[248,6]]},"784":{"position":[[227,7],[305,6],[369,6],[460,6]]},"786":{"position":[[848,6],[929,6],[2462,6],[2751,6],[2802,6],[2897,6],[3059,6],[3333,6],[3900,6]]},"791":{"position":[[44,7],[852,6]]},"795":{"position":[[12,6]]},"797":{"position":[[49,6],[352,6]]},"801":{"position":[[156,7],[986,6]]},"803":{"position":[[719,6]]},"809":{"position":[[104,7],[787,6],[877,6]]},"828":{"position":[[88,6]]},"841":{"position":[[174,6],[205,6]]},"843":{"position":[[117,6]]},"847":{"position":[[89,7],[309,7]]},"849":{"position":[[242,7],[356,6],[468,6],[545,6],[636,6],[936,6],[1270,6],[1346,6]]},"851":{"position":[[353,7],[487,6],[733,7]]},"853":{"position":[[115,6],[515,6],[1195,6],[1774,6],[2299,6]]},"855":{"position":[[650,6],[848,6]]},"857":{"position":[[274,6],[423,6],[716,6],[807,6],[863,6],[902,6],[1340,6]]},"861":{"position":[[480,7],[500,7],[541,7],[1507,7],[1539,6]]},"866":{"position":[[95,6],[258,6],[306,7],[523,7],[715,7]]},"870":{"position":[[360,7],[400,7],[640,7],[841,7],[1193,7],[1342,6],[1402,7],[1453,7],[1539,6],[1872,7],[2020,7],[2127,7]]},"873":{"position":[[231,6],[278,6],[332,6],[416,6],[498,7],[625,6],[667,6],[743,7],[823,6],[1071,6],[1197,7],[1431,6],[1517,6],[1577,6],[1638,6],[1721,6]]},"875":{"position":[[135,6]]},"877":{"position":[[229,7],[306,7],[341,6],[416,7],[493,6]]},"879":{"position":[[498,6]]},"881":{"position":[[278,7],[365,7]]},"905":{"position":[[183,6]]},"945":{"position":[[480,7]]},"977":{"position":[[462,7],[482,7]]},"979":{"position":[[701,8]]},"982":{"position":[[932,7]]},"988":{"position":[[220,7]]},"990":{"position":[[79,8],[555,7]]},"992":{"position":[[430,7]]},"999":{"position":[[993,7]]},"1006":{"position":[[2148,6],[2225,6]]},"1126":{"position":[[124,6]]},"1128":{"position":[[375,6]]},"1134":{"position":[[819,6]]},"1162":{"position":[[174,7]]},"1242":{"position":[[841,6],[877,6]]},"1341":{"position":[[1209,6]]},"1364":{"position":[[118,8]]},"1431":{"position":[[733,8],[829,8],[912,7],[2841,8]]},"1440":{"position":[[205,6]]},"1468":{"position":[[1284,6]]},"1489":{"position":[[126,7],[229,6]]},"1496":{"position":[[510,6],[645,6]]},"1659":{"position":[[1066,8]]},"1665":{"position":[[1397,6]]},"1674":{"position":[[471,6]]},"1736":{"position":[[708,8],[729,6],[752,6],[778,6],[865,6],[953,6]]},"1782":{"position":[[530,8]]}}}],["weightinh",{"_index":640,"t":{"138":{"position":[[367,9]]}}}],["weigt",{"_index":336,"t":{"63":{"position":[[185,5]]}}}],["welcome.md",{"_index":52,"t":{"7":{"position":[[245,10]]}}}],["welcome/index.md",{"_index":53,"t":{"7":{"position":[[267,16]]}}}],["well",{"_index":60,"t":{"7":{"position":[[378,5]]},"1622":{"position":[[236,5]]}}}],["wf1w_{f1}wf1",{"_index":2832,"t":{"791":{"position":[[872,14]]}}}],["wf1∈rd×dmw_{f1",{"_index":2812,"t":{"789":{"position":[[962,15]]}}}],["wf2w_{f2}wf2",{"_index":2833,"t":{"791":{"position":[[887,14]]},"797":{"position":[[115,13]]}}}],["wf2∈rdm×dw_{f2",{"_index":2814,"t":{"789":{"position":[[1019,15]]}}}],["whirlpool",{"_index":5637,"t":{"1802":{"position":[[1045,10]]}}}],["whole",{"_index":4542,"t":{"1393":{"position":[[546,5]]}}}],["wi,j(t)w^{(t)}_{i,j}wi,j(t",{"_index":3133,"t":{"853":{"position":[[1020,28]]}}}],["wi,jmi,jw_{i,j}m_{i,j}wi,j​mi,j",{"_index":3163,"t":{"855":{"position":[[414,32]]}}}],["wi,jw_{i,j}wi,j",{"_index":3136,"t":{"853":{"position":[[1107,16]]},"855":{"position":[[447,16],[792,16],[913,16]]}}}],["wi,j′=0w'_{i,j",{"_index":3174,"t":{"855":{"position":[[855,15]]}}}],["wi,j′=wi,jw'_{i,j",{"_index":3169,"t":{"855":{"position":[[657,18]]}}}],["wi,j′w'_{i,j}wi,j",{"_index":3162,"t":{"855":{"position":[[392,19]]}}}],["wi,j∂l∂wi,j′<0w_{i,j",{"_index":3166,"t":{"855":{"position":[[543,21]]}}}],["wic",{"_index":2086,"t":{"594":{"position":[[922,5]]},"633":{"position":[[60,3]]},"642":{"position":[[43,3]]},"646":{"position":[[324,3]]},"701":{"position":[[86,3]]},"997":{"position":[[432,4]]},"1002":{"position":[[805,3]]},"1070":{"position":[[161,3]]},"1113":{"position":[[83,3],[303,3],[430,3],[434,3]]},"1115":{"position":[[1068,4]]},"1117":{"position":[[196,3]]},"1181":{"position":[[93,4]]},"1208":{"position":[[163,4]]},"1253":{"position":[[162,4]]},"1427":{"position":[[1304,4]]},"1501":{"position":[[256,3],[291,3]]}}}],["width",{"_index":1050,"t":{"227":{"position":[[601,6]]},"1210":{"position":[[46,5]]}}}],["wijw_{ij}wij",{"_index":2973,"t":{"801":{"position":[[1153,13]]}}}],["wiki",{"_index":3580,"t":{"997":{"position":[[878,4]]},"1006":{"position":[[2367,4]]},"1070":{"position":[[275,4]]},"1253":{"position":[[329,4]]}}}],["wikiann",{"_index":1013,"t":{"215":{"position":[[2275,7]]}}}],["wikidata",{"_index":3836,"t":{"1107":{"position":[[55,8]]}}}],["wikipedia",{"_index":1617,"t":{"439":{"position":[[203,9]]},"674":{"position":[[178,9]]},"997":{"position":[[885,9]]},"1310":{"position":[[152,9]]}}}],["wikisql",{"_index":2656,"t":{"743":{"position":[[100,7]]}}}],["win",{"_index":3087,"t":{"849":{"position":[[1037,7]]},"851":{"position":[[983,8],[1068,7],[1099,7],[1173,7]]},"1468":{"position":[[859,7],[960,7],[1033,7]]},"1475":{"position":[[197,7],[221,7],[355,7]]},"1505":{"position":[[435,7]]},"1525":{"position":[[172,7]]}}}],["wind",{"_index":1661,"t":{"457":{"position":[[279,4]]}}}],["window",{"_index":4766,"t":{"1462":{"position":[[192,6]]}}}],["wingogend",{"_index":4919,"t":{"1546":{"position":[[788,11]]}}}],["wingogrand",{"_index":3607,"t":{"1006":{"position":[[2693,11]]}}}],["winogrand",{"_index":2083,"t":{"594":{"position":[[884,11]]},"997":{"position":[[842,10]]},"1002":{"position":[[465,11]]},"1006":{"position":[[1169,10]]},"1070":{"position":[[244,10]]},"1253":{"position":[[294,11]]},"1429":{"position":[[1607,12]]}}}],["wiq∈rdmodel×dk,wik∈rdmodel×dk,wiv∈rdmodel×dvw_i^q",{"_index":1226,"t":{"300":{"position":[[951,49]]}}}],["wise",{"_index":1170,"t":{"289":{"position":[[473,5]]},"292":{"position":[[115,4]]},"310":{"position":[[1780,4]]},"598":{"position":[[756,4],[912,4],[1308,4],[1426,4],[1746,4],[2785,4],[3204,4]]},"672":{"position":[[1079,4]]},"733":{"position":[[716,4]]},"786":{"position":[[1135,4]]},"795":{"position":[[1560,5]]},"801":{"position":[[171,4],[231,4]]},"835":{"position":[[36,4]]},"940":{"position":[[258,6]]},"982":{"position":[[670,4]]},"986":{"position":[[238,4],[327,4]]},"988":{"position":[[73,4]]},"992":{"position":[[335,4]]},"1008":{"position":[[130,4]]},"1062":{"position":[[1194,4]]},"1067":{"position":[[473,4]]},"1187":{"position":[[383,4]]}}}],["within",{"_index":4336,"t":{"1323":{"position":[[393,6]]}}}],["without",{"_index":360,"t":{"78":{"position":[[676,7]]}}}],["wiw_iwi",{"_index":3665,"t":{"1065":{"position":[[399,8]]},"1067":{"position":[[654,8]]}}}],["wi′=wi+△wi=wi+ba∈rs×d,\\begin{equ",{"_index":3685,"t":{"1067":{"position":[[505,38]]}}}],["wi∈rs×dw_i",{"_index":3660,"t":{"1065":{"position":[[229,10]]}}}],["wjw_jwj",{"_index":636,"t":{"132":{"position":[[979,8]]}}}],["wk=uk⨂vktw_k",{"_index":4138,"t":{"1242":{"position":[[451,12]]}}}],["wk\\triangl",{"_index":2693,"t":{"770":{"position":[[282,12]]}}}],["wklw^l_kwkl",{"_index":3181,"t":{"857":{"position":[[660,13]]}}}],["wkw_kwk",{"_index":2578,"t":{"721":{"position":[[189,9]]},"739":{"position":[[73,9]]},"873":{"position":[[1260,8]]},"1242":{"position":[[505,8],[884,8]]},"1384":{"position":[[1446,9]]}}}],["wk∈rdhidden×dhiddenw_k",{"_index":4498,"t":{"1384":{"position":[[3476,22]]}}}],["wmt",{"_index":1140,"t":{"283":{"position":[[172,3]]},"313":{"position":[[29,3]]},"322":{"position":[[0,3],[223,3]]},"328":{"position":[[243,3],[272,3]]},"1546":{"position":[[923,3]]}}}],["wnli",{"_index":1896,"t":{"529":{"position":[[81,4]]},"1006":{"position":[[2510,5]]},"1393":{"position":[[180,4]]}}}],["wolw^l_owol",{"_index":3183,"t":{"857":{"position":[[689,12]]}}}],["wonder",{"_index":5432,"t":{"1706":{"position":[[227,13]]}}}],["wong",{"_index":2390,"t":{"670":{"position":[[876,4]]}}}],["word",{"_index":1312,"t":{"313":{"position":[[228,4]]},"358":{"position":[[177,4],[543,4]]},"382":{"position":[[326,4]]},"384":{"position":[[953,4]]},"386":{"position":[[30,4]]},"391":{"position":[[13,4],[48,4],[79,4],[110,4],[142,4]]},"409":{"position":[[191,4]]},"428":{"position":[[161,4]]},"594":{"position":[[896,4]]},"630":{"position":[[967,4]]},"658":{"position":[[841,4]]},"696":{"position":[[122,4]]},"753":{"position":[[32,4]]},"859":{"position":[[181,4]]},"866":{"position":[[153,5]]},"885":{"position":[[319,4]]},"891":{"position":[[623,4]]},"893":{"position":[[46,4],[283,4],[373,4],[999,4],[1454,4]]},"938":{"position":[[204,4],[324,4]]},"953":{"position":[[569,4]]},"1014":{"position":[[793,4]]},"1062":{"position":[[1168,4],[1244,4]]},"1065":{"position":[[213,4],[377,4],[501,4]]},"1067":{"position":[[256,4],[485,4]]},"1101":{"position":[[101,4]]},"1111":{"position":[[220,4]]},"1113":{"position":[[460,4]]},"1126":{"position":[[1090,4]]},"1130":{"position":[[239,4]]},"1145":{"position":[[1533,5]]},"1151":{"position":[[1018,5]]},"1303":{"position":[[76,4],[196,4],[754,4]]},"1328":{"position":[[72,4]]},"1646":{"position":[[737,4],[839,4],[947,4],[1414,5],[1657,5],[2737,5]]},"1651":{"position":[[821,4]]},"1655":{"position":[[114,4],[776,4],[1195,4],[1676,4]]},"1657":{"position":[[1126,4],[2399,4]]},"1659":{"position":[[74,4],[186,4],[370,4],[405,4],[444,5],[575,5],[1049,4]]},"1665":{"position":[[905,4],[974,5]]},"1674":{"position":[[112,5]]},"1689":{"position":[[229,4]]},"1718":{"position":[[152,5],[200,5]]},"1730":{"position":[[1236,4]]},"1756":{"position":[[343,4]]},"1762":{"position":[[567,4]]},"1802":{"position":[[405,5]]}}}],["work",{"_index":123,"t":{"19":{"position":[[100,7],[126,4]]},"780":{"position":[[153,4]]},"1453":{"position":[[409,5]]},"1570":{"position":[[12,4]]}}}],["workaround",{"_index":3947,"t":{"1143":{"position":[[262,12]]}}}],["world",{"_index":2000,"t":{"553":{"position":[[12,5]]},"589":{"position":[[2193,5]]},"594":{"position":[[1029,6]]},"608":{"position":[[527,5]]},"618":{"position":[[39,5],[94,5],[467,5]]},"1164":{"position":[[449,5]]},"1323":{"position":[[408,7]]},"1646":{"position":[[82,5]]}}}],["worst",{"_index":4449,"t":{"1379":{"position":[[1763,5]]},"1397":{"position":[[344,5]]},"1531":{"position":[[221,6]]}}}],["wow_owo",{"_index":2580,"t":{"721":{"position":[[209,8],[252,8]]},"739":{"position":[[93,9]]}}}],["wo∈rd×dw_o",{"_index":2800,"t":{"789":{"position":[[534,10]]}}}],["wplugw_{plug}wplug",{"_index":2253,"t":{"630":{"position":[[408,19]]}}}],["wq,wk,wv,wf1,wf2w_q",{"_index":3019,"t":{"809":{"position":[[899,20]]}}}],["wq,wk,wv,wf1w_q",{"_index":2867,"t":{"797":{"position":[[63,16]]}}}],["wq,wv",{"_index":2695,"t":{"772":{"position":[[42,10]]}}}],["wq\\triangl",{"_index":2691,"t":{"770":{"position":[[258,12]]},"774":{"position":[[1009,12],[1080,12]]},"776":{"position":[[79,12],[160,12]]}}}],["wqi,wki,wvi∈rd×dhw_{qi",{"_index":2802,"t":{"789":{"position":[[601,24]]}}}],["wqlw^l_qwql",{"_index":3180,"t":{"857":{"position":[[646,13]]}}}],["wqw_qwq",{"_index":2577,"t":{"721":{"position":[[179,9]]},"739":{"position":[[62,10]]},"741":{"position":[[220,8]]},"757":{"position":[[91,8]]},"770":{"position":[[322,8]]},"772":{"position":[[77,8]]},"873":{"position":[[801,8],[1249,8],[1288,8],[1686,8]]},"1384":{"position":[[1436,9],[3465,8]]}}}],["wq​,wv",{"_index":2698,"t":{"772":{"position":[[62,11]]}}}],["write",{"_index":5581,"t":{"1778":{"position":[[926,6]]}}}],["written",{"_index":4713,"t":{"1442":{"position":[[1004,7]]}}}],["wsc",{"_index":2082,"t":{"594":{"position":[[877,4]]},"633":{"position":[[64,3]]},"640":{"position":[[180,3]]},"646":{"position":[[330,3]]},"701":{"position":[[92,3]]},"709":{"position":[[363,3],[1262,3],[2219,3]]},"997":{"position":[[437,4]]},"1004":{"position":[[47,4]]},"1070":{"position":[[165,3]]},"1113":{"position":[[398,3]]},"1115":{"position":[[1079,3]]},"1181":{"position":[[98,3]]},"1253":{"position":[[167,3]]},"1427":{"position":[[848,3],[1255,4]]},"1429":{"position":[[1805,3]]},"1431":{"position":[[1959,3]]},"1499":{"position":[[606,4]]},"1505":{"position":[[253,3]]},"1521":{"position":[[3,3]]},"1525":{"position":[[20,3]]}}}],["wsj",{"_index":1364,"t":{"326":{"position":[[253,3],[462,3],[779,3]]}}}],["wu",{"_index":4355,"t":{"1347":{"position":[[429,2]]},"1367":{"position":[[455,2]]}}}],["wukong",{"_index":1410,"t":{"339":{"position":[[198,6]]}}}],["wulw^l_uwul",{"_index":3184,"t":{"857":{"position":[[737,12]]}}}],["wupw_{\\text{up}}wup",{"_index":4039,"t":{"1172":{"position":[[45,20]]}}}],["wup∈rdmid×2nlayerdhiddenw_\\text{up",{"_index":4479,"t":{"1384":{"position":[[2061,35]]}}}],["wup∈rdmid×dhiddenw_\\text{up",{"_index":4496,"t":{"1384":{"position":[[3345,28]]}}}],["wup∈rdmid×dhiddenw_{\\text{up",{"_index":4464,"t":{"1384":{"position":[[759,30]]}}}],["wup∈rm×dw_{\\text{up",{"_index":4027,"t":{"1167":{"position":[[871,21]]}}}],["wup∈rm×dw_{up",{"_index":4076,"t":{"1218":{"position":[[216,14]]}}}],["wup∈rr×d(r<d)w_{up",{"_index":3532,"t":{"988":{"position":[[1249,19]]}}}],["wuw_uwu",{"_index":3267,"t":{"873":{"position":[[705,8],[978,8],[1039,8],[1647,8]]}}}],["wv\\triangl",{"_index":2722,"t":{"774":{"position":[[984,12],[1055,12]]},"776":{"position":[[102,12]]}}}],["wvlw^l_vwvl",{"_index":3182,"t":{"857":{"position":[[674,12]]}}}],["wvw_vwv",{"_index":2579,"t":{"721":{"position":[[199,9]]},"739":{"position":[[83,9]]},"741":{"position":[[231,8]]},"757":{"position":[[102,8]]},"770":{"position":[[333,8]]},"873":{"position":[[716,8],[989,8],[1050,8],[1299,8],[1697,8]]}}}],["wv∈rdhidden×dhiddenw_v",{"_index":4470,"t":{"1384":{"position":[[1456,22]]}}}],["www",{"_index":853,"t":{"174":{"position":[[1906,3]]},"630":{"position":[[1591,3]]},"658":{"position":[[1630,3],[1921,3],[2024,3],[2390,3]]},"721":{"position":[[246,3]]},"768":{"position":[[178,3]]},"778":{"position":[[22,3],[42,3],[316,3],[485,3],[528,3],[547,3],[605,3]]},"786":{"position":[[2029,3]]},"945":{"position":[[503,3]]},"1185":{"position":[[426,3]]}}}],["wx",{"_index":2637,"t":{"733":{"position":[[815,2]]}}}],["w|)(∼∣w",{"_index":2335,"t":{"658":{"position":[[2365,10]]}}}],["w|∣v∣≪∣w",{"_index":2333,"t":{"658":{"position":[[2315,10]]}}}],["wϕw_{\\phi}w",{"_index":4263,"t":{"1296":{"position":[[985,13]]}}}],["w∈r1×dw",{"_index":850,"t":{"174":{"position":[[1789,7]]}}}],["w∈rdb×dlw",{"_index":2262,"t":{"630":{"position":[[1256,9]]}}}],["w∈rn×n\\text{w",{"_index":3104,"t":{"853":{"position":[[65,14]]}}}],["w∣)(\\sim",{"_index":2334,"t":{"658":{"position":[[2353,11]]}}}],["w∣∣||w||∣∣w",{"_index":2733,"t":{"778":{"position":[[259,15]]}}}],["w△w",{"_index":2582,"t":{"721":{"position":[[317,3]]},"733":{"position":[[990,3]]},"768":{"position":[[172,3]]},"770":{"position":[[407,3]]},"772":{"position":[[126,3]]},"778":{"position":[[16,3],[60,3],[164,3],[457,3],[519,3],[599,3]]},"780":{"position":[[277,3]]}}}],["x",{"_index":190,"t":{"27":{"position":[[107,1]]},"230":{"position":[[108,1]]},"255":{"position":[[154,1]]},"527":{"position":[[1716,2]]},"598":{"position":[[2870,1]]},"686":{"position":[[260,2]]},"688":{"position":[[335,3]]},"723":{"position":[[580,2],[1301,2]]},"789":{"position":[[318,3]]},"791":{"position":[[197,1]]},"984":{"position":[[643,4]]},"986":{"position":[[506,4]]},"1060":{"position":[[692,1]]},"1107":{"position":[[422,1],[668,5]]},"1132":{"position":[[402,1],[490,1]]},"1164":{"position":[[373,4]]},"1296":{"position":[[110,2],[159,3]]},"1298":{"position":[[34,2]]},"1300":{"position":[[270,2]]},"1305":{"position":[[83,2],[186,2]]},"1314":{"position":[[407,1]]},"1330":{"position":[[109,2]]},"1350":{"position":[[405,3],[743,4]]},"1352":{"position":[[1220,4]]},"1379":{"position":[[1207,1]]},"1387":{"position":[[312,1],[319,1]]},"1389":{"position":[[1003,1]]},"1391":{"position":[[13,1],[28,1],[40,1]]},"1395":{"position":[[1127,2]]},"1558":{"position":[[792,3],[1598,2],[1621,4]]},"1655":{"position":[[448,2],[914,2],[1838,1]]},"1657":{"position":[[844,1]]},"1702":{"position":[[200,3],[267,3],[354,4],[506,3],[791,3]]},"1718":{"position":[[140,4]]},"1762":{"position":[[205,1]]},"1770":{"position":[[658,1]]},"1774":{"position":[[137,4]]},"1778":{"position":[[425,4]]}}}],["x)(y,x",{"_index":620,"t":{"130":{"position":[[1362,7]]}}}],["x))]+γex∼dpretrain[log(πϕrl(x))]\\textup{objective}(\\phi",{"_index":4948,"t":{"1558":{"position":[[1460,56]]}}}],["x))]+γex∼dpretrain​​[log(πϕrl​(x",{"_index":4957,"t":{"1558":{"position":[[1747,35]]}}}],["x))]objective(ϕ)=e(x,y)∼dπϕrl​​​[rθ​(x,y)−βlog(πϕrl​(i",{"_index":4956,"t":{"1558":{"position":[[1677,55]]}}}],["x))w_2(lff​⊙γ(w1​x))w2",{"_index":2167,"t":{"598":{"position":[[1816,23]]}}}],["x)/πsft(i",{"_index":4947,"t":{"1558":{"position":[[1448,9],[1735,9]]}}}],["x)=max⁡ϕ∑i∈yidxlog⁡pϕ(zi",{"_index":4272,"t":{"1300":{"position":[[178,24]]}}}],["x)=ϕmax​i∈yidx​∑​logpϕ​(zi",{"_index":4281,"t":{"1300":{"position":[[395,27]]}}}],["x)p_{\\phi}(i",{"_index":4238,"t":{"1296":{"position":[[83,13]]},"1298":{"position":[[7,13]]}}}],["x)pϕ​(i",{"_index":4239,"t":{"1296":{"position":[[100,7]]},"1298":{"position":[[24,7]]}}}],["x,y)(x",{"_index":3474,"t":{"982":{"position":[[495,8]]}}}],["x,y)=1t∑t=1tlog⁡p(yt∣x,y<t).\\beta(\\text{x",{"_index":2122,"t":{"596":{"position":[[1711,45]]}}}],["x,y)={xi,yi}i=1n(x,i",{"_index":4114,"t":{"1238":{"position":[[102,22]]}}}],["x,yw)−rθ(x,yl)))]\\textup{loss}(\\theta",{"_index":4933,"t":{"1558":{"position":[[677,39]]}}}],["x,yw​)−rθ​(x,yl",{"_index":4940,"t":{"1558":{"position":[[867,21]]}}}],["x1",{"_index":5436,"t":{"1712":{"position":[[342,5]]}}}],["x1,x2,…,xn}\\{x_1",{"_index":3891,"t":{"1128":{"position":[[1451,18]]}}}],["x1,…,xn)(x_1",{"_index":1161,"t":{"289":{"position":[[112,14]]},"310":{"position":[[52,14]]}}}],["x10",{"_index":3987,"t":{"1157":{"position":[[476,3]]}}}],["x1:n={x0,x1,…,xn}\\text{x}_{1:n",{"_index":3763,"t":{"1099":{"position":[[71,31]]}}}],["x1:n​={x0​,x1​,…,xn",{"_index":3767,"t":{"1099":{"position":[[129,23]]}}}],["x1=2pe",{"_index":444,"t":{"91":{"position":[[1527,7]]}}}],["x1=2p​e",{"_index":456,"t":{"91":{"position":[[1785,8]]}}}],["x2",{"_index":5437,"t":{"1712":{"position":[[348,4]]}}}],["x;infix;y][x",{"_index":4341,"t":{"1330":{"position":[[180,14]]}}}],["x={x1,x2,…,xn}x",{"_index":4366,"t":{"1350":{"position":[[127,15]]},"1477":{"position":[[208,15]]}}}],["x={…es​…eo",{"_index":5206,"t":{"1655":{"position":[[482,15]]}}}],["x={…es…eo",{"_index":5203,"t":{"1655":{"position":[[437,10]]}}}],["x\\text{x}x",{"_index":2100,"t":{"596":{"position":[[247,10]]},"945":{"position":[[490,10]]},"1019":{"position":[[208,10]]},"1099":{"position":[[332,10],[436,10],[527,10],[620,11]]}}}],["x\\triangl",{"_index":3012,"t":{"807":{"position":[[114,11]]}}}],["x][p;x",{"_index":3488,"t":{"984":{"position":[[435,7]]}}}],["x][z",{"_index":5539,"t":{"1756":{"position":[[351,8]]},"1778":{"position":[[411,7],[973,7]]}}}],["x]xnew​=[p,x",{"_index":2470,"t":{"688":{"position":[[188,13]]}}}],["x^1=2_p\\textup{",{"_index":450,"t":{"91":{"position":[[1622,19]]}}}],["x^1_p\\textup{",{"_index":449,"t":{"91":{"position":[[1604,17]]}}}],["x^=concat[e([cls]),p′,e(s[eos])]\\hat{x",{"_index":4046,"t":{"1185":{"position":[[80,39]]}}}],["x^=concat[p′,e(s)]\\hat{x",{"_index":4057,"t":{"1187":{"position":[[244,25]]}}}],["x^\\hat{x}x",{"_index":3518,"t":{"988":{"position":[[583,11],[755,11]]},"1185":{"position":[[60,11],[316,11]]},"1693":{"position":[[277,11]]}}}],["x^n_p\\textup{",{"_index":451,"t":{"91":{"position":[[1648,16]]}}}],["x^∈rd\\hat{x",{"_index":3514,"t":{"988":{"position":[[496,12]]}}}],["x_0",{"_index":3764,"t":{"1099":{"position":[[108,4]]}}}],["x_1",{"_index":3765,"t":{"1099":{"position":[[113,4]]},"1350":{"position":[[145,6]]},"1477":{"position":[[229,4]]}}}],["x_2",{"_index":3892,"t":{"1128":{"position":[[1470,4]]},"1350":{"position":[[152,4]]},"1477":{"position":[[234,4]]}}}],["x_\\textup{class",{"_index":448,"t":{"91":{"position":[[1584,19]]}}}],["x_e",{"_index":3900,"t":{"1128":{"position":[[1810,4]]},"1477":{"position":[[584,4],[825,5]]}}}],["x_i",{"_index":2588,"t":{"723":{"position":[[222,5]]},"1065":{"position":[[64,4]]},"1238":{"position":[[127,6],[895,4]]},"1244":{"position":[[935,3],[982,3]]}}}],["x_n",{"_index":3766,"t":{"1099":{"position":[[125,3]]}}}],["x_n)(x1​,…,xn",{"_index":1163,"t":{"289":{"position":[[134,15]]},"310":{"position":[[74,15]]}}}],["x_n\\}x={x1​,x2​,…,xn",{"_index":4367,"t":{"1350":{"position":[[164,22]]},"1477":{"position":[[246,22]]}}}],["x_n\\}{x1​,x2​,…,xn",{"_index":3893,"t":{"1128":{"position":[[1483,20]]}}}],["x_{<t",{"_index":5576,"t":{"1778":{"position":[[550,7]]}}}],["x_{<t};x_{\\textup{diagnosis}}];\\theta)p(xt​∣[x<t​;xdiagnosi",{"_index":5579,"t":{"1778":{"position":[[663,66]]}}}],["x_{\\max",{"_index":606,"t":{"130":{"position":[[646,9]]}}}],["x_{\\min",{"_index":604,"t":{"130":{"position":[[626,9]]}}}],["x_{\\textup{class}}z00​=xclass",{"_index":427,"t":{"91":{"position":[[844,30]]}}}],["x_{\\textup{keypoint",{"_index":614,"t":{"130":{"position":[[1204,20],[1256,20]]}}}],["x_{i,j}lj​xi,j",{"_index":2156,"t":{"598":{"position":[[1103,15]]}}}],["xatt",{"_index":819,"t":{"172":{"position":[[319,5]]}}}],["xatt(fv,fp)fv′=fv+fp2v",{"_index":821,"t":{"172":{"position":[[437,23]]}}}],["xatt(fv​,fp​)fv′​=fv​+fp2v",{"_index":833,"t":{"172":{"position":[[635,28]]}}}],["xatt}(f_v",{"_index":826,"t":{"172":{"position":[[530,10]]}}}],["xe∈rn×ex_",{"_index":3894,"t":{"1128":{"position":[[1584,10]]},"1477":{"position":[[302,10]]}}}],["xf(x)=x∗x",{"_index":5564,"t":{"1770":{"position":[[662,10]]}}}],["xi,yi)(x_i",{"_index":269,"t":{"49":{"position":[[598,12]]},"630":{"position":[[1543,12]]}}}],["xi,zi∈rdx_i",{"_index":1278,"t":{"310":{"position":[[312,12]]}}}],["xia",{"_index":3089,"t":{"851":{"position":[[103,3]]}}}],["xiao",{"_index":2300,"t":{"648":{"position":[[871,5]]}}}],["xidx\\text{x}_{\\text{idx}}xidx",{"_index":4242,"t":{"1296":{"position":[[192,30]]}}}],["xix_ixi",{"_index":2591,"t":{"723":{"position":[[279,8]]},"1065":{"position":[[202,8]]}}}],["xj,yj)(x_j",{"_index":271,"t":{"49":{"position":[[627,12]]}}}],["xl",{"_index":2026,"t":{"567":{"position":[[576,2]]},"628":{"position":[[711,2]]},"633":{"position":[[229,2]]},"638":{"position":[[22,2]]},"644":{"position":[[114,2]]},"705":{"position":[[162,2]]},"994":{"position":[[639,2]]},"1107":{"position":[[793,2]]},"1134":{"position":[[68,3]]},"1136":{"position":[[666,2]]},"1143":{"position":[[757,2]]},"1413":{"position":[[20,3]]},"1496":{"position":[[183,3]]},"1499":{"position":[[278,2],[517,2]]},"1511":{"position":[[94,2]]}}}],["xlarg",{"_index":3637,"t":{"1043":{"position":[[42,6]]}}}],["xlarge/xxlarg",{"_index":3639,"t":{"1043":{"position":[[55,14]]}}}],["xlnet",{"_index":3751,"t":{"1093":{"position":[[392,6]]},"1471":{"position":[[139,6]]}}}],["xl⊙wx=(l⊙w)x",{"_index":2183,"t":{"598":{"position":[[2886,12]]}}}],["xl⊙x",{"_index":2144,"t":{"598":{"position":[[813,4],[1052,4]]}}}],["xnew=[p,x]x_{new",{"_index":2469,"t":{"688":{"position":[[164,17]]}}}],["xnew=[p,x]∈rd×(m+n)x_{new",{"_index":2465,"t":{"686":{"position":[[227,26]]}}}],["xp",{"_index":4324,"t":{"1314":{"position":[[383,2]]}}}],["xp1e",{"_index":443,"t":{"91":{"position":[[1521,5]]}}}],["xp1​e",{"_index":455,"t":{"91":{"position":[[1778,6]]}}}],["xpne]+epo",{"_index":445,"t":{"91":{"position":[[1540,11]]}}}],["xpn​e]+epo",{"_index":457,"t":{"91":{"position":[[1799,13]]}}}],["xprompt",{"_index":2541,"t":{"703":{"position":[[192,7]]},"707":{"position":[[131,7]]},"709":{"position":[[2412,7]]},"1466":{"position":[[412,9],[434,7]]},"1468":{"position":[[1380,9],[1401,7],[1574,7],[1648,7]]},"1477":{"position":[[1174,7]]},"1479":{"position":[[9,7]]},"1496":{"position":[[139,7]]},"1499":{"position":[[0,7],[143,7],[386,7],[504,7],[853,7]]},"1501":{"position":[[0,7],[210,7],[399,7]]},"1503":{"position":[[0,7]]},"1505":{"position":[[101,7],[491,7],[571,7],[692,7],[724,7],[734,7],[897,7],[944,7],[990,7]]},"1507":{"position":[[0,7],[187,7],[286,7]]},"1509":{"position":[[301,7]]},"1511":{"position":[[26,7],[65,7],[160,7],[222,7]]},"1513":{"position":[[92,7],[131,7],[223,7],[246,7],[279,7],[422,7],[495,7],[599,7]]},"1515":{"position":[[146,7]]},"1523":{"position":[[44,7],[81,7],[176,7],[358,7]]}}}],["xp​∈rn×(p2⋅c",{"_index":412,"t":{"91":{"position":[[263,15]]}}}],["xp∈rn×(p2⋅c)x_p",{"_index":407,"t":{"91":{"position":[[208,15]]}}}],["xsum",{"_index":2788,"t":{"786":{"position":[[4530,5]]},"805":{"position":[[119,5]]},"826":{"position":[[101,6]]},"833":{"position":[[92,5],[156,4]]},"1310":{"position":[[228,4]]},"1314":{"position":[[542,4]]},"1319":{"position":[[130,4],[196,4]]}}}],["xu",{"_index":978,"t":{"215":{"position":[[371,2]]},"868":{"position":[[128,3]]}}}],["xv(ϕw(w))\\mathcal{x}_v(\\phi_w(w))xv​(ϕw​(w",{"_index":2322,"t":{"658":{"position":[[1783,44]]}}}],["xv\\mathcal{x}_vxv",{"_index":2321,"t":{"658":{"position":[[1755,18]]}}}],["xw_1",{"_index":1249,"t":{"304":{"position":[[245,4]]}}}],["xxl",{"_index":2245,"t":{"628":{"position":[[15,4]]},"633":{"position":[[307,3]]},"640":{"position":[[227,3]]},"761":{"position":[[73,3]]},"1126":{"position":[[943,3]]},"1134":{"position":[[72,4]]},"1136":{"position":[[398,3]]},"1139":{"position":[[202,3]]},"1141":{"position":[[741,3]]},"1143":{"position":[[324,3],[629,3]]},"1149":{"position":[[607,3]]},"1409":{"position":[[872,3]]},"1413":{"position":[[24,3]]},"1423":{"position":[[1021,3],[1192,3],[1344,3],[1500,3]]},"1496":{"position":[[187,4]]},"1499":{"position":[[286,3],[557,3],[597,3]]}}}],["xxlarg",{"_index":3863,"t":{"1111":{"position":[[1837,7]]}}}],["xxx",{"_index":634,"t":{"132":{"position":[[899,3],[923,3]]},"441":{"position":[[139,3]]},"527":{"position":[[1039,3],[1092,3]]},"658":{"position":[[1380,3]]},"688":{"position":[[721,3]]},"982":{"position":[[532,3],[861,3]]},"984":{"position":[[236,3]]},"988":{"position":[[147,3],[424,3]]},"990":{"position":[[9,3],[608,3]]},"1128":{"position":[[196,3],[503,3]]},"1162":{"position":[[118,3]]},"1164":{"position":[[124,3]]},"1167":{"position":[[1258,3]]},"1294":{"position":[[6,3],[123,3],[203,3]]},"1296":{"position":[[177,3],[225,3]]},"1298":{"position":[[98,3],[188,3]]},"1303":{"position":[[308,3],[342,3]]},"1330":{"position":[[161,3],[342,3]]},"1558":{"position":[[928,3]]},"1659":{"position":[[494,3]]},"1693":{"position":[[76,3],[180,3]]},"1698":{"position":[[37,3],[273,3],[356,3],[523,3]]},"1702":{"position":[[6,3],[180,3],[255,3],[316,3]]},"1718":{"position":[[61,3],[180,3],[416,3]]},"1738":{"position":[[61,3]]},"1742":{"position":[[31,3]]}}}],["x~i=λxj+(1−λ)xi\\tilde{x}_i",{"_index":273,"t":{"49":{"position":[[679,26]]}}}],["xˉ∈re\\bar{x}\\in",{"_index":4389,"t":{"1352":{"position":[[599,15]]}}}],["x′x'x",{"_index":5395,"t":{"1693":{"position":[[230,6]]},"1702":{"position":[[56,6],[388,6]]},"1704":{"position":[[216,6]]}}}],["x∈rd×nx",{"_index":2463,"t":{"686":{"position":[[172,7]]}}}],["x∈rh×w×cx",{"_index":403,"t":{"91":{"position":[[119,9]]}}}],["x∈rl×dx",{"_index":3510,"t":{"988":{"position":[[282,7]]}}}],["x∈rn\\text{x",{"_index":3107,"t":{"853":{"position":[[129,12]]}}}],["x∈rn×dx",{"_index":2793,"t":{"789":{"position":[[152,7]]}}}],["x∈rt×dx",{"_index":2147,"t":{"598":{"position":[[932,7]]}}}],["x△x",{"_index":3013,"t":{"807":{"position":[[126,3]]}}}],["x⟩\\langl",{"_index":3916,"t":{"1132":{"position":[[391,10],[478,11]]}}}],["y",{"_index":3429,"t":{"945":{"position":[[591,1],[624,1]]},"984":{"position":[[632,3]]},"986":{"position":[[484,3]]},"1107":{"position":[[694,5]]},"1132":{"position":[[443,1],[527,1]]},"1164":{"position":[[365,3]]},"1167":{"position":[[1404,1]]},"1350":{"position":[[400,2],[726,2]]}}}],["y)(x,i",{"_index":3475,"t":{"982":{"position":[[504,7]]}}}],["y)rθ​(x,i",{"_index":4942,"t":{"1558":{"position":[[908,10]]}}}],["y,x)(i",{"_index":619,"t":{"130":{"position":[[1353,8]]}}}],["y1,…,ym)(y_1",{"_index":1167,"t":{"289":{"position":[[282,14]]}}}],["y=(y1,y2,…,yt)\\text{i",{"_index":2101,"t":{"596":{"position":[[287,22]]}}}],["y=head(zn)i",{"_index":2536,"t":{"698":{"position":[[122,11]]}}}],["y=ln(zl0)i",{"_index":474,"t":{"91":{"position":[[2428,10]]}}}],["y={yi}i=1ni",{"_index":1618,"t":{"441":{"position":[[172,11]]}}}],["y><z′,i",{"_index":5489,"t":{"1730":{"position":[[224,8]]}}}],["y\\mathcal{y}i",{"_index":5181,"t":{"1651":{"position":[[875,13]]},"1698":{"position":[[289,13],[394,13]]},"1704":{"position":[[162,13]]},"1722":{"position":[[76,13]]},"1726":{"position":[[88,13]]},"1728":{"position":[[50,13],[655,13]]}}}],["y\\text{y}i",{"_index":3775,"t":{"1099":{"position":[[380,10],[473,10],[563,10],[639,10]]}}}],["y][prefix;x;i",{"_index":4340,"t":{"1330":{"position":[[112,14]]}}}],["y][x;infix;i",{"_index":4343,"t":{"1330":{"position":[[209,14]]}}}],["y]z=[prefix;x;i",{"_index":4290,"t":{"1305":{"position":[[86,16]]}}}],["y]z=[prefix;x;prefix′;i",{"_index":4292,"t":{"1305":{"position":[[205,24]]}}}],["y]z=[x;i",{"_index":4241,"t":{"1296":{"position":[[163,9]]}}}],["y^(n)=(y^1,y^2,…,y^t(n)\\hat{\\text{y}}^{(n",{"_index":2113,"t":{"596":{"position":[[829,43]]}}}],["y^=arg",{"_index":1441,"t":{"350":{"position":[[873,6]]}}}],["y^\\hat{y}i",{"_index":1440,"t":{"350":{"position":[[846,12]]},"1700":{"position":[[117,12]]},"1706":{"position":[[52,12]]}}}],["y_1",{"_index":2102,"t":{"596":{"position":[[312,5]]}}}],["y_2",{"_index":2103,"t":{"596":{"position":[[318,4]]}}}],["y_i",{"_index":1619,"t":{"441":{"position":[[189,3]]},"723":{"position":[[228,4]]},"1065":{"position":[[69,3],[749,4]]},"1238":{"position":[[890,4]]},"1244":{"position":[[892,4],[929,3],[975,4],[1491,4]]}}}],["y_i)(xi​,yi",{"_index":270,"t":{"49":{"position":[[611,13]]},"630":{"position":[[1556,13]]}}}],["y_i\\}^n_{i=1}(x,y)={xi​,yi​}i=1n",{"_index":4115,"t":{"1238":{"position":[[134,33]]}}}],["y_j)(xj​,yj",{"_index":272,"t":{"49":{"position":[[640,13]]}}}],["y_l)))]loss(θ)=−(2k​)1​e(x,yw​,yl​)∼d​[log",{"_index":4939,"t":{"1558":{"position":[[817,44]]}}}],["y_m)(y1​,…,ym",{"_index":1168,"t":{"289":{"position":[[304,15]]}}}],["y_t",{"_index":2097,"t":{"596":{"position":[[171,4]]},"723":{"position":[[1294,4]]}}}],["y_t)y=(y1​,y2​,…,yt",{"_index":2104,"t":{"596":{"position":[[330,21]]}}}],["y_w",{"_index":4937,"t":{"1558":{"position":[[796,4]]}}}],["y_{<i},c,x)yi​=argmaxpθ​(yi​∣y<i​,c,x",{"_index":1626,"t":{"441":{"position":[[288,38]]}}}],["y_{<t",{"_index":2602,"t":{"723":{"position":[[583,8],[1304,8]]}}}],["y_{<t})llm​=−t1​∑t​logp(yt​∣x,y<t",{"_index":2099,"t":{"596":{"position":[[188,35]]}}}],["y_{<t},z)l=−∑t=1t",{"_index":1075,"t":{"236":{"position":[[197,19]]}}}],["y_{\\max",{"_index":605,"t":{"130":{"position":[[636,9]]}}}],["y_{\\textup{keypoint",{"_index":613,"t":{"130":{"position":[[1176,22],[1230,20]]}}}],["yang",{"_index":1003,"t":{"215":{"position":[[1786,4]]},"681":{"position":[[802,4]]},"683":{"position":[[33,5],[1097,5]]}}}],["ye",{"_index":3249,"t":{"866":{"position":[[180,5]]},"1778":{"position":[[453,5]]}}}],["yelp",{"_index":3578,"t":{"997":{"position":[[809,4],[818,4]]},"999":{"position":[[808,4]]},"1002":{"position":[[477,5]]},"1006":{"position":[[2337,4]]},"1070":{"position":[[255,4]]},"1253":{"position":[[306,4]]},"1429":{"position":[[1469,5]]}}}],["yi=arg⁡max⁡pθ(yi∣y<i,c,x)y_i",{"_index":1622,"t":{"441":{"position":[[230,28]]}}}],["yidx\\text{y}_{\\text{idx}}yidx",{"_index":4244,"t":{"1296":{"position":[[259,30]]}}}],["yiy_iyi",{"_index":2592,"t":{"723":{"position":[[290,8]]}}}],["ykeypoint",{"_index":609,"t":{"130":{"position":[[1125,10]]}}}],["yly_lyl",{"_index":4944,"t":{"1558":{"position":[[1003,8]]}}}],["ymin⁡,xmin⁡,ymax⁡,xmax⁡,c][y_{\\min",{"_index":603,"t":{"130":{"position":[[588,37]]}}}],["yn",{"_index":1579,"t":{"422":{"position":[[59,5]]}}}],["yosinki",{"_index":2448,"t":{"681":{"position":[[408,8]]}}}],["you'll",{"_index":126,"t":{"19":{"position":[[172,6]]}}}],["you'r",{"_index":122,"t":{"19":{"position":[[93,6]]}}}],["youtub",{"_index":892,"t":{"177":{"position":[[1262,7]]},"191":{"position":[[19,7],[183,7]]},"197":{"position":[[0,7]]},"199":{"position":[[4,7]]},"201":{"position":[[53,7],[70,7],[84,7]]}}}],["youtuv",{"_index":898,"t":{"177":{"position":[[1319,7]]}}}],["ywy_wyw",{"_index":4943,"t":{"1558":{"position":[[981,8],[992,8]]}}}],["yxy_xyx",{"_index":5308,"t":{"1659":{"position":[[558,8]]}}}],["yyi",{"_index":430,"t":{"91":{"position":[[940,3]]},"132":{"position":[[917,3],[955,3]]},"236":{"position":[[321,3]]},"982":{"position":[[868,3]]},"984":{"position":[[512,3]]},"1128":{"position":[[209,3],[299,3],[531,3],[1339,3],[1906,3]]},"1162":{"position":[[144,3]]},"1167":{"position":[[1282,3]]},"1294":{"position":[[29,3],[158,3],[220,3]]},"1296":{"position":[[183,3],[292,3]]},"1298":{"position":[[148,3]]},"1303":{"position":[[411,3]]},"1330":{"position":[[167,3],[348,3],[395,3]]},"1350":{"position":[[240,3]]},"1477":{"position":[[713,3]]},"1558":{"position":[[977,3]]},"1657":{"position":[[2346,3]]},"1693":{"position":[[94,3],[308,3]]},"1698":{"position":[[61,3],[113,3],[313,3],[460,3],[558,3]]},"1702":{"position":[[204,3]]},"1718":{"position":[[74,3],[186,3]]},"1728":{"position":[[243,3]]},"1730":{"position":[[636,3],[762,3]]}}}],["y|[p';x",{"_index":4034,"t":{"1167":{"position":[[1427,11]]}}}],["y|[p;x])prθ​(y∣[p;x",{"_index":3884,"t":{"1128":{"position":[[572,22]]}}}],["y|x",{"_index":4000,"t":{"1162":{"position":[[312,6]]}}}],["y|x)pr(y∣x",{"_index":3879,"t":{"1128":{"position":[[144,12]]}}}],["y|x)prθ​(y∣x",{"_index":3882,"t":{"1128":{"position":[[275,14]]}}}],["y|x)pϕ​(y∣x",{"_index":4365,"t":{"1350":{"position":[[59,13]]}}}],["y~i=λyj+(1−λ)yi\\tilde{y}_i",{"_index":276,"t":{"49":{"position":[[760,26]]}}}],["y⟩\\langl",{"_index":3918,"t":{"1132":{"position":[[432,10],[516,10]]}}}],["z",{"_index":3921,"t":{"1132":{"position":[[556,1]]},"1702":{"position":[[240,3],[377,3],[435,3],[458,3],[519,4],[595,1],[797,3]]},"1704":{"position":[[225,3],[574,3]]},"1718":{"position":[[158,4]]},"1730":{"position":[[805,3],[972,3]]},"1736":{"position":[[541,3]]},"1738":{"position":[[148,4],[190,4]]},"1766":{"position":[[127,5]]},"1768":{"position":[[809,3]]},"1770":{"position":[[331,3]]},"1774":{"position":[[142,5]]},"1778":{"position":[[436,3]]}}}],["z'_\\varrho,\\qquad",{"_index":472,"t":{"91":{"position":[[2327,17]]}}}],["z)ffill​(x′,z",{"_index":5420,"t":{"1704":{"position":[[271,14]]}}}],["z00=xclassz_{0}^{0",{"_index":426,"t":{"91":{"position":[[822,19]]}}}],["z1,…,zn)(z_1",{"_index":1276,"t":{"310":{"position":[[111,14]]}}}],["z1=l1(pi1,e)z^1",{"_index":2511,"t":{"694":{"position":[[495,15]]}}}],["z=(z1,…,zn)z",{"_index":1164,"t":{"289":{"position":[[188,12]]}}}],["z=[prefix;x;prefix′;y]z",{"_index":4291,"t":{"1305":{"position":[[144,23]]}}}],["z=[prefix;x;y]z",{"_index":4288,"t":{"1305":{"position":[[49,15]]}}}],["z=[x;y]z",{"_index":4240,"t":{"1296":{"position":[[148,8]]}}}],["z={(xi,yi)}i=1,…,n,\\mathcal{z",{"_index":2587,"t":{"723":{"position":[[186,30]]}}}],["z\\mathcal{z}z",{"_index":5416,"t":{"1704":{"position":[[97,13]]},"1708":{"position":[[303,13]]},"1722":{"position":[[48,13]]},"1726":{"position":[[17,13]]},"1728":{"position":[[30,13],[122,13],[633,13]]},"1766":{"position":[[613,13]]},"1768":{"position":[[850,13]]}}}],["z^=searchz∈z",{"_index":5423,"t":{"1704":{"position":[[468,12]]}}}],["z^\\hat{z}z",{"_index":5415,"t":{"1704":{"position":[[39,11]]},"1706":{"position":[[30,11]]}}}],["z^{j",{"_index":2516,"t":{"694":{"position":[[652,4]]}}}],["z_1",{"_index":1165,"t":{"289":{"position":[[203,5]]}}}],["z_i",{"_index":1279,"t":{"310":{"position":[[325,3]]},"1296":{"position":[[736,5]]},"1300":{"position":[[346,5]]}}}],["z_j/t)pj​=z1​exp(zj​/t",{"_index":4168,"t":{"1244":{"position":[[1236,24]]}}}],["z_n)(z1​,…,zn",{"_index":1277,"t":{"310":{"position":[[133,15]]}}}],["z_n)z=(z1​,…,zn",{"_index":1166,"t":{"289":{"position":[[216,17]]}}}],["z_{<t})p(zt​∣x,z<t​):=k1​∑ik​p(zt​∣fprompt",{"_index":5519,"t":{"1736":{"position":[[1480,43]]}}}],["z_{\\varrho",{"_index":463,"t":{"91":{"position":[[2035,10]]}}}],["zaheer",{"_index":2452,"t":{"683":{"position":[[70,6]]}}}],["zaken",{"_index":4448,"t":{"1379":{"position":[[1087,5]]}}}],["zer",{"_index":1388,"t":{"334":{"position":[[264,3]]}}}],["zero",{"_index":595,"t":{"126":{"position":[[759,5]]},"234":{"position":[[346,4]]},"244":{"position":[[165,4],[185,4]]},"251":{"position":[[25,4]]},"273":{"position":[[0,4]]},"370":{"position":[[24,4]]},"434":{"position":[[44,4],[97,4],[305,4]]},"436":{"position":[[251,4],[319,4],[430,4],[1297,4],[1669,4],[1808,4],[2118,4],[2254,4]]},"445":{"position":[[287,4],[333,4]]},"447":{"position":[[6,4],[481,4],[556,4],[912,4]]},"451":{"position":[[202,4]]},"461":{"position":[[3,4]]},"466":{"position":[[475,4]]},"468":{"position":[[57,4],[150,4]]},"471":{"position":[[10,4],[182,4]]},"475":{"position":[[262,4],[280,4]]},"477":{"position":[[86,4],[129,4]]},"483":{"position":[[754,4]]},"485":{"position":[[1606,4]]},"517":{"position":[[1078,4],[1266,4]]},"539":{"position":[[455,4]]},"544":{"position":[[31,4]]},"559":{"position":[[226,4]]},"565":{"position":[[73,4],[251,4]]},"569":{"position":[[238,4],[262,4],[672,4],[822,4],[1108,4]]},"571":{"position":[[126,4]]},"594":{"position":[[302,4],[580,4]]},"606":{"position":[[66,4],[102,4],[382,4]]},"662":{"position":[[1240,4]]},"676":{"position":[[965,4]]},"847":{"position":[[733,4],[806,4]]},"849":{"position":[[260,4],[438,4],[1704,4]]},"851":{"position":[[383,4],[433,4]]},"861":{"position":[[1264,4]]},"870":{"position":[[1666,4]]},"885":{"position":[[336,4],[370,4],[643,4]]},"887":{"position":[[523,4],[774,4],[1210,4]]},"893":{"position":[[174,4],[1552,4],[2426,4]]},"897":{"position":[[0,4]]},"899":{"position":[[121,4]]},"901":{"position":[[31,4],[78,4],[163,4]]},"907":{"position":[[154,4]]},"919":{"position":[[0,4],[62,4],[190,4]]},"926":{"position":[[76,4]]},"928":{"position":[[106,4]]},"934":{"position":[[205,4]]},"938":{"position":[[270,4]]},"945":{"position":[[16,4]]},"949":{"position":[[428,4],[519,4]]},"953":{"position":[[538,4]]},"973":{"position":[[171,4],[211,4],[409,4]]},"1111":{"position":[[1967,4]]},"1147":{"position":[[286,4],[971,4]]},"1153":{"position":[[187,4]]},"1232":{"position":[[182,4]]},"1730":{"position":[[1068,4]]},"1746":{"position":[[0,4],[132,4],[402,4]]},"1752":{"position":[[317,4]]},"1754":{"position":[[318,4]]}}}],["zeroth",{"_index":3119,"t":{"853":{"position":[[534,6]]}}}],["zeta",{"_index":4819,"t":{"1487":{"position":[[594,5]]}}}],["zeta_1",{"_index":4822,"t":{"1487":{"position":[[643,10]]}}}],["zeta_2",{"_index":4823,"t":{"1487":{"position":[[654,8]]}}}],["zeta_i",{"_index":4832,"t":{"1487":{"position":[[1000,9]]}}}],["zeta_k\\}ζ={ζ1​,ζ2​,…,ζk",{"_index":4824,"t":{"1487":{"position":[[670,26]]}}}],["zhang",{"_index":5379,"t":{"1682":{"position":[[36,6]]}}}],["zhao",{"_index":1966,"t":{"531":{"position":[[981,4]]},"683":{"position":[[91,4]]}}}],["zhou",{"_index":5340,"t":{"1665":{"position":[[572,4]]}}}],["zhu",{"_index":3147,"t":{"853":{"position":[[1860,4]]},"861":{"position":[[82,4]]}}}],["ziz_izi",{"_index":4169,"t":{"1244":{"position":[[1261,8]]},"1296":{"position":[[627,8]]}}}],["zj=lj(pij,zj−1)j=2,3,…,nz^j",{"_index":2514,"t":{"694":{"position":[[576,27]]}}}],["zjz^jzj",{"_index":2519,"t":{"694":{"position":[[712,7]]}}}],["zl0z_{l}^{0}zl0",{"_index":429,"t":{"91":{"position":[[912,16],[1016,16]]}}}],["znz^nzn",{"_index":2538,"t":{"698":{"position":[[173,7]]}}}],["zo=[xclass",{"_index":442,"t":{"91":{"position":[[1509,11]]}}}],["zoph",{"_index":2389,"t":{"670":{"position":[[858,4]]}}}],["zou",{"_index":982,"t":{"215":{"position":[[450,3]]}}}],["zuo",{"_index":4435,"t":{"1364":{"position":[[237,4]]},"1369":{"position":[[353,3]]}}}],["zzz",{"_index":1077,"t":{"236":{"position":[[276,3]]},"1244":{"position":[[1299,3]]},"1702":{"position":[[219,3]]},"1704":{"position":[[61,3],[238,3],[459,3]]},"1728":{"position":[[230,3]]},"1730":{"position":[[662,3],[778,3]]}}}],["zϱ=mlp(ln(zϱ′))+zϱ′,ϱ=1",{"_index":469,"t":{"91":{"position":[[2246,23]]}}}],["zϱ′=msa(ln(zϱ−1))+zϱ−1",{"_index":460,"t":{"91":{"position":[[1946,23]]}}}],["zϱ−1z_{\\varrho",{"_index":467,"t":{"91":{"position":[[2211,14]]}}}],["z′)(z')(z",{"_index":5491,"t":{"1730":{"position":[[251,12]]}}}],["z′,y><z",{"_index":5488,"t":{"1730":{"position":[[213,10]]}}}],["z′\\mathcal{z}'z",{"_index":5487,"t":{"1730":{"position":[[134,16],[540,16],[1039,16],[1088,16]]}}}],["z⟩\\langl",{"_index":3920,"t":{"1132":{"position":[[545,10]]}}}]],"pipeline":["stemmer"]}}]