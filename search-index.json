[{"documents":[{"i":1,"t":"","u":"/blog/archive","b":["Blog"]},{"i":2,"t":"First Blog Post","u":"/blog/first-blog-post","b":["Blog"]},{"i":4,"t":"Long Blog Post","u":"/blog/long-blog-post","b":["Blog"]},{"i":6,"t":"MDX Blog Post","u":"/blog/mdx-blog-post","b":["Blog"]},{"i":8,"t":"Welcome","u":"/blog/welcome","b":["Blog"]},{"i":10,"t":"Tutorial Intro","u":"/docs/intro","b":["Docs"]},{"i":20,"t":"Paper Summarize EfficientNetV2","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","b":["Docs","Paper","Computer Vision","Image Classification"]},{"i":81,"t":"An Image Is Worth 16X16 Words: Transformers for image recognition at sacle","u":"/docs/Paper/Computer Vision/Image Classification/ViT","b":["Docs","Paper","Computer Vision","Image Classification"]},{"i":121,"t":"A Unified Sequence Interface for Vision Tasks","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","b":["Docs","Paper","Computer Vision","Multi-task"]},{"i":160,"t":"Prismer: A Vision-Language Model with An Esemble of Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","b":["Docs","Paper","Computer Vision","Vision-Language"]},{"i":224,"t":"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","b":["Docs","Paper","NLP","Multi-Task"]},{"i":276,"t":"From Images to Textual Prompts: Zero-shot Visual Question Answering with Frozen Large Language Models","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","b":["Docs","Paper","Computer Vision","Vision-Language"]},{"i":325,"t":"CodeT5+: Open Code Large Language Models for Code Understanding and Generation","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","b":["Docs","Paper","NLP","Multi-Task"]},{"i":363,"t":"Scaling Instruction-Finetuned Language Models","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","b":["Docs","Paper","NLP","Multi-Task"]},{"i":413,"t":"Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning","u":"/docs/Paper/NLP/PEFT/IA³","b":["Docs","Paper","NLP","PEFT"]},{"i":452,"t":"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","b":["Docs","Paper","NLP","PEFT"]},{"i":499,"t":"LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","b":["Docs","Paper","NLP","PEFT"]},{"i":544,"t":"LoRA: Low-Rank Adaptation of Large Language Models","u":"/docs/Paper/NLP/PEFT/LoRA","b":["Docs","Paper","NLP","PEFT"]},{"i":611,"t":"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","b":["Docs","Paper","NLP","PEFT"]},{"i":675,"t":"GPT Understands, Too","u":"/docs/Paper/NLP/PEFT/P-tuning","b":["Docs","Paper","NLP","PEFT"]},{"i":708,"t":"P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks","u":"/docs/Paper/NLP/PEFT/P-tuning v2","b":["Docs","Paper","NLP","PEFT"]},{"i":756,"t":"Prefix-Tuning: Optimizing Continuous Prompts for Generation","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","b":["Docs","Paper","NLP","PEFT"]},{"i":812,"t":"The Power of Scale for Parameter-Efficient Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","b":["Docs","Paper","NLP","PEFT"]},{"i":845,"t":"Reflexion: Language Agents with Verbal Reinforcement Learning","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","b":["Docs","Paper","NLP","Reinforcement Learning"]},{"i":871,"t":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing","u":"/docs/Paper/NLP/Survey/Prompting","b":["Docs","Paper","NLP","Survey"]},{"i":984,"t":"Training language models to follow instructions with human feedback (+ ChatGPT)","u":"/docs/Paper/NLP/Text Generation/InstructGPT","b":["Docs","Paper","NLP","Text Generation"]},{"i":1023,"t":"Congratulations!","u":"/docs/tutorial-basics/congratulations","b":["Docs","Tutorial - Basics"]},{"i":1027,"t":"Create a Blog Post","u":"/docs/tutorial-basics/create-a-blog-post","b":["Docs","Tutorial - Basics"]},{"i":1031,"t":"Create a Document","u":"/docs/tutorial-basics/create-a-document","b":["Docs","Tutorial - Basics"]},{"i":1037,"t":"Create a Page","u":"/docs/tutorial-basics/create-a-page","b":["Docs","Tutorial - Basics"]},{"i":1043,"t":"Deploy your site","u":"/docs/tutorial-basics/deploy-your-site","b":["Docs","Tutorial - Basics"]},{"i":1048,"t":"Markdown Features","u":"/docs/tutorial-basics/markdown-features","b":["Docs","Tutorial - Basics"]},{"i":1062,"t":"Manage Docs Versions","u":"/docs/tutorial-extras/manage-docs-versions","b":["Docs","Tutorial - Extras"]},{"i":1070,"t":"Translate your site","u":"/docs/tutorial-extras/translate-your-site","b":["Docs","Tutorial - Extras"]},{"i":1082,"t":"UNINEXT: Universal Instance Perception as Object Discovery and Retrieval","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","b":["Docs","Paper","Computer Vision","Multi-task"]},{"i":1132,"t":"Adaptive Budget Allocation For Parameter-Efficient Fine-Tuning","u":"/docs/Paper/NLP/PEFT/AdaLoRA","b":["Docs","Paper","NLP","PEFT"]},{"i":1195,"t":"Unsupervised Prompt Learning for Vision-Language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","b":["Docs","Paper","Computer Vision","Vision-Language"]}],"index":{"version":"2.3.9","fields":["t"],"fieldVectors":[["t/1",[]],["t/2",[0,3.946,1,2.605,2,2.605]],["t/4",[1,2.605,2,2.605,3,3.946]],["t/6",[1,2.605,2,2.605,4,3.946]],["t/8",[5,4.846]],["t/10",[6,4.35,7,4.35]],["t/20",[8,3.946,9,3.946,10,3.946]],["t/81",[11,3.291,12,2.695,13,2.695,14,2.695,15,2.695,16,2.695,17,2.695]],["t/121",[18,3.328,19,3.328,20,3.328,21,2.455,22,2.802]],["t/160",[21,2.277,23,3.086,24,1.141,25,1.228,26,3.086,27,3.086]],["t/224",[24,0.997,25,1.072,28,2.695,29,2.695,30,1.249,31,2.695,32,2.695,33,1.779]],["t/276",[11,1.81,24,0.795,25,0.855,30,0.996,33,1.419,34,2.15,35,1.81,36,1.81,37,1.81,38,2.15,39,2.15,40,2.15]],["t/325",[24,0.937,25,1.008,33,1.673,41,2.534,42,2.534,43,3.737,44,2.134,45,2.134]],["t/363",[24,1.231,25,1.324,46,2.455,47,2.455,48,3.328]],["t/413",[36,2.013,49,2.391,50,1.43,51,1.307,52,1.579,53,1.201,54,2.391,55,2.391,56,2.391,57,1.579]],["t/452",[24,0.884,25,0.952,35,2.013,51,1.307,52,1.579,53,1.201,58,2.013,59,1.579,60,2.391,61,2.391]],["t/499",[25,1.072,37,2.269,47,1.988,50,1.611,51,1.472,58,2.269,59,1.779,62,2.269]],["t/544",[24,1.064,25,1.145,33,1.899,59,1.899,63,2.877,64,2.877,65,2.877]],["t/611",[30,1.249,50,1.611,51,1.472,53,1.353,57,1.779,66,2.695,67,2.695,68,2.695]],["t/675",[44,3.662,69,4.35]],["t/708",[22,1.906,30,1.049,46,1.671,52,1.494,53,2.083,62,1.906,70,2.264,71,2.264,72,1.906]],["t/756",[30,1.43,45,2.598,53,1.549,73,3.086,74,3.086,75,3.086]],["t/812",[30,1.43,46,2.277,50,1.846,51,1.686,53,1.549,76,3.086]],["t/845",[24,1.141,57,2.037,77,3.086,78,3.086,79,3.086,80,3.086]],["t/871",[24,0.837,30,1.591,81,2.264,82,1.906,83,2.264,84,2.264,85,2.264,86,2.264,87,2.264,88,2.264]],["t/984",[24,0.937,25,1.008,47,1.87,82,2.134,89,2.534,90,2.534,91,2.534,92,2.534,93,2.534]],["t/1023",[94,4.846]],["t/1027",[1,2.605,2,2.605,95,2.912]],["t/1031",[95,3.21,96,4.35]],["t/1037",[95,3.21,97,4.35]],["t/1043",[98,4.35,99,3.662]],["t/1048",[100,4.35,101,4.35]],["t/1062",[102,3.946,103,3.946,104,3.946]],["t/1070",[99,3.662,105,4.35]],["t/1082",[72,2.422,106,2.877,107,2.877,108,2.877,109,2.877,110,2.877,111,2.877]],["t/1132",[50,1.721,51,1.572,52,1.899,53,1.445,59,1.899,112,2.877,113,2.877]],["t/1195",[21,2.277,24,1.141,25,1.228,30,1.43,57,2.037,114,3.086]]],"invertedIndex":[["",{"_index":92,"t":{"984":{"position":[[68,2]]}}}],["16x16",{"_index":13,"t":{"81":{"position":[[18,5]]}}}],["adapt",{"_index":59,"t":{"452":{"position":[[6,8]]},"499":{"position":[[6,7]]},"544":{"position":[[15,10]]},"1132":{"position":[[0,8]]}}}],["agent",{"_index":78,"t":{"845":{"position":[[20,6]]}}}],["alloc",{"_index":113,"t":{"1132":{"position":[[16,10]]}}}],["answer",{"_index":39,"t":{"276":{"position":[[58,9]]}}}],["attent",{"_index":61,"t":{"452":{"position":[[71,9]]}}}],["better",{"_index":54,"t":{"413":{"position":[[44,6]]}}}],["blog",{"_index":1,"t":{"2":{"position":[[6,4]]},"4":{"position":[[5,4]]},"6":{"position":[[4,4]]},"1027":{"position":[[9,4]]}}}],["budget",{"_index":112,"t":{"1132":{"position":[[9,6]]}}}],["chain",{"_index":28,"t":{"224":{"position":[[0,5]]}}}],["chatgpt",{"_index":93,"t":{"984":{"position":[[71,8]]}}}],["cheaper",{"_index":55,"t":{"413":{"position":[[55,7]]}}}],["code",{"_index":43,"t":{"325":{"position":[[14,4],[45,4]]}}}],["codet5",{"_index":41,"t":{"325":{"position":[[0,8]]}}}],["compar",{"_index":71,"t":{"708":{"position":[[34,10]]}}}],["congratul",{"_index":94,"t":{"1023":{"position":[[0,16]]}}}],["context",{"_index":56,"t":{"413":{"position":[[71,7]]}}}],["continu",{"_index":75,"t":{"756":{"position":[[26,10]]}}}],["creat",{"_index":95,"t":{"1027":{"position":[[0,6]]},"1031":{"position":[[0,6]]},"1037":{"position":[[0,6]]}}}],["deploy",{"_index":98,"t":{"1043":{"position":[[0,6]]}}}],["discoveri",{"_index":110,"t":{"1082":{"position":[[49,9]]}}}],["doc",{"_index":103,"t":{"1062":{"position":[[7,4]]}}}],["document",{"_index":96,"t":{"1031":{"position":[[9,8]]}}}],["effici",{"_index":51,"t":{"413":{"position":[[19,9]]},"452":{"position":[[15,9]]},"499":{"position":[[28,9]]},"611":{"position":[[42,9]]},"812":{"position":[[33,9]]},"1132":{"position":[[41,9]]}}}],["efficientnetv2",{"_index":10,"t":{"20":{"position":[[16,14]]}}}],["elicit",{"_index":31,"t":{"224":{"position":[[27,7]]}}}],["enabl",{"_index":67,"t":{"611":{"position":[[24,7]]}}}],["esembl",{"_index":26,"t":{"160":{"position":[[41,7]]}}}],["expert",{"_index":27,"t":{"160":{"position":[[52,7]]}}}],["featur",{"_index":101,"t":{"1048":{"position":[[9,8]]}}}],["feedback",{"_index":91,"t":{"984":{"position":[[59,8]]}}}],["few",{"_index":49,"t":{"413":{"position":[[0,3]]}}}],["fine",{"_index":52,"t":{"413":{"position":[[29,4]]},"452":{"position":[[25,4]]},"708":{"position":[[48,4]]},"1132":{"position":[[51,4]]}}}],["finetun",{"_index":48,"t":{"363":{"position":[[20,9]]}}}],["first",{"_index":0,"t":{"2":{"position":[[0,5]]}}}],["follow",{"_index":89,"t":{"984":{"position":[[28,6]]}}}],["frozen",{"_index":40,"t":{"276":{"position":[[73,6]]}}}],["gener",{"_index":45,"t":{"325":{"position":[[68,10]]},"756":{"position":[[49,10]]}}}],["gpt",{"_index":69,"t":{"675":{"position":[[0,3]]}}}],["human",{"_index":90,"t":{"984":{"position":[[53,5]]}}}],["imag",{"_index":11,"t":{"81":{"position":[[3,5],[48,5]]},"276":{"position":[[5,6]]}}}],["init",{"_index":60,"t":{"452":{"position":[[66,4]]}}}],["instanc",{"_index":107,"t":{"1082":{"position":[[19,8]]}}}],["instruct",{"_index":47,"t":{"363":{"position":[[8,11]]},"499":{"position":[[45,11]]},"984":{"position":[[35,12]]}}}],["interfac",{"_index":20,"t":{"121":{"position":[[19,9]]}}}],["intro",{"_index":7,"t":{"10":{"position":[[9,5]]}}}],["languag",{"_index":24,"t":{"160":{"position":[[18,8]]},"224":{"position":[[54,8]]},"276":{"position":[[86,8]]},"325":{"position":[[25,8]]},"363":{"position":[[30,8]]},"452":{"position":[[40,8]]},"544":{"position":[[35,8]]},"845":{"position":[[11,8]]},"871":{"position":[[84,8]]},"984":{"position":[[9,8]]},"1195":{"position":[[40,8]]}}}],["larg",{"_index":33,"t":{"224":{"position":[[48,5]]},"276":{"position":[[80,5]]},"325":{"position":[[19,5]]},"544":{"position":[[29,5]]}}}],["learn",{"_index":57,"t":{"413":{"position":[[79,8]]},"611":{"position":[[61,8]]},"845":{"position":[[53,8]]},"1195":{"position":[[20,8]]}}}],["llama",{"_index":58,"t":{"452":{"position":[[0,5]]},"499":{"position":[[0,5]]}}}],["long",{"_index":3,"t":{"4":{"position":[[0,4]]}}}],["lora",{"_index":63,"t":{"544":{"position":[[0,5]]}}}],["low",{"_index":64,"t":{"544":{"position":[[6,3]]}}}],["manag",{"_index":102,"t":{"1062":{"position":[[0,6]]}}}],["markdown",{"_index":100,"t":{"1048":{"position":[[0,8]]}}}],["mdx",{"_index":4,"t":{"6":{"position":[[0,3]]}}}],["method",{"_index":86,"t":{"871":{"position":[[65,7]]}}}],["model",{"_index":25,"t":{"160":{"position":[[27,5]]},"224":{"position":[[63,6]]},"276":{"position":[[95,6]]},"325":{"position":[[34,6]]},"363":{"position":[[39,6]]},"452":{"position":[[49,6]]},"499":{"position":[[57,5]]},"544":{"position":[[44,6]]},"984":{"position":[[18,6]]},"1195":{"position":[[49,6]]}}}],["multitask",{"_index":66,"t":{"611":{"position":[[0,9]]}}}],["natur",{"_index":87,"t":{"871":{"position":[[76,7]]}}}],["object",{"_index":109,"t":{"1082":{"position":[[42,6]]}}}],["open",{"_index":42,"t":{"325":{"position":[[9,4]]}}}],["optim",{"_index":74,"t":{"756":{"position":[[15,10]]}}}],["p",{"_index":70,"t":{"708":{"position":[[0,1]]}}}],["page",{"_index":97,"t":{"1037":{"position":[[9,4]]}}}],["paper",{"_index":8,"t":{"20":{"position":[[0,5]]}}}],["paramet",{"_index":50,"t":{"413":{"position":[[9,9]]},"499":{"position":[[18,9]]},"611":{"position":[[32,9]]},"812":{"position":[[23,9]]},"1132":{"position":[[31,9]]}}}],["percept",{"_index":108,"t":{"1082":{"position":[[28,10]]}}}],["post",{"_index":2,"t":{"2":{"position":[[11,4]]},"4":{"position":[[10,4]]},"6":{"position":[[9,4]]},"1027":{"position":[[14,4]]}}}],["power",{"_index":76,"t":{"812":{"position":[[4,5]]}}}],["pre",{"_index":81,"t":{"871":{"position":[[0,3]]}}}],["predict",{"_index":83,"t":{"871":{"position":[[23,8]]}}}],["prefix",{"_index":73,"t":{"756":{"position":[[0,6]]}}}],["prismer",{"_index":23,"t":{"160":{"position":[[0,8]]}}}],["process",{"_index":88,"t":{"871":{"position":[[93,10]]}}}],["prompt",{"_index":30,"t":{"224":{"position":[[17,9]]},"276":{"position":[[23,8]]},"611":{"position":[[10,6]]},"708":{"position":[[13,6]]},"756":{"position":[[37,7]]},"812":{"position":[[43,6]]},"871":{"position":[[11,7],[55,9]]},"1195":{"position":[[13,6]]}}}],["question",{"_index":38,"t":{"276":{"position":[[49,8]]}}}],["rank",{"_index":65,"t":{"544":{"position":[[10,4]]}}}],["reason",{"_index":32,"t":{"224":{"position":[[35,9]]}}}],["recognit",{"_index":16,"t":{"81":{"position":[[54,11]]}}}],["reflexion",{"_index":77,"t":{"845":{"position":[[0,10]]}}}],["reinforc",{"_index":80,"t":{"845":{"position":[[39,13]]}}}],["retriev",{"_index":111,"t":{"1082":{"position":[[63,9]]}}}],["sacl",{"_index":17,"t":{"81":{"position":[[69,5]]}}}],["scale",{"_index":46,"t":{"363":{"position":[[0,7]]},"708":{"position":[[79,6]]},"812":{"position":[[13,5]]}}}],["sequenc",{"_index":19,"t":{"121":{"position":[[10,8]]}}}],["shot",{"_index":36,"t":{"276":{"position":[[37,4]]},"413":{"position":[[4,4]]}}}],["site",{"_index":99,"t":{"1043":{"position":[[12,4]]},"1070":{"position":[[15,4]]}}}],["summar",{"_index":9,"t":{"20":{"position":[[6,9]]}}}],["survey",{"_index":85,"t":{"871":{"position":[[45,6]]}}}],["systemat",{"_index":84,"t":{"871":{"position":[[34,10]]}}}],["task",{"_index":22,"t":{"121":{"position":[[40,5]]},"708":{"position":[[90,5]]}}}],["textual",{"_index":34,"t":{"276":{"position":[[15,7]]}}}],["thought",{"_index":29,"t":{"224":{"position":[[9,7]]}}}],["train",{"_index":82,"t":{"871":{"position":[[4,6]]},"984":{"position":[[0,8]]}}}],["transfer",{"_index":68,"t":{"611":{"position":[[52,8]]}}}],["transform",{"_index":15,"t":{"81":{"position":[[31,12]]}}}],["translat",{"_index":105,"t":{"1070":{"position":[[0,9]]}}}],["tune",{"_index":53,"t":{"413":{"position":[[34,6]]},"452":{"position":[[30,6]]},"611":{"position":[[17,6]]},"708":{"position":[[2,6],[20,6],[53,6]]},"756":{"position":[[7,7]]},"812":{"position":[[50,6]]},"1132":{"position":[[56,6]]}}}],["tutori",{"_index":6,"t":{"10":{"position":[[0,8]]}}}],["understand",{"_index":44,"t":{"325":{"position":[[50,13]]},"675":{"position":[[4,12]]}}}],["unifi",{"_index":18,"t":{"121":{"position":[[2,7]]}}}],["uninext",{"_index":106,"t":{"1082":{"position":[[0,8]]}}}],["univers",{"_index":72,"t":{"708":{"position":[[60,11]]},"1082":{"position":[[9,9]]}}}],["unsupervis",{"_index":114,"t":{"1195":{"position":[[0,12]]}}}],["v2",{"_index":62,"t":{"499":{"position":[[14,3]]},"708":{"position":[[9,3]]}}}],["verbal",{"_index":79,"t":{"845":{"position":[[32,6]]}}}],["version",{"_index":104,"t":{"1062":{"position":[[12,8]]}}}],["vision",{"_index":21,"t":{"121":{"position":[[33,6]]},"160":{"position":[[11,6]]},"1195":{"position":[[33,6]]}}}],["visual",{"_index":37,"t":{"276":{"position":[[42,6]]},"499":{"position":[[38,6]]}}}],["welcom",{"_index":5,"t":{"8":{"position":[[0,7]]}}}],["word",{"_index":14,"t":{"81":{"position":[[24,6]]}}}],["worth",{"_index":12,"t":{"81":{"position":[[12,5]]}}}],["zero",{"_index":35,"t":{"276":{"position":[[32,4]]},"452":{"position":[[61,4]]}}}]],"pipeline":["stemmer"]}},{"documents":[{"i":12,"t":"Getting Started","u":"/docs/intro","h":"#getting-started","p":10},{"i":14,"t":"What you'll need","u":"/docs/intro","h":"#what-youll-need","p":10},{"i":16,"t":"Generate a new site","u":"/docs/intro","h":"#generate-a-new-site","p":10},{"i":18,"t":"Start your site","u":"/docs/intro","h":"#start-your-site","p":10},{"i":22,"t":"개요","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":24,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":26,"t":"2. Related Work","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":28,"t":"3. EfficientNetV2 Architecture Design","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":29,"t":"Understanding Training Efficiency","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#understanding-training-efficiency","p":20},{"i":30,"t":"Training with very large image sizes is slow","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#training-with-very-large-image-sizes-is-slow","p":20},{"i":32,"t":"Depthwise convolutions are slow in early layers but effective in later stages","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#depthwise-convolutions-are-slow-in-early-layers-but-effective-in-later-stages","p":20},{"i":34,"t":"Equally scailing up every stage is sub-optimal","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#equally-scailing-up-every-stage-is-sub-optimal","p":20},{"i":36,"t":"Training-Aware NAS and Scailing","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#training-aware-nas-and-scailing","p":20},{"i":37,"t":"NAS Search","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#nas-search","p":20},{"i":39,"t":"EfficientNetV2 Architecture","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#efficientnetv2-architecture","p":20},{"i":41,"t":"EfficientNetV2 Scailing","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#efficientnetv2-scailing","p":20},{"i":43,"t":"Training Speed Comparison","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#training-speed-comparison","p":20},{"i":45,"t":"4. Progressive Learning","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":46,"t":"Motivation","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#motivation","p":20},{"i":48,"t":"Progressive Learning with adaptive Regularization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#progressive-learning-with-adaptive-regularization","p":20},{"i":50,"t":"5. Main Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":51,"t":"ImageNet ILSVRC2012","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#imagenet-ilsvrc2012","p":20},{"i":52,"t":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup","p":20},{"i":54,"t":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results","p":20},{"i":56,"t":"ImageNet21k","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#imagenet21k","p":20},{"i":57,"t":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup-1","p":20},{"i":59,"t":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results-1","p":20},{"i":61,"t":"Transfer Learning Datasets","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#transfer-learning-datasets","p":20},{"i":62,"t":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup-2","p":20},{"i":64,"t":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results-2","p":20},{"i":66,"t":"6. Ablation Studies","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":67,"t":"Comparison to EfficientNet","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#comparison-to-efficientnet","p":20},{"i":69,"t":"Performance with the same training","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#performance-with-the-same-training","p":20},{"i":70,"t":"Scailing Down","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#scailing-down","p":20},{"i":71,"t":"Progressive Learning for Different Networks","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#progressive-learning-for-different-networks","p":20},{"i":73,"t":"Importance of Adaptive Regularization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#importance-of-adaptive-regularization","p":20},{"i":75,"t":"7. Conclusion","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":77,"t":"Summarization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":79,"t":"Experiments","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":83,"t":"Abstract","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":85,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":87,"t":"2. Related Work","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":89,"t":"3. Method","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":90,"t":"3.1 Vision Transformer (ViT)","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#31-vision-transformer-vit","p":81},{"i":92,"t":"Intuctive bias","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#intuctive-bias","p":81},{"i":94,"t":"Hybris Architecture","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#hybris-architecture","p":81},{"i":96,"t":"3.2 fine-tuning and higher resolution","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#32-fine-tuning-and-higher-resolution","p":81},{"i":98,"t":"4. Experiments","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":100,"t":"4.1 Setup","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#41-setup","p":81},{"i":101,"t":"Datasets","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#datasets","p":81},{"i":103,"t":"Model Variants","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#model-variants","p":81},{"i":105,"t":"Training & Fine-tuning","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#training--fine-tuning","p":81},{"i":107,"t":"Metrics","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#metrics","p":81},{"i":109,"t":"4.2 Comparison to State Of The Art","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#42-comparison-to-state-of-the-art","p":81},{"i":111,"t":"4.3 Pre-trained Data Requirements","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#43-pre-trained-data-requirements","p":81},{"i":113,"t":"4.4 Scailing Study","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#44-scailing-study","p":81},{"i":115,"t":"4.5 Inspecting Vision Transformer","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#45-inspecting-vision-transformer","p":81},{"i":117,"t":"4.6 self-supervision","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#46-self-supervision","p":81},{"i":119,"t":"5. Conclusion","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#5-conclusion","p":81},{"i":123,"t":"Abstract","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":125,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":127,"t":"2. Approach","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":129,"t":"2.1 A unified interface with tokenization","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#21-a-unified-interface-with-tokenization","p":121},{"i":131,"t":"2.2 Unified architecture and objective function","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#22-unified-architecture-and-objective-function","p":121},{"i":133,"t":"2.3 Training","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#23-training","p":121},{"i":135,"t":"Data mixing","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#data-mixing","p":121},{"i":137,"t":"Batch mixing","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#batch-mixing","p":121},{"i":139,"t":"2.4 Inference and de-tokenization","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#24-inference-and-de-tokenization","p":121},{"i":141,"t":"3. Experiments","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":142,"t":"3.1 Experimental settings and implementation details","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#31-experimental-settings-and-implementation-details","p":121},{"i":144,"t":"Object detection","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#object-detection","p":121},{"i":146,"t":"Instance segmentation","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#instance-segmentation","p":121},{"i":148,"t":"Keypoint detection","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#keypoint-detection","p":121},{"i":150,"t":"Four-tasks joint training","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#four-tasks-joint-training","p":121},{"i":152,"t":"Baselines","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#baselines","p":121},{"i":154,"t":"3.2 Quantitative results","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#32-quantitative-results","p":121},{"i":156,"t":"3.3 Qualitative results","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#33-qualitative-results","p":121},{"i":158,"t":"5. Conclusion","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":162,"t":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":164,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":166,"t":"2. Related Work","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":167,"t":"3. Prismer: Open-ended Reasoning with Multi-modal Knowledge","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":168,"t":"3.1 Model Overview","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#31-model-overview","p":160},{"i":170,"t":"3.2 Pre-trained Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#32-pre-trained-experts","p":160},{"i":172,"t":"3.3 Key Architectural Components","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#33-key-architectural-components","p":160},{"i":173,"t":"Modality-Specific Convolutional Stem","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#modality-specific-convolutional-stem","p":160},{"i":175,"t":"Experts Resampler","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#experts-resampler","p":160},{"i":177,"t":"Lightweight Adaptor","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#lightweight-adaptor","p":160},{"i":179,"t":"3.4 Training Objective","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#34-training-objective","p":160},{"i":181,"t":"4. Experiments","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":182,"t":"4.1 Prismer Model Variants","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#41-prismer-model-variants","p":160},{"i":184,"t":"4.2 Training and Evaluation Details","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#42-training-and-evaluation-details","p":160},{"i":185,"t":"Pre-training Datasets","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#pre-training-datasets","p":160},{"i":187,"t":"Optimisation and Implementation","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#optimisation-and-implementation","p":160},{"i":189,"t":"Evalution Setting","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#evalution-setting","p":160},{"i":191,"t":"4.3 Results on Vision-Language Benchmarks","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#43-results-on-vision-language-benchmarks","p":160},{"i":192,"t":"Fine-tuned Performance COCO Caption, NoCaps and VQAv2","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#fine-tuned-performance-coco-caption-nocaps-and-vqav2","p":160},{"i":194,"t":"Zero-shot Performance on Image Captioning","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#zero-shot-performance-on-image-captioning","p":160},{"i":196,"t":"Few-shot Performance on ImageNet Classification","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#few-shot-performance-on-imagenet-classification","p":160},{"i":198,"t":"5. Additional Analysis","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":200,"t":"5.1 Intriguing Properties of Prismer","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#51-intriguing-properties-of-prismer","p":160},{"i":201,"t":"More Experts, Better Performance","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#more-experts-better-performance","p":160},{"i":203,"t":"Better Experts, Better Performance","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#better-experts-better-performance","p":160},{"i":205,"t":"Robustness to Noisy Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#robustness-to-noisy-experts","p":160},{"i":207,"t":"5.2 Architecture Design and Training Details","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#52-architecture-design-and-training-details","p":160},{"i":208,"t":"Adaptor Design and Size","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#adaptor-design-and-size","p":160},{"i":210,"t":"Resampler Design and Multi-modal Sampling Strategy","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#resampler-design-and-multi-modal-sampling-strategy","p":160},{"i":212,"t":"The Effect of Frozen Backbones","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#the-effect-of-frozen-backbones","p":160},{"i":214,"t":"6. Conclusions, Limitations and Discussion","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":216,"t":"Multi-modal In-context Learning","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#multi-modal-in-context-learning","p":160},{"i":218,"t":"Zero-shot Adaptation on New Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#zero-shot-adaptation-on-new-experts","p":160},{"i":220,"t":"Free-form Inference on Partial Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#free-form-inference-on-partial-experts","p":160},{"i":222,"t":"Representation of Expert Knowledge","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#representation-of-expert-knowledge","p":160},{"i":226,"t":"Abstract","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":228,"t":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":230,"t":"2. Chain-of-Thought Prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":232,"t":"3. Arithmetic Reasoning","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":234,"t":"3.1. Experimental Steup","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#31-experimental-steup","p":224},{"i":235,"t":"Benchmarks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#benchmarks","p":224},{"i":237,"t":"Standard prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#standard-prompting","p":224},{"i":239,"t":"Chain-of-thought prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#chain-of-thought-prompting","p":224},{"i":241,"t":"Language models","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#language-models","p":224},{"i":243,"t":"3.2. Results","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#32-results","p":224},{"i":245,"t":"3.3. Ablation Study","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#33-ablation-study","p":224},{"i":247,"t":"Equation only","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#equation-only","p":224},{"i":249,"t":"Variable compute only","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#variable-compute-only","p":224},{"i":251,"t":"Chain of thought after answer","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#chain-of-thought-after-answer","p":224},{"i":253,"t":"3.4. Robustness of Chain of Thought","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#34-robustness-of-chain-of-thought","p":224},{"i":255,"t":"4. Commonsense Reasoning","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":256,"t":"Benchmarks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#benchmarks-1","p":224},{"i":258,"t":"Prompts","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#prompts","p":224},{"i":260,"t":"Results","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#results","p":224},{"i":262,"t":"5. Symbolic Reasoning","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":264,"t":"Tasks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#tasks","p":224},{"i":266,"t":"Last letter concatenation","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#last-letter-concatenation","p":224},{"i":268,"t":"Coin flip","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#coin-flip","p":224},{"i":270,"t":"6. Discussion","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":272,"t":"7. Related Work","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":274,"t":"8. Conclusions","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":278,"t":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":280,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":282,"t":"2. Related Work","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":283,"t":"2.1 Recent Advances in VQA Method","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#21-recent-advances-in-vqa-method","p":276},{"i":285,"t":"2.2 LLM for Zero/Few-Shot VQA Tasks","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#22-llm-for-zerofew-shot-vqa-tasks","p":276},{"i":287,"t":"Multi-modal pretraining","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#multi-modal-pretraining","p":276},{"i":289,"t":"Language-mediated VQA","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#language-mediated-vqa","p":276},{"i":291,"t":"3. Method","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":293,"t":"3.1 Answer Extraction","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#31-answer-extraction","p":276},{"i":295,"t":"3.2 Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#32-question-generation","p":276},{"i":297,"t":"Template-based Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#template-based-question-generation","p":276},{"i":299,"t":"Neural Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#neural-question-generation","p":276},{"i":301,"t":"3.3 Question-relevant Caption Prompt","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#33-question-relevant-caption-prompt","p":276},{"i":303,"t":"3.4 Prompt Design","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#34-prompt-design","p":276},{"i":305,"t":"4. Experiment","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":307,"t":"4.1 Enviroment Setup","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#41-enviroment-setup","p":276},{"i":308,"t":"Datasets","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#datasets","p":276},{"i":310,"t":"Implementation details","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#implementation-details","p":276},{"i":312,"t":"Competing methods","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#competing-methods","p":276},{"i":314,"t":"4.2 Main Results","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#42-main-results","p":276},{"i":315,"t":"SOTA results on zero-shot evaluation with plug-in frozen LLMs","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#sota-results-on-zero-shot-evaluation-with-plug-in-frozen-llms","p":276},{"i":317,"t":"Scaling effect of LLMs and their emergent capabilities on VQA","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#scaling-effect-of-llms-and-their-emergent-capabilities-on-vqa","p":276},{"i":319,"t":"Competitive performance with end-to-end pretraining and few-shot methods","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#competitive-performance-with-end-to-end-pretraining-and-few-shot-methods","p":276},{"i":321,"t":"4.3 Experimental Results of Different LLMs","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#43-experimental-results-of-different-llms","p":276},{"i":323,"t":"5. Limitation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":327,"t":"Abstract","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":325},{"i":329,"t":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":325},{"i":331,"t":"2. Related Work","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":325},{"i":332,"t":"3. CodeT5+: Open Code Large Language Models","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":325},{"i":334,"t":"3.1. Unimodal Pretraining on Code Data","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#31-unimodal-pretraining-on-code-data","p":325},{"i":336,"t":"Span Denoising","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#span-denoising","p":325},{"i":338,"t":"Causal Language Modeling (CLM)","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#causal-language-modeling-clm","p":325},{"i":340,"t":"3.2. Bimodal Pretraining on Text-code Data","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#32-bimodal-pretraining-on-text-code-data","p":325},{"i":342,"t":"Text-Code Contrastive Learning","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-contrastive-learning","p":325},{"i":344,"t":"Text-Code Matching","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-matching","p":325},{"i":346,"t":"Text-Code Causal LM","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-causal-lm","p":325},{"i":348,"t":"3.3. Compute-efficient Pretraining with Frozen Off-the-shelf LLMs","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#33-compute-efficient-pretraining-with-frozen-off-the-shelf-llms","p":325},{"i":350,"t":"3.4. Adaptation to Downstream Understanding and Generation Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#34-adaptation-to-downstream-understanding-and-generation-tasks","p":325},{"i":352,"t":"Seq2Seq Generation Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#seq2seq-generation-tasks","p":325},{"i":354,"t":"Decoder-only Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#decoder-only-tasks","p":325},{"i":356,"t":"Understanding Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#understanding-tasks","p":325},{"i":358,"t":"4. Pretraining and Instruction Tuning","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":325},{"i":359,"t":"4.1. Pretraining Dataset","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#41-pretraining-dataset","p":325},{"i":361,"t":"4.2. Pretraining Setup","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#42-pretraining-setup","p":325},{"i":365,"t":"Abstract","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":367,"t":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":369,"t":"2. Flan Finetuning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":371,"t":"2.1. Finetuning Data","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#21-finetuning-data","p":363},{"i":372,"t":"Task mixtures.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#task-mixtures","p":363},{"i":374,"t":"Chain-of-thought finetuning mixture.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#chain-of-thought-finetuning-mixture","p":363},{"i":376,"t":"Templates and formatting.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#templates-and-formatting","p":363},{"i":378,"t":"2.2. Finetuning procedure","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#22-finetuning-procedure","p":363},{"i":380,"t":"2.3. Evaluation Protocol","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#23-evaluation-protocol","p":363},{"i":381,"t":"Evaluation benchmarks.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#evaluation-benchmarks","p":363},{"i":383,"t":"Evaluation mathods and metrics.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#evaluation-mathods-and-metrics","p":363},{"i":385,"t":"3. Scaling to 540B parameters and 1.8K tasks","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":387,"t":"4. Finetuning with chain-of-thought annotations","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":389,"t":"4.1. Finetuning on chain-of-thought improves reasoning on held-out tasks","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#41-finetuning-on-chain-of-thought-improves-reasoning-on-held-out-tasks","p":363},{"i":391,"t":"4.2. Some chain-of-thought data is needed to maintain reasoning ability","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#42-some-chain-of-thought-data-is-needed-to-maintain-reasoning-ability","p":363},{"i":393,"t":"4.3. Unlocking zero-shot reasoning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#43-unlocking-zero-shot-reasoning","p":363},{"i":395,"t":"5. Putting it all together","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":397,"t":"6. Usability evaluation of open-ended generation","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":399,"t":"7. Discussion","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":401,"t":"Scaling curves for instruction finetuning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#scaling-curves-for-instruction-finetuning","p":363},{"i":403,"t":"CoT finetuning is critical for reasoning abilities","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#cot-finetuning-is-critical-for-reasoning-abilities","p":363},{"i":405,"t":"Instruction finetuning generalizes across models","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-generalizes-across-models","p":363},{"i":407,"t":"Instruction finetuning improves usability and mitigates some potential harms","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-improves-usability-and-mitigates-some-potential-harms","p":363},{"i":409,"t":"Instruction finetuning is relatively compute-efficient","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-is-relatively-compute-efficient","p":363},{"i":411,"t":"9. Conclusions","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":415,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":417,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":419,"t":"2. Background","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":420,"t":"3. Designing the T-Few Recipe","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":422,"t":"3.1 Model and Datasets","u":"/docs/Paper/NLP/PEFT/IA³","h":"#31-model-and-datasets","p":413},{"i":424,"t":"3.2 Unlikelihood Training and Length Normalization","u":"/docs/Paper/NLP/PEFT/IA³","h":"#32-unlikelihood-training-and-length-normalization","p":413},{"i":426,"t":"3.3 Parameter-efficient fine-tuning with (IA)3(IA)^3(IA)3","u":"/docs/Paper/NLP/PEFT/IA³","h":"#33-parameter-efficient-fine-tuning-with-ia3","p":413},{"i":428,"t":"3.4 Pre-training (IA)3(IA)^3(IA)3","u":"/docs/Paper/NLP/PEFT/IA³","h":"#34-pre-training-ia3","p":413},{"i":430,"t":"3.5 Combining the ingredients","u":"/docs/Paper/NLP/PEFT/IA³","h":"#35-combining-the-ingredients","p":413},{"i":432,"t":"4. Outperforming ICL with T-Few","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":434,"t":"4.1 Performance on T0 tasks","u":"/docs/Paper/NLP/PEFT/IA³","h":"#41-performance-on-t0-tasks","p":413},{"i":436,"t":"4.2 Comparing computational costs","u":"/docs/Paper/NLP/PEFT/IA³","h":"#42-comparing-computational-costs","p":413},{"i":438,"t":"Inference cost","u":"/docs/Paper/NLP/PEFT/IA³","h":"#inference-cost","p":413},{"i":440,"t":"Training cost","u":"/docs/Paper/NLP/PEFT/IA³","h":"#training-cost","p":413},{"i":442,"t":"Storage cost","u":"/docs/Paper/NLP/PEFT/IA³","h":"#storage-cost","p":413},{"i":444,"t":"Memory usage","u":"/docs/Paper/NLP/PEFT/IA³","h":"#memory-usage","p":413},{"i":446,"t":"4.3 Performance on Real-world Few-shot Tasks (RAFT)","u":"/docs/Paper/NLP/PEFT/IA³","h":"#43-performance-on-real-world-few-shot-tasks-raft","p":413},{"i":448,"t":"4.4 Ablation experiments","u":"/docs/Paper/NLP/PEFT/IA³","h":"#44-ablation-experiments","p":413},{"i":450,"t":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":454,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":456,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":458,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":459,"t":"3. LLaMA-Adapter","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":460,"t":"3.1 Learnable Adaptation Prompts","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":462,"t":"3.2 Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#32-zero-initialized-attention","p":452},{"i":464,"t":"3.3 Multi-modal Reasoning","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#33-multi-modal-reasoning","p":452},{"i":466,"t":"3.4 Zero-initialized Attention for other Large Models","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#34-zero-initialized-attention-for-other-large-models","p":452},{"i":468,"t":"Vision Models","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#vision-models","p":452},{"i":470,"t":"Language Models","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#language-models","p":452},{"i":472,"t":"4. Experiment","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":473,"t":"4.1 Instruction-following Evaluation","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#41-instruction-following-evaluation","p":452},{"i":474,"t":"Settings","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#settings","p":452},{"i":476,"t":"Performance","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#performance","p":452},{"i":478,"t":"Efficiency","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#efficiency","p":452},{"i":480,"t":"4.2 Multi-modal Evaluation","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#42-multi-modal-evaluation","p":452},{"i":481,"t":"Settings","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#settings-1","p":452},{"i":483,"t":"Performance","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#performance-1","p":452},{"i":485,"t":"4.3 Ablation Study","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#43-ablation-study","p":452},{"i":486,"t":"Insertion Layers","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#insertion-layers","p":452},{"i":488,"t":"Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#zero-initialized-attention","p":452},{"i":490,"t":"Robustness to Over-fitting","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#robustness-to-over-fitting","p":452},{"i":492,"t":"4.4 Zero-initialized Attention for other Large Models","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#44-zero-initialized-attention-for-other-large-models","p":452},{"i":493,"t":"Settings","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#settings-2","p":452},{"i":495,"t":"Performance","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#performance-2","p":452},{"i":497,"t":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":501,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":503,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":505,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":506,"t":"3. A Revisit of LLaMA-Adapter","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":507,"t":"Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#zero-initialized-attention","p":499},{"i":509,"t":"Simple Multi-modal Variant","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#simple-multi-modal-variant","p":499},{"i":511,"t":"Open-ended Multi-modal Reasoning","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#open-ended-multi-modal-reasoning","p":499},{"i":513,"t":"4. LLaMA-Adapter V2","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":514,"t":"4.1 Bias Tuning of Linear Layers","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#41-bias-tuning-of-linear-layers","p":499},{"i":516,"t":"Discussion","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#discussion","p":499},{"i":518,"t":"4.2 Joint Training with Disjoint Parameters","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#42-joint-training-with-disjoint-parameters","p":499},{"i":520,"t":"Discussion","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#discussion-1","p":499},{"i":522,"t":"4.3 Early Fusion of Visual Knowledge","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#43-early-fusion-of-visual-knowledge","p":499},{"i":524,"t":"4.4 Integration with Experts","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#44-integration-with-experts","p":499},{"i":526,"t":"5. Experiments","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":527,"t":"5.1 Experimental Setups","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#51-experimental-setups","p":499},{"i":528,"t":"Training Data","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#training-data","p":499},{"i":530,"t":"Implementation Details","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#implementation-details","p":499},{"i":532,"t":"5.2 Stronger Language Instruction Model","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#52-stronger-language-instruction-model","p":499},{"i":534,"t":"5.3 Visual Instruction Model","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#53-visual-instruction-model","p":499},{"i":536,"t":"Image Captioning","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#image-captioning","p":499},{"i":538,"t":"Visual Understanding","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#visual-understanding","p":499},{"i":540,"t":"Integration with Experts","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#integration-with-experts","p":499},{"i":542,"t":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":546,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":548,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":550,"t":"Terminologies and Conventions","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#terminologies-and-conventions","p":544},{"i":552,"t":"2. Problem Statement","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":554,"t":"3. Aren't Existing Solutions Good Enough?","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":556,"t":"Adapter Layer Introduce Inference Latency","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#adapter-layer-introduce-inference-latency","p":544},{"i":558,"t":"Directly Optimizing the Prompt is Hard","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#directly-optimizing-the-prompt-is-hard","p":544},{"i":560,"t":"4. Out Method","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":562,"t":"4.1 Low-Rank-Parameterized Update Matrices","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#41-low-rank-parameterized-update-matrices","p":544},{"i":564,"t":"A Generalization of Full Fine-tuning","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#a-generalization-of-full-fine-tuning","p":544},{"i":566,"t":"No Additional Inference Latency","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#no-additional-inference-latency","p":544},{"i":568,"t":"4.2 Applying LoRA to Transformer","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#42-applying-lora-to-transformer","p":544},{"i":570,"t":"Practical Benefits and Limitations","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#practical-benefits-and-limitations","p":544},{"i":572,"t":"5. Empirical Experiments","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":574,"t":"5.1 Baselines","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#51-baselines","p":544},{"i":576,"t":"Fine-Tuning (FT)","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#fine-tuning-ft","p":544},{"i":578,"t":"Bias-only or BitFit","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#bias-only-or-bitfit","p":544},{"i":580,"t":"Prefix-embedding tuning (PreEmbed)","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#prefix-embedding-tuning-preembed","p":544},{"i":582,"t":"Prefix-layer tuning (PreLayer)","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#prefix-layer-tuning-prelayer","p":544},{"i":584,"t":"Adapter tuning","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#adapter-tuning","p":544},{"i":586,"t":"LoRA","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#lora","p":544},{"i":588,"t":"5.2 RoBERTa Base/Large","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#52-roberta-baselarge","p":544},{"i":590,"t":"5.3 DeBERTa XXL","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#53-deberta-xxl","p":544},{"i":592,"t":"5.4 GPT-2 Medium/Large","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#54-gpt-2-mediumlarge","p":544},{"i":594,"t":"5.5 Scaling up to GPT-3 175B","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#55-scaling-up-to-gpt-3-175b","p":544},{"i":596,"t":"6. Related Works","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":597,"t":"7. Understanding the Low-Rank Updates","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":599,"t":"7.1 Which Weight Matrices in Transformer Should We Apply LoRA To?","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#71-which-weight-matrices-in-transformer-should-we-apply-lora-to","p":544},{"i":601,"t":"7.2 What is the Optimal Rank rrr For LoRA?","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#72-what-is-the-optimal-rank-r-for-lora","p":544},{"i":603,"t":"Subspace similarity between different rrr","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#subspace-similarity-between-different-r","p":544},{"i":605,"t":"Subspace similarity between different random seeds","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#subspace-similarity-between-different-random-seeds","p":544},{"i":607,"t":"7.3 How Does the Adaptation Matrix △W\\triangle W△W Compare To WWW?","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#73-how-does-the-adaptation-matrix-triangle-w-compare-to-w","p":544},{"i":609,"t":"8. Conclusion And Future Work","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":613,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":615,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":617,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":618,"t":"Parameter-efficient transfer learning","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#parameter-efficient-transfer-learning","p":611},{"i":620,"t":"Multitask learning","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#multitask-learning","p":611},{"i":622,"t":"Knowledge distillation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#knowledge-distillation","p":611},{"i":624,"t":"3. Approach","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":626,"t":"Prompt tuning","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#prompt-tuning","p":611},{"i":628,"t":"3.1 Multitask prompt tuning","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#31-multitask-prompt-tuning","p":611},{"i":630,"t":"Prompt decomposition","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#prompt-decomposition","p":611},{"i":632,"t":"Prompt distillation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#prompt-distillation","p":611},{"i":634,"t":"3.2 Source Training And Target Adaptation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#32-source-training-and-target-adaptation","p":611},{"i":636,"t":"Parameter-efficiency","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#parameter-efficiency","p":611},{"i":638,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":640,"t":"4.1 Experiemtal Setup","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#41-experiemtal-setup","p":611},{"i":641,"t":"Datasets and tasks","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#datasets-and-tasks","p":611},{"i":643,"t":"Models","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#models","p":611},{"i":645,"t":"Baseline","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#baseline","p":611},{"i":647,"t":"Implementation details","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#implementation-details","p":611},{"i":649,"t":"4.2 Results and Analysis","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#42-results-and-analysis","p":611},{"i":650,"t":"Full-dataset adaptation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#full-dataset-adaptation","p":611},{"i":652,"t":"Few-shot adaptation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#few-shot-adaptation","p":611},{"i":654,"t":"Natural language generation tasks","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#natural-language-generation-tasks","p":611},{"i":656,"t":"Model scaling","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#model-scaling","p":611},{"i":658,"t":"Analyzing prompt metrices","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#analyzing-prompt-metrices","p":611},{"i":660,"t":"4.3 Ablation studies","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#43-ablation-studies","p":611},{"i":661,"t":"Prompt decomposition and distillation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#prompt-decomposition-and-distillation","p":611},{"i":663,"t":"Distillation objective","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#distillation-objective","p":611},{"i":665,"t":"Prompt length","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#prompt-length","p":611},{"i":667,"t":"Target adaptation strategy","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#target-adaptation-strategy","p":611},{"i":669,"t":"Stochastic task sampling","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#stochastic-task-sampling","p":611},{"i":671,"t":"Number of source tasks for pretraining","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#number-of-source-tasks-for-pretraining","p":611},{"i":673,"t":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":677,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":679,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":681,"t":"2. Motivation","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":683,"t":"3. Method: P-tuning","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":685,"t":"3.1 Architecture","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#31-architecture","p":675},{"i":687,"t":"3.2 Optimization","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#32-optimization","p":675},{"i":689,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":691,"t":"4.1 Knowledge Probing","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#41-knowledge-probing","p":675},{"i":693,"t":"4.1.1 Datasets And Formulation","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#411-datasets-and-formulation","p":675},{"i":695,"t":"4.1.2 Results","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#412-results","p":675},{"i":697,"t":"4.2 SuperGLUE","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#42-superglue","p":675},{"i":699,"t":"4.2.1 Fully-Supervised Learning","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#421-fully-supervised-learning","p":675},{"i":701,"t":"4.2.2 Few-Shot Learning","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#422-few-shot-learning","p":675},{"i":703,"t":"4.2.3 Finetuning v.s. MP Finetuning v.s. P-tuning","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#423-finetuning-vs-mp-finetuning-vs-p-tuning","p":675},{"i":705,"t":"5. Related Work","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":706,"t":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":710,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":712,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":714,"t":"2. Preliminaries","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":715,"t":"NLU Tasks","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#nlu-tasks","p":708},{"i":717,"t":"Prompt Tuning","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#prompt-tuning","p":708},{"i":719,"t":"3. P-Tuning v2","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":720,"t":"3.1 Lack of Universality","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#31-lack-of-universality","p":708},{"i":722,"t":"Lack of universality across scales","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#lack-of-universality-across-scales","p":708},{"i":724,"t":"Lack of universality across tasks","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#lack-of-universality-across-tasks","p":708},{"i":726,"t":"3.2 Deep Prompt Tuning","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#32-deep-prompt-tuning","p":708},{"i":728,"t":"3.3 Optimization and Implementation","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#33-optimization-and-implementation","p":708},{"i":729,"t":"Reparameterization","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#reparameterization","p":708},{"i":731,"t":"Prompt Length","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#prompt-length","p":708},{"i":733,"t":"Multi-task Learning","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#multi-task-learning","p":708},{"i":735,"t":"Classification Head","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#classification-head","p":708},{"i":737,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":739,"t":"NLU Tasks","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#nlu-tasks-1","p":708},{"i":741,"t":"Pre-trained Models","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#pre-trained-models","p":708},{"i":743,"t":"Multitask Learning","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#multitask-learning","p":708},{"i":745,"t":"4.1 P-tuning v2: Across Scales","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#41-p-tuning-v2-across-scales","p":708},{"i":747,"t":"4.2 P-tuning v2: Across Tasks","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#42-p-tuning-v2-across-tasks","p":708},{"i":749,"t":"4.3 Ablation Study","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#43-ablation-study","p":708},{"i":750,"t":"Verbalizer with LM head v.s. [CLS] label with linear head","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#verbalizer-with-lm-head-vs-cls-label-with-linear-head","p":708},{"i":752,"t":"Prompt depth","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#prompt-depth","p":708},{"i":754,"t":"5. Conclusions","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":758,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":760,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":762,"t":"2. Related Work","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":763,"t":"3. Problem Statement","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":765,"t":"3.1 Autoregressive LM","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#31-autoregressive-lm","p":756},{"i":767,"t":"3.2 Encoder-Decoder Archirecture","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#32-encoder-decoder-archirecture","p":756},{"i":769,"t":"3.3 Fine-tuning","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#33-fine-tuning","p":756},{"i":771,"t":"4. Prefix-Tuning","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":772,"t":"4.1 Intuition","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#41-intuition","p":756},{"i":774,"t":"4.2 Method","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#42-method","p":756},{"i":776,"t":"4.3 Parameterization of PθP_{\\theta}Pθ​","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#43-parameterization-of-p_theta","p":756},{"i":778,"t":"5. Experimental Setup","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":779,"t":"5.1 Datasets and Metrics","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#51-datasets-and-metrics","p":756},{"i":781,"t":"5.2 Methods","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#52-methods","p":756},{"i":783,"t":"5.3 Architectures and Hyperparameters","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#53-architectures-and-hyperparameters","p":756},{"i":785,"t":"6. Main Results","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":786,"t":"6.1 Table-to-text Generation","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#61-table-to-text-generation","p":756},{"i":788,"t":"6.2 Summarization","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#62-summarization","p":756},{"i":790,"t":"6.3 Low-data Setting","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#63-low-data-setting","p":756},{"i":792,"t":"6.4 Extrapolation","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#64-extrapolation","p":756},{"i":794,"t":"7. Intrinsic Evaluation","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":795,"t":"7.1 Prefix Length","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#71-prefix-length","p":756},{"i":797,"t":"7.2 Full vs Embedding-only","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#72-full-vs-embedding-only","p":756},{"i":799,"t":"7.3 Prefix-tuning vs Infix-tuning","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#73-prefix-tuning-vs-infix-tuning","p":756},{"i":801,"t":"7.4 Initialization","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#74-initialization","p":756},{"i":803,"t":"7.5 Data Efficiency","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#75-data-efficiency","p":756},{"i":805,"t":"8. Discussion","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":806,"t":"Personalization","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#personalization","p":756},{"i":808,"t":"Batching across users.","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#batching-across-users","p":756},{"i":810,"t":"Inductive bias of prefix-tuning","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#inductive-bias-of-prefix-tuning","p":756},{"i":814,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":816,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":818,"t":"2. Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":820,"t":"2.1 Design Decisions","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#21-design-decisions","p":812},{"i":822,"t":"2.2 Unlearning Span Corruption","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#22-unlearning-span-corruption","p":812},{"i":824,"t":"3. Results","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":826,"t":"3.1 Closing the Gap","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#31-closing-the-gap","p":812},{"i":828,"t":"3.2 Ablation Study","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#32-ablation-study","p":812},{"i":829,"t":"Prompt Length","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#prompt-length","p":812},{"i":831,"t":"Prompt Initialization","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#prompt-initialization","p":812},{"i":833,"t":"Pre-training Objective","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#pre-training-objective","p":812},{"i":835,"t":"4. Comparison to Similar Approaches","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":837,"t":"5. Resilience to Domain Shift","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":839,"t":"6. Prompt Ensembling","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":841,"t":"7. Interpretability","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":843,"t":"8. Conclusion","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":847,"t":"Abstract","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":849,"t":"1 Introduction","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":851,"t":"2 Related work","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":852,"t":"3 Reflexion: reinforcement via verbal reflection","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":854,"t":"Actor","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#actor","p":845},{"i":856,"t":"Evaluator","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#evaluator","p":845},{"i":858,"t":"Self-reflection","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#self-reflection","p":845},{"i":860,"t":"Memory","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#memory","p":845},{"i":862,"t":"The Reflexion process","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#the-reflexion-process","p":845},{"i":864,"t":"4 Experiments","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":865,"t":"4.1 Sequential decision making: ALFWorld","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#41-sequential-decision-making-alfworld","p":845},{"i":866,"t":"4.2 Reasoning: HotpotQA","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#42-reasoning-hotpotqa","p":845},{"i":867,"t":"4.3 Programming","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#43-programming","p":845},{"i":868,"t":"Ablation study","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#ablation-study","p":845},{"i":869,"t":"5 Limitations","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":873,"t":"Abstract","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":875,"t":"1. Two Sea Changes in Natural Language Processing","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":877,"t":"2 A Formal Description of Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":878,"t":"2.1 Supervised Learning in NLP","u":"/docs/Paper/NLP/Survey/Prompting","h":"#21-supervised-learning-in-nlp","p":871},{"i":880,"t":"2.2 Prompting Basics","u":"/docs/Paper/NLP/Survey/Prompting","h":"#22-prompting-basics","p":871},{"i":882,"t":"2.2.1 Prompt Addition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#221-prompt-addition","p":871},{"i":884,"t":"2.2.2 Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#222-answer-search","p":871},{"i":886,"t":"2.2.3 Answer Mapping","u":"/docs/Paper/NLP/Survey/Prompting","h":"#223-answer-mapping","p":871},{"i":888,"t":"2.3 Design Considerations for Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#23-design-considerations-for-prompting","p":871},{"i":890,"t":"3 Prompt Template Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":892,"t":"3.1 Prompt Shape","u":"/docs/Paper/NLP/Survey/Prompting","h":"#31-prompt-shape","p":871},{"i":894,"t":"3.2 Manual Template Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#32-manual-template-engineering","p":871},{"i":896,"t":"3.3 Automated Template Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#33-automated-template-learning","p":871},{"i":898,"t":"3.3.1 Discrete Prompt","u":"/docs/Paper/NLP/Survey/Prompting","h":"#331-discrete-prompt","p":871},{"i":900,"t":"3.3.2 Continuous Prompt","u":"/docs/Paper/NLP/Survey/Prompting","h":"#332-continuous-prompt","p":871},{"i":902,"t":"4 Prompt Answer Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":904,"t":"4.1 Answer Shape","u":"/docs/Paper/NLP/Survey/Prompting","h":"#41-answer-shape","p":871},{"i":906,"t":"4.2 Answer Space Design Method","u":"/docs/Paper/NLP/Survey/Prompting","h":"#42-answer-space-design-method","p":871},{"i":908,"t":"4.2.1 Manual Design","u":"/docs/Paper/NLP/Survey/Prompting","h":"#421-manual-design","p":871},{"i":910,"t":"4.2.2 Discrete Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#422-discrete-answer-search","p":871},{"i":912,"t":"4.2.3 Continuous Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#423-continuous-answer-search","p":871},{"i":914,"t":"5 Multi-Prompt Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":916,"t":"5.1 Prompt Ensembling","u":"/docs/Paper/NLP/Survey/Prompting","h":"#51-prompt-ensembling","p":871},{"i":918,"t":"5.2 Prompt Augmentation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#52-prompt-augmentation","p":871},{"i":920,"t":"5.3 Prompt Composition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#53-prompt-composition","p":871},{"i":922,"t":"5.4 Prompt Decomposition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#54-prompt-decomposition","p":871},{"i":924,"t":"6 Training Strategies for Prompting Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":926,"t":"6.1 Training Settings","u":"/docs/Paper/NLP/Survey/Prompting","h":"#61-training-settings","p":871},{"i":928,"t":"6.2 Parameter Update Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"#62-parameter-update-methods","p":871},{"i":930,"t":"6.2.1 Promptless Fine-tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#621-promptless-fine-tuning","p":871},{"i":932,"t":"6.2.2 Tuning-free Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#622-tuning-free-prompting","p":871},{"i":934,"t":"6.2.3 Fixed-LM Prompt Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#623-fixed-lm-prompt-tuning","p":871},{"i":936,"t":"6.2.4 Fixed-Prompt LM Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#624-fixed-prompt-lm-tuning","p":871},{"i":938,"t":"6.2.5 Prompt+LM Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#625-promptlm-tuning","p":871},{"i":940,"t":"7 Applications","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":942,"t":"7.1 Knowledge Probing","u":"/docs/Paper/NLP/Survey/Prompting","h":"#71-knowledge-probing","p":871},{"i":944,"t":"7.2 Structure Prediction","u":"/docs/Paper/NLP/Survey/Prompting","h":"#72-structure-prediction","p":871},{"i":946,"t":"7.3 Classification-based Tasks","u":"/docs/Paper/NLP/Survey/Prompting","h":"#73-classification-based-tasks","p":871},{"i":948,"t":"7.4 Information Extraction","u":"/docs/Paper/NLP/Survey/Prompting","h":"#74-information-extraction","p":871},{"i":950,"t":"7.5 \"Reasoning\" in NLP","u":"/docs/Paper/NLP/Survey/Prompting","h":"#75-reasoning-in-nlp","p":871},{"i":952,"t":"7.6 Question Answering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#76-question-answering","p":871},{"i":954,"t":"7.7  Text Generation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#77--text-generation","p":871},{"i":956,"t":"7.8 Automatic Evaluation of Text Generation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#78-automatic-evaluation-of-text-generation","p":871},{"i":958,"t":"7.9 Meta-Applications","u":"/docs/Paper/NLP/Survey/Prompting","h":"#79-meta-applications","p":871},{"i":960,"t":"7.10 Multi-modal Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#710-multi-modal-learning","p":871},{"i":962,"t":"8 Prompt-Relevant Topics","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":964,"t":"9 Challenges","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":966,"t":"9.1 Selection of Pre-trained LMs","u":"/docs/Paper/NLP/Survey/Prompting","h":"#91-selection-of-pre-trained-lms","p":871},{"i":968,"t":"9.2 Prompt Design","u":"/docs/Paper/NLP/Survey/Prompting","h":"#92-prompt-design","p":871},{"i":970,"t":"9.3 Prompt Answer Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#93-prompt-answer-engineering","p":871},{"i":972,"t":"9.4 Selection of Tuning Strategy","u":"/docs/Paper/NLP/Survey/Prompting","h":"#94-selection-of-tuning-strategy","p":871},{"i":974,"t":"9.5 Multiple Prompt Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#95-multiple-prompt-learning","p":871},{"i":976,"t":"9.6 Theoretical and Empirical Analysis of Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#96-theoretical-and-empirical-analysis-of-prompting","p":871},{"i":978,"t":"9.7 Transferability of Prompts","u":"/docs/Paper/NLP/Survey/Prompting","h":"#97-transferability-of-prompts","p":871},{"i":980,"t":"9.8 Combination of Different Paradigms","u":"/docs/Paper/NLP/Survey/Prompting","h":"#98-combination-of-different-paradigms","p":871},{"i":982,"t":"9.9 Calibration of Prompting Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"#99-calibration-of-prompting-methods","p":871},{"i":986,"t":"Abstract","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":988,"t":"1. Introduction","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":990,"t":"2. Related Work","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":991,"t":"3. Methods and experimental details","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":992,"t":"3.1 High-level methodology","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#31-high-level-methodology","p":984},{"i":994,"t":"3.2 Dataset","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#32-dataset","p":984},{"i":996,"t":"3.3 Task","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#33-task","p":984},{"i":998,"t":"3.4 Human data collection","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#34-human-data-collection","p":984},{"i":1000,"t":"3.5 Models","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#35-models","p":984},{"i":1002,"t":"3.6 Evaluation","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#36-evaluation","p":984},{"i":1004,"t":"4. Result","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":1005,"t":"4.1 Results on the API distribution","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#41-results-on-the-api-distribution","p":984},{"i":1007,"t":"4.2 Results on public NLP datasets","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#42-results-on-public-nlp-datasets","p":984},{"i":1009,"t":"4.3 Qualitative results","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#43-qualitative-results","p":984},{"i":1011,"t":"5. Discussion","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":1012,"t":"5.1 Implications for alignment research","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#51-implications-for-alignment-research","p":984},{"i":1014,"t":"5.2 Who are we aligning to?","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#52-who-are-we-aligning-to","p":984},{"i":1015,"t":"5.3 Limitations","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#53-limitations","p":984},{"i":1017,"t":"ChatGPT","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":1019,"t":"Method","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#method","p":984},{"i":1021,"t":"Limitations","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#limitations","p":984},{"i":1025,"t":"What's next?","u":"/docs/tutorial-basics/congratulations","h":"#whats-next","p":1023},{"i":1029,"t":"Create your first Post","u":"/docs/tutorial-basics/create-a-blog-post","h":"#create-your-first-post","p":1027},{"i":1033,"t":"Create your first Doc","u":"/docs/tutorial-basics/create-a-document","h":"#create-your-first-doc","p":1031},{"i":1035,"t":"Configure the Sidebar","u":"/docs/tutorial-basics/create-a-document","h":"#configure-the-sidebar","p":1031},{"i":1039,"t":"Create your first React Page","u":"/docs/tutorial-basics/create-a-page","h":"#create-your-first-react-page","p":1037},{"i":1041,"t":"Create your first Markdown Page","u":"/docs/tutorial-basics/create-a-page","h":"#create-your-first-markdown-page","p":1037},{"i":1045,"t":"Build your site","u":"/docs/tutorial-basics/deploy-your-site","h":"#build-your-site","p":1043},{"i":1050,"t":"Front Matter","u":"/docs/tutorial-basics/markdown-features","h":"#front-matter","p":1048},{"i":1052,"t":"Links","u":"/docs/tutorial-basics/markdown-features","h":"#links","p":1048},{"i":1054,"t":"Images","u":"/docs/tutorial-basics/markdown-features","h":"#images","p":1048},{"i":1056,"t":"Code Blocks","u":"/docs/tutorial-basics/markdown-features","h":"#code-blocks","p":1048},{"i":1058,"t":"Admonitions","u":"/docs/tutorial-basics/markdown-features","h":"#admonitions","p":1048},{"i":1060,"t":"MDX and React Components","u":"/docs/tutorial-basics/markdown-features","h":"#mdx-and-react-components","p":1048},{"i":1064,"t":"Create a docs version","u":"/docs/tutorial-extras/manage-docs-versions","h":"#create-a-docs-version","p":1062},{"i":1066,"t":"Add a Version Dropdown","u":"/docs/tutorial-extras/manage-docs-versions","h":"#add-a-version-dropdown","p":1062},{"i":1068,"t":"Update an existing version","u":"/docs/tutorial-extras/manage-docs-versions","h":"#update-an-existing-version","p":1062},{"i":1072,"t":"Configure i18n","u":"/docs/tutorial-extras/translate-your-site","h":"#configure-i18n","p":1070},{"i":1074,"t":"Translate a doc","u":"/docs/tutorial-extras/translate-your-site","h":"#translate-a-doc","p":1070},{"i":1076,"t":"Start your localized site","u":"/docs/tutorial-extras/translate-your-site","h":"#start-your-localized-site","p":1070},{"i":1078,"t":"Add a Locale Dropdown","u":"/docs/tutorial-extras/translate-your-site","h":"#add-a-locale-dropdown","p":1070},{"i":1080,"t":"Build your localized site","u":"/docs/tutorial-extras/translate-your-site","h":"#build-your-localized-site","p":1070},{"i":1084,"t":"Abstract","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1086,"t":"1. Introduction","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1088,"t":"2. Related Work","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1089,"t":"3. Approch","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1091,"t":"3.1 Prompt Generation","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#31-prompt-generation","p":1082},{"i":1093,"t":"3.2 Image-Prompt Feature Fusion","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#32-image-prompt-feature-fusion","p":1082},{"i":1095,"t":"3.3 Object Discovery and Retrieval","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#33-object-discovery-and-retrieval","p":1082},{"i":1097,"t":"3.4 Training and Inference","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#34-training-and-inference","p":1082},{"i":1098,"t":"Training","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#training","p":1082},{"i":1100,"t":"Inference","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#inference","p":1082},{"i":1102,"t":"4. Experiments","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1103,"t":"4.1 Implementation Details","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#41-implementation-details","p":1082},{"i":1105,"t":"4.2 Evaluations on 10 Tasks","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#42-evaluations-on-10-tasks","p":1082},{"i":1106,"t":"Object Detection and Instance Segmentation","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#object-detection-and-instance-segmentation","p":1082},{"i":1108,"t":"REC and RES","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#rec-and-res","p":1082},{"i":1110,"t":"SOT","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#sot","p":1082},{"i":1112,"t":"VOS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#vos","p":1082},{"i":1114,"t":"MOT","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#mot","p":1082},{"i":1116,"t":"MOTS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#mots","p":1082},{"i":1118,"t":"VIS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#vis","p":1082},{"i":1120,"t":"R-VOS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#r-vos","p":1082},{"i":1122,"t":"4.3 Ablations and Other Analysis","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#43-ablations-and-other-analysis","p":1082},{"i":1124,"t":"Fusion","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#fusion","p":1082},{"i":1126,"t":"Queries","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#queries","p":1082},{"i":1128,"t":"Unification","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#unification","p":1082},{"i":1130,"t":"5. Conclusions","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1134,"t":"Abstract","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1136,"t":"1. Introduction","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1138,"t":"2. Background","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1139,"t":"Transformer-based Models","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#transformer-based-models","p":1132},{"i":1141,"t":"Low Rank Adaptation","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#low-rank-adaptation","p":1132},{"i":1143,"t":"3. AdaLoRA Method","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1145,"t":"3.1 SVD-Based Adaptation","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#31-svd-based-adaptation","p":1132},{"i":1147,"t":"3.2 Importance-Aware Rank Allocation","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#32-importance-aware-rank-allocation","p":1132},{"i":1149,"t":"Magnitude of singular values","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#magnitude-of-singular-values","p":1132},{"i":1151,"t":"Sensitivity-based importance","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#sensitivity-based-importance","p":1132},{"i":1153,"t":"3.3 Global Budget Scheduler","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#33-global-budget-scheduler","p":1132},{"i":1155,"t":"4. Experiments","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1157,"t":"Implementation Details","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#implementation-details","p":1132},{"i":1159,"t":"Baselines","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#baselines","p":1132},{"i":1161,"t":"4.1 Natural Language Understanding","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#41-natural-language-understanding","p":1132},{"i":1162,"t":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#models-and-datasets","p":1132},{"i":1164,"t":"Implementation Details","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#implementation-details-1","p":1132},{"i":1166,"t":"Main results","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#main-results","p":1132},{"i":1168,"t":"4.2 Question Answering","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#42-question-answering","p":1132},{"i":1169,"t":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#models-and-datasets-1","p":1132},{"i":1171,"t":"Implementation Details","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#implementation-details-2","p":1132},{"i":1173,"t":"Main Results","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#main-results-1","p":1132},{"i":1175,"t":"4.3 Nautral Language Generation","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#43-nautral-language-generation","p":1132},{"i":1176,"t":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#models-and-datasets-2","p":1132},{"i":1178,"t":"Implementation Details","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#implementation-details-3","p":1132},{"i":1180,"t":"Main Results","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#main-results-2","p":1132},{"i":1182,"t":"4.4 Analysis","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#44-analysis","p":1132},{"i":1183,"t":"Different budget levels","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#different-budget-levels","p":1132},{"i":1185,"t":"Comparison to low-rank parameterization","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#comparison-to-low-rank-parameterization","p":1132},{"i":1187,"t":"Variants of the importance score","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#variants-of-the-importance-score","p":1132},{"i":1189,"t":"The role of two components","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#the-role-of-two-components","p":1132},{"i":1191,"t":"The resulting budget distribution","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#the-resulting-budget-distribution","p":1132},{"i":1193,"t":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1197,"t":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1199,"t":"Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1201,"t":"Related Work","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1202,"t":"Vision-language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#vision-language-models","p":1195},{"i":1204,"t":"Prompt Learning","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-learning","p":1195},{"i":1206,"t":"Self-training","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#self-training","p":1195},{"i":1208,"t":"Method","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1210,"t":"Overview of UPL","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#overview-of-upl","p":1195},{"i":1212,"t":"Pseudo Label Generation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-generation","p":1195},{"i":1213,"t":"Inference of CLIP","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#inference-of-clip","p":1195},{"i":1215,"t":"Pseudo Label Generation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-generation-1","p":1195},{"i":1217,"t":"Pseudo Label Ensemble","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-ensemble","p":1195},{"i":1219,"t":"Prompt Representation Optimization","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-representation-optimization","p":1195},{"i":1221,"t":"Learnable Prompt Representation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#learnable-prompt-representation","p":1195},{"i":1223,"t":"Inference","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#inference","p":1195},{"i":1225,"t":"Prompt Representation Ensemble","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-representation-ensemble","p":1195},{"i":1227,"t":"Experiment","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1228,"t":"Implementation Details","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#implementation-details","p":1195},{"i":1229,"t":"Vision-language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#vision-language-models-1","p":1195},{"i":1231,"t":"Pseudo Label Generation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-generation-2","p":1195},{"i":1233,"t":"Learnable Prompt Representation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#learnable-prompt-representation-1","p":1195},{"i":1235,"t":"Training Details","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#training-details","p":1195},{"i":1237,"t":"Dataset","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#dataset","p":1195},{"i":1239,"t":"Main Results","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1241,"t":"Conclusion","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195}],"index":{"version":"2.3.9","fields":["t"],"fieldVectors":[["t/12",[0,6.947,1,5.972]],["t/14",[2,6.947,3,6.36]],["t/16",[4,3.497,5,5.482,6,4.7]],["t/18",[1,5.972,6,5.452]],["t/22",[7,7.571]],["t/24",[8,3.831,9,3.831]],["t/26",[10,3.26,11,3.61,12,3.552]],["t/28",[13,2.864,14,4.525,15,3.751,16,3.488]],["t/29",[17,4.535,18,3.034,19,4.268]],["t/30",[18,2.146,20,4.236,21,3.465,22,3.325,23,3.878,24,3.878]],["t/32",[24,3.245,25,3.545,26,3.245,27,3.245,28,2.782,29,3.047,30,3.545,31,3.245]],["t/34",[31,3.878,32,4.236,33,3.325,34,3.878,35,4.236,36,3.207]],["t/36",[18,2.666,33,4.131,37,4.818,38,4.818]],["t/37",[38,6.36,39,5.683]],["t/39",[14,5.972,15,4.951]],["t/41",[14,5.972,33,5.452]],["t/43",[18,3.034,40,5.989,41,4.7]],["t/45",[42,3.348,43,5.149,44,3.497]],["t/46",[45,7.571]],["t/48",[43,4.525,44,3.073,46,3.121,47,4.818]],["t/50",[48,3.348,49,4.393,50,3.178]],["t/51",[51,6.36,52,6.947]],["t/52",[53,5.742]],["t/54",[50,4.389]],["t/56",[54,8.271]],["t/57",[53,5.742]],["t/59",[50,4.389]],["t/61",[44,3.497,55,5.149,56,3.61]],["t/62",[53,5.742]],["t/64",[50,4.389]],["t/66",[57,4.059,58,4.158,59,4.268]],["t/67",[41,5.452,60,6.947]],["t/69",[18,3.034,61,3.886,62,5.989]],["t/70",[33,5.452,63,6.947]],["t/71",[43,4.525,44,3.073,64,3.985,65,5.263]],["t/73",[46,3.552,47,5.482,66,4.899]],["t/75",[67,5.095,68,4.12]],["t/77",[69,7.571]],["t/79",[70,4.986]],["t/83",[71,4.561]],["t/85",[8,3.831,9,3.831]],["t/87",[10,3.26,11,3.61,12,3.552]],["t/89",[13,3.781,72,4.12]],["t/90",[73,3.121,74,3.985,75,4.131,76,5.263]],["t/92",[77,6.947,78,5.683]],["t/94",[15,4.951,79,6.947]],["t/96",[80,2.784,81,3.346,82,2.327,83,4.694,84,4.694]],["t/98",[42,3.883,70,4.188]],["t/100",[53,4.823,85,4.056]],["t/101",[56,4.986]],["t/103",[86,3.733,87,5.683]],["t/105",[7,4.818,18,2.666,81,3.751,82,2.609]],["t/107",[88,6.766]],["t/109",[41,4.131,89,3.073,90,5.263,91,5.263]],["t/111",[18,2.378,92,2.93,93,3.443,94,3.181,95,4.694]],["t/113",[33,4.7,59,4.268,96,4.7]],["t/115",[74,3.985,75,4.131,97,5.263,98,5.263]],["t/117",[99,5.989,100,5.149,101,5.149]],["t/119",[48,3.883,68,4.12]],["t/123",[71,4.561]],["t/125",[8,3.831,9,3.831]],["t/127",[10,3.781,102,5.972]],["t/129",[103,4.131,104,4.818,105,5.263,106,4.818]],["t/131",[15,3.346,104,4.297,107,3.684,108,3.443,109,4.694]],["t/133",[18,3.519,110,5.972]],["t/135",[94,4.708,111,6.36]],["t/137",[111,6.36,112,6.36]],["t/139",[106,4.818,113,5.263,114,3.654,115,5.263]],["t/141",[13,3.781,70,4.188]],["t/142",[73,2.784,116,3.554,117,3.443,118,3.046,119,2.93]],["t/144",[108,5.095,120,5.972]],["t/146",[121,6.36,122,6.36]],["t/148",[120,5.972,123,6.947]],["t/150",[18,2.666,124,5.263,125,2.828,126,4.818]],["t/152",[127,6.766]],["t/154",[50,3.178,80,3.552,128,5.989]],["t/156",[50,3.178,129,3.809,130,5.482]],["t/158",[48,3.883,68,4.12]],["t/162",[71,4.561]],["t/164",[8,3.831,9,3.831]],["t/166",[10,3.26,11,3.61,12,3.552]],["t/167",[13,1.929,131,3.047,132,2.9,133,2.9,134,2.3,135,2.349,136,2.402,137,2.684]],["t/168",[73,3.552,86,3.218,138,5.482]],["t/170",[18,2.666,80,3.121,93,3.86,139,3.567]],["t/172",[15,3.751,129,3.348,140,5.263,141,4.525]],["t/173",[26,4.818,136,3.567,142,5.263,143,5.263]],["t/175",[139,4.708,144,6.36]],["t/177",[145,6.947,146,6.36]],["t/179",[18,3.034,108,4.393,147,4.268]],["t/181",[42,3.883,70,4.188]],["t/182",[85,3.073,86,2.828,87,4.306,131,4.525]],["t/184",[18,2.666,89,3.073,119,3.285,148,3.348]],["t/185",[18,3.034,56,3.61,93,4.393]],["t/187",[118,4.507,149,6.947]],["t/189",[117,5.095,150,6.947]],["t/191",[50,2.491,74,3.554,92,2.93,151,2.986,152,3.84]],["t/192",[61,2.504,81,2.751,82,1.913,153,3.86,154,3.157,155,3.86,156,3.86]],["t/194",[22,3.684,61,3.046,154,3.84,157,3.259,158,3.181]],["t/196",[51,4.297,61,3.046,158,3.181,159,3.443,160,4.035]],["t/198",[48,3.348,161,5.149,162,4.7]],["t/200",[131,4.525,163,3.985,164,5.263,165,5.263]],["t/201",[61,3.415,139,3.567,166,5.263,167,4.818]],["t/203",[61,3.415,139,3.567,167,6.901]],["t/205",[139,4.059,168,5.149,169,5.989]],["t/207",[15,3.346,16,3.11,18,2.378,119,2.93,170,3.554]],["t/208",[16,3.969,23,5.482,146,5.482]],["t/210",[16,2.807,135,2.807,136,2.871,144,3.878,171,3.878,172,3.465]],["t/212",[29,5.149,173,5.149,174,5.989]],["t/214",[57,3.567,68,3.121,175,3.985,176,3.86]],["t/216",[44,3.073,135,3.488,136,3.567,177,5.263]],["t/218",[5,4.297,46,2.784,139,3.181,157,3.259,158,3.181]],["t/220",[114,3.259,139,3.181,178,4.297,179,4.694,180,4.694]],["t/222",[137,4.535,139,4.059,181,4.7]],["t/226",[71,4.561]],["t/228",[8,3.831,9,3.831]],["t/230",[10,2.864,182,3.751,183,3.751,184,2.115]],["t/232",[13,3.26,134,3.886,185,5.989]],["t/234",[73,3.552,116,4.535,186,5.989]],["t/235",[152,6.766]],["t/237",[184,2.792,187,6.947]],["t/239",[182,4.268,183,4.268,184,2.407]],["t/241",[86,3.733,151,4.419]],["t/243",[50,3.687,80,4.12]],["t/245",[58,4.158,59,4.268,129,3.809]],["t/247",[188,8.271]],["t/249",[189,6.947,190,5.683]],["t/251",[182,4.268,183,4.268,191,3.886]],["t/253",[147,3.751,168,4.525,182,3.751,183,3.751]],["t/255",[42,3.348,134,3.886,192,5.989]],["t/256",[152,6.766]],["t/258",[184,3.324]],["t/260",[50,4.389]],["t/262",[48,3.348,134,3.886,193,5.989]],["t/264",[125,4.444]],["t/266",[194,5.989,195,5.989,196,5.989]],["t/268",[197,6.947,198,6.947]],["t/270",[57,4.708,176,5.095]],["t/272",[11,3.61,12,3.552,67,4.393]],["t/274",[68,4.12,199,5.452]],["t/278",[71,4.561]],["t/280",[8,3.831,9,3.831]],["t/282",[10,3.26,11,3.61,12,3.552]],["t/283",[72,2.784,103,3.684,200,4.694,201,4.694,202,3.84]],["t/285",[107,3.325,125,2.276,158,2.871,202,3.465,203,3.325,204,4.236]],["t/287",[135,3.969,136,4.059,205,4.158]],["t/289",[151,3.809,202,4.899,206,5.989]],["t/291",[13,3.781,72,4.12]],["t/293",[73,3.552,191,3.886,207,5.482]],["t/295",[4,3.497,80,3.552,208,4.535]],["t/297",[4,3.073,208,3.985,209,4.131,210,4.131]],["t/299",[4,3.497,208,4.535,211,5.989]],["t/301",[129,2.986,154,3.84,184,1.887,208,3.554,212,4.297]],["t/303",[16,3.969,147,4.268,184,2.407]],["t/305",[42,3.883,70,4.188]],["t/307",[53,4.158,85,3.497,213,5.989]],["t/308",[56,4.986]],["t/310",[118,4.507,119,4.337]],["t/312",[72,4.12,214,6.947]],["t/314",[49,4.393,50,3.178,89,3.497]],["t/315",[50,1.881,148,2.255,157,2.461,158,2.402,173,3.047,203,2.782,215,3.545,216,3.545]],["t/317",[29,3.642,202,3.465,203,3.325,217,3.107,218,4.236,219,4.236]],["t/319",[61,2.3,72,2.102,133,4.578,158,2.402,159,2.6,205,2.461,220,3.545]],["t/321",[50,2.491,64,3.554,92,2.93,116,3.554,203,3.684]],["t/323",[48,3.883,175,5.26]],["t/327",[71,4.561]],["t/329",[8,3.831,9,3.831]],["t/331",[10,3.26,11,3.61,12,3.552]],["t/332",[13,2.101,21,3.157,86,2.074,132,3.157,151,2.455,221,3.86,222,2.831]],["t/334",[73,2.784,94,3.181,205,3.259,222,3.443,223,4.694]],["t/336",[224,6.36,225,6.947]],["t/338",[86,2.828,151,3.348,226,4.818,227,5.263]],["t/340",[80,2.512,94,2.871,205,2.941,222,3.107,228,4.236,229,3.107]],["t/342",[44,3.073,222,3.86,229,3.86,230,5.263]],["t/344",[222,4.393,229,4.393,231,5.989]],["t/346",[222,3.86,226,4.818,229,3.86,232,3.985]],["t/348",[19,2.751,129,2.455,173,3.318,190,3.157,203,3.029,205,2.68,233,3.86]],["t/350",[4,2.473,17,3.207,46,2.512,125,2.276,147,3.019,234,4.236]],["t/352",[4,3.497,125,3.218,235,5.989]],["t/354",[125,3.733,236,6.36]],["t/356",[17,5.26,125,3.733]],["t/358",[42,2.942,82,2.609,205,3.654,237,3.751]],["t/359",[56,3.61,85,3.497,205,4.158]],["t/361",[53,4.158,89,3.497,205,4.158]],["t/365",[71,4.561]],["t/367",[8,3.831,9,3.831]],["t/369",[10,3.26,238,5.989,239,3.886]],["t/371",[94,4.059,103,4.7,239,3.886]],["t/372",[125,3.733,240,6.36]],["t/374",[182,3.751,183,3.751,239,3.415,240,4.818]],["t/376",[209,5.452,241,6.947]],["t/378",[107,4.7,239,3.886,242,5.989]],["t/380",[110,5.149,148,3.809,243,5.989]],["t/381",[148,4.419,152,5.683]],["t/383",[88,4.899,148,3.809,244,5.989]],["t/385",[13,2.306,125,2.276,217,3.107,245,4.236,246,3.207,247,4.236]],["t/387",[42,2.624,182,3.346,183,3.346,239,3.046,248,4.694]],["t/389",[85,1.913,125,1.761,134,2.126,182,2.336,183,2.336,239,2.126,249,3,250,3.277,251,3]],["t/391",[3,3.245,89,2.07,94,2.402,134,2.3,182,2.526,183,2.526,252,3.545,253,3.245]],["t/393",[92,2.93,134,3.046,157,3.259,158,3.181,254,4.694]],["t/395",[48,3.348,255,5.989,256,5.989]],["t/397",[4,2.473,57,2.871,132,3.465,133,3.465,148,2.695,257,3.878]],["t/399",[67,5.095,176,5.095]],["t/401",[217,3.86,237,3.751,239,3.415,258,5.263]],["t/403",[134,3.046,239,3.046,253,4.297,259,4.694,260,4.694]],["t/405",[4,3.073,86,2.828,237,3.751,239,3.415]],["t/407",[237,2.751,239,2.504,249,3.533,257,3.533,261,3.86,262,3.86,263,3.86]],["t/409",[19,3.346,190,3.84,237,3.346,239,3.046,264,4.694]],["t/411",[68,4.12,265,6.36]],["t/415",[71,4.561]],["t/417",[8,3.831,9,3.831]],["t/419",[10,3.781,266,6.36]],["t/420",[13,2.555,16,3.11,159,3.443,267,4.297,268,4.694]],["t/422",[56,3.61,73,3.552,86,3.218]],["t/424",[18,2.378,80,2.784,269,4.694,270,3.684,271,4.694]],["t/426",[19,3.019,81,3.019,82,2.1,129,2.695,246,3.207,272,3.878]],["t/428",[18,2.666,93,3.86,147,3.751,272,4.818]],["t/430",[273,5.482,274,5.482,275,5.989]],["t/432",[42,2.624,159,3.443,267,4.297,276,4.694,277,4.694]],["t/434",[61,3.415,85,3.073,125,2.828,278,5.263]],["t/436",[89,3.073,190,4.306,279,4.818,280,4.306]],["t/438",[114,4.823,280,5.683]],["t/440",[18,3.519,280,5.683]],["t/442",[280,5.683,281,6.947]],["t/444",[282,6.36,283,6.947]],["t/446",[61,2.3,92,2.213,125,1.905,158,2.402,159,2.6,284,3.545,285,3.545,286,3.545]],["t/448",[58,4.158,70,3.61,96,4.7]],["t/450",[48,3.883,68,4.12]],["t/454",[71,4.561]],["t/456",[8,3.831,9,3.831]],["t/458",[10,3.26,11,3.61,12,3.552]],["t/459",[13,3.26,46,3.552,287,5.149]],["t/460",[46,3.121,73,3.121,184,2.115,288,4.525]],["t/462",[80,3.121,157,3.654,289,3.86,290,4.131]],["t/464",[129,3.348,134,3.415,135,3.488,136,3.567]],["t/466",[21,3.465,86,2.276,147,3.019,157,2.941,289,3.107,290,3.325]],["t/468",[74,5.26,86,3.733]],["t/470",[86,3.733,151,4.419]],["t/472",[42,3.883,70,4.188]],["t/473",[85,3.073,148,3.348,237,3.751,291,5.263]],["t/474",[117,6.066]],["t/476",[61,5.366]],["t/478",[19,5.894]],["t/480",[89,3.073,135,3.488,136,3.567,148,3.348]],["t/481",[117,6.066]],["t/483",[61,5.366]],["t/485",[58,4.158,59,4.268,92,3.739]],["t/486",[28,5.452,292,6.947]],["t/488",[157,4.158,289,4.393,290,4.7]],["t/490",[168,5.149,293,5.989,294,5.989]],["t/492",[21,3.465,86,2.276,96,3.325,157,2.941,289,3.107,290,3.325]],["t/493",[117,6.066]],["t/495",[61,5.366]],["t/497",[48,3.883,68,4.12]],["t/501",[71,4.561]],["t/503",[8,3.831,9,3.831]],["t/505",[10,3.26,11,3.61,12,3.552]],["t/506",[13,2.864,46,3.121,287,4.525,295,5.263]],["t/507",[157,4.158,289,4.393,290,4.7]],["t/509",[87,4.306,135,3.488,136,3.567,296,5.263]],["t/511",[132,3.84,133,3.84,134,3.046,135,3.11,136,3.181]],["t/513",[42,2.942,46,3.121,287,4.525,297,4.306]],["t/514",[28,3.684,78,3.84,82,2.327,85,2.741,298,4.297]],["t/516",[176,6.066]],["t/518",[18,2.378,89,2.741,126,4.297,246,3.554,299,4.694]],["t/520",[176,6.066]],["t/522",[27,4.297,92,2.93,137,3.554,300,4.035,301,4.035]],["t/524",[96,4.7,139,4.059,302,5.482]],["t/526",[48,3.883,70,4.188]],["t/527",[53,4.158,116,4.535,163,4.535]],["t/528",[18,3.519,94,4.708]],["t/530",[118,4.507,119,4.337]],["t/532",[86,2.522,151,2.986,170,3.554,237,3.346,303,4.694]],["t/534",[86,2.828,237,3.751,301,4.525,304,4.131]],["t/536",[22,5.452,154,5.683]],["t/538",[17,5.26,301,5.972]],["t/540",[139,4.708,302,6.36]],["t/542",[57,4.708,68,4.12]],["t/546",[71,4.561]],["t/548",[8,3.831,9,3.831]],["t/550",[305,6.947,306,6.947]],["t/552",[10,3.26,307,5.482,308,5.482]],["t/554",[13,2.306,309,4.236,310,3.878,311,4.236,312,4.236,313,4.236]],["t/556",[28,3.684,46,2.784,114,3.259,314,4.694,315,4.297]],["t/558",[36,3.985,184,2.115,316,5.263,317,5.263]],["t/560",[42,3.348,72,3.552,251,5.482]],["t/562",[85,2.473,318,3.325,319,3.207,320,3.642,321,3.465,322,3.878]],["t/564",[4,3.073,81,3.751,82,2.609,323,4.525]],["t/566",[114,4.158,161,5.149,315,5.482]],["t/568",[75,4.131,89,3.073,324,4.818,325,4.306]],["t/570",[175,4.535,326,5.989,327,5.989]],["t/572",[48,3.348,70,3.61,328,5.482]],["t/574",[127,5.683,163,5.26]],["t/576",[81,4.268,82,2.969,329,5.989]],["t/578",[78,5.683,330,6.947]],["t/580",[82,2.609,331,3.985,332,4.818,333,5.263]],["t/582",[28,4.131,82,2.609,331,3.985,334,5.263]],["t/584",[46,4.12,82,3.444]],["t/586",[325,6.766]],["t/588",[170,4.535,335,5.989,336,5.989]],["t/590",[304,4.7,337,5.989,338,5.989]],["t/592",[10,2.864,339,4.818,340,4.818,341,5.263]],["t/594",[13,2.306,34,3.878,217,3.107,340,3.878,342,4.236,343,4.236]],["t/596",[11,3.61,12,3.552,57,4.059]],["t/597",[17,3.554,67,3.443,318,3.684,319,3.554,321,3.84]],["t/599",[75,3.325,322,3.878,324,3.878,325,3.465,344,3.642,345,4.236]],["t/601",[36,3.554,319,3.554,325,3.84,346,4.035,347,4.297]],["t/603",[64,3.554,347,4.297,348,4.297,349,4.035,350,4.297]],["t/605",[64,3.207,348,3.878,349,3.642,350,3.878,351,4.236,352,4.236]],["t/607",[46,2.289,279,3.533,353,3.318,354,3.86,355,3.86,356,3.86,357,3.86]],["t/609",[12,3.121,68,3.121,199,4.131,358,5.263]],["t/613",[71,4.561]],["t/615",[8,3.831,9,3.831]],["t/617",[10,3.26,11,3.61,12,3.552]],["t/618",[19,3.751,44,3.073,55,4.525,246,3.985]],["t/620",[44,4.056,359,5.972]],["t/622",[137,5.26,360,5.683]],["t/624",[13,3.781,102,5.972]],["t/626",[82,3.444,184,2.792]],["t/628",[73,3.121,82,2.609,184,2.115,359,4.525]],["t/630",[184,2.792,361,5.972]],["t/632",[184,2.792,360,5.683]],["t/634",[18,2.378,46,2.784,80,2.784,362,4.297,363,4.297]],["t/636",[19,4.951,246,5.26]],["t/638",[42,3.883,70,4.188]],["t/640",[53,4.158,85,3.497,364,5.989]],["t/641",[56,4.188,125,3.733]],["t/643",[86,4.444]],["t/645",[127,6.766]],["t/647",[118,4.507,119,4.337]],["t/649",[50,3.178,89,3.497,162,4.7]],["t/650",[46,3.552,56,3.61,323,5.149]],["t/652",[46,3.552,158,4.059,159,4.393]],["t/654",[4,3.073,125,2.828,151,3.348,365,4.525]],["t/656",[86,3.733,217,5.095]],["t/658",[88,4.899,184,2.407,366,5.989]],["t/660",[58,4.158,59,4.268,92,3.739]],["t/661",[184,2.407,360,4.899,361,5.149]],["t/663",[108,5.095,360,5.683]],["t/665",[184,2.792,270,5.452]],["t/667",[46,3.552,172,4.899,363,5.482]],["t/669",[125,3.218,171,5.482,367,5.989]],["t/671",[125,2.828,205,3.654,362,4.818,368,5.263]],["t/673",[48,3.883,68,4.12]],["t/677",[71,4.561]],["t/679",[8,3.831,9,3.831]],["t/681",[10,3.781,45,6.36]],["t/683",[13,2.864,72,3.121,82,2.609,369,4.131]],["t/685",[15,4.951,73,4.12]],["t/687",[36,5.26,80,4.12]],["t/689",[42,3.883,70,4.188]],["t/691",[85,3.497,137,4.535,370,5.482]],["t/693",[56,3.61,371,5.989,372,5.989]],["t/695",[50,3.687,373,6.947]],["t/697",[89,4.056,374,6.947]],["t/699",[44,3.073,101,4.525,375,4.818,376,5.263]],["t/701",[44,3.073,158,3.567,159,3.86,377,4.818]],["t/703",[82,1.757,239,3.631,369,2.782,378,3.245,379,5.122,380,3.545]],["t/705",[11,3.61,12,3.552,48,3.348]],["t/706",[57,4.708,68,4.12]],["t/710",[71,4.561]],["t/712",[8,3.831,9,3.831]],["t/714",[10,3.781,381,6.947]],["t/715",[125,3.733,382,6.36]],["t/717",[82,3.444,184,2.792]],["t/719",[13,2.864,82,2.609,297,4.306,369,4.131]],["t/720",[73,3.552,383,5.149,384,5.149]],["t/722",[217,4.393,383,5.149,384,5.149]],["t/724",[125,3.218,383,5.149,384,5.149]],["t/726",[80,3.121,82,2.609,184,2.115,385,5.263]],["t/728",[36,4.535,118,3.886,129,3.809]],["t/729",[386,8.271]],["t/731",[184,2.792,270,5.452]],["t/733",[44,3.497,125,3.218,135,3.969]],["t/735",[160,5.972,387,6.36]],["t/737",[42,3.883,70,4.188]],["t/739",[125,3.733,382,6.36]],["t/741",[18,3.034,86,3.218,93,4.393]],["t/743",[44,4.056,359,5.972]],["t/745",[82,2.327,85,2.741,217,3.443,297,3.84,369,3.684]],["t/747",[82,2.327,89,2.741,125,2.522,297,3.84,369,3.684]],["t/749",[58,4.158,59,4.268,92,3.739]],["t/750",[232,2.684,298,3.245,379,3.245,387,5.122,388,3.245,389,3.545,390,2.782]],["t/752",[184,2.792,391,6.947]],["t/754",[48,3.883,68,4.12]],["t/758",[71,4.561]],["t/760",[8,3.831,9,3.831]],["t/762",[10,3.26,11,3.61,12,3.552]],["t/763",[13,3.26,307,5.482,308,5.482]],["t/765",[73,3.552,232,4.535,392,5.989]],["t/767",[80,3.121,236,4.818,393,5.263,394,5.263]],["t/769",[81,4.268,82,2.969,129,3.809]],["t/771",[42,3.348,82,2.969,331,4.535]],["t/772",[85,4.056,395,6.947]],["t/774",[72,4.12,89,4.056]],["t/776",[92,3.739,320,5.149,396,5.989]],["t/778",[48,3.348,53,4.158,116,4.535]],["t/779",[56,3.61,88,4.899,163,4.535]],["t/781",[72,4.12,170,5.26]],["t/783",[15,4.268,304,4.7,397,5.989]],["t/785",[49,4.393,50,3.178,57,4.059]],["t/786",[4,3.073,229,3.86,398,4.818,399,5.263]],["t/788",[69,6.36,400,6.36]],["t/790",[94,3.567,117,3.86,318,4.131,401,5.263]],["t/792",[402,6.947,403,6.947]],["t/794",[67,4.393,148,3.809,404,5.989]],["t/795",[270,4.7,331,4.535,344,5.149]],["t/797",[323,4.525,332,4.818,346,4.525,405,4.818]],["t/799",[82,3.184,331,3.207,353,3.642,405,3.878,406,4.236]],["t/801",[289,5.095,407,6.36]],["t/803",[19,4.268,94,4.059,408,5.482]],["t/805",[176,5.095,199,5.452]],["t/806",[409,8.271]],["t/808",[112,6.36,410,6.947]],["t/810",[78,4.306,82,2.609,331,3.985,411,5.263]],["t/814",[71,4.561]],["t/816",[8,3.831,9,3.831]],["t/818",[10,3.26,82,2.969,184,2.407]],["t/820",[16,3.969,103,4.7,412,5.482]],["t/822",[107,4.131,224,4.818,413,5.263,414,5.263]],["t/824",[13,3.781,50,3.687]],["t/826",[73,3.552,415,5.989,416,5.989]],["t/828",[58,4.158,59,4.268,80,3.552]],["t/829",[184,2.792,270,5.452]],["t/831",[184,2.792,289,5.095]],["t/833",[18,3.034,93,4.393,108,4.393]],["t/835",[41,4.131,42,2.942,102,4.525,349,4.525]],["t/837",[48,2.942,417,5.263,418,5.263,419,5.263]],["t/839",[57,4.059,184,2.407,420,4.899]],["t/841",[67,5.095,421,6.947]],["t/843",[68,4.12,199,5.452]],["t/847",[71,4.561]],["t/849",[8,3.831,9,3.831]],["t/851",[10,3.26,11,3.61,12,3.552]],["t/852",[13,2.306,388,3.878,422,3.878,423,4.236,424,4.236,425,3.878]],["t/854",[426,8.271]],["t/856",[148,5.261]],["t/858",[100,5.972,425,6.36]],["t/860",[282,7.571]],["t/862",[422,6.36,427,6.36]],["t/864",[42,3.883,70,4.188]],["t/865",[85,2.741,412,4.297,428,4.694,429,4.694,430,4.694]],["t/866",[89,3.497,134,3.886,431,5.989]],["t/867",[92,4.337,432,6.947]],["t/868",[58,4.823,59,4.951]],["t/869",[48,3.883,175,5.26]],["t/873",[71,4.561]],["t/875",[8,2.128,151,2.455,365,3.318,427,3.533,433,3.533,434,3.86,435,3.86]],["t/877",[10,2.864,184,2.115,436,5.263,437,5.263]],["t/878",[44,3.073,101,4.525,103,4.131,438,4.525]],["t/880",[107,4.7,184,2.407,439,5.989]],["t/882",[161,5.149,184,2.407,440,5.989]],["t/884",[39,4.899,191,3.886,441,5.989]],["t/886",[191,3.886,442,5.989,443,5.989]],["t/888",[16,3.488,110,4.525,184,2.115,444,5.263]],["t/890",[13,2.864,184,2.115,209,4.131,445,4.306]],["t/892",[73,3.552,184,2.407,446,5.482]],["t/894",[80,3.121,209,4.131,445,4.306,447,4.818]],["t/896",[44,3.073,129,3.348,209,4.131,448,5.263]],["t/898",[184,2.407,449,5.989,450,5.482]],["t/900",[184,2.407,451,5.989,452,5.482]],["t/902",[42,2.942,184,2.115,191,3.415,445,4.306]],["t/904",[85,3.497,191,3.886,446,5.482]],["t/906",[16,3.11,72,2.784,89,2.741,191,3.046,453,4.694]],["t/908",[16,3.969,375,5.482,447,5.482]],["t/910",[39,4.306,191,3.415,377,4.818,450,4.818]],["t/912",[39,4.306,191,3.415,378,4.818,452,4.818]],["t/914",[44,3.073,48,2.942,135,3.488,184,2.115]],["t/916",[163,4.535,184,2.407,420,4.899]],["t/918",[170,4.535,184,2.407,454,5.989]],["t/920",[184,2.407,304,4.7,455,5.989]],["t/922",[184,2.407,339,5.482,361,5.149]],["t/924",[18,2.378,57,3.181,72,2.784,172,3.84,184,1.887]],["t/926",[18,3.034,117,4.393,398,5.482]],["t/928",[72,3.121,246,3.985,321,4.306,400,4.818]],["t/930",[81,3.751,82,2.609,456,5.263,457,5.263]],["t/932",[82,2.609,178,4.818,184,2.115,458,5.263]],["t/934",[82,2.327,184,1.887,232,3.554,459,4.694,460,4.297]],["t/936",[82,2.327,184,1.887,232,3.554,460,4.297,461,4.694]],["t/938",[82,2.969,462,5.989,463,5.989]],["t/940",[67,5.095,464,6.36]],["t/942",[137,4.535,344,5.149,370,5.482]],["t/944",[346,5.149,465,5.989,466,5.989]],["t/946",[125,2.828,160,4.525,210,4.131,353,4.525]],["t/948",[207,5.482,407,5.482,467,5.989]],["t/950",[134,3.886,408,5.482,438,5.149]],["t/952",[191,3.886,208,4.535,468,5.989]],["t/954",[4,3.497,229,4.393,469,5.989]],["t/956",[4,2.741,148,2.986,229,3.443,470,4.694,471,4.694]],["t/958",[464,5.482,472,5.989,473,5.989]],["t/960",[44,3.073,135,3.488,136,3.567,474,5.263]],["t/962",[184,2.115,199,4.131,212,4.818,475,5.263]],["t/964",[265,6.36,476,6.947]],["t/966",[18,2.378,93,3.443,232,3.554,477,4.694,478,4.297]],["t/968",[16,3.969,184,2.407,479,5.989]],["t/970",[184,2.115,191,3.415,445,4.306,480,5.263]],["t/972",[82,2.609,172,4.306,478,4.818,481,5.263]],["t/974",[44,3.073,184,2.115,482,5.263,483,5.263]],["t/976",[162,3.684,184,1.887,328,4.297,484,4.694,485,4.694]],["t/978",[55,5.149,184,2.407,486,5.989]],["t/980",[64,3.985,274,4.818,487,5.263,488,5.263]],["t/982",[72,3.121,184,2.115,489,5.263,490,5.263]],["t/986",[71,4.561]],["t/988",[8,3.831,9,3.831]],["t/990",[10,3.26,11,3.61,12,3.552]],["t/991",[13,2.864,72,3.121,116,3.985,119,3.285]],["t/992",[73,3.121,491,5.263,492,4.818,493,5.263]],["t/994",[56,4.188,80,4.12]],["t/996",[125,3.733,129,4.419]],["t/998",[94,3.567,147,3.751,494,5.263,495,5.263]],["t/1000",[86,3.733,273,6.36]],["t/1002",[148,4.419,496,6.947]],["t/1004",[42,3.883,50,3.687]],["t/1005",[50,2.793,85,3.073,497,5.263,498,4.818]],["t/1007",[50,2.491,56,2.83,89,2.741,438,4.035,499,4.694]],["t/1009",[50,3.178,92,3.739,130,5.482]],["t/1011",[48,3.883,176,5.095]],["t/1012",[163,3.985,500,5.263,501,4.818,502,5.263]],["t/1014",[170,5.26,501,6.36]],["t/1015",[175,5.26,304,5.452]],["t/1017",[503,8.271]],["t/1019",[72,4.905]],["t/1021",[175,6.262]],["t/1025",[504,6.947,505,6.947]],["t/1029",[506,4.7,507,4.899,508,5.989]],["t/1033",[506,4.7,507,4.899,509,5.149]],["t/1035",[510,6.36,511,6.947]],["t/1039",[506,4.131,507,4.306,512,4.818,513,4.818]],["t/1041",[506,4.131,507,4.306,513,4.818,514,5.263]],["t/1045",[6,5.452,515,6.36]],["t/1050",[516,6.947,517,6.947]],["t/1052",[518,8.271]],["t/1054",[22,6.491]],["t/1056",[222,5.095,519,6.947]],["t/1058",[520,8.271]],["t/1060",[141,5.149,512,5.482,521,5.989]],["t/1064",[506,4.7,509,5.149,522,5.149]],["t/1066",[522,5.149,523,5.482,524,5.482]],["t/1068",[310,5.482,321,4.899,522,5.149]],["t/1072",[510,6.36,525,6.947]],["t/1074",[509,5.972,526,6.947]],["t/1076",[1,5.149,6,4.7,527,5.149]],["t/1078",[523,5.482,524,5.482,527,5.149]],["t/1080",[6,4.7,515,5.482,527,5.149]],["t/1084",[71,4.561]],["t/1086",[8,3.831,9,3.831]],["t/1088",[10,3.26,11,3.61,12,3.552]],["t/1089",[13,3.781,528,6.947]],["t/1091",[4,3.497,73,3.552,184,2.407]],["t/1093",[22,3.684,80,2.784,184,1.887,300,4.035,529,4.694]],["t/1095",[108,3.86,129,3.348,530,5.263,531,5.263]],["t/1097",[18,3.034,114,4.158,147,4.268]],["t/1098",[18,4.19]],["t/1100",[114,5.742]],["t/1102",[42,3.883,70,4.188]],["t/1103",[85,3.497,118,3.886,119,3.739]],["t/1105",[89,3.073,125,2.828,148,3.348,532,5.263]],["t/1106",[108,3.86,120,4.525,121,4.818,122,4.818]],["t/1108",[533,6.947,534,6.947]],["t/1110",[535,8.271]],["t/1112",[536,7.571]],["t/1114",[537,7.571]],["t/1116",[537,7.571]],["t/1118",[538,8.271]],["t/1120",[536,6.36,539,6.947]],["t/1122",[58,4.158,92,3.739,162,4.7]],["t/1124",[300,7.11]],["t/1126",[540,8.271]],["t/1128",[541,8.271]],["t/1130",[48,3.883,68,4.12]],["t/1134",[71,4.561]],["t/1136",[8,3.831,9,3.831]],["t/1138",[10,3.781,266,6.36]],["t/1139",[75,4.7,86,3.218,210,4.7]],["t/1141",[46,3.552,318,4.7,319,4.535]],["t/1143",[13,3.26,72,3.552,542,5.989]],["t/1145",[46,3.121,73,3.121,210,4.131,543,5.263]],["t/1147",[37,4.297,66,3.84,80,2.784,319,3.554,544,4.694]],["t/1149",[545,5.989,546,5.989,547,5.989]],["t/1151",[66,4.899,210,4.7,548,5.989]],["t/1153",[129,3.348,549,5.263,550,4.525,551,5.263]],["t/1155",[42,3.883,70,4.188]],["t/1157",[118,4.507,119,4.337]],["t/1159",[127,6.766]],["t/1161",[17,3.985,85,3.073,151,3.348,365,4.525]],["t/1162",[56,4.188,86,3.733]],["t/1164",[118,4.507,119,4.337]],["t/1166",[49,5.095,50,3.687]],["t/1168",[89,3.497,191,3.886,208,4.535]],["t/1169",[56,4.188,86,3.733]],["t/1171",[118,4.507,119,4.337]],["t/1173",[49,5.095,50,3.687]],["t/1175",[4,3.073,92,3.285,151,3.348,552,5.263]],["t/1176",[56,4.188,86,3.733]],["t/1178",[118,4.507,119,4.337]],["t/1180",[49,5.095,50,3.687]],["t/1182",[96,5.452,162,5.452]],["t/1183",[64,4.535,492,5.482,550,5.149]],["t/1185",[41,4.131,318,4.131,319,3.985,320,4.525]],["t/1187",[66,4.899,87,4.899,553,5.989]],["t/1189",[141,5.149,433,5.482,554,5.989]],["t/1191",[50,3.178,498,5.482,550,5.149]],["t/1193",[48,3.883,68,4.12]],["t/1197",[71,4.561]],["t/1199",[9,4.561]],["t/1201",[11,4.188,12,4.12]],["t/1202",[74,4.535,86,3.218,151,3.809]],["t/1204",[44,4.056,184,2.792]],["t/1206",[18,3.519,100,5.972]],["t/1208",[72,4.905]],["t/1210",[138,6.36,555,6.947]],["t/1212",[4,3.497,390,4.7,556,4.899]],["t/1213",[114,4.823,557,6.947]],["t/1215",[4,3.497,390,4.7,556,4.899]],["t/1217",[390,4.7,420,4.899,556,4.899]],["t/1219",[36,4.535,181,4.7,184,2.407]],["t/1221",[181,4.7,184,2.407,288,5.149]],["t/1223",[114,5.742]],["t/1225",[181,4.7,184,2.407,420,4.899]],["t/1227",[70,4.986]],["t/1228",[118,4.507,119,4.337]],["t/1229",[74,4.535,86,3.218,151,3.809]],["t/1231",[4,3.497,390,4.7,556,4.899]],["t/1233",[181,4.7,184,2.407,288,5.149]],["t/1235",[18,3.519,119,4.337]],["t/1237",[56,4.986]],["t/1239",[49,5.095,50,3.687]],["t/1241",[68,4.905]]],"invertedIndex":[["",{"_index":7,"t":{"22":{"position":[[0,2]]},"105":{"position":[[9,1]]}}}],["1",{"_index":8,"t":{"24":{"position":[[0,2]]},"85":{"position":[[0,2]]},"125":{"position":[[0,2]]},"164":{"position":[[0,2]]},"228":{"position":[[0,2]]},"280":{"position":[[0,2]]},"329":{"position":[[0,2]]},"367":{"position":[[0,2]]},"417":{"position":[[0,2]]},"456":{"position":[[0,2]]},"503":{"position":[[0,2]]},"548":{"position":[[0,2]]},"615":{"position":[[0,2]]},"679":{"position":[[0,2]]},"712":{"position":[[0,2]]},"760":{"position":[[0,2]]},"816":{"position":[[0,2]]},"849":{"position":[[0,1]]},"875":{"position":[[0,2]]},"988":{"position":[[0,2]]},"1086":{"position":[[0,2]]},"1136":{"position":[[0,2]]}}}],["1.8k",{"_index":247,"t":{"385":{"position":[[34,4]]}}}],["10",{"_index":532,"t":{"1105":{"position":[[19,2]]}}}],["175b",{"_index":343,"t":{"594":{"position":[[24,4]]}}}],["2",{"_index":10,"t":{"26":{"position":[[0,2]]},"87":{"position":[[0,2]]},"127":{"position":[[0,2]]},"166":{"position":[[0,2]]},"230":{"position":[[0,2]]},"282":{"position":[[0,2]]},"331":{"position":[[0,2]]},"369":{"position":[[0,2]]},"419":{"position":[[0,2]]},"458":{"position":[[0,2]]},"505":{"position":[[0,2]]},"552":{"position":[[0,2]]},"592":{"position":[[8,1]]},"617":{"position":[[0,2]]},"681":{"position":[[0,2]]},"714":{"position":[[0,2]]},"762":{"position":[[0,2]]},"818":{"position":[[0,2]]},"851":{"position":[[0,1]]},"877":{"position":[[0,1]]},"990":{"position":[[0,2]]},"1088":{"position":[[0,2]]},"1138":{"position":[[0,2]]}}}],["2.1",{"_index":103,"t":{"129":{"position":[[0,3]]},"283":{"position":[[0,3]]},"371":{"position":[[0,4]]},"820":{"position":[[0,3]]},"878":{"position":[[0,3]]}}}],["2.2",{"_index":107,"t":{"131":{"position":[[0,3]]},"285":{"position":[[0,3]]},"378":{"position":[[0,4]]},"822":{"position":[[0,3]]},"880":{"position":[[0,3]]}}}],["2.2.1",{"_index":440,"t":{"882":{"position":[[0,5]]}}}],["2.2.2",{"_index":441,"t":{"884":{"position":[[0,5]]}}}],["2.2.3",{"_index":442,"t":{"886":{"position":[[0,5]]}}}],["2.3",{"_index":110,"t":{"133":{"position":[[0,3]]},"380":{"position":[[0,4]]},"888":{"position":[[0,3]]}}}],["2.4",{"_index":113,"t":{"139":{"position":[[0,3]]}}}],["3",{"_index":13,"t":{"28":{"position":[[0,2]]},"89":{"position":[[0,2]]},"141":{"position":[[0,2]]},"167":{"position":[[0,2]]},"232":{"position":[[0,2]]},"291":{"position":[[0,2]]},"332":{"position":[[0,2]]},"385":{"position":[[0,2]]},"420":{"position":[[0,2]]},"459":{"position":[[0,2]]},"506":{"position":[[0,2]]},"554":{"position":[[0,2]]},"594":{"position":[[22,1]]},"624":{"position":[[0,2]]},"683":{"position":[[0,2]]},"719":{"position":[[0,2]]},"763":{"position":[[0,2]]},"824":{"position":[[0,2]]},"852":{"position":[[0,1]]},"890":{"position":[[0,1]]},"991":{"position":[[0,2]]},"1089":{"position":[[0,2]]},"1143":{"position":[[0,2]]}}}],["3.1",{"_index":73,"t":{"90":{"position":[[0,3]]},"142":{"position":[[0,3]]},"168":{"position":[[0,3]]},"234":{"position":[[0,4]]},"293":{"position":[[0,3]]},"334":{"position":[[0,4]]},"422":{"position":[[0,3]]},"460":{"position":[[0,3]]},"628":{"position":[[0,3]]},"685":{"position":[[0,3]]},"720":{"position":[[0,3]]},"765":{"position":[[0,3]]},"826":{"position":[[0,3]]},"892":{"position":[[0,3]]},"992":{"position":[[0,3]]},"1091":{"position":[[0,3]]},"1145":{"position":[[0,3]]}}}],["3.2",{"_index":80,"t":{"96":{"position":[[0,3]]},"154":{"position":[[0,3]]},"170":{"position":[[0,3]]},"243":{"position":[[0,4]]},"295":{"position":[[0,3]]},"340":{"position":[[0,4]]},"424":{"position":[[0,3]]},"462":{"position":[[0,3]]},"634":{"position":[[0,3]]},"687":{"position":[[0,3]]},"726":{"position":[[0,3]]},"767":{"position":[[0,3]]},"828":{"position":[[0,3]]},"894":{"position":[[0,3]]},"994":{"position":[[0,3]]},"1093":{"position":[[0,3]]},"1147":{"position":[[0,3]]}}}],["3.3",{"_index":129,"t":{"156":{"position":[[0,3]]},"172":{"position":[[0,3]]},"245":{"position":[[0,4]]},"301":{"position":[[0,3]]},"348":{"position":[[0,4]]},"426":{"position":[[0,3]]},"464":{"position":[[0,3]]},"728":{"position":[[0,3]]},"769":{"position":[[0,3]]},"896":{"position":[[0,3]]},"996":{"position":[[0,3]]},"1095":{"position":[[0,3]]},"1153":{"position":[[0,3]]}}}],["3.3.1",{"_index":449,"t":{"898":{"position":[[0,5]]}}}],["3.3.2",{"_index":451,"t":{"900":{"position":[[0,5]]}}}],["3.4",{"_index":147,"t":{"179":{"position":[[0,3]]},"253":{"position":[[0,4]]},"303":{"position":[[0,3]]},"350":{"position":[[0,4]]},"428":{"position":[[0,3]]},"466":{"position":[[0,3]]},"998":{"position":[[0,3]]},"1097":{"position":[[0,3]]}}}],["3.5",{"_index":273,"t":{"430":{"position":[[0,3]]},"1000":{"position":[[0,3]]}}}],["3.6",{"_index":496,"t":{"1002":{"position":[[0,3]]}}}],["4",{"_index":42,"t":{"45":{"position":[[0,2]]},"98":{"position":[[0,2]]},"181":{"position":[[0,2]]},"255":{"position":[[0,2]]},"305":{"position":[[0,2]]},"358":{"position":[[0,2]]},"387":{"position":[[0,2]]},"432":{"position":[[0,2]]},"472":{"position":[[0,2]]},"513":{"position":[[0,2]]},"560":{"position":[[0,2]]},"638":{"position":[[0,2]]},"689":{"position":[[0,2]]},"737":{"position":[[0,2]]},"771":{"position":[[0,2]]},"835":{"position":[[0,2]]},"864":{"position":[[0,1]]},"902":{"position":[[0,1]]},"1004":{"position":[[0,2]]},"1102":{"position":[[0,2]]},"1155":{"position":[[0,2]]}}}],["4.1",{"_index":85,"t":{"100":{"position":[[0,3]]},"182":{"position":[[0,3]]},"307":{"position":[[0,3]]},"359":{"position":[[0,4]]},"389":{"position":[[0,4]]},"434":{"position":[[0,3]]},"473":{"position":[[0,3]]},"514":{"position":[[0,3]]},"562":{"position":[[0,3]]},"640":{"position":[[0,3]]},"691":{"position":[[0,3]]},"745":{"position":[[0,3]]},"772":{"position":[[0,3]]},"865":{"position":[[0,3]]},"904":{"position":[[0,3]]},"1005":{"position":[[0,3]]},"1103":{"position":[[0,3]]},"1161":{"position":[[0,3]]}}}],["4.1.1",{"_index":371,"t":{"693":{"position":[[0,5]]}}}],["4.1.2",{"_index":373,"t":{"695":{"position":[[0,5]]}}}],["4.2",{"_index":89,"t":{"109":{"position":[[0,3]]},"184":{"position":[[0,3]]},"314":{"position":[[0,3]]},"361":{"position":[[0,4]]},"391":{"position":[[0,4]]},"436":{"position":[[0,3]]},"480":{"position":[[0,3]]},"518":{"position":[[0,3]]},"568":{"position":[[0,3]]},"649":{"position":[[0,3]]},"697":{"position":[[0,3]]},"747":{"position":[[0,3]]},"774":{"position":[[0,3]]},"866":{"position":[[0,3]]},"906":{"position":[[0,3]]},"1007":{"position":[[0,3]]},"1105":{"position":[[0,3]]},"1168":{"position":[[0,3]]}}}],["4.2.1",{"_index":375,"t":{"699":{"position":[[0,5]]},"908":{"position":[[0,5]]}}}],["4.2.2",{"_index":377,"t":{"701":{"position":[[0,5]]},"910":{"position":[[0,5]]}}}],["4.2.3",{"_index":378,"t":{"703":{"position":[[0,5]]},"912":{"position":[[0,5]]}}}],["4.3",{"_index":92,"t":{"111":{"position":[[0,3]]},"191":{"position":[[0,3]]},"321":{"position":[[0,3]]},"393":{"position":[[0,4]]},"446":{"position":[[0,3]]},"485":{"position":[[0,3]]},"522":{"position":[[0,3]]},"660":{"position":[[0,3]]},"749":{"position":[[0,3]]},"776":{"position":[[0,3]]},"867":{"position":[[0,3]]},"1009":{"position":[[0,3]]},"1122":{"position":[[0,3]]},"1175":{"position":[[0,3]]}}}],["4.4",{"_index":96,"t":{"113":{"position":[[0,3]]},"448":{"position":[[0,3]]},"492":{"position":[[0,3]]},"524":{"position":[[0,3]]},"1182":{"position":[[0,3]]}}}],["4.5",{"_index":97,"t":{"115":{"position":[[0,3]]}}}],["4.6",{"_index":99,"t":{"117":{"position":[[0,3]]}}}],["5",{"_index":48,"t":{"50":{"position":[[0,2]]},"119":{"position":[[0,2]]},"158":{"position":[[0,2]]},"198":{"position":[[0,2]]},"262":{"position":[[0,2]]},"323":{"position":[[0,2]]},"395":{"position":[[0,2]]},"450":{"position":[[0,2]]},"497":{"position":[[0,2]]},"526":{"position":[[0,2]]},"572":{"position":[[0,2]]},"673":{"position":[[0,2]]},"705":{"position":[[0,2]]},"754":{"position":[[0,2]]},"778":{"position":[[0,2]]},"837":{"position":[[0,2]]},"869":{"position":[[0,1]]},"914":{"position":[[0,1]]},"1011":{"position":[[0,2]]},"1130":{"position":[[0,2]]},"1193":{"position":[[0,2]]}}}],["5.1",{"_index":163,"t":{"200":{"position":[[0,3]]},"527":{"position":[[0,3]]},"574":{"position":[[0,3]]},"779":{"position":[[0,3]]},"916":{"position":[[0,3]]},"1012":{"position":[[0,3]]}}}],["5.2",{"_index":170,"t":{"207":{"position":[[0,3]]},"532":{"position":[[0,3]]},"588":{"position":[[0,3]]},"781":{"position":[[0,3]]},"918":{"position":[[0,3]]},"1014":{"position":[[0,3]]}}}],["5.3",{"_index":304,"t":{"534":{"position":[[0,3]]},"590":{"position":[[0,3]]},"783":{"position":[[0,3]]},"920":{"position":[[0,3]]},"1015":{"position":[[0,3]]}}}],["5.4",{"_index":339,"t":{"592":{"position":[[0,3]]},"922":{"position":[[0,3]]}}}],["5.5",{"_index":342,"t":{"594":{"position":[[0,3]]}}}],["540b",{"_index":245,"t":{"385":{"position":[[14,4]]}}}],["6",{"_index":57,"t":{"66":{"position":[[0,2]]},"214":{"position":[[0,2]]},"270":{"position":[[0,2]]},"397":{"position":[[0,2]]},"542":{"position":[[0,2]]},"596":{"position":[[0,2]]},"706":{"position":[[0,2]]},"785":{"position":[[0,2]]},"839":{"position":[[0,2]]},"924":{"position":[[0,1]]}}}],["6.1",{"_index":398,"t":{"786":{"position":[[0,3]]},"926":{"position":[[0,3]]}}}],["6.2",{"_index":400,"t":{"788":{"position":[[0,3]]},"928":{"position":[[0,3]]}}}],["6.2.1",{"_index":456,"t":{"930":{"position":[[0,5]]}}}],["6.2.2",{"_index":458,"t":{"932":{"position":[[0,5]]}}}],["6.2.3",{"_index":459,"t":{"934":{"position":[[0,5]]}}}],["6.2.4",{"_index":461,"t":{"936":{"position":[[0,5]]}}}],["6.2.5",{"_index":462,"t":{"938":{"position":[[0,5]]}}}],["6.3",{"_index":401,"t":{"790":{"position":[[0,3]]}}}],["6.4",{"_index":402,"t":{"792":{"position":[[0,3]]}}}],["7",{"_index":67,"t":{"75":{"position":[[0,2]]},"272":{"position":[[0,2]]},"399":{"position":[[0,2]]},"597":{"position":[[0,2]]},"794":{"position":[[0,2]]},"841":{"position":[[0,2]]},"940":{"position":[[0,1]]}}}],["7.1",{"_index":344,"t":{"599":{"position":[[0,3]]},"795":{"position":[[0,3]]},"942":{"position":[[0,3]]}}}],["7.10",{"_index":474,"t":{"960":{"position":[[0,4]]}}}],["7.2",{"_index":346,"t":{"601":{"position":[[0,3]]},"797":{"position":[[0,3]]},"944":{"position":[[0,3]]}}}],["7.3",{"_index":353,"t":{"607":{"position":[[0,3]]},"799":{"position":[[0,3]]},"946":{"position":[[0,3]]}}}],["7.4",{"_index":407,"t":{"801":{"position":[[0,3]]},"948":{"position":[[0,3]]}}}],["7.5",{"_index":408,"t":{"803":{"position":[[0,3]]},"950":{"position":[[0,3]]}}}],["7.6",{"_index":468,"t":{"952":{"position":[[0,3]]}}}],["7.7",{"_index":469,"t":{"954":{"position":[[0,3]]}}}],["7.8",{"_index":470,"t":{"956":{"position":[[0,3]]}}}],["7.9",{"_index":472,"t":{"958":{"position":[[0,3]]}}}],["8",{"_index":199,"t":{"274":{"position":[[0,2]]},"609":{"position":[[0,2]]},"805":{"position":[[0,2]]},"843":{"position":[[0,2]]},"962":{"position":[[0,1]]}}}],["9",{"_index":265,"t":{"411":{"position":[[0,2]]},"964":{"position":[[0,1]]}}}],["9.1",{"_index":477,"t":{"966":{"position":[[0,3]]}}}],["9.2",{"_index":479,"t":{"968":{"position":[[0,3]]}}}],["9.3",{"_index":480,"t":{"970":{"position":[[0,3]]}}}],["9.4",{"_index":481,"t":{"972":{"position":[[0,3]]}}}],["9.5",{"_index":482,"t":{"974":{"position":[[0,3]]}}}],["9.6",{"_index":484,"t":{"976":{"position":[[0,3]]}}}],["9.7",{"_index":486,"t":{"978":{"position":[[0,3]]}}}],["9.8",{"_index":487,"t":{"980":{"position":[[0,3]]}}}],["9.9",{"_index":489,"t":{"982":{"position":[[0,3]]}}}],["abil",{"_index":253,"t":{"391":{"position":[[64,7]]},"403":{"position":[[41,9]]}}}],["ablat",{"_index":58,"t":{"66":{"position":[[3,8]]},"245":{"position":[[5,8]]},"448":{"position":[[4,8]]},"485":{"position":[[4,8]]},"660":{"position":[[4,8]]},"749":{"position":[[4,8]]},"828":{"position":[[4,8]]},"868":{"position":[[0,8]]},"1122":{"position":[[4,9]]}}}],["abstract",{"_index":71,"t":{"83":{"position":[[0,8]]},"123":{"position":[[0,8]]},"162":{"position":[[0,8]]},"226":{"position":[[0,8]]},"278":{"position":[[0,8]]},"327":{"position":[[0,8]]},"365":{"position":[[0,8]]},"415":{"position":[[0,8]]},"454":{"position":[[0,8]]},"501":{"position":[[0,8]]},"546":{"position":[[0,8]]},"613":{"position":[[0,8]]},"677":{"position":[[0,8]]},"710":{"position":[[0,8]]},"758":{"position":[[0,8]]},"814":{"position":[[0,8]]},"847":{"position":[[0,8]]},"873":{"position":[[0,8]]},"986":{"position":[[0,8]]},"1084":{"position":[[0,8]]},"1134":{"position":[[0,8]]},"1197":{"position":[[0,8]]}}}],["actor",{"_index":426,"t":{"854":{"position":[[0,5]]}}}],["adalora",{"_index":542,"t":{"1143":{"position":[[3,7]]}}}],["adapt",{"_index":46,"t":{"48":{"position":[[26,8]]},"73":{"position":[[14,8]]},"218":{"position":[[10,10]]},"350":{"position":[[5,10]]},"459":{"position":[[9,7]]},"460":{"position":[[14,10]]},"506":{"position":[[22,7]]},"513":{"position":[[9,7]]},"556":{"position":[[0,7]]},"584":{"position":[[0,7]]},"607":{"position":[[17,10]]},"634":{"position":[[31,10]]},"650":{"position":[[13,10]]},"652":{"position":[[9,10]]},"667":{"position":[[7,10]]},"1141":{"position":[[9,10]]},"1145":{"position":[[14,10]]}}}],["adaptor",{"_index":146,"t":{"177":{"position":[[12,7]]},"208":{"position":[[0,7]]}}}],["add",{"_index":523,"t":{"1066":{"position":[[0,3]]},"1078":{"position":[[0,3]]}}}],["addit",{"_index":161,"t":{"198":{"position":[[3,10]]},"566":{"position":[[3,10]]},"882":{"position":[[13,8]]}}}],["admonit",{"_index":520,"t":{"1058":{"position":[[0,11]]}}}],["advanc",{"_index":201,"t":{"283":{"position":[[11,8]]}}}],["alfworld",{"_index":430,"t":{"865":{"position":[[32,8]]}}}],["align",{"_index":501,"t":{"1012":{"position":[[21,9]]},"1014":{"position":[[15,8]]}}}],["alloc",{"_index":544,"t":{"1147":{"position":[[26,10]]}}}],["analysi",{"_index":162,"t":{"198":{"position":[[14,8]]},"649":{"position":[[16,8]]},"976":{"position":[[30,8]]},"1122":{"position":[[24,8]]},"1182":{"position":[[4,8]]}}}],["analyz",{"_index":366,"t":{"658":{"position":[[0,9]]}}}],["annot",{"_index":248,"t":{"387":{"position":[[36,11]]}}}],["answer",{"_index":191,"t":{"251":{"position":[[23,6]]},"293":{"position":[[4,6]]},"884":{"position":[[6,6]]},"886":{"position":[[6,6]]},"902":{"position":[[9,6]]},"904":{"position":[[4,6]]},"906":{"position":[[4,6]]},"910":{"position":[[15,6]]},"912":{"position":[[17,6]]},"952":{"position":[[13,9]]},"970":{"position":[[11,6]]},"1168":{"position":[[13,9]]}}}],["api",{"_index":497,"t":{"1005":{"position":[[19,3]]}}}],["appli",{"_index":324,"t":{"568":{"position":[[4,8]]},"599":{"position":[[51,5]]}}}],["applic",{"_index":464,"t":{"940":{"position":[[2,12]]},"958":{"position":[[9,12]]}}}],["approach",{"_index":102,"t":{"127":{"position":[[3,8]]},"624":{"position":[[3,8]]},"835":{"position":[[25,10]]}}}],["approch",{"_index":528,"t":{"1089":{"position":[[3,7]]}}}],["archirectur",{"_index":394,"t":{"767":{"position":[[20,12]]}}}],["architectur",{"_index":15,"t":{"28":{"position":[[18,12]]},"39":{"position":[[15,12]]},"94":{"position":[[7,12]]},"131":{"position":[[12,12]]},"172":{"position":[[8,13]]},"207":{"position":[[4,12]]},"685":{"position":[[4,12]]},"783":{"position":[[4,13]]}}}],["aren't",{"_index":309,"t":{"554":{"position":[[3,6]]}}}],["arithmet",{"_index":185,"t":{"232":{"position":[[3,10]]}}}],["art",{"_index":91,"t":{"109":{"position":[[31,3]]}}}],["attent",{"_index":290,"t":{"462":{"position":[[21,9]]},"466":{"position":[[21,9]]},"488":{"position":[[17,9]]},"492":{"position":[[21,9]]},"507":{"position":[[17,9]]}}}],["augment",{"_index":454,"t":{"918":{"position":[[11,12]]}}}],["autom",{"_index":448,"t":{"896":{"position":[[4,9]]}}}],["automat",{"_index":471,"t":{"956":{"position":[[4,9]]}}}],["autoregress",{"_index":392,"t":{"765":{"position":[[4,14]]}}}],["awar",{"_index":37,"t":{"36":{"position":[[9,5]]},"1147":{"position":[[15,5]]}}}],["backbon",{"_index":174,"t":{"212":{"position":[[21,9]]}}}],["background",{"_index":266,"t":{"419":{"position":[[3,10]]},"1138":{"position":[[3,10]]}}}],["base",{"_index":210,"t":{"297":{"position":[[9,5]]},"946":{"position":[[19,5]]},"1139":{"position":[[12,5]]},"1145":{"position":[[8,5]]},"1151":{"position":[[12,5]]}}}],["base/larg",{"_index":336,"t":{"588":{"position":[[12,10]]}}}],["baselin",{"_index":127,"t":{"152":{"position":[[0,9]]},"574":{"position":[[4,9]]},"645":{"position":[[0,8]]},"1159":{"position":[[0,9]]}}}],["basic",{"_index":439,"t":{"880":{"position":[[14,6]]}}}],["batch",{"_index":112,"t":{"137":{"position":[[0,5]]},"808":{"position":[[0,8]]}}}],["benchmark",{"_index":152,"t":{"191":{"position":[[31,10]]},"235":{"position":[[0,10]]},"256":{"position":[[0,10]]},"381":{"position":[[11,11]]}}}],["benefit",{"_index":327,"t":{"570":{"position":[[10,8]]}}}],["better",{"_index":167,"t":{"201":{"position":[[14,6]]},"203":{"position":[[0,6],[16,6]]}}}],["between",{"_index":350,"t":{"603":{"position":[[20,7]]},"605":{"position":[[20,7]]}}}],["bia",{"_index":78,"t":{"92":{"position":[[10,4]]},"514":{"position":[[4,4]]},"578":{"position":[[0,4]]},"810":{"position":[[10,4]]}}}],["bimod",{"_index":228,"t":{"340":{"position":[[5,7]]}}}],["bitfit",{"_index":330,"t":{"578":{"position":[[13,6]]}}}],["block",{"_index":519,"t":{"1056":{"position":[[5,6]]}}}],["budget",{"_index":550,"t":{"1153":{"position":[[11,6]]},"1183":{"position":[[10,6]]},"1191":{"position":[[14,6]]}}}],["build",{"_index":515,"t":{"1045":{"position":[[0,5]]},"1080":{"position":[[0,5]]}}}],["calibr",{"_index":490,"t":{"982":{"position":[[4,11]]}}}],["capabl",{"_index":219,"t":{"317":{"position":[[42,12]]}}}],["caption",{"_index":154,"t":{"192":{"position":[[28,8]]},"194":{"position":[[31,10]]},"301":{"position":[[22,7]]},"536":{"position":[[6,10]]}}}],["causal",{"_index":226,"t":{"338":{"position":[[0,6]]},"346":{"position":[[10,6]]}}}],["chain",{"_index":182,"t":{"230":{"position":[[3,5]]},"239":{"position":[[0,5]]},"251":{"position":[[0,5]]},"253":{"position":[[19,5]]},"374":{"position":[[0,5]]},"387":{"position":[[19,5]]},"389":{"position":[[19,5]]},"391":{"position":[[10,5]]}}}],["challeng",{"_index":476,"t":{"964":{"position":[[2,10]]}}}],["chang",{"_index":435,"t":{"875":{"position":[[11,7]]}}}],["chatgpt",{"_index":503,"t":{"1017":{"position":[[0,7]]}}}],["cl",{"_index":389,"t":{"750":{"position":[[29,5]]}}}],["classif",{"_index":160,"t":{"196":{"position":[[33,14]]},"735":{"position":[[0,14]]},"946":{"position":[[4,14]]}}}],["clip",{"_index":557,"t":{"1213":{"position":[[13,4]]}}}],["clm",{"_index":227,"t":{"338":{"position":[[25,5]]}}}],["close",{"_index":415,"t":{"826":{"position":[[4,7]]}}}],["coco",{"_index":153,"t":{"192":{"position":[[23,4]]}}}],["code",{"_index":222,"t":{"332":{"position":[[17,4]]},"334":{"position":[[29,4]]},"340":{"position":[[33,4]]},"342":{"position":[[5,4]]},"344":{"position":[[5,4]]},"346":{"position":[[5,4]]},"1056":{"position":[[0,4]]}}}],["codet5",{"_index":221,"t":{"332":{"position":[[3,8]]}}}],["coin",{"_index":197,"t":{"268":{"position":[[0,4]]}}}],["collect",{"_index":495,"t":{"998":{"position":[[15,10]]}}}],["combin",{"_index":274,"t":{"430":{"position":[[4,9]]},"980":{"position":[[4,11]]}}}],["commonsens",{"_index":192,"t":{"255":{"position":[[3,11]]}}}],["compar",{"_index":279,"t":{"436":{"position":[[4,9]]},"607":{"position":[[51,7]]}}}],["comparison",{"_index":41,"t":{"43":{"position":[[15,10]]},"67":{"position":[[0,10]]},"109":{"position":[[4,10]]},"835":{"position":[[3,10]]},"1185":{"position":[[0,10]]}}}],["compet",{"_index":214,"t":{"312":{"position":[[0,9]]}}}],["competit",{"_index":220,"t":{"319":{"position":[[0,11]]}}}],["compon",{"_index":141,"t":{"172":{"position":[[22,10]]},"1060":{"position":[[14,10]]},"1189":{"position":[[16,10]]}}}],["composit",{"_index":455,"t":{"920":{"position":[[11,11]]}}}],["comput",{"_index":190,"t":{"249":{"position":[[9,7]]},"348":{"position":[[5,7]]},"409":{"position":[[37,7]]},"436":{"position":[[14,13]]}}}],["concaten",{"_index":196,"t":{"266":{"position":[[12,13]]}}}],["conclus",{"_index":68,"t":{"75":{"position":[[3,10]]},"119":{"position":[[3,10]]},"158":{"position":[[3,10]]},"214":{"position":[[3,12]]},"274":{"position":[[3,11]]},"411":{"position":[[3,11]]},"450":{"position":[[3,10]]},"497":{"position":[[3,10]]},"542":{"position":[[3,10]]},"609":{"position":[[3,10]]},"673":{"position":[[3,10]]},"706":{"position":[[3,10]]},"754":{"position":[[3,11]]},"843":{"position":[[3,10]]},"1130":{"position":[[3,11]]},"1193":{"position":[[3,10]]},"1241":{"position":[[0,10]]}}}],["configur",{"_index":510,"t":{"1035":{"position":[[0,9]]},"1072":{"position":[[0,9]]}}}],["consider",{"_index":444,"t":{"888":{"position":[[11,14]]}}}],["context",{"_index":177,"t":{"216":{"position":[[15,7]]}}}],["continu",{"_index":452,"t":{"900":{"position":[[6,10]]},"912":{"position":[[6,10]]}}}],["contrast",{"_index":230,"t":{"342":{"position":[[10,11]]}}}],["convent",{"_index":306,"t":{"550":{"position":[[18,11]]}}}],["convolut",{"_index":26,"t":{"32":{"position":[[10,12]]},"173":{"position":[[18,13]]}}}],["corrupt",{"_index":414,"t":{"822":{"position":[[20,10]]}}}],["cost",{"_index":280,"t":{"436":{"position":[[28,5]]},"438":{"position":[[10,4]]},"440":{"position":[[9,4]]},"442":{"position":[[8,4]]}}}],["cot",{"_index":259,"t":{"403":{"position":[[0,3]]}}}],["creat",{"_index":506,"t":{"1029":{"position":[[0,6]]},"1033":{"position":[[0,6]]},"1039":{"position":[[0,6]]},"1041":{"position":[[0,6]]},"1064":{"position":[[0,6]]}}}],["critic",{"_index":260,"t":{"403":{"position":[[18,8]]}}}],["curv",{"_index":258,"t":{"401":{"position":[[8,6]]}}}],["data",{"_index":94,"t":{"111":{"position":[[16,4]]},"135":{"position":[[0,4]]},"334":{"position":[[34,4]]},"340":{"position":[[38,4]]},"371":{"position":[[16,4]]},"391":{"position":[[27,4]]},"528":{"position":[[9,4]]},"790":{"position":[[8,4]]},"803":{"position":[[4,4]]},"998":{"position":[[10,4]]}}}],["dataset",{"_index":56,"t":{"61":{"position":[[18,8]]},"101":{"position":[[0,8]]},"185":{"position":[[13,8]]},"308":{"position":[[0,8]]},"359":{"position":[[17,7]]},"422":{"position":[[14,8]]},"641":{"position":[[0,8]]},"650":{"position":[[5,7]]},"693":{"position":[[6,8]]},"779":{"position":[[4,8]]},"994":{"position":[[4,7]]},"1007":{"position":[[26,8]]},"1162":{"position":[[11,8]]},"1169":{"position":[[11,8]]},"1176":{"position":[[11,8]]},"1237":{"position":[[0,7]]}}}],["de",{"_index":115,"t":{"139":{"position":[[18,2]]}}}],["deberta",{"_index":337,"t":{"590":{"position":[[4,7]]}}}],["decis",{"_index":412,"t":{"820":{"position":[[11,9]]},"865":{"position":[[15,8]]}}}],["decod",{"_index":236,"t":{"354":{"position":[[0,7]]},"767":{"position":[[12,7]]}}}],["decomposit",{"_index":361,"t":{"630":{"position":[[7,13]]},"661":{"position":[[7,13]]},"922":{"position":[[11,13]]}}}],["deep",{"_index":385,"t":{"726":{"position":[[4,4]]}}}],["denois",{"_index":225,"t":{"336":{"position":[[5,9]]}}}],["depth",{"_index":391,"t":{"752":{"position":[[7,5]]}}}],["depthwis",{"_index":25,"t":{"32":{"position":[[0,9]]}}}],["descript",{"_index":437,"t":{"877":{"position":[[11,11]]}}}],["design",{"_index":16,"t":{"28":{"position":[[31,6]]},"207":{"position":[[17,6]]},"208":{"position":[[8,6]]},"210":{"position":[[10,6]]},"303":{"position":[[11,6]]},"420":{"position":[[3,9]]},"820":{"position":[[4,6]]},"888":{"position":[[4,6]]},"906":{"position":[[17,6]]},"908":{"position":[[13,6]]},"968":{"position":[[11,6]]}}}],["detail",{"_index":119,"t":{"142":{"position":[[45,7]]},"184":{"position":[[28,7]]},"207":{"position":[[37,7]]},"310":{"position":[[15,7]]},"530":{"position":[[15,7]]},"647":{"position":[[15,7]]},"991":{"position":[[28,7]]},"1103":{"position":[[19,7]]},"1157":{"position":[[15,7]]},"1164":{"position":[[15,7]]},"1171":{"position":[[15,7]]},"1178":{"position":[[15,7]]},"1228":{"position":[[15,7]]},"1235":{"position":[[9,7]]}}}],["detect",{"_index":120,"t":{"144":{"position":[[7,9]]},"148":{"position":[[9,9]]},"1106":{"position":[[7,9]]}}}],["differ",{"_index":64,"t":{"71":{"position":[[25,9]]},"321":{"position":[[28,9]]},"603":{"position":[[28,9]]},"605":{"position":[[28,9]]},"980":{"position":[[19,9]]},"1183":{"position":[[0,9]]}}}],["directli",{"_index":316,"t":{"558":{"position":[[0,8]]}}}],["discoveri",{"_index":530,"t":{"1095":{"position":[[11,9]]}}}],["discret",{"_index":450,"t":{"898":{"position":[[6,8]]},"910":{"position":[[6,8]]}}}],["discuss",{"_index":176,"t":{"214":{"position":[[32,10]]},"270":{"position":[[3,10]]},"399":{"position":[[3,10]]},"516":{"position":[[0,10]]},"520":{"position":[[0,10]]},"805":{"position":[[3,10]]},"1011":{"position":[[3,10]]}}}],["disjoint",{"_index":299,"t":{"518":{"position":[[24,8]]}}}],["distil",{"_index":360,"t":{"622":{"position":[[10,12]]},"632":{"position":[[7,12]]},"661":{"position":[[25,12]]},"663":{"position":[[0,12]]}}}],["distribut",{"_index":498,"t":{"1005":{"position":[[23,12]]},"1191":{"position":[[21,12]]}}}],["doc",{"_index":509,"t":{"1033":{"position":[[18,3]]},"1064":{"position":[[9,4]]},"1074":{"position":[[12,3]]}}}],["domain",{"_index":418,"t":{"837":{"position":[[17,6]]}}}],["down",{"_index":63,"t":{"70":{"position":[[9,4]]}}}],["downstream",{"_index":234,"t":{"350":{"position":[[19,10]]}}}],["dropdown",{"_index":524,"t":{"1066":{"position":[[14,8]]},"1078":{"position":[[13,8]]}}}],["earli",{"_index":27,"t":{"32":{"position":[[35,5]]},"522":{"position":[[4,5]]}}}],["effect",{"_index":29,"t":{"32":{"position":[[52,9]]},"212":{"position":[[4,6]]},"317":{"position":[[8,6]]}}}],["effici",{"_index":19,"t":{"29":{"position":[[23,10]]},"348":{"position":[[13,9]]},"409":{"position":[[45,9]]},"426":{"position":[[14,9]]},"478":{"position":[[0,10]]},"618":{"position":[[10,9]]},"636":{"position":[[10,10]]},"803":{"position":[[9,10]]}}}],["efficientnet",{"_index":60,"t":{"67":{"position":[[14,12]]}}}],["efficientnetv2",{"_index":14,"t":{"28":{"position":[[3,14]]},"39":{"position":[[0,14]]},"41":{"position":[[0,14]]}}}],["embed",{"_index":332,"t":{"580":{"position":[[7,9]]},"797":{"position":[[12,9]]}}}],["emerg",{"_index":218,"t":{"317":{"position":[[33,8]]}}}],["empir",{"_index":328,"t":{"572":{"position":[[3,9]]},"976":{"position":[[20,9]]}}}],["encod",{"_index":393,"t":{"767":{"position":[[4,7]]}}}],["end",{"_index":133,"t":{"167":{"position":[[17,5]]},"319":{"position":[[29,3],[36,3]]},"397":{"position":[[32,5]]},"511":{"position":[[5,5]]}}}],["engin",{"_index":445,"t":{"890":{"position":[[18,11]]},"894":{"position":[[20,11]]},"902":{"position":[[16,11]]},"970":{"position":[[18,11]]}}}],["enough",{"_index":313,"t":{"554":{"position":[[34,7]]}}}],["ensembl",{"_index":420,"t":{"839":{"position":[[10,10]]},"916":{"position":[[11,10]]},"1217":{"position":[[13,8]]},"1225":{"position":[[22,8]]}}}],["enviro",{"_index":213,"t":{"307":{"position":[[4,10]]}}}],["equal",{"_index":32,"t":{"34":{"position":[[0,7]]}}}],["equat",{"_index":188,"t":{"247":{"position":[[0,8]]}}}],["evalu",{"_index":148,"t":{"184":{"position":[[17,10]]},"315":{"position":[[26,10]]},"380":{"position":[[5,10]]},"381":{"position":[[0,10]]},"383":{"position":[[0,10]]},"397":{"position":[[13,10]]},"473":{"position":[[26,10]]},"480":{"position":[[16,10]]},"794":{"position":[[13,10]]},"856":{"position":[[0,9]]},"956":{"position":[[14,10]]},"1002":{"position":[[4,10]]},"1105":{"position":[[4,11]]}}}],["evalut",{"_index":150,"t":{"189":{"position":[[0,9]]}}}],["exist",{"_index":310,"t":{"554":{"position":[[10,8]]},"1068":{"position":[[10,8]]}}}],["experi",{"_index":70,"t":{"79":{"position":[[0,11]]},"98":{"position":[[3,11]]},"141":{"position":[[3,11]]},"181":{"position":[[3,11]]},"305":{"position":[[3,10]]},"448":{"position":[[13,11]]},"472":{"position":[[3,10]]},"526":{"position":[[3,11]]},"572":{"position":[[13,11]]},"638":{"position":[[3,11]]},"689":{"position":[[3,11]]},"737":{"position":[[3,11]]},"864":{"position":[[2,11]]},"1102":{"position":[[3,11]]},"1155":{"position":[[3,11]]},"1227":{"position":[[0,10]]}}}],["experiemt",{"_index":364,"t":{"640":{"position":[[4,11]]}}}],["experiment",{"_index":116,"t":{"142":{"position":[[4,12]]},"234":{"position":[[5,12]]},"321":{"position":[[4,12]]},"527":{"position":[[4,12]]},"778":{"position":[[3,12]]},"991":{"position":[[15,12]]}}}],["expert",{"_index":139,"t":{"170":{"position":[[16,7]]},"175":{"position":[[0,7]]},"201":{"position":[[5,8]]},"203":{"position":[[7,8]]},"205":{"position":[[20,7]]},"218":{"position":[[28,7]]},"220":{"position":[[31,7]]},"222":{"position":[[18,6]]},"524":{"position":[[21,7]]},"540":{"position":[[17,7]]}}}],["extract",{"_index":207,"t":{"293":{"position":[[11,10]]},"948":{"position":[[16,10]]}}}],["extrapol",{"_index":403,"t":{"792":{"position":[[4,13]]}}}],["featur",{"_index":529,"t":{"1093":{"position":[[17,7]]}}}],["few",{"_index":159,"t":{"196":{"position":[[0,3]]},"319":{"position":[[56,3]]},"420":{"position":[[19,3]]},"432":{"position":[[28,3]]},"446":{"position":[[30,3]]},"652":{"position":[[0,3]]},"701":{"position":[[6,3]]}}}],["fine",{"_index":81,"t":{"96":{"position":[[4,4]]},"105":{"position":[[11,4]]},"192":{"position":[[0,4]]},"426":{"position":[[24,4]]},"564":{"position":[[25,4]]},"576":{"position":[[0,4]]},"769":{"position":[[4,4]]},"930":{"position":[[17,4]]}}}],["finetun",{"_index":239,"t":{"369":{"position":[[8,10]]},"371":{"position":[[5,10]]},"374":{"position":[[17,10]]},"378":{"position":[[5,10]]},"387":{"position":[[3,10]]},"389":{"position":[[5,10]]},"401":{"position":[[31,10]]},"403":{"position":[[4,10]]},"405":{"position":[[12,10]]},"407":{"position":[[12,10]]},"409":{"position":[[12,10]]},"703":{"position":[[6,10],[25,10]]}}}],["first",{"_index":507,"t":{"1029":{"position":[[12,5]]},"1033":{"position":[[12,5]]},"1039":{"position":[[12,5]]},"1041":{"position":[[12,5]]}}}],["fit",{"_index":294,"t":{"490":{"position":[[19,7]]}}}],["fix",{"_index":460,"t":{"934":{"position":[[6,5]]},"936":{"position":[[6,5]]}}}],["flan",{"_index":238,"t":{"369":{"position":[[3,4]]}}}],["flip",{"_index":198,"t":{"268":{"position":[[5,4]]}}}],["follow",{"_index":291,"t":{"473":{"position":[[16,9]]}}}],["form",{"_index":179,"t":{"220":{"position":[[5,4]]}}}],["formal",{"_index":436,"t":{"877":{"position":[[4,6]]}}}],["format",{"_index":241,"t":{"376":{"position":[[14,11]]}}}],["formul",{"_index":372,"t":{"693":{"position":[[19,11]]}}}],["four",{"_index":124,"t":{"150":{"position":[[0,4]]}}}],["free",{"_index":178,"t":{"220":{"position":[[0,4]]},"932":{"position":[[13,4]]}}}],["front",{"_index":516,"t":{"1050":{"position":[[0,5]]}}}],["frozen",{"_index":173,"t":{"212":{"position":[[14,6]]},"315":{"position":[[50,6]]},"348":{"position":[[40,6]]}}}],["ft",{"_index":329,"t":{"576":{"position":[[12,4]]}}}],["full",{"_index":323,"t":{"564":{"position":[[20,4]]},"650":{"position":[[0,4]]},"797":{"position":[[4,4]]}}}],["fulli",{"_index":376,"t":{"699":{"position":[[6,5]]}}}],["function",{"_index":109,"t":{"131":{"position":[[39,8]]}}}],["fusion",{"_index":300,"t":{"522":{"position":[[10,6]]},"1093":{"position":[[25,6]]},"1124":{"position":[[0,6]]}}}],["futur",{"_index":358,"t":{"609":{"position":[[18,6]]}}}],["gap",{"_index":416,"t":{"826":{"position":[[16,3]]}}}],["gener",{"_index":4,"t":{"16":{"position":[[0,8]]},"295":{"position":[[13,10]]},"297":{"position":[[24,10]]},"299":{"position":[[16,10]]},"350":{"position":[[48,10]]},"352":{"position":[[8,10]]},"397":{"position":[[38,10]]},"405":{"position":[[23,11]]},"564":{"position":[[2,14]]},"654":{"position":[[17,10]]},"786":{"position":[[18,10]]},"954":{"position":[[10,10]]},"956":{"position":[[33,10]]},"1091":{"position":[[11,10]]},"1175":{"position":[[21,10]]},"1212":{"position":[[13,10]]},"1215":{"position":[[13,10]]},"1231":{"position":[[13,10]]}}}],["get",{"_index":0,"t":{"12":{"position":[[0,7]]}}}],["global",{"_index":549,"t":{"1153":{"position":[[4,6]]}}}],["good",{"_index":312,"t":{"554":{"position":[[29,4]]}}}],["gpt",{"_index":340,"t":{"592":{"position":[[4,3]]},"594":{"position":[[18,3]]}}}],["hard",{"_index":317,"t":{"558":{"position":[[34,4]]}}}],["harm",{"_index":263,"t":{"407":{"position":[[71,5]]}}}],["head",{"_index":387,"t":{"735":{"position":[[15,4]]},"750":{"position":[[19,4],[53,4]]}}}],["held",{"_index":250,"t":{"389":{"position":[[58,4]]}}}],["high",{"_index":491,"t":{"992":{"position":[[4,4]]}}}],["higher",{"_index":83,"t":{"96":{"position":[[20,6]]}}}],["hotpotqa",{"_index":431,"t":{"866":{"position":[[15,8]]}}}],["human",{"_index":494,"t":{"998":{"position":[[4,5]]}}}],["hybri",{"_index":79,"t":{"94":{"position":[[0,6]]}}}],["hyperparamet",{"_index":397,"t":{"783":{"position":[[22,15]]}}}],["i18n",{"_index":525,"t":{"1072":{"position":[[10,4]]}}}],["ia)3(ia)^3(ia)3",{"_index":272,"t":{"426":{"position":[[41,16]]},"428":{"position":[[17,16]]}}}],["icl",{"_index":277,"t":{"432":{"position":[[17,3]]}}}],["ilsvrc2012",{"_index":52,"t":{"51":{"position":[[9,10]]}}}],["imag",{"_index":22,"t":{"30":{"position":[[25,5]]},"194":{"position":[[25,5]]},"536":{"position":[[0,5]]},"1054":{"position":[[0,6]]},"1093":{"position":[[4,5]]}}}],["imagenet",{"_index":51,"t":{"51":{"position":[[0,8]]},"196":{"position":[[24,8]]}}}],["imagenet21k",{"_index":54,"t":{"56":{"position":[[0,11]]}}}],["implement",{"_index":118,"t":{"142":{"position":[[30,14]]},"187":{"position":[[17,14]]},"310":{"position":[[0,14]]},"530":{"position":[[0,14]]},"647":{"position":[[0,14]]},"728":{"position":[[21,14]]},"1103":{"position":[[4,14]]},"1157":{"position":[[0,14]]},"1164":{"position":[[0,14]]},"1171":{"position":[[0,14]]},"1178":{"position":[[0,14]]},"1228":{"position":[[0,14]]}}}],["implic",{"_index":500,"t":{"1012":{"position":[[4,12]]}}}],["import",{"_index":66,"t":{"73":{"position":[[0,10]]},"1147":{"position":[[4,10]]},"1151":{"position":[[18,10]]},"1187":{"position":[[16,10]]}}}],["improv",{"_index":249,"t":{"389":{"position":[[36,8]]},"407":{"position":[[23,8]]}}}],["induct",{"_index":411,"t":{"810":{"position":[[0,9]]}}}],["infer",{"_index":114,"t":{"139":{"position":[[4,9]]},"220":{"position":[[10,9]]},"438":{"position":[[0,9]]},"556":{"position":[[24,9]]},"566":{"position":[[14,9]]},"1097":{"position":[[17,9]]},"1100":{"position":[[0,9]]},"1213":{"position":[[0,9]]},"1223":{"position":[[0,9]]}}}],["infix",{"_index":406,"t":{"799":{"position":[[21,5]]}}}],["inform",{"_index":467,"t":{"948":{"position":[[4,11]]}}}],["ingredi",{"_index":275,"t":{"430":{"position":[[18,11]]}}}],["initi",{"_index":289,"t":{"462":{"position":[[9,11]]},"466":{"position":[[9,11]]},"488":{"position":[[5,11]]},"492":{"position":[[9,11]]},"507":{"position":[[5,11]]},"801":{"position":[[4,14]]},"831":{"position":[[7,14]]}}}],["insert",{"_index":292,"t":{"486":{"position":[[0,9]]}}}],["inspect",{"_index":98,"t":{"115":{"position":[[4,10]]}}}],["instanc",{"_index":121,"t":{"146":{"position":[[0,8]]},"1106":{"position":[[21,8]]}}}],["instruct",{"_index":237,"t":{"358":{"position":[[19,11]]},"401":{"position":[[19,11]]},"405":{"position":[[0,11]]},"407":{"position":[[0,11]]},"409":{"position":[[0,11]]},"473":{"position":[[4,11]]},"532":{"position":[[22,11]]},"534":{"position":[[11,11]]}}}],["integr",{"_index":302,"t":{"524":{"position":[[4,11]]},"540":{"position":[[0,11]]}}}],["interfac",{"_index":105,"t":{"129":{"position":[[14,9]]}}}],["interpret",{"_index":421,"t":{"841":{"position":[[3,16]]}}}],["intrigu",{"_index":164,"t":{"200":{"position":[[4,10]]}}}],["intrins",{"_index":404,"t":{"794":{"position":[[3,9]]}}}],["introduc",{"_index":314,"t":{"556":{"position":[[14,9]]}}}],["introduct",{"_index":9,"t":{"24":{"position":[[3,12]]},"85":{"position":[[3,12]]},"125":{"position":[[3,12]]},"164":{"position":[[3,12]]},"228":{"position":[[3,12]]},"280":{"position":[[3,12]]},"329":{"position":[[3,12]]},"367":{"position":[[3,12]]},"417":{"position":[[3,12]]},"456":{"position":[[3,12]]},"503":{"position":[[3,12]]},"548":{"position":[[3,12]]},"615":{"position":[[3,12]]},"679":{"position":[[3,12]]},"712":{"position":[[3,12]]},"760":{"position":[[3,12]]},"816":{"position":[[3,12]]},"849":{"position":[[2,12]]},"988":{"position":[[3,12]]},"1086":{"position":[[3,12]]},"1136":{"position":[[3,12]]},"1199":{"position":[[0,12]]}}}],["intuct",{"_index":77,"t":{"92":{"position":[[0,9]]}}}],["intuit",{"_index":395,"t":{"772":{"position":[[4,9]]}}}],["joint",{"_index":126,"t":{"150":{"position":[[11,5]]},"518":{"position":[[4,5]]}}}],["key",{"_index":140,"t":{"172":{"position":[[4,3]]}}}],["keypoint",{"_index":123,"t":{"148":{"position":[[0,8]]}}}],["knowledg",{"_index":137,"t":{"167":{"position":[[50,9]]},"222":{"position":[[25,9]]},"522":{"position":[[27,9]]},"622":{"position":[[0,9]]},"691":{"position":[[4,9]]},"942":{"position":[[4,9]]}}}],["label",{"_index":390,"t":{"750":{"position":[[35,5]]},"1212":{"position":[[7,5]]},"1215":{"position":[[7,5]]},"1217":{"position":[[7,5]]},"1231":{"position":[[7,5]]}}}],["lack",{"_index":383,"t":{"720":{"position":[[4,4]]},"722":{"position":[[0,4]]},"724":{"position":[[0,4]]}}}],["languag",{"_index":151,"t":{"191":{"position":[[22,8]]},"241":{"position":[[0,8]]},"289":{"position":[[0,8]]},"332":{"position":[[28,8]]},"338":{"position":[[7,8]]},"470":{"position":[[0,8]]},"532":{"position":[[13,8]]},"654":{"position":[[8,8]]},"875":{"position":[[30,8]]},"1161":{"position":[[12,8]]},"1175":{"position":[[12,8]]},"1202":{"position":[[7,8]]},"1229":{"position":[[7,8]]}}}],["larg",{"_index":21,"t":{"30":{"position":[[19,5]]},"332":{"position":[[22,5]]},"466":{"position":[[41,5]]},"492":{"position":[[41,5]]}}}],["last",{"_index":194,"t":{"266":{"position":[[0,4]]}}}],["latenc",{"_index":315,"t":{"556":{"position":[[34,7]]},"566":{"position":[[24,7]]}}}],["later",{"_index":30,"t":{"32":{"position":[[65,5]]}}}],["layer",{"_index":28,"t":{"32":{"position":[[41,6]]},"486":{"position":[[10,6]]},"514":{"position":[[26,6]]},"556":{"position":[[8,5]]},"582":{"position":[[7,5]]}}}],["learn",{"_index":44,"t":{"45":{"position":[[15,8]]},"48":{"position":[[12,8]]},"61":{"position":[[9,8]]},"71":{"position":[[12,8]]},"216":{"position":[[23,8]]},"342":{"position":[[22,8]]},"618":{"position":[[29,8]]},"620":{"position":[[10,8]]},"699":{"position":[[23,8]]},"701":{"position":[[15,8]]},"733":{"position":[[11,8]]},"743":{"position":[[10,8]]},"878":{"position":[[15,8]]},"896":{"position":[[23,8]]},"914":{"position":[[15,8]]},"960":{"position":[[17,8]]},"974":{"position":[[20,8]]},"1204":{"position":[[7,8]]}}}],["learnabl",{"_index":288,"t":{"460":{"position":[[4,9]]},"1221":{"position":[[0,9]]},"1233":{"position":[[0,9]]}}}],["length",{"_index":270,"t":{"424":{"position":[[30,6]]},"665":{"position":[[7,6]]},"731":{"position":[[7,6]]},"795":{"position":[[11,6]]},"829":{"position":[[7,6]]}}}],["letter",{"_index":195,"t":{"266":{"position":[[5,6]]}}}],["level",{"_index":492,"t":{"992":{"position":[[9,5]]},"1183":{"position":[[17,6]]}}}],["lightweight",{"_index":145,"t":{"177":{"position":[[0,11]]}}}],["limit",{"_index":175,"t":{"214":{"position":[[16,11]]},"323":{"position":[[3,10]]},"570":{"position":[[23,11]]},"869":{"position":[[2,11]]},"1015":{"position":[[4,11]]},"1021":{"position":[[0,11]]}}}],["linear",{"_index":298,"t":{"514":{"position":[[19,6]]},"750":{"position":[[46,6]]}}}],["link",{"_index":518,"t":{"1052":{"position":[[0,5]]}}}],["llama",{"_index":287,"t":{"459":{"position":[[3,5]]},"506":{"position":[[16,5]]},"513":{"position":[[3,5]]}}}],["llm",{"_index":203,"t":{"285":{"position":[[4,3]]},"315":{"position":[[57,4]]},"317":{"position":[[18,4]]},"321":{"position":[[38,4]]},"348":{"position":[[61,4]]}}}],["lm",{"_index":232,"t":{"346":{"position":[[17,2]]},"750":{"position":[[16,2]]},"765":{"position":[[19,2]]},"934":{"position":[[12,2]]},"936":{"position":[[19,2]]},"966":{"position":[[29,3]]}}}],["local",{"_index":527,"t":{"1076":{"position":[[11,9]]},"1078":{"position":[[6,6]]},"1080":{"position":[[11,9]]}}}],["lora",{"_index":325,"t":{"568":{"position":[[13,4]]},"586":{"position":[[0,4]]},"599":{"position":[[57,4]]},"601":{"position":[[37,5]]}}}],["low",{"_index":318,"t":{"562":{"position":[[4,3]]},"597":{"position":[[21,3]]},"790":{"position":[[4,3]]},"1141":{"position":[[0,3]]},"1185":{"position":[[14,3]]}}}],["magnitud",{"_index":545,"t":{"1149":{"position":[[0,9]]}}}],["main",{"_index":49,"t":{"50":{"position":[[3,4]]},"314":{"position":[[4,4]]},"785":{"position":[[3,4]]},"1166":{"position":[[0,4]]},"1173":{"position":[[0,4]]},"1180":{"position":[[0,4]]},"1239":{"position":[[0,4]]}}}],["maintain",{"_index":252,"t":{"391":{"position":[[45,8]]}}}],["make",{"_index":429,"t":{"865":{"position":[[24,7]]}}}],["manual",{"_index":447,"t":{"894":{"position":[[4,6]]},"908":{"position":[[6,6]]}}}],["map",{"_index":443,"t":{"886":{"position":[[13,7]]}}}],["markdown",{"_index":514,"t":{"1041":{"position":[[18,8]]}}}],["match",{"_index":231,"t":{"344":{"position":[[10,8]]}}}],["mathod",{"_index":244,"t":{"383":{"position":[[11,7]]}}}],["matric",{"_index":322,"t":{"562":{"position":[[34,8]]},"599":{"position":[[17,8]]}}}],["matrix",{"_index":354,"t":{"607":{"position":[[28,6]]}}}],["matter",{"_index":517,"t":{"1050":{"position":[[6,6]]}}}],["mdx",{"_index":521,"t":{"1060":{"position":[[0,3]]}}}],["mediat",{"_index":206,"t":{"289":{"position":[[9,8]]}}}],["medium/larg",{"_index":341,"t":{"592":{"position":[[10,12]]}}}],["memori",{"_index":282,"t":{"444":{"position":[[0,6]]},"860":{"position":[[0,6]]}}}],["meta",{"_index":473,"t":{"958":{"position":[[4,4]]}}}],["method",{"_index":72,"t":{"89":{"position":[[3,6]]},"283":{"position":[[27,6]]},"291":{"position":[[3,6]]},"312":{"position":[[10,7]]},"319":{"position":[[65,7]]},"560":{"position":[[7,6]]},"683":{"position":[[3,7]]},"774":{"position":[[4,6]]},"781":{"position":[[4,7]]},"906":{"position":[[24,6]]},"924":{"position":[[36,7]]},"928":{"position":[[21,7]]},"982":{"position":[[29,7]]},"991":{"position":[[3,7]]},"1019":{"position":[[0,6]]},"1143":{"position":[[11,6]]},"1208":{"position":[[0,6]]}}}],["methodolog",{"_index":493,"t":{"992":{"position":[[15,11]]}}}],["metric",{"_index":88,"t":{"107":{"position":[[0,7]]},"383":{"position":[[23,8]]},"658":{"position":[[17,8]]},"779":{"position":[[17,7]]}}}],["mitig",{"_index":261,"t":{"407":{"position":[[46,9]]}}}],["mix",{"_index":111,"t":{"135":{"position":[[5,6]]},"137":{"position":[[6,6]]}}}],["mixtur",{"_index":240,"t":{"372":{"position":[[5,9]]},"374":{"position":[[28,8]]}}}],["modal",{"_index":136,"t":{"167":{"position":[[44,5]]},"173":{"position":[[0,8]]},"210":{"position":[[27,5]]},"216":{"position":[[6,5]]},"287":{"position":[[6,5]]},"464":{"position":[[10,5]]},"480":{"position":[[10,5]]},"509":{"position":[[13,5]]},"511":{"position":[[17,5]]},"960":{"position":[[11,5]]}}}],["model",{"_index":86,"t":{"103":{"position":[[0,5]]},"168":{"position":[[4,5]]},"182":{"position":[[12,5]]},"241":{"position":[[9,6]]},"332":{"position":[[37,6]]},"338":{"position":[[16,8]]},"405":{"position":[[42,6]]},"422":{"position":[[4,5]]},"466":{"position":[[47,6]]},"468":{"position":[[7,6]]},"470":{"position":[[9,6]]},"492":{"position":[[47,6]]},"532":{"position":[[34,5]]},"534":{"position":[[23,5]]},"643":{"position":[[0,6]]},"656":{"position":[[0,5]]},"741":{"position":[[12,6]]},"1000":{"position":[[4,6]]},"1139":{"position":[[18,6]]},"1162":{"position":[[0,6]]},"1169":{"position":[[0,6]]},"1176":{"position":[[0,6]]},"1202":{"position":[[16,6]]},"1229":{"position":[[16,6]]}}}],["more",{"_index":166,"t":{"201":{"position":[[0,4]]}}}],["mot",{"_index":537,"t":{"1114":{"position":[[0,3]]},"1116":{"position":[[0,4]]}}}],["motiv",{"_index":45,"t":{"46":{"position":[[0,10]]},"681":{"position":[[3,10]]}}}],["mp",{"_index":380,"t":{"703":{"position":[[22,2]]}}}],["multi",{"_index":135,"t":{"167":{"position":[[38,5]]},"210":{"position":[[21,5]]},"216":{"position":[[0,5]]},"287":{"position":[[0,5]]},"464":{"position":[[4,5]]},"480":{"position":[[4,5]]},"509":{"position":[[7,5]]},"511":{"position":[[11,5]]},"733":{"position":[[0,5]]},"914":{"position":[[2,5]]},"960":{"position":[[5,5]]}}}],["multipl",{"_index":483,"t":{"974":{"position":[[4,8]]}}}],["multitask",{"_index":359,"t":{"620":{"position":[[0,9]]},"628":{"position":[[4,9]]},"743":{"position":[[0,9]]}}}],["na",{"_index":38,"t":{"36":{"position":[[15,3]]},"37":{"position":[[0,3]]}}}],["natur",{"_index":365,"t":{"654":{"position":[[0,7]]},"875":{"position":[[22,7]]},"1161":{"position":[[4,7]]}}}],["nautral",{"_index":552,"t":{"1175":{"position":[[4,7]]}}}],["need",{"_index":3,"t":{"14":{"position":[[12,4]]},"391":{"position":[[35,6]]}}}],["network",{"_index":65,"t":{"71":{"position":[[35,8]]}}}],["neural",{"_index":211,"t":{"299":{"position":[[0,6]]}}}],["new",{"_index":5,"t":{"16":{"position":[[11,3]]},"218":{"position":[[24,3]]}}}],["next",{"_index":505,"t":{"1025":{"position":[[7,5]]}}}],["nlp",{"_index":438,"t":{"878":{"position":[[27,3]]},"950":{"position":[[19,3]]},"1007":{"position":[[22,3]]}}}],["nlu",{"_index":382,"t":{"715":{"position":[[0,3]]},"739":{"position":[[0,3]]}}}],["nocap",{"_index":155,"t":{"192":{"position":[[37,6]]}}}],["noisi",{"_index":169,"t":{"205":{"position":[[14,5]]}}}],["normal",{"_index":271,"t":{"424":{"position":[[37,13]]}}}],["number",{"_index":368,"t":{"671":{"position":[[0,6]]}}}],["object",{"_index":108,"t":{"131":{"position":[[29,9]]},"144":{"position":[[0,6]]},"179":{"position":[[13,9]]},"663":{"position":[[13,9]]},"833":{"position":[[13,9]]},"1095":{"position":[[4,6]]},"1106":{"position":[[0,6]]}}}],["open",{"_index":132,"t":{"167":{"position":[[12,4]]},"332":{"position":[[12,4]]},"397":{"position":[[27,4]]},"511":{"position":[[0,4]]}}}],["optim",{"_index":36,"t":{"34":{"position":[[39,7]]},"558":{"position":[[9,10]]},"601":{"position":[[16,7]]},"687":{"position":[[4,12]]},"728":{"position":[[4,12]]},"1219":{"position":[[22,12]]}}}],["optimis",{"_index":149,"t":{"187":{"position":[[0,12]]}}}],["out",{"_index":251,"t":{"389":{"position":[[63,3]]},"560":{"position":[[3,3]]}}}],["outperform",{"_index":276,"t":{"432":{"position":[[3,13]]}}}],["over",{"_index":293,"t":{"490":{"position":[[14,4]]}}}],["overview",{"_index":138,"t":{"168":{"position":[[10,8]]},"1210":{"position":[[0,8]]}}}],["p",{"_index":369,"t":{"683":{"position":[[11,1]]},"703":{"position":[[41,1]]},"719":{"position":[[3,1]]},"745":{"position":[[4,1]]},"747":{"position":[[4,1]]}}}],["page",{"_index":513,"t":{"1039":{"position":[[24,4]]},"1041":{"position":[[27,4]]}}}],["paradigm",{"_index":488,"t":{"980":{"position":[[29,9]]}}}],["paramet",{"_index":246,"t":{"385":{"position":[[19,10]]},"426":{"position":[[4,9]]},"518":{"position":[[33,10]]},"618":{"position":[[0,9]]},"636":{"position":[[0,9]]},"928":{"position":[[4,9]]}}}],["parameter",{"_index":320,"t":{"562":{"position":[[13,13]]},"776":{"position":[[4,16]]},"1185":{"position":[[23,16]]}}}],["partial",{"_index":180,"t":{"220":{"position":[[23,7]]}}}],["perform",{"_index":61,"t":{"69":{"position":[[0,11]]},"192":{"position":[[11,11]]},"194":{"position":[[10,11]]},"196":{"position":[[9,11]]},"201":{"position":[[21,11]]},"203":{"position":[[23,11]]},"319":{"position":[[12,11]]},"434":{"position":[[4,11]]},"446":{"position":[[4,11]]},"476":{"position":[[0,11]]},"483":{"position":[[0,11]]},"495":{"position":[[0,11]]}}}],["person",{"_index":409,"t":{"806":{"position":[[0,15]]}}}],["plug",{"_index":216,"t":{"315":{"position":[[42,4]]}}}],["post",{"_index":508,"t":{"1029":{"position":[[18,4]]}}}],["potenti",{"_index":262,"t":{"407":{"position":[[61,9]]}}}],["practic",{"_index":326,"t":{"570":{"position":[[0,9]]}}}],["pre",{"_index":93,"t":{"111":{"position":[[4,3]]},"170":{"position":[[4,3]]},"185":{"position":[[0,3]]},"428":{"position":[[4,3]]},"741":{"position":[[0,3]]},"833":{"position":[[0,3]]},"966":{"position":[[17,3]]}}}],["predict",{"_index":466,"t":{"944":{"position":[[14,10]]}}}],["preemb",{"_index":333,"t":{"580":{"position":[[24,10]]}}}],["prefix",{"_index":331,"t":{"580":{"position":[[0,6]]},"582":{"position":[[0,6]]},"771":{"position":[[3,6]]},"795":{"position":[[4,6]]},"799":{"position":[[4,6]]},"810":{"position":[[18,6]]}}}],["prelay",{"_index":334,"t":{"582":{"position":[[20,10]]}}}],["preliminari",{"_index":381,"t":{"714":{"position":[[3,13]]}}}],["pretrain",{"_index":205,"t":{"287":{"position":[[12,11]]},"319":{"position":[[40,11]]},"334":{"position":[[14,11]]},"340":{"position":[[13,11]]},"348":{"position":[[23,11]]},"358":{"position":[[3,11]]},"359":{"position":[[5,11]]},"361":{"position":[[5,11]]},"671":{"position":[[27,11]]}}}],["prismer",{"_index":131,"t":{"167":{"position":[[3,8]]},"182":{"position":[[4,7]]},"200":{"position":[[29,7]]}}}],["probe",{"_index":370,"t":{"691":{"position":[[14,7]]},"942":{"position":[[14,7]]}}}],["problem",{"_index":307,"t":{"552":{"position":[[3,7]]},"763":{"position":[[3,7]]}}}],["procedur",{"_index":242,"t":{"378":{"position":[[16,9]]}}}],["process",{"_index":427,"t":{"862":{"position":[[14,7]]},"875":{"position":[[39,10]]}}}],["program",{"_index":432,"t":{"867":{"position":[[4,11]]}}}],["progress",{"_index":43,"t":{"45":{"position":[[3,11]]},"48":{"position":[[0,11]]},"71":{"position":[[0,11]]}}}],["prompt",{"_index":184,"t":{"230":{"position":[[20,9]]},"237":{"position":[[9,9]]},"239":{"position":[[17,9]]},"258":{"position":[[0,7]]},"301":{"position":[[30,6]]},"303":{"position":[[4,6]]},"460":{"position":[[25,7]]},"558":{"position":[[24,6]]},"626":{"position":[[0,6]]},"628":{"position":[[14,6]]},"630":{"position":[[0,6]]},"632":{"position":[[0,6]]},"658":{"position":[[10,6]]},"661":{"position":[[0,6]]},"665":{"position":[[0,6]]},"717":{"position":[[0,6]]},"726":{"position":[[9,6]]},"731":{"position":[[0,6]]},"752":{"position":[[0,6]]},"818":{"position":[[3,6]]},"829":{"position":[[0,6]]},"831":{"position":[[0,6]]},"839":{"position":[[3,6]]},"877":{"position":[[26,9]]},"880":{"position":[[4,9]]},"882":{"position":[[6,6]]},"888":{"position":[[30,9]]},"890":{"position":[[2,6]]},"892":{"position":[[4,6]]},"898":{"position":[[15,6]]},"900":{"position":[[17,6]]},"902":{"position":[[2,6]]},"914":{"position":[[8,6]]},"916":{"position":[[4,6]]},"918":{"position":[[4,6]]},"920":{"position":[[4,6]]},"922":{"position":[[4,6]]},"924":{"position":[[26,9]]},"932":{"position":[[18,9]]},"934":{"position":[[15,6]]},"936":{"position":[[12,6]]},"962":{"position":[[2,6]]},"968":{"position":[[4,6]]},"970":{"position":[[4,6]]},"974":{"position":[[13,6]]},"976":{"position":[[42,9]]},"978":{"position":[[23,7]]},"982":{"position":[[19,9]]},"1091":{"position":[[4,6]]},"1093":{"position":[[10,6]]},"1204":{"position":[[0,6]]},"1219":{"position":[[0,6]]},"1221":{"position":[[10,6]]},"1225":{"position":[[0,6]]},"1233":{"position":[[10,6]]}}}],["prompt+lm",{"_index":463,"t":{"938":{"position":[[6,9]]}}}],["promptless",{"_index":457,"t":{"930":{"position":[[6,10]]}}}],["properti",{"_index":165,"t":{"200":{"position":[[15,10]]}}}],["protocol",{"_index":243,"t":{"380":{"position":[[16,8]]}}}],["pseudo",{"_index":556,"t":{"1212":{"position":[[0,6]]},"1215":{"position":[[0,6]]},"1217":{"position":[[0,6]]},"1231":{"position":[[0,6]]}}}],["public",{"_index":499,"t":{"1007":{"position":[[15,6]]}}}],["put",{"_index":255,"t":{"395":{"position":[[3,7]]}}}],["pθp_{\\theta}p",{"_index":396,"t":{"776":{"position":[[24,15]]}}}],["qualit",{"_index":130,"t":{"156":{"position":[[4,11]]},"1009":{"position":[[4,11]]}}}],["quantit",{"_index":128,"t":{"154":{"position":[[4,12]]}}}],["queri",{"_index":540,"t":{"1126":{"position":[[0,7]]}}}],["question",{"_index":208,"t":{"295":{"position":[[4,8]]},"297":{"position":[[15,8]]},"299":{"position":[[7,8]]},"301":{"position":[[4,8]]},"952":{"position":[[4,8]]},"1168":{"position":[[4,8]]}}}],["r",{"_index":539,"t":{"1120":{"position":[[0,1]]}}}],["raft",{"_index":286,"t":{"446":{"position":[[45,6]]}}}],["random",{"_index":351,"t":{"605":{"position":[[38,6]]}}}],["rank",{"_index":319,"t":{"562":{"position":[[8,4]]},"597":{"position":[[25,4]]},"601":{"position":[[24,4]]},"1141":{"position":[[4,4]]},"1147":{"position":[[21,4]]},"1185":{"position":[[18,4]]}}}],["re",{"_index":534,"t":{"1108":{"position":[[8,3]]}}}],["react",{"_index":512,"t":{"1039":{"position":[[18,5]]},"1060":{"position":[[8,5]]}}}],["real",{"_index":284,"t":{"446":{"position":[[19,4]]}}}],["reason",{"_index":134,"t":{"167":{"position":[[23,9]]},"232":{"position":[[14,9]]},"255":{"position":[[15,9]]},"262":{"position":[[12,9]]},"389":{"position":[[45,9]]},"391":{"position":[[54,9]]},"393":{"position":[[25,9]]},"403":{"position":[[31,9]]},"464":{"position":[[16,9]]},"511":{"position":[[23,9]]},"866":{"position":[[4,10]]},"950":{"position":[[4,11]]}}}],["rec",{"_index":533,"t":{"1108":{"position":[[0,3]]}}}],["recent",{"_index":200,"t":{"283":{"position":[[4,6]]}}}],["recip",{"_index":268,"t":{"420":{"position":[[23,6]]}}}],["reflect",{"_index":425,"t":{"852":{"position":[[38,10]]},"858":{"position":[[5,10]]}}}],["reflexion",{"_index":422,"t":{"852":{"position":[[2,10]]},"862":{"position":[[4,9]]}}}],["regular",{"_index":47,"t":{"48":{"position":[[35,14]]},"73":{"position":[[23,14]]}}}],["reinforc",{"_index":423,"t":{"852":{"position":[[13,13]]}}}],["rel",{"_index":264,"t":{"409":{"position":[[26,10]]}}}],["relat",{"_index":11,"t":{"26":{"position":[[3,7]]},"87":{"position":[[3,7]]},"166":{"position":[[3,7]]},"272":{"position":[[3,7]]},"282":{"position":[[3,7]]},"331":{"position":[[3,7]]},"458":{"position":[[3,7]]},"505":{"position":[[3,7]]},"596":{"position":[[3,7]]},"617":{"position":[[3,7]]},"705":{"position":[[3,7]]},"762":{"position":[[3,7]]},"851":{"position":[[2,7]]},"990":{"position":[[3,7]]},"1088":{"position":[[3,7]]},"1201":{"position":[[0,7]]}}}],["relev",{"_index":212,"t":{"301":{"position":[[13,8]]},"962":{"position":[[9,8]]}}}],["reparameter",{"_index":386,"t":{"729":{"position":[[0,18]]}}}],["represent",{"_index":181,"t":{"222":{"position":[[0,14]]},"1219":{"position":[[7,14]]},"1221":{"position":[[17,14]]},"1225":{"position":[[7,14]]},"1233":{"position":[[17,14]]}}}],["requir",{"_index":95,"t":{"111":{"position":[[21,12]]}}}],["resampl",{"_index":144,"t":{"175":{"position":[[8,9]]},"210":{"position":[[0,9]]}}}],["research",{"_index":502,"t":{"1012":{"position":[[31,8]]}}}],["resili",{"_index":417,"t":{"837":{"position":[[3,10]]}}}],["resolut",{"_index":84,"t":{"96":{"position":[[27,10]]}}}],["result",{"_index":50,"t":{"50":{"position":[[8,7]]},"54":{"position":[[0,7]]},"59":{"position":[[0,7]]},"64":{"position":[[0,7]]},"154":{"position":[[17,7]]},"156":{"position":[[16,7]]},"191":{"position":[[4,7]]},"243":{"position":[[5,7]]},"260":{"position":[[0,7]]},"314":{"position":[[9,7]]},"315":{"position":[[5,7]]},"321":{"position":[[17,7]]},"649":{"position":[[4,7]]},"695":{"position":[[6,7]]},"785":{"position":[[8,7]]},"824":{"position":[[3,7]]},"1004":{"position":[[3,6]]},"1005":{"position":[[4,7]]},"1007":{"position":[[4,7]]},"1009":{"position":[[16,7]]},"1166":{"position":[[5,7]]},"1173":{"position":[[5,7]]},"1180":{"position":[[5,7]]},"1191":{"position":[[4,9]]},"1239":{"position":[[5,7]]}}}],["retriev",{"_index":531,"t":{"1095":{"position":[[25,9]]}}}],["revisit",{"_index":295,"t":{"506":{"position":[[5,7]]}}}],["roberta",{"_index":335,"t":{"588":{"position":[[4,7]]}}}],["robust",{"_index":168,"t":{"205":{"position":[[0,10]]},"253":{"position":[[5,10]]},"490":{"position":[[0,10]]}}}],["role",{"_index":554,"t":{"1189":{"position":[[4,4]]}}}],["rrr",{"_index":347,"t":{"601":{"position":[[29,3]]},"603":{"position":[[38,3]]}}}],["same",{"_index":62,"t":{"69":{"position":[[21,4]]}}}],["sampl",{"_index":171,"t":{"210":{"position":[[33,8]]},"669":{"position":[[16,8]]}}}],["scail",{"_index":33,"t":{"34":{"position":[[8,8]]},"36":{"position":[[23,8]]},"41":{"position":[[15,8]]},"70":{"position":[[0,8]]},"113":{"position":[[4,8]]}}}],["scale",{"_index":217,"t":{"317":{"position":[[0,7]]},"385":{"position":[[3,7]]},"401":{"position":[[0,7]]},"594":{"position":[[4,7]]},"656":{"position":[[6,7]]},"722":{"position":[[28,6]]},"745":{"position":[[24,6]]}}}],["schedul",{"_index":551,"t":{"1153":{"position":[[18,9]]}}}],["score",{"_index":553,"t":{"1187":{"position":[[27,5]]}}}],["sea",{"_index":434,"t":{"875":{"position":[[7,3]]}}}],["search",{"_index":39,"t":{"37":{"position":[[4,6]]},"884":{"position":[[13,6]]},"910":{"position":[[22,6]]},"912":{"position":[[24,6]]}}}],["seed",{"_index":352,"t":{"605":{"position":[[45,5]]}}}],["segment",{"_index":122,"t":{"146":{"position":[[9,12]]},"1106":{"position":[[30,12]]}}}],["select",{"_index":478,"t":{"966":{"position":[[4,9]]},"972":{"position":[[4,9]]}}}],["self",{"_index":100,"t":{"117":{"position":[[4,4]]},"858":{"position":[[0,4]]},"1206":{"position":[[0,4]]}}}],["sensit",{"_index":548,"t":{"1151":{"position":[[0,11]]}}}],["seq2seq",{"_index":235,"t":{"352":{"position":[[0,7]]}}}],["sequenti",{"_index":428,"t":{"865":{"position":[[4,10]]}}}],["set",{"_index":117,"t":{"142":{"position":[[17,8]]},"189":{"position":[[10,7]]},"474":{"position":[[0,8]]},"481":{"position":[[0,8]]},"493":{"position":[[0,8]]},"790":{"position":[[13,7]]},"926":{"position":[[13,8]]}}}],["setup",{"_index":53,"t":{"52":{"position":[[0,5]]},"57":{"position":[[0,5]]},"62":{"position":[[0,5]]},"100":{"position":[[4,5]]},"307":{"position":[[15,5]]},"361":{"position":[[17,5]]},"527":{"position":[[17,6]]},"640":{"position":[[16,5]]},"778":{"position":[[16,5]]}}}],["shape",{"_index":446,"t":{"892":{"position":[[11,5]]},"904":{"position":[[11,5]]}}}],["shelf",{"_index":233,"t":{"348":{"position":[[55,5]]}}}],["shift",{"_index":419,"t":{"837":{"position":[[24,5]]}}}],["shot",{"_index":158,"t":{"194":{"position":[[5,4]]},"196":{"position":[[4,4]]},"218":{"position":[[5,4]]},"285":{"position":[[21,4]]},"315":{"position":[[21,4]]},"319":{"position":[[60,4]]},"393":{"position":[[20,4]]},"446":{"position":[[34,4]]},"652":{"position":[[4,4]]},"701":{"position":[[10,4]]}}}],["sidebar",{"_index":511,"t":{"1035":{"position":[[14,7]]}}}],["similar",{"_index":349,"t":{"603":{"position":[[9,10]]},"605":{"position":[[9,10]]},"835":{"position":[[17,7]]}}}],["simpl",{"_index":296,"t":{"509":{"position":[[0,6]]}}}],["singular",{"_index":546,"t":{"1149":{"position":[[13,8]]}}}],["site",{"_index":6,"t":{"16":{"position":[[15,4]]},"18":{"position":[[11,4]]},"1045":{"position":[[11,4]]},"1076":{"position":[[21,4]]},"1080":{"position":[[21,4]]}}}],["size",{"_index":23,"t":{"30":{"position":[[31,5]]},"208":{"position":[[19,4]]}}}],["slow",{"_index":24,"t":{"30":{"position":[[40,4]]},"32":{"position":[[27,4]]}}}],["solut",{"_index":311,"t":{"554":{"position":[[19,9]]}}}],["sot",{"_index":535,"t":{"1110":{"position":[[0,3]]}}}],["sota",{"_index":215,"t":{"315":{"position":[[0,4]]}}}],["sourc",{"_index":362,"t":{"634":{"position":[[4,6]]},"671":{"position":[[10,6]]}}}],["space",{"_index":453,"t":{"906":{"position":[[11,5]]}}}],["span",{"_index":224,"t":{"336":{"position":[[0,4]]},"822":{"position":[[15,4]]}}}],["specif",{"_index":142,"t":{"173":{"position":[[9,8]]}}}],["speed",{"_index":40,"t":{"43":{"position":[[9,5]]}}}],["stage",{"_index":31,"t":{"32":{"position":[[71,6]]},"34":{"position":[[26,5]]}}}],["standard",{"_index":187,"t":{"237":{"position":[[0,8]]}}}],["start",{"_index":1,"t":{"12":{"position":[[8,7]]},"18":{"position":[[0,5]]},"1076":{"position":[[0,5]]}}}],["state",{"_index":90,"t":{"109":{"position":[[18,5]]}}}],["statement",{"_index":308,"t":{"552":{"position":[[11,9]]},"763":{"position":[[11,9]]}}}],["stem",{"_index":143,"t":{"173":{"position":[[32,4]]}}}],["steup",{"_index":186,"t":{"234":{"position":[[18,5]]}}}],["stochast",{"_index":367,"t":{"669":{"position":[[0,10]]}}}],["storag",{"_index":281,"t":{"442":{"position":[[0,7]]}}}],["strategi",{"_index":172,"t":{"210":{"position":[[42,8]]},"667":{"position":[[18,8]]},"924":{"position":[[11,10]]},"972":{"position":[[24,8]]}}}],["stronger",{"_index":303,"t":{"532":{"position":[[4,8]]}}}],["structur",{"_index":465,"t":{"944":{"position":[[4,9]]}}}],["studi",{"_index":59,"t":{"66":{"position":[[12,7]]},"113":{"position":[[13,5]]},"245":{"position":[[14,5]]},"485":{"position":[[13,5]]},"660":{"position":[[13,7]]},"749":{"position":[[13,5]]},"828":{"position":[[13,5]]},"868":{"position":[[9,5]]}}}],["sub",{"_index":35,"t":{"34":{"position":[[35,3]]}}}],["subspac",{"_index":348,"t":{"603":{"position":[[0,8]]},"605":{"position":[[0,8]]}}}],["summar",{"_index":69,"t":{"77":{"position":[[0,13]]},"788":{"position":[[4,13]]}}}],["superglu",{"_index":374,"t":{"697":{"position":[[4,9]]}}}],["supervis",{"_index":101,"t":{"117":{"position":[[9,11]]},"699":{"position":[[12,10]]},"878":{"position":[[4,10]]}}}],["svd",{"_index":543,"t":{"1145":{"position":[[4,3]]}}}],["symbol",{"_index":193,"t":{"262":{"position":[[3,8]]}}}],["t",{"_index":267,"t":{"420":{"position":[[17,1]]},"432":{"position":[[26,1]]}}}],["t0",{"_index":278,"t":{"434":{"position":[[19,2]]}}}],["tabl",{"_index":399,"t":{"786":{"position":[[4,5]]}}}],["target",{"_index":363,"t":{"634":{"position":[[24,6]]},"667":{"position":[[0,6]]}}}],["task",{"_index":125,"t":{"150":{"position":[[5,5]]},"264":{"position":[[0,5]]},"285":{"position":[[30,5]]},"350":{"position":[[59,5]]},"352":{"position":[[19,5]]},"354":{"position":[[13,5]]},"356":{"position":[[14,5]]},"372":{"position":[[0,4]]},"385":{"position":[[39,5]]},"389":{"position":[[67,5]]},"434":{"position":[[22,5]]},"446":{"position":[[39,5]]},"641":{"position":[[13,5]]},"654":{"position":[[28,5]]},"669":{"position":[[11,4]]},"671":{"position":[[17,5]]},"715":{"position":[[4,5]]},"724":{"position":[[28,5]]},"733":{"position":[[6,4]]},"739":{"position":[[4,5]]},"747":{"position":[[24,5]]},"946":{"position":[[25,5]]},"996":{"position":[[4,4]]},"1105":{"position":[[22,5]]}}}],["templat",{"_index":209,"t":{"297":{"position":[[0,8]]},"376":{"position":[[0,9]]},"890":{"position":[[9,8]]},"894":{"position":[[11,8]]},"896":{"position":[[14,8]]}}}],["terminolog",{"_index":305,"t":{"550":{"position":[[0,13]]}}}],["text",{"_index":229,"t":{"340":{"position":[[28,4]]},"342":{"position":[[0,4]]},"344":{"position":[[0,4]]},"346":{"position":[[0,4]]},"786":{"position":[[13,4]]},"954":{"position":[[5,4]]},"956":{"position":[[28,4]]}}}],["theoret",{"_index":485,"t":{"976":{"position":[[4,11]]}}}],["thought",{"_index":183,"t":{"230":{"position":[[12,7]]},"239":{"position":[[9,7]]},"251":{"position":[[9,7]]},"253":{"position":[[28,7]]},"374":{"position":[[9,7]]},"387":{"position":[[28,7]]},"389":{"position":[[28,7]]},"391":{"position":[[19,7]]}}}],["togeth",{"_index":256,"t":{"395":{"position":[[18,8]]}}}],["token",{"_index":106,"t":{"129":{"position":[[29,12]]},"139":{"position":[[21,12]]}}}],["topic",{"_index":475,"t":{"962":{"position":[[18,6]]}}}],["train",{"_index":18,"t":{"29":{"position":[[14,8]]},"30":{"position":[[0,8]]},"36":{"position":[[0,8]]},"43":{"position":[[0,8]]},"69":{"position":[[26,8]]},"105":{"position":[[0,8]]},"111":{"position":[[8,7]]},"133":{"position":[[4,8]]},"150":{"position":[[17,8]]},"170":{"position":[[8,7]]},"179":{"position":[[4,8]]},"184":{"position":[[4,8]]},"185":{"position":[[4,8]]},"207":{"position":[[28,8]]},"424":{"position":[[17,8]]},"428":{"position":[[8,8]]},"440":{"position":[[0,8]]},"518":{"position":[[10,8]]},"528":{"position":[[0,8]]},"634":{"position":[[11,8]]},"741":{"position":[[4,7]]},"833":{"position":[[4,8]]},"924":{"position":[[2,8]]},"926":{"position":[[4,8]]},"966":{"position":[[21,7]]},"1097":{"position":[[4,8]]},"1098":{"position":[[0,8]]},"1206":{"position":[[5,8]]},"1235":{"position":[[0,8]]}}}],["transfer",{"_index":55,"t":{"61":{"position":[[0,8]]},"618":{"position":[[20,8]]},"978":{"position":[[4,15]]}}}],["transform",{"_index":75,"t":{"90":{"position":[[11,11]]},"115":{"position":[[22,11]]},"568":{"position":[[21,11]]},"599":{"position":[[29,11]]},"1139":{"position":[[0,11]]}}}],["translat",{"_index":526,"t":{"1074":{"position":[[0,9]]}}}],["tune",{"_index":82,"t":{"96":{"position":[[9,6]]},"105":{"position":[[16,6]]},"192":{"position":[[5,5]]},"358":{"position":[[31,6]]},"426":{"position":[[29,6]]},"514":{"position":[[9,6]]},"564":{"position":[[30,6]]},"576":{"position":[[5,6]]},"580":{"position":[[17,6]]},"582":{"position":[[13,6]]},"584":{"position":[[8,6]]},"626":{"position":[[7,6]]},"628":{"position":[[21,6]]},"683":{"position":[[13,6]]},"703":{"position":[[43,6]]},"717":{"position":[[7,6]]},"719":{"position":[[5,6]]},"726":{"position":[[16,6]]},"745":{"position":[[6,6]]},"747":{"position":[[6,6]]},"769":{"position":[[9,6]]},"771":{"position":[[10,6]]},"799":{"position":[[11,6],[27,6]]},"810":{"position":[[25,6]]},"818":{"position":[[10,6]]},"930":{"position":[[22,6]]},"932":{"position":[[6,6]]},"934":{"position":[[22,6]]},"936":{"position":[[22,6]]},"938":{"position":[[16,6]]},"972":{"position":[[17,6]]}}}],["two",{"_index":433,"t":{"875":{"position":[[3,3]]},"1189":{"position":[[12,3]]}}}],["understand",{"_index":17,"t":{"29":{"position":[[0,13]]},"350":{"position":[[30,13]]},"356":{"position":[[0,13]]},"538":{"position":[[7,13]]},"597":{"position":[[3,13]]},"1161":{"position":[[21,13]]}}}],["unif",{"_index":541,"t":{"1128":{"position":[[0,11]]}}}],["unifi",{"_index":104,"t":{"129":{"position":[[6,7]]},"131":{"position":[[4,7]]}}}],["unimod",{"_index":223,"t":{"334":{"position":[[5,8]]}}}],["univers",{"_index":384,"t":{"720":{"position":[[12,12]]},"722":{"position":[[8,12]]},"724":{"position":[[8,12]]}}}],["unlearn",{"_index":413,"t":{"822":{"position":[[4,10]]}}}],["unlikelihood",{"_index":269,"t":{"424":{"position":[[4,12]]}}}],["unlock",{"_index":254,"t":{"393":{"position":[[5,9]]}}}],["up",{"_index":34,"t":{"34":{"position":[[17,2]]},"594":{"position":[[12,2]]}}}],["updat",{"_index":321,"t":{"562":{"position":[[27,6]]},"597":{"position":[[30,7]]},"928":{"position":[[14,6]]},"1068":{"position":[[0,6]]}}}],["upl",{"_index":555,"t":{"1210":{"position":[[12,3]]}}}],["usabl",{"_index":257,"t":{"397":{"position":[[3,9]]},"407":{"position":[[32,9]]}}}],["usag",{"_index":283,"t":{"444":{"position":[[7,5]]}}}],["user",{"_index":410,"t":{"808":{"position":[[16,6]]}}}],["v.",{"_index":379,"t":{"703":{"position":[[17,4],[36,4]]},"750":{"position":[[24,4]]}}}],["v2",{"_index":297,"t":{"513":{"position":[[17,2]]},"719":{"position":[[12,2]]},"745":{"position":[[13,3]]},"747":{"position":[[13,3]]}}}],["valu",{"_index":547,"t":{"1149":{"position":[[22,6]]}}}],["variabl",{"_index":189,"t":{"249":{"position":[[0,8]]}}}],["variant",{"_index":87,"t":{"103":{"position":[[6,8]]},"182":{"position":[[18,8]]},"509":{"position":[[19,7]]},"1187":{"position":[[0,8]]}}}],["verbal",{"_index":388,"t":{"750":{"position":[[0,10]]},"852":{"position":[[31,6]]}}}],["veri",{"_index":20,"t":{"30":{"position":[[14,4]]}}}],["version",{"_index":522,"t":{"1064":{"position":[[14,7]]},"1066":{"position":[[6,7]]},"1068":{"position":[[19,7]]}}}],["vi",{"_index":538,"t":{"1118":{"position":[[0,3]]}}}],["via",{"_index":424,"t":{"852":{"position":[[27,3]]}}}],["vision",{"_index":74,"t":{"90":{"position":[[4,6]]},"115":{"position":[[15,6]]},"191":{"position":[[15,6]]},"468":{"position":[[0,6]]},"1202":{"position":[[0,6]]},"1229":{"position":[[0,6]]}}}],["visual",{"_index":301,"t":{"522":{"position":[[20,6]]},"534":{"position":[[4,6]]},"538":{"position":[[0,6]]}}}],["vit",{"_index":76,"t":{"90":{"position":[[23,5]]}}}],["vo",{"_index":536,"t":{"1112":{"position":[[0,3]]},"1120":{"position":[[2,3]]}}}],["vqa",{"_index":202,"t":{"283":{"position":[[23,3]]},"285":{"position":[[26,3]]},"289":{"position":[[18,3]]},"317":{"position":[[58,3]]}}}],["vqav2",{"_index":156,"t":{"192":{"position":[[48,5]]}}}],["vs",{"_index":405,"t":{"797":{"position":[[9,2]]},"799":{"position":[[18,2]]}}}],["w\\triangl",{"_index":355,"t":{"607":{"position":[[35,11]]}}}],["weight",{"_index":345,"t":{"599":{"position":[[10,6]]}}}],["what'",{"_index":504,"t":{"1025":{"position":[[0,6]]}}}],["work",{"_index":12,"t":{"26":{"position":[[11,4]]},"87":{"position":[[11,4]]},"166":{"position":[[11,4]]},"272":{"position":[[11,4]]},"282":{"position":[[11,4]]},"331":{"position":[[11,4]]},"458":{"position":[[11,4]]},"505":{"position":[[11,4]]},"596":{"position":[[11,5]]},"609":{"position":[[25,4]]},"617":{"position":[[11,4]]},"705":{"position":[[11,4]]},"762":{"position":[[11,4]]},"851":{"position":[[10,4]]},"990":{"position":[[11,4]]},"1088":{"position":[[11,4]]},"1201":{"position":[[8,4]]}}}],["world",{"_index":285,"t":{"446":{"position":[[24,5]]}}}],["www",{"_index":357,"t":{"607":{"position":[[62,4]]}}}],["w△w",{"_index":356,"t":{"607":{"position":[[47,3]]}}}],["xxl",{"_index":338,"t":{"590":{"position":[[12,3]]}}}],["you'll",{"_index":2,"t":{"14":{"position":[[5,6]]}}}],["zero",{"_index":157,"t":{"194":{"position":[[0,4]]},"218":{"position":[[0,4]]},"315":{"position":[[16,4]]},"393":{"position":[[15,4]]},"462":{"position":[[4,4]]},"466":{"position":[[4,4]]},"488":{"position":[[0,4]]},"492":{"position":[[4,4]]},"507":{"position":[[0,4]]}}}],["zero/few",{"_index":204,"t":{"285":{"position":[[12,8]]}}}]],"pipeline":["stemmer"]}},{"documents":[{"i":3,"t":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","s":"First Blog Post","u":"/blog/first-blog-post","h":"","p":2},{"i":5,"t":"This is the summary of a very long blog post, Use a <!-- truncate --> comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","s":"Long Blog Post","u":"/blog/long-blog-post","h":"","p":4},{"i":7,"t":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. <button onClick={() => alert('button clicked!')}>Click me!</button> Click me!","s":"MDX Blog Post","u":"/blog/mdx-blog-post","h":"","p":6},{"i":9,"t":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md 2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","s":"Welcome","u":"/blog/welcome","h":"","p":8},{"i":11,"t":"Let's discover Docusaurus in less than 5 minutes.","s":"Tutorial Intro","u":"/docs/intro","h":"","p":10},{"i":13,"t":"Get started by creating a new site. Or try Docusaurus immediately with docusaurus.new.","s":"Getting Started","u":"/docs/intro","h":"#getting-started","p":10},{"i":15,"t":"Node.js version 16.14 or above: When installing Node.js, you are recommended to check all checkboxes related to dependencies.","s":"What you'll need","u":"/docs/intro","h":"#what-youll-need","p":10},{"i":17,"t":"Generate a new Docusaurus site using the classic template. The classic template will automatically be added to your project after you run the command: npm init docusaurus@latest my-website classic You can type this command into Command Prompt, Powershell, Terminal, or any other integrated terminal of your code editor. The command also installs all necessary dependencies you need to run Docusaurus.","s":"Generate a new site","u":"/docs/intro","h":"#generate-a-new-site","p":10},{"i":19,"t":"Run the development server: cd my-website npm run start The cd command changes the directory you're working with. In order to work with your newly created Docusaurus site, you'll need to navigate the terminal there. The npm run start command builds your website locally and serves it through a development server, ready for you to view at http://localhost:3000/. Open docs/intro.md (this page) and edit some lines: the site reloads automatically and displays your changes.","s":"Start your site","u":"/docs/intro","h":"#start-your-site","p":10},{"i":21,"t":"논문 및 이미지 출처 : https://arxiv.org/abs/2104.00298","s":"Paper Summarize EfficientNetV2","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":23,"t":"EfficientNetV2는 neural architecture speed (NAS) 와 scailing을 통해 이전 모델들 보다 더 빠르고 적은 파라미터 가지는 Convolution Network 특히 SOTA 모델보다 더 빠르면서 6.8배 작다 빠른 속도를 위해 progressive learning 을 도입하지만 이는 정확도를 떨어뜨려, 개선된 method인 adaptively adjust regularization 을 도입","s":"개요","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":25,"t":"GPT3-3 처럼 엄청 큰 모델과 데이터셋을 통한 훈련은 좋은 성능을 보여주지만, 수 천개의 GPU와 주 단위 학습으로, 재훈련 및 개선이 어려움 따라서 훈련 효율성이 최근 관심도가 높아지고 있다. model aim NFNets expensive batch normalization 제거 ConNets attention layer 추가로 훈련 속도 개선 VIT Transformer 블록으로 큰 데이터셋에 훈련 효율성 개선 이전 연구인 EfficientNet 에선 다음 문제점이 존재했다. 매우 큰 사이즈 이미지에는 훈련이 느림 depthwise convolution 이 초기 레이어에선 느림 매 단계마다 하는 동일한 scailing up은 차선책이었음 이를 Fused-MBConv 로 설계하고, NAS 와 scailing 으로 정확도, 속도, 파라미터 사이즈를 최적화한다. (파라미터는 6.8배 작아지고 속도는 4배 빨라짐) 이전 progressive learning 연구(FixRes, Mix&Match)는 모든 이미지 사이즈를 같은 정규화를 하지만, 이는 이상적이지 못하므로 개선된 progressive learning 제안 초기 epoch에 작은 이미지와 약한 정규화로, 서서히 이미지 사이즈를 증가시켜 큰 이미지엔 강한 정규화 학습키는 방법 이 접근법은 정확도를 떨어뜨리지 않으며 속도를 증가시킴 ImageNet 에서 3~9배 빠르고 이전 모델보다 6.8배 작아졌지만 87.7%의 정확도를 보임 이는 ViT-L/16 보다 5~11배 빠르면서 2% 의 높은 정확도를 가졌다.","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":27,"t":"훈련 및 파라미터 효율성 model aim DenseNet, EfficientNet 적은 파라미터로 좋은 정확도를 목표 ResNet, ResNetSt, TResNet, EfficientNet-X inference 속도를 개선 NFNet, BoTNet 훈련 속도 개선 이러한 연구들은 training 이나 inference 속도를 개선했지만 더 많은 파라미터가 생겨났다. Progressive training 관련 연구로 Progressive resizing 과 Mix&Match 가 있지만, 이는 accuracy drop 을 야기한다. curriculum learning 에 영감을 받아, 점점 정규화를 추가함으로써 서서히 학습을 어렵게 한다. Neural architecture search (NAS) image classification, object detection, segmentation 등에선 FLOPs 나 inference 효율 개선으로 주로 연구됐지만, 본 논문에서는 training 및 parameter 효율 개선으로 사용","s":"2. Related Work","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":31,"t":"EfficientNet 에선 큰 이미지에 대한 학습이 느리다고 했다. (모든 메모리가 GPU/TPU 에 고정 & 큰 이미지로 인한 작은 배치를 사용했어야 했서 속도가 느려졌다고 함) 간단한 개선법으로 작은 이미지 사이즈로 FixRes 를 적용하는 것이다. 위 표와 같이 작은 이미지로 배치를 늘려 2.2배 속도가 빨라지고 약간의 높은 정확도를 얻었다. (어떠한 fine-tuning 을 이용하지 않고도)","s":"Training with very large image sizes is slow","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#training-with-very-large-image-sizes-is-slow","p":20},{"i":33,"t":"EfficientNet 에서 사용한 Depthwise convolution 은 regular convolution 보다 적은 파라미터와 FLOPs 를 가지지만 accelerator 를 활용할 수 없게 된다. 그래서 최근에 MBConv 의 depthwise conv3x3 과 Conv1x1 을 single regular conv3x3 으로 교체한 Fused-MBConv 가 제안되었다. 두 블록을 비교하기 위해 MBConv 로 이루어진 EfficientNet-B4 모델에 서서히 Fused-MBConv 로 교체해보았다. 모든 블록을 Fused-MBConv 로 바꾸기 보단, 1-3 초기 단계를 교체하니 Params 와 FLOPs 가 적으면서도 정확도가 높았다.","s":"Depthwise convolutions are slow in early layers but effective in later stages","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#depthwise-convolutions-are-slow-in-early-layers-but-effective-in-later-stages","p":20},{"i":35,"t":"EfficientNet 에서 매 단계 동일하게 scailing up 하는 것은 차선책이었다. 이는 훈련 속도 및 파라미터 효율성에 기여를 하지 못하여, 본 논문에서는 non-uniform scaliling 전략으로 후기 단계에 서서히 추가하는 것을 제안 추가로 EfficientNet 에서 이미지를 scale up 을 하니 큰 메모리 소비와 훈련 속도 저하를 야기했음 이 이슈 해결을 위해서 scailing 규칙을 약간 수정하고, 최대 이미지 크기를 좀 더 작은 값으로 제한함","s":"Equally scailing up every stage is sub-optimal","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#equally-scailing-up-every-stage-is-sub-optimal","p":20},{"i":38,"t":"accelerator 를 사용하여 정확도, 파라미터 그리고 훈련 효율성을 최적화하기 위해 training-aware NAS 를 사용 EfficientNet 을 사용하며 search space 는 stage 기반의 factorized space 로 구성되며, {MBConv, Fused-MBConv} 의 convolution 과 {3x3, 5x5} 의 커널 사이즈, 확장 비율 {1, 4, 6} 을 포함한다. 반면에, 불필요한 작업인 pooling 을 제거 EfficientNet 에서 이미 연구된 채널 크기를 재사용 하여 search space 사이즈를 줄임 A - model accuracy S - nomalized training step time P - parameter size 를 다음과 같이 결합하여 search reward 에 대한 간단한 가중치를 만든다. A · Sw · Pv - weight w = -0.007 v = -0.05","s":"NAS Search","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#nas-search","p":20},{"i":40,"t":"위는 EfficientNetV2-S 의 아키텍처로, 기존 EfficientNet 과의 차이점은 다음과 같다. MBConv 와 초기 단계에 fused-MBConv 사용 MBConv 의 적은 비율을 선호 3x3 kernel 사이즈를 선호 EfficientNet 의 마지막 단계에서 stride-1 을 제거 위 차이점들로 파라미터와 처리시간을 줄임","s":"EfficientNetV2 Architecture","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#efficientnetv2-architecture","p":20},{"i":42,"t":"몇 가지 추가적인 최적화로 EfficientNetV2-S 를 scale up 하여 EfficientNetV2-M/L 을 얻었다. 매우 큰 이미지는 큰 메모리 비용 및 훈련 속도 오버헤드를 야기하므로 최대 480 으로 제한 EfficientNetV2-S 처럼 5-6단계에서 서서히 레이어를 더 추가","s":"EfficientNetV2 Scailing","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#efficientnetv2-scailing","p":20},{"i":44,"t":"모든 모델을 progressive learning 을 하지 않고 고정된 사이즈 이미지로 훈련한 결과, training-aware NAS 와 scailing 을 적용한 EfficientNetV2 가 다른 모델들 보다 매우 빠른 것을 관찰했다.","s":"Training Speed Comparison","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#training-speed-comparison","p":20},{"i":47,"t":"이미지 사이즈는 훈련 효율성에 큰 영향을 준다고 했었다. 다른 연구에서 다이나믹하게 이미지 사이즈를 훈련 중에 바꾸는데 (고정된 regularization 으로), 이는 정확도 저하를 야기했다. 이는 unbalanced regularization 으로 인해 생겨난다고 가설을 세운다. unbalanced regularization 가설을 입증하기 위해 각기 다른 이미지 사이즈와 데이터 augmentation으로, 작은 이미지는 약한 augmentation, 큰 이미지는 강한 augmentation을 사용한 것이 정확도가 좋았다. 따라서 본 논문에서는 작은 이미지에는 약한 regularization 을, 큰 이미지에는 강한 regularization 으로 과적합을 방지하는 것이 중요하다고 주장한다. 위 실험을 통해, progressive learning 을 개선한 method 인 adaptively adjust regularization 을 제안한다.","s":"Motivation","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#motivation","p":20},{"i":49,"t":"위와 같이 훈련 프로세스에 개선된 progressive learning 을 사용한다. 초기 에폭에 작은 이미지와 약한 정규화를 사용하여 학습을 쉽게하고 빠르게 한다. 이미지 크기를 서서히 증가 시키며, 강한 정규화를 추가하여 학습을 어렵게 한다. N - 전체 steps Se - 타깃 이미지 사이즈 Φe - 정규화 magnitude 리스트 = {Φek} k - dropout rate 또는 maxiup rate value 와 같은 정규화 타입 M - 각 훈련을 M stage 로 나눔 각 stage 는 1 <= i <= M 이고, 모델은 Si 사이즈 이미지와 Φi = {Φik} 의 정규화를 훈련한다. 처음엔 S0 와 Φ0 을 초기화하고, 각 단계의 값을 결정하기 위해 linear interpolation 을 사용한다. 알고리즘은 다음과 같다. 본 논문에서는 다음 3 가지의 정규화를 다룬다. Dropout - 무작위로 채널을 dropping 함. magnitude - γ\\gammaγ RandAugment - 각 이미지마다 데이터 증강. magnitude - ϵ\\epsilonϵ Mixup - data augmentation 을 교차시킨다. 라벨이 있는 두 이미지 (xi,yi)(x_i, y_i)(xi​,yi​) 와 (xj,yj)(x_j, y_j)(xj​,yj​) 가 주어졌을 때, λ 비율로 섞어 결합한다. x~i=λxj+(1−λ)xi\\tilde{x}_i = \\lambda{x}_j + (1-\\lambda)x_ix~i​=λxj​+(1−λ)xi​ and y~i=λyj+(1−λ)yi\\tilde{y}_i = \\lambda{y}_j + (1-\\lambda)y_iy~​i​=λyj​+(1−λ)yi​ magnitude - λ\\lambdaλ","s":"Progressive Learning with adaptive Regularization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#progressive-learning-with-adaptive-regularization","p":20},{"i":53,"t":"1.28M 훈련셋과 50,000 검증셋의 1000 클래스가 포함된 ImageNet ILSVRC2012 에는 테스트셋이 없으므로 훈련셋에서 25,000 이미지를 남김 훈련 세팅은 EfficientNet 을 따른다. RMSProp optimizer ( 0.9 decay, 0.9 momentum ) 0.99 batch norm momentum 1e-5 weight decay 350 epoch 0.256 lr, decayed 0.97 every 2.4 epoch exponential moving average (EMA) 0.9999 decay rate Regularization RandAgment Mixup Dropout progressive learning 은 4단계로, 약 87 에폭 당 진행했다고 한다.","s":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup","p":20},{"i":55,"t":"위의 성능표에서 보이듯 같은 computing resource 에서 EfficientNetV2-M 은 EfficientNet-B7 보다 11배 빠르다 한다. ResNetSt 와 비교하면 EfficientNetV2-M 이 2.8배 더 빠르면서도 0.6% 의 정확도가 높았다.","s":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results","p":20},{"i":58,"t":"ImageNet21k 는 21,841 클래스와 13M 훈련셋을 가진다. 테스트와 검증셋이 없으므로 무작위로 100,000개 이미지를 검증셋으로, 나머지는 테스트셋으로 이용한다. ImageNet ILSVRC2012 의 세팅을 사용하면서도 약간 변화를 주었다. 훈련 시간을 줄이기 위해 에폭수를 60 또는 30으로 변경 각 이미지는 multiple labels 를 가지므로, softmax loss 계산 전에 1로 합쳐서 정규화 진행","s":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup-1","p":20},{"i":60,"t":"위 성능표에서 보이듯 EfficientNetN2-L 는 Vit-L 보다 2.5배 더 적은 파라미터와 3.6배 더 적은 FLOPs, 그리고 6~7배 빨라진 학습 속도를 보였다.","s":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results-1","p":20},{"i":63,"t":"ImageNet ILSVRC2012 을 훈련하여 CIFAR-10, CIFAR-100, Flowers, Cars 데이터셋을 fine-tuning 한다. 훈련 세팅은 ImageNet 과 비슷하며, 약간의 수정이 있다. 512 batch size 0.001 lr, cosine decay fixed 10,000 steps disable weigt decay, simple data augmentation","s":"Setup","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#setup-2","p":20},{"i":65,"t":"위의 성능표에서 보이듯, CIFAR-100 에서 EfficientNetV2-L 은 이전 모델 GPipe/EfficientNets 보다 0.6%, ViT/DeiT 보다 1.5% 더 좋은 정확도를 보인다.","s":"Results","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#results-2","p":20},{"i":68,"t":"EfficientNetV2 와 EfficientNets 를 비교해보자.","s":"Comparison to EfficientNet","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#comparison-to-efficientnet","p":20},{"i":72,"t":"progressive learning 을 다른 모델에도 적용하여 비교한다.","s":"Progressive Learning for Different Networks","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#progressive-learning-for-different-networks","p":20},{"i":74,"t":"이미지 크기에 따른 adaptive regularization 접근법을 이용하여 결과를 관찰한다.","s":"Importance of Adaptive Regularization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"#importance-of-adaptive-regularization","p":20},{"i":76,"t":"training-aware NAS 와 model scailing 으로 최적화 개선된 progressivel learning 인 adaptively adjust learning 으로 이미지 크기를 서서히 증가시키며 강한 정규화를 사용 기존의 EfficientNet 의 아키텍처 초기 단계에 Fused-MBConv 를 교체 위 사항들을 통해 기존 EfficientNet 모델보다 6.8배 작아졌으며 11배 빨라졌다.","s":"7. Conclusion","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":78,"t":"Problems Solutions Training with very large image size is slow Apply FixRes with small image size Depthwise convolutions are slow in early layers but effective in later stages Gradually replace MBConv with Fused-MBConv Equally scailing up every stage is sub-optimal In early stage, Train small image size with weak regularization and gradually increase image size with stronger regularization Improved method of progressive learning: adaptively adjust regularization In the early epoch, train the network with small image size and weak regularization (e.g., dropout, randaugment, mixup) then gradually increase image size and add stronger regularization Speed up the training without causing accuracy drop use three types of regularization Dropout RandAugment Mixup Defference from EfficientNet Architecture In the early stage (1-3), replace MBConv with Fused-MBConv remove stride-1 in the last stage refer kernel of 3x3 size Training-Aware NAS and Scailing Algorithm","s":"Summarization","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":80,"t":"Setup 350 epoch 1e-4 lr, 1e-5 weight decay, 0.9 momentum RMSProp Implemented Network Code https://github.com/whdnjsdyd111/Paper-Experiments/blob/main/Image%20Classification/models/net/efficientnet.py","s":"Experiments","u":"/docs/Paper/Computer Vision/Image Classification/EfficientNetV2","h":"","p":20},{"i":82,"t":"논문 및 이미지 출처 : https://arxiv.org/abs/2010.11929v2","s":"An Image Is Worth 16X16 Words: Transformers for image recognition at sacle","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":84,"t":"NLP task 에서 Transformer Architecture 가 사용되어 오고 있다. 본 논문에서는 vision 의 CNN 구조를 유지하면서 Transformer 를 적용해 훌륭한 결과로 SOTA 를 달성하였다. 이를 Vision Transformer (ViT) 로 명명한다.","s":"Abstract","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":86,"t":"비전 분야에서, CNN-like 아키텍처 와 self-attention 을 결합하는 여러 시도가 있었고, 일부에서는 CNN 을 완전 교체 후자 모델은 이론적으로는 효율적이지만 GPU 에서 효과적으로 확장되지 않았음 위 사항들로 여전히 ResNet 과 같은 아키텍처가 여전히 SOTA 를 달성 본 논문은, 이에 가능한 한 적은 수정으로 표준 Transformer 를 직접 이미지에 적용하기 위해 실험을 진행 이미지를 패치 단위로 분할 분할된 패치의 선형 임베딩 시퀀스를 NLP 의 토큰처럼 처리하여 Transformer 에 입력으로 제공 중간 규모 데이터셋(ImageNet)으로 학습했을 때는 ResNet 보다 정확도가 낮은데, Transformer 는 equivariance 와 locality 같은 inductive bias 가 부족하여 일반화가 잘 되지 않기 때문으로 보인다. 큰 규모의 데이터셋(14M-300M 이미지)에서 훈련되면, 위 단점이 보완되어 다른 데이터셋에 transfer learning 을 한 결과 뛰어난 정확도를 보였다. inductive bias inductive bias 란 머신 러닝이 학습할 때, 어떤 가정이나 제한을 통하여 문제 공간을 탐색하는 방식 모델이 데이터로부터 일반화를 하는 데 중요한 역할 딥 러닝에서 inductive bias 의 예로 Layer 의 수, 각 Layer 의 뉴런 수, activation function 등의 구조적 제한이 있다. 적절한 inductive bias 로 일반화 성능을 올릴 수 있지만, 부적절하면 과적합을 발생한다. Trnasformer 에서 이러한 inductive bias 가 부족한 이유는 논문의 방법론 설명에 나온다.","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":88,"t":"Transformer 를 이미지 처리에 적용하려면 각 픽셀이 다른 모든 픽셀에 대한 self-attention 을 적용해야 했기 때문에 실질적으론 힘들다. self-attention 따라서 각 쿼리 픽셀의 지역 이웃에 대해서 self-attention 을 적용하거나, Sparse Transformer, block 크기 가변적 조정 등 다양한 방법으로 self-attention 을 적용하였지만 GPU 에서 효율적이지 못하였다. patch 이어, Cordonnier 모델은 2x2 크기 패치로 self-attention 을 적용하였는데, ViT 와 유사하지만, 패치가 작아 작은 해상도에서만 적용이 가능하나 본 연구는 중간 해상도에도 적용이 가능하다. combination CNN with self-attention Bello 등은 feature map 에 self-attention 을 추가, Hu 등은 CNN 의 출력 결과를 self-attention 으로 추가 처리하며 다양하게 CNN 과 self-attention 을 결합한 연구가 이루어지고 있다. 본 연구에서는 ImageNet 보다 큰 ImageNet-21k 와 JFT-300M 과 같은 대규모 데이터셋에서, 데이터셋 크기에 따른 CNN 성능이 어떻게 변화하는 지 연구하며 Transformer 를 훈련시킨다.","s":"2. Related Work","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":91,"t":"표준 Transformer (NLP) 에서는 token embedding 의 1D sequence 를 받는다. 2D 인 이미지를 다루기 위해, 이미지를 다음과 같이 처리한다. 이미지 입력 Embedding 이미지 x∈RH×W×Cx \\in \\mathbb{R}^{H \\times W \\times C}x∈RH×W×C 를 flattened 2D patch 의 sequence 인 xp∈RN×(P2⋅C)x_p \\in \\mathbb{R}^{N \\times ( P^2 \\cdot C )}xp​∈RN×(P2⋅C) 로 재배치한다. (H,W)(H, W)(H,W) : 원본 이미지 해상도 CCC : 채널 수 (P,P)(P, P)(P,P) : 각 이미지 패치의 해상도 N=HW/P2N = HW/P^2N=HW/P2 : 생성된 패치의 수, Transformer 의 효과적인 input sequence 길이 Transformer 는 모든 레이어에서 일정한 latent vector 사이즈 DDD 를 사용하므로, 패치를 flatten 하고 linear projection (아래의 식 1) 으로 DDD 차원으로 매핑한다. 이 projection 의 출력을 patch embedding 이라 칭한다. latent vector $$ latent vector 는 데이터를 압축하고 잠재적인 특징을 추출하는 데 사용되는 벡터이다. 일반적으로 입력 데이터를 저차원 벡터 공간으로 매핑하여 유용한 정보를 추출하고, 해당 정보를 바탕으로 다양한 테스크를 수행하는 데 사용된다. Token BERT 의 [ class ] token 과 유사하게, embedding patch 에 학습 가능한 embedding ( z00=xclassz_{0}^{0} = x_{\\textup{class}}z00​=xclass​ ) 을 추가 Transformer encoder 의 출력 상태 ( zL0z_{L}^{0}zL0​ ) 는 이미지 표현 yyy 로 사용 (아래의 식 4) pre-training 및 fine-tuning 을 수행할 때 Classification Head 를 zL0z_{L}^{0}zL0​ 에 부착 Classification Head pre-training : 1-hidden layer 인 MLP fine-tuning : 1-linear layer Position embedding position 정보 유지를 위해, Position embedding 을 patch embedding 에 추가 2D-aware position embedding 의 성능 향상은 관찰되지 않음 → 1D position embedding 사용 embedding vector 의 sequence 를 encoder 에 입력 Transformer encoder Multi-Head self-attention 와 MLP Block 을 교차하는 Layer 를 포함 Layernorm (LN) 을 모든 Block 이전에 적용 Residual Connection 을 모든 블록 끝에 적용 MLP 는 GELU non-linearity 가 있는 두 개의 레이어를 포함 (1) zo=[xclass; xp1E; x1=2pE; ...; xpNE]+Epos, E∈RN×(P2⋅C), Epos∈R(N+1)×Dz_o = [x_\\textup{class};\\ x^1_p\\textup{E};\\ x^1=2_p\\textup{E};\\ ...;\\ x^N_p\\textup{E}] + E_{pos},\\ E \\in \\mathbb{R}^{N \\times ( P^2 \\cdot C )},\\ E_{pos} \\in \\mathbb{R}^{(N + 1) \\times D}zo​=[xclass​; xp1​E; x1=2p​E; ...; xpN​E]+Epos​, E∈RN×(P2⋅C), Epos​∈R(N+1)×D 입력에 해당하는 수식으로, patch 로 나눈 각 이미지 시퀀스다. 마지막 EposE_{pos}Epos​ 는 각 시퀀스의 순서를 나타내는 Positional Encoding 이다. (2) zϱ′=MSA(LN(zϱ−1))+zϱ−1, ϱ=1 ... Lz'_\\varrho = \\textup{MSA}(\\textup{LN}(z_{\\varrho-1})) + z_{\\varrho-1},\\ \\varrho = 1 \\ ...\\ Lzϱ′​=MSA(LN(zϱ−1​))+zϱ−1​, ϱ=1 ... L Transformer Encoder 의 수식으로, Layer Normalization (LN) 후, Multi-head Attention (MSA) 을 적용 이후, Residual 로 zϱ−1z_{\\varrho - 1}zϱ−1​ 을 더한다 (3) zϱ=MLP(LN(zϱ′))+zϱ′,ϱ=1 ... Lz_\\varrho = \\textup{MLP}(\\textup{LN}(z'_\\varrho)) + z'_\\varrho,\\qquad \\varrho = 1 \\ ...\\ Lzϱ​=MLP(LN(zϱ′​))+zϱ′​,ϱ=1 ... L MLP head 의 수식으로, 위와 동일하다. (4) y=LN(zL0)y = \\textup{LN}(z^0_L)y=LN(zL0​) 마지막으로, classification 으로 target 값을 찾는다.","s":"3.1 Vision Transformer (ViT)","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#31-vision-transformer-vit","p":81},{"i":93,"t":"CNN 은 locality, 2D 이웃 구조체를 내재 반면, ViT 는 MLP 레이어만 지역성을 가지고, self-attention 레이어는 전역적이기 때문에 CNNs 보다 inductive bias 가 적다. Transformer 에서는 이 2D 이웃 구조체는 극히 드물게 사용한다. 모델 시작 부분에서 이미지를 패치로 자르는 것 fine-tuning 시 이미지의 position embedding 조절 position embedding 은 초기화 시 패치들의 2D position 정보가 없으며, 패치 간의 모든 관계를 처음부터 학습 해야함","s":"Intuctive bias","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#intuctive-bias","p":81},{"i":95,"t":"원시적인 Image patch 대안으로, sequence 는 CNN 의 feature map 으로 구성하는 것이 가능하여 Hybrid model 을 만든다. patch embedding projection EEE (식 1) 은 CNN feature map 으로 추출된 patch 에 적용한다. 특별한 경우, patch 는 1x1 사이즈도 가능 한데, 이는 sequence 가 feature map 의 차원을 flatten 하고 projecting 하여 Transformer 차원으로 얻을 수 있다는 것을 의미한다. CNN feature map 으로 patch 추출 → Flatten → embedding projection EEE (식 1)","s":"Hybris Architecture","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#hybris-architecture","p":81},{"i":97,"t":"일반적으로 ViT 를 큰 데이터셋에 pre-training 하고 downstream task 로 fine-tuning 이를 위해 다음 사항들을 진행한다. prediction head 제거 0 으로 초기화된 D×KD \\times KD×K 를 feedforward layer 에 부착 (여기서 KKK 는 downstream class 수) pre-training 보다 높은 해상도로 fine-tune 하는 것이 이득 높은 해상도로 할 땐, patch size 를 동일하게 해야함 → 더 큰 effective sequence length 가 생성 fine-tune 시, pre-trained 의 position embedding 은 의미가 없음 따라서 pre-trained 의 position embedding 을 2D 보간 (interpolation) 해야 함 위의 해상도 조정 및 패치 추출은 ViT 에 대한 이미지 구조의 inductive bias 를 삽입하는 방법","s":"3.2 fine-tuning and higher resolution","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#32-fine-tuning-and-higher-resolution","p":81},{"i":99,"t":"Resnet, ViT, hybrid 를 각각 평가한다.","s":"4. Experiments","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"","p":81},{"i":102,"t":"train dataset ILSVRC-2012 ImageNet-1k (1.3M images) ImageNet-21k (14M images) JFT-18k (303M high resolution images) transfer dataset transfer learning 평가 ImageNet ImageNet ReaL CIFAR-10/100 Oxford-IIIT Pets/-Flowers102 VTAV 또한 19-task VTAB 분류 평가로 여러 그룹의 작은 데이터셋 transfer 평가 Natural : Pets, CIFAR Specialized : medical, satellite imagery Structured : geometric, localization","s":"Datasets","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#datasets","p":81},{"i":104,"t":"Table 1 의 Base, Large, Huge 는 BERT 를 기반으로한 ViT 의 구성이다. 간단한 표기법으로 모델 사이즈 및 input patch 사이즈를 다음과 같이 나타낸다. ViT-L/16 : 16x16 input patch 및 \"Large\" 모델 sequence length 는 patch 크기 제곱에 반비례 → patch 가 작을수록 계산량 증가 CNN 베이스라인은 ResNet 으로, 다음과 같이 수정을 더하였다. Batch Normalization → Group Normalization & Standardized Convolution 이렇게 수정한 ResNet 을 BiT 라 표시 transfer learning 의 성능 향상 Hybrid 모델의 경우, 중간 feature map 으로 ViT 에 한 픽셀 (1x1) 의 patch 사이를 입력 각기 다른 sequence length 로 실험 ResNet50 - stage 4 ResNet50 - stage 3 (단, Layer 수 유지) → 4배 더 긴 sequence length (stage 3 의 output 이 확장되므로)","s":"Model Variants","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#model-variants","p":81},{"i":106,"t":"train model include ResNet Adam ( β1=0.9\\beta_1 = 0.9β1​=0.9 , β2=0.999\\beta_2 = 0.999β2​=0.999 ) batch size 4096 weight decay 0.1 fine-tune SGD batch size 512 고해상도 변경 : 512 - ViT-L/16, 518 - ViT-H/14","s":"Training & Fine-tuning","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#training--fine-tuning","p":81},{"i":108,"t":"few-shot 정확도는 다음과 같이 얻는다. 고정된 훈련 이미지의 representation 추출 {−1,1}K\\{ -1,1 \\}^K{−1,1}K target vector 로 매핑 위 과정으로 regularized least-squares regression 문제를 해결하여 얻음 주로 fine-tuning 성능에 초점을 두지만, 비용이 많이 들어 linear few-shot 정확도를 빠르게 평가","s":"Metrics","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#metrics","p":81},{"i":110,"t":"ViT-H/14 와 ViT-L/16 를 CNN SOTA 모델들과 비교 한다. BiT Large EfficientNet 으로 semi-supervised 훈련한 Noisy Student 모든 모델은 TPUv3 로 훈련을 진행하였고, 결과는 위 Table 에서 나타난다. 위 그림은 각 VTAB 작업 그룹에 따른 결과 비교이다.","s":"4.2 Comparison to State Of The Art","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#42-comparison-to-state-of-the-art","p":81},{"i":112,"t":"각각 ImageNet, ImageNet-21k, JFT-300M 데이터셋으로 pre-train 한 결과 JFT-300M 이 가장 좋았다. 이는 ResNet 보다 inductive bias 가 적기 때문에 많은 데이터가 있어야 하기 때문이다. 각 pre-train 후 작은 데이터셋에서 성능을 올리기 위해, 세 가지 regularization 을 설정한다. weight decay dropout label smoothing 두 번째로, JFT-300M 의 하위집합으로 9M, 30M, 90M 및 전체를 학습하여 비교한다. 하위 집합에는 추가적인 정규화를 수행하지 않고 모든 하이퍼파라미터를 동일하게 사용한다. 여기서 fine-tuning 정확도 대신 linear few-shot 정확도를 관찰한다. 위 그래프에서 보이듯 작은 데이터셋에는 ResNet 보다 오버피팅 발생한다. 이 결과로 다음을 알 수 있다. transfer learning 시 작은 데이터셋에는 convolution inductive bias 가 유리 transfer learning 시 ViT 는 큰 데이터셋에 유리","s":"4.3 Pre-trained Data Requirements","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#43-pre-trained-data-requirements","p":81},{"i":114,"t":"각 Transformer, BiT, Hybrid 의 크기에 대한 실험 모델은 다음과 같다 ResNets, R50x1, R50x2 R101x1, R152x1, R152x2 pre-train for 14 epochs R152x2, R200x3 pre-train for 14 epochs ViT-B/32, B/16, L/32, L/16 pre-train for 7 epochs L/17, H/14 pre-train for 14 epochs R50+ViT-B/32, B/16, L/32, L/16 pre-train for 7 epochs R50-ViT-L/16 pre-train for 14 epochs 이 실험에서 다음을 관찰할 수 있다. ViT 는 성능/계산 적으로 BiT 보다 뛰어남 적은 비용에선 Hybrid 가 ViT 보다 약간 더 좋음 ViT 는 포화되지 않아, 성능이 더 좋아질 수도 있다.","s":"4.4 Scailing Study","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#44-scailing-study","p":81},{"i":116,"t":"ViT 가 이미지를 처리하는 법을 이해하기 위해 internal representation 을 분석한다. internal representation 이미지 처리 과정에 모델은 입력 이미지의 다양한 특징을 추출하며, 이러한 특징을 모델 내부의 데이터에 맞는 representation 으로 변환한다. Transformer 에서는 이미지 정보를 2D attention 메커니즘으로 1D embedding 으로 변환한다. 이 embedding 이 Transformer 의 internal representation 이다. 왼쪽 : ViT-L/32 로 RGB 의 initial linear embedding 로 Filter 각 Filter 는 저차원의 CNN filter 와 유사 중앙 : ViT-L/32 의 position embedding 유사도 Projection 후 position embedding 이 patch representation 에 추가 즉, 더 가까운 패치 (같은 행/열 등)는 더 유사한 position embedding 을 가짐 → patch 간의 공간정보가 잘 학습 오른쪽 : head 와 network depth 에 따른 attened area 사이즈 self-attention 으로 전체 이미지 정보를 통합 가능한지 조사 attention weight 를 기반으로 image space 간 평균 거리 계산 이 attention distance 는 CNN 의 receptive field 와 유사 낮은 layer 의 self-attention head (낮은 attention distance 지님) 는 CNN 의 초기 convolutional layer 와 유사한 기능을 가짐 → localization 효과 나아가 이미지 분류에 의미있는 영역에 attention 하는 것 발견 receptive field receptive field 는 입력된 이미지의 어떤 부분에서 반응을 보이는지를 나타내는 개념","s":"4.5 Inspecting Vision Transformer","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#45-inspecting-vision-transformer","p":81},{"i":118,"t":"NLP task 에서 self-supervision 을 시도 예로, BERT 에서의 masking ViT 에선 masked patch 를 예측함으로 self-supervision ViT 에서 self-supervision 한 결과 ViT-B/16 모델은 ImageNet 에서 79.9% 정확도 달성 Supervised Learning 보다는 4% 떨어짐","s":"4.6 self-supervision","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#46-self-supervision","p":81},{"i":120,"t":"patch 추출 단계에서 image-specific inductive bias 를 도입하지 않음 대신, 이미지를 sequence 처럼 해석하여 표준 Transformer encoder 로 진행 큰 데이터셋으로 pre-train 하면 잘 작동 (위 실험의 JFT-300M) 남은 과제 detection, segmentation 에서는 ViT 를 어떻게 적용할 것인가 self-supervised 와 큰 규모의 supervised pre-training 간의 갭 ViT 의 scailing 으로 성능 향상 기대","s":"5. Conclusion","u":"/docs/Paper/Computer Vision/Image Classification/ViT","h":"#5-conclusion","p":81},{"i":122,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2206.07669v2.pdf","s":"A Unified Sequence Interface for Vision Tasks","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":124,"t":"NLP 분야는 단일 통합 모델링 프레임워크로 표현할 수 있지만 computer vision 분야에선 아직 없다. 결과로, 서로 다른 vision task 에 대한 아키텍처와 loss function 이 급증하고 있다. 이에 저자는 computer vision 의 다양한 핵심 task 들은 공유된 pixel-to-sequence interface 형태로 나타내면, 통합될 수 있다고 한다. 그리고 bounding box 나 dense mask 와 같은 다양한 타입의 출력을 가진 task 인 object detection, instance segmentation, keypoint detection 및 image captioning 과 같은 네 가지 task 에 초점을 둔다. 각 출력을 통합된 interface 와 discrete token 의 시퀀스로, 특정 task 에 커스터마이징 없이 단일 모델 아키텍처와 모든 task 에 대한 loss function 으로 모델을 학습시킨다. 특정 task 에 풀기 위해, short prompt 를 task description 으로 사용하고 시퀀스 출력을 prompt 에 적응하여 특정 task 의 output 을 생성한다. 이러한 모델로 task 별로 잘 알려진 모델과도 갱쟁력 있는 성능을 보였다.","s":"Abstract","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":126,"t":"다양한 task 를 수행할 수 있는 단일 신경망을 훈련하는 것은 인공 지능의에서 중요한 진전이다. 최근 몇년간, Transformer 을 사용한 큰 언어 모델의 등장으로, 서로 다른 언어 및 관련 task 들이 단일 모델링으로 통합되었다. 이러한 언어 모델은 주어진 task description 으로 해결책을 예측하도록 훈련된다. 이것이 가능한 이유는 이러한 task 들은 동일한 rich language interface 에서 표현할 수 있기 때문이다. 이는 image captioning 이나 visual question answering 처럼 computer vision 쪽으로 확장 가능하나, \"핵심\" computer vision task 에는 자연어로 쉽게 표현할 수 없다는 것이다. object detection : bounding boxes, class label instance segmentation : segmentation mask, image regions keypoint detection : keypoints 이러한 복잡한 tasks 들은 각각 따로 특화된 아키텍처나 loss function 이 개발된다. 서로 다른 vision 을 통합하기 한다는 것은 아키텍처 및 loss function 설계를 간소화하고 task 간의 feature/representation 공유를 촉진하여, task 간의 정교한 output head 를 필요로 하지 않도록 하는 것이다. 또한 기존 모델을 새 task 에 적응시키는 것을 용이하게하고, zero, few 의 새로운 기능을 잠재적으로 열 수 있다. 끝으로, 저자는 네 가지 서로 다른 task 를 단일 pixel-to-sequence interface 로 통합하는 방법을 제시한다. 네 가지 vision task는 object detection, instance segmentation, human keypoint detection, image captioning 이며, 먼저 이 task 들을 single shared interface 로 통합하는 방법을 보여준다. 이후, shared architecture 와 object function 이 있는 뉴럴 네트워크를 훈련한다. 특정 task 에 적용하기 위해선, specific head 사용과, prompt 를 사용하여 task 를 지정하며, sequence output 을 prompt 에 적응시킨다. 이로서, 주어진 task description 으로 특정 task 의 output 을 생성한다.","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":128,"t":"저자는 computer vision task 를 pixel input (task 의 description 과 함께) 을 별개의 tokensequence 로 변환하는 task 중 하나로 캐스팅한다. 저자는 다음 4 가지 task 에 초점을 둔다. object detection instance segmentation keypoint detection image captioning","s":"2. Approach","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":130,"t":"서로 다른 task 는 각각 다음 output 을 가진다. object detection : bounding boxes, class label instance segmentation : segmentation mask, image regions keypoint detection : keypoints image captioning : natural language description, sequence 위와 같이 각각의 task 는 출력 형태가 차이가 있어, 전용 모델 아키텍처와 loss function 이 필요하다. 이를 단일 모델로 해결하기 위해, 저자는 task input 및 output 을 unified interface 로 transformation/tokenization 하는 것을 주장한다. 이 연구에서, sequence interface 를 제안하며, tkas description 및 output 은 다양한 작업의 시퀀스로 표현된다. Object Detection bounding boxes 와 object description 을 연속적인 이미지 좌표를 quantizing 하여 다양한 토큰 의 시퀀스 로 변환 object 는 [ymin⁡,xmin⁡,ymax⁡,xmax⁡,c][y_{\\min}, x_{\\min}, y_{\\max}, x_{\\max}, c][ymin​,xmin​,ymax​,xmax​,c] 와 같은 5 개의 discrete token 의 시퀀스 로 표현 multiple object 는 훈련 이미지를 샘플링할 때마다 주막위로 정렬되어 하나의 시퀀스 로 직렬화 Instance Segmentation 픽셀 단위의 마스크 대신, 해당 instance mask 에 대응하는 polygon 을 개별 객체 인스턴스에 조건화된 이미지 좌표의 시퀀스로 예측하고 또한, polygon 을 시퀀스로 바꾸기 위해, 훈련용 이미지가 샘플링될 때마다 시작 토큰에 대한 시작점을 무작위로 선택 동일한 인스턴스에 여러 polygon 이 있다면, 각 polygon 의 시퀀스를 연결하여 모든 인스턴스에 대해 하나의 대응하는 시퀀스를 얻도록 한다. Keypoint Prediction 주어진 사람 인스턴스에 조건부로 양자화된 이미지 좌표의 시퀀스로 keypoint 를 예측 keypoint 의 시퀀스는 [ykeypoint 1,xkeypoint 1,ykeypoint 2,xkeypoint 2,⋯ ][y_{\\textup{keypoint\\ 1}}, x_{\\textup{keypoint\\ 1}}, y_{\\textup{keypoint\\ 2}}, x_{\\textup{keypoint\\ 2}}, \\cdots][ykeypoint 1​,xkeypoint 1​,ykeypoint 2​,xkeypoint 2​,⋯] 로 인코딩 각 (y,x)(y, x)(y,x) 좌표에 keypoint label (예; 코, 왼쪽 눈, 오른쪽 눈)을 사용할 수 있지만, 간단함을 위해 고정된 순서는 필요하지 않음 일부 keypoint 가 가려져 있는 경우, 좌표 토큰을 특수한 가림 토큰 (occlusion token) 으로 대체 Captioning discrete token 의 시퀀스로 주어진 caption 의 text token 을 직접 예측 네 가지 task 는 모두 동일한 단일 vocabulary 를 가진다.","s":"2.1 A unified interface with tokenization","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#21-a-unified-interface-with-tokenization","p":121},{"i":132,"t":"저자는 복잡한 image input 과 sequence output 을 유연하고 표현력 있는 아키텍처가 필요하다. 따라서 image encoder 와 sequence decoder 가 있는 encoder-decoder 아키텍처를 사용한다. image encoder : 픽셀 인식 및 hidden representation 으로 매핑 여기서 hiden representation 은 ConvNet, Transforer 이나 이들의 조합으로 구현 가능 sequence decoder transformer 기반 디코더는 하나의 토큰을 생성하며, 이전 토큰과 인코딩된 image representation 에 의존한다 이는 여러 vision task 에 대한 현대 뉴럴 네트워크의 아키텍처에 대한 복잡성과 커스터마이징을 제거해준다. 단일 object detection task 에서 디코더가 output token 을 직접적으로 생성하는 것과 달리, 여기선 task prompt 를 조정하여 모델이 관심 task 에 적합한 output 을 생성하도록 한다. 훈련 중엔, prompt 와 원하는 output 을 하나의 시퀀스로 연결하지만, token weighting 체계를 활용하여 디코더가 원하는 output 뿐만 아니라 prompt token 도 예측하도록 훈련된다. 추론 중엔, prompt 가 주어지고 고정되므로, 디코더는 나머지 시퀀스만 생성하면 된다. 훈련 목표는 이미지와 이전 토큰에 조건화된 토근의 likelihood 를 최소화하는 것이다. maximize∑j=1Lwjlog⁡P(yj∣x,y1:j−1),(1)\\textup{maximize} \\sum^L_{j=1}w_j \\log P(y_j|x,y_{1:j-1}), \\tag{1}maximizej=1∑L​wj​logP(yj​∣x,y1:j−1​),(1) xxx 는 input image yyy 는 xxx 와 관련한 시퀀스 길이 LLL, 언급했듯이 시퀀스 yyy 의 초기 부분은 prompt 이다. wjw_jwj​ 를 0 으로 설정하여 loss 에 포함하지 않도록 한다.","s":"2.2 Unified architecture and objective function","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#22-unified-architecture-and-objective-function","p":121},{"i":134,"t":"각 task 는 image-sequence 쌍의 훈련 데이터를 가진다. 두 가지 방법으로 task 를 결합하고 합동으로 훈련을 수행할 수 있다.","s":"2.3 Training","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#23-training","p":121},{"i":136,"t":"서로 다른 task 에서 가져온 mixed image-sequence 쌍으로 dataset 을 만들 수 있으며, 서로 다른 dataset 크기와 task 어려움에 대한 균형을 맞출 수 있다. 이 구성은 개념적으로 매우 간단하지만, image augmentation 은 관련된 시퀀스를 쉽지 않은 방법으로 변경해야할 수 있어 통합하기 어려울 수 있다.","s":"Data mixing","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#data-mixing","p":121},{"i":138,"t":"각 배치에서, 단일 task 에 대한 annotation 을 가진 이미지를 샘플링하고, 이 task 에 적합한 image augmentation 을 수행하고, 증강된 데이터를 image-sequence 쌍으로 변환한다. 이 모델은 각 task 에 대한 loss 와 gradient 를 계산한 수 있고, 특정 task batch 의 gradient 를 적절한 weighting 을 결합할 수 있다. Algorithm 1 과 2 에서 요약 및 전략을 보여준다. 이 연구에선 image augmentation 을 단순하게 처리하기 위해 batch mixing 전략을 사용한다. data mixing 과 batch mixing 은 각 task 에 대한 부분 또는 weightinh 을 지정해야 한다. 이는 경험적인 문제이며, 저자는 한 번에 하나의 task 를 추가하여 greedy 전략을 사용한다. task 추가할 때마다마다, 저자는 기존 task 에 따른 상대적인 weighting 을 유지하면서 new task 의 weighting 을 조절한다. 모든 task 에 걸친 weight 의 합을 하나로 고정한다.","s":"Batch mixing","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#batch-mixing","p":121},{"i":140,"t":"추론할 땐, 시퀀스 시작 시 prompt 가 주어진 모델의 likelihood (예; P(yj∣x,y1:j−1)P(y_j|x,y_{1:j-1})P(yj​∣x,y1:j−1​) ) 로부터 토큰을 샘플링한다. nucleus sampling 을 사용하고 있지만 beam search 와 같은 다른 기술 또한 사용된다. 토큰이 생성되면, 각 task 에 대한 토큰을 디코딩할 수 있다. 서로 다른 task 가 토큰 시퀀스를 생성하기 위해 특정 tokenization scheme 를 필요로 하는 것과 동일하게, 디코딩 (de-tokenization) 프로세스 또한 각 task 에 고유하다. 각 task 의 추론 디코딩에 대한 자세한 설명은 다음과 같다. bounding boxes : 예측된 시퀀스를 5 개 토큰의 tuple 로 분할하여 좌표 토큰과 클래스 토큰을 얻고, 좌표 토큰을 dequantizing 하여 bounding box 를 얻는다. instance segmentation : 각 polygon 에 해당하는 좌표 토큰을 dequantize 한 다음, dense mask 로 변환한다. 모델은 정규화로 훈련되지 않아, output polygonal mask 는 다소 노이즈가 있을 수 있다. 노이즈를 줄이기 위해, multiple sequence 를 샘플링하고 mask 를 평균화한 다음, single binary mask 를 얻기 위해 간단하게 임계값으로 나눈다. keypoint detection : keypoint 의 이미지 좌표 토큰을 직접적으로 dequantizing 한다 captioning : 예측된 discrete token 을 바로 text 로 매핑한다","s":"2.4 Inference and de-tokenization","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#24-inference-and-de-tokenization","p":121},{"i":143,"t":"118k 훈련용 이미지와 5k 검증용 이미지를 포함하는 MS-COCO 2017 dataset 으로 평가를 하며 이 데이터셋으로 4가지 task 를 고려한다. 해당 데이터셋의 이미지는 object bounding box 를 위한 annotation, object instance 를 위한 segmentation mask, person instance 를 위한 keypoint, 그리고 few captions 을 포함한다. 이전 논문 Pix2Seq 을 따라, Vision Transformer (ViT-B) encoder 와 Transformer autoregressive decoder를 사용한다. 이 모델의 총 132M 파라미터를 가지고 있다. 초기화를 위해, Objects365dataset 에서 object detection 을 훈련한 pretrained checkpoint 를 사용했다. COCO 가 상대적으로 작아, task 에 덜 특화된 사전 지식을 가져서 유용 COCO 훈련의 경우 128 이미지 배치 사이즈 1e−41e^{-4}1e−4 의 lr 100 epochs 35k single vocabulary 및 32K text tokens 1K coordinate quantization bins 및 few other class label 최대 시퀀스 길이는 512 백본은 640x640 이미지 사이즈 pretrain 및 finetuning 은 640x640 또는 1024x1024 해상도","s":"3.1 Experimental settings and implementation details","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#31-experimental-settings-and-implementation-details","p":121},{"i":145,"t":"Pix2seq 에 따라 훈련 중 sequence augmentation 을 사용하고, 추론 시 class token 확률을 사용하여 점수를 매긴다. 또한 Pix2seq (가로 세로 비율이 변하지 않고 무작위로 영상 스케일링, 고정된 크기 영역을 무작위로 자른 다음 최대 크기로 패딩) 처럼 scale jittering 을 사용한다.","s":"Object detection","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#object-detection","p":121},{"i":147,"t":"polygon 의 최대 점수를 128 로 설정한다. 모델에게 추론 시 여러 샘플을 생성하도록 요청하고, 생성된 마스크를 평균내는 것이 이득이라는 것을 발견했다. 구체적으로, 각 샘플을 독립적으로 추출하여 이를 prompt 된 객체의 semantic mask 로 변환한다. 그 후, 50% 임계값을 설정하여 마스크를 평균내고, 50% 이상의 픽셀은 해당 인스턴스를 위해 선택된다. 저자는 8개의 샘플이 충분히 좋은 성능을 제공하며 (단일 샘플 사용 시보다 약 6 AP 높음), 12개 이상의 샘플에서는 성능 형상이 보이지 않는 다는 것을 발견했다. 또한 추론 과정에서 prompt 된 object instance 를 포함하는 이미지의 cropped region 에서도 평가를 한다. 이 경우엔, 입력 이미지를 cropped region 만 포함하는 새 이미지로 대체한다. 640x640 크기의 작은 이미지에서는 1.3 AP 로 개선이 이루어졌지만, 1024x1024 크기의 큰 이미지에서는 큰 효과가 없었다.","s":"Instance segmentation","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#instance-segmentation","p":121},{"i":149,"t":"저자는 person instance 을 포함하는 이미지의 copped region 에서 훈련 및 평가한다. 학습 중엔, 이 region 들이 ground-truth annotation 에 의해 제공되며 추론 중엔, 이 region 들은 object detection model 에 의해 제공된다. 이 region 에 제공된 bounding box 의 두 배 크기로 선택한다. 이런 최적의 crop 을 사용하여, 매우 큰 crop (bounding box 크기의 약 20배, 전체 이미지 사용에 근접한 것으로 간주)을 사용하는 것보다 약 9 AP 향상을 얻었다. 또한, quantized sequence 에서 보이지 않는 토큰 좌표를 나타내는 특수 토큰을 사용한다. 학습 시, 이런 토큰에 대한 작은 loss weight 0.1 을 사용한다. 더 큰 가중치를 사용하더라도 AP 에 큰 영향을 미치지 않지만(가중치 1.0 에서 1 낮아짐), 가중치 0.0 을 사용하면 훨씬 나쁜 결과가 나온다 (12 AP 낮음). 추론 시에는 보이지 않는 토큰을 모델이 keypoint 좌표의 최선의 추측값으로 대체한다.","s":"Keypoint detection","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#keypoint-detection","p":121},{"i":151,"t":"object detection, instance segmentation, image captioning 및 keypoint detection 각각 0.1782, 0.7128, 0.099, 0.01 의 mixed weighting 을 사용한다. 이러한 weight 의 셋은 한 번에 하나의 task 를 추가하여 greedy 탐색을 한다.","s":"Four-tasks joint training","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#four-tasks-joint-training","p":121},{"i":153,"t":"object detection 의 경우 strong 2-stage detector 인 Faster R-CNN 및 보다 최신인 Transformer-based detector 인 DETR 와 비교한다. Faster R-CNN 및 DRET 는 모두 Faster R-CNN 의 non-maximum suppression 및 DRET 의 일반화된 IoU 과의 biparite graph matching 같은 설계에서 task 별 사전 설정을 사용한다. 커스터마이징된 아키텍처 및 loss function 때문에, 넓은 범위의 task 로 확장하는 것은 간단하지 않으며 새로운 모델을 설계할 필요가 있다. Mask RCNN 은 Faster R-CNN 을 확장하여 segmentation 및 keypoint 를 통합하는 설계를 지지한다. Mask RCNN 은 네 가지 작업 중 세 가지를 수행할 수 있지만, 여전히 Faster R-CNN 과 동일한 task 기반 세팅이 필요하다. 또한 Transformer 와 유사한 attention 메커니즘을 통합하는 non-local 아키텍처가 있는 Mask R-CNN 의 개선된 버전도 고려한다. 위 방법들은 image captioning 을 할 수 없으므로, task 에 특화된 Transformer 기반의 caption model 을 훈련한다. 이 모델은 caption single task 을 위해 제안된 방법으로 훈련된 것과 유사하지만, 높은 dropout rate 이 있는 사전 훈련된 visual encoder 를 사용하고 있다.","s":"Baselines","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#baselines","p":121},{"i":155,"t":"위 테이블 1 에 결과가 요약 돼있으며, 다음 베이스라인과 두 가지의 모델을 소개 한다. single task 에 대해 훈련된 single task model (여전히 동일한 아키텍처 및 objective function). 따라서 각 task 는 자체의 network weight 를 가진다. sinle network weight 의 셋이 4 가지 task 에 대해 사용된 multi-task model 특정 task 에 대한 아키텍처나 loss function 의 사전 지식 없음에도, 저자의 모델은 여전히 각 개별적인 task 에 대한 결과가 경쟁력 있다고 한다 (심지어 이미지 사이즈가 작을 때도). 모든 task 에 대해 single model 로 훈련했을 때, 모델 사이즈를 동일하게 유지 했음에도 각각의 task 를 해결할 수 있었다. 또한, 이미지 사이즈를 크게 하면 성능 향상도 관찰했다. 한 예외로는 keypoint detection 인데, 감지한 key point 에 대한 cropped interest region 을 이미 사용하여, 이미지 사이즈를 키우는 것이 반드시 유용한 것은 아니며 labeld data 에 제한된 경우 과적합으로 이어질 수 있다. greedy 을 각 task 에 사용하여 적합한 loss weighting 을 선택한 것을 Figure 에서 볼 수 있다. Figure 4a 에서 object detection 과 instance segmentation 간의 weight 비율을 탐색한다. 광범위한 weight 비율의 경우 두 작업의 성능이 모두 피크에 가까워서 두 작업에 대해 2:8 weight 비율을 선택한다. 이후, image captioning task 를 추가하고, captioning task 의 서로 다른 weighting 에서의 성능을 Figure 4b 에서 확인할 수 있으며, 여기서 기존 task 와 image captioning task 에 대한 9:1 weighting 비율이 적절하다는 것을 알 수 있다. 마지막으로, keypoint detection task 를 추가하면, Figure 4c 에서, 이 weight 가 상대적으로 작게 설정될 수 있으며 0.01 을 사용하기로 선택한다.","s":"3.2 Quantitative results","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#32-quantitative-results","p":121},{"i":157,"t":"보다 시각적이고 직관적인 방식으로 모델의 기능과 성능을 입증하기 위해, object detection, instance segmentation, keypoint detection 및 image captioning 과 같은 네 가지 각 task 에 대해 COCO 검증셋으로부터 선택된 이미지에 대한 multi-task 모델의 출력을 보여준다. Figure 5 에서 object detection task 결과를 보여 준다. 이 모델은 어수선한 장면에서도 크기가 다른 물체들을 성공적으로 감지한다. instance segmentation 과 keypoint detection 에 대한 경험적 결과는 Figure 6, 7 에서 보여준다. 두 task 에서 multi-task 모델은 localized 및 정확한 예측을 생성한다. 또한 Table 2 에서 생성된 몇 가지 caption 을 보여준다. 이러한 결과로, 저자는 모델이 대규모 이미지 텍스트 데이터셋을 사용하여 사전 훈련되지 않았다는 것에 주목하며, 이는 모델의 captioning 성능이 크게 향상될 것으로 예상된다.","s":"3.3 Qualitative results","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"#33-qualitative-results","p":121},{"i":159,"t":"본 연구에서, task description (prompt) 과 task output 모두 토큰의 discrete sequence 로 표현되는 다양한 \"핵심\" vision task 의 다양한 셋을 해결하기 위한 통합 시퀀스 인터페이스를 탐구한다. 이는 아키텍처 및 loss function 이 task 간에 공유된다는 점에서 multi-task vision model 의 기존 규범에서 크게 벗어난다는 것으로, 이러한 모델이 잘 확립된 task-specific model 에 비해 경쟁력 있는 성능을 달성 할 수 있음을 보여준다. 이 연구에는 제한이 없으며, 기존 접근법에서 크게 벗어났기 때문에 이 아키텍처와 다른 훈련법 모두가 특화된 시스템의 SOTA 에 더 개선됬다고 믿는다. 또한 더 큰 데이터셋(예; image-text pairs) 에 대한 pretraining 또는 더 큰 모델 사이즈를 사용하는 것 모두에서 확장의 이점을 크게 얻을 수 있다고 믿는다. 다른 한계는 접근법이 autoregressive 모델링에 기반하여 특화된 시스템에 비해 추론 속도가 잠재적으로 느릴 수 있다. 효율성을 향상시키는 몇 가지 방법이 있는데, 여기에 non-autoregressive sequence 모델링 사용이 포함된다. 본 연구에서, 모델 추론 속도를 높이기 위해 병렬 쿼리를 활용한다. 예로, 여러 사람의 포즈를 예측하는 것은 독립적인 (모델 자체로 감지되거나 미리 주어진) bounding box 로 모델에 prompt 를 표시하여 독립적으로 수행할 수 있어, 유일한 순차적 예측은 몇 개의 keypoint 를 가진 single person 으로 제한된다. instance segmentation 에도 동일한 전략을 적용할 수 있다. 통합 인터페이스의 최적 구현에는 여전히 더 많은 연구가 필요하고 이 task 에서 탐색된 시퀀스 인터페이스는 잠재적인 구현 중 하나에 불과하지만, 저자는 다양한 task 들이 표현되는 방식의 인터페이스가 향후 범용 인공지능 시스템에서 점점 중요한 역할을 할 것이라 믿고 있다.","s":"5. Conclusion","u":"/docs/Paper/Computer Vision/Multi-task/Unified Interface","h":"","p":121},{"i":161,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.02506.pdf","s":"Prismer: A Vision-Language Model with An Esemble of Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":163,"t":"최근 vision-language 모델이 multi-modal 능력을 보이기 위해 거대한 학습이 필요하다. 이에 Prismer 로 데이터 및 파라미터에 효율적인 vision-language 를 소개 Prismer 는 적은 수의 구성요소만 학습하며, 대부분의 가중치는 미리 학습된 domain experts 로부터 상속받아 학습 중 동결 상태를 유지한다. 넓은 범위의 domain experts 를 모아, Prismer 는 효율적으로 expert knowledge 를 수집하고, 다양한 vision-language 추론 작업에 적용할 수 있음을 보여준다. 최대 2배 적은 데이터로도 Prismer 는 SOTA 를 달성한 모델들과 경쟁력 있는 fine-tuning 과 few-shot learning 성능에 도달 했다.","s":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":165,"t":"pretraining 한 대규모 모델은 다양한 작업에 좋은 일반화 능력을 가졌지만 대량의 훈련 데이터 및 계산 비용이 든다. 특히, vision-language 은 image captioning, visual question answering 등과 같은 multi-modal 추론이 필요하므로 recognition, detection, counting, 3D perception 등의 많은 기술이 요구된다. 일반적으로 이들은 대규모 데이터를 학습한 모델로 해결한다. 대신에, 저자들의 접근법으로 experts 라고 하는 서로 분리된 sub-network 로 이러한 스킬들과 domain knowledge 을 학습시키는 것이다. 이 모델은 모든 것을 한번 학습하는 것보다, 여러 스킬과 domain knowledge 를 통합하는데 초점을 둔다. 이 방법은 multi-modal 학습을 축소하는데 효과적인 방법이다. Prismer 의 핵심 설계는 다음 요소를 포함한다. web-scale knowledge 에 대한 강력한 vision, language 백본 모델 auxiliary knowledge 형태의 low-level vision signals (e.g. depth) 과 high-level vision signals (e.g. instance, segmentic label) 로 다양한 형태의 vision 정보를 인코딩한 vision experts 모든 expert model 은 따로 따로 pre-trained 하여 동결하여 전체 network parameter 에 약 20% 에 해당하는 학습가능한 components 로 연결된다. Prismer 는 13M 에도 불구하고 image captioning, image classification, visual question answering 등의 multi-modal 에 좋은 추론 성능을 보인다. 마지막으로, Prismer 의 다음 학습 방식을 분석한다. noisy experts 에 대해 강한 견고함을 보임 학습 성능 또한 experts 양이 증가함에 따라 호의적으로 확장","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":169,"t":"Prismer 는 encoder-decoder 인 transformer model 이다. endoer : vision input : RGB image 와 multi-label labels (e.g. depth, surface normal, segmentation ..) output : RGB 와 multi-modal features 의 sequence decoder : auto-regressive language cross attention 을 통해 multi-modal features 를 조절 output : 텍스트 token 의 sequence 위 Prismer 는 다른 SOTA 만큼의 성능에 도달하는데 필요한 GPU 시간을 줄였다. web-sacle 을 학습한 pretrained vision 과 language 인 top backbone 모델로 만들어 졌다. 또한 multi-modal signals 를 받아들이기 위해 vision encoder 를 확장하였으며, 이는 generated multi-modal auxiliary knowledge 와 capture semantic 을 가능케 했다. 예를 들어, \"text-reading\" 은 OCR detection expert 로 해결 \"object-recognition\" 은 object detection 으로 해결 모든 visual expert labels 은 Prismer 에 포함한다. Prismer 는 생성 모델로, language modeling 이나 prefix language modeling 같은 vision-language 추론 작업을 새로 만들었다.","s":"3.1 Model Overview","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#31-model-overview","p":160},{"i":171,"t":"Prismer 는 두 가지의 pre-trained experts 를 포함한다. Backbone Experts vision 과 language 모델 모두 transformer 아키텍처를 기반으로 한다 학습가능한 components 로 쉽게 연결 모델 parameter 에 encoding 된 domain knowledge 를 보존하기 위해 pretraining 면서 대부분의 weight 를 동결 Modality Experts low-level vision signals: depth, surface, edge; high-level vision signals: object labels, segmentation labels, text labels; 를 인코딩한 6 modality expert 포함 위 mdality experts 는 black-box 예측기 modality experts 의 weight 를 동결하여 어떤 설계도 가능하도록 함 위 predicted labels 에 modality 별로 후 처리 후 RH×W×C\\mathbb{R}^{H \\times W \\times C}RH×W×C tensor 로 transforming 한다 (H, W, C 는 height, width, channel 임. e.g. depth 는 C=1C = 1C=1, surface 는 C=3C = 3C=3). high-level semantic signal 를 인코딩한 모든 experts 에 대해, 각 픽셀을 이에 대응하는 pretrained CLIP model 로 text embedding 과 함께 tiling 한다. 이후 효과적인 훈련을 위해서 PCA 를 적용하여 차원수를 C=64C = 64C=64 으로 down-sampling 한다. 모든 modality experts 에 대한 자세한 사항은 아래 테이블과 같다.","s":"3.2 Pre-trained Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#32-pre-trained-experts","p":160},{"i":174,"t":"모든 experts labels 는 처음에 무작위로 초기화된 convolution layer 를 지난다. 같은 차원수로 매핑하기 위함 5 convolution layers 를 적용 각각에 [3 x 3] 의 작은 커널을 구성 기존 ViT 의 큰 커널로 된 single convolutional layer 보다 성능이 좋음 For high-level semantic labels 실행중인 메모리를 보존하기 위해 해상도를 4배로 다운 샘플링 object instance 간의 차이를 식별하기 위해 학습 가능한 무작위로 샘플링된 embedding 을 추가 → instance embedding, 128 로 설정 For RGB images 간단하게 pretrained vision 백본으로 convolutional stem 정의 모든 modality expert embedding 은 RGB 를 포함하며, transformer layer 를 지나기 전에, pretrained positional embedding 을 추가한다.","s":"Modality-Specific Convolutional Stem","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#modality-specific-convolutional-stem","p":160},{"i":176,"t":"self-attention 의 계산 복잡도는 patch 수에 비례하므로, modality experts 의 수가 크면 쉽게 많은 메모리를 요구할 수도 있다. 이 이슈를 해결하기 위해 Experts Resampler 를 제안한다. For Experts Resampler 다양한 experts 를 input 으로 받음 고정된 수의 embedding 을 출력 language decoder 와 vision encoder 와 무관하게 self-attention 계산에 대해 일정한 메모리를 소모 모든 multi-modal features 에서 연결된 flattened embedding 을 cross-attend 하기 위해 pretrained latent query 를 학습 이후 multi-modal features 를 auxiliary knowledge distillation 형태처럼 latent query 의 수와 동일한 작은 수의 토큰으로 압축한다. 결국, 더 좋은 효과를 위해 multi-modal features 와 learned latent queries 를 연결하기 위해 key 와 value 로 설계","s":"Experts Resampler","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#experts-resampler","p":160},{"i":178,"t":"multi-modal features 의 표현력과 훈련성을 향상 시키기 위해 vision 과 language 백본 모델의 각 transformer layer 에 lightweight adaptor 를 삽입 For Lightweight Adaptor 먼저, input feature 를 non-linearity 적용으로 작은 차원으로 down-projection 한다. 훈련 안정성을 위해 Squared ReLU 를 사용한다. 이후, input 의 원래 차원으로 되돌리기 위해 up-projection 한다. residual connection 을 이용하여, identity function 을 일치시키기 위해 near-zero weights 로 모든 adaptor 를 초기화 한다. 위 adaptor 를 통해서, language decoder 에서 cross attention block 과 연결하여 domain 별 vision 및 language 백본을 vision-language 로 자연스럽게 변환시킨다.","s":"Lightweight Adaptor","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#lightweight-adaptor","p":160},{"i":180,"t":"저자는 Prismer 를 next token 을 autoregressive 하게 예측하기 위한 한 가지 목표로 훈련 시켰다. 표준 encoder-decoder 아키텍처에 따라 다음의 forward autoregressive factorisation 진행 L=−∑t=1T log p(yt∣y<t,z)L = - \\sum^T_{t=1}\\ log\\ p(y_t |y_{<t},z)L=−∑t=1T​ log p(yt​∣y<t​,z) vision encoder 의 multi-modal feature 예측값 zzz language decoder 는 TTT 길이만큼 text caption yyy 의 조건부 우도 (conditional likelihood)를 최대화하도록 학습 위 목표는 gradient 계산을 위해 한 번의 forward pass 만 요구되며, 다른 VLMs 보다 효과적이고 능률적이다. 하지만 모델은 multi-modal language generation 에 초점을 두기 때문에, image-text retrieval 이나 visual entailment 와 같은 mutli-modal discriminative task 에는 적합하지 못하다.","s":"3.4 Training Objective","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#34-training-objective","p":160},{"i":183,"t":"Prismer 말고도, Experts Resampler 없이 RGB 이미지 만으로 학습을 진행한 PrismerZ 도 있다. 두 모델은 vision encoder 에 pretrained CLIP, language decoder 에 RoBERTa 를 활용했다. 실험 초기엔 다른 언어 모델인 OPT 나 BLOOM 을 사용했지만 좋은 성능은 내지 못했다. 모델 사이즈는 LARGE, BASE 두 가지로 진행을 한다. BASE : ViT-B/16 and RoBERTaBASE_{BASE}BASE​ LARGE : ViT-L/14 and RoBERTaLARGE_{LARGE}LARGE​","s":"4.1 Prismer Model Variants","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#41-prismer-model-variants","p":160},{"i":186,"t":"in-domain 데이터셋 COCO Visual Genome web 데이터셋 Conceptual Captions SBU captions Conceptual 12M web 데이터셋은 image captioner 로 pre-filter 와 re-caption 을 거쳤다. 데이터셋은 11M image 또는 12.7M 의 image/text 쌍을 포함하고 있다.","s":"Pre-training Datasets","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#pre-training-datasets","p":160},{"i":188,"t":"Optimizer AdamW weight decay, 0.05 Model Sharding model parameters 의 일부만 훈련이 가능하여 고해상도 fine-tuning 할 때만 적용 모든 GPU 에 교차하여 optimiser states 와 parameter gradient 가 가능한 ZeRO Stage 2 기술을 채용 ZeRO Stage 분산 학습 및 추론을 효율적이고, 효과적으로 만드는 딥러닝 최적화 라이브러리 Mixed Precision 훈련 시간 감소를 위해 Automatic Mixed Precision (AMP) 사용 fp16 precision 적용 AMP 일반적으로 모델 학습 시 FP32 (부동소수점 표기법, 32bit) 를 사용하는데, 연산량 감소를 위해 FP16 을 적용하면 loss 가 올라가는 현상이 있음비트 수가 줄어든 만큼 backpropagation 을 진행하면서 정확한 수를 표현 못하기 때문이다. 이에 NVIDIA 측에서 이를 해결하고자 다음과 같은 automatic 방법을 제안한 것모델 최적화 및 훈련 속도 감소를 가능케 한다.","s":"Optimisation and Implementation","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#optimisation-and-implementation","p":160},{"i":190,"t":"image captioning 평가를 위해 텍스트 생성을 beam size 3 으로 beam search 를 사용한다. fine-tining 된 image captioning 에 \"A picture of\" 라는 접두사 prompt 를 input text 에 추가하니 품질 개선에 도움이 되는 것을 발견했다. VQA 및 image classification 평가에 대해서는 미리 정의된 답변 목록에서 token 단위로 log-likelihood 를 순위로 매겨서 closed ended 방식으로 평가한다. beam search NLP 분야의 Decoder 알고리즘 모든 단어 조합을 생성하고 그 중 가장 가능성이 높은 조합을 선택하는데, 이때 단어 조합 수를 파라미터인 \"beam size\" 를 설정한다. 즉, beam size 는 후보군 개수이다. Open-ended & Close-ended Open-ende 는 문제에 대한 미리 정의된 대답에 제한되지 않고, 개념적 이해나 문맥적 이해가 필요한 것. 예로 이미지 캡셔닝 작업에서 이미지에 대한 설명이나 이야기를 생성 Close-ended 는 미리 정의된 목록에서 선택할 수 있는 한정된 대답만 가지고 문제를 해결 하는 것. 예로 이미지가 주어졌을 때 미리 정의된 카테고리 목록에 해당하여 분류 되는지 봄","s":"Evalution Setting","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#evalution-setting","p":160},{"i":193,"t":"표준 cross-entropy loss 로 COCO Caption 을 fine-tuning 진행 이후, COCO Caption test 와 NoCaps validation, VQAv2 dataset 와 Visual Genome training samples 로 평가 다른 VLMs 모델들과 다음과 같이 비교를 하였다.","s":"Fine-tuned Performance COCO Caption, NoCaps and VQAv2","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#fine-tuned-performance-coco-caption-nocaps-and-vqav2","p":160},{"i":195,"t":"Fig 4 Prismer approach 는 zero-shot 생성도 가능하며, 추가적인 fine-tuning 없이 image captioning 에 직접적으로 적용이 가능하다. 위 중앙 테이블을 살펴보자. NoCaps 데이터셋에서, 140회 정도의 훈련만으로 SimVLM 과 경쟁력이 있다. 다음과 같은 Prismer 로 생성한 caption 목록 예제를 보여준다.","s":"Zero-shot Performance on Image Captioning","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#zero-shot-performance-on-image-captioning","p":160},{"i":197,"t":"few-shot 으로 ImageNet 데이터셋을 통해 평가를 진행 \"A photo of a [CLASS NAME]\" 과 같은 임시 caption 으로 각 카테고리를 매핑하여 classification task 로 변환하였으며, log-likelihood 를 사용하여 모든 caption 에 점수를 매긴다. Flamingo 는 gradient 업데이트 없이 in-context (문맥에 포함되는지) 를 통해 few-shot 한것과 달리, Prismer 는 가벼운 fine-tuning 으로 few-shot 하였다. Fig 4 의 오른쪽을 살펴보자. GIT 이나 Flamingo 보다는 좋은 실적을 내지 못함. few-shot 에서 백본 모델인 ViT-B 와 ViT-L 과 큰 차이로 성능이 좋음 위 사실로, 더 좋은 experts label 이나 vision backbone 으로 성능을 더 끌어올릴 수 있다는 것을 시사","s":"Few-shot Performance on ImageNet Classification","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#few-shot-performance-on-imagenet-classification","p":160},{"i":199,"t":"저자는 Prismer 에 대한 추가적인 조사와 발견을 위해 추가 실험을 수행, 여러 component 아키텍처 를 제거 모든 실험은 BASE 모델로 진행하였으며, 총 3M data 인 Conceptual Captions 와 SBU 를 결합하여 훈련 하였으며, 평가는 [224 x 224] 해상도의 VQAv2 로 평가했다.","s":"5. Additional Analysis","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":202,"t":"위 그림의 (a) 와 같이 더 많은 modality experts 를 추가하니 성능 개선이 나타남 이유는 모델에 더 많은 domain knowledge 를 제공할 수 있기 때문 하지만 끝내 성능이 정체되며, 이후 추가되는 modality experts 는 확실한 이득을 제공하진 않음","s":"More Experts, Better Performance","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#more-experts-better-performance","p":160},{"i":204,"t":"위 그림 (b) 와 같이 expert 의 퀄리티에 대한 영향을 평가 일정 수의 예측된 depth labels 를 손상된 depth 로 교체 (균일하게 분포된 무작위 noise 를 샘플링) 위 사항으로 좋은 quality experts 는 더 정확한 domain knowledge 를 제공한다는 사실을 관찰","s":"Better Experts, Better Performance","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#better-experts-better-performance","p":160},{"i":206,"t":"위 그림 (c) 와 같이Prismer 가 noise 를 예측하는 expert 를 포함해도 성능이 유지되는 것을 관찰 RGB 이미지만 학습한 것 보다 noise 를 추가한 것이 정확도가 좋다. 위 사항은 암묵적으로 정규화로 간주될 수 있으며, Prismer 가 유익하지않은 expert 에 대해서도 안전하게 학습하고 성능 저하를 일으키지 않는 다는 것이다 표준적인 multi-task 나 auxiliary learning 보다 더 효과적인 학습 전략이라는 것을 암시","s":"Robustness to Noisy Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#robustness-to-noisy-experts","p":160},{"i":209,"t":"adaptor 설계에 대한 ablation study 는 위 표에서 확인할 수 있다. 표준 residual connection 과 encoder-decoder 구조가 포함된, 간단한 adaptor design 이 가장 성능이 좋았다. 각 transformer layer 끝마다 adaptor 를 추가하거나 learnable gating 메커니즘을 구성한 복잡한 설계에 대해서는 성능이 좋지 않았다. 나아가, 단일 adaptor 에 큰 bottleneck hidden size 를 주니 개선된 성능을 보였다.","s":"Adaptor Design and Size","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#adaptor-design-and-size","p":160},{"i":211,"t":"resampler 설계에 대한 ablation study 는 위 표에서 확인할 수 있다. 간단한 설계가 학습에 가장 적합했다. 무작위로 non-learnable 샘플링한 접근법은 learnable resampler 보다 성능이 낮았고, resampler 를 RGB 를 포함하여 모든 input signal 을 받아 들이니 (Prismer design 은 RGB 에 대해선 받지 않음) 성능 감소가 일어났다. 마지막으로 resampler 크기를 키우니 이득을 얻지 못하였다.","s":"Resampler Design and Multi-modal Sampling Strategy","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#resampler-design-and-multi-modal-sampling-strategy","p":160},{"i":213,"t":"모델을 freezing 한 것과, pre-training 및 fine-tuning 을 비교한 실험을 진행 freezing pre-trained 파라미터가 좋은 성능이 나타났으며, 과적합 및 학습하며 배운 knowledge 을 잊는 것을 피하였다. 또한 이 파라미터들을 freezing 을 하니 GPU 메모리의 상당 수의 양을 save 하였다. 심지어 다른 downstream task 에 fine-tuning 할 때도 이득을 얻었다.","s":"The Effect of Frozen Backbones","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#the-effect-of-frozen-backbones","p":160},{"i":215,"t":"이 논문의 결론으로 Prismer 가 적은 수의 trainable components 를 활용하여, Image captioning, VQA, image classification 등에 좋은 성능을 보인다는 것을 말한다.","s":"6. Conclusions, Limitations and Discussion","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"","p":160},{"i":217,"t":"zero-shot in-context generalisation 은 큰 언어 모델에만 존재하는 신생적인 특성 Prismer 는 효율적인 학습을 중점으로 두어, 작은 규모라서 few-shot in-context prompting 수행 능력이 없음","s":"Multi-modal In-context Learning","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#multi-modal-in-context-learning","p":160},{"i":219,"t":"다른 데이터셋으로 pre-train 한 segmentation expert 로 pre-train 된 Prismer 의 추론을 실험 동일한 언어 모델로 semantic label 을 인코딩하지만, 서로 다른 semantic 정보에 대한 experts 에 대해 제한된 적응성을 보여, 성능 저하를 일으킴","s":"Zero-shot Adaptation on New Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#zero-shot-adaptation-on-new-experts","p":160},{"i":221,"t":"위 내용과 비슷하게, Prismer 가 pretraining 할 때 포함되는 모든 experts 의 multi-modal features 에 얽매이는 것을 발견 따라서 추론 중 일부 experts 만 있으면 성능 저하를 일으킴 마스킹된 auto-encoding 같은 다른 훈련 목표로, Prismer 를 임의의 수로 experts 를 기반으로 추론하니 성능 저하가 일어남","s":"Free-form Inference on Partial Experts","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#free-form-inference-on-partial-experts","p":160},{"i":223,"t":"Prismer 는 모든 experts 에 대해 후 처리 후 이미지와 동일한 3차원 텐서로 변환하는데, object detection labels 을 텍스트 토큰 시퀀스로 변환과 같은 domain knowladge 을 나타내는 효과적인 방법도 있으며, 이는 앞으로의 연구에서 더 강한 추론과 안정적인 훈련이 가능할 것으로 보임.","s":"Representation of Expert Knowledge","u":"/docs/Paper/Computer Vision/Vision-Language/Prismer","h":"#representation-of-expert-knowledge","p":160},{"i":225,"t":"논문 및 이미지 출처 : https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf","s":"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":227,"t":"chain-of-thought 로 intermediate reasoning step 의 series 를 생성하여 LLM 의 complex reasoning 능력을 크게 향상하는 방법 탐구 chain-of-thought prompting 이란 간단한 방법을 통해 reasoning 능력이 자연스럽게 나타나는 것을 보임 3개의 LLM 에 실험 arithmetic, commonsense 및 symbolic reasoning task 에 성능 향상 empirical gain 이 현저할 수 있음 8개의 CoT exemplar 로 PaLM 540B 를 prompting 할 경우, math word problem 의 GSM8K 벤치마크에서 SOTA 달성 -> finetuned GPT-3 능가","s":"Abstract","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":229,"t":"최근, LM 의 크기 확장이 성능 및 샘플 효율성이 향상되는 여러 이점을 준다는 사실을 입증 하지만, 크기 확장만으론 arithmetic, commonsense 및 symbolic reasoning 같은 어려운 task 에서 높은 성능은 부족 본 논문은 두 가지 아이디어에 기반한 방법으로 LLM 의 reasoning 능력을 탐구 arithmetic reasoning 기술은 final answer 로 이어지는 근거를 생성하여 이득을 얻을 수 있음 처음부터 훈련 또는 pretrained model 을 finetuning 하여 intermediate steps 에 자연어 생성 능력 부여 언어 대신 neuro-symbolic 방법도 존재 LLM 은 prompting 을 통해 in-context few-shot learning 의 흥미로운 가능성 제공 new task 마다 별도의 LM checkpoint 를 finetuning 하는 대신, few input-output exemplar 를 사용하여 간단한 \"prompt\" 가능 위 두 아이디어는 각각 주요 제한 사항 존재 rationale-augmented training 및 finetuning 의 경우 고품질의 근거셋을 생성하는 것은 간단한 input-output 보다 훨씬 복잡하며 비용이 큼 few-shot prompting 의 경우, 추론 능력을 필요로하는 작업에 대해 성능이 나쁘고 모델 크기가 증가함에 따라 크게 향상되지 않음 구체적으로 <input, chain of thought, output> 세 가지를 포함한 few-shot prompting 의 reasoning task 의 수행 능력을 탐구 approach : chain-of-thought prompting 저자의 접근법은 arithmetic, commonsense 및 symbolic reasoning 벤치마크에 평가하여 standard prompting 을 능가 math word problem 인 GSM8K 의 경우, CoT 를 사용한 PaLM 540B 이 standard prompting 을 큰 폭으로 능가하여 SOTA 달성 prompt-only approach 는 대규모 훈련셋을 필요로 하지 않으며 single model checkpoint 가 일반성을 잃지 않고 많은 task 를 수행하므로 이 또한 중요한 특성이지만 본 논문은 어떻게 LLM 이 few examples 로 task 를 학습할 수 있는지 관한 연구인지 강조한다.","s":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":231,"t":"복잡한 추론 task 인 multi-step math word problem 을 고려해보자. 일반적으로 문제를 intermediate steps 로 분해하고 각각 해결 후 final answer 를 제시한다. 저자는 충분히 큰 언어 모델이 CoT 의 few-shot prompting exemplar 가 제공되면 CoT 를 생성할 수 있다는 것을 보여준다. (Fig 1 참고) CoT 는 multi-step 을 intermediate step 으로 분해할 수 있으며, 더 많은 추론 단계가 필요한 문제에 추가적인 계산 할당 CoT 는 모델의 동작을 해석 가능하게 하여 답변에 도달하는 방식을 시사 및 잘못된 추론 경로를 찾는 기회 제공 CoT 추론은 arithmetic, commonsense 및 symbolic reasoning 같은 task 에 사용 가능 CoT 추론은 CoT 에 few-shot prompting 예제로 간단히 포함하여 off-the-shelf LM 에 쉽게 유도 가능","s":"2. Chain-of-Thought Prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":233,"t":"LM 의 arithmetic reasoning 능력을 측정 540B parameter LM 에 CoT prompting 을 사용하여 여러 task 에서, task-specific finetuning 모델들과 비교 (GSM8K 에서 SOTA)","s":"3. Arithmetic Reasoning","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":236,"t":"GSM8K : math word problems SVAMP : 다양한 구조의 math word problems ASDiv : 다양한 math word problems AQuA : algebraic word problems MAWPS : algebraic word problems","s":"Benchmarks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#benchmarks","p":224},{"i":238,"t":"Fig 1 의 왼쪽. input-output pair 의 in-context 예제에 맞춘 standard few-shot prompting","s":"Standard prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#standard-prompting","p":224},{"i":240,"t":"저자의 approach : few-shot prompting 의 각 exemplars 와 관련된 답변에 CoT 로 보강하는 것 기존 데이터셋은 evaluation 으로만 분리되어, 저자는 8개의 few-shot exemplars 를 직접 작성 Fig 1 오른쪽. CoT exemplar, AQUA 를 제외한 벤치마크는 각각 8개 CoT 를 사용. AQuA 는 mutiple choice 형태이므로 4개의 exemplar 와 solution 을 사용","s":"Chain-of-thought prompting","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#chain-of-thought-prompting","p":224},{"i":242,"t":"5가지 LLM 평가 GPT-3 (350M, 1.3B, 6.7B, 175B) LaMDA (422M, 2B, 8B, 68B, 137B) PaLM (8B, 62B, 540B) UL2 (20B) Codex 각 모델은 greedy decoding 으로 샘플링 LaMDA 의 경우, 각 seed 가 서로 다른 무작위로 섞인 exemplar 순서를 가진 5개의 seed 에서 평균 : 다른 seed 간의 큰 분산이 보이지 않아 연산량을 줄이기 위해 single exemplar 사용","s":"Language models","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#language-models","p":224},{"i":244,"t":"CoT prompting 은 model scale 의 새로운 능력 작은 모델 대신, 약 100B 정도의 모델과 함께 사용할 때만 성능 향상 작은 모델에선 유창하지만 논리적으로 부적절한 CoT 생성 CoT prompting 은 더 복잡한 문제에서 더 큰 성능 향상 GSM8K (baseline 성능이 가장 낮은 데이터셋)에서, GPT 및 PaLM 같은 LLM 에서 성능이 두 배 이상 향상 해결을 위한 단계가 하나만 필요한 MAWPS 의 경우, 성능 향상이 부정적이거나 매우 작음 LLM 을 통한 CoT prompting 은 task-specific model 을 finetuning 한 것과 비교 PaLM 540B 에 CoT 를 사용하여 여러 task 에 SOTA 달성 CoT prompting 의 동작을 더 잘 이해하기 위해 GSM8K 에 대한 LaMDA 137B 에서 생성한 CoT 를 수동으로 검토 50개 무작위 예제를 생성한 CoT 는 2개를 제외하고 모두 논리적 및 수학적으로 올바른 것을 나타냄 또한 모델이 잘못된 답변을 반환한 50개의 무작위 예제도 조사 PaLM 62B 에서 발행한 오류가 PaLM 540B 에서도 발생하는 지 조사. 62B 의 one step 누락 및 의미 이해 오류의 큰 부분이 수정","s":"3.2. Results","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#32-results","p":224},{"i":246,"t":"CoT prompting 의 이점이 다른 유형의 prompting 으로도 얻을 수 있는지, ablation 연구 진행","s":"3.3. Ablation Study","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#33-ablation-study","p":224},{"i":248,"t":"CoT prompting 이 도움되는 이유 중 하나는 평가에 수학적 수식을 생성하기 때문. 그래서 답변 제공 전 수학적 수식만 유도하여 테스트. Fig 5 를 보면 equation only prompting 은 GSM8K 에 큰 도움이 되지 않는 것을 확인 의미론이 CoT 의 추론 단계에 직접 수식으로 번역하기 어렵기 때문 one-step / two-step problem dataset 의 경우, 질문에서 수식을 도출할 수 있어 equation only prompting 이 도움이 됨","s":"Equation only","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#equation-only","p":224},{"i":250,"t":"CoT model 이 어려운 문제에 더 많은 계산 (i.e. intermediate tokens)을 사용하도록 허용하는 것 → 변수 계산의 영향을 CoT 의 이론적 추론과 격리하여, 문제 해결에 필요한 수식의 문자 수와 동일한 점(.) 개수만을 출력하도록 유도 baseline 과 비슷한 성능을 보이며, variable compute only 만으로는 CoT 의 성공 원인이 아니며, intermediate steps 로 표현하는 데 유용성이 있는 것으로 보임","s":"Variable compute only","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#variable-compute-only","p":224},{"i":252,"t":"CoT prompting 의 다른 잠재적 이점은 pre-training 중 얻은 지식을 더 잘 활용한다는 것. → 답변 이후에만 CoT prompting 을 제공하는 설정으로 테스트 위 설정으로 모델이 최종 답변을 내기 위해 CoT 에 의존하는 것을 격리함 이는 baseline 과 비슷한 성능을 보이며, CoT 내의 순차적 추론이 knowledge 활성화 이상으로 유용하다는 것 시사","s":"Chain of thought after answer","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#chain-of-thought-after-answer","p":224},{"i":254,"t":"서로 다른 annotators 가 작성한 CoT 에 대한 Robustness 를 평가 CoT prompting 을 위해 동일한 few-shot exemplars 에 annotator A, B 및 C 등 독립적으로 CoT 작성. A 는 원래 CoT 보다 더 간결히 CoT 를 작성 ([Training Verifiers to Solve Math Word Problems] 의 설정을 따른 것) Fig 6 은 LaMDA 137B 의 GSM8K 및 MAWPS 결과 다양한 CoT annotators 사이에 분산이 있지만, baseline 보다 높은 성능 CoT 의 성공적인 사용이 특정 스타일에 의존하지 않음을 시사 CoT prompting 이 다양한 exemplars 에도 잘 작동하는지 확인을 위해 GSM8K 훈련셋에 8개 샘플 3 셋에 실험 Fig 6 은 CoT prompting 이 수동으로 작성한 exemplar 와 비슷한 결과를 보여줌 standard prompting 보다 훨씬 높은 성능 annotator, 독립적으로 작성된 CoT, 다양한 LM 에 대한 robustness 외에도, arithmetic reasoning 을 위한 CoT prompting 이 다른 exemplars 에 대해서도 robust 하다는 것을 발견","s":"3.4. Robustness of Chain of Thought","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#34-robustness-of-chain-of-thought","p":224},{"i":257,"t":"CSQA 사전 지식이 필요한 복잡한 의미를 가진 상식적 질문 StrategyQA multi-hop 전략 추론을 요구 BIG-bench 의 두 가지 특정 평가셋 Date Understanding : 주어진 문맥으로 날짜 추론 Sports Understanding : 스포츠 관련 문장이 타당한지 불가능한지 판단 SayCan 로봇 동작 순서로 매핑","s":"Benchmarks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#benchmarks-1","p":224},{"i":259,"t":"CSQA 및 StrategyQA 경우 무작위 예제를 선택하고 few-shot CoT example 을 사용하기 위해 수동으로 구성 BIG-bench task 두 개의 경우 훈련셋이 없어, 10개 예제를 few-shot CoT example 로 선택 SayCan 경우 훈련셋에서 6개 example 을 사용하고 수동으로 CoT 구성","s":"Prompts","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#prompts","p":224},{"i":261,"t":"모든 task 에 대해, 모델 크기를 스케일 업하면 standard prompting 성능 향상되지만 CoT prompting 은 더 큰 향상을 이끌어 냄 (특히 PaLM 540B) 위 결과로 CoT prompting 이 상식적 추론 능력의 다양한 범위를 필요로 하는 task 에 대해서도 성능 향상을 시킬 수 있음을 시사","s":"Results","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#results","p":224},{"i":263,"t":"CoT prompting 이 challenging symbolic reasoning 을 수행할 뿐만 아니라, 미리 본 적 없는 입력에 대한 추론에도 일반화하는데 용이한 다는 것을 보여줌","s":"5. Symbolic Reasoning","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":265,"t":"다음 두 toy task 를 사용","s":"Tasks","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#tasks","p":224},{"i":267,"t":"모델에게 이름에서 단어의 마지막 글자를 연결하도록 요청하는 task. (e.g. \"Amy Brown\" → \"yn\") 첫 글자 연결보다 어려운 버전 인구 조사 데이터 (https://namecensus.com/) 에서 상위 1000개 이름을 임의로 연결하여 전체 이름 생성","s":"Last letter concatenation","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#last-letter-concatenation","p":224},{"i":269,"t":"모델에게 동전을 던지거나 던지지 않은 후에도 동전이 여전히 앞면인지 아닌지 대답 요청. (e.g. \"동전이 앞면입니다. Phoebe 가 동전을 던졌습니다. Osvaldo 가 동전을 동전을 던지지 않았습니다. 동전은 여전히 앞면입니까?\" → \"아니오\") last letter concatenation 의 경우, 모델이 2개 단어로된 이름만 보고, 3개 및 4개 단어의 이름에 대해 수행한다. 이는 Coin flip 에서도 동일한 방식을 적용한다. (Fig 3 참고) Fig 8 결과, PaLM 540B 의 CoT prompting 은 거의 100% 해결. 적은 수의 CoT exemplar 로 완벽한 solution structure 가 제공되어 \"toy task\" 라 부름 Out-of-Domain (OOD) 에서는 standard prompting 이 두 task 모두에서 실패. 하지만 CoT 는 상승하는 curves 를 보이며, 충분한 규모의 LM 에서의 CoT prompting 은 일반화에 용이함을 시사","s":"Coin flip","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"#coin-flip","p":224},{"i":271,"t":"저자는 multi-step 을 유도하는 간단한 메커니즘인 CoT prompting 을 탐구 arithmetic reasoning 에서 큰 폭의 성능 향상 다양한 annotators, exemplar, LM 에 robust 한 개선 commonsense 실험에서, CoT reasoning 의 특성이 일반적으로 적용되는 것 강조 symbolic 실험에서, OOD 일반화를 긴 시퀀스로 용이하게 하는 것 보여줌 model scaling 결과 standard prompting 은 flat scaling curves 를 갖는 reasoning task 에서, CoT prompting 은 upward scaling curves CoT prompting 은 LLM 이 잘 수행할 수 있는 task 범위를 확장 여전히 많은 의문점이 존재 CoT 는 실제로 \"reasoning\" 을 하는지? few-shot exemplar 에 CoT 수동 추가의 비용은 미미하지만, finetuning 의 비용은 매우 클 수 있음 올바른 reasoning path 를 보장할 수 없어, 올바른 답변/부정확한 답변 모두 발생 가능 LLM 에서만 CoT reasoning 이 발생하여, 실제 응용에서는 비용이 클 수 있음 → 작은 모델에서도 CoT 를 유도하는 연구 필요","s":"6. Discussion","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":273,"t":"이 연구는 가장 관련성 높은 두 가지 방향의 논문에서 영감을 받음 reasoning 해결을 위해 intermediate step 을 사용 [Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems] 최종 출력보다 step-by-step 으로 예측하는 것이 성능이 우수 prompting [The power of scale for parameter-efficient prompt tuning] 을 자동으로 학습하거나 지침을 제공하여 prompting 입력을 개선/보완 반면, 저자는 언어 모델의 출력을 CoT 로 보강하는 상반된 방향","s":"7. Related Work","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":275,"t":"CoT prompting 은 LM 에서 reasoning 향상을 간단하고 일반적으로 적용 가능한 방법에 탐구 arithmaric, commonsense 및 symbolic 등으로 CoT reasoning 이 모델 규모에 결과를 보여주며, CoT reasoning 은 충분히 큰 LM 이 reasoning task (다른 이들은 flat scaling curves 를 가짐) 에서 잘 수행하도록 하는 새로운 model scaling 속성을 가지는 것을 발견","s":"8. Conclusions","u":"/docs/Paper/NLP/Multi-Task/Chain-of-Thought","h":"","p":224},{"i":277,"t":"논문 및 이미지 출처 : http://boyangli.org/paper/Jiaxian-CVPR-2023-Img2LLM.pdf","s":"From Images to Textual Prompts: Zero-shot Visual Question Answering with Frozen Large Language Models","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":279,"t":"Large Language Modes (LLMs) 는 새로운 task 에 대한 zero-shot 일반화가 우수하지만 visual question-answering (VQA) zero-shot 에 활용하는데는 어려운 과제가 있다. LLM 과 VQA 간의 modality disconnect 와 task disconnect 때문이며, multimodal data 를 End-to-End 학습을 하여 해소할 수 있지만, 유연함이 없고 계산 비용이 크다. 이를 해결하기 위해 저자는 Img2LLM 를 제안한다. LLM 이 end-to-end 학습 없이 zero-shot VQA task 를 수행할 수 있도록 plug-and-play module 로 LLM prompt 를 제공한다. LLM-agnostic model 을 개발하여 이미지 내용을 exemplar question-answering 쌍으로 설명, 이는 효과적인 LLM prompt 로 입증된다. Img2LLM 은 다음 benefit 을 제공한다. end-to-end training 에 의존한 방법보다 경쟁력있고 성능이 나음. 예로, VQAv2 에서 Flamingo 보다 5.6% 성능이 좋고, A-OKVQA 에서 few-shot 방법으로 최대 20% 까지 성능이 좋다. VQA 수행을 위해 LLM 을 넓은 범위로 유연하게 interface 로 연결 end-to-end finetuning 으로 LLMs 를 specialize 할 필요성을 제거하고 고도의 specialized LLMs 를 사용자에게 제공하여, 비용을 줄인다. 코드는 https://github.com/salesforce/LAVIS/tree/main/projects/img2llm-vqa 에서 확인 가능하다.","s":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":281,"t":"VQA 는 실세계 응용에 중요한 vision-language task 이다. 다양한 VQA 데이터셋이 제안됐으며, 몇몇은 이미지 인식이나 논리적 추론에 초점을 맞추었지만, 인간의 주석을 얻는 것은 비용적으로 비싸고 인간의 편향이 개입할 수도 있다. 이는 VQA 시스템이 새로운 답변 스타일과 질문 유형을 취약하게 만든다. 위 사항들로 인해 연구자들은 ground-truth question-answering annotation 을 필요로 하지 않는 zero-shot VQA 방법을 사용하여, 더 잘 일반화가 가능한 VQA 시스템을 구축하는 추세이다. 최근, LLMs 가 zero in-domain task 를 수행하고 논리적 추론 및 NLP task 의 commonsence knowledge 를 적용하는데 우수한 능력을 입증한다. 그 결과, 최근 approach 는 zero-shot VQA 에서 LLMs 활용한다. 하지만, VQA task 에 LLMs 를 적용하는 건 쉽지 않은데, vision 과 language 사이의 modality disconnect language modeling 과 question answering 사이의 task disconnect 때문이다. 일반으로 vision 과 language representation space 간의 align 을 위해 LLM 과 vision encoder 를 공통적으로 finetuning 하는데, 이는 계산 및 데이터 비용이 크다. 예로, Flamingo 는 수천 개의 TPU 로 수십억 개의 image-text 쌍을 finetuning 하는데 다가, finetuning 에 specialize 되며 vision encoder 와 LLM 사이에 상호의존성이 커진다. 또한 LLM 을 새 버전으로 업그레이드 한다면, 전체 모델을 비용이 큰 재학습을 수행해야 한다. LLM 을 VQA 와 통합하는 end-to-end 대신, 본 논문에선 frozen off-the-shelf LLM 으로 구축한 modular VQA 를 제안한다. 이는 두 가지 이점이 있다. 배치 비용을 줄이고 간단함 LLM 업그레이드가 간단 하지만 end-to-end training 없으면 modality disconnect 와 task disconnect 해결이 힘들다. PICa 는 image 를 caption 으로 변환하여 훈련 데이터에서 예시 QA 쌍을 LLM 에게 prompt 로 제공한다. 하지만 주석된 훈련 데이터가 존재한다는 가정을 전제로 하여, 성능이 few-shot 선택에 민감하다. 이에 저자는 Img2LLM 을 제안한다. 이는 off-the-shelf LLMs 가 zero-shot VQA 을 수행할 수 있도록 하는 plug-and-play module 이다(규격품을 연결만하면 쉽게 사용할 수 있는 모듈). Img2LLM 의 핵심은 vision-language model (예; BLIP) 과 question-generation model 을 활용하여 이미지 내용을 QA 쌍으로 변환하는 것이다. 이러한 예시 QA 쌍은 이미지 내용을 언어로 설명하여 modality connect 를, LLM 에게 QA task 시연하여 task disconnect 를 해결한다. 특히, 예시 QA 쌍은 test image 와 question 을 기반으로 구성되며, PICa 에서 필요한 similar few-shot 예제가 practical zero-shot 시나리오에서 항상 사용 가능하지 않으므로 사전에 제거한다. 오픈 소스인 OPT language model 을 적용했을 때, Img2LLM 은 비용이큰 end-to-end training 을 수행하는 방법들과 비교 가능하거나 우수한 zero-shot VQA 성능을 달성한다. 본 논문의 contribution 은 다음과 같다. 저자는 current image 와 질문을 기반으로 image 를 합성된 QA 쌍으로 변환하는 plug-and-play 모듈인 Img2LLM 을 제안. 이는 visual 과 language 간의 modality disconnect 와 language modeling 과 VQA 간의 task disconnect 를 연결해준다. Img2LLM 은 비용이 큰 end-to-end training 이나 특화된 QA 네트워크 없이 off-the-shelf LLM 이 zero-shot VQA 를 수행할 수 있게 한다. 그래서 낮은 비용과 유연한 모델 배치 및 간편한 LLM 업그레이드가 가능하다. 실험 결과, Img2LLM 이 적용된 OTP 모델이 end-to-end 로 학습된 모델과 비교 가능하거나 우수한 zero-shot VQA 성능을 달성한다. 예로, VQAv2 에서 Flamingo 보다 5.6% 우수하고, 많은 few-shot VQA 방법보다 우수하다.","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":284,"t":"VQA 는 이미지에 따라 자연어 question 에 대답하는 모델을 요구하는 multimodal 평가 벤치마크로 활발한 연구 초점이 되었다. 대규모 image-text pretraining 후 VQA 데이터셋의 finetuning 과 함께 지난 몇년간 빠른 성능 향상이 이루어졌다. knowledge 기반 VQA 해결을 위해 최근 연구는 ConceptNet 이나 Wikipedia 같은 외부 지식을 포함하지만, 이러한 방법들은 복잡한 추론을 필요로 하는 question 에 대한 answer 이 여전히 어려움을 나타낸다.","s":"2.1 Recent Advances in VQA Method","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#21-recent-advances-in-vqa-method","p":276},{"i":286,"t":"LLMs 를 웹 규모의 말뭉치로 학습되어 자연어 이해와 추론에 강하다. task data 추론을 위해, LLMs 는 보통 autoregressively 하게 target token 을 생성한다. 구체적으론 prompt CCC 및 task input xxx 이 주어지면, LLM 은 target token 인 Y={yi}i=1nY = \\{ y_i \\}^n_{i = 1}Y={yi​}i=1n​ 을 생성한다. 여기서 yi=arg⁡max⁡pθ(yi∣y<i,C,x)y_i = \\arg \\max p_{\\theta}(y_i | y_{<i},C,x)yi​=argmaxpθ​(yi​∣y<i​,C,x) 이며 θ\\thetaθ 는 모델 파라미터다. LLM 을 이용한 이전 VQA 방법은 주로 두 가지 범주인 multi-modal pretraining 과 language-mediated VQA 로 나뉜다.","s":"2.2 LLM for Zero/Few-Shot VQA Tasks","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#22-llm-for-zerofew-shot-vqa-tasks","p":276},{"i":288,"t":"이 접근법은 Figure 1(a) 에서 보여주며, 추가적인 alignment module 을 훈련하여 visual 과 language embedding 을 align 한다. LLMs 가 효율적으로 finetuning 하기엔 큰 것을 고려할 때, [Multimodal Few-Shot Learning with Frozen Language Models] 논문에서는 visual encoder 만을 finetuning 하는 것을 택하고, Flamingo 는 cross-modality 상호작용을 모델링하기 위해 추가적인 cross-attention layer 를 훈련한다. 그러나 이 패러다임엔 두 가지 단점이 있다. 계산 비효율적. visual backbone 과 LLM 을 동시에 정렬하기엔 계산 자원이 많이 필요하다. 치명적인 forgetting. align 단계가 LLMs 와 visual model 이 함께 훈련되면, LLMs 의 추론 능력에 해가 될 수 있다.","s":"Multi-modal pretraining","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#multi-modal-pretraining","p":276},{"i":290,"t":"이 패러다임은 벡터화된 representation 대신, intermediate representation 으로 자연어를 사용하며, 비싼 pretraining 을 필요로 하지 않는다. Figure 1(b) 처럼, 현재 이미지를 언어 설명으로 변환한 다음, 설명을 frozen LLM 에 입력한다. few-shot 설정에서 PICa 는 image caption 을 생성하고, in-context exemplar 로 훈련 데이터 샘플을 선택하지만, exemplar 가 제외되면 성능이 크게 저하된다. 동시에 진행되는 zero-shot 방식으로 question 과 관련된 caption 을 생성한다. zero-shot 요구사항 때문에 in-context exemplar 를 제공할 수 없으며, in-context 학습의 이점을 누릴 수 없다. 결과적으로 이 접근법은 고성능 달성을 위해 QA 전용 LLM 인 UnifiedQAv2 에 의존한다.","s":"Language-mediated VQA","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#language-mediated-vqa","p":276},{"i":292,"t":"LLM 을 zero-shot VQA 에 효과적으로 활용하는데 주요 두 장애물이 있다. modality disconnection : LLMs 은 이미지를 처리하지 않으며 visual 정보를 LLMs 이 처리할 수 있도록 인코딩하는 것도 어렵다. task disconnection : LLMs 는 언어 모델링 task 에서 생성적 또는 노이즈 제거 목적으로 pretraining 한다. LLMs 은 QA 이나 VQA task 의 특성을 알지 못하여 answer 를 생성할 때 contextual 정보르 활용하지 못하는 경우가 있다. VQA 에서 modality disconnect 는 이미지를 dense vector 대신 intermediate language description 으로 변환한다. task disconnect 는 few-shot in-context exemplar 나 QA 에 직접 finetuning 된 LLM 을 사용하여 해결해야한다. 이는 zero-shot 설정에 일반적인 LLM 에서 task disconnection 을 어떻게 다룰지 분명하지 않다. 이에 저자는 새로운 zero-shot 기술인, 일반적인 LLM 의 task disconnect 를 해결하기 위해 Img2LLM 을 제안한다. 이는 image 관련 exemplar prompt 를 생성한다. question QQQ 와 image 가 주어지면, 핵심은 current image 의 in-context exemplar 로써 합성된 QA 쌍을 생성할 수 있다. 이러한 exemplar 는 QA task 를 보여줄 뿐만 아니라 이미지 내용을 LLM 에 전달하여 question QQQ 에 대한 answering 생성하는 데도 기여한다. Img2LLM 은 LLM-agnostic 이며, off-the-shelf LLMs 의 지식과 추론 능력을 활용해 zero-shot VQA 에 강력하면서 유연한 솔루션을 제공한다.","s":"3. Method","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":294,"t":"VQA image 에서 in-context learning 을 위해, 이미지 내용을 exemplar 로 통합하기 위해서, 저자는 먼저 합성된 question 에 대한 answering 으로 사용될 수 있는 단어를 찾는다. question 관련 caption 생성 모듈을 사용해 여러 개의 caption 을 생성한다. 최근 논문을 따라, 명사구(고유명사 포함), 동사구, 형용사구, 숫자, '예' 와 '아니오' 같은 부울 타입의 단어를 answer 후보로 추출한다.","s":"3.1 Answer Extraction","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#31-answer-extraction","p":276},{"i":296,"t":"추출된 answer 후보 집합 {a^}j=1U\\{ \\hat{a} \\}^U_{j=1}{a^}j=1U​ 로, 각 answer 후고군에 대한 특정 question 을 생성하기 위해 question generation network 를 직접 사용할 수 있다. 본 논문에서는 template 과 neural 기반의 question-generation 방법에서 실험한다. zero-shot 요구사항을 위반하는 것을 피하기 위해, VQA 데이터에 접근이 없는 순전히 textual 기반으로 한다.","s":"3.2 Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#32-question-generation","p":276},{"i":298,"t":"off-the-shelf parser 를 사용해, 각 answer 의 품사를 얻고, 각 POS 타입의 특정 question 템플릿을 설계한다. 예로, noun answer : \"What object is being taken in this image?\" verb answer : \"What action is being taken in this image?\"","s":"Template-based Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#template-based-question-generation","p":276},{"i":300,"t":"[All You May Need for VQA are Image Captions] 논문에 영감을 받아, textual QA 데이터셋에서 neural question 생성 모델을 훈련시킨다. answer 로 question 을 생성하도록 pretrained T5-large 모델을 finetuning 한다. 모델의 input 은 \"Answer: [answer]\\textup{[answer]}[answer]. Context: [context]\\textup{[context]}[context]\" 을 포함한다. 여기서 textual QA 데이터셋으로부터, [answer]\\textup{[answer]}[answer] 은 answer text 을, [context]\\textup{[context]}[context] 은 context text 를 나타낸다. 추론 중에는, [answer]\\textup{[answer]}[answer] 을 추출된 answer 후보로, [context]\\textup{[context]}[context] 는 해당 추출된 answer 로부터 생성된 caption 으로 교체된다. 모델은 5 가지 textual QA 데이터셋으로 finetuning 한다. SQuAD2.0 MultiRC BookQA CommonsenseQA SocialIQA 위 question 생성 방법으로, 합성된 question-answer 쌍 {q^j,a^j}j=1U\\{ \\hat{q}_j, \\hat{a}_j \\}^U_{j=1}{q^​j​,a^j​}j=1U​ 을 얻는다. 이 쌍을 LLM in-context learning 의 exemplar 로 사용하며, 주어진 이미지 내용으로 QA task 를 수행하도록 가이드하고 language modeling 과 VQA 간의 task disconnect 를 연결해준다. 위 테이블로 exemplar QA 쌍의 효과를 보여준다. 저자는 exemplar QA prompt 가 caption prompt 보다 더 우수함을 관찰했다. 이는 exemplar QA 가 LLM pretraining 과 VQA task 간의 task disconnection 을 연결한다는 효과를 입증한다. 또한, exemplar prompt 가 이미지의 많은 내용을 설명하고 있어, modality disconnection 도 연결하는데 도움이 되며, 이에 caption 을 추가하는 것은 크게 새로운 정보를 제공하지 않으며 성능 향상이 제한적이다.","s":"Neural Question Generation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#neural-question-generation","p":276},{"i":302,"t":"합성된 exemplar QA 쌍와 추가적으로, question-relevant image captions 를 LLM 에 제공한다. 저자는 question 이 이미지의 특정 객체나 지역을 묻지만 기존 네트워크로 생성된 일반적인 caption 은 관련 정보를 포함하지 않을 수 있는 것을 관찰했다. 위 Figure 2 에서 , question \"What items are spinning in the blackground which can be used to control electricity?\" 는 wind turbine 에만 관련있다. 그러나 전체 이미지에서 생성된 caption 은 salient orange boat 에 초점을 맞출 가능성이 높으며, LLM 은 question 에 대한 answer 정보가 없게 된다. 이 문제를 해결하기 위해 question 관련 이미지 부분에 대한 caption 을 생성하고, LLM 에게 이 prompt 에 포함시킨다. 이를 위해 저자는 BLIP 의 Image grounded Text Encoder (ITE) 를 사용하여 question 관련된 이미지 영역을 결정한다. ITE 는 image vvv 와 textual question qqq 쌍에 대한 유사도 점수 sim(v,q)\\textup{sim}(v, q)sim(v,q) 을 할당한다. ITE 와 함께 GradCAM 이라는 feature-attribution 해석 기술을 사용하여 주어진 question 과 맞는 image 영역을 강조하는 coarse localisation map 을 생성한다. 간단히 말해, GradCAM 은 Transformer 의 croiss-attention score를 ITE 유사도 함수인 sim(v,q)\\textup{sim}(v, q)sim(v,q) 에 대한 gradient 와 결합하여 계산한다. patch 관령성 rrr 을 얻은 후, 이와 비례하는 확률로 이미지 패치의 하위 집합을 샘플링한다. 그 후, top-k 샘플링으로 샘플링된 image patches 로 caption 을 생성한다. 의미있는 caption 을 생성하기 위해, 짧은 prompt \"a picture of\" 는 text encoder 에 입력한다. MMM 개의 다양한 caption 을 생성하기 위해 이를 MMM 번 반복한다. 그리고 다른 caption 의 정확한 문자열이 아닌 caption 만 유지한다. 하지만, top-k 샘플링은 비결정적인 특성이 있어서, caption model 은 성능에 부정적인 영향을 미치는 노이즈 캡션을 생성할 수도 있다. 노이즈 캡션을 제거하기 위해, ITE 를 사용하여 생성된 캡션과 샘플링된 question 관련 이미지 패치 간의 유사도 점수를 계산한다. 그리고 매칭 점수 0.5 이하인 캡션들을 필터링한다. 위 과정으로, question 과 관련된, 다양한 및 깨끗한 합성 캡션을 얻을 수 있으며, visual 과 language 정보를 연결 역할을 제공한다.","s":"3.3 Question-relevant Caption Prompt","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#33-question-relevant-caption-prompt","p":276},{"i":304,"t":"합성 question 관련 캡션과 question-answer 쌍으로, 저자는 instruction, caption 및 QA exemplar 를 연결하여 LLM 에 완전한 prompt 를 구성한다. Instruction text : \"Please reason the answer of question according to the contexts\" caption prompt : \"Contexts: [all captions]\\textup{[all captions]}[all captions]\" 같은 형태 QA exemplar : \"Question: [question]\\textup{[question]}[question] Answer: [answer]\\textup{[answer]}[answer]\" 같은 형태 current question 은 prompt 마지막 부분에 위치 시킴 : \"Question: [question]\\textup{[question]}[question]. Answer: \". answer 을 얻기 위해, LLM 에서 greedy decoding 을 수행하고, Flamingo 와 같이 무의미한 token 을 제거한다. 또한 LLM input 에는 최대 길이 제한이 있다 (예; OPT, GPT3 에선 2048). 따라서 prompt 구성을 위해 question 관련 캡션과 question-answer 쌍의 subset 선택이 필수적이다. 정보가 풍부한 prompt 선택을 위해, 저자는 100 개의 생성된 캡션에서 합성된 answer 후보의 빈도를 계산한다. 또한, 빈도가 가장 높은 30 개의 answer 후보를 선택하고 각각에 대해 한 개의 question 을 생성한다. 그리고, 빈도가 가장 낮은 30 개의 answer 와 각각을 포함하는 캡션 하나를 포함시킨다.","s":"3.4 Prompt Design","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#34-prompt-design","p":276},{"i":306,"t":"다른 zero-shot 및 few-shot VQA 방법들과 비교한다. 그 후에, prompt patterns 및 caption selection 전략과 같은 설계 선택에 있어 ablation 연구를 수행한다.","s":"4. Experiment","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":309,"t":"VQAv2 : 214,354 question, 107,394 test-dev OK-VQA : 5,046 test question A-OKVQA : 1,100 validation question, 6,700 test question 위 데이터셋에서 approach 를 평가한다.","s":"Datasets","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#datasets","p":276},{"i":311,"t":"question 관련 caption prompt 를 얻기 위해, BLIP 을 사용하여 caption 을생성하고 image-question 매칭을 수행한다. question 관련 이미지 영역의 지역화를 위해, BLIP image-grounded text encoder 의 cross-attention layer 로부터 GradCAM 을 생성한다. 그런 다음, GradCAM 을 기반으로 K′=20K' = 20K′=20 이미지 패치를 샘플링하고, 이를 이용해 100 개의 question 관련 caption 을 얻는다. LLMs 의 경우, 여러 다른 크기의 오픈 소스 OPT 모델을 주로 사용한다. ablation study 는 다양한 다른 LLMs 를 실험하여 저자의 방법의 일반화 능력을 보여준다. 저자는 LLMs 를 사용하여 auto-regressively 한 answer 를 생성사며, answer list 나 훈련 샘플에 액세스 하지 않으므로 zero-shot VQA 를 용이하게 한다.","s":"Implementation details","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#implementation-details","p":276},{"i":313,"t":"이전 VQA 와 비교하며 세 가지 카테고리로 나뉜다. PICa 와 같은 frozem LLM 을 사용한 Zero-shot method Flamingo, Frozen, VL-T5, Few VLM 및 VLKD 와 같은 multi modal pretraining 을 수행하는 Zero-shot mothod few-shot method 결과도 포함하며, PICa, FewVLM 및 ClipCap 결과가 포함된다. 위 방법들은 대규모의 vision-language 데이터셋이 필요하고 업데이트 비용이 많이 든다. 이 카테고리엔 VQ2^22A 나 WeaQA 도 결과로 포함하지만, 실제론 answer 후보에 접근할 수 없어 주의가 필요하다. 그러므로 이 결과에 대해선 주의하여 해석해야 한다.","s":"Competing methods","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#competing-methods","p":276},{"i":316,"t":"Img2LLM 은 zero-shot with frozen LLMs 인 PICa 보다 크게 능가 (OK-VQA 에서 45.6 대 17.7) 또한 PICa 는 frozen LLM 을 사용하지만 prompt 구성을 위해 훈련 샘플이 필요하지만 저자의 방법은 VQA 샘플에 접근하지 않고도 question-answer 을 생성하므로 zero-shot 요구사항도 충족","s":"SOTA results on zero-shot evaluation with plug-in frozen LLMs","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#sota-results-on-zero-shot-evaluation-with-plug-in-frozen-llms","p":276},{"i":318,"t":"LLMs parameter 를 6.7B 에서 175B 로 키웠을 때, VQA 에서 3-10 point 의 향상을 관찰했다. 이는 강력한 언어 모델이 qustion 을 더 잘 이해하고, 더 정확한 answer 을 주는데 도움이 된다는 것이다. 이 경향은 OK-VQA 및 A-OKVQA 에 명확하고 일관성 있으며, 이러한 데이터셋의 question 은 LLM 이 제공하는 상식적 추론과 외부 지식을 요구하기 때문이다. 이는 LLM 이 VQA 에 유익하다는 것을 뒷받침한다. 다른 흥미로운 점은 LLMs 스케일링이 크기가 클 때 명백하다는 것이다. 30B 이상에선 효과가 있지만, 작은 모델 (6.7B, 13B)에선 예측이 힘들었다.","s":"Scaling effect of LLMs and their emergent capabilities on VQA","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#scaling-effect-of-llms-and-their-emergent-capabilities-on-vqa","p":276},{"i":320,"t":"Img2LLM 은 대부분의 end-to-end training 모델과 몇몇 few-shot 설정에서 평가된 모델보다 우수하다. VQAv2 에서 저자의 방법은 500K TPU hour 과 십억 개 규모 데이터셋을 사용한 Flamingo80B_{80B}80B​ 보다 5.6 point 이상 앞섰다. A-OKVQA 에선 Img2LLM 이 최고의 결과이며 ClipClap 을 두 배 앞선다. Img2LLM 은 대부분의 supervised model 보다 성능이 좋은데, 이는 zero 훈련 데이터를 사용하고 zero-shot setup 에서 평가되었는데도 불구하고 효과적임을 입증한다.","s":"Competitive performance with end-to-end pretraining and few-shot methods","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#competitive-performance-with-end-to-end-pretraining-and-few-shot-methods","p":276},{"i":322,"t":"Img2LLM 을 OPT 와 다른 오픈 소스 LLM (GPT-J, GPT-Neo 및 BLOOM) 에서 성능 평가를 진행한다. 실험 결과 Img2LLM 은 zero-shot VQA task 수행에 있어 다양한 LLMs 가 가능하며, zero-shot PICa 및 Fozen 성능 만큼 도달했다. 이는 저자의 방법의 일반화 성능이 강하다는 것을 보여준다.","s":"4.3 Experimental Results of Different LLMs","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"#43-experimental-results-of-different-llms","p":276},{"i":324,"t":"image caption 및 question-answer 생성에 추가 비용 발생 8XA100 기기에서 175B OPT 의 추론 시간에 비해 약 24.4% 의 추가 계산 요구 prompt 를 줄여 오버헤드를 줄일 수 있으며, 이는 정확성을 희생하고 속도를 얻겠다는 것이다. 특히, 저자의 방법은 Flamingo 의 경우인 500K TPU 시간 이상 소요되는 비싼 end-to-end multimodal representation 정렬을 피하는 것이다.","s":"5. Limitation","u":"/docs/Paper/Computer Vision/Vision-Language/Img2LLM","h":"","p":276},{"i":326,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2305.07922v2.pdf","s":"CodeT5+: Open Code Large Language Models for Code Understanding and Generation","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":325},{"i":328,"t":"현재 code LLMs 는 두 가지 주요 한계점 존재 specific architecture (encoder-only, decoder-only) 또는 encoder-decoder network 에 의존 전자는 응용하는데 있어 inflexibility 후자는 모든 task 에 대한 single system 을 다루어 subset 에 대해 suboptimal 성능을 보임 관련없는 downstream task 로 pretraining limited set 을 사용 이를 해결하기 위해, component modules 를 유연하게 결합하여 넓은 범위의 downstream code task 에 적합한 encoder-decoder LLMs 의 CodeT5+ 를 제안 이러한 유연성은 pretrain-finetune 불일치성을 완화하기 위해 pretraining objectives 의 mixture을 제안 이 objectives 는 단일 또는 이중의 code 말뭉치에서 span denoising, contrasive learning, text-code matching 및 causal LM pretraining tasks 수행 가능 또한 모델을 효율적으로 scale up 하기 위해 CodeT5+ 를 처음부터 훈련하지 않고 frozen off-the-shelf LLMs 으로 초기화하는 방법 그리고 instruction-tuning 을 탐구 저자는 CodeT5+ 를 20개의 code-related benchmarks 에 광범위하게 평가를 했으며, zero-shot, finetuning, instruction-tuning 을 포함한다. code generation/completion, math programming 및 text-to-code retrieval task 같은 다양한 code-related task 에서 SOTA 를 달성","s":"Abstract","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":325},{"i":330,"t":"LLMs 는 대규모 코드 기반 데이터 (예; GitHub 공개 데이터)로 pretrain 하여 다양한 코드 관련 downstream task 로 transfer 할 수 있다. 하지만 기존의 많은 모델이 특정 downstream task 만 잘 수행되도록 설계가 되어 있다. 이는 주로 아키텍처와 pretraining task 수행 과제에 대한 두 제한으로 인한 것으로 주장한다. Architecture 기존의 code LLM 은 understanding / generation task 에만 잘 수행되는 encoder-only / decoder-only 모델을 채택한다. 특히, text-to-code retrieval 같은 understading task 용이한 encoder model, code generation 같은 generation task 에 대한 decoder model 이 강력한 성능을 보인다. 그러나 디코더 모델은 인코더 모델에 비해 검색 및 감지 작업같은 understading task 에 이상적이지 않으며, 최근 encoder-decoder architecture 를 많이 채택한다. understanding 과 generation 모두를 지원하지만, 여전히 최적의 성능을 내지 못한다. Unixcoder 는 encoder-decoder 모델이 검색 및 코드 완성 작업에서 SOTA 인 encoder 및 decoder-only 모델을 능가하지 못하는 것을 발견했다. 이 결함은 주로 모든 작업에 적응되는 단일 모듈 아키텍처의 한계다. 요약하자면, 기존 접근방식은 개별 구성 요소가 다른 downstream task 에 더 활성화될 수 있도록 설계되지 않았다. 현재 제한된 훈련셋으로 사용하여, pretrain, transfer 사이의 불일치로 인한 downstream task 의 성능 하락을 야기함. 예로 T5 기반 모델은 종종 span denoising 목적으로 훈련된다. 그러나 코드 생성 같은 downstream task 의 대부분 SOTA 모델은 프로그램 토큰을 하나씩 auto-regressively predict 하여 다음 토큰을 예측하는 목적으로 pretrain 한다. 최근 시도는 위 문제 완화를 위해 contrastive learning 을 도입하지만, text 와 code representation 사이의 alignment 를 무시한다. 저자는 CodeT5+ 의 모델 크기를 확장하기 위해 계산 효율적인 pretrain 전략을 사용하여 CodeT5+ 의 구성 요소를 초기화하는데 존재하는 code LLMs 를 활용한다. pretrained checkpoint 로 encoder, decoder 를 초기화하고 cross attention layer 로 연결하는 \"shallow encoder, deep decoder\" architecture 를 채택한다. deep decoder LLM 은 고정하며, shallow encoder 와 cross attention layer 만 훈련하여 효율적인 조정을 위해 훈련 가능한 매개 변수의 수를 크게 줄인다. 마지막으로, NLP 분야의 최근 연구인로 Instruction tuning 으로 탐구한다. 20개 이상의 code 관련 벤치마크에서 CodeT5+ 를 광범위하게 평가했다. zero-shot, finetuning 및 instruction tuning 을 포함한다. 결과는 CodeT+ 가 많은 downstream 작업에서 SOTA baseline 에 비해 상당한 성능 향상을 보여준다.","s":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":325},{"i":333,"t":"code understanding 및 generation task 를 위한 새로운 open code LLMs 인 CodeT5+ 를 개발. encoder-decoder 를 기반으로한 CodeT5+ 는 unimodal 및 bimodal 데이터에 대한 다양한 pretrain objectives 를 통해 다양한 모드에서 작동 가능한 유연성을 갖추고 있다. unimodal pretraining 첫 단계로, 계산 효율적인 목적으로 대규모 코드 데이터로 pretrain bimodal pretraining 두 번째 단계로, cross-modal 학습 목적으로 code-text data 의 smaller set으로 모델을 계속 pretrain 각 단계에서 여러 pretrain objective 를 동일한 가중치로 공통 최적화 위 접근 방식이 모델이 다양한 데이터에 노출되어 풍부한 context representation 을 학습하는 데 효율적이란 것을 발견","s":"3. CodeT5+: Open Code Large Language Models","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"","p":325},{"i":335,"t":"먼저, CodeT+ 를 대규모 코드 unimodal data 로 사전학습. GitHub 의 오픈 소스로, 코드 및 주석이 포함되어 있음. 두 번째로, code-text 쌍의 데이터로, Span Denoising 및 CLM task 를 사전학습한다. 이 작업은 모델이 다양한 범위의 code context 를 복구하는 방법을 학습할 수 있도록 한다.","s":"3.1. Unimodal Pretraining on Code Data","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#31-unimodal-pretraining-on-code-data","p":325},{"i":337,"t":"encoder input 에 15% 토큰을 무작위 mask 로 대체하고, decoder 가 복구하도록 한다.","s":"Span Denoising","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#span-denoising","p":325},{"i":339,"t":"두 가지 변형으로 auto-regressive generation 을 위해 최적화. 임의로 피벗 위치를 선택하여, 그 이전의 context 를 source sequence 로, 이 후의 시퀀스를 target output 으로 간주. 이를 seq2seq 와 언어 모델링 목적으로 표기 피벗 위치는 전체 sequence 의 10% - 90% 사이에서 균등하게 샘플링되도록 제한하고 source sequence 에 특수 토큰 [CLM] 을 추가 decoder 전용 generation task 로, 첫 번째 변형의 극단적인 경우. [CLM] 토큰을 encoder 에 입력으로 전달하고, decoder 에게 전체 코드 시퀀스를 생성하도록 요구.","s":"Causal Language Modeling (CLM)","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#causal-language-modeling-clm","p":325},{"i":341,"t":"두 번째 단계로, 저자는 text-code bimodal data 로 pretrain 하였다. 여기서 각 text-code 쌍은 code function 과 대응하는 docstring describing 을 포함한다. 이런 bimodal data 는 모델 훈련이 cross-modal understanding 과 generation 에 용이하도록 한다. bimodal tasks 는 cross-modal contrastive learning, matching 및 causal LM task 를 포함한다.","s":"3.2. Bimodal Pretraining on Text-code Data","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#32-bimodal-pretraining-on-text-code-data","p":325},{"i":343,"t":"이 tasks 는 text 및 code representations 의 feature space 를 정렬하기 위해 positive text-code paris 는 모으고 negative text-code pairs 를 분리하는 것을 목표로 한다. Guo et al. [2022] 는 code understanding task 에서 이점을 입증했다. 이 task 는 encoder 에서만 활성화하며, text 나 code snippet 을 bidirectional self-attention 을 통해 continuous representation 으로 인코딩한다. BERT 와 유사하게, 저자는 input 앞에 special token [CLS] 을 붙이고, 최종 Transformer layer 의 output embeddings 를 해당 input text 나 input code 의 representations 으로 간주한다. 또한, linear layer 를 추가하고 L2 normalization 을 사용하여 출력을 256-dimensional embeddings 로 매핑한다. negative samples 를 보강하기 위해, momentum encoder 를 사용하여 이전 mini-batches 의 임베딩을 저장한다. 구체적으로, momentum encoder 는 현재 mini-batch 의 샘플을 enqueue 하고 가장 오래된 mini-batch 는 dequeue 하여 queuing 시스템을 유지한다. 기존의 encoder 와 momentum encoder 의 linear interpolation 을 통해 momentum encoder 를 업데이트하여 training step 간의 representation 일관성을 보장한다.","s":"Text-Code Contrastive Learning","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-contrastive-learning","p":325},{"i":345,"t":"이 task 는 decoder 를 활성화시키고 text 와 code snippet 이 동일안 의미를 가지는지 예측하는 것을 목표로 함. 이는 text 와 code modalities 간의 fine-grained alignment 를 포착하는 더 나은 bimodal representations 를 학습 하는데 도움이 된다. code sample 이 주어지면 decoder 는 embedding layer 및 causal self-attention layer 를 통과시킨 후, self-attention representation 은 cross attention layer 로 전달되어 encoder 로부터 받은 text representation 와 관련한 signal 을 query 한다. task-specific [Match] token 은 code input sequence 의 맨 앞에 추가되어 decoder 에 text-code matching functionality 를 제공해주며, [EOS] token 은 code input 끝에 추가된다. decoder 는 causal self-attention mask 를 사용하며 last decoder token 만 전체 context 에 참여할 수 있어, [EOS] 의 output embedding 을 text-code cross-modal 의 alignment representation 으로 다룬다. 마지막으로, binary matching task 를 위해 decoder 의 output embedding 위에 linear layer 를 사용하여 text-code pair 가 positive (match) 인지 negative (unmatched) 인지를 예측한다. 정보가 많은 negative 를 찾기 위해, 저자는 hard negative mining 전략을 사용한다. 특히, 현재 샘플과 momentum encoder 가 유지하는 queue 내의 이전 샘플 간의 contrastive-based similarity score 에 따라 hard negative 를 샘플링한다. 이렇게 하면 harder negative 가 선택될 가능성이 높아진다. positive pairs 의 batch 의 경우, code/text query 를 사용하여 text/code queue 에서 negative 를 mining 하여 negative pairs 의 두 batch 를 구성한다.","s":"Text-Code Matching","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-matching","p":325},{"i":347,"t":"이 task 는 encoder 및 decoder 모두 활성화시키며, text-to-code 및 code-to-text 생성으로 dual multimodal conversion 을 통한 cross-modal generative 목표에 초점을 둔다. 구체적으로, text sample 이 input 일 경우, decoder 의 input sequence 에 [CDec] token 을 앞에 추가한다. 이 경우, decoder 는 code generation funtionality 로 작동한다. 반대로, input 이 code sample 인 경우엔 decoder 의 input sequence dp [TDec] token 맨 앞에 추가하여, deocder 는 text generation functionality 로 작동한다. 이런 유형의 Causal LM 은 code summarization 같은 multimodal generative downstream tasks 에서 pretrain-finetune gap 을 줄이기 위한 효과적인 learning objective 로 입증되었다.","s":"Text-Code Causal LM","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#text-code-causal-lm","p":325},{"i":349,"t":"모델을 첨부터 pretraining 하지 않고 효율적으로 확장하기 위해, 저자는 CodeT5+ 의 component (encoder, decoder)를 off-the-shelf pretrained LLM 로 초기화하는 compute-efficient pretraining 전략을 제안한다. (Fig 2. 오른쪽) 이 확장을 위해, [Li et al., 2022b] 의 영감을 받아, 기존 T5 모델과 동일한 크기의 encoder 와 decoder 대신 \"shallow encoder and deep decoder\" architecture 를 사용한다. [Li et al., 2022b] 에 따르면, T5-based model 의 decoder 는 종종 생성 작업에서 더 높은 복잡성을 처리해야 하므로, 더 많은 neural parameters 로 강화해야 한다. 분리되어 pretrain 된 encoder 와 decoder 를 연결하기 위해, 저자는 self-attention layer 이후 decoder block 에 무작위로 초기화된 cross-attention layer 를 삽입한다. efficient tuning 을 위해, cross-attention layer 는 top-LLL decoder layer (본 실험은LLL=1)에만 삽입한다. small encoder 와 cross-attention layer 만 trainable 하도록 유지하면서, 대부분의 decoder parameter 는 고정한다. 또한, training stability 향상을 위해 gating function 을 추가하거나 특정 frequency 로 multiple cross-attention layer 를 삽입하는 등의 설계도 탐구한다. 하지만, 상당한 성능 향상은 관찰되지 않았으며, 더 좋지 않은 결과로는 이런 설계 선택은 계산 비용이 너무 많이 들게 된다.","s":"3.3. Compute-efficient Pretraining with Frozen Off-the-shelf LLMs","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#33-compute-efficient-pretraining-with-frozen-off-the-shelf-llms","p":325},{"i":351,"t":"pretraining 의 두 단계 후, CodeT5+ 는 다양한 모드에 유연하게 작동하여 Seq2Seq generation task, decoder-only tasks 및 understanding-based tasks 를 포함한 다양한 task 를 지원할 수 있다.","s":"3.4. Adaptation to Downstream Understanding and Generation Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#34-adaptation-to-downstream-understanding-and-generation-tasks","p":325},{"i":353,"t":"encoder-decoder model 인 CodeT5+ 는 code generation 및 summarization 같은 Seq2Seq generation task 에 자연스럽게 적응할 수 있다. 또한, encoder 를 사용하여 code snippets 를 검색하고, 이를 code generation 을 위해 encoder 및 decoder 모두 사용하는 retrieval-agumented generation model 로 적용할 수 있다.","s":"Seq2Seq Generation Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#seq2seq-generation-tasks","p":325},{"i":355,"t":"이 설정에선, encoder input 에 항상 [CLM] 토큰을 주입하고, source sequence 를 prefix context 로 decoder 에 전달한다. encoder 와 decoder 의 cross-attention layers 의 weight 를 고정한다. 이 전략은 decoder 파트만 활성화하며 기술적으로 전체 model parameter 의 약 절반을 줄인다. 저자는 next-line code completion task 를 사용하여 CodeT5+ 의 decoder 전용 generation 능력을 평가한다.","s":"Decoder-only Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#decoder-only-tasks","p":325},{"i":357,"t":"CodeT5+ 는 understanding tasks 를 두 가지 방식으로 지원할 수 있다 encoder 를 사용하여 text/code embedding 을 얻어 이를 detection task 나 retrieval task 를 위해 binary classifier 에 전달할 수 있다. encoder 를 decoder 와 결합하여 text-to-code retrieval task 에 대한 text-code matching score 를 예측할 수 있다.","s":"Understanding Tasks","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#understanding-tasks","p":325},{"i":360,"t":"최근 출시된 GitHub Code 데이터셋을 사용하여 CodeSearchNet 의 pretraining dataset 을 확장했다. 9 개의 PLs (Python, Java, Ruby, JavaScript, GO, PHP, C, C++, C#)를 선택하였고, 허용 라이선스를 가진 코드와 50 ~ 2000 tokens 을 가진 파일들만 필터링 하였다. 또한, GitHub repository name 을 확인하여 CodeSearchNet 과 다른 downstream tasks 에서 중복되는 부분을 필터링했다. 중복 데이터는 exact match 를 기준으로 필터링되어 중복되는 부분이 있을 수 있지만, 이 중복은 모델 성능에 큰 영향을 미치지 않을 것으로 예상된다. 저자는 CodeT5 tokenizer 를 사용하여 다국어 데이터셋을 토큰화했으며, 이로 인해 5150억 개의 토큰이 생성되었다. 이는 CodeSearchNet 보다 약 50배 큰 크기이다. Table 1 에는 unimodal code 및 bimodal text-code pretrained dataset 의 통계이다. 표에서 보이듯, GitHub 코드로부터 정리된 데이터셋은 CodeSearchNet bimodal data 의 function level 보다 훨씬 큰 데이터 크기를 가지고 있어, 모델이 pretrain 의 첫 단계에서 풍부한 representation 을 학습할 수 있게 해준다. CodeT5 와 달리 저자는 CodeSearchNet 의 bimodal 데이터만을 CodeT5+ 의 두 번째 단계 pretrain 에 사용한다. 이 단계에서는 주로 text-code 관련 task 인 text-to-code retrieval 및 generation 에 모델을 적응시킨다.","s":"4.1. Pretraining Dataset","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#41-pretraining-dataset","p":325},{"i":362,"t":"저자는 CodeT5+ models 을 두 그룹으로 pretrain 한다. CodeT5+ 220M 및 770M 은 T5 의 아키텍처에 따라 처음부터 train 된다. CodeT5+ 2B, 6B, 16B 는 decoder 를 CodeGen-mono 2B, 6B, 16B model 에서 초기화하고 encoder 를 CodeGen-mono 350M 에서 초기화한다. scaing 전략을 주목하자, 원래의 CodeGen 모델과 비교하여 후자의 CodeT5+ 모델 그룹은 무시할 만한 학습 가능한 매개변수를 도입합니다(2B, 6B, 16B 모델에 대해 350M 인코더와 36M, 67M, 151M의 크로스 어텐션 레이어 하나). 이 두 그룹의 모델에는 각각 CodeT5 토크나이저와 CodeGen 토크나이저를 사용합니다. 사전학습에서는 16개의 A100-40G GPU가 장착된 Google Cloud Platform의 클러스터에서 CodeT5+를 대규모의 단모달 데이터셋과 이후 작은 이중모달 데이터셋에 대해 단계적인 전략으로 사전학습합니다. 첫 번째 단계에서는 10,000번의 학습 단계 동안 모델을 스팬 노이즈 제거 작업으로 예열한 후, 두 개의 CLM 작업과 같은 가중치로 합동 훈련을 100,000번의 단계 동안 진행합니다. 스팬 노이즈 제거 작업에 대해 선형 감쇠 학습률(LR) 스케줄러를 사용하며, 최대 학습률은 2e-4이고 배치 크기는 노이즈 제거에는 2048, CLM에는 512로 설정합니다. 입력 및 출력 데이터를 준비하기 위해 스팬 노이즈 제거 작업의 최대 길이를 512로 설정하고, 코드 완성 CLM의 소스 및 타겟 시퀀스의 최대 길이를 각각 768과 600으로, 디코더만을 사용한 생성 CLM의 최대 길이를 1과 1024로 설정합니다. 두 번째 단계에서는 대조 학습, 매칭 및 두 개의 CLM 손실을 동일한 가중치로 10 에폭 동안 합동으로 최적화합니다. 배치 크기는 256이고 최대 시퀀스 길이는 코드와 텍스트 시퀀스 각각 420과 128로 설정합니다. 모든 실험에서는 0.1 가중치 감쇠를 가진 AdamW 옵티마이저 [Loshchilov and Hutter, 2019]를 사용합니다. 또한 DeepSpeed의 ZeRO Stage 2 [Rasley et al., 2020]와 FP16의 혼합 정밀도 훈련을 사용하여 훈련 가속화를 수행합니다. CodeT5+ 2B, 6B 및 16B의 훈련에는 FP16로 고정된 디코더 가중치를 사용하고 다른 학습 가능한 가중치는 FP32로 유지합니다. CodeT5+ 6B 및 16B 모델에 대해서는 DeepSpeed ZeRO Stage 3의 매개변수 분할을 사용합니다.","s":"4.2. Pretraining Setup","u":"/docs/Paper/NLP/Multi-Task/CodeT5+","h":"#42-pretraining-setup","p":325},{"i":364,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2210.11416.pdf","s":"Scaling Instruction-Finetuned Language Models","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":366,"t":"instruction 으로 finetuning 한 모델은 모델 성능이나 unseen task 에 대한 생성 능력을 향상 시킨다. 저자는 다음 instruction finetuning 을 탐구 scailing the number of tasks scailing the model size finetuning on chain-of-thought data 저자는 다양한 모델(PaLM, T5, U-PaLM), prompt setups(zero/few-shot, CoT), evaluation benchmarks 에 대해, 극정인 성능 향상을 보이는 것을 발견","s":"Abstract","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":368,"t":"저자는 instruction finetuning 의 두 가지를 접근 instruction finetuning 의 scaling 영향 task 수와 model size 가 함께 잘 확장 되는 것 발견 instruction finetuning 의 추론 작업 수행 능력 CoT (chain-of-thought) 를 포함하지 않은 instruction finetuning 은 CoT 평가에 저하를 일으킴 9개의 CoT dataset 을 추가하니 모든 평가에 대해 더 나은 성능을 보임 540B 의 Flan-PaLM 을 훈련(1.8K Tasks, CoT data)한 결과 Massive Multi-task Language Understanding (MMLU) 에 대해 75.2% 달성 PaLM 과 비교하여 TyDiQA 에 one-shot 으로 14.9% 향상 instruction finetuning Flan-T5 모델은 zero-shot, few-shot 및 CoT 능력이 T5 보다 뛰어남 Flan-T5 11B 는 T5 11B 보다 십의 자리 더 뛰어나며 BIG-Bench task 에서 PaLM 62B 보다 뛰어남 전체적으로 instruction tuning 는 model, prompting, evaluation 전역에서 성능이 향상","s":"1. Introduction","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":370,"t":"Fig 2 와 같은 데이터 소스를 모아 Fig 3 과 같은 여러 instruction template 으로 instruction finetuning 이 프로세스는 Flan 이며 이러한 과정으로 finetuning 된 모델 앞에 \"Flan\" 을 붙인다. (e.g. Flan-T5)","s":"2. Flan Finetuning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":373,"t":"[Finetuned Language Models Are Zero-Shot Learners] 은 instruction 과 함께 finetuning 의 task 수를 늘려 unseen task 에 대한 일반화를 향상 시켰다. 본 논문에선, 이전 연구의 Muffin (80 tasks), T0-SF (193 tasks), NIV2 (1554 tasks) 및 CoT 를 결합하여 1,836 task 로 확장","s":"Task mixtures.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#task-mixtures","p":363},{"i":375,"t":"CoT annotation 을 포함하여, CoT 에 대한 finetuning 이 unseen task 에 대한 추론 성능 향상시키는지 조사 9 가지 데이터셋의 혼합을 만들며, 이에 arithmetic reasoning, multi-hop reasoning, natural language inference 등을 포함한다.","s":"Chain-of-thought finetuning mixture.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#chain-of-thought-finetuning-mixture","p":363},{"i":377,"t":"Muffin, T0-SF 및 NIV2 의 경우, 데이터셋 창작자가 만든 instructional template 을 사용 CoT 의 경우, 9 가지 데이터셋 각각에 10 개의 instruction template 수동 작성 few-shot template 생성에는, \"Q:/\"\"A\" 같이 다양한 examplar 구분을 작성하며, 이를 무작위 example level 로 적용 (Fig 3)","s":"Templates and formatting.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#templates-and-formatting","p":363},{"i":379,"t":"T5, PaLM, U-PaLM 등 다양한 모델에 instruction finetuning 을 적용 각 모델들의 학습 절차는 learning rate, batch size, dropout, finetuning step 등 일부 hyperparameter 를 제외하고 동일하게 적용 일정한 schedule 및 Adafactor optimizer 사용 multiple training example 을 single sequence 에 결합하기 위해 [T5] 의 packing 을 사용했으며, input 과 target 을 eos sequence token 을 사용하여 분리한다. optimal step 은 held-out-tasks 의 periodic evaluation (모델 크기에 따라 2k ~ 10k step 마다) 를 기반으로 선택됨.","s":"2.2. Finetuning procedure","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#22-finetuning-procedure","p":363},{"i":382,"t":"Flan-PaLM 의 world knowledge 및 reasoning task 성능 평가를 위해 finetuning 에 포함하지 않은 held-out-task 에 평가 MMLU : mathematics, history, medicine 등 57 task 의 exam question 포함 BBH : BIG-Bench 로부터 23 challenging task 포함 TyDiQA : QA benchmark 로, 8 typologically language 포함 MGSM : math 단어 문제로 10 languages 포함","s":"Evaluation benchmarks.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#evaluation-benchmarks","p":363},{"i":384,"t":"MMLU (five-shot), BBH (three-shot) : direct prompting 을 통한 answer 예측 및 CoT prompting 을 통한 추론 능력 모두 평가 TyDiQA (one-shot) : 복잡한 추론을 요구하지 않아, direct prompting exact-match 점수를 측정 MGSM (8-shot) : direct prompting 성능이 낮아, CoT prompting 정확도만 측정 또한 BIG-Bench 에 따른 normalized average metric (macro-average) 을 보고.","s":"Evaluation mathods and metrics.","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#evaluation-mathods-and-metrics","p":363},{"i":386,"t":"모델 사이즈 및 finetuning task 수에 대한 scaling 효과 검토 PaLM 모델 8B, 62B 및 540B 에 대해 실험 CoT, Muffin, T0-SF 및 NIV2 를 순차적으로 추가하여 mixture multi-task instruction fietuning 및 no finetuning 을 비교하여 9.4% ~ 15.5% 의 성능 향상 finetuning task 를 늘리면 성능 향상이 있지만, 최대 282 tasks 에서 나타나며, 여기엔 두 가지 이유가 있음 추가 task 가 특별히 다양하지 않아 새로운 knowledge 를 제공할 수 없음 이미 pretraining 에서 알고 있던 knowledge 라서 큰 도움이 되지 않음 모델 사이즈를 한 단계씩 확장하는 것 (8B → 62B or 62B → 540B)이 finetuning 및 non-finetuning 모두 성능 향상","s":"3. Scaling to 540B parameters and 1.8K tasks","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":388,"t":"instruction finetuning mixture 에 CoT 를 포함한 효과를 탐구 여러 벤치마크에서 이전 모델을 능가하는 Flan-PaLM 의 향상된 추론 능력 CoT finetuning data 를 제거하고 CoT 없이 finetuning 수행 시 실제로 추론 능력 하락 CoT finetuning 가 어려운 BIG-Bench task 에서 \"let's think step-by-step\" 으로 zero-shot 추론이 가능한 것을 보여줌","s":"4. Finetuning with chain-of-thought annotations","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":390,"t":"저자는 CoT annotation 을 9 개의 데이터셋 finetuning mixture 에 포함시키는 것이 추론 능력을 향상시켜 주는 것을 보여준다. CoT prompting 이 [self-consistency] 와 결합하여 여러 벤치마크에서 SOTA 를 달성 MMLU 에서 Flan-PaLM 540B 은 75.2% 달성 다국어 math problem 인 MGSM 에서 CoT + SC 로 크게 개선하여 SOTA 달성 GSM8K 에서 Flan-PaLM + CoT + SC 가 83.9% 로 SOTA 달성 저자는 특정 특화된 모델과 비교하여 Flan-PaLM 이 SOTA 를 달성하지 않은 점도 주목 symbolic 조작만 요구되는 BBH-algo 의 경우, CoT + SC 로도 능가하지 못함 one-shot TyDiQA 에서 PaLM 보다 성능은 높지만 SOTA 모델과는 비교할 수준이 아님","s":"4.1. Finetuning on chain-of-thought improves reasoning on held-out tasks","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#41-finetuning-on-chain-of-thought-improves-reasoning-on-held-out-tasks","p":363},{"i":392,"t":"다음으로는, instruction finetuning 에 9개의 CoT 데이터셋을 제거해 본다. CoT 및 non-CoT fintuning 을 결합한 것이 이 CoT 만 finetuning 한 것 보다 성능이 좋았다. 이를 통해 non-CoT task 에서의 성능을 저하시키지 않음을 확인 Fig 5-왼쪽 에서 중요한 점은 CoT 에 대한 finetuning 이 추론 능력 유지에 중요하단 것을 보여준다. Non-CoT 만 finetuning 하는 것은 CoT 성능을 상당히 저하 unseen task 가 finetuning task 와 동일한 prompting paradigm (i.e. non-CoT, CoT)에 속할 때, instruction tuning 이 효과적으로 성능 향상 즉, non-CoT 및 CoT 데이터 모두 모델 향상에 필요","s":"4.2. Some chain-of-thought data is needed to maintain reasoning ability","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#42-some-chain-of-thought-data-is-needed-to-maintain-reasoning-ability","p":363},{"i":394,"t":"exemplar 를 포함하거나 포함하지 않은 CoT 데이터에 대한 instruction finetuning 의 최종 이점은 모델이 zero-shot 세팅에 대한 CoT 추론을 수행하는 것이다. Fig 6 에서 23개의 unseen challenging 인 BBH 벤치마크에서 Flan-PaLM 이 \"let's think step-by-step\" 구문을 사용하여 CoT 추론 수행 성능을 향상시켰다. Fig 7 에서 PaLM 및 Flan-PaLM 의 zero-shot 을 보여준다.","s":"4.3. Unlocking zero-shot reasoning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#43-unlocking-zero-shot-reasoning","p":363},{"i":396,"t":"instruction finetuning 의 일반화를 다양한 사이즈, 아키텍처 및 training objective 의 여러 모델을 적용하여 보여준다. decoder-only 아키텍처인 PaLM 에 대항하여 encoder-decoder 아키텍처인 T5 를 instruction finetuning PaLM 62B 모델에 500B token 을 pretraining 한 cont-PaLM 을 instruction tuning PaLM 540B 에 UL2 objective 로 20k 추가적인 step 으로 pretraining 한 U-PaLM instruction finetuning 은 모든 model 에 비해 큰 마진으로 normalized average 가 향상 instruction finetuning 하지 않은 T5 의 경우 LM-adapted model 을 사용하여 standard language modeling objective 로 100B 추가 토큰으로 훈련 T5 는 non-finetuned 모델과 비교하여 instruction- finetuning 은 이점을 얻음 위 결과로 다음을 얻음 3B 의 Flan-T5-XL : MMLU 52.4% score instruction finetuning 및 UL2 continued pre-training 을 결합한 U-PaLM model 사용 instruction 및 UL2 continued pre-training 은 model scale 을 증가시키지 않고 성능을 향상시키는 compute-efficient method","s":"5. Putting it all together","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":398,"t":"190개 예제로 구성된 평가 생성 5가지 카테고리 (creativity, reasoning over contexts, complex reasoning, planning 및 explanation) 각각 20개 question 포함 60개 examples (complex reasoning, planning 및 explanation) 에는 CoT 구문 (e.g. \"let's think step-by-step\") 생성하여 CoT zero-shot 가능 여부 평가 160개 zero-shot input 에 instruction finetuning 없이 잘 수행되는 30개 few-shot 을 포함 temperature sampling 은 τ=0.7\\tau = 0.7τ=0.7 로 설정하여 5개의 response 를 랜덤으로 선택 length normalization 없이 log probability score 로 rank 매김 score 절반 위로만 선택하는 filtering step 후, best score 선택 이 단계로, 원치 않는 반복 생성을 제거 예로 5개의 생성의 log probability 가 -20 이면, -3 은 반복 생성일 확률이 높아 제거 결과, 평가자들은 PaLM 및 Flan-PaLM 의 190개 examples 에 대해, Fla-PaLM 생성이 79% 의 선호도를 보임 모든 zero-shot 에 대해선 Flan-PaLM 이 큰 폭으로 선호도가 높음 CoT 구문을 사용한 경우, Flan-PaLM 이 10% 정도 증가 few-shot 의 경우, 비교할만한 성능은 없었다. instruction finetuning 된 모델이 open-ended zero-shot input 에 더 좋은 응답을 할 수 있는 능력은 [Training language models to follow instructions with human feedback, InstructGPT] 에서 finetuning LM 이 human feedback 으로 강화학습하여 human evaluation 을 개선시키는 것과 일관성 있다. 또한 PaLM 의 생성을 보면, pretraining on next-token prediction objective 만으로 강력한 성능을 보이지만 좋은 zero-shot 을 충분히 활용하지 못함을 볼 수 있다. PaLM 으로 만들어진 불필요한 행동은 다음을 포함한다. 질문에 답변하는 대신 관련된 텍스트 계속 생성 입력 질문을 약간 수정하여 반복 텍스트 생성을 멈추는 시점을 모름","s":"6. Usability evaluation of open-ended generation","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":400,"t":"본 연구는 instruction finetuning 을 확장 finetuning task 수 확장 모델 사이즈 확장 CoT 데이터에 finetuning instruction-finetuned model 결과 few-shot, zero-shot 및 CoT 등 전역에 성능 향상 다음은 논문 요약이다.","s":"7. Discussion","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":402,"t":"instruction finetuning 의 핵심 키는 모델 사이즈 및 finetuning task 수 확장이 성능 향상으로 이어진다는 것 저자는 scaling curve 를 그렸을 때, 모델 사이즈 및 task 수를 모두 확장하면 계속 성능이 향상될 것이라 예상 했지만, 앞서 282 task 와 1,836 task 가 큰 차이가 없는 것으로 보아, 누적 수를 더할 수록 이득이 줄어드는 경향이 있다. instruction finetuning 을 하지 않은 모델 대비하여 수행한 모델은 개선 폭이 감소하지 않는 것으로 보아 의미있은 역할을 계속 할 것으로 보임.","s":"Scaling curves for instruction finetuning","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#scaling-curves-for-instruction-finetuning","p":363},{"i":404,"t":"CoT finetuning 은 추론 능력에 중요한데, 이전 연구에선 unseen non-CoT task 에 대한 non-CoT finetuning 이 성능 향상되는 것을 보였지만, 본 논문에선 이로 인해 CoT task 에 성능 저하가 발생하는 것을 발견 해결책으로 non-Cot 및 CoT 데이터에 jointly finetuning 을 수행 non-CoT 성능을 유지하며 더 나은 CoT 성능을 가능케 함 큰 모델에 대한 CoT finetuning 이 held-out task 에서의 성능을 개선하며 non-CoT 작업의 성능 향상 유지","s":"CoT finetuning is critical for reasoning abilities","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#cot-finetuning-is-critical-for-reasoning-abilities","p":363},{"i":406,"t":"다양한 모델 (decoder-only, encoder-decoder), 사이즈 (T5-80M ~ PaLM-540B) 및 pre-training objectives (causal LM, span corruption 및 prefix LM + span corruption)에 instruction finetuning 을 적용하여, 일반화를 관찰 이는 decoder-only 및 encoder-decoder 에 효과적임을 보여줌. 또한 instruction finetuning 이 UL2R 과 결합하여 강력한 모델 (Flan-U-PaLM)을 만드는 데 잘 결합되는 것을 보여줌","s":"Instruction finetuning generalizes across models","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-generalizes-across-models","p":363},{"i":408,"t":"pre-trained checkpoint 직접사용하면 non-experts 에 challeng next token prediction objective 만으로 언제 생성을 멈출지 모름 사용자 입력에 계속 생성하는 실수를 저지름 Flan-PaLM 출력은 human evaluation 에서 상당한 결과를 보임 (complex reasoning, planning 등의 CoT). 유해한 언어 피해를 측정하는 벤치마크에서도 PaLM 보다 우수한 결과를 보임 이를 통해 instruction finetuning 이 인간의 선호와 일치하는 출력을 생성하는 것을 발견","s":"Instruction finetuning improves usability and mitigates some potential harms","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-improves-usability-and-mitigates-some-potential-harms","p":363},{"i":410,"t":"LM 크기 확장은 성능 향상에 신뢰적이지만, 상당한 계산량이 필요 instruction finetuning 은 상대적으로 적은 양의 컴퓨팅으로 성능을 개선시킨다. PaLM 540B 의 경우, instruction finetuning 은 pre-training 의 0.2% 만 필요, 전반에 걸쳐 평균 9.4% 향상 instruction finetuning 은 작은 모델로도 우수한 성능을 냄","s":"Instruction finetuning is relatively compute-efficient","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"#instruction-finetuning-is-relatively-compute-efficient","p":363},{"i":412,"t":"instruction finetuning 으로 확장하여 Flan-PaLM 을 을 훈련 540B parameter 로 확장 1.8K finetuning task 로 확장 chain-of-thought (CoT) 포함 실험 결과 모델 성능이 크게 향상 이전 연구에선 instruction finetuning 이 CoT task 에 성능 저하를 일으키지만, CoT 를 포함하여 jointly finetuning 한 결과 CoT 및 전체 평가에 성능 향상","s":"9. Conclusions","u":"/docs/Paper/NLP/Multi-Task/Flan-T5","h":"","p":363},{"i":414,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2205.05638.pdf","s":"Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":416,"t":"Few-shot in-context learning (ICL)은 pre-trained language model (LM) 이 input 의 일부에 적은 수의 training examples 를 feeding 하여 unseen task 를 gradient-based training 없이 수행하게 했다. ICL 은 all training examples 를 처리해야 하여 계산, 메모리 및 저장 비용이 큼 Parameter-efficient fine-tuning (PEFT) (e.g. adapter modules, prompt tuning, sparse update, etc) 은 모델이 new task 를 수행하도록 훈련된 parameter small set 을 제공하는 paradigm 본 논문은 few-shot ICL 과 PEFT 를 비교하여 PEFT 가 better accuracy 및 lower computational cost 제공을 입증한다. 이 과정에 learned vector 로 activations 를 확장하는 new PEFT 인 (IA)3(IA)^3(IA)3 소개 tiny new parameter 만 도입하여 더 강력한 성능 T0 model 에 기반하는 F-Few 로, new tasks 에 대한 task-specific tuning 또는 modifications 없이 적용할 수 있는 simple recipe 제안 T-Few 를 RAFT benchmark 에 적용함으로써 unseen tasks 에 대한 효과성 검증 super-human 성능을 최초로 6% 로 능가하여 SOTA 달성","s":"Abstract","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":418,"t":"pre-trained LM 은 NLP 의 중요한 요소 모델로 target task 에 대한 data-efficient 를 크게 향상. 즉, pre-trained LM 을 초기화에 사용하여 less labeled data 에 better results common approach 는 pre-trained LM 의 parameter 를 초기화에 사용한 다음, target downstream task 에 gradient-based fine-tuning 수행 fine-tuning 은 SOTA 를 도출하지만, new parameter set 값을 가지는 single task 에 특화된 모델을 생성하여 여러 downstream task 에 fine-tuning 할 경우 불필요하게 복잡해짐 [Language models are unsupervised multitask learners, Language models are few-shot learners] 에서 인기 있는 alternative approach 는 in-context learning (ICL) 이다. ICL 은 모델이 prompted example 을 inputting 하여 downstream task 를 수행하도록 유도 Few-shot prompting 은 input-target pairs 를 예측이 필요한 single unlabeled example 을 따라, human-understandable instructions 및 example 로 변환 ICL 은 gradient-based training 이 필요하지 않아, single model 은 즉시 다양한 task 에 수행 가능 따라서, ICL 은 pre-training 중에 모델이 학습한 능력에만 의존하며, 이 특성으로 인해 ICL 방법에 관심이 쏠림 ICL 은 위 이점에도 불구하고 여러 단점 존재 모델이 예측할 때마다 prompted input-target pairs 를 모두 처리하면 상당한 계산 비용 발생 ICL 은 일반적으로 fine-tuning 보다 성능 떨어짐 prompt 의 exact formatting (단어 선택 및 예제 순서 포함)이 모델의 성능에 미치는 영향을 예측 불가능 최근 ICL 이 incorrect labels 를 제공해도 잘 수행하는 점을 보여주며, 얼마나 많은 학습이 이루어지는지에 대한 의문 제기 최근의 연구는 ICL이 부정확한 레이블을 제공받아도 잘 수행할 수 있다는 점을 보여주는데, 이는 학습이 얼마나 많이 이루어지는지에 대한 의문을 불러일으킴 model 이 new task 수행을 위해 minimal updates 로 모델을 활성화하는 추가적인 패러다임인 parameter-efficient fine-tuning (PEFT) pre-trained model 에 추가 또는 선택된 small parameter 만 update 하여 fine-tuning 최근 전체 모델의 subset parameter (e.g. 0.01%)만 update 하거나 추가하여 fine-tuning 과 동등한 성능 달성 특정 PEFT 은 batch 내의 examples 를 다르게 처리하는 mixed-task batches 를 허용하여 PEFT 및 ICL 은 multitask models 모두에 적합 PEFT 의 이점은 fine-tuning 의 일부 단점을 해소하지만, 매우 적은 양의 label data 만 사용 가능할 경우 PEFT 방법이 잘 작동하는지에 대한 연구가 적다. 본 논문의 주요 목표는 이 공백을 메우기 위해 model, PEFT method 및 fixed hyperparameter set 을 사용하여, 모델의 일부 parameter 만 업데이트하며 novel, unseen task 에서 강력한 성능을 달성하는 recipe 제안 저자의 approach 는 T0 model 을 기반 이 모델은 T5 의 변형으로 다양한 prompt dataset 의 multitask mixture 을 fine-tuning 한 것 classification 및 multiple-choice tasks 성능 향상을 위해 unlikelihood 및 length normalization-based loss term 추가 intermediate activations 를 learned vectors 와 곱하는 PEFT method (IA)3(IA)^3(IA)3 개발 (IA)3(IA)^3(IA)3 은 parameter 를 최대 10,000배 적게 업데이트하며 full fine-tuning 보다 강력한 성능 달성 저자의 T-Few recipe 는 ICL (16배 큰 모델과 비교) 에 비해 상당히 더 나은 성능 발휘 real-world few-shot learning 벤치마크 RAFT 에서 처음으로 human 능가 less compute 및 inference 중 mixed-task batches 가능","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":421,"t":"PEFT 는 small storage requirement 및 computational cost 로 model 을 new task 에 adapting 할 가능성을 제시하여 ICL 의 대안으로 유망함 따라서 저자는 computational 및 storage cost 를 최소화하며 inference 중 mixed-task batches 가 가능한, limited labeled examples 로 new task 에 높은 정확도를 달성할 수 있는 recipe 개발이 목표 여기서 recipe 란 new task 에서 강력한 성능을 제공하는 model 및 hyperparameter 설정을 의미하며, manual tuning 이나 per-task adjustments 없이 강력한 성능을 보장할 수 있는 것이다. 이를 평가하기 위해 limited labeled data 만 사용 가능한 few-shot settings 에서 approach 가 실질적인 옵션임을 보장할 수 있다.","s":"3. Designing the T-Few Recipe","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":423,"t":"limited labeled examples 로 fine-tuning 후에도 성능이 높은 이상적인 pre-trained model 선택에 있어, PEFT method 적용으로 best 성능을 달성한 T0 채택. T0 는 T5 기반이며, unlabeled text data 인 large corpus 의 masked language modeling objective 로 pre-training 한 encoder-decoder Transformer dataset multitask mixture 을 기반으로 T5 를 fine-tuning 하여 zero-shot generalization 가능 (i.e. additional gradient-based training 없이 task 수행) T0 training 에 사용된 dataset examples 는 Public Pool of Prompts (P3) 의 prompt templates 를 적용한 prompted 이며, prompted text-to-text format 으로 변환 T0 는 3B 와 11B parameter 를 제공하며 각각 \"T0-3B\" 및 \"T0\" 로 지칭 T0 는 zero-shot generalization 을 위해 설계되었지만, 저자는 few labeled example 만으로 fine-tuning 후에도 강력한 성능을 달성하는 것을 증명 T0 generalization 능력 테스트를 위해 multitask training mixture 에서 제외할 task 선택 sentence completion (COPA, H-SWAG 및 Stroy Cloze datasets) natural language inference (ANLI, CB 및 RTE) coreference resolution (WSC 및 Winogrande) word sense disambiguation (WiC) 또한 RAFT 벤치마크에서 T-Few 의 능력을 Sectiopn 4.3 에서 테스트 RAFT 는 validation 및 held-out test set 없이 unseen \"real-world\" few-shot collection 평가에는 \"rank classification\" 을 사용하며, all possible label strings 에 대한 모델의 log-probabilities 는 순위를 지정하며, 가장 높은 순위의 choice 는 가 올바른 답일 경우 모델 예측이 올바르다 간주 Rank classification evaluation 은 classification 및 multiple choice tasks 모두와 호환 모델 성능은 prompt template 에 따라 크게 다르므로 각 데이터셋에 대한 all prompt template 를 median accuray 로 보고 test label 이 public 이 아닐 경우 (e.g. SuperGLUE) test set 또는 validation set 에 대한 정확도를 보고 본문에선 위에서 언급한 9개 데이터셋에 대한 median accuracy 보고","s":"3.1 Model and Datasets","u":"/docs/Paper/NLP/PEFT/IA³","h":"#31-model-and-datasets","p":413},{"i":425,"t":"PEFT 연구 전에, 저자는 LM 의 few-shot fine-tuning 의 성능 향상을 위한 두 가지 additional loss terms 탐구 LM 은 보통 cross-entropy loss LLM=−1T∑tlog⁡p(yt∣x,y<t)L_{LM} = -\\frac{1}{T} \\sum_t \\log p (y_t | \\text{x}, y_{<t})LLM​=−T1​∑t​logp(yt​∣x,y<t​) 로 훈련된다. input sequence x\\text{x}x 에 대한 correct target sequence y=(y1,y2,…,yT)\\text{y} = (y_1, y_2, \\dots, y_T)y=(y1​,y2​,…,yT​) 의 probability 가 증가하도록 훈련 평가를 위해, 모델의 correct/incorrect choice 의 probability 에 따라 다른 rank classification 사용 LUL=−∑nN=1∑t=1T(n)log⁡(1−p(y^i(n)∣x,y^<t(n)))∑n=1NT(n)\\begin{equation} L_{\\text{UL}} = -\\frac{\\sum^N_n=1 \\sum^{T^{(n)}}_{t=1} \\log (1 - p (\\hat{y}_i^{(n)}|\\text{x}, \\hat{y}^{(n)}_{<t}))}{\\sum^N_{n=1}T^{(n)}} \\end{equation}LUL​=−∑n=1N​T(n)∑nN​=1∑t=1T(n)​log(1−p(y^​i(n)​∣x,y^​<t(n)​))​​​ 모델이 incorrect target sequence 의 tokens 을 예측하는 것을 억제한다. incorrect target sequence y^(n)=(y^1,y^2,…,y^T(n)\\hat{\\text{y}}^{(n)} = (\\hat{y}_1, \\hat{y}_2, \\dots, \\hat{y}_{T^(n)}y^​(n)=(y^​1​,y^​2​,…,y^​T(n)​ 는 NNN 개 incorrect target sequence 의 nnn-th LULL_{\\text{UL}}LUL​ 을 추가하여 rank classification 결과가 개선될 것으로 가정 이는 모델이 incorrect choice 에 더 낮은 확률을 할당하도록 훈련되므로 correct choice 가 가장 높은 순위로 ranking 될 가능성이 향상될 것으로 예상 training example 에 대한 possible target sequence 는 길이가 다양하며, 특히 multiple-choice tasks 에서 더 그렇다. 각 choice 를 proability 에 따라 ranking 매기면 모델은 더 shorter choice 를 선호한다. 이는 각 token 에 할당된 확률이 ≤1\\leq 1≤1 이기 때문이다. 이를 보정하기 위해 rank classification 수행 시에 length normalization 사용을 고려한다. length normalization 은 모델이 각 possible answer choice 에 대한 score 를 choice token 수로 나누어 계산하는 방법 (GPT-3 에서 사용됨) evaluation 중 length normalization 을 사용할 때는 training 중 length-normalized evaluation 을 더 정확히 반영하는 additional loss 도입 먼저, 주어진 output sequence 의 length-normalized log probability β(x,y)=1T∑t=1Tlog⁡p(yt∣x,y<t).\\beta(\\text{x}, \\text{y}) = \\frac{1}{T}\\sum^T_{t=1} \\log p(y_t|\\text{x},y_{<t}).β(x,y)=T1​∑t=1T​logp(yt​∣x,y<t​). 을 계산 그 후, Eq. 2 의 softmax cross-entropy loss 를 최소화함으로써 correct answer choice 의 length-normalized log probability 최대화 LLN=−log⁡exp⁡(β(x,y))exp⁡(β(x,y))+∑n=1Nexp⁡(β(x,y^(n)))\\begin{equation} L_{\\text{LN}} = - \\log \\frac{\\exp(\\beta(\\text{x}, \\text{y}))}{\\exp(\\beta(\\text{x}, \\text{y})) + \\sum^N_{n=1} \\exp(\\beta(\\text{x}, \\hat{\\text{y}}^{(n)}))} \\end{equation}LLN​=−logexp(β(x,y))+∑n=1N​exp(β(x,y^​(n)))exp(β(x,y))​​​ LLML_{\\text{LM}}LLM​, LULL_{\\text{UL}}LUL​ 및 LLNL_{\\text{LN}}LLN​ 을 사용하여 모델을 training 할 때 이 loss 들을 단순히 합한다. 이는 few-shot setting 에 tuning 하기 어려운 hyperparameter 도입을 파하기 위함 LLML_{\\text{LM}}LLM​ 추가로 정확도가 60.7% → 62.71% 향상 모두 포함하면 63.3% 로 더 개선 이러한 loss 들은 additional hyperparameter 를 도입하지 않고도 성능을 향상시키므로 저자의 recipe 에 포함하고 이후 모든 실험에도 사용","s":"3.2 Unlikelihood Training and Length Normalization","u":"/docs/Paper/NLP/PEFT/IA³","h":"#32-unlikelihood-training-and-length-normalization","p":413},{"i":427,"t":"few-shot ICL 과 유리한 비교를 위해 다음 PEFT 특성이 필요 storage 및 memory cost 발생하지 않기 위해 가능한 한 few parameter 만 추가하거나 업데이트 new task 에 대해 few-shot training 후에도 강력한 정확도 달성 ICL 기능 중 하나인 mixed-task batches 허용성 mixed-task batches 이 가능하면서 PEFT 방법을 지키려면 모델 자체를 수정하면 안된다. 위를 만족시키기 위해선 batch 의 각 examples 를 다른 모델 또는 computational graph 로 처리해야 한다. example 이 어떤 task 에 해당하는지에 따라 batch 의 각 examples 에 독립적이고 비용이 저렴하게 수행 가능하여 모델의 activations 를 직접 수정하는 방법이 대인일 수 있다. Prompt tuning 및 Prefix-tuning 은 learned vectors 를 activation 또는 embedding sequence 에 연결하여 작동하므로 mixed-task batches 를 허용하는 activation-modifying PEFT method 의 예이다. 하지만 합리적인 정확도를 얻지 못하였으며, 성능이 좋은 다른 PEFT method 는 mixed-task batches 를 허용하지 않음 위 사항으로 저자는 새로운 PEFT 방법을 개발 대안으로, 저자는 모델의 activations 와 learned vector 간의 element-wise multiplication (i.e. rescaling) 을 탐구 저자는 l⊙xl \\odot xl⊙x 형태의 adaptation 고려 l∈Rdl \\in \\mathbb{R}^dl∈Rd : learned task-specific vector ⊙\\odot⊙ : element-wise multiplication x∈RT×dx \\in \\mathbb{R}^{T \\times d}x∈RT×d : activations 의 length-TTT sequence \"broadcasting notation\" 을 사용하여 l⊙xl \\odot xl⊙x 의 (i,j)th(i, j)^{th}(i,j)th entry 는 ljxi,jl_j x_{i,j}lj​xi,j​ 이다. 예비 실험에선, Transformer 모델의 각 activation set 에 대한 learned rescaling vector 를 도입할 필요가 없음을 발견 대신, self-attention 및 encoder-decoder attention 매커니즘에서 key, value 에 rescaling vector 도입 position-wise feed-forward network 의 intermediate activation 에도 rescaling vector 를 도입 구체적으로, 다음과 같이 attention 매커니즘 도입 position-wise feed-forward 네트워크의 중간 활성화에도 재조정 벡터를 도입하는 것이 충분하다는 것을 발견했습니다. 구체적으로, Vaswani et al. [33]의 표기법을 사용하여 우리는 다음과 같이 attention 메커니즘에 도입합니다: softmax(Q(lk⊙KT)dk)(lv⊙V)\\begin{equation} \\text{softmax}\\left ( \\frac{Q(l_k \\odot K^T)}{\\sqrt{d_k}} \\right ) (l_v \\odot V) \\end{equation}softmax(dk​​Q(lk​⊙KT)​)(lv​⊙V)​​ 또한 position-wise feed-forward network 에서는 (lff⊙γ(W1x))W2(l_{ff} \\odot \\gamma (W_1 x))W_2(lff​⊙γ(W1​x))W2​ 형태로 도입 γ\\gammaγ : feed-forward network nonlinearity 각 Transformer layer block 마다 별도의 lkl_klk​, lvl_vlv​ 및 lffl_{ff}lff​ vector set 을 도입 이로 인해 LLL-layer-block Transformer encoder 에 L(dk+dv+dff)L(d_k + d_v + d_{ff})L(dk​+dv​+dff​) new parameter 추가 LLL-layer-block decoder 에는 L(2dk+2dv+2dff)L(2d_k + 2d_v + 2d_{ff})L(2dk​+2dv​+2dff​) (self-attention 및 encoder-decoder attention 모두가 있어 2 factor 존재) 가 추가 lkl_klk​, lvl_vlv​ 및 lffl_{ff}lff​ 는 모두 1로 초기화되어 있으므로 이러한 vecotrs 가 추가 되면 모델이 계산하는 전반적인 함수는 변경되지 않는다. 저자는 위와 같은 방법을 (IA)3(IA)^3(IA)3 이라 부르며, \"Infused Adapter by Inhibiting and Amplifying Inner Activations\" 의 약자다. (IA)3(IA)^3(IA)3 은 batch 내의 각 activations sequence 는 learned task vector 에 의해 별도로 및 저렴하게 multiple 되므로 mixed-task batches 를 가능하게 함 또한 모델이 single task 에만 사용될 것이라면, (IA)3(IA)^3(IA)3 의 도입으로 인한 수정은 weight matrices 에 영구적으로 적용하여 elementwise multiplication 이 필요하지 않고 model architecture 가 변경되지 않도록 할 수 있다. 이는 (IA)3(IA)^3(IA)3 에서 수행된 element-wise multiplication 이 항상 matrix multiplication 과 동시에 발생하기 때문이다. l⊙Wx=(l⊙W)xl \\odot W x = (l \\odot W) xl⊙Wx=(l⊙W)x 이 경우, original model 과 비교하여 (IA)3(IA)^3(IA)3 는 additional computational cost 를 부담하지 않는다. (IA)3(IA)^3(IA)3 검증을 위해, held-out task 의 few-shot dataset 에서 fine-tuning T0-3B 에 대한 저자의 설정에서 다양한 adaptation methods 를 비교 9 가지 강력한 PEFT 방법들과 비교한다. BitFit : bias parameter 만 update Adapters : self-attention 및 position-wise feed forward networks 후 task-specific layer 도입 Compacter 및 Compacter++ : low-rank matrices 및 hypercomplex multiplication 을 사용하여 adapter 개선 Prompt tuning : model input 에 연결되는 task-specific prompt embeddings 학습 FISH Mask : Fisher information 에 기반하여 업데이트할 parameter subset 을 선택 Intrinsic SAID : low-dimensional subspace 에서 optimization 수행 Prefix-tuning : model 의 activations 에 연결되는 task-specific vectors 학습 LoRA : parameter matrices 에 low-rank 를 할당 추가적으로 저자는 baseline full fine-tuning 및 layer normalization parameter 만 업데이트하는 것 포함 결과는 Fig. 2 에서 확인 가능 (IA)3(IA)^3(IA)3 은 full fine-tuning baseline 보다 높은 정확도 달성 다른 PEFT 는 parameter update 또는 introduce fewer parameter 이지만 (IA)3(IA)^3(IA)3 은 훨씬 우수한 성능 발휘 Compacter 및 Compacter++ 는 few-shot setting 에서 full fine-tuning 보다 뛰어나다 하며, prompt tuning 은 full fine-tuning 과 일치할 수 있다고 발견 했지만, 두 경우엔 다양한 hyperparameter choices 시도 위 경우는 다른 모델 및 다른 데이터셋에서 비롯되어, 검증셋 성능이 training 과정 중 급격하게 변동할 수 있어 최적화 문제 가능성 시사","s":"3.3 Parameter-efficient fine-tuning with (IA)3(IA)^3(IA)3","u":"/docs/Paper/NLP/PEFT/IA³","h":"#33-parameter-efficient-fine-tuning-with-ia3","p":413},{"i":429,"t":"최근 prompt tuning 에서 prompt embeddings 를 pre-training 하는 것이 downstream few-shot tasks 를 fine-tuning 할 때 성능 향상시키는 것 보여줌 이전 연구에서 unlabeled text data 에 적용되는 self-supervised tasks 를 사용하거나 separate task 또는 multitask mixture 로부터의 embeddings 를 사용하는 것을 고려했다. 저자는 전자를 따라, (IA)3(IA)^3(IA)3 에 의해 도입된 new parameter 를 T0 훈련에 사용된 동일한 multitask mixture 에 간단히 pre-training 한다. 16 batch size 로 100,000 steps pretraining 후 (IA)3(IA)^3(IA)3 parameter 를 각 개별 downstream dataset 에 대해 fine-tuning 저자의 pre-training 이 fine-tuning 정확도를 64.6 에서 65.8 로 향상시켜 recipe 에 추가","s":"3.4 Pre-training (IA)3(IA)^3(IA)3","u":"/docs/Paper/NLP/PEFT/IA³","h":"#34-pre-training-ia3","p":413},{"i":431,"t":"요약하면 T-Few recipe 는 다음과 같이 정의 T0 모델을 백본으로 사용 downstream task adaptation 을 위해 (IA)3(IA)^3(IA)3 사용 T0 와 동일한 multitask mixture 에서 pre-training 한 (IA)3(IA)^3(IA)3 으로 초기화된 parameter objective 로는 standard language modeling loss LLML_{\\text{LM}}LLM​, incorrect choices 에 대해선 unlikelihood loss LULL_{\\text{UL}}LUL​ 및 length-normalized loss LLNL_{\\text{LN}}LLN​ 사용 다음 hyperparameter 로 학습 learning rate 3e−3e^{-3}e−3 linear decay schedule 60 step warmup Adafactor optimizer 8 sequence 의 batch size 1,000 steps training 및 inference 중 downstream dataset 에 prompt template 을 적용하여 각 example 을 instructive text-to-text 형태로 변환 중요한 점은, 위 recipe 를 각 downstream dataset 에 동일한 방식으로 적용하며 per-dataset hyperparameter tuning 및 modifications 없이 사용 이는 recipe 가 validation sets 가 적은 few-shot learning setting 에서 실용적인 옵션으로 사용될 수 있다.","s":"3.5 Combining the ingredients","u":"/docs/Paper/NLP/PEFT/IA³","h":"#35-combining-the-ingredients","p":413},{"i":433,"t":"T-Few recipe 를 T0-3B 에 설계 및 확립 후, T0 (11B) 에 적용하여 strong few-shot ICL baseline 과 성능 비교 그리고 모든 task 에 대해 동일한 recipe 및 hyperparameter 를 사용","s":"4. Outperforming ICL with T-Few","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":435,"t":"먼저 T0 의 training mixture 에서 제외된 dataset 에 대한 T-Few 성능 평가 저자는 T0 의 zero-shot learning 과 비교한다. (T0 에 대한 zero-shot 보다 few-shot ICL 이 성능이 떨어지는 것을 확인하였기 때문) T5+LM 으로 few-shot ICL (T0 기반으로 하는 next-step-prediction LM) GPT-3 의 6.7, 13 및 175B 의 few-shot ICL T-Few 는 다른 방법보다 훨씬 큰 마진으로 성능 우수 특히 16배 작은 크기에도 GPT-3 175B 의 few-shot ICL 보다 6% 높은 정확도 달성 smaller GPT-3 보다 훨씬 큰 마진으로 성능 높임 T-Few 는 T0 zero-shot learning 및 T5-LM 의 few-shot ICL 보다 높은 정확도 달성","s":"4.1 Performance on T0 tasks","u":"/docs/Paper/NLP/PEFT/IA³","h":"#41-performance-on-t0-tasks","p":413},{"i":437,"t":"T-Few 가 ICL-based models 을 크게 앞선 성능을 보여줬으므로 이제 각 few-shot learning approach 에서 상대적인 cost 를 비교한다. 단순성을 위해, Transformer-based LM 에 대한 FLOPs-per-tokens estimates 를 사용한다. 구체적으로, NNN parameter 를 가진 decoder-only Transformer (e.g. GPT)가 interence 에는 2N2N2N FLOPs per token 을 사용하고 training 에는 6N6N6N FLOPs per token 을 사용한다고 추정 T0 및 T5 같은 encoder-decoder 모델 (encoder 와 decoder 가 동일한 layer 수 및 크기를 가지는 경우) 은 각 token 을 encoder 또는 decoder 중 하나만 처리하므로 FLOPs per token estimates 는 inference 및 training 에 각각 NNN 및 3N3N3N 이 사용된다. FLOPs 는 real-world computational cost 가 아니므로 latency, power usage 및 other costs 등에 따라 다양한 비용 발생 가능. 하지만 하드웨어 설정이 크게 다를 것으로 예상되므로 FLOPs 에 중점을 둠 cost 에 대한 요약은 Table 1 에서 제공 저자는 dataset 의 중간 수의 shot (41) 사용 rank evaluation 및 unlikelihood loss 두 경우엔 unlabeled example 에 대한 prediction 을 얻기 위해 모든 possible output choice 를 처리해야 한다. input 및 all possible target 에 대해 combined tokenized sequence length 중간 값은 저자가 고려한 데이터셋에서 103 이다 few-shot ICL 로 처리된 in-context examples 의 경우 correct target 만 필요하므로, median sequence length 는 98 이다. ICL 로 single example 을 처리하는데 필요한 것은 41×98+10341 \\times 98 + 10341×98+103 token 이다.","s":"4.2 Comparing computational costs","u":"/docs/Paper/NLP/PEFT/IA³","h":"#42-comparing-computational-costs","p":413},{"i":439,"t":"향상된 정확도 외에도 few-shot ICL 을 피하는 주된 이점은 inference costs 가 크게 낮아지는 것 T-Few 를 사용하여 single input 및 all target choice 를 처리하려면 11e9×103=1.1e1211e9 \\times 103 = 1.1e1211e9×103=1.1e12 FLOPs 가 필요하다 GPT-3 175B 를 사용한 few-shot ICL 은 2×175e9×(41×98+103)=1.4e152×175e9× (41 × 98 + 103) = 1.4e152×175e9×(41×98+103)=1.4e15 FLOPs 가 필요 Section 2.1 에서 언급했듯이, same in-context examples set 을 재사용할 때 key 와 value vectors 를 caching 하면 ICL 의 computational cost 를 줄일 수 있다. 이는 약 41배 정도만 감소시켰으며, GPT-3 ICL costs 를 T-Few 만큼 충분히 낮추진 못한다.","s":"Inference cost","u":"/docs/Paper/NLP/PEFT/IA³","h":"#inference-cost","p":413},{"i":441,"t":"T-Few 는 updating parameter 를 수반한 방법이기 때문에 training cost 발생 11B encoder-decoder model 을 103 length sequence 의 8 batch size 로 1,000 steps training 하는데 약 3×11e9×1,000×8×103=2.7e163 × 11e9 × 1, 000 × 8 × 103 = 2.7e163×11e9×1,000×8×103=2.7e16 FLOPs 가 필요 few-shot ICL 을 사용한 GPT-3 175B 의 single example 처리에 필요한 FLOPs 의 약 20배 더 크다. T-Few training cost 는 GPT-3 175B 를 사용한 few-shot ICL 로 20 examples 처리하는데 드는 비용만큼 사용 single dataset 에서 T-Few 로 T0 를 fine-tuning 하는데 single NVIDIA A100 GPU 로 약 30분 밖에 안걸림","s":"Training cost","u":"/docs/Paper/NLP/PEFT/IA³","h":"#training-cost","p":413},{"i":443,"t":"T-Few 는 가장 큰 Storage cost 발생 (IA)3(IA)^3(IA)3 에 의해 추가된 parameter 는 single-precision floats 로 저장될 때, 4.2MB dist space 를 차지 반면, ICL method 는 tokenized in-context example 만 저장하므로 (일반적으로 32-bit integers), 41×98×32bits=1641 × 98 × 32 bits = 1641×98×32bits=16kB disk space 요구 하지만 4.2MB 는 model checkpoint 와 비교하면 미미 10,000 개 task 에 대한 adaptation vectors (IA)3(IA)^3(IA)3 를 저장하는 데는 T0 checkpoint (41.5GB) 만큼의 space 필요 그러나 4.2MB는 모델 체크포인트 자체의 디스크 크기와 비교하면 미미합니다. 10,000개의 작업에 대한 (IA)3 적응 벡터를 저장하는 데는 T0 체크포인트(약 41.5GB)만큼의 공간이 필요합니다.","s":"Storage cost","u":"/docs/Paper/NLP/PEFT/IA³","h":"#storage-cost","p":413},{"i":445,"t":"inference 중 memory usage 는 model parameter 에 의해 발생 T-Few 는 inference 중에 더 낮은 memory usage 소요 training 중에는 backpropagation 을 위해 intermediate activations 를 caching 하고 Adafactor 의 gradient accumulator 변수를 위한 memory usage 소요 하지만 위에서 언급했듯, T-Few recipe 를 single 80GB A100 GPU 로 사용 가능","s":"Memory usage","u":"/docs/Paper/NLP/PEFT/IA³","h":"#memory-usage","p":413},{"i":447,"t":"few-shot learning 에 대해 성능 평가를 하며, real world 에서의 T-Few 성능을 더 잘 평가하기 위해 RAFT 에서 평가 RAFT 는 real-world applications 를 반영하는 11 가지 task 구성 각 RAFT datasets 는 validation 및 test set 없으며 public label 이 없는 50 training example 만 가지고 있음 unrealistically-large validation set 또는 test set 에 tuning 하는 속임수를 쓸 수 없다는 점 T-Few 를 adapting 하기 위해 dataset 과 함께 제공된 standard prompt 사용 top-5 정확도는 Table 2 에 표시 T-Few 는 75.8 의 SOTA 정확도 달성 인간 기준 (73.5%) 능가 위 결과로 T-Few 가 강력한 성능을 달성하기 위해 new real-world task 에 즉시 적용 가능함을 검증","s":"4.3 Performance on Real-world Few-shot Tasks (RAFT)","u":"/docs/Paper/NLP/PEFT/IA³","h":"#43-performance-on-real-world-few-shot-tasks-raft","p":413},{"i":449,"t":"T-Few design 실험은 T0-3B 에서 진행하여, T0 에서 T-Few Ablation 실험 수행 각 구성 요소를 추가함으로써 얻는 이득이 각 개별 데이터셋의 정확도를 크게 증가시키진 않지만, 데이터셋 전체에서 평균 성능을 일관되게 향상 pre-training 을 제거하면 정확도가 1.6% 감소하며, unlikelihood training 및 length normalization 을 제거하면 정확도가 4.1% 감소하며, 모두 제거하면 2.5% 감소했다.","s":"4.4 Ablation experiments","u":"/docs/Paper/NLP/PEFT/IA³","h":"#44-ablation-experiments","p":413},{"i":451,"t":"저자는 T-Few recipe 소개 few-shot learning 에 대한 computational cost 가 낮은 parameter-efficient recipe few-shot ICL 보다 높은 정확도 달성 T-Few 에 (IA)3(IA)^3(IA)3 라는 새로운 PEFT 방법 사용 learned vectors 로 inner activations 를 rescales full fine-tuning 보다 훨씬 적은 additional parameter 로 더 나은 성능 T-Few 는 incorrect choice 에 대한 lower probability 를 outputting 하고 다양한 answer choices 의 length 를 고려하기 위해 두 가지 loss 사용 T-Few 를 그대로 RAFT 에 적용할 때, human 성능을 뛰어 넘음 computational costs 의 detailed characterization 을 통해 T-Few 가 few-shot ICL 과 비교하여, inference 중 1,000배 이상 fewer FLOPs 를 사용 single NVIDIA A100 GPU 에 30 분 만에 훈련 가능 모든 실험은 classification tasks 이기 때문에 summarization 및 QA 같은 generation task 에 대해서도 T-Few 적용 가능할 것으로 보이며, LLM 을 사용한 few-shot learning 을 최적으로 수행하는 것에 대한 새로운 관점의 제공을 추후 연구 필요","s":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/IA³","h":"","p":413},{"i":453,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.16199.pdf","s":"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":455,"t":"LLaMA-Adapter 는 LLaMA 를 instruction-following model 로 효율적으로 fine-tuning 하기 위한 경량 adaptation method 52K self-instruction 사용 LLaMA 7B model 을 freezing 한 채, LLaMA-Adapter 를 사용하면 1.2M learnable parameter 만 추가됨 8대의 A100 GPU 에서 1시간 이하의 fine-tuning cost 발생 구체적으로, learnable adaptation prompts 를 채택, 이를 상단의 Transformer layer 의 word token 앞에 추가 zero-initialized attention 메커니즘 및 zero gating 제안 new instruction 을 LLaMA 에 adaptively injects 하는 동시에 pre-trained knowledge 를 효과적으로 보존 LLaMA-Adapter 는 multi-model instruction 으로 확장 가능 ScienceQA 및 COCO caption 벤치마크에 우수한 reasoning 성능 달성 전통적인 비전 및 언어 task 에서 pre-trained model (ViT, RoBERTa)을 fine-tuning 하기 위해 zero-initialized attention 메커니즘을 평가하여 저자의 approach 의 우수한 일반화 능력 보여줌","s":"Abstract","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":457,"t":"LLM 이 크게 발전하는데 비해 instruction model 은 높은 비용 및 시간이 든다. 이를 해결하려, Stanford Alpaca 는 LLaMA 를 instruction-following model 로 fine-tuning 하는 방법을 제안하여 저렴하고 복제 가능한 모델을 만들었지만 여전히 시간이 많이 소요된다. 본 논문은 LLaMA-Adapter 도입으로 LLaMA 를 instruction-following model 로 효율적으로 fine-tuning 하는 방법 제안 training 을 목적으로 52K instruction-output data 활용 LLaMA 를 freezing 하여 efficiency 보존 LLaMA 상단의 transformer layer 에 learnable adaptation prompts 를 input instruction token 앞에 붙임 초기 훈련 단계에서 adaptation prompt 의 noise 를 피하기 위해, layer 의 vanilla attention 메커니즘을 zero-initialized attention 으로 수정하고 learnable gating 추가 다음 LLaMA-Adapter 는 Fig 1 에서 네 가지 특징 가짐 1.2M Parameters pre-trained LLaMA 7B 는 freezing 하고 1.2M parameter 인 adaptation prompt 만 학습 7B Alpaca 와 comparable instruction-following One-hour Fine-tuning zero-initialized gating 을 사용한 경량 adaptation module 덕에 8개의 A100 GPU 에서 1시간 미만으로 Alpaca 보다 3배 빠름 Plug with Expertise 여러 시나리오에 대한 여러 adapter 를 삽입하고 LLaMA 에 다양한 expert knowledge 를 부여하는 유연성 지님 Multi-model Instruction text instruction 뿐 아니라 image input 으로 multi-model reasoning 수행 가능 image tokens 을 adaptation prompts 에 추가함으로써 ScienceQA 및 COCO caption 벤치마크에서 comparable 한 성능 instruction-following model 뿐 아니라, vision 및 language models 에 대해서도 zero-initialized attention 이 parameter-efficient fine-tuning 으로 일반화 가능 pre-trained ViT 를 fine-tuning 하는데 저자의 approach 로 VTAB-1k 벤치마크에서 우수한 성능 달성 ReBERTa 의 경우 SQuAD v1.1 및 v2.0 에서 선도적인 결과 달성","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":461,"t":"52K instruction-output data 및 NNN-layer transformer 를 사용하는 pre-trained LLaMA 가 주어졌을 때, 저자는 instruction-following fine-tuning 을 위해 learnable adaptation prompts 셋 채택 {Pl}l=1L\\{ P_l \\}^L_{l=1}{Pl​}l=1L​ : LLL transformer layer 에 대한 prompts Pl∈RK×CP_l \\in \\mathbb{R}^{K \\times C}Pl​∈RK×C KKK : 각 layer 에 대한 prompt length CCC : LLaMA transformer 의 feature dimension prompt 를 transformer 의 가장 상단 LLL layer (l≤L)(l \\leq L)(l≤L) 에 삽입한 것을 주목하자. 이는 higher-level semantics 를 갖는 language representation 을 더 잘 tuning 하도록 해줌 예로 lll-th inserted layer (l≤L)(l \\leq L)(l≤L) 를 보자. Ti∈RM×CT_i \\in \\mathbb{R}^{M \\times C}Ti​∈RM×C : MMM-length word tokens input instruction 및 이미 생성된 response 표시 learnable adaptation prompt 는 token dimension 을 따라 TiT_iTi​ 과 prefix 로 연결 [Pl;Tl]∈R(K+M)×C\\begin{equation} [P_l; T_l] \\in \\mathbb{R}^{(K+M) \\times C} \\end{equation}[Pl​;Tl​]∈R(K+M)×C​​ PlP_lPl​ 에서 학습된 instruction knowledge 는 transformer block 의 attention layers 를 통해 subsequent contextual response 를 생성하도록 TiT_iTi​ 에게 효율적으로 가이드함","s":"3.1 Learnable Adaptation Prompts","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":463,"t":"adaptation prompts 가 무작위로 초기화되면, training 초기에 word token 에 혼란을 일으킬 수 있어, fine-tuning 의 안정성과 효과를 해칠 수 있음 이로 인해 저자는 last LLL transformer layers 에서 vanilla attention 매커니즘을 수정하여 zero-initialized attention 으로 수정 lll-th inserted layer 의 [Pl;Tl][P_l; T_l][Pl​;Tl​] 상단의 (M+1)(M + 1)(M+1)-th word 를 생성하는 상황을 가정 tl∈R1×Ct_l \\in \\mathbb{R}^{1 \\times C}tl​∈R1×C : 해당 (M+1)(M+1)(M+1)-th word token attention 매커니즘은 input tokens 을 queries, keys 및 values 로 변환하기 위해 linear projection 에 적용 Ql=Linearq( tl );Kl=Lineark( [Pl;Tl;tl] );Vl=Linearv( [Pl;Tl;tl] ).\\begin{align} & Q_l = \\text{Linear}_q (\\ t_l\\ ); \\\\ & K_l = \\text{Linear}_k (\\ [P_l; T_l; t_l] \\ ); \\\\ & V_l = \\text{Linear}_v (\\ [P_l; T_l; t_l] \\ ). \\end{align}​Ql​=Linearq​( tl​ );Kl​=Lineark​( [Pl​;Tl​;tl​] );Vl​=Linearv​( [Pl​;Tl​;tl​] ).​​ 이후 softmax function 전에 QlQ_lQl​ 와 KlK_lKl​ 의 attention scores 를 계산 Sl=QlKlT/C∈R1×(K+M+1)\\begin{equation} S_l = Q_l K_l^T / \\sqrt{C} \\in \\mathbb{R}^{1 \\times (K+M+1)} \\end{equation}Sl​=Ql​KlT​/C​∈R1×(K+M+1)​​ 이는 new word tlt_ltl​ 와 모든 K+M+1K+M+1K+M+1 tokens 간의 feature simiarities 를 기록하는 것. 한편 SlS_lSl​ 은 두 component 로 재정립될수 있다. Sl=[SlK;SlM+1]T\\begin{equation} S_l = [S_l^K; S_l^{M+1}]^T \\end{equation}Sl​=[SlK​;SlM+1​]T​​ SlK∈RK+1S^K_l \\in \\mathbb{R}^{K+1}SlK​∈RK+1 : KKK adaptation prompts 의 attention score learnable prompt 가 tlt_ltl​ 를 생성하는데 얼마나 많은 정보를 제공하는지 지표 훈련 초기 단계에 혼란을 야기할 수 있음 SlM+1∈R(M+1)×1S_l^{M+1} \\in \\mathbb{R}^{(M+1)\\times 1}SlM+1​∈R(M+1)×1 : M+1M+1M+1 word tokens learnable gating factor glg_lgl​ 을 도입하여 attention 의 SlKS_l^KSlK​ 를 adaptively control zero 로 초기화 glg_lgl​ 은 부적합한 prompt 의 영향을 제거한 후 LLaMA 에 더 많은 instruction semantics 제공을 위해 크기를 증가시킬 수 있음 저자는 Eq 6 의 두 component 에 독립적으로 softmax function 을 적용하고, 첫 번째 항을 glg_lgl​ 로 곱함 Slg=[softmax(SlK)⋅gl; softmax(SlM+1)]T\\begin{equation} S^g_l = [\\text{softmax}(S_l^K) \\cdot g_l ; \\ \\text{softmax}(S_l^{M+1})]^T \\end{equation}Slg​=[softmax(SlK​)⋅gl​; softmax(SlM+1​)]T​​ separate softmax function 은 두 번째 항이 adaptation prompt 와 관련 없도록 보장 glg_lgl​ 이 거의 0에 가까울 때, 기존 LLaMA pre-trained knowledge 를 토큰 tlt_ltl​ 에 전달하여 생성 가능 attention 내의 독립적으로 학습되는 여러 glg_lgl​ 을 도입하여 multi-head 매커니즘의 학습 다양성을 촉진 어텐션 내에서 서로 독립적으로 학습되는 여러 gl을 도입하여 다중 헤드 메커니즘의 학습 다양성을 촉진합니다. 마지막으로, lll-th attention layer 의 output 을 linear projection layer 를 사용하여 계산 tlo=Linearo(SlgVl)∈R1×C\\begin{equation} t_l^o = \\text{Linear}_o (S_l^g V_l) \\in \\mathbb{R}^{1 \\times C} \\end{equation}tlo​=Linearo​(Slg​Vl​)∈R1×C​​ 위의 zero-initialized attention 을 사용하면, adaptation prompts 는 점진적으로 transformer 에 새로 습득한 instructional signals 을 주입하는 동시에 LLaMA 의 pre-trained knowledge 를 통합하여 고품질 response 제공 가능","s":"3.2 Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#32-zero-initialized-attention","p":452},{"i":465,"t":"text instruction 외에도, LLaMA-Adapter 는 다른 modalities input 에 대한 answering 능력이 존재 ScieneceQA 를 예로 들자. visualtextual contextsquestionoptionanswer visual context 로 input image 가 주어진 경우 pre-trained visual encoder CLIP 을 활용하여, multi-scale global feature 추출 {Im}m=1M\\{ I_m \\}^M_{m=1}{Im​}m=1M​ Im∈R1×CI_m \\in \\mathbb{R}^{1 \\times C}Im​∈R1×C MMM : scale number 이후 channel dimension 을 따라 MMM-scale features 를 연결하고 learnable proejction network 적용 Ip=Projection(Concat({Im}m=1M))\\begin{equation} I_p = \\text{Projection} \\left( \\text{Concat} ( \\{ I_m \\}^M_{m=1} ) \\right) \\end{equation}Ip​=Projection(Concat({Im​}m=1M​))​​ Ip∈R1×CI_p \\in \\mathbb{R}^{1 \\times C}Ip​∈R1×C 이는 adaptation prompts 와 동일한 feature dimension 을 갖는 전체 image token 으로 간주 IpI_pIp​ 를 KKK 번 반복하고, 이를 모든 inserted transformer layer LLL 의 KKK-length 의 adaptation prompt 에 요소별로 더함 lll-th layer 에 대해 획득한 multi-modal prompt 를 다음과 같이 나타냄 Plv=Pl+Repeat(Ip)∈RK×C\\begin{equation} P_l^v = P_l + \\text{Repeat}(I_p) \\in \\mathbb{R}^{K \\times C} \\end{equation}Plv​=Pl​+Repeat(Ip​)∈RK×C​​ PlvP_l^vPlv​ : image context 로부터의 visual information 을 통합한 adaptation prompt 위 과정을 통해 LLaMA 는 vision-language input 에 대한 response 를 생성하도록 fine-tuning 되고, multi-modal understanding 으로 어려운 generation task 도 처리 가능","s":"3.3 Multi-modal Reasoning","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#33-multi-modal-reasoning","p":452},{"i":467,"t":"zero-initialized attention 을 사용한 adaptation prompt 는 instruction model 에만 한정되지 않고, vision 및 language task 의 Large model 에도 활용 및 일반화 능력 발휘 가능","s":"3.4 Zero-initialized Attention for other Large Models","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#34-zero-initialized-attention-for-other-large-models","p":452},{"i":469,"t":"pre-trained ViT 를 활용하여 최상위 transformer layer LLL 개에 adaptation prompt 를 prefix 로 삽입 후, 모든 inserted layer 에 attention 작업을 zero-initialized 로 수정 ViT 를 고정한 채 모델의 일부 parameter 만 추가하고 VTAB-1k 벤치마크에서 full fine-tuning 과 유사한 결과 얻음","s":"Vision Models","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#vision-models","p":452},{"i":471,"t":"RoBERTa 를 활용하여 SQuAD QA task 에 zero-initialized attention 를 평가 P-tuning v2 위에 zero-initialized attention 을 구현 마찬가지로 fine-tuning 중 P-tuning v2 의 prompt token 과 저자의 zero gating factor 만 learnable 하게 설정 기존 language tasks 에서 우수성을 입증","s":"Language Models","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#language-models","p":452},{"i":475,"t":"Standord Alpaca 를 따라 52K instruction-following 활용, 175 instruction-output pairs 로 추가 확장 LLaMA-Adapter 를 8대 A100 GPU 에서 5 epoch fine-tuning warmup epoch 2 batch size 64 learning 0.009 weight decay 0.02 7B parameter 및 N=32N = 32N=32 transformer layer 를 가진 pre-trained LLaMA 사용 prompt length K=10K=10K=10 adaptation prompt 를 last L=30L=30L=30 layer 에 삽입 generation 단계 temperature 0.1 top-p=0.75\\text{top-p} = 0.75top-p=0.75 로 설정된 샘플링을 default decoding 로 설정 quantitative 평가 GPT-4 에게 80개 질문에 대한 instruction-following model 의 응답품질 평가하도록 요청 비교적 첫 번째 응답에 높은 점수 부여","s":"Settings","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#settings","p":452},{"i":477,"t":"Fig 4 에서 LLaMA-Adapter 와 Alpaca 의 response 비교 Alpaca 와 comparable 한 합리적은 응답 출력 Fig 6 에서 quantitative 결과 비교 GPT-4 평가에서 LLaMA-Adapter 가 비교적 많은 승리를 얻음 이를 통해 zero-initialized attention 메커니즘의 효과 입증","s":"Performance","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#performance","p":452},{"i":479,"t":"Table 1 에서 다양한 instruction-following 의 learnable parameter, 저장 공간 및 훈련 시간 비교 LLaMA-Adapter 는 1.2M parameter, 4.9M 저장 공간 및 1 시간 훈련으로 우수한 훈련 효율성 제공 모바일에서도 LLaMA 같은 LLM 을 fine-tuning 가능","s":"Efficiency","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#efficiency","p":452},{"i":482,"t":"Multi-modal 의 경우 input image 의 multi-sacle global feature 추출을 위해 CLIP 의 visual encoder 를 활용하여 learnable projection network 로 간단한 연속 MLP 사용 생성을 위한 ecoding 으로 greedy search 사용 다른 hyperparameter 는 LLaMA-Adapter 와 동일 ScienceQA 및 COCO Caption 에서 평가 visualtextual contextsquestionoptionanswer","s":"Settings","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#settings-1","p":452},{"i":484,"t":"LLaMA-Adapter 와 VQA methods 및 language models 를 ScienceQA 에서 비교 LLaMA-AdapterT_TT​ 는 1.2M Parameter 만으로 78.31% 성능 달성 0.6M 개 projection network 를 추가 주입하여 multi-modal 에 +6.88% 성능 향상 COCO Caption 에서는 BLIP 및 BLIP-2 같은 모델과 비교 많은 비용이 드는 모델들과 비교하여 LLaMA-Adapter 는 Caption 에서도 ClipCap 보다 나은 성능을 보임","s":"Performance","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#performance-1","p":452},{"i":487,"t":"transformer layer 에 삽입할 수를 조사. layer 수 증가시킬 수록 parameter 가 많아지지만 ScienceQA 에서 큰 성능 향상","s":"Insertion Layers","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#insertion-layers","p":452},{"i":489,"t":"zero-initialized 매커니즘은 LLaMA-Adapter 의 초기 훈련 중 안정성과 생성 능력에 필수 zero-initialized attention 으로 +43.08% 성능 향상 기여 반면 rand-init attention 은 40.77% 만 달성 Table 2 의 첫번 째 항인 Random Choice 와 동일한 성능 위는 zero-initialized attention 의 loss curves 로, rand-init attention 보다 더 빨리 수렴하고 더 낮은 loss 에 도달","s":"Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#zero-initialized-attention","p":452},{"i":491,"t":"LLM 의 fine-tuning data 는 보통 pre-trained 보다 작은 규모다. 이 때문에 over-fitting 방지를 위해 hyperparameter 조정에 조심해야 한다 위는 LLaMA-Adapter 가 over-fitting 에 상대적으로 견고함을 보여준다. 15 - 60 epoch 으로 변하는 과정에도 여전히 정확도가 상승하는 것을 볼 수 있다. 이는 parameter 가 가벼운 Adapter 만 학습하기 때문","s":"Robustness to Over-fitting","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#robustness-to-over-fitting","p":452},{"i":494,"t":"image classification 을 위해 ImageNet-21K dataset 에서 pre-trained ViT-B/16 을 fine-tuning VTAB-1K 사용하여 평가 진행 QA task 의 경우, RoBERTalarge_{large}large​ 모델을 SQuAD 에 평가 진행","s":"Settings","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#settings-2","p":452},{"i":496,"t":"저자의 approach 는 VPT 에 비해 각각 +3.26%, +2.00%, +1.77% 의 향상 SQuAD v1.1 및 v2.0 에서 zero-initialized attention 은 P-tuning v2 보다 향상","s":"Performance","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"#performance-2","p":452},{"i":498,"t":"LLaMA-Adapter 는 1.2M parameter 및 1시간의 훈련으로 Alpaca 와 comparable 훈련 안정성 및 좋은 성능을 위해 gating mamechanism 을 갖춘 zero-initialized attention 도입 instruction singal 을 적응적으로 통합 및 LLaMA 의 pre-trained knowledge 보존 multi-modal reasoning 을 잘 일반화하여 ScienceQA 및 COCO caption 에 comparable","s":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter","h":"","p":452},{"i":500,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2304.15010.pdf","s":"LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":502,"t":"최근 LLaMA-Adapter 가 LLMs 와 visual input 을 다루는 잠재력을 보여주지만 여전히 open-ended visual instruction 은 잘 처리하지 못하며 GPT-4 에 뒤쳐지고 있다. 본 논문에서는 parameter-efficient visual instruction model 인 LLaMA-Adapter V2 제안 LLaMA-Adapter 를 더 많은 learnable parameter (norm, bias 및 scale 등) 을 활용하여 보강 Adapter 외의 전체 LLaMA model 의 instruction-following 능력을 분산 visual token 을 early LLM layer 에만 주입하는 early fusion 전략을 제안 visual knowledge incorporation 개선 image-text pair 및 instruction-following data 의 joint training paradigm 을 도입 learnable parameter 의 분리된 그룹을 최적화 image-text alignment 및 instruction-following 두 작업 간의 간섭을 효과적으로 완화 소규모 image-text 및 instruction-following dataset 만으로 강력한 multi-modal reasoning 달성 inference 단계 LLaMA-Adapter 에 추가적인 expert models (e.g. captioning/OCR) 을 통합 training cost 발생하지 않고 image understanding 능력 더욱 향상 기존 LLaMA-Adapter 와 비교하여 LLaMA-Adapter V2 는 LLaMA 에 14M parameter 추가만으로 open-ended multi-modal instruction 수행ㅅ 가능 그리고 이 설계는 language-only instruction-following 을 더욱 강화시키며 채팅 상호작용에도 뛰어난 성능을 보임","s":"Abstract","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":504,"t":"최근 LLM 을 instruction-following model 로 변환하는 연구가 진행 Stanford Alpaca 는 InstructGPT model 로 생성된 instruction examples 를 사용하여 LLaMA 를 instruction-following model 로 fine-tuning 한다. LLaMA-Adapter 는 가벼운 Adapter 와 zero-initialized attention 의 도입으로 frozen LLaMA 에게 parameter-efficient fine-tuning 으로 multi-modal knowledge 를 주입한다. 가장 최근은 MiniGPT-4 및 LLaVA 같은 연구로, language-only instruction model 을 multi-modal 로 확장하여 visual reasoning 능력을 부여하는 새로운 연구 파동을 일으켰다. 본 논문은 parameter-efficient visual instruction model 설계를 목표로 한다. LLaMA-Adapter 기반의 새로운 method 인 LLaMA-Adapter V2 개발 LLaMA-Adapter 는 instruction-following model visual feature 를 adaptation prompts 로 주입하여 visual instruction model 로 변환 multi-modal instruction tuning data 의 부족으로 전통적인 vision-language model 로 제한됨 예로, COCO Caption 에서 훈련된 LLaMA-Adapter 는 \"“Generate caption for this image\" 같은 prompt 에 대해 짧은 caption 만 생성 가능 복잡한 visual reasoning 및 QA task 같은 open-ended multi-modal instruction 에는 adaptation 이 불가능 frozen LLaMA-Adapter 를 사용하여 image-text pairs 에서 visual projection layer 를 최적화하여 vision-language alignment 를 보장하도록 개선 visual feature 가 adaptation prompts 에 두드러지며 instruction-following 능력이 빠르게 저하되는 것 관찰 이를 대응하기 위해 image-text alignment 와 language instruction funing 두 가지 task 간의 간섭을 해결하는 간단한 early fusion of visual knowledge 제안 LLaMA-Adapter 의 dynamic visual prompts 는 last LLL layer 의 static adaptation prompts 에 통합 LLaMA-Adapter V2 에서는 dynamic visual prompt 를 처음 KKK layer 에만 분배 K<N−LK < N - LK<N−L NNN : total number of Transformer layers 이를 통해 image-text alignment 가 model 의 instruction-following 능력 방해하지 않음 joint training with disjoint parameter 고품질의 multi-modal instruction data 없이, image caption 및 instruction-following data 로 분리된 parameter 를 joint training 하여 우수한 visual instruction learning 가능 bias tuning of linear layers LLaMA-Adapter 를 normalization, layer bias 및 scale 같은 learnable parameter 를 unlocking 하여 보완 tunable capacity 를 증가시켜 instruction-following knowledge 를 LLM 전체에 분산 이러한 parameter 는 모델 전체의 약 0.04% 만 차지 이를 통해 parameter-efficient approach 유지 additional expert models (captioning, detection 및 OCR system) expert model 과 협력하여 LLaMA-Adapter V2 는 대규모 image-text pair 불필요 다양한 expert 를 plugging 가능하여 유연성 얻음 다음은 주요 기여 요약 Stronger Language Instruction Model parameter-efficient tuning 및 high-quality language instruction data 사용하여 LLaMA-Adapter 능가 Balanced Visual Instruction Tuning image-text alignment 와 instruction-following object 간의 간섭 해결을 위해 early fusion 전략 사용 multi-modal instruction training data 없이 captioning data 및 instruction-following data 의 분리된 parameter 를 joint training Integration of Expert Systems 다양한 expert model 통합","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":508,"t":"instruction-following 능력 습득을 위한 parameter-efficient fine-tuning LLaMA-Adapter 는 LLaMA 를 freezing 하고 1.2M 추가 adapter module 만 도입 adapter layer 는 LLaMA 의 Transformer layer 상단에 사용 leanable soft prompt set 을 word token 의 prefix 에 연결 new adapting knowledge 를 LLaMA 에 통합하기 위해 zero-initialized attention 사용 이를 통해 adaptation prompt word token 에 대한 기여를 학습 초기에 0으로 초기화된 gating factor 를 학습하여 조절 훈련 중 gating 크기는 점진적으로 커지며 LLaMA 에 주입 이 전략은 훈련 초기, LLaMA 의 언어 생성 능력을 보존하며 새로운 지식을 지속적으로 통합하여 강력한 instruction-following 능력을 만든다.","s":"Zero-initialized Attention","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#zero-initialized-attention","p":499},{"i":510,"t":"multi-modal reasoning 을 위해 image 및 video 통합 가능 pre-trained visual encoder 를 지닌 CLIP 으로 multi-scale visual feature 추출 learnable projection layer 를 통과하여 visual semantics 를 language embedding space 와 alignment 이후 visual feature 는 Transformer layer 상단에서 element-wisely added 위 과정으로 LLaMA-Adapter 는 text 및 visual input 을 기반으로 response 생성 가능하여 ScienceQA 에서 comparable","s":"Simple Multi-modal Variant","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#simple-multi-modal-variant","p":499},{"i":512,"t":"LLaMA-Adapter 를 사용하여 COCO Caption dataset 에서 adapter module 및 visual projection layer 를 fine-tuning 하는 실험 수행 새로운 visual 단서가 adaptation prompt 를 간섭하는 경향이 나타나 instruction-following feature 를 덮어버림. 따라서 LLaMA-Adapter V2 를 제안하여, multi-modal 잠재력을 완전히 발휘하도록 함","s":"Open-ended Multi-modal Reasoning","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#open-ended-multi-modal-reasoning","p":499},{"i":515,"t":"LLaMA-Adapter 는 zero-initialized attention 으로 adaptation prompt 를 frozen LLaMA 에 사용 이는 new knowledge 를 통합하지만 LLM 내부 parameter 를 수정하지 않고는 parameter update 가 adaptation prompt 및 gating factor 로 제한됨 이 때문에 deep fine-tuning 수행 능력이 제한된다. 이를 고려하여 더욱 효과적인 통합을 위해 bias tuning 전략 제안 instruction-following data 를 adaptively handle 하기 위해 LLaMA 의 모든 normalization layers 를 unfreezing Transformer 의 각 linear layer 에 대해 learnable parameter 로 bias 및 scale factor 추가 특정 linear layer 및 pre-trained weights 를 x\\text{x}x 및 WWW 로 표시 LLaMA-Adapter V2 에선, bias bbb 및 scale sss 를 사용하여 linear layer 수정 \\begin{align} y = W \\cdot \\text{x} \\rightarrow y = s \\cdot (W \\cdot \\text{x} + b), \\tag{1} \\\\ \\text{where} \\ b = \\text{Init}(0),\\ s = \\text{Init}(1). \\tag{2} \\end{align} bias 와 scale factor 는 각각 0 과 1 로 초기화하여 초기 단계에 안정화 bias tuning 및 high-quality instruction data 를 통합하여 우수한 instruction-following 능력을 얻음 특히, newly added parameter 는 전체 LLaMA 의 0.04% (약 5M) 만 차지 LLaMA-Adapter V2 는 여전히 highly parameter-efficient approach","s":"4.1 Bias Tuning of Linear Layers","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#41-bias-tuning-of-linear-layers","p":499},{"i":517,"t":"bias tuning 은 이전 parameter-efficient method 와 유사 BERT fine-tuning 을 위한 BitFit 및 visual prompt tuning 을 위한 SSF 가 있음 BitFit 및 SSF 는 80M parameter scale 을 가진 comprehension task 를 위해 설계 저자의 approach 는 70B - 650B parameter scale 의 LLM 에서 효율성 나타냄 bias tuning 은 input 에 독립적이며, row-rank 를 사용하여 input 에 의존적인 bias 를 추가하는 LoRA 와는 달리, fine-tuning 비용을 더 줄임","s":"Discussion","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#discussion","p":499},{"i":519,"t":"저자의 목표는 LLaMA-Adapter V2 에게 long language response 를 생성하는 능력과 multi-modal understanding 을 동시에 부여하는 것 저자는 LLaMA-Adapter V2 를 위해 image-text captioning data 및 language-only instruction examples 를 활용하기 위한 joint training paradigm 제안 500K image-text pairs 및 50K instruction data 사이의 데이터양 차이로 인해, instruction-following 능력에 피해가 갈 수 있음 따라서 이질적인 (disjoint) parameter groups 를 최적화 image-text captioning data : visual projection layer 및 초기 zero-initialized gating 과 관련된 부분만 학습 language instruction data : late adaptation prompts 와 zero gating, unfrozen norm 및 newly added bias 및 scale factor (선택적으로 low-rank adaptation) 가 사용 이를 통해 image-text understanding 과 instruction-following 간의 간섭 문제를 자연스럽게 해결","s":"4.2 Joint Training with Disjoint Parameters","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#42-joint-training-with-disjoint-parameters","p":499},{"i":521,"t":"joint training 전략 덕에 MiniGPT-4 와 LLaVA 같은 high-quality multi-modal instruction data 가 불필요 대신 image-text pairs 및 instruction-following 데이터만 요구 (Fig. 1 에서 비교) captioning data 는 Fig. 2 에서 처럼 short answers 를 포함하여 image understanding 에 대한 LLM 을 확장하는 역할을 해준다. 한편 language-only instruction data 는 long detailed sentences 를 생성할 능력을 보존하기 위해 사용한다. 위와 같은 상호보완적으로 조합하여 LLaMA-Adapter V2 는 high-quality instruction data 없이 소규모의 image-text 및 instruction-following data 만으로 우수한 multi-modal reasoning 을 달성","s":"Discussion","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#discussion-1","p":499},{"i":523,"t":"vision 및 language fine-tuning 간의 간섭을 피하기 위해, visual prompts 와 adaptation prompts 간의 직접적인 상호작용 방지를 위해 early fusion 제안 LLaMA-Adapter 에선 visual prompt input 이 frozen visual encoder 에 의해 순차적으로 encoding 되고 learnable visual projection layer 에 의해 추가되어 각 inserted layer 에 adaptation prompt 결합 LLaMA-Adapter V2 는 encoded visual tokens 와 adaptation prompt 를 서로다른 Transformer layer 에 fusing 하지 않고 삽입 dataset-shared adaptation prompts : LLaMA-Adapter 를 따라, last LLL layers (e.g. L=30L=30L=30) 에 삽입 input visual prompts : first Transformer layer with zero-initialized attention 에서의 word token 에 직접 연결 이 early fusion 으로 두 가지 fine-tuning target 간의 충돌을 효과적으로 해결하는데 도움되며, proposed joint training 과 함께 사용하여 우수한 multi-modal reasoning 능력을 가짐","s":"4.3 Early Fusion of Visual Knowledge","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#43-early-fusion-of-visual-knowledge","p":499},{"i":525,"t":"MiniGPT4 및 LLaVA 모델들은 visual model 과 LLM 연결을 위해 대규모 image-text 훈련이 필요 이에 반해, LLaMA-Adapter V2 는 작은 규모의 image captioning data 에 fine-tuning 하여 높은 data-efficient 하지만 이 방법의 image understanding 능력이 비교적 약하여 때로 부정확하거나 관련 없은 응답을 유발 더 많은 image-text data 수집 및 강력한 multi-modal module 도입 대신, caption, OCR 및 search engines 같은 expert system 을 통합하여 additional visual reasoning proficiency 을 부여하는 것을 제안 저자는 caption, detection 및 OCR 같은 expert system 으로 visual instruction-following 능력 향상 input image 를 고려하여 pre-trained visual encoder 를 사용하여 visual context 를 encoding 하고 expert system 에게 textual context 의 caption 을 생성하도록 요청 COCO Caption 에 pre-trainig 된 LLaMA-Adapter 를 expert system 으로 채택 어떠한 image 및 text model 또는 search engine 을 이 expert system 으로 사용할 수 있음을 주목 위 approach 는 특정 downstream task 에 따라 다양한 expert system 간에 쉽게 전환 가능","s":"4.4 Integration with Experts","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#44-integration-with-experts","p":499},{"i":529,"t":"LLaMA-Adapter V2 는 52K single-turn instruction data from GPT-4-LLM 및 567K captioning data from COCO Caption 에 훈련 MiniGPT-4 및 LLaVA 와 달리 어떠한 visual instruction data 도 사용하지 않음 또한 ShareGPT 의 80K conversation data 를 사용하여 chatbot system 훈련","s":"Training Data","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#training-data","p":499},{"i":531,"t":"32 Transformer layers 를 사용한 LLaMA-7B model 의 경우 static adaptation prompts 를 last 31 layers 에 삽입 dynamic visual prompts 는 prompt length 를 20으로 설정하고, 첫 번째 layer 에 삽입 normalization layers, linear layer bias 및 scalie 의 모든 parameter 는 training 중 update 되며, LLaMA 의 나머지 parameter 는 freezing 유지","s":"Implementation Details","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#implementation-details","p":499},{"i":533,"t":"bias tuning 및 high-quality instruction data 를 사용한 LLaMA-Adapter V2 는 LLaMA 의 instruction-following 능력을 향상 Table 1 의 결과에서 처럼, LLaMA-Adapter V2 는 인간의 지시에 포괄적인 답변과 상세한 설명 제공 knowledge updating 을 위해 bias tuning 에 더 많은 learnable parameter 를 수반했을 때, language context 에 대한 깊은 이해가 필요한 chatbot system 도 구축이 가능했다. 80K conversation data 를 훈련시키면, 더 강력한 chatbot model 개발 Fig. 11 은 7B 의 chatbot examples 이며, 시스템은 질문에 대답하지만 문맥 이해는 그리 정확하진 않다. 모델을 65B 으로 확장하면 (Fig. 10), chatbot 은 더욱 강력하고 대답도 잘 한다. Fig. 5 에서는 GPT-4 를 사용하여 response quality 평가. LLaMA-Adapter V2 는 total score 및 50/80 qustions 에 대해 ChatGPT 를 이기는 성능 보임","s":"5.2 Stronger Language Instruction Model","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#52-stronger-language-instruction-model","p":499},{"i":535,"t":"LLaMA-Adapter 는 주로 language instruction model / close-set vision-language model 인 반면, LLaMA-Adapter V2 는 caption 및 language-only instruction data 에 joinly training 한 강력한 vision instruction model. 이번 섹션에서 LLaMA-Adapter V2 의 image captioning 능력 및 어떻게 GPT-4 같은 일반적인 목적의 multi-modal understanding 시스템으로 확장하는지 보여줌. 또한 expert system 을 통합하여 instruction-following 능력을 더욱 향상","s":"5.3 Visual Instruction Model","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#53-visual-instruction-model","p":499},{"i":537,"t":"LLaMA-Adapter 는 단순히 adaptation prompts 에 visual feature 를 추가하여 multi-modal input 을 지원. COCO Caption dataset 에 fine-tuning 후, 강력한 image captioning model 로 변했다. 위 결과에서 LLaMA-Adapter 가 대규모 image-text pretraining 없이 BLIP 과 comparable 결과 달성하는 것 관찰. 하지만 LLM 능력을 재사용 불가능 및 특정 prompt (e.g. Generate caption for this image) 에는 민감하게 된다. early fusion 및 joint training 사용으로, LLaMA-Adapter V2 는 language instruction-following 및 image captioning 이 동시에 수행 가능한 강력한 visual instruction model 이 됐다. 위에서 LLaMA-Adapter 및 LLaMA-Adapter V2 의 image captioning 결과를 비교한다. LLaMA-Adatper 는 대답이 짧은 반면 LLaMA-Adatper V2 는 natural 하고 detail 한 설명을 생성한다. Failure Case 를 보면, 의도적으로 분포 밖의 예제 (카툰풍)을 선택했을 때 항상 정확한 이미지 설명을 생성하진 않음을 볼 수 있다. 이는 image-text alignment stage 가 부족한 것일 수 있다.","s":"Image Captioning","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#image-captioning","p":499},{"i":539,"t":"Fig. 7 에서 보이듯, image content 에 대한 prompt 를 \"why is ...\" 및 \"what should ...\" 같은 형태로 질문했을 경우, 모델은 visual information 을 language context 와 통합하여 더 복잡한 reasoning 및 decision 을 하는 것을 볼 수 있다. image 에서 question 이 참조하는 객체나 특징을 식별하고 설명하며, context 기반으로 관련 정보나 제안을 해준다. 이는 image-text pairs 와 instruction data 간의 간섭을 해결하는 효과를 보여주며, language 및 vision understanding 이 모두 필요한 현실 세계 응용에 대한 잠재력을 보여준다.","s":"Visual Understanding","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#visual-understanding","p":499},{"i":541,"t":"visual understanding 향상을 위해, inference 중 visual expert models 를 통합하여 추가적인 textual contexts 를 제공 Fig. 8 에서 caption expert 를 포함한 LLaMA-Adapter V2 를 보여준다. image 의 visual contents 에 대한 정확하고 상세한 설명을 생성한다. Fig. 9 에서 DocVQA 의 OCR expert 를 사용한 예제를 볼 수 있다. image 에서 감지된 text 를 활용하여 안경의 가격 같은 구체적인 단서로 질문에 대한 정확한 답변을 생성.","s":"Integration with Experts","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"#integration-with-experts","p":499},{"i":543,"t":"본 연구는 parameter-efficient visual instructions tuning system 인 LLaMA-Adapter V2 제안 joint training on image-text pairs 및 instruction-following data 이를 통해, pre-trained LLM 을 zero-shot visual instruction model 로 변환 zero-shot visual instruction-following 은 image-text pairs 와 instruction-following data 간의 간섭을 줄여 더욱 향상 chatbot 과 같이 강력한 multi-turn dialog 능력을 보유 부정확한 이미지 설명 문제 해결을 위해 expert system 과 통합 expert 통합으로 zero-shot instruction-following 은 수행 understanding 은 LLaVA 보다 뒤쳐지며, expert 로부터의 부정확한 정보 영향을 받을 수 있음 이후 visual-following 향상을 위해 multi-modal instruction dataset 또는 다른 PEFT 방법을 통한 fine-tuning 방법 탐구","s":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/LLaMA-Adapter V2","h":"","p":499},{"i":545,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2106.09685.pdf","s":"LoRA: Low-Rank Adaptation of Large Language Models","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":547,"t":"GPT-3 175B 의 파라미터를 fine-tuning 하기에는 매우 부담. 이에 저자는 Low-Rank Adaptation, LoRA 제안 pre-trained model weights 를 freeze Transformer layer 에 trainable rank decomposition 을 주입 downstream task 에 대한 trainable parameter 를 매우 크게 줄임 Adam 으로 fine-tuning 한 GPT-3 175B 와 비교하여, LoRA 는 trainable parameter 수를 10,000배 줄이고 GPU 메모리 요구사항 3배 줄임 RoBERTa, DeBERTa, GPT-2 및 GPT-3 에서도 더 좋은 성능 LoRA 는 adapter 와 달리, 추가적인 inference latency 없음 language model (LM) 의 adaptation 에서 rank-deficiency 에 대한 경험적 연구 제공하여 LoRA 의 효과 제공","s":"Abstract","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":549,"t":"보통 multiple downstream 에 적응하기 위해 하나의 LLM 에 의존한다. task 에 adaptation 할 때 일반적으로 fine-tuning 을 하지만, 모든 파라미터를 훈련하는 것이 큰 단점이다. 이에, 몇몇 파라미터만 adapting 하거나 new task 를 위한 외부 모듈을 학습하는 시도도 있다. task 마다 pre-trained model 에 적은 수의 task-specific parameter 를 저장하고 로드하여, 모델 사용 시 효율이 향상한다. 하지만, depth 확장이나 sequence 길이를 줄이는 등 모델 품질과 효율성간의 trade-off 설정이 힘들다. 저자는 이전 연구에서 learned over-parameterized models 이 사실은 low intrinsic dimension 에 존재한다는 것을 보고 영감을 받았다. model adaptation 중 weight 의 변화가 낮은 \"intrinsic rank\" 를 가질 것이라는 가설을 기반으로 Low-Rank Adaptation (LoRA) approach 를 제안 pre-trained weights 를 고정한 채, model adaptation 중 dense layer 의 변화에 대한 rank decomposition matrices 를 최적화하여 신경망의 일부 dense layer 를 간접적으로 학습하게 함 예로, GPT-3 175B 사용 시, LoRA 를 사용하면 low rank 는 full rank (ddd) 가 12,288 와 같아도 충분 이로써 LoRA 는 저장 및 계산 효율적 LoRA 핵심 이점 pre-trained model 은 여러 task 에 대해, 매우 작은 LoRA 모듈을 구축하여 공유 및 사용 가능 shared model 을 freeze 하고 Fig 1 의 행렬 AAA 와 BBB 를 교체하여 task 를 효율적으로 전환 저장 요구사항 및 task-switching overhead 크게 줄임 LoRA 는 adaptive optimizer 를 사용할 때 더 효율적인 학습 가능 및 hardware barrier 3배 줄임 대부분의 parameter 에 대한 optimizer states 를 유지하거나 gradient 계산 불필요 주입된 smaller low-rank matrices 만 최적화 이 설계는 사용 시, trainable matrices 및 frozen weights 를 병합할 수 있게 함 full fine-tuned model 과 비교하여, inference latency 가 없음 LoRA 는 이전 방법들과는 독립적 그리고 prefix-tuning 같은 다양한 방법과 결합 가능","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":551,"t":"Transformer 아키텍처를 빈번히 언급하니, 이 차원에 대한 용어 사용 Transformer layer 의 input 및 output dimensions : dmodeld_{model}dmodel​ self-attention module query/key/value/output projection matrix : WqW_qWq​, WkW_kWk​, WvW_vWv​, WoW_oWo​ pre-trained weight matrix : WWW 및 WOW_OWO​ adaptation 중인 accumulated gradient update : △W\\triangle W△W LoRA Module : rrr Transformer MLP feedforward dimension : dffn=4×dmodeld_{ffn} = 4 \\times d_{model}dffn​=4×dmodel​","s":"Terminologies and Conventions","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#terminologies-and-conventions","p":544},{"i":553,"t":"LoRA 는 training objective 와 상관없이 모두 사용가능하지만, 본 논문은 LM 에 focus 하여 설명 GPT 같은 pre-trained autogressive LM Pϕ(y∣x)P\\phi(y|x)Pϕ(y∣x) 가 있다 가정 downstream task 는 context-target paris 데이터셋이 있다면, Z={(xi,yi)}i=1,…,N,\\mathcal{Z} = \\{ (x_i, y_i) \\}_{i=1, \\dots,N,}Z={(xi​,yi​)}i=1,…,N,​ 로 표현 xix_ixi​ 및 yiy_iyi​ : token sequence 기존 fine-tuning 은, pre-trained weight ϕ0\\phi_0ϕ0​ 로 초기화 후 objective 최대화를 위해 gradient 를 반복적으로 업데이트하여 ϕ0+△ϕ\\phi_0 + \\triangle \\phiϕ0​+△ϕ max⁡ϕ∑(x,y)∈Z∑t=1∣y∣log⁡(Pϕ(yt∣x,y<t))(1)\\underset{\\phi}{\\max} \\sum_{(x,y) \\in \\mathcal{Z}} \\sum_{t=1}^{|y|} \\log (P_{\\phi}(y_t | x, y_{<t})) \\tag{1}ϕmax​(x,y)∈Z∑​t=1∑∣y∣​log(Pϕ​(yt​∣x,y<t​))(1) full fine-tuning 의 단점은 각 downstream task 마다 차이가 있는 parameter set △ϕ\\triangle \\phi△ϕ 을 학습한다는 것 이 parameter 의 dimension ∣△ϕ∣|\\triangle \\phi|∣△ϕ∣ 는 ∣ϕ0∣|\\phi_0|∣ϕ0​∣ 과 동일 따라서 pre-trained model 이 크면 fine-tuned model 을 저장하고 배포하기에 실용성 없음 본 논문은 parameter-efficient approach 를 채택 task-specific parameter 의 증가 △ϕ=△ϕ(θ)\\triangle \\phi = \\triangle \\phi (\\theta)△ϕ=△ϕ(θ) 는 더 적은 크기의 parameter set θ\\thetaθ 로 적절히 인코딩 (∣θ∣≪∣ϕ0∣|\\theta| \\ll |\\phi_0|∣θ∣≪∣ϕ0​∣) 따라서 △ϕ\\triangle \\phi△ϕ 를 찾는 것은 θ\\thetaθ 의 최적화 max⁡θ∑(x,y)∈Z∑t=1∣y∣log⁡(Pϕ0+△ϕ(θ)(yt∣x,y<t))(2)\\underset{\\theta}{\\max} \\sum_{(x,y) \\in \\mathcal{Z}} \\sum_{t=1}^{|y|} \\log (P_{\\phi_0 + \\triangle \\phi(\\theta)} (y_t | x, y_{<t})) \\tag{2}θmax​(x,y)∈Z∑​t=1∑∣y∣​log(Pϕ0​+△ϕ(θ)​(yt​∣x,y<t​))(2)","s":"2. Problem Statement","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":555,"t":"기존 연구에서도 PEFT 를 다루었다. adapter layer 추가 및 input layer 일부 형태를 최적화하는 등이 있었다. 하지만 large-scalie 및 latency 에 제한사항이 있었다.","s":"3. Aren't Existing Solutions Good Enough?","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":557,"t":"여러 adapter 가 있지만 다음 두 연구에 중점을 둠 [Parameter-Efficient Transfer Learning for NLP.] : Transformer 블록당 두 개의 adapter layer [Exploring versatile generative language model via parameter-efficient transfer learning.] : 블록당 하나의 adapter layer 와 추가적인 LayerNorm layer 및 multitask 에 활용하여 전체 latency 는 줄지만, adapter layer 의 추가 계산은 못피함. adapter layer 는 작은 bottleneck dimension 을 가지고 있어 few parameter (모델의 < 1%) 를 가지도록 설계되어 추가 FLOPs 가 제한됨 하지만 Transformer 는 latency 를 낮추기 위해 하드웨어 병렬처리를 사용하지만 adapter layer 는 순차처리하게 되어 Table 1 을 보면 추가 작업이 증가한 것을 볼 수 있다.","s":"Adapter Layer Introduce Inference Latency","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#adapter-layer-introduce-inference-latency","p":544},{"i":559,"t":"이 방법엔 대표적으로 prefix tuning 가 이쓴데, 최적화가 어렵고 성능이 단조적으로 증가하지 않고 진동하는 경우가 논문에서 관측된다. 근본적으로 sequence 의 일부를 adaptation 을 위해 보류해야 하여 downstream 처리 시 sequence 길이가 줄어들어 효과가 덜하다는 것이 한계","s":"Directly Optimizing the Prompt is Hard","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#directly-optimizing-the-prompt-is-hard","p":544},{"i":561,"t":"본 논문은 Transformer 에 초점을 두지만, 다른 딥러닝에도 적용 가능","s":"4. Out Method","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":563,"t":"많은 network 의 dense layers 는 행렬곱으로 이루어져 있다. 그리고 이 weight matrices 는 보통 full-rank 를 가진다. 기존 연구에서, specific task 에 adapting 중, pre-trained LM 이 \"low instrisic dimension\" 을 가지며 더 적은 subspace 으로의 random projection 에도 여전히 효과적인 학습을 하는 것을 보여준다. pre-trained weight matrix W0∈Rd×kW_0 \\in \\mathbb{R}^{d \\times k}W0​∈Rd×k 의 경우 이를 low-rank decomposition W0+△W=W0+BAW_0 + \\triangle W = W_0 + BAW0​+△W=W0​+BA 로 표현 여기서 B∈Rd×rB \\in \\mathbb{R}^{d \\times r}B∈Rd×r, A∈Rr×kA \\in \\mathbb{R}^{r \\times k}A∈Rr×k rank rrr 은 r≪min⁡(d,k)r \\ll \\min (d, k)r≪min(d,k) training 중 W0W_0W0​ 는 freeze 및 gradient update 하지 않음 AAA 및 BBB 는 trainable parameter 를 포함 W0W_0W0​ 및 △W=BA\\triangle W = BA△W=BA 는 동일한 input 과 곱해자며, 각 output vectors 는 coordinate-wise 로 합산 h=W0xh = W_0xh=W0​x 에 대한 forward pass 는 다음과 같다. h=W0x+△Wx=W0x+BAx(3)h = W_0x + \\triangle Wx = W_0x + BAx \\tag{3}h=W0​x+△Wx=W0​x+BAx(3) AAA 는 random Gaussian 및 BBB 는 0 으로 초기화하여 △W=BA\\triangle W = BA△W=BA 는 training 에 0 으로 시작 이후 αr\\frac{\\alpha}{r}rα​ 으로 △W\\triangle W△W 를 scaling α\\alphaα 는 rrr 에 대한 상수 Adam 으로 최적화 시, α\\alphaα 를 tuning 하는 것은 초기화를 적절히 scaling 하는 것과 동일 이 scaling 은 rrr 을 변화시킬 때 hyperparameter 를 retuning 할 필요를 줄이는데 도움","s":"4.1 Low-Rank-Parameterized Update Matrices","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#41-low-rank-parameterized-update-matrices","p":544},{"i":565,"t":"모든 weight matrices 및 bias 에 LoRA 적용하여 훈련 시, full-rank → r-rank 을 통해 효율적인 학습이 가능하다. 하지만 한계점으로, MLP 가 필요하며 prefix-tuning 기반 방법의 경우 long input sequence 가 있어야 한다.","s":"A Generalization of Full Fine-tuning","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#a-generalization-of-full-fine-tuning","p":544},{"i":567,"t":"다른 downstream task 에 적용할 시, BABABA 대신 B′A′B'A'B′A′ 를 추가하여 빠른 작업 및 적은 메모리가 가능 이는 추가적인 inference latency 가 없음을 보장","s":"No Additional Inference Latency","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#no-additional-inference-latency","p":544},{"i":569,"t":"Transformer 에는 4 가지 weight matrix 가 있다. self-attention module (WqW_qWq​, WkW_kWk​, WvW_vWv​, WoW_oWo​) Encoder 및 Decoder 각각의 MLP module simplicity 및 parameter-efficiency 를 위해서, 위 둘 중 attention weight 의 adapting 만 연구하는 것으로 제한하며 MLP 는 freeze 한다. (downstream task 에서 훈련되지 않도록)","s":"4.2 Applying LoRA to Transformer","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#42-applying-lora-to-transformer","p":544},{"i":571,"t":"가장 큰 이점은 메모리 및 저장 공간 사용량 감소 Large Transformer 를 Adam 으로 훈련하는 경우 frozen parameter 에 대한 states 를 저장할 필요가 없어, r≪dmodelr \\ll d_{model}r≪dmodel​ 일 경우 최대 2/3 VRAM 사용량 감소 GPT-3 175B 의 VRAM 소비를 1.2TB 에서 350B 로 줄임 r=4r = 4r=4 이고 WqW_qWq​ 및 WvW_vWv​ 만 adapting 하는 경우 checkpoint 크기가 10,000배 감소 (350GB → 35MB) 대부분의 parameter 에 gradient 계산이 필요 없어, GPT-3 175B 훈련 중 25% 속도 향상 LoRA 는 한계점 또한 존재 서로 다른 task 에 사용 시, B′A′B'A'B′A′ 를 동적으로 선택해야 함","s":"Practical Benefits and Limitations","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#practical-benefits-and-limitations","p":544},{"i":573,"t":"RoBERTa, DeBERTa 및 GPT-2 에도 LoRA 실험 task 또한 natural language understanding (NLU), generation (NLG), WikiSQL (SQL queries), SAMSum (conversation summarization) 등 다양하게 실험","s":"5. Empirical Experiments","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":575,"t":"이전 연구의 설정을 재사용","s":"5.1 Baselines","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#51-baselines","p":544},{"i":577,"t":"일반적인 approach 이며, 마지막 두 layer 만 적응한 것을 FTTop2\\text{FT}^{Top2}FTTop2 로 표현","s":"Fine-Tuning (FT)","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#fine-tuning-ft","p":544},{"i":579,"t":"bias vectors 만 훈련하고 제외한 다른 것들은 freezing","s":"Bias-only or BitFit","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#bias-only-or-bitfit","p":544},{"i":581,"t":"input token 사이에 special token 을 삽입하는 것으로, 어디에 배치할지에 따라 성능이 달라진다. 저자는 \"prefixing\" 및 \"infixing\" 에 중점을 두고 실험 trainable parameter 는 ∣θ∣=dmodel×(lp+li)|\\theta| = d_{model} \\times (l_p + l_i)∣θ∣=dmodel​×(lp​+li​) lpl_plp​ : prefix lil_ili​ : infix","s":"Prefix-embedding tuning (PreEmbed)","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#prefix-embedding-tuning-preembed","p":544},{"i":583,"t":"prefix-embedding tuning 의 확장으로, word embedding 학습하는 대신 Transformer layer 이후의 activation 을 학습 이전 layer 로부터의 계산된 activation 은 학습 가능한 activation 으로 대체 trainable parameter 는 ∣θ∣=L×dmodel×+(lp+li)|\\theta| = L \\times d_{model} \\times + (l_p + l_i)∣θ∣=L×dmodel​×+(lp​+li​) LLL : Transformer layers number","s":"Prefix-layer tuning (PreLayer)","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#prefix-layer-tuning-prelayer","p":544},{"i":585,"t":"self-attention 과 residual connection 사이에 adapter layer 삽입 adapter layer 는 두 fully connected layer 와 bias 중간에 nonlinearity 로 구성되어 있다. 이 디자인을 AdapterH\\text{Adapter}^HAdapterH 라 부른다. adapter layer 를 MLP module 이후와 LayerNorm 이후에만 적용한 디자인도 있으며, AdapterL\\text{Adapter}^LAdapterL 라 부른다. 다른 설계로 Adapter-fusion 이 있으며 이는 AdapterP\\text{Adapter}^PAdapterP 로 부른다. 더 큰 효율성을 위해 일부 adapter layer 를 제거한 AdapterD\\text{Adapter}^DAdapterD 도 있다. 위 모든 케이스에서, 실험에선 ∣θ∣=L^Adpt×(2×dmodel×r+r+dmodel)+2×L^LN×dmodel|\\theta| = \\hat{L}_{Adpt} \\times (2 \\times d_{model} \\times r + r + d_{model}) + 2 \\times \\hat{L}_{LN} \\times d_{model}∣θ∣=L^Adpt​×(2×dmodel​×r+r+dmodel​)+2×L^LN​×dmodel​ 를 가짐 L^Adpt\\hat{L}_{Adpt}L^Adpt​ : adapter layer 수 L^LN\\hat{L}_{LN}L^LN​ : trainable LayerNorms 수","s":"Adapter tuning","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#adapter-tuning","p":544},{"i":587,"t":"기존 weight matrices 를 rank decomposition matrices 의 trainable pairs 를 추가 위에서 언급했듯이, 간단함을 위해 WqW_qWq​ 와 WvW_vWv​ 에만 LoRA 를 적용 trainable parameter : ∣θ∣=2×L^LoRA×dmodel×r|\\theta| = 2 \\times \\hat{L}_{LoRA} \\times d_{model} \\times r∣θ∣=2×L^LoRA​×dmodel​×r L^LoRA\\hat{L}_{LoRA}L^LoRA​ : LoRA 를 적용한 weight matrices 수","s":"LoRA","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#lora","p":544},{"i":589,"t":"RoBERTa 에서 LoRA 는 task 성능을 향상 시킴 HuggingFace Transformers 의 pre-trained RoBERTa base (125M) 및 RoBERTa large (335M) 사용 모든 task 는 동일한 배치 크기 및 128 sequence length MRPC, RTE 및 STS-B 의 경우 MNLI 에 adapted model 이 아닌 pre-trained model","s":"5.2 RoBERTa Base/Large","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#52-roberta-baselarge","p":544},{"i":591,"t":"DeBERTa 는 훨씬 큰 규모로 training 되어 GLUE 및 SuperGLUE 에 큰 성능 발휘 LoRA 는 DeBERTa XXL 에서도 여전히 성능 향상","s":"5.3 DeBERTa XXL","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#53-deberta-xxl","p":544},{"i":593,"t":"LoRA 가 NLU 에서 full fine-tuning 과 경쟁력있는 대안으로 보여, GPT-2 medium 및 large 에서도 우세한지 확인","s":"5.4 GPT-2 Medium/Large","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#54-gpt-2-mediumlarge","p":544},{"i":595,"t":"GPT-3 175B parameter 로 확장 Table 4 에서 보이듯, 3가지 데이터셋 모두 FT 와 비슷하거나 능가 Fig 2 에서 보이듯, 일부 방법은 더 많은 special token (prefix-embedding tuning 은 256개 이상 또는 prefix-layer tuning 의 경우 32개 이상)을 사용 시 성능 저하","s":"5.5 Scaling up to GPT-3 175B","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#55-scaling-up-to-gpt-3-175b","p":544},{"i":598,"t":"LoRA 에 대해 더 잘 이해할 수 있도록 경험적 실험들을 설명. 이에 대한 세 가지 질문이 있다. pre-trained Transformer 의 어떠한 가중치 행렬에 LoRA 를 적용해야 가장 높은 성능을 얻을까? 최적의 rank rrr 는 무엇일까? adaptation matrix △W\\triangle W△W 와 WWW 간의 상관관계","s":"7. Understanding the Low-Rank Updates","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":600,"t":"이전에, attention module 에만 고려했다고 언급했다. GPT-3 175B 의 경우, 1개의 attention weight 만 adapting 하면 r=8r = 8r=8 에 해당하는 18M (약 35MB 저장)의 parameter 를 설정하며, 2개의 attention weight 을 adapting 하면 r=4r = 4r=4 에 해당하는 parameter 를 모든 96개 layer 에 적용하게 된다. (Table 5) 모든 parameter 를 △Wq\\triangle W_q△Wq​ 또는 △Wk\\triangle W_k△Wk​ 에 두면 성능이 크게 저하되지만, WqW_qWq​ 및 WvW_vWv​ 둘 다 adapting 하면 최상의 결과를 얻는다. 이를 통해 rank 를 4 로 두면 충분히 △W\\triangle W△W 의 정보를 담을 수 있음을 시사한다.","s":"7.1 Which Weight Matrices in Transformer Should We Apply LoRA To?","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#71-which-weight-matrices-in-transformer-should-we-apply-lora-to","p":544},{"i":602,"t":"놀랍게도 매우 작은 rrr 에서도 LoRA 는 경쟁력있는 성능을 발휘했다. ({Wq,Wv}\\{ W_q, W_v \\}{Wq​,Wv​} 보다 WqW_qWq​ 에 더 많은 영향) 이는 update matrix △W\\triangle W△W 가 매우 작은 \"intrinsic rank\" 를 가질 수 있음을 시사","s":"7.2 What is the Optimal Rank rrr For LoRA?","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#72-what-is-the-optimal-rank-r-for-lora","p":544},{"i":604,"t":"Ar=8A_{r=8}Ar=8​ 및 Ar=64A_{r=64}Ar=64​ 가 주어졌을 때, 동일한 pre-trained model 을 사용하여 singular value decomposition (SVD) 수행하고 right-singular unitary matrices UAr=8U_{A_{r=8}}UAr=8​​ 및 UAr=64U_{A_{r=64}}UAr=64​​ 를 얻음 이때 UAr=8U_{A_{r=8}}UAr=8​​ (1≤i≤81 \\leq i \\leq 81≤i≤8) 의 top iii singular vectors 로 구성된 subspace 중, UAr=64U_{A_{r=64}}UAr=64​​ (1≤i≤641 \\leq i \\leq 641≤i≤64) 의 top jjj singular vectors 의 subspace 에 얼마나 포함되었을 까? 이를 Grassmann distance 기반으로 정규화된 subspace similarity 를 측정 ϕ(Ar=8,Ar=64,i,j)=∣∣UAr=8i⊤UAr=64j∣∣F2min⁡(i,j)∈[0,1](4)\\phi (A_{r=8}, A_{r=64}, i, j) = \\frac{|| U^{i\\top}_{A_{r=8}} U^{j}_{A_{r=64}} ||^2_F}{\\min (i, j)} \\in [0,1] \\tag{4}ϕ(Ar=8​,Ar=64​,i,j)=min(i,j)∣∣UAr=8​i⊤​UAr=64​j​∣∣F2​​∈[0,1](4) UAr=8i⊤U^{i\\top}_{A_{r=8}}UAr=8​i⊤​ : top-iii singular vectors 에 해당하는 UAr=8U_{A_{r=8}}UAr=8​​ 의 columns ϕ(⋅)\\phi ( \\cdot )ϕ(⋅) 는 [0,1][0,1][0,1] 범위 1 은 subspace 에 완전한 중첩 0 은 완전한 분리 iii 및 jjj 를 변화시키면 ϕ\\phiϕ 가 어떻게 변하는 지는 Fig 3 참고 위를 통해 다음 주요 관찰을 할 수 있다. Ar=8A_{r=8}Ar=8​ 의 △Wv\\triangle W_v△Wv​ (또는 △Wq\\triangle W_q△Wq​) 와 Ar=64A_{r=64}Ar=64​ 의 △Wv\\triangle W_v△Wv​ (또는 △Wq\\triangle W_q△Wq​) 는 dimension 1 의 subspace 를 공유하며 normalized similarity >0.5> 0.5>0.5 이며, 이것이 GPT-3 에 r=1r = 1r=1 잘 동작하는 이유","s":"Subspace similarity between different rrr","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#subspace-similarity-between-different-r","p":544},{"i":606,"t":"r=64r = 64r=64 로 무작위 seed 로 실행된 두 normalized subspace similarity 를 Fig 4 에서 확인 △Wq\\triangle W_q△Wq​ 는 △Wv\\triangle W_v△Wv​ 보다 높은 \"intrinsic rank\" 를 가질 것으로 보이며, △Wq\\triangle W_q△Wq​ 에 대한 두 실행 모두 학습된 common singular value direction 이 더 많이 있어, Table 6 의 관찰과 일치","s":"Subspace similarity between different random seeds","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#subspace-similarity-between-different-random-seeds","p":544},{"i":608,"t":"저자는 △W\\triangle W△W 와 WWW 간의 상관관계를 더욱 조사. WWW 는 △W\\triangle W△W 의 rrr-dimensional subspace 에 U⊤WV⊤U^{\\top}WV^{\\top}U⊤WV⊤ 를 계산하여 project 여기서 U/VU/VU/V 는 △W\\triangle W△W 의 left/right singular-vector matrix 이다. 이후, ∣∣U⊤WV⊤∣∣F||U^{\\top}WV^{\\top}||_F∣∣U⊤WV⊤∣∣F​ 와 ∣∣W∣∣||W||∣∣W∣∣ 간의 Frobenius norm 비교 비교를 위해 U,VU, VU,V 를 WWW 의 top rrr singular vectors 또는 random matrix 로 대체하여 ∣∣U⊤WV⊤∣∣F||U^{\\top}WV^{\\top}||_F∣∣U⊤WV⊤∣∣F​ 계산 위 Table 에서 다음 결론을 얻을 수 있음 △W\\triangle W△W 는 random matrix 와 비교하여, WWW 와 더 강한 상관관계를 가지며, △W\\triangle W△W 는 이미 WWW 에 있는 일부 기능을 강화 WWW 의 top singular direction 을 반복하는 대신, △W\\triangle W△W 는 WWW 의 강조되지 않은 direction 만을 강화 증폭 계수가 매우 큼: r=4r = 4r=4 에 대해, 21.5≈6.91/0.3221.5 \\approx 6.91/0.3221.5≈6.91/0.32","s":"7.3 How Does the Adaptation Matrix △W\\triangle W△W Compare To WWW?","u":"/docs/Paper/NLP/PEFT/LoRA","h":"#73-how-does-the-adaptation-matrix-triangle-w-compare-to-w","p":544},{"i":610,"t":"LLM 을 fine-tuning 하는 것인 많은 비용 및 시간이 듬 본 연구의 LoRA 라는 방법을 통해 inference latency 을 줄이며 sequence length 를 줄이지 않는 전략 대부분의 model parameter 를 공유하여 배포도 용이 Future work LoRA 를 다른 adaptation method 와 결합하여 개선 가능 fine-tuning 또는 LoRA 의 숨겨진 메커니즘 LoRA 를 adapting 할 weight matrix 선택 △W\\triangle W△W 의 rank 축소 가능한지 여부","s":"8. Conclusion And Future Work","u":"/docs/Paper/NLP/PEFT/LoRA","h":"","p":544},{"i":612,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.02861.pdf","s":"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":614,"t":"Prompt tuning : pre-trained model 을 각 task 에 맞게 adapt 하는 방법. 학습된 prompt vector 에 의존하여 Large Language Model (LLM) 을 다양한 downstream task 에 효율적으로 adapt 하는 approach 로 등장. 기존 방법은 처음부터 soft prompt vectors 를 학습 multitask 에서 풍부한 cross-task knowledge 를 어떻게 활용해야 하는지 명확하지 않음 이에 저자는 다음을 제안 multitask prompt tuning (MPT) multiple task-specific source prompt 로 distilling knowledge 를 하여, single transferable prompt 를 학습 각 downstream target task 에 효율적으로 adapt 하기 위해 shared prompt 에 multiplicative low rank updates 를 학습 23개 데이터셋에 실험 결과, 최근 approach / method 와 비교하여 우수한 성능 보여줌 특정 경우엔, task-specific parameter 의 0.035% 만 tuning 하여, full finetuning baseline 을 능가","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":616,"t":"Finetuning pretrained language models (PLMs) 은 downstream task 에 큰 성능 향상을 이끌어 냄 하지만, full task-specific finetuning (FT) 은 현재 PLM 이 수십억 개의 파라미터로 인해 적용하기 어려워지고 있어, 효율적인 방법에 관심이 늘어나고 있다. 본 연구는 task 당 추가 파라미터를 적은 수로만 학습하여 full finetuning 과 비슷한 성능 달성을 목표 Prompt tuning (PT) 는 tunable continuous prompt vectors 를 앞에 덧붙여, PLM 에 parameter-efficient transfer learning 하는 approach 가 등장 PT 는 PLM 파라미터를 고정하고 task-specific prompt vectors 만 학습 여전히 full finetuning 과 큰 격차라 존재 초기화에 민감하며 때로는 full finetuning 보다 많은 훈련 시간 필요 최근 이 문제를 해결하기 위해 다양한 tasks 에 transferring prompt vectors 를 제안 multiple source tasks 에 soft prompt 훈련 이 pre-trained prompt 를 사용하여, similarity measure 를 기반으로 target task 에 더 많이 finetuning 하기 위해 prompt 를 초기화 (Fig 1. Top) 본 논문에선 이 연구 방향을 확장하여 multitask prompt tuning (MPT) 소개 multitask data 를 사용하여 target task 에 효율적으로 transfer 할 수 있는 single prompt 학습 shared prompt space 학습은 서로 다른 task 간의 공통점을 학습하고 간섭 최소화가 필요하여 힘듬 저자는 각 task 의 soft prompt (prompt matrix) 를 shared matrix 와 low-rank task-specific matrix 의 곱으로 분해 이 분해는 shared prompt matrix 보다 효과적임을 발견 이 분해는 일반적인 prompt tuning 에서 얻은 soft prompt 로 부터 knowledge distillation 을 통해 학습 new task 에 transfer 하기 위해, shared prompt matrix 에 low-rank multiplicative updates 수행 (Fig. Bottom) 23 task 에 실험 결과, 저자의 approach 가 SOTA prompt transfer 보다 효과적임을 입증 SuperGLUE 에 T5-Base 를 사용한 MPT 는 vanilla PT 를 16.3% 개선 multitask prompt transfer baseline (ATTEMPT) 보다 훨씬 적은 task-specific prompt parameter (77.6K vs 232K) 로 더 나은 성능 일부 벤치마크에 MPT 가 full finetuning 을 능가하는 경우 존재하며, task 당 0.035% 의 tunable parameter 만 필요 MPT 가 각 target task 에 4-32 label 로 수행하는 few-shot learning 에 효과적임을 발견","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":619,"t":"adapter 및 그 변형들은 trainable layers 를 삽입 BitFit 은 bias parameter 만 업데이트 Diff pruning 및 FISH 은 original PLM 와 sparse update 하게 학습 prompt tuning 은 input 앞에 붙인 soft prompt vectors 만 업데이트 generation task 에 대한 continuous prompts 최적화인 Prefix-tuning UNIPELT 는 gating 메커니즘으로 다양한 tuning 방법을 결합하여 학습 HyperPrompt 는 task-specific information 을 조건부화하여 prompt 생성 LST 는 ladder side network 로 parameter-efficient tuning 의 training memory 를 줄인다 Discrete prompt 는 많은 케이스에서 효율성을 보인다 저자는 prompt 의 transferability 에 더 관련 (Transprompt, SPoT, [On transferability of prompt tuning for natural language processing]) 있으며, 많은 task 에 걸친 prompt tuning 의 성능을 향상시키는데 중점 둠 Spot 는 similarity measure 을 통해 하나의 prompt 를 선택 ATTEMP 는 target task 데 대한 prompt 초기화를 위해 source prompt 에 대한 attention 메커니즘 저자는 위와 달리, source prompt 를 분해하여, knowledge distillation 으로 다양한 target task 에 효율적으로 adaptation 하기 위해 single shared prompt 학습","s":"Parameter-efficient transfer learning","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#parameter-efficient-transfer-learning","p":611},{"i":621,"t":"Multitask learning : single model 로 multiple related tasks 를 동시에 해결하는데 초점 둠 multiple source tasks 에서 finetuned model 을 다른 target task 로 transfer massive multitask learning 을 통해 LM 의 zero-shot 및 few-shot 능력 보여줌 specific parameter-sharing 전략을 설계하는 것 또한 multitask learning 의 최근 동향 저자의 approach 는 LM 의 parameter-efficient adaption 을 위한 multitask prompt transfer 에 중점","s":"Multitask learning","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#multitask-learning","p":611},{"i":623,"t":"knowledge distillation 은 많은 task 에서 성능 및 효율성 향상에 사용 model compression, transfer learning, machine translation, question answering 및 document retrieval 등 포함 PANDA 는 similarity measure 로 하나의 source task 에서 target task 로 transfer 하는데 초점 저자의 MPT approach 는 prompt transfer 을 위해 multitask learning 을 활용하여 task 간의 cross-task knowledge 를 활용","s":"Knowledge distillation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#knowledge-distillation","p":611},{"i":625,"t":"Given: source tasks S={S1,S2,…,Sk}\\pmb{\\mathcal{S}} = \\{ \\mathcal{S}_1, \\mathcal{S}_2, \\dots, \\mathcal{S}_k \\}SS={S1​,S2​,…,Sk​} target tasks T={T1,T2,…,TT}\\pmb{\\mathcal{T}} = \\{ \\mathcal{T}_1, \\mathcal{T}_2, \\dots, \\mathcal{T}_\\mathcal{T} \\}TT={T1​,T2​,…,TT​} 저자의 목표는 각 task Ti\\mathcal{T}_iTi​ 가 adapt 될 수 있는 single soft prompt S\\mathcal{S}S 를 학습하는 것 Simply, S\\pmb{\\mathcal{S}}SS 에서 single soft prompt 학습 그 후, 각 Ti\\pmb{\\mathcal{T}}_iTTi​ 에 finetuning 하지만 finetuning 은 sub-optimal 이며, source task 의 공통적인 특징을 활용하지 못하면서, 동시에 간섭을 최고화하기 어렵기 때문 이를 위해, MPT 는 knowledge distillation 를 통해 S\\pmb{\\mathcal{S}}SS 의 task-shared knowledge 를 single prompt matrix ϕS\\pmb{\\phi_\\mathcal{S}}ϕS​ϕS​ 로 압축하여, T\\pmb{\\mathcal{T}}TT 의 성능을 향상시키고 transfer learning 에 덜 유용한 task-specific information 걸러냄","s":"3. Approach","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":627,"t":"Given: pre-trained LM with parameter θ\\thetaθ one target task T\\pmb{\\mathcal{T}}TT with training data (X,Y)={xi,yi}i=1N(X,Y) = \\{x_i, y_i\\}^N_{i=1}(X,Y)={xi​,yi​}i=1N​ standard approach 모든 parameter 를 바로 finetuning 하여 conditional probability P(Y∣X;θ)P(Y|X; \\theta)P(Y∣X;θ) 최대화 target tasks T\\pmb{\\mathcal{T}}TT group 을 고려할 때, 이 방식은 효율적이지 않을 수 있음 더 parameter-efficient 한 방법은 prompt tuning model parameter θ\\thetaθ 를 고정한 채, learnable prompt vectors (soft prompts) 의 소수를 무작위로 초기화하여 PLM 의 input embeddings 앞에 추가 공식화하면, token embedding 이 ddd 차원인 input sequence T=[t1,t2,…,tn]∈Rn×dT = [t_1, t_2, \\dots, t_n] \\in \\mathbb{R}^{n \\times d}T=[t1​,t2​,…,tn​]∈Rn×d 일 때, PT 는 동일한 차원을 가진 learnable prompt matrix P∈Rl×dP \\in \\mathbb{R}^{l \\times d}P∈Rl×d (lll 은 hyperparameter) 를 input embeddings 에 추가 그 후, 다음과 같은 loss function 으로 PPP 를 최적화 LPLM=−∑ilog⁡P(yi∣xi ; θ,P)(1)\\mathcal{L}_{PLM} = - \\sum_i \\log P (y_i |x_i \\ ; \\ \\theta, P) \\tag{1}LPLM​=−i∑​logP(yi​∣xi​ ; θ,P)(1) LM 의 input 은 [P;T]∈R(l+n)×d[P; T] \\in \\mathcal{R}^{(l+n) \\times d}[P;T]∈R(l+n)×d 위 approach 는 일부 task 및 모델엔 성공적이지만, vanilla PT 엔 가끔 성능 저하 (특히 작은 PLM) 수렴 속도도 느리며 parameter 초기화에 높은 민감도 관찰 최근 이를 해결하기 위해 multiple source tasks 에 prompt 를 training 하고, similarity measure 로 target task 의 prompt 로 초기화하는 방식을 다룸. 저자는 이를 확장하여 transfering multiple knowledge 으로 downstream target tasks T\\mathcal{T}T 로의 transfer learning 을 더 효과적이고 parameter-efficient 를 가능케 하는 framework MPT 제안","s":"Prompt tuning","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#prompt-tuning","p":611},{"i":629,"t":"MPT framework 는 두 단계로 구성 source training second stage 에 재사용될 single soft prompt matrix 를 생성 구체적으로, source task 를 위한 prompt matrix 는 task-shared matrix (shared across all tasks) 와 low-rank task-specific matrix (prompt decomposition) 로 분해 분해된 task-shared/specific matrix 는 knowledge distillation 으로 학습 target adaptation 학습 후, shared prompt matrix 는 low-rank multiplicative update 를 통해 downstream target task 에 adapt","s":"3.1 Multitask prompt tuning","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#31-multitask-prompt-tuning","p":611},{"i":631,"t":"prompt decomposition 목표 : source task S\\mathcal{S}S 간의 knowledge sharing 을 효율적으로 가능하게 하면서, 각 task 의 고유 parameters 를 유지하여 task-specific knowledge 를 인코딩할 수 있게 하는 것 kkk-th task 를 위한 soft prompt PkP_{k}Pk​ 를 두 부분으로 나눔 (Fig 3 참고) P∗∈Rl×dP^* \\in \\mathbb{R}^{l \\times d}P∗∈Rl×d : shared prompt across all tasks uk∈Rl,vk∈Rdu_k \\in \\mathbb{R}^l, v_k \\in \\mathbb{R}^duk​∈Rl,vk​∈Rd : 각 task kkk 에 대한 task-specific vectors task-specific vectors 는 rank-one matrix Wk=uk⨂vkTW_k = u_k \\bigotimes v_k^TWk​=uk​⨂vkT​ 으로 형성 WkW_kWk​ 는 shared prompt P∗P^*P∗ 와 동일한 차원 kkk-th source task 에 대한 task prompt P^\\hat{P}P^ 는 다음과 같이 매개변수화 함 P^=P∗∘Wk=P∗∘(uk⨂vkT)(2)\\hat{P} = P^* \\circ W_k = P^* \\circ (u_k \\bigotimes v_k^T) \\tag{2}P^=P∗∘Wk​=P∗∘(uk​⨂vkT​)(2) ∘\\circ∘ : hadamard product 위의 prompt decomposition 의 매개변수화는 low-rank method 에 영감을 받음 source task set 에 걸친 \"slow\" weight P∗P^*P∗ 로 일반적인 정보를 캡쳐 \"fast\" weight WkW_kWk​ 는 low-rank subspace 에서의 Sk\\mathcal{S}_kSk​ 에 대한 task-specific knowledge 를 인코딩","s":"Prompt decomposition","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#prompt-decomposition","p":611},{"i":633,"t":"multitask dataset S\\mathcal{S}S 에 직접 prompt decomposition 를 학습하면 shared component P∗P^*P∗ 가 큰 task 에 과적합하는 경향 있음 이에 좋은 decomposable prompt 를 학습하기 위해 효과적인 전략으로, 별도로 훈련된 source prompt 로 knowledge distillation 을 발견 일반적인 prompt tuning 으로 kkk-th source task 에 대한 teacher prompt Pk(teacher)P_k^{(teacher)}Pk(teacher)​ 을 얻음 상응하는 student prompt P^k=P∗∘(uk⨂vkT)\\hat{P}_k = P^* \\circ (u_k \\bigotimes v_k^T)P^k​=P∗∘(uk​⨂vkT​) 을 무작위로 초기화 모든 student prompts 는 P∗P^*P∗ 를 공유하고 위에서 설명한 대로 task-specific vecotrs 를 가짐 distillation 을 사용하여 cross-task knowledge 를 shared prompt matrix 로 transfer shared prompt matrix P∗P^*P∗ 및 task-specific parameters uku_kuk​ 와 vkv_kvk​ 에 대한 KL-Divergence 를 최소화하여 student 와 teacher 의 output probability distributions 를 일치시키기 위한 first loss 계산 LLogit=∑k∈S∣∑(xi,yi)∈SkKL [ P(yi∣xi ; θ,Pk(teacher))∣∣P(yi∣xi ; θ,P^k) ](3)\\mathcal{L}_{Logit} = \\sum_{k \\in \\mathcal{S} |} \\sum_{(x_i, y_i) \\in \\mathcal{S_k}} KL \\ [ \\ P ( y_i | x_i \\ ; \\ \\theta, P_k^{(teacher)}) || P (y_i | x_i \\ ; \\ \\theta, \\hat{P}_k) \\ ] \\tag{3}LLogit​=k∈S∣∑​(xi​,yi​)∈Sk​∑​KL [ P(yi​∣xi​ ; θ,Pk(teacher)​)∣∣P(yi​∣xi​ ; θ,P^k​) ](3) teacher 및 student model 의 output distribution 의 smoothness 를 제어하기 위해 temperature TTT 사용 pj=1Zexp⁡(zj/T)p_j = \\frac{1}{Z} \\exp (z_j/T)pj​=Z1​exp(zj​/T) ziz_izi​ : class jjj 에 대한 logit score ZZZ : normalization 요소 또한 teacher model 의 hidden states 에 mean squared loss 추가 LHidden=∑k∈S∣∑(xi,yi)∈Sk ( Hk,i−Hk,i(teacher) )2(4)\\mathcal{L}_{Hidden} = \\sum_{k \\in \\mathcal{S} |} \\sum_{(x_i, y_i) \\in \\mathcal{S_k}} \\ ( \\ H_{k,i} - H_{k,i}^{(teacher)} \\ )^2 \\tag{4}LHidden​=k∈S∣∑​(xi​,yi​)∈Sk​∑​ ( Hk,i​−Hk,i(teacher)​ )2(4) Hk,i(teacher)H_{k,i}^{(teacher)}Hk,i(teacher)​ 및 Hk,iH_{k,i}Hk,i​ ; 각각 teacher 및 student networks 의 hidden states iii-th input 에 대한 hidden vector 의 sequence 로 구성 intermediate states 에서의 추가적인 distillation loss 은 PLMs 에 distilling 한 결과, 개선된 것을 보여줌 target 측면으로 transfer 할 single shared prompt 를 얻기 위한 student source prompts 를 training 하는 데 사용되는 total loss function 은 다음과 같다. LTotal=LPLM+λ(LLogits+LHidden)(5)\\mathcal{L}_{Total} = \\mathcal{L}_{PLM} + \\lambda ( \\mathcal{L}_{Logits} + \\mathcal{L}_{Hidden} ) \\tag{5}LTotal​=LPLM​+λ(LLogits​+LHidden​)(5) LPLM=∑k∈∣S∣LPLMk\\mathcal{L}_{PLM} = \\sum_{k \\in |\\mathcal{S}|} \\mathcal{L}_{PLM}^kLPLM​=∑k∈∣S∣​LPLMk​ : all source tasks 에 대해 집계된 task losses λ\\lambdaλ : distillation loss 의 영향을 균형잡기 위한 가중치","s":"Prompt distillation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#prompt-distillation","p":611},{"i":635,"t":"target tasks 로의 transfer 할 single source prompt 의 training 에는 2 단계 필요 all source tasks 에 대한 teacher prompts 를 vanilla prompt tuning 으로 개별적 pre-training S={S1,…,Sk}\\mathcal{S} = \\{S_1, \\dots,S_k \\}S={S1​,…,Sk​} 에서 multitask training 수행하여 Eq 5 의 knowledge distillation loss function 으로 single shared prompt 를 공통적으로 학습 간단한 stochastic tasks sampling 전략을 채용하여, batch 당 task 수를 동적으로 변경 multitask samples 의 각 batch 에 대해, 먼저 [2,k][2, k][2,k] 에서 KKK 수를 무작위로 선택 S\\mathcal{S}S 에서 KKK 개의 tasks 를 무작위로 선택 해당 samples 를 mini-batches 로 구성 target adaptation 의 경우 target task Tt\\mathcal{T}_tTt​ 에 대한 target prompt 를 shared prompt matrix 와 task-specific low-rank prompt matrix 의 Hadamard product 로 초기화 i.e. P^t=P∗∘(ut⨂vtT)\\hat{P}_t = P^* \\circ (u_t \\bigotimes v_t^T)P^t​=P∗∘(ut​⨂vtT​) P∗P^*P∗, utu_tut​, vtv_tvt​ 에 대한 Eq 1 의 regular task loss 를 최적화 P∗P^*P∗, utu_tut​, vtv_tvt​ 각각 별도의 learning rate 를 사용 MPT 또한 target tasks T={T1,T2,…,TT}\\pmb{\\mathcal{T}} = \\{ \\mathcal{T}_1, \\mathcal{T}_2, \\dots, \\mathcal{T}_{\\mathcal{T}} \\}TT={T1​,T2​,…,TT​} 의 group 에서 multitask learning 에 사용될 수 있음 이 경우 P∗P^*P∗ 는 T\\mathcal{T}T 전체에 공유됨","s":"3.2 Source Training And Target Adaptation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#32-source-training-and-target-adaptation","p":611},{"i":637,"t":"각 task 에는 vanilla soft prompt 와 동일한 차원을 가지는 shared prompt l×dl \\times dl×d 와 더 적은 수의 task-specific vecotrs (l×d)(l \\times d)(l×d) 를 포함 → single target task 에 대한 tunable parameters 의 total number 는 (l×d)+(l×d)(l \\times d) + (l \\times d)(l×d)+(l×d) → training 후, 이를 l×d2l \\times d^2l×d2 사이즈의 single matrix 로 압축 가능 target task group 의 경우 tunable parameter 의 total number : (l×d)+(l×d)τ(l \\times d) + (l \\times d)\\tau(l×d)+(l×d)τ τ\\tauτ : target tasks number Table 1 에서 trainable parameter 의 수를 기준으로 비교","s":"Parameter-efficiency","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#parameter-efficiency","p":611},{"i":639,"t":"다양한 범위의 NLP dataset 에서 MPT 가 강력한 baseline 을 이기는 것을 보여줌 full-datset (Table 1, 2) few-shot (Table 3, 4) 기존 방법들보다 parameter-efficient","s":"4. Experiments","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":642,"t":"MPT 평가를 위해 100k 개 이상의 annotations 가 있는 6개 데이터셋을 source task 로 사용 MNLI QNLI QQP SST-2 SQuAD ReCoRD 4개 벤치마크의 23개 데이터셋를 target task 로 사용 SuperGLUE : MultiRC, BoolQ, WiC, WSC 및 CB GLUE : RTE, CoLA, STS-B, MRPC, MNLI, QQP, QNLI 및 SST-2 MRQA : Natural Questions, HotpotQA, NewsQA 및 SearchQA Others : WinoGrande, Yelp-2, SciTail 및 PAWS-Wiki generation task 의 adapting 을 위한 E2E 및 WebNLG","s":"Datasets and tasks","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#datasets-and-tasks","p":611},{"i":644,"t":"prompt tuning 의 standard approach 를 따라, 주로 220M parameters 를 가진 공개된 pretrained T5-Baase 를 사용. 모든 벤치마크에 대해 100개의 prompt vectors 사용 (따라서, P^k∈R100×d\\hat{P}_k \\in \\mathbb{R}^{100 \\times d}P^k​∈R100×d) 저자의 ablation study 에서는 T5-Small (60M) 및 T5-Large (770M) 모델도 고려","s":"Models","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#models","p":611},{"i":646,"t":"MPT 를 다음 baselines 와 비교 Full finetuning (FT) : 모든 model parameters 를 각 downstream task 에 adaptation 하면서 tuning Vanilla prompt tuning (PT) : target prompt vectors 는 top vocabularies 를 무작위로 sample 하여 초기화 SPoT 및 ATTEMPT 를 포함하는 prompt transfer method : source prompts 검색 또는 집계하여 target prompts 초기화 Adapters 및 BitFit 을 포함하는 parameter-efficient method","s":"Baseline","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#baseline","p":611},{"i":648,"t":"source training 의 경우 examples-proportional mixing 전략 및 stochastic task sampling 을 사용하여 5 epochs 동안 MPT 를 source tasks 의 mixture 에서 훈련 prompt distillation 의 경우 T5 의 encoder 및 decoder 의 hidden states 에 대한 loss 계산 target adaptation 의 경우 MPT 의 shared prompt 를 재사용 target task-specific vector 를 초기화하기 위해 MPT 의 source task-specific 평균을 사용 모든 실험을 서로 다른 seed 로 세 번 실행하고 평균과 표준편차 보고 few-shot 실험에서는, 각 shot 수 kkk 에 대해 서로 다른 무작위 seed 로 training set 을 10번 샘플링하고 평균 성능 보고","s":"Implementation details","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#implementation-details","p":611},{"i":651,"t":"Table 1 (top) MPT 는 parameter-efficient finetuning 에 대해 SOTA 결과 보여줌 Table 1 (bottom) 더욱 parameter-efficient 측면으로 매우 큰 잠재력을 보임 Table 2 PT 에 비해 상당한 향상 프롬프트 길이 100 에서 300 으로 증가시키면 Adapters 와의 성능 차이를 줄이고, parameter-efficient 결과를 보임","s":"Full-dataset adaptation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#full-dataset-adaptation","p":611},{"i":653,"t":"few training examples (kkk = 4, 16, 32) 만 사용 가능한 new tasks 에 어떻게 일반화되는지 측정하기 위해 BoolQ, CB 및 SciTail 에 few-shot 실험 Table 3 MPT 는 PT 및 SPoT 모두 능가 다른 method 들도 few-shot learning 에서 어려움을 겪고 있음 Table 4 MPT 가 대부분의 dataset 에서 Vanilla PT 를 큰 폭으로 능가 위 결과는 source task 에서 target task 로 효과적으로 활용함을 보여줌","s":"Few-shot adaptation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#few-shot-adaptation","p":611},{"i":655,"t":"NLU task 에서 학습한 prompt decomposition 이 target NLG task 로 일반화되는지 테스트 6가지의 source task 를 사용하여 pre-trained T5-Large prompt 를 두 가지 NLG task 인 E2E 및 WebNLG 에 transfer Table 5 MPT 가 모든 metric 에서 PT 보다 큰 폭으로 우수한 성능 NLU 및 NLG 양쪽에서 효과적임 이는 source task 가 NLU task 임에도 NLG task 로의 knowledge transfer 가 효과적임을 나타냄","s":"Natural language generation tasks","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#natural-language-generation-tasks","p":611},{"i":657,"t":"3가지 SuperGLUE task 에서 pre-trained model 크기를 증가시키면서 MPT 성능 분석 Figure 4 (왼쪽) MPT 및 full finetuning (FT), Adapter, PT 및 ATTEMPT 를 사용한 세 가지 서로 다른 T5 model 의 성능을 보여줌 MPT 가 SOTA parameter-efficient 를 달성 60M ~ 770M parameter 전 범위의 model scaling 에서 효과적임","s":"Model scaling","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#model-scaling","p":611},{"i":659,"t":"MPT 를 사용하여 학습한 prompt 를 분석하고 cross-task knowledge 가 실제로 task-shared prompt 에 인코딩되어 target task 에 효과적으로 adapt 되는지, 자체 knowledge 를 인코딩하여 분석 target task 의 모든 pairs 간의 cosine similarity 를 계산하기 위해 prompt metrices 사용 각 ㅅask 는 task-shared 및 task-specific prompt 의 조합으로 표현 (single vector 를 얻기 위해 평균화) Figure 4 (오른쪽) SPoT 및 MPT 의 cosine similarity matrix 를 시각화 task embeddings 가 유사한 task 를 효과적으로 클러스터링 하는 것 발견","s":"Analyzing prompt metrices","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#analyzing-prompt-metrices","p":611},{"i":662,"t":"모든 hyperparameter 를 고정하고 MPT source training 을 재실행하여 transfer 된 prompt 의 여러 버전을 실험 prompt decomposition 효과 측정을 위해 source prompt 를 task-shared 및 task-specific components 로 구성된 decomposable prompt 로 대체하고 prompt distillation 없이 훈련 첫 번째 행에 비해 3.5% 성능 향상 MPT 의 prompt decomposition 의 중요성을 보여줌 shared component 가 target downstream task 에 유용한 cross-task knowledge 를 효과적으로 캡쳐하는 것을 보여줌 prompt distillation 효과 측정을 위해 모든 source task 에서 동일한 training loss 를 갖는 일반적은 prompt 를 훈련 첫 번째 행에 비해 1.1% 향상 prompt decomposition 과 결합하면 74.1% 성능 달성 따로 훈련된 source prompt 에서 knowledge 를 추출하는 것이 좋은 decomposable prompt 를 학습하기 위한 효과적인 전략임을 보여줌","s":"Prompt decomposition and distillation","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#prompt-decomposition-and-distillation","p":611},{"i":664,"t":"prompt distillation 의 개별 component 를 조사하여 최종 성능에 미치는 영향 측정 Eq 5 의 hidden state loss 를 제거하고 이로 인해 SuperGLUE 에서 73.7% 성능을 얻음을 확인 logits 과 함께 hidden states 를 정규화하여 전체 성능에 도달하는 효과 검증 teacher 및 student prompt 간의 distance 최소화를 위해 loss 에 MSE loss 추가하여 두 prompt 를 일치시크는 distillation loss 변형 distillation loss 를 distance loss 로 대체하여 SuperGLUE 에서 73.6% 도달 logits 및 hidden state 기반의 distillation loss 보다 성능이 떨어짐","s":"Distillation objective","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#distillation-objective","p":611},{"i":666,"t":"논문의 실험들은 l=100l = 100l=100 prompt vectors 를 사용 Fig 5 에서 보이듯, 더 긴 prompt 를 사용하면 l=300l = 300l=300 까지 개선 가능하며, 더 늘리면 정확도가 감소하게 되어 오버피팅이 발생","s":"Prompt length","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#prompt-length","p":611},{"i":668,"t":"source 에서 target task 로 shared prompt 를 transfer 할 때, task-shared component 만 업데이트하는 경우 (즉, task-specific vectors 제거) 또는 task-specific vectors 만 업데이트하는 경우 (즉, task-shared component 를 freezing) 결과가 부적절 (SuperGLUE 에 각각 62.5% 및 71.3%) 이는 target adaptation 을 위한 두 component 의 중요성을 보여줌","s":"Target adaptation strategy","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#target-adaptation-strategy","p":611},{"i":670,"t":"stochastic task sampling 제거 시, SuperGLUE 에서 73.7% 결과 (낮은 성능) 이는 multitask training 전략에서 이점을 보임","s":"Stochastic task sampling","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#stochastic-task-sampling","p":611},{"i":672,"t":"주요 실험은 6 개의 NLP task 에 추가적인 다양한 source task 를 포함하여 총 12개의 source task 통합 topic classification, multi-choice QA, OpenBookQA, ARC, adversarial NLI 및 commonsense reasoning 포함 Table 7 12 개의 task 를 사용하는 MPT 는 여전히 target adaptation 에 효과적 6 개의 task 를 사용한 MPT 보다 약간 우수한 성능","s":"Number of source tasks for pretraining","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"#number-of-source-tasks-for-pretraining","p":611},{"i":674,"t":"Multitask Prompt Tuning 연구 결과 다음과 같다. multiple source task 및 task-specific source prompt 에서 knowledge 를 decomposition 하고 distillation 하여 single transferable prompt 를 학습 task prompt 를 shared prompt matrix 와 rank-one task-specific matrix 를 Hadamard product 하여 decomposition shared component 가 target task 로 transfer 및 adapt 하여 tuning 실험 결과 다양한 NLP 벤치마크에서 target downstream task 로의 parameter-efficient transfer learning 이 가능 경우에 따라 훨씬 적은 task-specific parameter 로 tuning 하여 full finetuning 능가","s":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/Multitask Prompt Tuning","h":"","p":611},{"i":676,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2103.10385.pdf","s":"GPT Understands, Too","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":678,"t":"전통적인 fine-tuning 으로는 GPT model 의 natural language understanding (NLU) task 에 좋은 결과를 달성하지 못하는 반면, 저자는 trainable continuous prompt embeddings 를 사용한 P-tuning 을 통해 나은 결과를 얻을 수 있었다. knowledge probing (LAMA) 벤치마크에서 최고인 GPT 는 테스트할 때 additional text 없이 64% (P@1) 복구 (이전 best 의 +20%) SuperGlue 벤치마크에서 GPT 모델은 supervised learning 에서, 유사한 크기인 BERT 와 비슷하거나 더 나은 성능 달성 P-tuning 이 prompt engineering 의 필요성을 줄여, BERT 모델의 성능도 향상시킨다는 것 결과적으로 P-tuning 이 few-shot SuperGlue 벤치마크에서 SOTA 능가","s":"Abstract","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":680,"t":"이전 연구들은 pre-training 과정에 text 표현 뿐 아니라 문법, 구문, 상식 및 세계 지식 등의 요소를 학습한다는 증거를 제시하기도 한다. training objectives 에 따라 pre-trained language model (LM) 은 세 가지 범주로 나눌 수 있다. unidirectional language models for natural language generation (NLG) (e.g. GPT) bidirectional language models for natural language understanding (NLU) (e.g. BERT) hybrid language models for combining the first two paradigms (e.g. XLNet, UniLM) GPT 스타일의 모델이 fine-tuning 으로 NLU task 에 대한 성능이 좋지않아, language undetstanding 에 적합하지 않다고 가정해왔다. 하지만 manual prompt 사용으로 흥미로운 성능을 보여, large unidirectional model 와 manual prompt 가 NLU 에 적합하게 작용할 수 있음을 시사 그러나 best-performing prompt 란 사막에서 바늘찾기 이며, 현실적으로 불가능한 매우 큰 검증 데이터셋이 필요하다. 많은 케이스에서도, prompt engineering 은 테스트셋에 overfitting 하며, 큰 성능 하락을 일으키는 prompt 를 만들 가능성도 있다. 이러한 연구들을 통해 저자는 discrete prompts 를 자동으로 검색하고, 효과를 입증하는데 초점을 둔다. 하지만 neural networks 는 continuous 하므로 discrete prompts 는 sub-optimal 일 수 있다. 본 연구는 P-tuning 으로 GPT 와 NLU 간의 간격을 좁히기 위해 continuous space 에서 prompt 를 자동으로 검색하는 방법을 연구 few continuous free parameters 를 활용하여 pre-trained LM 에 입력으로 제공되는 prompt 역할 continuous prompt 를 discrete prompt searching 대신 gradient descent 를 활용하여 최적화 간단한 P-tuning 으로 GPT 에 상당한 개선을 가져왔다. 저자는 P-tuning 기반 GPT 을 두 가지 NLU 벤치마크에 검토 LAMA knowledge probing 64.2% 달성하여 이전 SOPTA prompt searching 방법인 45.2% 를 크게 능가 SuperGLUE few-shot 및 fine-tuning 을 함께 진행 동일한 규모의 BERT 와 유사한 성능이거나 일부 데이터셋에선 능가 BERT 스타일 모델에도 P-tuning 이 이점을 얻을 수 있음을 관찰 ALBERT 의 P-tuning 은 성능 크게 능가하고 few-shot SuperGLUE 에서 SOTA 위 방법은 GPT 는 언어를 이해하지 못한다는 고정관념을 부쉈다. P-tuning 은 pre-trained LM 을 downstream task 에 최상의 성능을 위해 fine-tuning 에도 작동한다. 본 논문의 기여는 다음과 같다. P-tuning 으로 GPT 의 NLU 가 BERT 와 comparable (때론 더 나음)하여, pre-trained LM 의 성능을 향상 시킴 P-tuning 은 few-shot 및 fine-tuning 설정에서도 GPT 및 BERT 를 모두 개선 LAMA knowledge probing 및 few-shot SuperGLUE 에서 SOTA 능가 LM 이 pre-training 중 생각보다 더 많은 지식을 습득했음을 시사","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":682,"t":"GPT-3 및 DALL-E 는 LLM 이 만병통치약임을 시사하지만, transferability 가 낮다는 것. downstream task 의 fine-tuning 은 trillion-scale model 에는 거의 작동하지 않는다. many-shot fine-tuning 에서도 빠르게 fine-tuning sample 을 메모리에 저장하기엔 너무 크다. 대안으로 GPT-3 와 DALL-E 는 downstream 을 위해 model fine-tuning 을 위해 manual prompt 를 활용하는 것이 보고 되었다. 그러나 manual prompt searching 은 큰 검증셋에 지나치게 의존하며 성능도 불안정하다. 최근 discrete prompts searching 을 자동으로 하는 것에 집중하며, training corpus 를 mining gradient searching separate model 저자의 목적은 미분하여 최적화될 수 있는 continuous prompt 를 찾는 것","s":"2. Motivation","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":684,"t":"discrete prompt 와 유사하게 P-tuning 은 input 에 비침범적인 (noninvasive) 수정만 적용 pre-trained input embeddings 을 differential (미분계수) output embeddings 로 대체","s":"3. Method: P-tuning","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":686,"t":"pre-trained LM M\\mathcal{M}M 이 주어졌을 경우 discrete input token 의 sequence x1:n={x0,x1,…,xn}\\text{x}_{1:n} = \\{ x_0, x_1, \\dots, x_n \\}x1:n​={x0​,x1​,…,xn​} pre-trained embedding layer e∈Me \\in \\mathcal{M}e∈M 에 의해 input embeddings {e(x0),e(x1),…,e(xn)}\\{ e(x_0), e(x_1), \\dots, e(x_n) \\}{e(x0​),e(x1​),…,e(xn​)} 으로 매핑 특정 시나리오에선 context x\\text{x}x 에 대해, downstream 처리를 위해 target token y\\text{y}y 의 output embeddings 사용이 일반적 pre-training 에선, x\\text{x}x 는 unmasked tokens 을 나타내며, y\\text{y}y 는 [MASK] 를 나타냄 sentence classification 에선, x\\text{x}x 는 sentence token 을 나타내며, y\\text{y}y 는 [CLS] 를 나타냄 prompt p\\bold{p}p 의 역할은 context x\\text{x}x, target y\\text{y}y 및 template TTT 로 구성하는 것 예로, 국가 수도를 예측하는 작업 (LAMA-TREx P36) template \"The capital of Britain is [MASK].\" prompt \"The capital of ... is ... .\" context \"Britain\" target \"[MASK]\" prompt 는 context 또는 target 로 삽입할 수 있는 유연성을 지닐 수 있다. LM M\\mathcal{M}M 의 vocabulary 를 V\\mathcal{V}V, template TTT 의 ithi^{th}ith prompt token 을 [Pi][\\text{P}_i][Pi​] 라 하자. 간단하게, T={[P0:i],x,[Pi+1:m],y}T = \\{ [\\text{P}_{0:i}], \\text{x}, [\\text{P}_{i+1:m}],\\text{y} \\}T={[P0:i​],x,[Pi+1:m​],y} 가 주어졌다고 하자. traditional discrete prompts 와 비교하며, 이는 [Pi]∈V[\\text{P}_i] \\in \\mathcal{V}[Pi​]∈V 를 만족시키고 TTT 를 다음과 같이 매핑 {e([P0:i]),e(x),e([Pi+1:m]),e(y)}\\begin{equation} \\{ e([\\text{P}_{0:i}]), e(\\text{x}), e([\\text{P}_{i+1:m}]), e(\\text{y}) \\} \\end{equation}{e([P0:i​]),e(x),e([Pi+1:m​]),e(y)}​​ 반면, P-tuning 은 [Pi][\\text{P}_i][Pi​] 를 pseudo tokens 로 간주하고 template 를 다음과 같이 매핑 {h0,…hi,e(x),hi+1,…hm,e(y)}\\begin{equation} \\{ h_0, \\dots h_i, e(\\text{x}), h_{i+1}, \\dots h_m, e(\\text{y}) \\} \\end{equation}{h0​,…hi​,e(x),hi+1​,…hm​,e(y)}​​ hi(0≤i≤m)h_i (0 \\leq i \\leq m)hi​(0≤i≤m) : trainable embedding tensors 이를 통해 M\\mathcal{M}M 의 original vocabulary V\\mathcal{V}V 를 넘어 더 나은 continuous prompts 를 찾을 수 있게 됨 downstream loss function L\\mathcal{L}L 를 사용하여 continuous prompt hi(0≤i≤m)h_i (0 \\leq i \\leq m)hi​(0≤i≤m) 를 미분으로 최적화할 수 있다. h^0:m=argmin⁡h L(M(x,y))\\begin{equation} \\hat{h}_{0:m} = \\underset{h}{\\text{arg} \\min}\\ \\mathcal{L} (\\mathcal{M}(\\text{x}, \\text{y})) \\end{equation}h^0:m​=hargmin​ L(M(x,y))​​","s":"3.1 Architecture","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#31-architecture","p":675},{"i":688,"t":"continuous prompts 의 training idea 는 간단하지만 실제로 두 가지 최적화 문제를 직면 Discreteness M\\mathcal{M}M 의 original word embedding eee 은 pre-training 후 높은 discrete 성질을 가짐 hhh 가 random distribution 된 후 stochastic gradient descent (SGD) 로 최적화될 경우, small neighborhood 의 parameter 만 변경될 수 있음 위 optimizer 는 쉽게 local minima 에 빠질 수 있음 Association prompt embeddings hih_ihi​ 의 값이 독립적이 아닌 서로 종속되어야 한다는 것. prompt embeddings 를 서로 연관시키기 위한 매커니즘 필요 위 어려움을 대응하여 P-tuning 에선 hih_ihi​ 를 서로 종속적인 시퀀스로 모델링 하는 것을 제안 이를 위해 매우 가벼운 신경망으로 구성된 prompt encoder 를 사용하여 discreteness 및 association 해결 양방향 LSTM 을 선택하고 ReLU activated two-layer MLP 를 사용하여 discreteness 촉진 LM M\\mathcal{M}M 에 대한 실제 input embeddings hi′h_i'hi′​ 는 다음과 같이 유도 hi=MLP([h→i : h←i])=MLP([LSTM(h0:i) : LSTM(hi:m)])\\begin{equation} \\begin{align*} h_i & = \\text{MLP}([\\overrightarrow{h}_i \\ : \\ \\overleftarrow{h}_i]) \\\\ & = \\text{MLP}([\\text{LSTM}(h_{0:i}) \\ : \\ \\text{LSTM}(h_{i:m})]) \\end{align*} \\end{equation}hi​​=MLP([hi​ : hi​])=MLP([LSTM(h0:i​) : LSTM(hi:m​)])​​​ LSTM head 사용은 continuous prompts 의 training 에 일부 파라미터를 추가하지만, LSTM head 는 pre-training 보다 훨씬 작으며, inference 에서는 output embedding hhh 만 필요하므로 LSTM head 를 폐기할 수 있다. 또한 몇 개의 anchor tokens 추가하는 것이 SuperGLUE 의 일부 NLU task 에 도움되는 것을 발견 RTE task 의 경우, prompt template \"[PRE][prompt tokens][HYP]?[prompt tokens][MASK]\" 내의 \"?\" token 은 anchor token 으로 특별히 추가되어 성능에 큰 영향을 미친다. 이러한 anchor tokens 는 각 구성 요소를 나타내며, 이 경우 \"?\" 는 \"[HYP]\" 가 의문문 부분으로 작용","s":"3.2 Optimization","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#32-optimization","p":675},{"i":690,"t":"NLU 벤치마크인 LAMA knowledge probing 및 SuperGLUE 에 포괄적으로 실험 결과, P-tuning 이 GPT 의 NLU 능력을 향상시키고 BERT 스타일 모델에도 이점이 있음을 보여줌","s":"4. Experiments","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":692,"t":"knowledge probing 또는 fact retrieval 은 LM 이 pre-training 에서 얼마나 세계 지식을 습득했는지 평가 LAMA dataset 은 knoledge base 에서 선택한 triple 에서 생성된 cloze test 로 평가 예로 triple 을 \"Dante was born in [MASK].\" 라는 handcraft prompt 로 변환한 다음 LM 에게 추론하도록 요청 pre-trained model 의 parameter 는 고정되어 있으므로, pre-training 에서 얻은 지식으로 평가","s":"4.1 Knowledge Probing","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#41-knowledge-probing","p":675},{"i":694,"t":"Datasets​ LAMA 의 모든 answers 를 single-token 으로 강제함 41개의 Wikidata relations 및 34,039개의 texting triples (즉, LAMA-34K) 로 구성된 original LAMA-TREx dataset 채택 (모두 BERT vocabulary 에 포함) GPT 와 BERT 의 vocabulary 가 서로 다르므로 교집합을 포함하는 다른 버전의 LAMA 를 설정 이 subset 은 약 29,000 tasting triples 를 추가하고, 이를 LAMA-29K 라고 명명 training 에 대해선 all prompt searching approaches 가 prompt 를 훈련하거나 찾기 위해 일부 추가 데이터가 필요. 저자는 AutoPrompt 설정을 따르며, original TRE-x dataset 에 training set 구축. 이 training set 은 test set 과 유사하지만 약간 다른 answer distribution 을 가지고 있다. Evaluation​ 원래, LAMA 는 Table 1 처럼 각 관계에 대한 handcraft prompt 를 제공했으며 이러한 prompt 는 효과적이지만 sub-optimal 이다. bidirectional masked language models 의 경우, \"[X]\" 를 subject entity 로, \"[Y]\" 를 [MASK] token 으로 데체 GPT 같은 unidirectional language model 의 경우, LAMA 의 원래 설정에 따라 Transformer-XL 에서 target position 앞의 network output 을 사용 P-tuning 진행 시, bidirectional models 에는 (3, sub, 3, obj, 3) template 을 사용 unidirectional models 에는 (3, sub, 3, obj) 을 사용 숫자는 prompt tokens 수를 나타낸다. 이 knowledge probing task 에서는 어떠한 anchor token 도 사용하지 않으며, training 중 learning rate 1e-5 및 Adam optimizer 사용","s":"4.1.1 Datasets And Formulation","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#411-datasets-and-formulation","p":675},{"i":696,"t":"General performance​ P-tuning 은 LAMA-34K 에서 43.3% 를 50.6% 로 끌어 올림 LAMA-29K 에서 45.2% 를 64.2% 까지 향상 AutoPrompt 및 LPAQA 같은 discrete prompt searching approach 보다 뛰어남 위 결과는 prompt 를 개선하고 fine-tuning 없이 단순히 더 나은 prompt 를 찾음으로써, LM 이 생각보다 훨씬 더 많은 knowledge 를 capture 했다는 것을 시사 P-tuning v.s. Fine-tuning​ 저자는 pre-training 중 LM 이 얼마나 많은 지식을 습득하는지 평가 주요 연구는 GPT 같은 unidirectional model 에서 P-tuning 과 fine-tuning 을 비교하는 것 하지만 다음 질문이 발생할 수 있다. \"unidirectional 및 bidirectional model 은 P-tuning 에서 유사한 개선을 얻을까?\" 기존의 tuning 방법을 포괄적으로 검토하고자 다음 approach 포함 Manual Prompt (MP) : LAMA 의 original manual prompt 사용 Fine-tuning (FT) : subject 를 제시하고 object 를 예측하기 위해 모델을 FT Manual Prompt with Fine-tuning (MP + FT) : manual prompt 로 LM 을 FT P-tuning : continuous prompt 를 사용하면서 LM parameter freezing LAMA-29K 에서 네 가지 전략을 구현 (Table 2 오른쪽) 놀라운 점은 FT 가 LM 의 all parameter 를 tuning 하지만, P-tuning 은 그렇지 않으니 더 강력해야 한다는 것. 하지만 P-tuning 이 FT 기반 방법과 비슷하거나 더 나은 결과 knowledge probing 에선 reasoning 보다는 hard-coding 이 되야하는 경우가 많아, FT 는 치명적인 망각을 초래할 수 있음 반면 P-tuning 은 pre-trained LM's parameter 를 변경하지 않고, continuous prompt 로 저장된 knowledge 활용 BERT 와 GPT 의 P-tuning 에 대한 개선 사항 사이에 명확한 격차가 있다는 놀라운 점 high-quality MP + FT 를 사용한 fine-tuning 의 효과가 관찰되지만, GPT 는 BERT 만큼 MP+FT 에서 이점을 얻지 못함 P-tuning 은 unidirectional LM 과 더 어울린다는 것을 시사 11B 의 큰 모델인 MegatronLM2 의 경우, FT 가 거의 작동하지 않는 반면, P-tuning 은 여전히 적용 가능하여 SOTA 달성","s":"4.1.2 Results","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#412-results","p":675},{"i":698,"t":"P-tuning 평가를 위해 SuperGLUE 에서 실험 수행 SuperGLUE 는 총 8개의 NLU task 를 지님 ReCoRD 는 prompt 가 없으므로 P-tuning 이 불가능하여 포함하지 않아 7개의 task 를 다룸 question answering MultiRC textual entailment RTE co-reference resolution causal reasoning word sense disambiguation 실험 설정에서 fully-supervised 및 few-shot 모두 고려 fully-supervised 에선 전체 훈련셋 (Dtrain\\mathcal{D}_{train}Dtrain​) 사용하고 모델 선택 및 hyperparameter tuning 을 위해 개발셋 (Ddev\\mathcal{D}_{dev}Ddev​) 사용 few-shot 에선 SuperGLUE 의 few-shot 버전 (FewGlue) 채택 SuperGLUE 의 subset, 각 task 는 32개의 훈련 데이터 (Dtrain32\\mathcal{D}_{train32}Dtrain32​) 및 크기가 400~20000 까지 다양한 unlabeled 구성 (Dunlabeled\\mathcal{D}_{unlabeled}Dunlabeled​) 이전 연구에서 개발셋이 없고 고정된 hyperparameter 를 채택하여 테스트셋에 과적합되었음. 저자는 적절한 few-dev set (Ddev32\\mathcal{D}_{dev32}Ddev32​) 구성. 더 큰 개발셋은 추가적인 이점을 제공한다는 것이 입증되었기 때문 Ddev32\\mathcal{D}_{dev32}Ddev32​ 는 사용되지 않은 훈련셋에서 random sample 로 선택하여 구성되며, few-training set 의 크기보다 크지 않도록 제한 [Small language models are also few-shot learners] 와 동일한 matric 사용 저자는 NLU task 를 blank filling task 로 재구성. [Small language models are also few-shot learners] 와 달리 P-tuning 은 initial prompt embeddings 을 패턴 내의 다른 position 에 배치한 후 pre-trained model 과 함께 prompt embedding 을 FT fully-supervised 설정 linearly decayed learning rate 를 사용하는 AdamW optimizer 사용 hyperparameter 에 대해 greedy search 를 수행하고 Ddev\\mathcal{D}_{dev}Ddev​ 또는 Ddev32\\mathcal{D}_{dev32}Ddev32​ 에서 최상의 조합 선택 구체적으로 learning rate 1e-5, 2e-5, 3e-5 선택하고 batch size 16, 32 small datasets 의 경우 pre-trained model 을 20 epoch fine-tuning larger datasets 의 경우, 모델의 빠른 수렴을 위해 training epoch 을 10 으로 줄임. overfitting 피하기 위해 early stop 사용 few-shot learning 의 경우 동일한 hyperparameter prompt embeddings 의 FT 에 더 많은 단계가 필요하여 3500 으로 확장 P-tuning 은 bidirectional 및 unidirectional model 에 사용 가능 공정한 비교를 위해 연산량이 유사한 BERT-base 3 과 GPT2-base, BERT-large 와 GPT2-medium 비교 few-shot learning 을 위해 albert-xxlarge-v2 모델도 실험 각 사전 훈련 모델에 대한 결과로 표준 FT (즉, [CLS] 임베딩을 사용한 분류), PET FT [Small language models are also few-shot learners], PET zero-shot 및 P-tuning의 성능을 보고","s":"4.2 SuperGLUE","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#42-superglue","p":675},{"i":700,"t":"bert-base-cased 및 bert-large-cased model 모두 P-tuning 으로 7개 task 중 5개 task 가 우수한 결과 WiC 및 MultiRC 는 큰 훈련셋을 가져, FT 가 더 큰 이점을 취함 gpt2-base 및 gpt2-medium model 에 대해 P-tuning 은 모든 gpt2-base 중 가장 유망한 결과 위 결과로 bert 및 gpt 기반 모델의 NLU 성능 효과적으로 향상 gpt2-base with P-tuning 은 7개 task 중 6개에서 BERT-base 의 best 결과 능가하고 WiC task 에서 comparable BERT-large 와 비교하면 P-tuning 을 사용한 GPT2-medium 은 7개 task 중 4개에서 우위, RTE 와 WSC task 에선 comparable, 유일한 예외는 WiC WiC task 에선 FT 가 우수하며, 이는 word sense disambiguation task 가 prompt-based MLM prediction 에 적합하지 않음을 추측 모두 종합하여 P-tuning 을 사용하면 GPT2 가 BERT-based model 과 comparable 하거나 더 나은 성능 달성 이는 BERT 같은 bidirectional model 이 NLU task 에서 항상 GPT2 와 같은 unidirectional model 보다 더 우수하다는 것을 뒤엎음","s":"4.2.1 Fully-Supervised Learning","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#421-fully-supervised-learning","p":675},{"i":702,"t":"Sub-optimal and Sensitive Manual Prompts​ PEFT/iPET 는 manual prompt 로 SuperGLUE few-shot learning task 에 SOTA 달성 이 prompt 는 효과적이지만 sub-optimal 이며 노동이 필요하다. manual prompt 의 종합적 이해를 위해 비교 실험 진행 다양한 manual prompt 와 P-tuning 을 사용한 결과 (Table 6) 결과는 prompt 의 의미, 형식, 문법과 few-shot learning 성능 간에 명확한 상관 관계가 없음 합리적으로 여기는 prompt 가 LM 에 효과적이지 않을 수 있음 manual prompt 의 작은 변경 사항이 큰 성능 차이 일으킴 pre-trained LM 은 prompt 선택에 있어 민감 manual prompt 는 복잡하다 결론 Table 6 에서 Ddev32\\mathcal{D}_{dev32}Ddev32​ 사용으로 best manual prompt 찾는 것은 불가능 few-shot 환경에서도 optimal manual prompt 선택은 어려움 반면 P-tuning 은 훨씬 적은 수동 작업으로 더 나은 prompt 를 자동으로 검색하는 데 유망 Updated SOTA for SuperGLUE Few-shot Learning​ P-tuning 에 의해 SuperGLUE few-shot SOTA 달성함을 보여줌 유의할 점은 PET 는 manual prompt fine-tuning 외에도 데이터 증강, 앙상블 및 distillation 으로 성능 향상하고 있으며, 모델 선택 및 hyperparameter tuning 을 테스트셋에 overfitting 하여 수행 공정성을 위해 Ddev32\\mathcal{D}_{dev32}Ddev32​ 에서 재실험하며 모든 보조 기술 제거 Table 5 는 P-tuning 이 모든 작업에서 manual prompt 로 비교하여 PET 및 PET-best 보다 우수한 성능 P-tuning 이 manual prompt 보다 훨씬 우수한 prompt 검색 및 few-shot task 성능 크게 향상함을 입증 CB, WiC, RTE 및 WSC 등의 task 에서 P-tuning 은 데이터 증강, 앙상블 및 distillation 등 보조 기술로 PET/iPET 보다 우수한 성능 위 결과는 P-tuning 이 few-shot NLU task 의 이점 입증","s":"4.2.2 Few-Shot Learning","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#422-few-shot-learning","p":675},{"i":704,"t":"Table 3, 4 는 NLU 성능 향상을 위해 세 가지 tuning-based paradigm 제시 P-tuning 은 BERT-based model 에서 평균적으로 약 2 point, GPT-based model 에선 5 points 이상 우수한 성능 구체적으로, P-tuning 은 대부분 task 에서 best results 를 달성하였지만, WiC 에선 cloze questions 로 정식화하기 어려워, FT 가 우수한 성능 달성 P-tuning 과 MP+FT 를 비교하면 P-tuning 이 평균적으로 MP+FT 보다 큰 이점을 보여주며, 이는 MP+FT 가 좋은 manual prompt 찾기엔 어렵기 때문이다. 반면 P-tuning 은 자동으로 더 나은 prompt 를 검색 가능 P-tuning 은 fine-tuned model 의 parameter 를 tuning 하면서 광범위한 prompt space 탐색 가능하여 새로운 tuning paradigm 으로, fine-tuning 이 어려운 LLM 을 유도하는 데 경쟁력 있는 잠재력 입증","s":"4.2.3 Finetuning v.s. MP Finetuning v.s. P-tuning","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"#423-finetuning-vs-mp-finetuning-vs-p-tuning","p":675},{"i":707,"t":"본 연구에서 P-tuning 제안 continuous space 에서 더 나은 prompt 를 자동으로 탐색하여 pre-trained model 의 NLU 능력 강화 큰 검증셋에 덜 의존적이며, adversarial prompt 로부터의 피해를 덜 입고, overfitting 완화 test 동안 추가 text 를 제공하지 않고도 LLM 의 세계 지식의 64% (P@1) 복구 SuperGLUE 에서 GPT 스타일 모델에게 NLU 능력을 BERT 와 comparable 한 성능 부여 (과거엔 불가능하다 여김) bidirectional model 에 도움되며, SuperGLUE 에서 SOTA 성능 발휘 위 결과는 LM 이 pre-training 중 생각보다 더 많은 세계 지식을 습득한 것을 입증","s":"6. Conclusion","u":"/docs/Paper/NLP/PEFT/P-tuning","h":"","p":675},{"i":709,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2110.07602.pdf","s":"P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":711,"t":"Prompt tuning 은 language model (LM) 을 freezing 한 상태에서 continuous prompt 만 조정하여, training 중 task 당 저장 및 메모리 사용량을 크게 줄이는 것 하지만 Natural Language Understanding (NLU) 엔, 이전 연구에서 prompt tuning 이 일반적인 크기의 pre-trained model 에 대해서는 잘 수행되지 않음 기존의 prompt tuning 방법이 hard sequence labeling task 를 처리할 수 없다는 것 발견 위 사항은 범용성의 부족 저자는 적절하게 최적화된 prompt tuning 이 모델 규모와 NLU 작업의 넓은 범위에 걸쳐 보편적으로 효과적일 수 있는 새로운 경험적인 결과를 제시 fine-tuning 의 성능을 맞추면서도 tuned parameter 가 0.1 ~ 3% 에 불과 P-tuning v2 는 NLU 용으로 optimized 및 adapted Deep Prompt Tuning (Prefix-tuning, soft prompts) 의 구현 P-tuning v2 의 보편성과 간단함을 고려하면, fine-tuning 의 대체제로서 향후 연구를 위한 강력한 baseline 으로 기능 가능","s":"Abstract","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":713,"t":"Pre-trained LM 은 넓은 범위의 NLU tasks 의 성능을 향상시킨다. 널리 사용되는 방법으로는 다음이 있다. Fine-tuning (FT) : target task 에 대해, model parameter 전체를 update 좋은 성능을 얻는 반면, all parameters 에 대한 gradient 및 optimizer states 를 저장해야 하므로 training 중 메모리 소비가 심하다. inference 중 각 task 에 대한 model parameter 의 copy 를 유지하는 것은, 보통 LM 이 크기 때문에 여간 불편하다 Prompting : pre-trained LM 의 all parameter 를 freezing 하고 natural language prompt 를 사용하여 LM 에 query 하는 방식 sentiment analysis 의 경우, sample (e.g. \"Amazing movie!\") 에 \"[MASK]\" 라는 prompt 를 연결하고 pre-trained LM 에게 masked token 이 \"good\" 과 \"bad\" 인 확률을 예측하도록 요청하여 label 결정 prompting 은 training 을 필요로 하지 않으며 model parameter 의 single copy 만 저장 discrete prompting 은 fine-tuning 과 비교하여 성능이 부적절한 경우가 많음 Prompt tuning (PT) : discrete prompts 만 tuning 하는 아이디어 continuous embedding (prompts) 을 input word embeddings 의 original sequence 에 추가 training 중 continuous prompts 만 updates PT 은 많은 task 에서 prompting 을 개선하지만, 모델 크기가 10B parameter 이하의 경우 FT 를 능가하지 못함 hard sequence labeling task 에서 PT 가 prompting 에 비해 성능이 나쁜 것을 관찰 본 논문의 기여는 적절히 최적화된 PF 이 다양한 모델 규모와 NLU task 범위에서 보편적으로 fine-tuning 과 comparable 하다는 발견 이전 연구와 대조적으로 저자는 NLU 에 대한 PF 의 보편성과 잠재력 발견 새로운 개념은 아니며, 생성 및 지식 탐색을 위해 설계된 Deep Prompt Tuning (Prefix-tuning, soft prompts) 의 최적화 및 적응된 구현 input layer 뿐 아니라 pre-trained LM 의 모든 layer 에 continuous prompt 적용 Deep Prompt Tuning 은 continuous 의 용량을 증가시키고 모델 크기와 hard task 의 간격을 좁히는 데 기여 fine-tuning 과 유사한 성능 보장을 위한 최적화 및 구현의 중요한 세부 사항 제시 실험 결과 P-tuning v2 는 300M 에서 10B parameter 까지 다양한 모델 규모 및 extractive question answering 및 named entity recognition 같은 hard sequence tagging task 을 포함하여 다양한 task 에서 fine-tuning 과 유사한 성능을 보이며, task 당 trainable parameter 의 비율이 0.1% ~ 3% fine-tuning 과 비교하여 training 시간 메모리 비용 및 task 당 저장 비용을 크게 줄임","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":716,"t":"NLU task 를 두 가지로 분류 simple classification tasks label space 기반으로 하는 분류 포함 GLUE 및 SuperGLUE 포함 hard sequence labeling tasks token sequence 기반으로 하는 분류 포함 named entity recognition 및 extractive question answering 포함","s":"NLU Tasks","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#nlu-tasks","p":708},{"i":718,"t":"LM M\\mathcal{M}M 의 vocabulary 를 V\\mathcal{V}V LM M\\mathcal{M}M 의 embedding layer eee discrete prompting 의 경우, prompt tokens {\"It\", \"is\", \"[MASK]\"} ⊂V\\subset \\mathcal{V}⊂V 를 영화 리뷰 분류에 사용될 수 있다. 예로, input text x\\text{x}x = \"Amazing movie!\" 가 주어지면, input embedding sequence 는 [e(x),e(\"It\"),e(\"is\"),e(\"[MASK]\")][e(\\text{x}), e(\\text{\"It\"}), e(\\text{\"is\"}), e(\\text{\"[MASK]\"})][e(x),e(\"It\"),e(\"is\"),e(\"[MASK]\")] 로 공식화 [prompt tuning. Lester, P-tuning] 는 frozen pre-trained LM 을 사용하여 NLU 에 대한 natural language prompts 대신 trainable continuous prompts 도입 trainable continuous embeddings [h0,…,hi][h_0, \\dots, h_i][h0​,…,hi​] 가 주어지면, input embedding sequence 는 Figure 2 처럼 [e(x),h0,…,hi,e(\"[MASK]\")][e(\\text{x}), h_0, \\dots, h_i, e(\\text{\"[MASK]\"})][e(x),h0​,…,hi​,e(\"[MASK]\")] 로 쓸 수 있다. Prompt tuning 은 간단한 classification task 에 10B model 을 FT 로 comparable 하게 할 수 있다.","s":"Prompt Tuning","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#prompt-tuning","p":708},{"i":721,"t":"[prompt tuning. Lester, P-tuning] 등 여러 NLP application 에서 효과적임을 입증했지만, 범용성 부족으로 인해 FT 를 대체하기엔 여전히 한계 존재","s":"3.1 Lack of Universality","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#31-lack-of-universality","p":708},{"i":723,"t":"[prompt tuning. Lester] 은 10B parameter 이상의 model scale 이 되면 PT 은 FT 와 comparable 하지만 일반적인 medium-sized model (100M ~ 1B) 의 경우에는, PT 는 FT 보다 훨씬 성능이 안좋다.","s":"Lack of universality across scales","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#lack-of-universality-across-scales","p":708},{"i":725,"t":"[prompt tuning. Lester, P-tuning] 등은 NLU 벤치마크 중 일부에 우위를 보였지만, sequence tagging task 에 대한 PT 의 효과는 검증되지 않았다. sequence tagging 은 각 input token 에 대한 label sequence 을 예측하는 task 로, 어려우며 동사화와 호환되지 않을 수 있다. 저자의 실험에서 (Section 4.2 및 Table 3 참조) [prompt tuning. Lester, P-tuning] 등은 FT 와 비교하여 전형적인 sequence tagging task 에서 성능이 좋지 않음을 보여준다. 위 어려움을 고려하여 scales 및 NLU task 에 걸쳐 범용적인 솔루션으로 deep prompt tuning 을 채택한 P-tuning v2 제안","s":"Lack of universality across tasks","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#lack-of-universality-across-tasks","p":708},{"i":727,"t":"[prompt tuning. Lester, P-tuning] 에서 continuous prompt 는 input embedding sequence 에만 삽입된다. (Figure 2 참조) 이로 인해 두 가지 challenge 발생 sequence length 제안으로 인해 tunable parameters 의 수가 제한됨 input embeddings 는 model prediction 에 상대적으로 간접적인 양향만 끼침 위 과제를 해결하기 위해 P-tuning v2 는 Deep Prompt Tuning 아이디어 채택 Fig 2 에서 설명했듯, 여러 layers 의 prompt 가 prefix tokens 에 추가됨 P-tuning v2 는 더 많은 tunable task-specific parameters (0.01% ~ 3% 까지) 를 가지고 있어 조금 더 per-task capacity 을 허용하면서도 parameter-efficient 를 유지 deeper layers 에 추가된 prompt 는 model prediction 에 더 직접적인 영향을 미침","s":"3.2 Deep Prompt Tuning","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#32-deep-prompt-tuning","p":708},{"i":730,"t":"이전 연구에서 보통 trainable embeddings 를 변환을 위해 MLP 같은 reparameterization encoder 를 활용한다. 하지만 NLU 의 경우, 그 유용성이 task 및 dataset 에 의존적이다. 일부 dataset (e.g. RTE 및 CoNLL04) 의 경우, MLP 가 일관된 성능 향상을 가져오지만, 다른 dataset (e.g. BoolQ 및 CoNLL12) 에서는 결과에 미미하거나 음의 영향을 미친다.","s":"Reparameterization","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#reparameterization","p":708},{"i":732,"t":"prompt length 는 P-Tuning v2 에서 중요한 역할을 한다. 다양한 NLU task 는 일반적으로 다른 prompt length 로 best 성능을 달성한다. 일반적으로 간단한 classification task 는 더 짧은 prompt (20 미만)을 선호하며, hard sequence labeling task 는 더 긴 prompt (약 100)을 선호한다.","s":"Prompt Length","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#prompt-length","p":708},{"i":734,"t":"Multi-task learning 은 개별 tasks 에 대한 FT 전에 shared continuous prompts 로 여러 task 를 공동으로 최적화한다. Multi-task 는 P-tuning v2 에 선택적으로 적용 가능하지만 더 나은 최적화를 제공하여 성능을 더 향상시킬 수 있다.","s":"Multi-task Learning","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#multi-task-learning","p":708},{"i":736,"t":"verbalizers 예측을 위해 LM head 를 사용하는 것은 PF 에 중요했지만, full-dataset 설정에선 불필요하며 sequence labeling 과 호환되지 않는다. 대신 P-tuning v2 는 BERT 와 같이 token 위에 randomly-initialized classification head 를 적용한다. P-tuning v2 의 주요 기여를 쉽게 Table 1 에 기재한다.","s":"Classification Head","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#classification-head","p":708},{"i":738,"t":"P-tuning v2 효과 검증을 위해 다양한 pre-trained model 과 NLU task 에 대해 광범위한 실험 수행 이 연구는 FT 를 제외한 모든 방법을 frozen language model backbones 에서 진행하며, 이는 [prompt tuning. Lester] 의 설정과 일치하지만 [P-tuning] 의 tuning 설정과는 다르다. task-specific parameters 비율 (0.1%) 은 continuous prompt 의 parameter 와 transformer 의 parameter 를 비교하여 유도 또 주목할 점은 저자의 실험은 모두 few-shot 가 아닌 fully-supervised 설정에서 진행","s":"4. Experiments","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":740,"t":"P-tuning v2 의 NLU 능력을 테스트하기 위해 SuperGLUE 를 데이터셋에 포함 또한 named entity recognition, extractive Question Answering 및 semantic role labeling 포함","s":"NLU Tasks","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#nlu-tasks-1","p":708},{"i":742,"t":"평가를 위해 BERT-large, RoBERTa-large, DeBERTa-xlarge 및 GLM-xlarge/xxlarge 포함 이 모델들은 모두 NLU task 를 위해 설계된 bidirectional model 로, 약 300M ~ 10B 까지 다양한 크기를 커버","s":"Pre-trained Models","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#pre-trained-models","p":708},{"i":744,"t":"multi-task 설정에서는 각 task type 의 데이터셋을 결합 (e.g. combing all training sets of semantic role labeling) 각 데이터셋에 대해 별도의 linear classification 를 사용하면서 continuous prompt 를 공유","s":"Multitask Learning","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#multitask-learning","p":708},{"i":746,"t":"Table 2 는 P-tuning v2 의 model scales 별 성능이다. SuperGLUE 에서 [prompt tuning. Lester, P-tuning] 은 smaller scales 에서 성능이 매우 저조할 수 있다. 반면 P-tuning v2 는 smaller scales 에서 모든 task 에서 FT 성능과 일치한다. larger scales (2B ~ 10B) 에서 GLM 을 사용하는 경우 [prompt tuning. Lester, P-tuning] 와 FT 간의 차이가 점차 좁혀짐 10B scale 에서는 [prompt tuning. Lester] 의 보고와 유사하게, PT 가 FT 와 comparable 즉, P-tuning v2 는 모든 scale 에서 FT 와 비교하여 0.1% 의 task-specific parameters 만 필요로 하면서 항상 FT 와 comparable","s":"4.1 P-tuning v2: Across Scales","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#41-p-tuning-v2-across-scales","p":708},{"i":748,"t":"Table 3 에서 우리는 P-tuning v2가 일반적으로 모든 task 에서 FT 와 유사할 수 있음을 관찰 QA task 중에서 가장 어려운 QA task 을 포함하여 [prompt tuning. Lester, P-tuning] 간의 성능 차이가 크다 [prompt tuning. Lester, P-tuning] 의 SQuAD 2.0 에서 일부 일반적이지 않은 결과 관찰. 이는 SQuAD 2.0 에는 unanswerable question 이 포함되어 있어 single-layer prompt tuning 의 최적화에 어려움을 주기 때문 QA 를 제외한 대부분의 task 에서 multi-task learning 은 P-tuning v2 에 대해 상당한 개선을 줌","s":"4.2 P-tuning v2: Across Tasks","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#42-p-tuning-v2-across-tasks","p":708},{"i":751,"t":"이전 PT approach 방식에서 Verbalizer with LM head 는 중요한 구성 요소 였다. 하지만 supervised learning 설정에서 P-tuning v2 를 사용한 경우, 약 몇 천개의 parameter 를 가진 linear head 를 tuning 하는 것이 가능하다. 저자는 다른 hyperparameter 를 유지하고 [CLS] label 을 linear head 에서 LM head 로 변경하는 것 외에 간단한 비교를 제안 간단하게 SST-2, RTE 및 BoolQ 에 대해 \"true\" 및 \"false\" 를 사용하고, CB 에 대해 \"true\", \"false\" 및 \"neutral\" 를 사용 결과 Verbalizer 와 [CLS] 의 성능 간에 유의미한 차이가 없었음","s":"Verbalizer with LM head v.s. [CLS] label with linear head","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#verbalizer-with-lm-head-vs-cls-label-with-linear-head","p":708},{"i":753,"t":"[prompt tuning. Lester] 와 P-tuning v2 사이의 주요 차이점은 multi-layer continuous prompt 이다. 정확한 영향 검증을 위해 prompt 를 추가할 kkk layers 를 선택하고, 오름 및 내림차순으로 prompt 를 추가하도록 하여 특정 수의 layer 에 대해 실험을 수행하고 나머지 layer 에 대해서는 그대로 둔다. 동일한 parameter 양 (prompt 를 추가할 transformer layer 수)으로 내림차순으로 추가하는 것이 항상 오름차순 보다 나은 결과를 가져옴 RTE 경우엔 layers 17-24 에만 prompt 를 추가하는 것만으로 모든 layer 를 사용하는 것과 거의 유사한 성능 달성","s":"Prompt depth","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"#prompt-depth","p":708},{"i":755,"t":"P-tuning v2 제안 상대적으로 제한적인 혁신성을 가지지만, PF 이 모든 규모 (330M ~ 10B parameter)와 task 에 걸쳐 FT 와 comparable 한 새로운 발견에 기여 높은 정확도와 parameter-efficient 를 가지며, P-tuning v2 는 미래 연구의 강력한 baseline 이 될 수 있는 잠재적인 대안","s":"5. Conclusions","u":"/docs/Paper/NLP/PEFT/P-tuning v2","h":"","p":708},{"i":757,"t":"논문 및 이미지 출처 : https://aclanthology.org/2021.acl-long.353.pdf","s":"Prefix-Tuning: Optimizing Continuous Prompts for Generation","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":759,"t":"Fine-tuning (FT) 는 large pre-trained language models 를 downstream task 에 활용하는 표준 방법이다. 하지만 FT 는 language model (LM) parameter 를 수정하고 각 task 에 대한 full copy 를 저장해야 한다. 본 논문에선 natural language generation (NLG) tasks 에 대한 FT 의 경량적 대안인 prefix-tuning 를 제안 prefix-tuning 는 LM parameter 를 freezing 하는 대신 continuous task-specific vectors 의 sequence 인, prefix 를 최적화 LM prompting 에서 영감을 받아 subsequent tokens 가 이 prefix 를 \"virtual tokens\" 처럼 참조할 수 있게함 저자는 prefix-tuning 을 table-to-text generation 을 위해 GPT-2 에 적용하고 요약을 위해 BART 에 적용 0.1% parameter 만 수정함으로써, prefix-tuning 은 full data 설정에서 동등한 성능 및 low-data 설정에서 FT 를 능가하며, training 중 unseen topics 를 가진 examples 를 더 잘 추론","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":761,"t":"Fine-tuning (FT) 은 large pre-trained language model 을 사용하여 donwstream task (e.g. summarization) 를 수행하는 주요 패러다임. 하지만 FT 는 LM 의 모든 parameter 를 update 하고 저장해야 하므로 각 task 마다 수정된 모든 LM parameter 의 copy 를 저장해야 한다. 현재 LM 크기를 고려하면 비용이 매우 많이 든다. 예로, GPT-2 는 774M parameter, GPT-3 는 175B parameter 를 가지고 있다. 이 문제를 lightweight fine-tuning 으로, pre-trained LM 대부분의 parameter 를 freezing 하고 smaller parameter set 만 tuning 하는 것이다. 예로, adapter-tuning 은 pre-trained LM 의 layers 사이에 additional task-specific layers 를 삽입한다. adapter-tuning 은 NLU 및 NLG 에서 유망한 성능을 보이며 FT 와 유사한 성능을 달성하여 약 2-4% 정도의 task-specific parameter 를 추가한다. 극단적으로 GPT-3 는 어떠한 LM parameter 도 수정하지 않고 in-context learning 을 사용하여 배포 가능하다. in-context learning 은 prompting 의 한 형태로, natural language task instruction 와 몇 가지 예제를 task input 에 먼저 추가한 다음 LM 에서 task output 생성. 하지만 Transformer 는 제한된 길이의 context (GPT-3 의 경우 2048) 에만 의존할 수 있어, in-context learning 은 매우 작은 훈련셋으로 제한된다. 본 논문에서는 prompting 에 영감을 받은 lightweight FT 인 prefix-tuning 을 제안 task input 은 linearized table (e.g. \"name: Starbucks | type: coffee shop\") 이며 output 은 text description (예: \"Starbucks serves coffee\") Prefix-Tuning 은 input 에 continuous task-specific vectors sequence 인 prefix 를 앞에 추가 이 prefix 는 Figure 1 (아래) 에 빨간 블록으로 표시 각 토큰 생성 시, LM 은 prefix 에 참조할 수 있으므로 prefix 가 \"virtual token\" sequence 처럼 작동하지만 prefix 는 실제 토큰과 대응하지 않는 free parameter 로만 구성 반면 Figure 1 (위) 의 FT 는 모든 LM parameter 를 update 하고 각 task 마다 tuned model 의 copy 를 저장해야 함 결과적으로, 저자는 LLM 과 learned task-specific prefix 의 copy 만 저장하면 되므로 각 additional task 에 대한 매우 작은 overhead 발생 (e.g. 250K parameter for table-to-text)","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":764,"t":"input xxx 가 context 고 output yyy 가 token sequence 인 조건부 생성 작업을 고려 Figure 2 (오른쪽)에 나와 있는 두 가지 작업에 중점을 둔다. table-to-text 에서, xxx 는 linearized data table 에 해당하고 yyy 는 text description 이다. summarization 에서, xxx 는 article 이고 yyy 는 summary 이다.","s":"3. Problem Statement","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"","p":756},{"i":766,"t":"ϕ\\phiϕ (e.g. GPT-2) 에 의한 parameterized autoregressive neural language model pϕ(y ∣ x)p_{\\phi}(y\\ |\\ x)pϕ​(y ∣ x) 가 있다고 가정하자. Figure 2 (위)에 있는 것 처럼, z=[x;y]z = [x; y]z=[x;y] 으로, xxx 와 yyy 의 연결 Xidx\\text{X}_{\\text{idx}}Xidx​ 는 xxx 에 해당하는 indices sequence 로 나타냄 Yidx\\text{Y}_{\\text{idx}}Yidx​ 도 yyy 에 대해 동일하게 적용 iii time step 에서의 activation vector 는 hi∈Rdh_i \\in \\mathbb{R}^dhi​∈Rd 여기서 hi=[hi(1);⋯ ;hi(n)]h_i = [h_i^{(1)}; \\cdots; h_i^{(n)}]hi​=[hi(1)​;⋯;hi(n)​] 은 이 time step 의 all activation layers 를 연결 hi(j)h_i^{(j)}hi(j)​ 는 time step iii 에서의 jjj-th layer 의 activation vector autoregressive neural LM 은 다음과 같이 left context 에서 ziz_izi​ 와 past activations 의 function 으로 hih_ihi​ 계산 hi=LMϕ(zi,h<i),\\begin{equation} h_i = \\text{LM}_{\\phi} (z_i, h_{<i}), \\end{equation}hi​=LMϕ​(zi​,h<i​),​​ hih_ihi​ 의 last layer 는 next token: pϕ(zi+1 ∣ h≤i)=softmax(Wϕhi(n))p_{\\phi}(z_{i+1}\\ |\\ h_{\\leq i}) = \\text{softmax}(W_{\\phi} h_i^{(n)})pϕ​(zi+1​ ∣ h≤i​)=softmax(Wϕ​hi(n)​) 의 distribution 계산을 위해 사용 WϕW_{\\phi}Wϕ​ 는 hi(n)h_i^{(n)}hi(n)​ 를 vocabulary logits 으로 매핑하기 위한 행렬","s":"3.1 Autoregressive LM","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#31-autoregressive-lm","p":756},{"i":768,"t":"pϕ(y ∣ x)p_{\\phi}(y\\ |\\ x)pϕ​(y ∣ x) 모델링을 위해 encoder-decoder architecture (e.g. BART) 를 사용할 수 있다. xxx 는 bidirectional encoder 에 의해 인코딩된 것 decoder 는 yyy 를 autoregressively predict (encoded xxx 및 left context 에 조건을 둔 상태) 동일한 indexing 및 activation notation 은 Figure 2 (아래) 와 같이 표시 i∈Xidxi \\in \\text{X}_{\\text{idx}}i∈Xidx​ 는 bidirectional encoder 에 의해 계산 i∈Yidxi \\in \\text{Y}_{\\text{idx}}i∈Yidx​ 에 대한 각 hih_ihi​ 는 Eq. 1 을 사용하여 autoregressive decoder 로 계산","s":"3.2 Encoder-Decoder Archirecture","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#32-encoder-decoder-archirecture","p":756},{"i":770,"t":"full FT 에서, 저자는 pre-trained parameter ϕ\\phiϕ 를 초기화한다. 여기서 pϕp_{\\phi}pϕ​ 는 trainable LM distribution 이며, 다음 log-likelihood objective 를 따라 gradient update 를 수행한다. max⁡ϕ log⁡pϕ(y ∣ x)=max⁡ϕ∑i∈Yidxlog⁡pϕ(zi ∣ h<i).\\begin{equation} \\underset{\\phi}{\\max}\\ \\log p_{\\phi}(y\\ |\\ x) = \\underset{\\phi}{\\max} \\sum_{i \\in \\text{Y}_{\\text{idx}}} \\log p_{\\phi} (z_i\\ |\\ h_{<i}). \\end{equation}ϕmax​ logpϕ​(y ∣ x)=ϕmax​i∈Yidx​∑​logpϕ​(zi​ ∣ h<i​).​​","s":"3.3 Fine-tuning","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#33-fine-tuning","p":756},{"i":773,"t":"Prompting 은 parameter 를 변경하지 않고 LM 을 조절할 수 있는 적절한 context 에 조건을 둔다. 예로 LM 이 word (e.g. Obama) 를 생성하길 원하면, 해당 단어의 일반적인 공존어를 context 로 추가할 수 있으며 (e.g. Barack), LM 은 원하는 단어에 훨씬 더 높은 확률을 할당한다. single word 나 sentence 생성을 넘어, 이러한 intuition 을 확장하여 LM 을 NLG task 를 해결하도록 조절하는 context 를 찾기를 원한다. context 는 task input xxx 에서 추출할 내용을 가이드함으로써 task input xxx 의 인코딩에 영향을 미칠 수 있다. next token distribution 을 조절함으로써 task output yyy 의 생성에도 영향을 미칠 수 있다. 하지만 위같은 context 가 존재하는지 명백하지 않으며, natural language task instruction (e.g. \"summarize the following table in one sentence\") 를 사용하면 context 가 task 를 해결하도록 인간을 가이드할 수 있지만, 중간 규모의 pre-trained LM 에서는 실패한다. discrete instruction 최적화는 도움 될 수 있지만, computationally challenging discrete token 최적화 대신, instruction 을 저자는 continuous word embeddings 로 최적화할 수 있으며, 그 효과는 all Transformer activation layers 로 propagated upward 되고 subsequent token 으로 rightward 된다. 이는 실제 단어의 embeddings 로 제한되는 discrete prompt 보다 표현력이 높다. Prefix-tuning 은 표현력을 높이는데서 더 나아가 all activation layers 를 최적화함으로써 나아간다. 다른 이점으로는 network depth 에 따라 long computation paths 를 피하기 위해 representations 를 직접 수정할 수 있다.","s":"4.1 Intuition","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#41-intuition","p":756},{"i":775,"t":"Prefix-Tuning 은 autoregressive LM 에 prefix 를 덧붙여 z=[PREFIX;x;y]z = [\\text{PREFIX}; x; y]z=[PREFIX;x;y] 를 얻거나 encoder 및 decoder 모두에 prefix 를 덧붙여 z=[PREFIX;x;PREFIX′;y]z = [\\text{PREFIX}; x; \\text{PREFIX}'; y]z=[PREFIX;x;PREFIX′;y] 을 얻는다. (Fig 2 참조) 여기서, Pidx\\text{P}_{\\text{idx}}Pidx​ 는 prefix indices 의 sequence ∣Pidx∣|\\text{P}_{\\text{idx}}|∣Pidx​∣ 는 prefix length Eq. 1 의 recurrence relation 을 따르되, prefix indices 의 activation 은 free parameter 이며, dimension ∣Pidx∣×dim(hi)|\\text{P}_{\\text{idx}}| \\times \\text{dim}(h_i)∣Pidx​∣×dim(hi​) 의 matrix Pidx\\text{P}_{\\text{idx}}Pidx​ (θ\\thetaθ 에 의해 parameterized) 에 의해 주어진다. hi={Pθ[i,:],ifi∈PidxLMϕ(zi,h<i),otherwise.\\begin{equation} h_i = \\left\\{\\begin{matrix} P_\\theta [i, :], & \\text{if} i \\in \\text{P}_{\\text{idx}} \\\\ \\text{LM}_{\\phi}(z_i, h_{<i}), & \\text{otherwise.} \\end{matrix}\\right. \\end{equation}hi​={Pθ​[i,:],LMϕ​(zi​,h<i​),​ifi∈Pidx​otherwise.​​​ training objective 는 Eq. 2 와 동일하게 하지만 trainable parameters set 은 변경한다. LM parameters ϕ\\phiϕ 는 고정되고 prefix parameters θ\\thetaθ 만 trainable parameters 이다. 여기서 각 hih_ihi​ 는 trainable PθP_\\thetaPθ​ 의 function 이다. i∈Pidxi \\in \\text{P}_{\\text{idx}}i∈Pidx​ 인 경우 hih_ihi​ 는 PθP_\\thetaPθ​ 로 직접 copy 되기 때문에 clear 하다. i∉Pidxi \\notin \\text{P}_{\\text{idx}}i∈/Pidx​ 인 경우 prefix activation 은 항상 left context 에 있으며 right activation 에 어떠한 영향을 미칠 것이기 때문에 hih_ihi​ 는 여전히 PθP_\\thetaPθ​ 에 의존적이다.","s":"4.2 Method","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#42-method","p":756},{"i":777,"t":"PθP_\\thetaPθ​ 를 직접적으로 update 하는 것은 불안정한 최적화와 약간의 성능 저하를 유발 따라서 저자는 smaller matrix (Pθ′P'_\\thetaPθ′​) 로 large feedforward neural network MLPθ\\text{MLP}_\\thetaMLPθ​ 를 포함한 reparameterized matrix Pθ[i:0]=MLPθ(Pθ′[i,:])P_\\theta [i:0] = \\text{MLP}_\\theta (P'_\\theta [i,:])Pθ​[i:0]=MLPθ​(Pθ′​[i,:]) 을 만든다. 이제 trainable parameters 는 Pθ′P'_\\thetaPθ′​ 및 MLPθ\\text{MLP}_\\thetaMLPθ​ 의 parameter 를 포함한다. PθP_\\thetaPθ​ 와 Pθ′P_\\theta'Pθ′​ 는 rows 수는 같지만 column 수가 다르다. training 이 완료되면, 이런 reparameterization parameters 를 drop 하고 prefix (PθP_\\thetaPθ​) 만 저장하면 된다.","s":"4.3 Parameterization of PθP_{\\theta}Pθ​","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#43-parameterization-of-p_theta","p":756},{"i":780,"t":"table-to-text task 를 위한 세 가지 generation dataset 인 E2E, WebNLG 및 DART 에서 평가 dataset 은 복잡성과 크기에 따라 정렬됨 E2E 는 레스토랑 리뷰만 1 domain WebNLG 는 14 domains DART 는 Wikipedia 의 open domain table 사용 summarization task 의 경우, 뉴스 기사에 대한 요약 데이터셋 XSUM 사용 ROUGE-1, ROUGE-2 및 ROUGE-L 을 보고","s":"5.1 Datasets and Metrics","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#51-datasets-and-metrics","p":756},{"i":782,"t":"table-to-text generation task 대해 prefix-tuning 을 다른 세 가지 방법과 비교 full fine-tuning (FT-FULL), top 2 layers fine-tuning (FTTOP2), adapter tuning (ADAPTER)","s":"5.2 Methods","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#52-methods","p":756},{"i":784,"t":"table-to-text 에 대해 GPT-2-MEDIUM 및 GPT-2-LARGE 사용 summarization task 에 대해선 BART LARGE 사용 저자의 구현은 huggingface transformers 에 기반 training 시 AdamW optimizer 및 Hugging Face 의 기본 설정에 따른 linear learning rate scheduler 사용 hyperparameter 는 epochs, batch size, learning rate 및 prefix length 들을 조정 10 epochs 5 batch size 5⋅10−55 \\cdot 10^{-5}5⋅10−5 learning rate 10 prefix length model 은 TITAN Xp 또는 GeForce GTX TITAN X 에서 훈련 Prefix-tuning 은 22,000개 examples 에 대해 epoch 당 0.2 시간 걸림 Fine-tuning 은 epoch 당 0.3 시간 걸림 summarization model 은 Telsa V100 에서 훈련 XSUM dataset 은 epoch 당 1.25 시간 걸림 prefix-tuning 은 fine-tuning 보다 약 30% 시간 효율성이 좋음 GPU 메모리 효율성에선, 1 batch size 로 하는 prefix-tuning 은 총 GPU 메모리의 10% 차지 및 fine-tuning 은 50% 차지 디코딩 시엔 table-to-text task 에 대해 beam search 사용하며 크기는 5 summarization task 에선 6 beam 과 0.8 length normalization 사용 table-to-text 의 경우, batch 처리를 하지 않고 문장 당 1.2초, summarization 의 경우엔 10 batch size 를 사용하여 배치당 2.6초가 걸림","s":"5.3 Architectures and Hyperparameters","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#53-architectures-and-hyperparameters","p":756},{"i":787,"t":"0.1% 의 task-specific parameter 만 update 하여, prefix-tuning 은 table-to-text generation 에서 효과적 다른 lightweight baseline (ADAPTER 및 FT-TOP2) 를 능가하며 parameter 를 30배 적게 update 하면서도 (full) FT 와 comparable prefix-tuning 과 adapter-tuning 의 parameter 수를 0.1% 로 맞추면, Table 2 에서 prefix-tuning 이 ADAPTER 보다 큰 성능을 보임 평균적으로 데이터셋 당 4.1 BLEU 개선 fine-tuning (100%) 및 adapter-tuning (3.0%) 와 비교하여 prefix-tuning 은 두 시스템과 comparable 또는 나은 성능 이는 prefix-tuning 이 adapter-tuning 보다 Pareto efficient 이며, generation quality 향상 및 parameter 를 크게 줄임 DART 에서 좋은 성능을 달성하여, prefix-tuning 이 다양한 domain 과 많은 table 에 일반화될 수 있음을 시사 요약하면, prefix-tuning 은 GPT-2 를 table-to-text generation 에 적응시키는데 효과적이고 공간 효율적인 방법. 또한 GPT-2-LARGE 로 확장하면 성능 이득을 유지하며, GPT-3 같은 아키텍처로 더 큰 모델로의 확장에서도 잠재력이 있음을 시사","s":"6.1 Table-to-text Generation","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#61-table-to-text-generation","p":756},{"i":789,"t":"위에서 보이듯 2% parameter 로 prefix-Tuning 는 FT 보다 약간 낮다. parameter 가 0.1% 일 때, prefix-tuning 은 full FT 에 못미친다. table-to-text dataset 과 XSUM 간에는 prefix-Tuning 이 table-to-text 에서 우위를 가지는 이유는 다음 차이점이 있다. XSUM 은 평균적으로 세 개의 table-to-text dataset 보다 4배 많은 예제 포함 입력 기사에는 평균적으로 table-to-text dataset 의 linearized table input 보다 17배 김 요약에선 기사로부터 주요 내용을 선택해야 하므로 table-to-text 보다 복잡","s":"6.2 Summarization","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#62-summarization","p":756},{"i":791,"t":"table-to-text 및 summarization 결과를 기반으로, prefix-tuning 은 training example 수가 적을 때 비교적 이점을 가짐 low-data 설정에 대해 체계적으로 탐구하기 위해 전체 데이터셋의 sub-sample 을 사용 각 크기에 대해 5개의 다른 데이터셋을 샘플링하고 2개의 훈련 랜덤 시드에서 평균을 냈다. 따라서 low-data 설정마다 10개의 모델을 평균화하였다. 위의 오른쪽은 dataset size 가 커짐에 따라 간격이 좁아지지만, low-data 에서 prefix-tuning 이 평균적으로 2.9 BLEU 더 높은 성능을 보이고 smaller parameter 가 필요하다는 것을 시사한다. 왼쪽에선 다른 데이터 수준에서 훈련된 prefix-tuning 및 fine-tuning 모델에 의해 생성된 8개의 예제이다. 두 방법 모두 low-data 설정에서 table content 가 누락되는 경향이 있지만, prefix-tuning 은 fine-tuning 보다 믿음직 스러운 경향이 있다. 예로 fine-tuning (100, 200) 은 실제 평균 고객 등급을 낮게 평가하는 반면, prefix-tuning (100, 200) 은 테이블과 일치하는 설명을 생성한다.","s":"6.3 Low-data Setting","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#63-low-data-setting","p":756},{"i":793,"t":"table-to-text 및 summarization 의 unseen topic 으로 extrapolation 성능 조사 extrapolation 설정을 위해 기존 데이터셋을 분할하여 training 및 test 가 다른 topic 을 다루도록 함 table-to-text 의 경우 WebNLG 데이터셋은 table topic 으로 label 지정 training 및 dev 에 나타나는 9개 카테고리는 SEEN, text 에만 나타나는 5개의 카테고리는 UNSEEN 으로 표시 SEEN 카테고리에 훈련하고 UNSEEN 카테고리에 테스트 summarization 의 경우 두 가지 extrapolation data 분할을 구성 new-to-sports 에서, 뉴스 기사를 훈련하고 스포츠 기사를 테스트 within-new 에서, {world, UK, business} 뉴스를 훈련하고 나머지 뉴스 카테고리에서 테스트 table-to-text 및 summarization 모두에서 prefix-tuning 은 Table 4 와 Table 2 에 표시된 것과 같이 모든 메트릭에서 FT 보다 extrapolation 성능이 우수 또한 adapter-tuning 도 prefix-tuning 과 유사한 extrapolation 성능 달성하며, Table 2 에서 보이듯 이 공통된 경향은 LM parameter 를 보존하는 것이 extrapolation 에 긍정적인 영향을 미친다는 것을 시사","s":"6.4 Extrapolation","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#64-extrapolation","p":756},{"i":796,"t":"longer prefix 는 더 많은 trainable parameter 를 통해 더 큰 표현력을 의미 prefix 증가에 따라 성능이 증가하다 임계값에 도달 (summarization 은 200, table-to-text 는 10) 후 약간의 성능 저하 임계값보다 긴 prefix 는 낮은 training loss 를 유발하지만 약간 더 나쁜 테스트 성능을 나타내어 training data 에 overfitting 가능성을 시사","s":"7.1 Prefix Length","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#71-prefix-length","p":756},{"i":798,"t":"\"virtual token\" 의 continuous embedding 을 최적화하는 것을 embedding-only 라 부른다. word embedding 은 free parameter 이며 나머지 activation layers 는 Transformer 에 의해 계산된다. Table 5 상단에는 성능 하락을 보여주며, embedding layer 만 조정하는 것은 충분한 표현력이 부족하는 것을 시사 embedding-only 는 discrete prompt 최적화의 성능 상한선을 제시한다. 이유는 discrete prompt 가 embedding layer 를 정확하게 실제 단어의 embedding 과 일치시키도록 제한하기 때문이다. 따라서 다음과 같은 증가하는 표현력 chain 이 있다. discrete prompting < embedding-only < prefix-tuning","s":"7.2 Full vs Embedding-only","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#72-full-vs-embedding-only","p":756},{"i":800,"t":"sequence 내에서 trainable activations 위치에 따른 성능 조사 이러한 trainable activation 을 시작 부분 [PREFIX;x;y][\\text{PREFIX}; x; y][PREFIX;x;y] 에 배치한다. 또한 trainable activation 을 xxx 와 yyy 사이 (i.e. [x;INFIX;y][x; \\text{INFIX}; y][x;INFIX;y]) 에도 위치하며 이를 infix-tuning 이라 한다. Table 5 (하단) 에서 infix-tuning 이 prefix-tuning 보다 약간 성능이 낮다는 것을 보여준다. 이는 prefix-tuning 이 xxx 와 yyy 의 activation 에 영향을 미칠 수 있지만 infix-tuning 은 yyy 의 activation 에만 영향을 미칠 수 있기 때문이다.","s":"7.3 Prefix-tuning vs Infix-tuning","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#73-prefix-tuning-vs-infix-tuning","p":756},{"i":802,"t":"저자는 prefix 가 data 설정에 어떻게 initialization 되는지가 성능에 큰 영향을 끼지는 것을 발견 Random initialization 은 low performance, high variance 를 가짐 실제 단어의 activation 으로 초기화하는 것은 generation 을 크게 향상시킴 특히 summarization 과 text-to-text task 에 이와 관련된 단어로 초기화하면 \"elephant\" 나 \"divide\" 같이 관련 없는 단어보다 약간 더 나은 성능을 얻지만 random initialization 이 더 나은 성능을 보임 또한 전체 데이터 설정에서 initialization trick 은 영향을 미치지 않으며 random initialization 도 동일한 수준의 성능 제공 prefix 를 pre-trained LM 에 의해 계산된 실제 단어의 activation 으로 초기화하기 때문에 이 전략은 prefix-tuning 개념과 일치","s":"7.4 Initialization","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#74-initialization","p":756},{"i":804,"t":"data efficiency 측면에서도 random initialization 을 사용한 prefix-tuning 과 전체 fine-tuning 의 성능을 비교하면 E2E task 의 5가지 데이터 규모 (10%, 20%, 40%, 60% 및 80%) 에서 성능 비교 Figure 6 은 20% 이상의 데이터를 사용할 때 prefix-tuning 이 fine-tuning 보다 성능이 우수함을 보여줌. 데이터 규모가 10% 인 경우 random initialization 을 사용한 prefix-tuning 이 full fine-tuning 과 유사하거나 약간 더 낮은 성능을 제공하여 이 low-data 범위에서 성능을 향상시키기 위해 initialization trick 이 필요함을 시사","s":"7.5 Data Efficiency","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#75-data-efficiency","p":756},{"i":807,"t":"1 에서 언급했듯, prefix-tuning 은 독립적인 훈련이 많은 task 에 유리 한 사례로 user privacy 보호를 위해 각 사용자의 데이터를 분리하고 각 사용자에 대해 별도의 개인화된 모델을 훈련한다고 했을 때, 각 사용자는 독립적인 task 로 간주할 수 있음 수백만 명의 사용자가 있을 경우 prefix-tuning 은 이 설정에서 확장 가능하며, 유연한 방식으로 사용자를 추가하거나 삭제할 수 있어 교차 오염없이 작동할 수 있다.","s":"Personalization","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#personalization","p":756},{"i":809,"t":"동일한 personalization 설정에서도 prefix-tuning 은 다른 prefix 를 사용한 다른 사용자의 쿼리를 배치로 처리 가능 여러 사용자가 입력으로 클라우드 GPU 에 쿼리하는 경우, 동일한 배치에 넣는 것이 계산적으로 효율적 prefix-tuning 은 shared LM 을 그대로 유지하므로 배치를 만드는 것은 입력에 개인화된 prefix 를 추가하는 단순한 단계가 필요하며 나머지 계산은 변경되지 않는다. 반면, adapter-tuning 은 shared transformer layer 사이에 개인화된 adapter 가 있는 경우 서로 다른 사용자를 배치로 처리할 수 없다. 이러한 배치 이점은 동일한 task 에 훈련된 여러 prefix 의 효율적인 앙상블을 생성하는 데 도움이 될 수도 있다.","s":"Batching across users.","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#batching-across-users","p":756},{"i":811,"t":"Fine-tuning 은 all pretrained parameter 를 업데이트하는 반면, prefix-tuning 과 adapter-tuning 은 보존한다. LM 은 일반적인 목적의 corpora 에서 pretraining 되었으므로 LM parameter 를 보존하면 training 중의 unseen domain 에 대한 일반화에 도움 가능 이에 따라 prefix-tuning 과 adapter-tuning 이 inference 설정에서 큰 성능 향상을 보이는 것을 관찰 (6.4). 그러나 이러한 방법이 추론을 어떻게 개선하는지는 여전히 알려지지 않은 문제 Prefix-tuning 과 adapter-tuning 은 둘 다 pre-trained parameter 를 고정하지만 Transformer 의 activation layer 에 영향을 미치기 위해 다른 parameter set tuning. Prefix-tuning 은 LM 을 그대로 유지하며 prefix 와 pre-trained attention block 을 사용하여 이후 activation 에 영향을 미친다. 반면, adapter-tuning 은 LM layer 사이에 trainable module 을 삽입하여 activation 에 직접 residual vectors 추가. 더불어, prefix-tuning 은 adapter-tuning 에 비해 훨씬 적은 parameter 를 필요로 하는 것을 관찰했는데, 이는 prefix-tuning 이 pre-trained LM 을 가능한 한 그대로 유지하여, adapter-tuning 보다 LM을 더 활용하기 때문이라고 생각한다. 최근 연구는 intrinsic dimension 을 사용하여 fine-tuning 과 동일한 효과를 내는 low-dimensional reparameterization 수가 존재함을 보여줌. 왜 downstream task 에서 작은 수의 parameter 만 update 해도 좋은 정확도를 얻을 수 있는지를 설명한다. 저자의 연구는 small prefix 를 update 함으로써 좋은 생성 성능도 얻을 수 있음을 보여준다. 그러나 prefix-tuning 은 단순히 trainable parameter 의 크기뿐만 아니라 어떤 subset parameter 를 수정해야 하는지에 관한 것이다. 따라서 미래 연구에서 더 나은 accuracy-size trade-off 를 달성하는 다른 light-weight fine-tuning 방법을 탐구하는 것은 흥미로울 것.","s":"Inductive bias of prefix-tuning","u":"/docs/Paper/NLP/PEFT/Prefix-Tuning","h":"#inductive-bias-of-prefix-tuning","p":756},{"i":813,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2104.08691.pdf","s":"The Power of Scale for Parameter-Efficient Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":815,"t":"본 연구는 Prompt Tuning 탐구 downstream task 수행을 위해 frozen language model (LM) 으로 soft prompt 를 학습하기 위한 간단하면서 효과적인 매커니즘 GPT-3 의 discrete prompt 와 달리, soft prompt 는 backpropagation 으로 학습되며, 여러 labeled examples 의 signals 를 통합하기 위해 tuning 가능 저자의 end-to-end learned appoach 는 GPT-3 의 few-shot learning 을 큰 폭으로 능가 T5 로 model size 에 대한 실험으로, 수십 억 이상의 parameter 를 가지면 prompt tuning 이 comparable 한 것을 보여줌 이 결과는 큰 모델은 sharing 및 serve 가 어려워 특히 중요하며, one frozen model 을 여러 downstream 에 재사용 가능한 능력은 이 부담을 줄여줌 저자의 방법은 prefix tuning 을 단순화한 것이며, 유사한 접근 방식과 비교한다. soft prompt 를 사용한 frozen model 을 설정하는 것이 domain transfer 에 대한 robustness 를 제공하고 효율적인 prompt ensembling 가능하게 함","s":"Abstract","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":817,"t":"LLM 의 성공으로 downstream task 에 맞게 tuning 하는 것이 등장. ELMo 는 frozen pre-trained model 로 per-layer representation 의 task-specific weight 를 학습하는 것 제안 GPT 및 BERT 이후엔 우세한 adaptation 기술이 model tuning (fine-tuning) 이며 adaptating 중 all model parameter 가 tuning 됨 [Universal language model fine-tuning for text classification. Howard, Ruder] 의 제안대로 model tuning 이루어짐 이후 [Language models are few-shot learners. Brown] 에서 prompt design (priming) 이 frozen GPT-3 의 동작을 text prompt 를 통해 효과적인 tuning 이 가능하단 것을 보여줌 prompt 는 일밥적으로 task description 및 여러 examples 로 구성된다. model size 가 증가함에 따라 pre-trained model 을 freezing 하는 것은 매력적이며, downstream task 마다 별도의 model copy 를 요구하지 않고, 하나의 모델이 동시에 많은 task 를 수행할 수 있다. 하지만 prompt-based adaptation 에는 주요 단점이 있다. task description 은 오류 발생이 쉽고 인간 개입이 필요 prompt 의 효과는 model input 에 얼마나 많은 conditioning text 가 fit 될 수 있는지 제한 downstream task quality 는 여전히 tuned model 의 quality 를 뒤쳐지게 함 예로 GPT-3 175B 의 few-shot 성능은 Fine-tuned T5-XXL 보다 낮다. (parameter 는 16배 큰데 낮음) prompt design 자동화를 위해 여러 연구가 진행됐다. [AutoPrompt. Shin] 은 downstream application program training data 에 의해 가이드되는 word discrete space 에서의 search algorithm 제안 manual prompt design 을 능가하지만 model tuning 과 비교하면 여전히 차이남 [Prefix-tuning. Li and Liang] 은 generation task 에 강력한 결과를 보여줌 frozen model parameter 로 tuning 중 각 layer 의 prepended activations 로 prefix 훈련 [WARP. Hambardzumyan] 는 masked LM 의 input 및 output subnetwork 로 제한된 trainable parameter 제안 classification 에 합리적인 결과 보여줌 본 논문은 adapting LM 에 대한 더 간단한 prompt tuning 제안 frozen entire pre-trained LM 으로 각 downstream task 마다 input text 에 additional kkk tunable tokens 만 prepend 이 soft prompt 는 end-to-end 로 training 되며 full labeled dataset 의 signals 압축하여 few-shot prompt 를 능가하고 model tuning 과의 quality gap 좁힐 수 있음 (Fig. 1) 동시에 single pre-trained model 이 all downstream task 에 재활용되므로 frozen model 의 efficient serving 이점 유지 (Fig. 2) 저자의 method 는 [Prefix-tuning. Li and Liang, WARP. Hambardzumyan] 와 달리, prompt tuning 만으로도 model tuning 과 comparable (with no intermediate-layer prefixes 또는 task-specific output layers) Section 2-3 에서, 자세한 실험으로 LM capacity 가 이러한 approach 를 통해 성공하기 중요한 요소임을 입증 Section 4 에서, 유사한 approach 와 비교 task-specific parameters 를 NLU 에 필요한 \"generalist\" parameters 로부터 명시적으로 분리하여 추가적인 혜택을 얻을 수 있음 Section 5 에서, prompt 에서의 task definition 를 capture 하면서 generalist parameters 를 고정시키면, domain shifts 에 대한 resilience (내구성) 향상시키며 classic model ensembling 보다 효율적임을 보여줌 Section 7 에서 learned soft prompt 의 해석 조사 주요 기여는 다음과 같다. prompt tuning 제안 및 LLM 영역에서의 model tuning 과 comparable 여러 design choices ablating 및 quality 와 robustness with scale 로 향상 보여줌 prompt tuning 이 domain shift problems 을 위한 model tuning 을 능가 prompt ensembling 제안으로 효과적임을 보여줌","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":819,"t":"T5 의 text-to-text approach 를 따라 all task 를 text generation 처리 some input 에 대한 output class 의 probability 같은 classification modeling Pr⁡(y∣X)\\Pr (y|X)Pr(y∣X) 대신에, 저자는 conditional generation 으로 모델링 XXX : 일련의 토큰 yyy : single class label T5 는 classfication 을 Pr⁡θ(Y∣X)\\Pr_\\theta (Y|X)Prθ​(Y∣X) 로 모델링한다. YYY : class label 을 나타내는 token sequence encoder-decoder 로 구성된 Transformer 의 weight θ\\thetaθ 로 parameterize Prompting 은 generation 중 condition 을 위해 extra information 을 추가하는 approach 일련의 tokens PPP 를 input XXX 에 prepend 하여 수행 correct YYY 의 likelihood Pr⁡θ(Y∣[P;X])\\Pr_\\theta (Y|[P;X])Prθ​(Y∣[P;X]) 를 최대화 parameter θ\\thetaθ 는 고정 GPT-3 에서는 prompt token P={p1,p2,…,,pn}P = \\{ p_1, p_2, \\dots, , p_n \\}P={p1​,p2​,…,,pn​} 의 representations 는 model 의 embedding table 일부로 구성 frozen θ\\thetaθ 로 parameterize 따라서 최적의 prompt 를 찾으려면 prompt token 을 선택해야 하며, 이는 manual search 또는 non-differentiable search method 로 이루어진다. prompt tuning 은 prompt PPP 가 θ\\thetaθ 로 parameterize 되어야 한다는 제한을 제거하고, 대신 prompt 에 자체적인 parameters θP\\theta_PθP​ 가 있어, update 할 수 있는 방식이다. prompt design 은 frozen embeddings 의 fixed vocabulary 에서 prompt tokens 를 선택하는 것을 포함한 반면, prompt tuning 은 special tokens 의 fixed prompt 를 사용하는 것으로 생각할 수 있으며, 이때 special tokens 의 embeddings 만 update 이제 새로운 conditional generation 은 Pr⁡θ;θP(Y∣[P;X])\\Pr_{\\theta;\\theta_P}(Y|[P;X])Prθ;θP​​(Y∣[P;X]) 이며, YYY 의 likelihood 를 최대화하기 위해 backpropagation 으로 훈련된다. 반면, θP\\theta_PθP​ 에는 gradient update 만 적용된다. nnn 개의 tokens {x1,x2,…,xn}\\{x_1, x_2, \\dots , x_n\\}{x1​,x2​,…,xn​} 이 주어지면, T5 는 먼저 이러한 token 을 embedding 하여 embedding space 의 dimension 이 eee 인 행렬 Xe∈Rn×eX_e \\in \\mathbb{R}^{n \\times e}Xe​∈Rn×e 를 형성한다. 저자의 soft prompt 는 parameter Pe∈Rp×eP_e \\in \\mathbb{R}^{p \\times e}Pe​∈Rp×e 로 표시, ppp : prompt length 이후 prompt 가 embedded input 에 연결되어 single matrix [Pe;Xe]∈R(p+n)×e[P_e; X_e] \\in \\mathbb{R}^{(p + n) \\times e}[Pe​;Xe​]∈R(p+n)×e 를 형성하고 encoder-decoder 를 통과한다. 저자의 모델은 YYY 의 probability 를 최대화하기 위해 훈련되지만, prompt parameters PeP_ePe​ 만 update 된다.","s":"2. Prompt Tuning","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":821,"t":"prompt representation 을 initialize 에 여러 방법이 있다. random initialization 으로 scratch training each prompt token 을 model vocabulary 에서 추출한 embedding 으로 initialization 개념적으론 저자의 soft prompt 는 frozen network 의 행동을 input 앞의 text 와 동일한 방식으로 조절하므로, word-like representation 이 좋은 initialization spot 으로 작용한다, classification task 의 경우, [Exploiting cloze-questions for few-shot text classification and natural language inference. Schick and Schütze] 의 \"verbalizers\" 와 유사하게, prompt 를 output classes 로 나열한 embedding 으로 초기화하는 것 저자는 모델이 output 에서 이러한 token 을 생성하기를 원하므로, prompt 를 유효한 target tokens 의 embedding 으로 초기화하면, 모델이 output 을 legal output classes 로 제한하도록 유도한다. 또 다른 design 고려 사항은 prompt length 다. 저자의 방법의 parameter cost 는 EPEPEP 이다. EEE : token embedding dimension PPP : prompt length prompt 가 짧을수록 tuning 해야할 new parameters 가 적기 때문에 성능이 여전히 우수할 최소한의 길이를 찾아야 한다.","s":"2.1 Design Decisions","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#21-design-decisions","p":812},{"i":823,"t":"autoregressive 인 GPT-3 와 달리 저자가 실험한 T5 모델은 encoder-decoder 로, span corruption objective 로 pre-training 한다. T5 는 input text 에서 unique sentinel tokens 로 표시된 masked span 을 reconstructing 하는 task 수행 all masked content 로 구성된 target output text 는 sentinel 로 분리되어, final sentinel 에 추가된다. 예로, text \"Thank you for inviting me to your party last week\" 에서 pre-training example 구성 가능 input : \"Thank you ⟨X⟩\\langle X \\rangle⟨X⟩ me to your party ⟨Y⟩\\langle Y \\rangle⟨Y⟩ week\" target output : \"⟨X⟩\\langle X \\rangle⟨X⟩ for inviting ⟨Y⟩\\langle Y \\rangle⟨Y⟩ last ⟨Z⟩\\langle Z \\rangle⟨Z⟩\" [Exploring the limits of transfer learning with a unified text-totext transformer. Raffel] 은 이런 아키텍처와 pre-training objective 가 traditional language modeling 보다 효과적임을 발견했지만, 이 설정이 prompt tuning 을 통해 쉽게 제어 가능한 frozen model 을 생성하기엔 적합하지 않음을 가정 span corruption 만 pre-training 한 T5 를 사용할 경우, 실제 natural input text (free of sentinel tokens) 을 본 적이 없어 실제 natural target 을 예측하지 못한다. 사실 T5 의 span corruption preprocessing 의 details 때문에, 모든 pre-training target 은 sentinel 로 시작한다. 이런 \"unnatural\" sentinel output 경향은 fine-tuning 으로 쉽게 극복할 수 있지만, prompt 만 사용하면 이런 경향을 덮어쓰기가 어려울 것으로 예상된다. decoder priors 를 조정할 수 없기 때문이다. 위 고려사항으로 T5 model 에 세 가지 설정으로 실험한다. Span Corruption frozen pre-trained T5 그대로 사용하고 downstream task 에 대한 expected text output 능력을 테스트 Span Corruption + Sentinel 동일한 모델을 사용하지만 all downstream target 에 sentinel 을 prepend 하여 pre-training 에서 관찰된 target 과 유사하게 만듦 LM Adaptation T5 의 self-supervised training 을 적은 수 추가 이때 LM objective 는 input 으로 natural text prefix 를 받고 output 으로 natural text continuation 생성 이 adaptation 은 한 번만 일어나며, downstream task 전역에 prompt tuning 을 하기 위해 재사용할 수 있는 frozen model 생성 LM adaptation 으로 저자는 T5 를 GPT-3 와 유사한 모델로 \"빠르게\" 변환하고, 항상 현실적인 text 를 출력하고 prompt 에 few-shot learner 가 잘 반응하기를 희망. 이 late-stage transformation 이 처음부터 pre-training 한 것과 비교하여 얼마나 성공적일진 모르지만, 다양한 adaptation length 를 실험하며 최대 100K steps 가지 실험한다.","s":"2.2 Unlearning Span Corruption","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#22-unlearning-span-corruption","p":812},{"i":825,"t":"frozen model 은 pre-trained T5 checkpoints 모든 사이즈에서 구축 (Small, Base, XL, XXL) public T5.1.1 checkpoints 를 활용 green ×\\times× 로 표시된 default configuration 는 T5 를 추가 100K steps 를 학습한 LM-adapted version class labels 초기화 100 tokens 의 prompt length Prefix-tuning 보다 default 10-token 보다 길지만 저자의 방법은 input layer 만 tuning 하기 때문에 여전히 훨씬 적은 task-specific parameter 사용 자세한 비교를 위해 Fig. 4 참조. 또한 model size 증가에 따라 훨씬 짧은 prompt 가 사용 가능한 것도 확인 가능 저자는 SuperGLUE 에서 성능 측정 8개의 어려운 NLU task 를 모아놓은 것 각 데이터셋과 관련된 dev set 에서 메트릭 보고 각 prompt 는 하나의 SuperGLUE task 에 대해 훈련 (no multi-task, mixing) 각 SuperGLUE dataset 에 따라 text-to-text 형식으로 변환, task example 에 task names 을 추가하진 않음 standard cross-entropy loss 를 사용하여 30,000 steps 동안 prompt 훈련 0.3 learning rate 32 batch size early stopping 으로 checkpoint 선택 모든 실험은 JAX 를 사용 Adafactor optimizer 1e-5 weight decay 0.8 β2\\beta_2β2​ decay parameter scaling off 모델은 Flax 로 구현","s":"3. Results","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":827,"t":"standard model tuning 비교를 위해, T5 에서 지정한 default hyperparameter (learning rate 0.001, Adafactor optimizer) 사용 두 가지 기준 고려 Model Tuning : apples-to-apples 비교를 위해, 각 task 별로 tuning Model Tuning (Multi-task) : competitive baseline 을 얻기 위해 T5 의 multi-task tuning 설정 사용. 이 경우 모델이 all task 를 함께 tuning 하며 task name 을 나타내는 text prefix 가 있음 Fig. 1 에서 scale 이 커짐에 따라 prompt tuning 이 model tuning 과 comparable XXL size (11B) 에서 prompt tuning 은 task-specific parameter 가 2만 배 이상 적음에도 불구하고 stronger multi-task model tuning 과 일치 prompt design 비교를 위해 SuperGLUE dev set 에 GPT-3 의 few-shot 성능 포함. Fig. 1 에서 prompt tuning 이 GPT-3 prompt design 을 큰 차이로 이김 prompt tuned T5-Small 은 GPT-3 XL (16배 큼)과 일치, prompt tuned T5-Large 는 GPT-3 175B (220배 큼)를 이김","s":"3.1 Closing the Gap","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#31-closing-the-gap","p":812},{"i":830,"t":"{1,5,20,100,150}\\{1, 5, 20, 100, 150 \\}{1,5,20,100,150} 의 다양한 prompt length 로 다른 설정은 고정한 채로 각 모델 크기에 대해 prompt 를 훈련 Fig. 3(a) 에서 대부분의 모델 크기에서 prompt length 를 single token 이상으로 늘리는 것이 좋은 성능을 위한 요소임을 보여줌 XXL 모델은 single token prompt 로 여전히 강력한 결과 제공 모든 모델에서 20 token 이상 늘린 경우엔 미미한 이득만 얻음","s":"Prompt Length","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#prompt-length","p":812},{"i":832,"t":"모델 크기별로 다른 default value 로 hyperparameter 를 고정시켜 prompt initialization 의 효과를 ablating random initialization 의 경우, [−0.5,0.5][-0.5, 0.5][−0.5,0.5] 에서 균등하게 샘플링 sampled vocabulary 로부터 initializing 하는 경우, T5 의 SentencePiece vocabulary 의 \"common\" token 5,000 개로 제한 이 vocabulary 는 pre-training corpus 의 likelihood 로 정렬 class label initialization 의 경우, downstream task 의 각 class string representation 에 대한 embedding 을 가져와 prompt 의 one token 을 초기화하는데 사용 class label 이 multi-token 일 땐 token embedding 을 평균 longer prompt lengths 에서는 모든 prompt token 초기화하기 전에 class label 이 부족하여, prompt 를 채우기 위해 sampled vocab 전략으로 돌아감 Fig. 3(b) 에서 모델 크기별 initialization 전략의 실험 결과 보여줌 class based initialization 이 best smaller model size 에선 initialization 간의 큰 차이는 없지만, XXL 크기에선 차이가 두드러짐 class label initialization 에선, class label 이 일반적으로 learned prompt 에 유지되어 가장 가까운 token embedding (in cosine distance)이 초기화에 사용된 token 과 일치하는 경우가 많음","s":"Prompt Initialization","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#prompt-initialization","p":812},{"i":834,"t":"Fig. 3(c, d) 에서 pre-training object 가 prompt tuning quality 에 영향을 미치는 것을 볼 수 있음 T5 의 span corruption objective 는 prompt condition 에 적합하지 않음 sentinel token 을 읽고 쓰도록 pre-traing 된 model 은 sentinel 이 없는 데엔 직접 적용하기 어려움 Fig. 3(c) 에서 target downstream 에 sentinel 을 추가한 \"workaround\" 조차 거의 이익이 없었다. LM adaptation 은 모든 모델 크기에서 가치를 더함 XXL 모델은 가장 관용적이고 span corruption 조차 강력한 결과 제공 LM adaptation 의 이점을 고려하려, 얼마나 오랫동안 adapting 이 도움이 되는지 탐색 Fig. 3(d) 에서 long adaptation 이 추가 이득 제공 최대 100K steps 까지 확장 span corruption 에서 LM objective 로의 전환이 간단하지 않으며, 효과적인 전환에는 training resources (original T5 pre-training 의 10% steps)가 필요하다는 것 시사 다른 실험과 마찬가지로 XXL 모델은 non-ideal 설정에도 robust 하며 adapting 이득은 미미 non-optimal span corruption 에선 모델 크기별로 불안정성 관찰 Small model 이 더 큰 Base, Large 및 XL 모델을 능가하는 경우가 많이 발생 중간 크기 모델은 많은 task 에 대해 legal class label 을 출력하는 방법을 학습하지 못하여 0% score 를 받게됨 두 가지 common error 는 input 에서 subspan 을 복사하는 것과 empty string 을 예측하는 것. 이러한 부정적인 성능은 prompt tuning 의 random variance 때문이 아닌 각 크기별로 3회 실행하여 low variance 를 관찰하기 때문이란 점 위 결과는 span corruption objective 로 pre-training 된 모델을 사용하는 것은 불안정하며, LM adaptation 은 신뢰성 있게 작동한다는 것","s":"Pre-training Objective","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"#pre-training-objective","p":812},{"i":836,"t":"continuous prompts learning 연구 검토 및 저자의 방법과 비교 비교의 중요한 측면 중 하나는 각 방법이 필요로 하는 task-specific parameter 의 수 있으며 Fig. 4 에서 볼 수 있다. learnable parameter method 중 prompt tuning 은 모델 크기가 1B 이상의 모델의 0.01% 미만의 task-specific parameter 만 필요로 하여 가장 parameter-efficient prefix-tuning 은 all transformer layer 마다 여러 additional prepended prefix sequence 학습 모든 layer 에서 examples 간에 고정된 activation 을 학습하는 것과 유사 반면 prompt tuning 은 embedded input 에 prepend 된 single prompt representation 을 사용하여 더 적은 parameter 만 필요 저자의 방법은 input example 로 contextualize 된 intermediate-layer task representations 을 update 할 수 있도록 transformer 에 허용 prefix-tuning 은 GPT-2 및 BART 에 기반 저자는 T5 에 focus 하고 model size 증가에 따른 성능 및 robustness 에 대한 design 선택 사항의 변화 검토 BART 사용하면 prefix-tuning 은 encoder-decoder network 에 모두 prefix 를 추가 prompt tuning 은 encoder 에만 prompt 필요 prefix-tuning 은 학습 안정성을 위해 prefix reparameterize 필요하여 학습 중 많은 parameter 필요 저자는 reparameterize 필요하지 않으며 SuperGLUE task 및 모델 크기 전반에 robust WARP 는 prompt parameter 를 input layer 에 추가 masked LM 과 함께 작동하며 [MASK] token 및 learnable output layer 를 사용하여 mask 를 class logit 으로 project model 을 single output 을 생성하도록 제한하여 classification 으로 제한됨 prompt tuning 은 input 또는 task-specific head 에 대한 어떠한 변경도 필요하지 않음 prompt tuning 의 성능도 model tuning 의 강력한 성능과 유사 P-tuning 은 learnable coninuous prompt 를 input 내에 교차로 삽입 저자는 이러한 복잡성을 제거하고 간단하게 input 에 prompt 를 놓은 것 강력한 SuperGLUE 결과를 위해선, P-tuning 은 model tuning 과 함께 사용해야 함 모델은 prompt 와 주요 parameter 를 업데이트하는 반면 저자는 original model 을 유지하면서 continuous prompt 만 추가 soft prompt 는 soft words 를 사용하여 pre-trained LM 에서 knowledge distillation 을 위해 prompt 를 학습하는 방법 prompt 는 hand-designed prompt prototype 를 기반으로 input 과 관련하여 위치시킴 각 layer 에는 learnable paramter △ie\\triangle^e_i△ie​ 를 포함하여 model depth 에 따라 parameter cost 발생 few-shot sequence learning 은 learnable prepended token 으로 transformer 를 다양한 task 에 adapting 하지만, 큰 데이터셋 대신 task representation 수용을 위해 설계된 작은 mixing dataset 에 중점을 둔다. base model 이 small trasnformer 이며 task representation 과 함께 훈련 반면 저자는 base model 을 유지하며 큰 transformer 로 크기를 확장하여 조사 task prompt 에 대한 작업은 \"adapters\" 와 밀접한 관련이 있다. adapter 는 LM 의 small bottleneck layers 를 의미하며 frozen pre-trained netwrok layer 사이에 삽입된다. task-specific parameter 를 줄이는 또 다른 수단으로서, BERT-Large 를 freezing 하고 2-4$ 의 추가 parameter 만으로 GLUE 성능을 model tuning 과 근접하게 달성하기도 했다. multiple adapter 을 사용하여 task specification 에서 language understanding 으로 분리하는 방식이 저자의 model behavior 을 변경하는 방법과 핵심적인 차이가 있다. adapter 는 실제로 input representation 에 작용하는 실제 함수를 수정하여 model behavior 을 변경하는 반면, prompt tuning 는 그대로 유지하며 새로운 input representation 을 추가함으로써 후속 input 처리에 영향을 미치게 한다.","s":"4. Comparison to Similar Approaches","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":838,"t":"frozen LM 으로, prompt tuning 은 모델이 언어에 대한 일반적인 이해도를 수정하지 못하게 한다. 대신 prompt representation 을 간접적으로 input representation 을 변형한다. 이는 모델이 특정 vocab 와 잘못된 상관관계를 기억하여 데이터셋에 overfitting 되는 것을 줄임 prompt tuning 이 domain shift 에 대한 robustness 를 향상을 시사 저자는 두 가지 task, QA 및 Paraphrase Detection 에 대한 zero-shot domain transfer 조사 QA 의 경우 MRQA 2019 사용 통합된 형식의 추출형 QA dataset 을 수집하고 in-domain dataset 에서 훈련된 모델이 out-of-domain dataset 에 어떻게 수행되는지 테스트 SQuAD 에서 훈련하고 각 out-of-domain 에 평가 Table 1 은 prompt tuning 이 out-of-domain 대부분의 데이터셋에 model tuning 보다 우수한 성능 보여줌 TextbookQA 의 경우 두 approach 간의 12.5% F1 차이를 보여줌 larger domain shift 의 경우 (BioASQ → Biomedical, TextbookQA → Textbooks)에는 prompt tuning 이 더 큰 이점 관찰 domain shift 에 대한 robustness 테스트를 위해 GLUE 의 두 paraphrase detection tasks 간의 transfer 탐구 QQP task 로, Q&A 사이트에서 가져온 두 개의 질문이 중복인지 물음 MPRC task 로, 뉴스 기사에서 추출한 두 문장이 부분적으로 동일한지 물음 both direictions (QQP ↔ MRPC) transfer 을 테스트하고 이전과 같이 \"in-domain\" task 에서 훈련하고 \"out-of-domain\" task 에서 zero-shot 평가 Table 2 는 QQP dataset 에서 lightweight prompt 를 훈련하고 MRPC 에서 평가 full model tuning 보다 훨씬 나은 성능 제공 other direction 에서의 결과도 유사하며, 정확도에서 작은 향상과 F1 에서의 작은 감소가 나타났다. 위 결과는 model tuning 이 training 을 과도하게 parameterize 하고 다른 domain 의 유사한 task 에 미치는 악영향을 고려하는 관점으로 볼 수 있다.","s":"5. Resilience to Domain Shift","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":840,"t":"model ensembling 은 동일한 데이터셋에 다른 initialization 으로 훈련된 여러 모델을 결합하여 task 성능을 향상시키는 것 하지만 모델 크기 증가에 따라, 앙상블은 어려워진다. 모델 저장에 필요한 공간 외에도 NNN 개의 모델을 실행하는 데 상당한 inference cost 가 들기 때문이다. 이를 해결하기 위해 prompt tuning 은 pre-trained LM 의 multiple adaptation 을 앙상블하는 더 효율적인 방법 제공 동일 task 에 NNN 개의 prompt 를 훈련하여 별도의 \"model\" 을 생성하면서도 LM parameter 를 모두 sharing prompt ensembling 은 inference 를 더 효율적으로 만든다. 예로, 한 example 처리를 위해 NNN 개의 다른 모델을 forward pass 를 실행하고 example 을 배치 내에서 복제하여 prompt 를 다양하게 설정 가능 위 이점은 Fig. 2 의 multi-tasking 에서 볼 수 있는 것과 유사 prompt ensembling 유효성을 보여주기 위해 각 SuperGLUE task 에 대해 다섯 개의 prompt 를 frozen T5-XXL 모델에서 사용하여 훈련 저자는 ensembling 에서 예측 계산을 위해 간단한 majority voting 을 사용 Table 3 은 all task 에서 앙상블이 single-prompt average 를 능가하며, 개별 best prompt 를 능가하거나 일치","s":"6. Prompt Ensembling","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":842,"t":"해석 가능한 prompt 는 task 를 명확히 설명하는 natural language 로 구성되어 있어 모델에 어떤 결과 및 동작을 요청하고, 모델로부터 어떤 동작을 유발하는지 이해하기 쉽게 말들어야 한다. prompt tuning 은 discrete token 이 아닌 continuous embedding space 에서 작동하여 해석이 더 어렵다. 저자의 learned soft prompt 해석 가능성을 테스트하기 위해 각 prompt token 에 대해 nearest neighbors 를 frozen model's vocabulary 에서 계산한다. similarity metric 로 vocabulary embedding vector 와 prompt token representation 사이의 cosine distance 를 사용한다. 특정 learned prompt token 에 대해 top-5 nearest neighbors 가 tight semantic clusters 를 형성하는 것을 관찰했다. 예로, {Technology / technology / Technologies / technological / technologies}\\{ Technology \\ /\\ technology \\ /\\ Technologies \\ /\\ technological \\ /\\ technologies \\}{Technology / technology / Technologies / technological / technologies} 와 같이 similar cluster 를 관찰 {entirely / completely / totally / altogether / 100% }\\{ entirely \\ /\\ completely \\ /\\ totally \\ /\\ altogether \\ /\\ 100\\% \\ \\}{entirely / completely / totally / altogether / 100% } 와 같이 더 다양한 related cluster 도 관찰 위와 같은 cluster 의 성격은 prompt 가 \"word-like\" representation 을 학습하고 있다는 것을 시사. 저자는 embedding space 에서 추출한 random vector 가 이런 유형의 semantic clustering 을 보여주지 않는 다는 것을 발견했다. prompt 를 \"class label\" 전략으로 초기화할 때, 종종 class label 이 훈련 후에도 지속된다. 구체적으로, prompt token 이 given label 로 초기화된 경우, 해당 label 이 tuned token 의 nearest neighbors 중 하나가 되는 경우가 많다. Random Uniform 또는 Sampled Vocab 방법으로 초기화하는 경우에도 class label 이 prompt 의 nearest neighbors 에서 발견되는 경우가 많다. 이는 모델이 prompt 에 expected output classes 를 참조로 저장하고, prompt 를 output class 로 초기화하면 이를 더 쉽게 centralize 한다는 것을 시사한다. longer prompt (e.g. 100) 을 조사할 때 종종 동일한 nearest neighbors 를 가진 여러 prompt tokens 를 찾을 수 있다. 이는 prompt 에 과도한 용량이 있거나 prompt representation 에 sequential structure 이 부족하여 모델이 특정 위치로 정보를 localize 하는 것이 어렵다는 것을 시사한다. sequence 로 가져온 learned prompt 는 해석 가능성이 없지만, BoolQ dataset 에서 훈련된 prompt 에 대해, \"science, technology 및 engineering\" 같은 단어가 높은 빈도로 나타난다. 그리고 질문의 20% 가 \"Nature/Science\" 범주에 속한다. 이는 prompt 의 한 가지 역할이 model 에 specific domain 또는 context (e.g. scientific) 에서 입력을 해석하도록 준비하는 것일 수 있음을 시사","s":"7. Interpretability","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":844,"t":"prompt tuning 이 frozen pre-trained LM 을 downstream task 에 adapting 하는 comaprable 한 기술임을 증명 SuperGLUE 에서 task performance 가 traditional model tuning 과 comparable model scale 증가에 따른 gap 줄임 zero-shot domain transfer 에서 prompt tuning 이 generalization 향상 general-purpose 의 language understanding parameter 를 동결하고 downstream learning 을 lightweight parameter footprint 제한하여 specific domain 에 overfitting 되는 것 피함을 시사 task quality metric 외에도, storage 및 serving cost 측면의 frozen pre-trained model moving 의 매력에 대해 논의. 이 move 는 efficient multi-task serving 과 efficient high-performing prompt ensembling 모두 가능하게 함","s":"8. Conclusion","u":"/docs/Paper/NLP/PEFT/Prompt Tuning","h":"","p":812},{"i":846,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.11366v3.pdf","s":"Reflexion: Language Agents with Verbal Reinforcement Learning","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":848,"t":"최근 LLMs 는 goal-driven agents 로 사용되는 것이 증가하고 있다. 하지만, 기존의 reinforcement learning 은 훈련 샘플이 많이 필요하고 모델의 fine-tuning 으로 비용이 많이 들어, 이러한 language agent 근 시행착오로부터 빠르고 효율적으로 학습하는 것은 어려운 과제다. 저자는 Reflexion 을 제안한다. weight 업데이트하는 대신 언어적 피드백으로 language agent 를 강화하는 것이다. Reflexion 은 feedback signal 을 반영한 후, 이러한 reflective text 를 episodic memory 에 유지하여 subsequent trial 에서 더 나은 의사결정을 유도한다. Reflexion 은 다양한 타입 (scolor value / free-form language) 및 소스 (외부/내부적 시뮬레이션) 의 feedback signal 을 유연하게 통합하며, 다양한 task (sequential decision-making, coding, language reasoning) 에서 baseline agent 에 비해 상당한 개선을 보인다. HumanEval coding bachmark 에서 91% pass@1 정확도를 달성하여, 이전 SOTA 인 GPT-4 의 80% 를 뛰어 넘었다. 또한, feedback signal, feedback incorporation 및 agent type 에 대한 분석 및 ablation 실험으로 성능을 비교한다.","s":"Abstract","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":850,"t":"최근 연구에선 LLM core 로 구축한 자동 의사결정 agent 의 가능성을 입증한다. 이 방법은 LLMs 를 사용하여 API 호출 및 환경에서 실행할 수 있는 text 및 'action' 을 생성할 수 있다. 하지만 방대한 파라미터 수를 가진 거대한 모델에 의존하여, 기존의 강화학습과 경사하강을 이용한 최적화 방법같은 전통적인 방식은 계산량과 시간이 많이 소비되어 문맥 내의 예제로 agent 에게 가르치는 방식으로 제한되어 있다. 본 논문은 agent 가 이전의 실패로부터 배우는 것을 돕기위해 언어적 강화를 사용하는 Reflexion 이란 대안적 접근법을 제안한다. 이는 환경으로부터 binary 또는 scalar feedback 을 텍스트 요약 형태의 verbal feedback 으로 변환하며, 이는 다음 에피소드에서 LLM agent 에 대한 additional context 로 추가된다. 이 self-reflective feedback 은 'semantic' gradient signal 역할을 하며, 구체적인 개선 방향을 제시하여 과제를 더 잘 수행하도록 도와준다. 이는 인간이 몇 번의 시도로 실패를 반영하여 개선하며 복잡한 작업을 달성하는 것과 유사하다. 예로, Figure 1 에서 Reflexion agent 는 trial, error, self-reflection 을 통해 decision-making, programming 및 reasoning task 를 해결하기 위해 자신의 동작을 최적화하는 방법을 배우게 된다. 유용한 reflective feedback 생성은 어디서 실수했는지를 잘 이해하는 능력과 개선을 위한 통찰을 담은 요약을 생성하는 능력이 필요하여, 매우 어려운 과제이다. 저자는 이러한 수행을 위해 3 가지 방법을 탐구한다. simple binary enviroment feedback pre-defined heuristics for common failure cases LLMs 을 이용한 binary classification 또는 self-written unitests (programming) 과 같은 self-evaluation 모든 구현에서, evaluation signal 은 long-term memory 에 저장될 수 있는 자연어 요약으로 증폭된다. Reflexion 은 policy 또는 value-based learning 같은 기존의 강화학습과 비교하여 몇몇 이점이 있다. 가벼우며 LLM finetuning 불필요 scalar 또는 vector reward 와 비교했을 때, 보다 더 정교한 형태의 feedback (예; action 에 대한 targeted changes)이 가능하며, 정확한 credit assignment 가 어려운 경우에도 수행 이전 경험보다 더 명시적이며 episodic memory 의 해석 가능한 형태 미래 에피소트의 action 에 대한 더 명시적인 힌트를 제공 동시에 LLM 의 self-evaluation capabilities (or heuristics) 의 힘에 의존하는 단점이 있으며, 성공에 대한 정규적 보증이 없다. 다음과 같은 실험 진행 decision-making task : 긴 경로를 통해 sequential action choice test reasoning task : knowledge-intensive, single-step generation improvement test programming task : compiler 및 interpreter 같은 외부 도구로 효과적으로 가르침 세 가지의 task 결과, decision-making task 인 AlfWorld 에선 22%, reasoning task 인 HotPotQA 에선 20%, programming task 인 HumanEval 에선 최대 11% 까지 개선되었다. 주요 contribution 은 다음과 같다. 'verbal' 강화를 위한 새로운 Reflexion 패러다임을 제안. 이는 policy 를 agent 의 memory encoding 과 LLM parameter 의 선택과 결합하는 방식으로 parameterize LLM 에서 나타나는 self-reflection 의 특성을 탐구하고, self-reflection 이 소수의 시도로도 복잡한 작업을 학습하는 데 매우 유용하다는 것을 경험적으로 보여줌 LeetcodeHardGym 을 도입하며, 19개의 프로그래밍 언어로 구성된 40개의 어려운 Leetcode 문제로 구성된 코드 생성 RL gym 환경이다. Reflexion 이 강력한 baseline 모델에 비해 여러 작업에서 개선을 이루며, 다양한 code generation benchmarks 에서 SOTA 달성","s":"1 Introduction","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":853,"t":"활용할 세 가지 모델을 다음과 같이 공식화 Actor model : text 및 action 을 생성할 MaM_aMa​ Evaluator model : MaM_aMa​ 로 생성된 output 의 score 를 나타내는 MeM_eMe​ Self-Reflection model : self-improvement 로 Actor 를 도와주기 위해 verbal reinforcement cues 를 생성할 MsrM_{sr}Msr​","s":"3 Reflexion: reinforcement via verbal reflection","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":855,"t":"Actor 는 state 관찰에 필요한 text 및 action 생성을 위해 특별히 prompted LLM 에 기반하여 만든다. 기존의 policy-based RL 설정과 유사하게, time ttt 에서의 current policy πθ\\pi_\\thetaπθ​ 로부터의 action 또는 generation ata_tat​ 을 샘플링 하고, environment oto_tot​ 로부터 관찰을 얻는다. Chain of Thought 및 ReAct 를 포함한 다양한 Act 모델을 탐구한다. 이러한 다양한 generation model 은 Relfexion framework 내의 text 및 action generation 의 다른 측면을 탐색하여 성능과 효과에 대한 유용한 통찰력을 제공 또한, agent 에게 추가적인 context 를 제공하는 memory component memmemmem 을 추가한다.","s":"Actor","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#actor","p":845},{"i":857,"t":"Reflexion framework 의 Evaluator component 는 Actor 로 생성한 output 의 퀄리티를 평가하는 데 중요한 역할을 함 생성된 trajectory 를 입력으로 받아, 주어진 task context 내의 성능을 반역하는 reward score 를 계산 semantic space 에 적용되는 효율적인 value 나 reward function 정의는 어려움으로, 다양한 Evaluator model 을 탐구한다. reasoning task : 생성된 output 이 expected solution 과 밀접하게 align 하기를 보장하는 exact match (EM) grading 에 기반한 reward function 탐구 decision-making task : evaluation criteria 를 명시하기 위해 맞춤형의 pre-defined heuristic function 사용 decision-making 및 programming task 에 대한 reward 생성하는 Evaluator 로서 LLM 의 다른 인스턴스를 사용하여 실험 위의 multi-faceted 접근법으로 생성된 output 에 대한 다양한 scoring 전략을 조사하여, 다양한 task 에 대한 효과성과 적합성에 대한 통찰력을 제공한다.","s":"Evaluator","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#evaluator","p":845},{"i":859,"t":"LLM 인 Self-Reflection model 은 future trials 에 대한 valuable feedback 을 제공하기 위해 verbal self-reflections 를 생성하는, Relfexion framework 에서 중요한 역할을 한다. binary success status (success/fail) 같은 reward signal, current trajectory 및 persistent memory memmemmem 이 주어지면, self-reflection model 은 세부적이며 구체적인 feedback 을 생성한다. 이 feedback 은 scalar rewards 보다 많은 정보를 주며, 이는 agent 의 memmemmem 에 저장된다. 예로 multi-step decision-making 에서, agent 가 failure signal 을 받았을 때 특정 동작 aia_iai​ 가 이후의 잘못된 action ai+1a_{i+1}ai+1​ 와 ai+1a_{i+1}ai+1​ 으로 이어질 수 있음을 추론 그럼 agent 는 다른 action ai′a'_iai′​ 을 취했어야 하며, 이는 ai+1′a'_{i+1}ai+1′​ 와 ai+2′a'_{i+2}ai+2′​ 를 발생할 것임을 말함 위의 경험을 memory 에 저장 이후의 trial 에서 agent 는 과거 경험을 통해 time ttt 에서의 decision-making approach 개선을 위해 action ai′a'_iai′​ 을 선택 이런 trial, error, self-reflection 및 persisting memory 과정을 통해 agent 는 정보성 있는 feedback signal 을 활용하여 다양한 환경에서 decision-making 능력을 빠르게 향상","s":"Self-reflection","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#self-reflection","p":845},{"i":861,"t":"Reflexion 과정의 핵심 컴포넌트는 short-term 과 long-term memory 개념. inference time 에, Actor 는 short 와 long-term moemory 에 의존하여 결정 내린다. 이는 인간이 최근 세부사항은 기억하며 장기 기억에서 중요한 경험을 회상하는 것과 유사하다. RL 설졍에선, trajectory history 가 short-term memory 에 작용하며, Self-Reflection model 의 output 은 long-term memory 에 저장된다. 이 두 memory components 특정 context 제공을 위해 함께 작동하지만, 여러 trial 에서 얻는 교훈에 영향을 받는다. 이는 Reflexion agent 가 다른 LLM action choice works 에 비해 주요한 이점을 가지고 있다는 것이다.","s":"Memory","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#memory","p":845},{"i":863,"t":"first trial 에서, Actor 는 환경과 상호작용하여 trajectory τ0\\tau_0τ0​ 을 생성 Evaluator 는 rt=Me(τ0)r_t = M_e(\\tau_0)rt​=Me​(τ0​) 으로 계산되는 score r0r_0r0​ 을 생성 rtr_trt​ 는 trial ttt 에 대한 scalar reward 으로, task-specific performance 가 향상됨에 따라 개선됨 first trial 후, LLM 으로 인한 개선을 사용할 수 있는 feedback 형식으로 r0r_0r0​ 을 강화하기 위해 Self-Reflection model 이 {τ0,r0}\\{ \\tau_0, r_0 \\}{τ0​,r0​} 집합을 분석하여 summary sr0sr_0sr0​ 을 생성하고 memmemmem 에 저장 srtsr_tsrt​ 는 trial ttt 에 대한 verbal experience feedback Actor, Evaluator 및 Self-Reflection model 은 루프를 통해 협력하여 작동하며, Evaluator deems τt\\tau_tτt​ 가 올바른 것으로 판단할 때까지 반복 memory 파트에서 언급했듯, Reflexion 의 memory component 는 효과성에 중요하다. 각 trial ttt 이후 srtsr_tsrt​ 는 memmemmem 에 추가된다. 실제론 최대 경험 저장 수 Ω\\OmegaΩ (보통 1-3)를 제한하여 max context LLM 제한을 준수","s":"The Reflexion process","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"#the-reflexion-process","p":845},{"i":870,"t":"Reflxion 은 NL 로 policy optimization 하는 최적화 기법이다. policy optimization 은 경험을 통한 action choice 개선에 강력하지만, non-optimal local minima 에 빠질 수 있다. 본 연구는 long-term memory 를 maximum capacity 로된 sliding window 로 제한했지만, 향후 연구에선 vector embedding databases 또는 전통적인 SQL database 같은 고급 구조로 Reflexion 의 memory component 를 확장하는 것을 권장한다. code generation 에 특정하면, non-deterministic generator function, API 와 상호작용하는 impure function, 하드웨어 사양에 따라 output 이 다른 function, 병렬 또는 동시 동작을 호출하는 함수 등과 같은 정확한 input-output 매핑을 지정하는 데 많은 실질적 제한 사항이 있을 수 있다.","s":"5 Limitations","u":"/docs/Paper/NLP/Reinforcement Learning/Reflexion","h":"","p":845},{"i":872,"t":"논문 및 이미지 출처 : https://dl.acm.org/doi/pdf/10.1145/3560815","s":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":874,"t":"NLP 의 새로운 패러다임으로 prompt-based learning 이 등장 기존 방식 supervised learning input xxx 를 사용하여 output yyy 을 예측하도록 P(y∣x)P(y|x)P(y∣x) 를 훈련 prompt-based learning 텍스트의 확률 직접적으로 모델링 기존의 input xxx 를 채워지지 않은 공백(unfilled slot)을 가진 텍스트 문자 prompt x′x'x′ 로 수정하여 사용 그 후, 미입력된 정보를 확률적으로 채워 최종 문자열 x^\\hat{x}x^ 를 얻음. 이를 최종 output yyy 으로 유도함 이 방식은 다음과 같은 이유로 강력함 LM 이 대량의 raw text 를 pre-trained 할 수 있게 함 새로운 prompting 함수를 정의하여, few/no labeled data 로 few/zero-shot learning 가능 본 논문은 prompting 패러다임을 소개하며 pretrained LM, prompt 및 튜닝 전략의 선택과 같은 다양한 측면의 리뷰를 소개함. 이 외에도 NLPedia-Pretrain 사이트를 제공하며, 지속적으로 업데이트되는 조사 및 논문 목록을 포함한다.","s":"Abstract","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":876,"t":"Fully Supervised Learning : task-specific model 이며, target task 에 대한 데이터셋에 의존 feature engineering : 연구자 또는 엔지니어가 raw data 에서 feature 를 추출하고 모델에 제공하는 방식 제한된 데이터를 학습하여 bias 가 내재 architecture engineering : NLP 의 neural network model 이 진보하며, 주요 feature 를 잘 학습하는 network architecture 구축에 초점을 둠 적절한 아키텍처 설계로 inductive bias 를 제공 2017~2019 에 NLP 의 큰 변화로 fully superviesd 패러다임은 축소됨 pre-train and fine-tune paradigm : language model (LM) 을 대규모 데이터셋에서 pre-train을 진행한 task-specific objective function 으로 fine-tune 을 진행한다. objective engineering : pre-training 및 fine-tuning 과정에 objective 맞게 훈련을 설계 대규모 문장 예측에 loss function 을 도입하여 pre-trained LM 이 text summarization 에 좋은 성능을 보여주며, pre-trained LM 의 몸체가 일반적으로 downstream task 에 대한 해결책으로 적절하게 fine-tuning 된다. 2021 에 다시 큰 변화가 일어나 \"pre-train and fine-tune\" 에서 \"pre-train, prompt, and predict\" 로 대체됨 pre-train, prompt, and predict : LM 을 downstream 에 object engineering 으로 적응시키는 대신 downstream task 와 유사하게 textual prompt 를 재구성 예시로 다음과 같다. \"나 오늘 버스 놓쳤어,\" 그리고 prompt \"내 기분은 _\" 으로 계속하여 LM 에게 공백을 채우도록 요청 \"English:I missed the bus today. French: _\" 으로 번역을 예측하도록 공백을 채우게 한다 이처럼 적절한 prompt 를 선택하여 task-specific training 없이 원하는 출력을 예측할 수 있음 장점으로 다양한 prompt 를 unsupervised 으로 LM 을 통해 많은 task 해결 가능 적절한 prompt 를 찾는 prompt engineering 이 필수","s":"1. Two Sea Changes in Natural Language Processing","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":879,"t":"NLP 의 기존 supervised learning 은 input xxx (보통 text) 으로 output yyy 를 예측하는, P(y∣x;θ)P(y|x;\\theta)P(y∣x;θ) 모델에 기반한다. yyy 는 label, text 또는 다른 형태의 output 일 수 있다. parameter θ\\thetaθ 를 학습시키기 위해, input 과 output 쌍의 데이터셋을 사용하며, 이의 확률 값을 예측하는 모델로 훈련시킨다. 먼저 text classification 에선 text xxx 로 label set Y\\mathcal{Y}Y 로부터 label yyy 를 예측하게 한다. sentiment analysis 에서 input xxx = \"I love this movie\" 로 label set Y\\mathcal{Y}Y = {++, +, ~, -, --} (positive, negative 정도) 중 label yyy = ++ 을 예측하도록 한다. conditional text generation 에서 필란드어 input xxx = \"Hyvää huomenta\" 로 영어 output yyy = \"Good morning\" 을 생성한다.","s":"2.1 Supervised Learning in NLP","u":"/docs/Paper/NLP/Survey/Prompting","h":"#21-supervised-learning-in-nlp","p":871},{"i":881,"t":"supervised learning 은 대규모의 annotated data 가 필수이다. prompt-based learning 은 이 문제를 해결하기 위해 3 단계의 prompting 으로 가장 높은 점수의 y^\\hat{y}y^​ 를 예측한다.","s":"2.2 Prompting Basics","u":"/docs/Paper/NLP/Survey/Prompting","h":"#22-prompting-basics","p":871},{"i":883,"t":"input xxx → fprompt(x)f_{prompt}(x)fprompt​(x) → prompt x′x'x′ prompting function fprompt(⋅)f_{prompt}(\\cdot)fprompt​(⋅) 은 template 를 적용하는 것으로, 두 가지 slot 이 있는 textual string input xxx 를 위한 input slot [X] yyy 로 매핑될 text zzz 가 있는 answer slot [Z] input text xxx 으로 slot [X] 를 채움 이전의 sentiment analysis 의 예시로 들면 다음과 같다. xxx = \"I love this movie,\" template = \"[X] Overall, it was a [Z] movie\" x′x'x′ = \"I love this movie. Overall, it was a [Z] movie,\" 위와 같은 과정으로 [Z] 를 예측하도록 한다. translation 의 예시로 한다면 \"Finnish: [X] English: [Z]\" 가 될 수 있겠다. 더 많은 예시는 Table 3 에서 볼 수 있다. 세 가지의 주목할 점이 있다. 위와 같은 prompt 는 z 를 채우기 위한 빈 슬롯을 middle, end 에 가진다. close prompt : middle prefix prompt : end 이러한 template 은 natural language token 가 아닌 다음과 같을 수 있다. continuous space 상의 embedding 될 수 있는 가상 단어 continuous vectors [X] 및 [Z] 슬롯은 task 에 따라 유연하게 변경할 수 있음","s":"2.2.1 Prompt Addition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#221-prompt-addition","p":871},{"i":885,"t":"LM 의 score 를 최대화하는, 가장 높은 score 의 text z^\\hat{z}z^ 를 찾아야 한다. zzz 는 언어 전체 범위나 작은 부분 집합일 수 있다. 예로, Z\\mathcal{Z}Z = {\"excellent\", \"good\", \"OK\", \"bad\", \"horrible\"} 괴 Y\\mathcal{Y}Y = {++, +, ~, -, --} 처럼 나타낼 수 있다. prompt x′x'x′ 의 [Z] 의 answer zzz 를 채울 ffill(x′,z)f_{fill}(x', z)ffill​(x′,z) 함수 정의 filled prompt : 위 함수로 채워진 prompt answered prompt : true answer 로 채워진 prompt (예; Table 2) pretrained LM P(⋅;θ)P(\\cdot ;\\theta)P(⋅;θ) 으로 filled prompt 의 확률을 계산하여 answer zzz 를 탐색 z^=searchz∈Z P(ffill(x′,z);θ).(1)\\hat{z} = \\underset{z \\in \\mathcal{Z}}{\\textup{search}} \\ P(f_{fill}(x', z); \\theta). \\tag{1}z^=z∈Zsearch​ P(ffill​(x′,z);θ).(1) 위 search 함수는 다음이 가능 argmax search : 가장 높은 score 의 output 을 찾는 함수 sampling : LM 확률 분포에 따른 무작위 output 생성","s":"2.2.2 Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#222-answer-search","p":871},{"i":887,"t":"마지막 단계로, 가장 score 가 높은 answer z^\\hat{z}z^ 으로 output y^\\hat{y}y^​ 을 낸다. 번역 같은 생성 작업에선 answer 에 대한 output 생성은 쉽지만, multiple answer 에 대해 동일한 output 을 내는 경우가 있다. 예로, single class (예; ++)를 나타내는 여러 감정 단어 (예; \"excellent\", \"fabulous\", \"wonderful\")를 사용할 수 있다. 이 경우, searched answer 와 output 간의 매핑이 필요하다.","s":"2.2.3 Answer Mapping","u":"/docs/Paper/NLP/Survey/Prompting","h":"#223-answer-mapping","p":871},{"i":889,"t":"수학적 공식을 알았으니, prompting 방법에 대한 기본적인 설계 고려사항을 보자. Pre-trained LM Choice P(x;θ)P(x;\\theta)P(x;θ) 를 계산할 다양한 pretrained LM Prompt Template Engineering task 에 따른 proper prompt 선택 정확도뿐만 아니라 model 수행에도 영향 끼침 Section 3 에서 fprompt(x)f_{prompt}(x)fprompt​(x) 로 template 선택법 설명 Prompt Answer Engineering task 에 따른 Z\\mathcal{Z}Z 설계 가능 경우에 따라선 매핑 함수와 함께 설계도 할 수 있음 Section 4 다양한 방법을 다룸 Expanding the Paradigm Section 5 에서 기본 패러다임을 확장하여 더욱 개선하고 적용 가능성을 높이는 방법을 다룸 Prompt-based Training Strategies prompt, LM 둘의 parameter 를 훈련시키는 방법도 있음 Section 6 에서 다양한 전략을 요약하고 이점을 설명","s":"2.3 Design Considerations for Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#23-design-considerations-for-prompting","p":871},{"i":891,"t":"Prompt template engineering : downstream task 에 효과적인 성능을 만다는 prompting function fprompt(x)f_{prompt}(x)fprompt​(x) 를 생성하는 과정 task 에 따른 최상의 template 을 위해서, Figure 1 과 같이 두 가지 접근법으로 원하는 shape 의 prompt 를 만들 수 있다.","s":"3 Prompt Template Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":893,"t":"앞서 close prompt 와 prefix prompt 를 언급했다. 이는 task 및 model 에 따라 선택이 갈린다. 생성 관련 task / 표준 auto-regressive LM 의 경우 : prefix prompt 가 더 유리 left-to-right 특성의 모델과 어울림 masked LM 의 경우 : close prompt 가 적합 pre-training task 형식과 유사 텍스트 재구성 모델의 경우 : close prompt 및 prefix prompt 함께 사용 가능 text pair classification 같은 multiple input 의 경우 : prompt template 은 [X1], [X2] 두 개의 input 또는 그 이상을 포함해야함","s":"3.1 Prompt Shape","u":"/docs/Paper/NLP/Survey/Prompting","h":"#31-prompt-shape","p":871},{"i":895,"t":"가장 자연스러운 prompt 는 사람의 심리를 기반한 직관적인 template 을 수동으로 생성하는 것이다. 예로, LAMA 데이터셋은 LM 의 knowledge 를 조사하기 위해 수동으로 생성된 close template 을 제공한다. Language Models are Few-Shot Learners 논문에선 question answering, translation 및 probing task 와 같은 일반적인 추론 task 를 포함한 다양한 영역을 처리하기 위해 prefix prompt 를 수동으로 만든다 Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference, Few-Shot Text Generation with Natural Language Instructions, It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners 논문들은 text classification 및 text generation task 에서 few-shot learning setting 에서 미리 정의한 template 을 사용","s":"3.2 Manual Template Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#32-manual-template-engineering","p":871},{"i":897,"t":"수동 제작된 template 은 직관적이고 다양한 task 를 어느 정도 해결할 수 있지만 몇 가지 이슈가 있다. prompt 를 생성하고 실험하는 시간 및 비용이 든다; 특히 의미 이해같은 복잡한 task 는 더 힒듬 경험이 많은 prompt 디자이너도 최적의 prompt 를 발견하는데 실패할 수 있음 이 문제를 해결하기 위해 template 을 자동으로 설계하는 프로세스가 제안됨 discrete prompt : 실제 텍스트 문자열 continuous prompt : LM 의 임베딩 공간에 직접 설명되는 prompt","s":"3.3 Automated Template Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#33-automated-template-learning","p":871},{"i":899,"t":"discrete prompt 방법은 다음과 같다. D1: Prompt Mining training input xxx 및 output yyy 에서 자동으로 template 를 찾는 마이닝 기법 large text corpus (예; 위키피디아) 에서, \"[X] middle words [Z]\" 와 같은 template 으로 xxx 와 yyy 간의 middle words 또는 dependency path 를 찾음 D2: Prompt Paraphrasing seed prompt 로 다른 후보 prompt 간에 paraphrase 하여 가장 높은 정확도를 선택하는 기법 prompt 를 다른 언어로 번역한 후 재번역하는 방법 시사어에 구절을 바꾸는 방법 정확도 향상에 특화된 neural prompt rewriter 사용하는 방법 특히 이 방법은 xxx 가 template 에 입력된 후 paraphrase 수행 후 각각의 input 에 다른 paraphrase 생성 가능 D3: Gradient-based Search 실제 토큰에 대한 gradient-based search 로 생성가능한 짧은 시퀀스를 찾는 기법 반복 수행 및 prompt 토큰에 순차 탐색 downstream 에 대한 training sample 로 탐색하여 강력한 성능을 보여줌 D4: Prompt Generation 텍스트 생성 모델로 prompt 를 생성 누락된 범위를 채우는데 특화된 T5 를 사용한 32 이 있음 template 내에 template token 을 삽입할 위치 지정 T5 가 template token 을 디코딩 하도록 training sample 제공 36 : prompt 생성 제어를 위해 강화 학습을 사용하기도 함 5 : T5 를 각 input 에 domain relevant feature (DRFs) 을 생성하도록 훈련하는 도메인 적응 알고리즘 제안 DRF (도메인 정보를 특징화하는 키워드 집합) 는 input 과 연결하여 template 을 형성하고 downstream task 에 의해 추가 사용 D5: Prompt Scoring 19 : knowledge base 의 task 를 조사 후 LM 을 이용하여 input(head-relation-tail)에 대한 template 설계 후보군 template 셋을 수동으로 작성하고 input 과 output slot 을 채워 prompt 를 형성 그 후, 단방향 LM 으로 filled prompt 를 평가하여 가장 높은 확률을 선택","s":"3.3.1 Discrete Prompt","u":"/docs/Paper/NLP/Survey/Prompting","h":"#331-discrete-prompt","p":871},{"i":901,"t":"continuous prompt : LM 가 효과적으로 task 를 수행하도록 인간이 이해 가능한 자연어가 아닌, LM 의 임베딩 공간에 직접 prompting 을 수행하도록 하는 방법이다. 이 방법은 두 가지 제약을 없앤다. template 단어의 임베딩과 자연어 단어의 임베딩이 일치해야 한다는 제약 완화 template 가 pretrained LM 의 파라미터화 되야 한다는 제약 제거 대신, downstream task 의 데이터에 따라 조정할 수 있는 자체 파라미터가 있음 아래 대표적인 방법들이 있다. C1: Prefix Tuning Prefix Tuning 17 : input 에 continuous task-specific vector 의 시퀀스를 접두어로 추가하는 기법. 동시에 frozen LM 파라미터를 유지 max⁡ϕlog⁡P(y∣x;θ;ϕ)=max⁡ϕ∑yilog⁡P(yi,h<i;θ;ϕ)(2)\\underset{\\phi}{\\max} \\log P(y|x;\\theta;\\phi) = \\underset{\\phi}{\\max}\\sum_{y_i}\\log P(y_i, h_{<i};\\theta;\\phi)\\tag{2}ϕmax​logP(y∣x;θ;ϕ)=ϕmax​yi​∑​logP(yi​,h<i​;θ;ϕ)(2) 수학적으로, matrix MϕM_{\\phi}Mϕ​ 와 pre-trained LM 의 파라미터 θ\\thetaθ 가 주어였을 때 log-likelihood 목표에 따라 최적화한다. h<i=[h<i(1);⋯ ;h<i(n)]h_{<i} = [h^{(1)}_{<i}; \\cdots;h^{(n)}_{<i}]h<i​=[h<i(1)​;⋯;h<i(n)​] 는 timestep iii 에 따른 모든 neural network 층의 연결이다. 해당 timestep 이 prefix (hih_ihi​ 가 Mϕ[i])M_{\\phi}[i])Mϕ​[i]) 내에 있는 경우, 직접 MϕM_{\\phi}Mϕ​ 에서 복하된다. 그렇지 않으면 pre-trained LM 으로 계산한다. 71 : continuous prefix-based learning 이 실제 단어로된 discrete prompt 보다 저데이터 설정에서 초기화에 더 민감하단 것을 관찰 67 : input 시퀀스에 특수 토큰을 추가하여 template 를 형성 하고 토큰의 임베딩을 직접 tuning 71 와 비교하여, 이 방법이 추가 매개변수를 도입하지 않아, 더 적은 매개변수를 사용 135 : 캡션 생성을 위해, frozen LM 을 사용하여 이미지를 임베딩 시퀀스로 인코딩하는 visual encoder 를 학습 visual-language task 에 대한 few-shot learning 이 가능한 것을 보여줌 위 두 논문과 달리, prefix 는 샘플에 따라 다르며, task embedding 이 아닌 input image 의 representation 이다. C2: Tuning Initialized with Discrete Prompt discrete prompt 탐색 기법으로 생성된 prompt 로 continuous prompt 를 초기화하는 기법 152 는 AutoPrompt 와 같은 discrete 탐색 기법으로 template 를 정의 이 prompt 를 기반으로 가상 토큰을 초기화 후 정확도 상승을 위해 임베딩을 finetuning 수동 template 로 초기화하면 탐색 기법보다 더 나은 starting point 를 제공한 다는 점 발견 103 : 각 input 에 대한 soft template 의 혼합을 학습한다. 각 template 의 가중치와 파라미터를 training sample 로 공동 학습한다. 초기 template 셋은 수동으로 만들거나 prompt mining 기법으로 얻는다. 40 : 수동 prompt template 의 shape 를 따르는 continuous template 을 사용한다. C3: Hard-Soft Prompt Hybrid Tuning 단순히 learnable prompt template 사용 대신, hard prompt template 를 tunable 임베딩에 삽입하는 기법 77 : P-tuning 을 제안 continuous prompt 를 학습 가능한 변수를 embedded input 에 삽입하여 학습됨 prompt token 간의 상호작용을 위해, prompt embedding 을 BiLSTM 의 출력으로 나타냄 성능 향상을 위해 template 에 고정된 anchor token 을 사용 41 : prompt tuning with rules (PTR) 제안 규칙 기반으로 완전한 template 을 만들기 위해 수동 제작된 sub-templates 를 사용 template ability 향상을 위해 training sample 을 통해, pretrained LM parameter 와 함께 tunable 가상 토큰을 삽입 PTR 의 template token 은 actual token 및 virtual token 포함 relation classification task 에 효과적","s":"3.3.2 Continuous Prompt","u":"/docs/Paper/NLP/Survey/Prompting","h":"#332-continuous-prompt","p":871},{"i":903,"t":"promt answer engineering : 예측 모델에서 answer space Z\\mathcal{Z}Z 를 탐색하고 output Y\\mathcal{Y}Y 와 매핑하는 것이 목표 answer shape 및 answer design 기법에 대해 고려해야함","s":"4 Prompt Answer Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":905,"t":"answer 의 모양은 세부도를 특징 짓는다. 일반적인 선택은 다음과 같다. Token : pre-trained LM 의 vocabulary 에 있는 token 중 하나 또는 vocabulary 의 하위집합 Span : 짧은 multi-token span. 보통 close prompt 와 사용됨 Sentence : 문장 또는 문서. 보통 prefix prompt 와 사용 answer shape 는 task 에 따라 다르다. token/text-span 의 answer space 는 classification (감정 분류; 144), relation extraction 100 또는 entity recognition 17 등 널리 사용된다. longer phrasal/sentential 의 answer space 는 언어 생성 105 이나 mutliple-choice question answering 55 task 등에 자주 사용된다.","s":"4.1 Answer Shape","u":"/docs/Paper/NLP/Survey/Prompting","h":"#41-answer-shape","p":871},{"i":907,"t":"적절한 answer space Z\\mathcal{Z}Z 을 설계하는 방법과 answer 이 최종 output 으로 사용되지 않을 경우 output space Y\\mathcal{Y}Y 를 매핑하는 방법이다.","s":"4.2 Answer Space Design Method","u":"/docs/Paper/NLP/Survey/Prompting","h":"#42-answer-space-design-method","p":871},{"i":909,"t":"manutal design : answer space Z\\mathcal{Z}Z 와 매핑할 Y\\mathcal{Y}Y 에 대해 관심사로 수동으로 만드는 기법 Unconstrained Spaces : answer space Z\\mathcal{Z}Z 는 모든 토큰 공간 100 , fixed-length spans 50 , 또는 token sequence 105 이다. identity mapping 으로 answer zzz 을 output yyy 와 직접 매핑하는 것이 일반적 Constrained Spaces : text classification / entitiy recognition / multiple-choice question answering 와 같은 제한된 라벨 공간에 대한 task 를 수행할 때 사용하는 기법 144 : input text 와 관련한 단어의 목록 (예; 감정 [\"anger\", \"joy\", \"sadness\", \"fear\"], topics [\"health\", \"finance\", \"politics\"]) 를 수동으로 설계 17 : named entity recognition (NER) task 에 대해 \"person\", \"location\" 같은 목록을 수동으로 설계 위 두 논문 같은 경우, answer Z\\mathcal{Z}Z 와 class Y\\mathcal{Y}Y 간의 매핑이 필수 155 : multiple-choice question answering task 에 대해선 LM 을 사용하여 여러 선택 중 하나의 출력 확률 계산이 일반적","s":"4.2.1 Manual Design","u":"/docs/Paper/NLP/Survey/Prompting","h":"#421-manual-design","p":871},{"i":911,"t":"수동 생성된 answer 으로 이상적인 예측 성능을 얻는 다는 것은 sub-optimal 이다. discrete answer search : 자동으로 answer search Answer Paraphrasing 초기 answer space Z′\\mathcal{Z}'Z′ 을 시작으로, paraphrasing 을 사용하여 answer space 를 확장 answer 및 output <z′,y><z', y><z′,y> 주어지면, answer para (z′)(z')(z′) 인 paraphased set 을 생성하는 함수 정의 최종 output 을 모든 answer 에 대한 마진 확률을 정의. P(y∣x)=∑z∈para(z′)P(z∣x)P(y|x) = \\sum_{z \\in \\textup{para}(z')}P(z|x)P(y∣x)=∑z∈para(z′)​P(z∣x) 51 : back-translation 방법을 사용 다른 언어로 번역한 다음, 다시 되돌려 여러 paraphrased answer 을 생성한다 Prune-then-Search : 그럴듯한 answers Z′\\mathcal{Z}'Z′ 를 초기 pruned answer space 에 생성한 후, 알고리즘으로 최종 answer 셋을 선택하는 기법 117, 115 : label yyy 에서 single answer toek zzz 로 매핑하는 함수를 정의. verbalizer 라고 함 최소 두 개의 알파벳 문자를 포함한 토큰 탐색 탐색 단계에서, 데이터의 likelihood 를 극대화하여 label yyy 에 대한 answer zzz 로의 적합도 계산 AutoPrompt : [Z] token 의 contextualized representation 을 입력으로 사용해 logistic classifier 를 학습 탐색 단계에서, 학습된 logistic classifier 로 top-kkk token 을 선택 선택된 토큰들로 answer 형성 32 : 훈련 샘플로 결정된 [Z] 위치의 확률값을 기반으로 top-kkk vocabulary 단어를 선택하여, pruned search space Z′\\mathcal{Z}'Z′ 를 구성 훈련 샘플에 zero-shot 정확도를 기반으로 Z′\\mathcal{Z}'Z′ 의 하위 집합을 선택하여 search space 를 더욱 pruning 함 탐색 단계에서, 고정된 template 와 모든 answer 매핑을 사용하여 LM 을 finetuning 한 후, 이의 정확도를 기반으로 가장 좋은 label word 를 선택 Label Decomposition 13 : 관계 추출 시, 관계 라벨을 구성 요소 단어로 자동으로 분해하고 answer 로 사용 예; per:city_of_death 의 경우, {person,city,death} 로 분해한다. answer span 의 확률은 각 토큰의 확률의 합으로 계산","s":"4.2.2 Discrete Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#422-discrete-answer-search","p":871},{"i":913,"t":"몇몇 연구는 경사하강법으로 최적화할 수 있는 soft answer token 을 사용하는 가능성을 연구한다. 40 에서는 각 class label 에 대한 가상 토큰을 할당하고 prompt token embedding 과 함께 각 클래스에 대한 token embedding 을 최적화한다. answer token 은 임베딩 공간에 직접 최적화할 수 있어, LM 으로 학습된 임베딩을 사용하는 대신 각 라벨을 처음부터 학습한다.","s":"4.2.3 Continuous Answer Search","u":"/docs/Paper/NLP/Survey/Prompting","h":"#423-continuous-answer-search","p":871},{"i":915,"t":"multi-prompt learning : single prompt learning 을 확장하여 효율성을 향상한 방법","s":"5 Multi-Prompt Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":917,"t":"prompt ensembling : 추론 시, 여러 unanswered prompt 를 이용한 프로세스 multiple prompt 는 discrete prompt 또는 continuous prompt 일 수 있다. 서로 보완적인 prompt 의 이점을 활용 prompt engineering 비용 완화 downstream task 의 성능을 안정화 Prompt ensembling 은 머신 러닝의 긴 역사 중 멀티 시스템을 결합한 앙상블 방법을 이용한 것으로, 현재 효과적인 방법을 도출 Uniform averaging : 여러 prompt 의 확률값을 평균 P(z∣x):=1K∑iKP(z∣fprompt,i(x))P(z|x) := \\frac{1}{K} \\sum^K_i P(z|f_{prompt, i}(x))P(z∣x):=K1​∑iK​P(z∣fprompt,i​(x)) fprompt,i(⋅)f_{prompt, i}(\\cdot)fprompt,i​(⋅) 은 iiith prompt 52 : 가장 높은 정확도의 KKK 개 prompt 선택 후, 평균 로그 확률을 사용하여 [Z] 위치의 single token 에 대한 확률 계산 117 : unlabeled 데이터셋에 annotate 하기 위해 앙상블 모델을 사용할 때 간단한 평균화 시도 Bartscore : text generation task 에서, 다양한 prompt 를 사용하여 최종 생성 스코어의 평균을 사용 Weighted averaging : weight 가 있는 각 prompt 로 weight average 를 사용하여 앙상블 weight 는 prompt 성능에 따라 다르고 훈련셋으로 최적화된다. 52 : 훈련셋으로 target output 확률값을 최대화하여 각 prompt 의 weight 학습 103 : 위와 동일한 approach 지만, 데이터 의존적 전략 사용 117, 120 : 훈련셋에서 정확도에 비례하여 각 prompt 에 weight 를 설정 Majority voting : classification task 에서, 다양한 prompt 의 결과를 결합하기 위해 다수결 투표를 사용 (40, 67) Knowledge distillation : 성능 향상을 위해 우수한 모델을 단일 모델로의 knowledge distillation 117, 118, 120 : 수동 생성된 template-answer 쌍으로 모델 훈련 및 앙상블을 통해 unlabeled 데이터셋을 annotate 32 : 자동으로 생성된 template 에서 앙상블 사용 Prompt ensembling for text generation generation task 에 대한 prompt ensembling 연구는 상대적으로 적음 answer sequence 의 다음 단어의 앙상블될 확률 P(zt∣x,z<t):=1K∑iKP(zt∣fprompt, i(x),z<t)P(z_t|x,z_{<t}) := \\frac{1}{K} \\sum^K_i P(z_t|f_{\\textup{prompt, i}}(x), z_{<t})P(zt​∣x,z<t​):=K1​∑iK​P(zt​∣fprompt, i​(x),z<t​) 을 기반으로 output 생성 [118] : 각 prompt fprompt, i(x)f_{\\textup{prompt, i}}(x)fprompt, i​(x) 에 대한 별도의 모델을 훈련 각각의 finetuned LM 을 메모리에 저장하기 힘듬 대신 각 모델의 생성을 디코드한 다음, 생성 확률의 평균을 사용하여 평가","s":"5.1 Prompt Ensembling","u":"/docs/Paper/NLP/Survey/Prompting","h":"#51-prompt-ensembling","p":871},{"i":919,"t":"Prompt Augmentation ( Demonstration Learning ) : LM 에게 input xxx 로 인스턴스화된 실제 프롬프트에 대한 answer 를 제공하는데 사용될 수 있는 answered prompt 를 추가로 제공하는 것 \"중국의 수도는 [Z]\" 대신, \"영국의 수도는 런던. 일본의 수도는 도쿄. 중국의 수도는 [Z]\" 와 같이 prompt 를 제공할 수 있음 few-shot demonstration 으로 강력한 언어 모델이 반복 패턴을 학습하는 데 활용한다. 아이디어는 간단하지만 다음 어려움이 있음 Sample Selection : 가장 효과적인 예는 어떻게 선택? few-shot 시나리오는 선택에 따라 성능이 천차만별 32. 74 : 문장 임베딩으로 input 과 가까운 예제를 샘플링 87 : instruction 에 기반한 LM 의 일반화를 측정하기 위해, 주의할 사항을 강조하는 positive, negative sample 을 모두 제공 Sample Ordering : 선택한 샘플을 올바르게 정렬하는 방법은 무엇? 80 : answered prompt 의 정렬은 모델 성능에 중요한 역할하는 점 발견 및 다양한 후보 순열을 평가하기 위해 entropy 기반 방법 제안 62 : prompt augmentation 으로 훈련 예제의 좋은 순열을 찾고, prompt 사이의 separator token 을 학습하여 성능 증가 145 : prompting 을 통한 answered prompt 를 기반으로 meta-prompt 를 생성하는 것을 제안 37 : Prompt Augmentation 은 많은 textual context 를 제공하여 성능을 증가시키는 검색 기법과 관련 있음을 발견 99 : 37 방법은 prompt 기반 학습에도 효과적임을 발견 37 와의 차이는, prompt augmentation 은 template 과 answer 에 좌우되는 반면, larger context learning 은 그렇지 않다는 것","s":"5.2 Prompt Augmentation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#52-prompt-augmentation","p":871},{"i":921,"t":"Prompt Composition : 여러 하위 프롬프트를 사용하여 각 하위 작업에 수행하고, 해당 하위 프롬프트를 기반으로 composite prompt 를 정의하는 기법 relation extraction task 의 경우, 두 개체 간의 관계를 추출하는 것으로, 개체 식별 및 개체 분류를 포함한 하위 작업으로 분해할 수 있다. 41 : 개체 관계 및 관계 분류에 대한 수동 생성한 여러 sub-prompt 를 생성하고, 관계 추출 로직을 기반으로 완전한 prompt 로 조합","s":"5.3 Prompt Composition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#53-prompt-composition","p":871},{"i":923,"t":"한 샘플로 여러 예측을 수행하는 작업은 전체 input xxx 에 대한 holistic prompt 를 직정 정의하는 것으로 어려움 Prompt Decomposition : holistic prompt 를 여러 sub-prompts 로 분해하여 각 sub-prompts 를 개별적으로 answer 하는 기법 개체 식별 작업에서, input 을 text span 셋으로 변환하고, 모델은 각 span 에 대한 개체 타입 (\"Not an Entity\" 포함)을 예측하도록 prompt 될 수 있음. 이는 span 수가 많아서, 각 span 에 대한 여러 prompt 를 생성하고 개별적으로 예측한다. 17 : 개체 인식에 대한 prompt decomposition 의 접근법을 조사","s":"5.4 Prompt Decomposition","u":"/docs/Paper/NLP/Survey/Prompting","h":"#54-prompt-decomposition","p":871},{"i":925,"t":"prompt 를 통해 모델을 훈련하는 방법을 보자.","s":"6 Training Strategies for Prompting Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":927,"t":"zero-shot learning : text P(x)P(x)P(x) 확률을 예측하는 간단한 모델로 훈련하지 않고 close / prefix prompt 를 채우는 것을 적용할 수 있다. 이는 특정 task 에 대한 훈련 데이터가 없는 zero-shot learning setting 이라 한다. full-data learning : 많은 수의 예제를 모델이 훈련 few-shot learning : 적은 수의 예제로 모델 훈련 훈련 예제가 충분하지 않고 모델이 올바르게 작동하는데 효과적 annotated 훈련 샘플을 downstream task 훈련 에 사용되지 않지만, downstream task 에 사용할 prompt 생성이나 검증에 사용된다. 이점은 96 에 따르면, downstream task 에 관련한 zero-shot learning 이 아니라고 한다.","s":"6.1 Training Settings","u":"/docs/Paper/NLP/Survey/Prompting","h":"#61-training-settings","p":871},{"i":929,"t":"prompt 기반 downstream task learning 엔 두 타입의 파라미터다 있다. pre-trained LMs prompts 다양한 시나리오에 적용 가능한 수준이 다르기 때문에, 파라미터 결정은 중요하다. 다음 여부에 따라 5 가지 tuning 전략을 소개 LM parameter 의 tuning 여부 prompt 관련 parameter 의 추가 여부 추가 prompt 가 있는 경우, 해당 parameter 의 tuning 여부","s":"6.2 Parameter Update Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"#62-parameter-update-methods","p":871},{"i":931,"t":"Promptless Fine-tuning : pretrained LM 의 모든 parameter (또는 일부 46, 98) 가 downstream task 훈련 샘플에서 prompt 없이 gradient 를 통해 업데이트하는 기법 BERT 및 RoBERTa : 위 방법으로 pretrained LM 을 finetuning 이 방법은 간단하며 강력하여 널리 사용되지만, 적은 데이터셋에선 과적합 및 안정적인 학습이 안될 수 있음 84 : 이러한 모델은 catastrophic forgetting 에 취약. 즉, LM 이 finetuning 전에 한 일을 할 수 없게 되는 것 Advantages : 간단, prompt 설계 불필요, LM 의 parameter 를 tuning 하여 큰 데이터셋에 fit 가능 Disadvantages : 적은 데이터셋에선 과적합 및 불안정","s":"6.2.1 Promptless Fine-tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#621-promptless-fine-tuning","p":871},{"i":933,"t":"Tuning-free Prompting : prompt 기반의 pre-trained LM 의 파라미터를 변경하지 않고 직접 answer 를 생성하는 기법 answered prompt 를 선택적으로 augmentation 하거나, in-context learning 으로 tuning-free prompting 과 prompt augmentation 을 조합 가능 일반적으로 tuning-free prompting 의 예로 LAMA 및 GPT-3 이 있음 Advantages : 효율적, 파라미터 업데이트 과정 없음, catastrophic forgetting 없음, zero-shot 설정 적용 가능 Disadvantages : 높은 정확도를 위해선 heavy engineering 필요. in-context learning 에서, 많은 answered prompt 가 제공되면 테스트 시간이 느리고 대규모 훈련셋에 쉽게 사용 불가","s":"6.2.2 Tuning-free Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#622-tuning-free-prompting","p":871},{"i":935,"t":"Fixed-LM Prompt Tuning : prompt 관련 파라미터가 추가되는 상황에, downstream task 훈련 샘플로 얻은 supervision 을 사용하여 prompt 의 파라미터 만을 업데이트하면서도 pretrained LM 은 변하지 않는 기법 일반적으로 Prefix-Tuning 및 Prompt-Tuning 이 있음 Advantages : tuning-free prompting 과 유사하게, LM 의 knowledge 유지 및 few-shot 에 적합. 종종 tuning-free prompting 보다 정확도 높음 Disadvantages : zero-shot 불가능, 대규모 데이터셋에선 representation 이 제한됨, hyperparameter / seed prompts 선택을 통한 prompt engineering 필수. 사람이 이해 및 조작할 수 없음","s":"6.2.3 Fixed-LM Prompt Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#623-fixed-lm-prompt-tuning","p":871},{"i":937,"t":"Fixed-prompt LM Tuning : pretraining 및 finetuning 으로 LM 을 tuning 하지만, 고정된 파라미터의 prompt 를 사용하여 모델의 동작을 지정하는 기법 few-shot 상황에 잠재적인 성능 향상을 가져옴 자연스러운 방법은 모든 훈련 및 테스트 예제에 적용되는 discrete textual template 을 제공하는 것 일반적으로 117, 118 및 32 이 있음 48 : LM finetuning 일부와 prompt answer engineering 의 조합으로 prompt engineering 을 줄일 수 있음을 관찰 input 과 mask 를 template word 없는 \"[X][Z]\" 로 직접 연결한 간단한 템플릿 null prompt 를 정의 경쟁력 있는 정확도를 달성 Advantages : Template 및 answer engineering 은 특정 task 에 더 경쟁력 있고 더 효과적인 학습을 함. 특히 few-shot 상황에 좋음. Disadvantages : prompt 가 없으면 Template 및 answer engineering 이 여전히 필요. 한 downstream task 에 finetuning 된 LM 은 다른 downstream task 에 비효율적","s":"6.2.4 Fixed-Prompt LM Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#624-fixed-prompt-lm-tuning","p":871},{"i":939,"t":"Prompt+LM Tuning : pretrained LM 의 파라미터의 일부나 모두를 prompt 관련 파라미터와 함께 finetuning 하는 기법 일반적으로 PADA 및 P-Tuning 이 있음 표준 pretraining 과 finetuning 패러다임과 유사하지만, prompt 추가로 모델 훈련 시작 시 추가 부스팅을 제공 Advantages : 표현력이 가장 뛰어난 방법, 높은 수준의 데이터에 적합 Disadvantages : 모든 모델의 파라미터를 훈련하고 저장이 필요. 적은 데이터셋에는 과적합","s":"6.2.5 Prompt+LM Tuning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#625-promptlm-tuning","p":871},{"i":941,"t":"어떠 분야에 사용되었는지 관점으로 섹션 시작","s":"7 Applications","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":943,"t":"Factual Probing : prompting method 를 적용하여 사실을 탐색하는 가장 초기의 시나리오로, LM 의 representation 이 얼마나 사실적 지식을 많이 담는지 정량화하는 것 LM parameter 를 고정되고, 수동 / 자동으로 발견될 수 있는 close prompt 로 original input 을 변환하여 지식을 탐색 LAMA 및 X-FACTR 가 관련 데이터셋 포함 answer 가 미리 정의되어, 효과적인 template 및 다양한 모델의 결과 분석에 중점적 discrete template search [43, 50, 52, 96, 99, 100, 125] continuous template learning [77 103 152] 및 prompt ensemble learning [52 103] 가 탐구됨 Linguistic Probing : 대규모 pretrained LM 은 analogies 9, negations 25, semantic role sensitivity 25, semantic similarity 131, understanding 131 및 rare word understanding 116 가능 위 지식은 LM 이 완성해야할 자연어 문장의 형태로 lignuistic probing 작업을 제시하여 도출","s":"7.1 Knowledge Probing","u":"/docs/Paper/NLP/Survey/Prompting","h":"#71-knowledge-probing","p":871},{"i":945,"t":"Semantic Parsing : 자연어가 주어지면 구조화된 의미있는 representation 을 생성하는 작업 124 : LM 으로 few-shot semantic parsing 에 대한 task 를 탐구 의미있는 파싱 작업을 paraphrasing 작업으로 재구성 문법에 따라 유효한 출력만 허용하여 디코딩 in-context learning 으로 테스트 예제와 의미있게 가까운 answered prompt 선택 pretrained LM 으로 의미있는 파싱에 대한 paraphrasing 재구성의 효과를 입증","s":"7.2 Structure Prediction","u":"/docs/Paper/NLP/Survey/Prompting","h":"#72-structure-prediction","p":871},{"i":947,"t":"classification-based tasks 는 텍스트 분류와 자연어 추론과 같이 템플릿을 쉽게 구성할 수 있다. 핵심 prompting 은 적절한 prompt 를 구성하는 것이다. 예로, 144 에서는 \"이 문서의 주제는 [Z].\" 같은 prompt 를 사용하며, 이 prompt 는 슬롯을 채우기 위해 masked pretrained LM 에 입력된다. Text Classification 이전 연구들에선 대부분 close prompt 사용 prompt template engineering [32. 40, 67] 및 prompt answer engineering [32, 115, 117] 이 탐구되어, fixed-prompt LM Tuning 으로 few-shot 에서 텍스트 분류에 대한 prompt 효율성을 탐구 Text Pair Classification : 두 문장 간의 관계 (유사성, 함축 등)를 예측하는 작업 paraphrase 식별, 자연어 추론, 텍스트 유사성 예측 등의 작업 포함 text classification 과 유사하게, close prompt 일반적으로 사용 [117, 120] few-shot 의 template 에 중점을 두거나 answer space Z\\mathcal{Z}Z 를 vocabulary 에서 수동으로 선택하는 연구 존재","s":"7.3 Classification-based Tasks","u":"/docs/Paper/NLP/Survey/Prompting","h":"#73-classification-based-tasks","p":871},{"i":949,"t":"prompt 를 구성하는 데, 섬세함이 classification task 보다 더 필요 Relation Extraction : 문장 내의 두 개체 간의 관계 예측 13 : relation extraction 에서 처음으로 fixed-prompt LM Tuning 기법 적용 및 classification task 로 부터의 prompting 상속을 방해하는 두 가지를 논의 더 큰 label space (예; 80개 관계 추출 vs 이진 감정 분류) 는 prompt answer engineering 에 큰 어려움 초래 관계 추출에서 input sequence 의 여러 token 들은 중요도가 다름. 위 문제 해결을 위해, adaptive answer selection method 제안 task-oriented prompt template 구축 template 에서 entity mention 을 강조하기 위해 특수 마커 (예; [E]) 사용 41 : 위와 유사하게, multiple prompt 를 통해 개체 유형 정보를 통합 Named Entity Recognition : 문장 내의 named entity 식별 (예; 사람 이름, 지역) tagging task 에 prompt-based learning 적용이 어려움 예측 단위가 text 가 아닌 token 이나 span 임 token label 간의 잠재적인 관계가 존재 17 : BART 로 template-based NER 모델 제안 text span 열거 및 수동 생성된 template 내에서 각 타입의 생성 확률 고려 \"마이크는 어제 뉴욕에 갔다\" 가 주어지면 \"마이크는 [Z] 개체다.\" 라는 template 으로 결정 answer space Z\\mathcal{Z}Z 는 \"사람\", \"조직\" 과 같은 값으로 구성","s":"7.4 Information Extraction","u":"/docs/Paper/NLP/Survey/Prompting","h":"#74-information-extraction","p":871},{"i":951,"t":"신경망이 \"추론\" 을 하는지 \"페턴\" 을 인식하는지는 아직도 논쟁이다. 추론 능력 조사를 위해 다양한 시나리오를 포괄하는 벤치마크 작업을 정의하는 시도가 많다. Commonsense Reasoning : NLP 의 상식 추론을 테스트 하는 것. 많은 벤치마크 데이터셋 존재 [47, 72, 101, 107] 68 : 모호한 대명사를 선행 식별하거나 여러 선택 중 문장을 완성하도록 모델에게 요구하여 해결 전자의 경우, \"트로피가 갈색 가방에 못 들어가. 이것은 너무 커.\" 에서 \"이것\" 이 트로피인지 가방인지 추론 후자의 경우, \"Eleanor 은 손님에게 커피를 제안했다. 그녀는 깨끗한 [Z] 가 없단걸 깨달았다\" 에서 후보군은 \"컵\", \"그릇\", \"숟가락\" 이다. 134 : 잠재적 후보의 다양한 선택 확률을 계산하여 pretrained LM 으로 가장 높은 확률을 택하여 전자 해결 25 : 각 후보의 생성 확률을 평가하여 가장 높은 확률을 선택하여 후자 해결 Mathematical Reasoning : 산술, 함수 등과 같은 수학 문제를 해결하는 것 pretrained embedding 및 LM 은 작은 숫자에서 산술을 수행하지만, 숫자가 크면 실패하는 것을 발견 [9, 88, 139] 110 : 복잡한 수학 추론 문제 탐구 (예; f(x)=x∗xf(x) = x * xf(x)=x∗x, f(f(3))f(f(3))f(f(3)) =?) 및 질문에 대한 추론을 직렬화하여 LM 성능 향상","s":"7.5 \"Reasoning\" in NLP","u":"/docs/Paper/NLP/Survey/Prompting","h":"#75-reasoning-in-nlp","p":871},{"i":953,"t":"Question answering (QA) : context document 를 기반으로 input question 에 대한 answer 제공을 목표 QA 는 다양한 형태 존재 extractive QA [SQuAD] : context document 에서 answer 을 포함하는 내용 식별 multiple-choice QA [RACE] : 모델이 여러 선택지 중에 선택 free-form QA [NarrativeQA] : 모델이 임의의 텍스트 문자열을 answer 로 반환 이런 다양한 형태는 서로 다른 모델링 프레임워크로 처리하지만, prompting 을 통하면 한 프레임워크로 처리할 수 있다는 장점이 있다. 55 : context 와 question 으로 적절한 프롬프트 및 seq2seq pretrained T5 를 finetuning 하여 QA task 를 text generation 문제로 재구성 51 : seq2seq pretrained LMs (T5, BART, GPT2) 으로 QA task 를 관찰하여, 이러한 모델들의 확률이 QA 작업에 유용하지 않다는 점 발견","s":"7.6 Question Answering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#76-question-answering","p":871},{"i":955,"t":"Text Generation : 다른 정보에 따라 텍스트를 생성하는 작업들의 집합. prompting 방법은 prefix prompt 와 함께 autoregressive pretrained LM 으로 쉽게 적용 가능 105 : \"프랑스어 번역, [X], [Z].\" 같은 prompt 를 사용하여 텍스트 요약 및 번역의 생성 작업의 놀라운 성능 입증 9 : 텍스트 생성에 in-context learning 수행, multiple answered prompt 로 수동 템플릿 및 augmenting 와 함께 prompt 생성 118 : 수동 생성된 template 로 few-shot 텍스트 요약에 대한 fixed-prompt LM tuning 탐구 71 : few-shot 에서 텍스트 요약 및 data-to-text 생성에 대한 fixed-LM prompt tuning 을 탐구 learnable prefix token 을 input 앞에 붙임 pretrained LM 의 파라미터를 유지 23 : 텍스트 요약 task 에서 prompt+LM tuning 전략 탐구 learnable prefix prompt 사용 및 pretrained LM 의 파라미터와 함께 업데이트","s":"7.7  Text Generation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#77--text-generation","p":871},{"i":957,"t":"147 : 생성된 텍스트에 자동 평가를 prompt learning 으로 사용될 수 있음을 입증 pretrained seq2seq 을 사용하여 생성된 텍스트의 평가를 텍스트 생성 문제로 개념화하고 pretraining task 와 가깝게 평가하도록 하는 prefix prompt 사용 실험적으로 변역된 텍스트에 \"such as\" 문구를 추가하여, 독일어-영어 번역 평가에서 상당한 관계 개선을 가져올 수 있음을 발견","s":"7.8 Automatic Evaluation of Text Generation","u":"/docs/Paper/NLP/Survey/Prompting","h":"#78-automatic-evaluation-of-text-generation","p":871},{"i":959,"t":"prompting 기술은 NLP task 뿐 아니라 다른 task 에도 모델을 훈련하는 데 유용한 요소로 작용 Domain Adaptation : 한 도메일에서 다른 도메인으로 적응 시키는 것 (예; 뉴스 → 소셜 미디아) 5 : 원본 텍스트 input 을 augmentation 하기 위해 self-generated DRFs 사용 및 seq2seq 모델로 시퀀스 태깅 수행 Debiasing 121 : LMs 가 biased / debiased instruction 에 따라 self-diagnosis / self-bebiasing 을 수행할 수 있음을 발견 self-diagnosis 의 경우 폭력적인 정보가 포함되었는지 self-diagnosis 하기 위해, \"The following text contains violence. [X][Z]\" 사용 가능 ㅤ[X] 를 채우고 [Z] 의 생성 확률을 본다. \"Yes\" 와 \"No\" 의 확률을 통해 폭력이 포함되었는지 아닌지 추정 debiasing 의 경우 input 이 주어지면 다음 단어의 확률 P(xt∣x<t;θ)P(x_t | x_{<t}; \\theta)P(xt​∣x<t​;θ) 계산 self-diagnosis input 을 원본 input 에 추가하여 다음 단어의 확률 P(xt∣[x<t;xdiagnosis];θ)P(x_t | [x_{<t};x_{\\textup{diagnosis}}];\\theta)P(xt​∣[x<t​;xdiagnosis​];θ) 계산 다음 토큰에 대한 위의 두 확률 분포를 결합하여 원하지 않는 속성을 막음 Dataset Construction 117 : 특정 instruction 이 주어지면 데이터셋을 생성하기 위해 pretrained LM 사용을 제안 의미적으로 유사한 문장으로 데이터셋 구성할 경우, 각 input 문장은 다음과 같은 template 을 사용할 수 있다. \"Write two sentences that mean the same thing. [X][Z]\" 그리고 같은 의미를 공유하는 문장을 생성할 수 있다.","s":"7.9 Meta-Applications","u":"/docs/Paper/NLP/Survey/Prompting","h":"#79-meta-applications","p":871},{"i":961,"t":"135 : NLP 의 prompt learning 을 multi-modal 에서 적용 fixed-LM prompting tuning 과 prompt augmentation 사용 각 이미지를 continuous embedding 의 시퀀스로 표현하고 파라미터가 고정된 pretrained LM 으로 프롬프트화하여 image caption 을 생성 위 결과는 few-shot learning 능력을 보여줌 → few demonstration (answered prompt) 을 통해 시스템이 새로운 객체와 시각점 카테고리에 대한 단어를 빠르게 학습","s":"7.10 Multi-modal Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#710-multi-modal-learning","p":871},{"i":963,"t":"prompt-based learning 의 본질 및 다른 learning method 와의 관계를 알아보자. Ensemble Learning : 여러 시스템의 상보성(complementarity) 의 이점을 사용하여 task 의 성능 향상을 목적 앙상블은 여러 시스템의 아키텍처, 학습 전략, 데이터 순서 또는 무작위 초기화로 생성 prompt template 의 선택 또한 여러 결과를 생성하는 하나의 방법 여러 번 학습할 필요가 없는 이점 예로, discrete prompt 사용 시 추론 단계에서 간단히 변경 가능 [52] Few-shot Learning : 적은 훈련 샘플로 데이터가 적은 상황에 훈련하는 것을 목표. 다양한 방법 존재 model agnostic meta-learning [29] : 새로운 task 에 빨리 적응하는 feature 학습 embedding learning [8] : 유사한 샘플이 서로 가깝도록 각 샘플을 저차원 공간에 임베딩 memory-based learning [53] : 각 샘플이 메모리에서 내용을 weighted average prompt augmentation [62] : few-shot 을 위한 방법으로 볼 수 있음. 파라미터 tuning 없이 pretrained LM 에서 knowledge 를 유도하여 여러 샘플을 더 추가 가능 Larger-context Learning : input 에 학습 데이터셋 [11] 또는 외부 데이터 소스 [38] 에서 검색된 추가적인 문맥 정보로 augmentation 하여 성능을 향상하는 것이 목표 Prompt Augmentation 은 input 에 관련 라벨 샘플을 추가하지만, larger-context learning 과의 차이점은 라벨 데이터가 반드시 필요하지 않다는 점 Query Reformulation : input query 를 관련된 용어로 확장하거나 paraphrasing 을 생성하여 관련성 높은 텍스트를 유도하는 것이 목표 정보 검색 [90] 및 QA task [10, 136] 에서 사용 prompt-based learning 와 query reformulation 간의 공통성이 있음 기존 지식 베이스를 더 잘 활용하기 위해 올바른 질문을 던짐 지식 베이스는 일반적으로 black-box 여서, 질문에만 기반한 최적화 방법을 학습해야 함 차이점 또한 존재 query reformulation : 지식 베이스는 search engine [90] / QA system [10] 에 사용 prompt-based learning : 지식 베이스를 LM 으로 정의 및 적절한 answer 유도를 위해 적절한 프롬프트 탐색 필요 위 차이점에도 불구하고, query reformulation 은 prompt learning 에 도움이 됨 QA-based Task Reformulation : 다양한 NLP task 를 question-answer 문제로 개념화 하는 것을 목표 어떤 task 를 수행할지 지정하기 위해 text question 을 사용하는 점에서 prompting 방법과 유사 61. 83 : 다양한 NLP task 를 QA 프레임워크로 통합을 시도한 초기 연구 정보 추출 [70, 142] 및 텍스트 분류 [12] 로 위 아이디어 더욱 연구 argRanker : 논쟁적인 관계 분류를 수동으로 연결한 두 문장의 랭킹 문제로 개념화 Controlled Generation : input text 외의 다양한 유형의 가이드를 생성 모델에 통합하는 것을 목표 guidance signal 은 style token [27, 123], length spacifications [56], domain tags [14] 또는 생성된 텍스트를 제어하기 위해 사용되는 다양한 다른 정보일 수 있다. 생성된 텍스트의 내용을 계획하기 위해 keywords [112], relation triples [154] 또는 highlighted phrases or sentences [34, 78] 일 수도 있다. 이 작업에서 prompt 는 task 지정에 사용되며, 다음 두 유형 사이에 공통점을 발견할 수 있음 나은 생성을 위해 input text 에 정보를 추가하며, 이러한 additional signals 는 learnable parameter 이다 \"controlled generation\" 을 seq2seq pretrained LM (예;BART) 로 얻었다면, input 종송적인 prompt 및 prompt+LM fine-tuning 전략을 가진 prompt learning 으로 간주 가능. 예; prompt 및 LM 파라미터로 tuning 가능한 GSum controlled generation 과 prompt-based text generation 의 차이 control 은 생성 스타일이나 내용 제어하는데 사용 [23, 27] 하면서도 동일한 task 상태로 유지. pretrained LM 이 필수적이지 않음 text generation 의 prompt 사용 동기는 task 명시 및 pretrained LM 활용 text generation 의 prompt learning 은 최근 연구에서 데이터셋 또는 task-level prompt 를 공유 [71] 몇몇 연구에서만 input 종속성에 대해 탐구하지만, contolled text generation 에서 일반적인 세팅이며 효과적이다. prompt learning 에 대한 미래 연구의 방향을 제공할 수도 있다. Supervised Attention : 데이터 기반 attention 은 과적합될 수 있어, 모델의 attention 을 supervised 로 제공하는 것을 목표 [76] 주요 정보에 attention 하는 것은, long text sequence [75, 129], images [130, 149] 또는 knowledge bases [23, 146] 과 같은 객체에서 유용한 정보를 추출하는데 핵심적인 단계 prompt learning 및 supervised attention 은 어떠한 단서로 주요 정보를 추출하는 아이디어가 같으며, 이 단서는 별도로 제공되야 한다. 이를 해결하기 위해, supervised attention 은 수동으로 라벨링된 corpus 에서 gold attention 예측을 위해 추가 손실 함수를 사용하여 학습을 시도 [31, 49, 102] Data Augmentation : 기존 데이터를 수정하여 훈련에 사용될 데이터 양을 늘리는 기술 [26, 109] 114 : prompt 추가가 분류 작업 전반에 걸쳐 100개 이상의 데이터 포인트 추가와 유사한 정확도 향상을 평균적으로 얻을 수 있음을 발견 downstream task 에 대한 prompt 사용이 data augmentation 을 암묵적으로 수행하는 것과 유사하다는 것을 시사","s":"8 Prompt-Relevant Topics","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":965,"t":"prompt-based learning 은 다양한 task 와 상황에 대해 상당한 잠재력을 보여주지만, 아직 몇몇 과제들이 있다.","s":"9 Challenges","u":"/docs/Paper/NLP/Survey/Prompting","h":"","p":871},{"i":967,"t":"다양한 LMs 가 있어, prompt-based learning 을 더 잘 활용하기 위해 선택하는 법도 과제이다. 현재까지 다양한 pretrained LM 에 대한 prompt-based learning 이점의 체계적인 비교가 거의 없거나 전무하다.","s":"9.1 Selection of Pre-trained LMs","u":"/docs/Paper/NLP/Survey/Prompting","h":"#91-selection-of-pre-trained-lms","p":871},{"i":969,"t":"Tasks beyond Classification and Generation : prompt-based learning 은 text classification / generation-based task 에 비해 information extraction / text analysis task 는 덜 다루어졌다. 이유는 prompt 설계가 덜 직관적이기 때문이다. 추후, 적절한 텍스트 형태로의 구조화된 출력을 표현하는 효과적인 prompt answer engineering 이나, 텍스트 분류 및 생성 작업처럼 재구성이 필요할 것으로 보임 Prompting with Structured Information : NLP task 에서 input 은 tree, graph, table, relational structure 등 다양하게 표현할 수 있는데, template / answer engineering 에서 어떻게 잘 표현할지가 과제 13 : 기존 연구는 entity marking 처럼, 어휘 정보를 인코딩하여 추가적인 marks 와 prompt 를 만들어서 단계를 나아간다. 1 : fine-grained web text 생성에 대해 hyper text markup language 를 기반으로 구조화된 prompt 제안 하지만 이 방법은 복잡한 구조의 다양한 형태로 확장하는 것은 아직 탐구되지 않아, 흥미로운 연구 주제일 수 있다. Entanglement of Template and Answer : 모델 성능은 사용 중인 template 과 고려 중인 answer 에 따라 달라진다. template 과 answer 의 최상의 조합을 동시에 탐색하거나 학습하는 방법은 여전히 어려운 문제 최근 template 선택 전에 answer 을 선택하지만 [32, 125] , 40 에서는 두 가지의 동시 학습의 잠재력을 입증","s":"9.2 Prompt Design","u":"/docs/Paper/NLP/Survey/Prompting","h":"#92-prompt-design","p":871},{"i":971,"t":"Many-class Classification Tasks : class 가 너무 많은 경우, 적절한 answer space 를 선택하는 방법은 어려운 최적화 문제 Long-answer Classification Tasks : multi-token answer 을 사용하는 경우, LMs 를 사용하여 다중 토큰을 잘 디코딩하는 방법은 아직 알려지지 않았으며, 몇 가지 다중 토큰 디코딩 방법이 제안되었지만 [50], 여전히 최적이지 않음 Multiple Answers for Generation Tasks : text generation 의 경우, 적절한 answer 는 의미는 동등하지만 문법적으로는 다양 거의 모든 연구가 single answer 에 의존하여 text generation 을 prompt learning 을 사용하며, 예외적인 경우는 거의 없음 [52] 멀티 레퍼런스로 학습 과정을 잘 가이드하는 방법은 여전히 크게 연구되지 않은 문제","s":"9.3 Prompt Answer Engineering","u":"/docs/Paper/NLP/Survey/Prompting","h":"#93-prompt-answer-engineering","p":871},{"i":973,"t":"prompt, LMs, 또는 둘 모두의 파라미터 튜닝에는 다양한 방법이 있다. 이 연구 분야의 초기 단계에서, 이러한 방법들 사이의 균형에 대한 체계적인 이해가 부족하다. 다양한 전략들 간의 균형에 대한 체계적인 탐구로 pretrain 및 finetune 패러다임에 수행되는 것과 유사학 이득을 취할 수 있을 것이다 [98].","s":"9.4 Selection of Tuning Strategy","u":"/docs/Paper/NLP/Survey/Prompting","h":"#94-selection-of-tuning-strategy","p":871},{"i":975,"t":"Prompt Ensembling : prompt ensembling 에서, prompt 를 많이 고려할수록 공간 및 시간 복잡도는 증가 다양한 프롬프트의 knowledge 를 추출하는 방법은 아직 충분히 탐구되지 않음 118, 120 및 117 : 앙상블 모델을 사용하여 다양한 프롬프트의 knowledge 추출을 위해 대규모 데이터셋에 annotation 을 달았다. 앙상블 할만한 프롬프트를 선택하는 방법도 아직 충분히 탐구되지 않음 텍스트 생성 작업의 경우, prompt ensemble learning 의 연구가 수행되오지 않았으며, 이는 텍스트 생성에서의 앙상블 학습이 비교적 복잡하기 때문 Refactor : 위 해결방안으로, neural ensembling method 제안 Prompt Composition and Decomposition : 다중 sub-prompt 를 도입하여 복잡한 task input 의 어려움을 제거하는 것이 목표. 좋은 선택을 해야 하는 것이 중요 token [81] / span [30] 예측 task (예; NER) 의 경우, prompt decomposition 를 고려할 수 있음 span relation [66] 예측 task (예; 개체 인식) 의 경우, prompts composition 이 더 좋은 선택일 것임 Prompt Augmentation : 기존의 prompt augmentation 은 입력 길이에 제한이 있다. 예로, 너무 많은 demonstration 을 input 으로 넣으면 실행 불가능하다. 정보를 가진 demonstration 을 선택하고 적절하게 정렬하는 방법은 흥미롭고 도전적인 문제다 [62] Prompt Sharing : 이전엔 주로 single task, domain, language 에 대한 prompt 적용이었지만 multiple 에 대해서도 prompt learning 을 적용하는 prompt sharing 을 고려할 수 있다. 다양한 task 에서 개별 prompt 를 설계 및 각각의 상호작용을 맞추는 법이 핵심 지금까지 많이 탐구되지 않은 분야 Fig. 3 에서 mutiple task 에 대한 multiple prompt learning 전략으로 prompt template 을 공유하는 것을 보여준다","s":"9.5 Multiple Prompt Learning","u":"/docs/Paper/NLP/Survey/Prompting","h":"#95-multiple-prompt-learning","p":871},{"i":977,"t":"많은 상황에선 성공하지만, prompt-based learning 의 이론적 분석과 보장은 희박하다. 141 : soft-prompt tuning 은 downstream recovery (예; downstream task 의 ground-truth labels 을 복원하는 것)를 위해 필요한 non-degeneracy assumptions (각 토큰의 생성 확률은 선형적으로 독립) 을 완화시킬 수 있음을 입증 이는 task-specific 정보를 추출하기 쉽게 만들어줌 113 : 텍스트 분류 작업은 문장 완성 작업으로 재구성할 수 있음을 검증하여, 언어 모델링이 의미 있는 pretrained 작업이 될 수 있음을 보여줌 114 : 분류 작업 전반에 걸쳐 prompt 가 평균 데이터 포인트 수백 개에 해당하는 가치가 있다는 것을 경험적으로 보여줌","s":"9.6 Theoretical and Empirical Analysis of Prompting","u":"/docs/Paper/NLP/Survey/Prompting","h":"#96-theoretical-and-empirical-analysis-of-prompting","p":871},{"i":979,"t":"prompt 가 모델에 특화된 정도를 이해하고 prompt 의 전이성을 향상시키는 것 또한 중요한 주제 96 에선 tuned few-shot learning 상황 (prompt 를 선택하기 위해 더 큰 검증셋이 있는 경우)에서 선택된 prompt 가 유사한 크기의 모델에 잘 일반화되는 반면, true few-shot 상황 (학습 샘플이 몇 개 뿐일 경우)에서 선택된 prompt 는 전자보다 일반화되지 않는 다는 것을 보여줌. 모델 크기가 두 상황 모두에서 상당히 다른 전 경우, 전이성이 낮다.","s":"9.7 Transferability of Prompts","u":"/docs/Paper/NLP/Survey/Prompting","h":"#97-transferability-of-prompts","p":871},{"i":981,"t":"prompting 패러다임의 성공은 BERT 같은 pretrain 및 finetune 으로 개발된 pretrained LMs 의 top 에서 구축되었다. 하지만, 후자에 대한 효과적인 pretraining 방법이 전자에 그대로 적용할 수 있는지, 또는 다시 생각하여 정확성이나 prompt-based learning 의 적용 용이성을 더 개선할 수 있는지 중요한 연구 질문으로, 이에 대한 문헌은 충분히 다뤄지지 않았다.","s":"9.8 Combination of Different Paradigms","u":"/docs/Paper/NLP/Survey/Prompting","h":"#98-combination-of-different-paradigms","p":871},{"i":983,"t":"Calibration (보정)는 모델이 좋은 확률적 예측을 할 수 있는 능력을 말한다 33. answer 예측을 위해 pretrained LMs (예; BART) 의 생성 확률 사용 시, 확률 분포가 일반적으로 잘 보정되어 있지 않아 조심할 필요가 있다. 51 : QA task 에서의 pretrained LMs (예; BART, T5, GPT2) 의 확률이 잘 보정된다는 점 발견 151 : answered prompt 가 제공됐을 때, pretrained LMs 가 특정 answer 로 향하도록 편향되는 세 가지 문제점 (대부분 label bias, receny bias, common token bias)을 식별함 예로, 최종 answered prompt 가 positive label 이면, 모델은 positive words 를 예측하도록 편향됨 이를 해결하기 위해 context-free input (예; prompt 가 \"Input: Subpar acting. Sentiment: Negative\\n Input: Beautiful film. Sentiment: Positive\\n Input: N/A. Sentiment:\")을 사용하여 초기 확률 분포 P0P_0P0​ 을 얻는다 real input (예; prompt 가 \"Input: Subpar acting. Sentiment: Negative\\n Input: Beautiful film. Sentiment: Positive\\n Input: Amazing. Sentiment:\") 를 사용하여 확률 분포 P1P_1P1​ 를 얻는다. 이 두 분포를 사용하여 보정된 생성 확률 분포를 얻는다. 이 모델은 두 가지 단점이 있다. 적절한 context-free input (예; \"N/A\" 나 \"None\" 을 사용할지 여부)을 찾는 추가 비용 발생 pretrained LMs 의 확률 분포는 여전히 보정되지 않음 보정된 확률 분포가 있어도, input 에 대한 single gold answer 추정할 때 조심할 필요가 있다. 동일한 객체의 표면 형태가 유한한 확률 질량을 경쟁한다는 것을 의미 45 예로, \"Whirlpool bath\" 가 gold answer 이라면, 해당 생성 확률은 일반적으로 낮을 것이다. 이유는 \"Bathtub\" 단어는 동일한 의미를 공유하며 더 큰 확률 질량을 차지하기 때문이다. 이를 해결하기 위해 paraphrasing 을 사용하여 gold answer set 을 포괄적으로 구성하는 prompt answer angineering 을 수행 단어 확률을 context 내의 이전 확률에 기반하여 보정","s":"9.9 Calibration of Prompting Methods","u":"/docs/Paper/NLP/Survey/Prompting","h":"#99-calibration-of-prompting-methods","p":871},{"i":985,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2203.02155.pdf https://openai.com/blog/chatgpt 논문 제목 : Training language models to follow instructions with human feedback ChatGPT Blog","s":"Training language models to follow instructions with human feedback (+ ChatGPT)","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":987,"t":"큰 규모의 language 모델은 허위나 toxic 을 유저에게 생성할 수 있다. 다시 말해, 모델이 사용자의 원하는 답과 일치하지 않음을 뜻한다. 본 논문에서는 다음 방법을 제안한다. 라벨러가 쓴 prompt 와 OpenAI API 로 제출된 prompt 의 셋으로 입증된 데이터셋을 모음 지도 학습으로 GPT-3 를 supervised fine-tune 한다. 모델 output 에 랭킹을 매김 human feedback 으로 강화 학습을 진행하여 지도 학습된 모델을 fine-tune 위 과정을 통해 나오는 결과 모델을 InstructGPT 라 칭한다. 이 모델은 175B GPT-3 보다 100배 적은 1.3B 파라미터로 허위가 줄고, 신뢰있도록 개선되었다.","s":"Abstract","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":989,"t":"최근의 Large language models (LMs) 는 인터넷의 정보들을 토큰으로 예측하기 때문에 사용자가 원하는 지시와는 다를 수 있다. 따라서 이는 모델과 유저의 목표가 불일치하다고 할 수 있다. 따라서 사용자의 지시와 일치하는 행동을 하도록 훈련을 하여 aligning 한 언어 모델을 만든다. 여기에 aligning language model 를 위해 fine-tune 접근법에 초점을 맞춘다. 특히, broad class (instructions) 로 GPT-3 를 fine-tune 하기 위해 human feedback 으로 강화학습을 한다. ( RLHF ) 이 모델 (InstructGPT) 과정은 다음과 같다. 40명의 라벨러로부터 입증된 데이터셋을 모아 GPT-3 를 supervised fine-tune (SFT) 라벨러가 선호하던 output 으로 예측할 수 있도록 reward model (RM) 으로 훈련 이 RM 을 PPO optimization 으로 강화 학습 이 모델은 GPT-3 를 사용했으며, 사이즈가 1.3B, 6B, 175B parameter 를 가진다. 주요 결과는 다음과 같다. 라벨러가 GPT-3 결과보다 InstructGPT 결과를 더 선호 InstructGPT 가 GPT-3 의 truthfulness 를 개선 InstructGPT 가 GPT-3 의 toxicity 를 조금 개선, 그러나 bias 는 개선을 보이지 않음 RealToxicityPrompt 데이터셋으로 toxicity 를 측정 GPT-3 보다 25% 더 적은 toxic output 을 생성 Wingogender 와 CrowSPairs 데이터셋은 GPT-3 보다 나은 개선은 보이지 않았다. RLHF 를 수정하여 공개 데이터셋의 성능 저하를 최소화 RLHF fine-tuning 하는 동안 SQuAD, DROP, HellaSwag, WMT 2015 데이터셋에서 GPT-3 와 비교하여 성능 저하를 관찰했다. PPO 와 pretraining 분포의 log-likelihood 의 증가를 혼합하여 성능 저하를 감소 데이터를 생성하지 않은 보류중인 라벨러의 선호도를 일반화 공개 데이터셋에는 InstructGPT 에 사용된 방식을 반영하지 않음 InstructGPT 는 RLHF fine-tuning 에 벗어난 명령에도 좋은 일반화를 보임 InstructGPT 는 여전히 약간의 실수가 있음 log-likelihood 특정 확률 분포에서 주어진 데이터가 관찰될 가능성을 나타내는 값 간단히, 주어진 데이터가 특정 분포에 얼마나 잘 맞는 가를 측정하는 척도","s":"1. Introduction","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":993,"t":"방법론은 다음 세 가지 스텝을 따른다. 입증된 데이터를 모아, supervised policy 훈련 라벨러로부터 입증된 데이터 수집 pretrained GPT-3 를 supervised learning 하여 fine-tuning 비교 데이터를 모아, reward model 훈련 모델 output 을 비교하여, 라벨러가 어떤 것을 선호하는지 랭킹 부여 이후 reward model 을 훈련 PPO 로 reward model 에 대한 policy 를 최적화 RM 에 PPO 알고리즘을 사용하여 supervised policy 를 최적화하며 fine-tuning","s":"3.1 High-level methodology","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#31-high-level-methodology","p":984},{"i":995,"t":"본 논문의 데이터셋에는 OpenAI AIP 로 제출된 text prompt 가 포함되어 있디. 처음 InstructGPT 를 학습할 때, 라벨러에게 스스로 prompt 를 작성하라고 요청했다. 이 이유는 모델이 스스로 작동하기 위한 instruct-like prompt 초기 자원이 필요하다. 또한 라벨러에게 다음의 3가지 종류의 prompt 를 작성하길 요청했다. Plain : 간단한 arbitrary task 을 생산하면서도 다양성을 가지도록 함 Few-shot : instruction 과 이에 대응하는 질의응답 생산 User-based : OpenAPI API 의 application 사용사례를 가지고 있으므로, 라벨러에게 사용 사례에 대응하는 prompt 를 생산하도록 요청 세 가지의 데이터셋을 생산하여 fine-tuning 에 사용한다. SFT 모델의 훈련으로 사용할 SFT dataset (13k) RM 모델의 훈련으로 사용할, 모델의 출력에 라벨러가 랭킹을 매긴 RM dataset (33k) 라벨러 없이, RLHF fine-tuning 을 위한 input 으로 사용될 PPO dataset (31k)","s":"3.2 Dataset","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#32-dataset","p":984},{"i":997,"t":"훈련 task 는 두 가지의 형태를 지닌다. 라벨러가 작성한 promtpt dataset API 로 InstructGPT 에 제출된 prompt dataset 위의 prompt 는 generation, question, answer, dialog, summarization, extraction, other natural language task 를 포함하고 있다.","s":"3.3 Task","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#33-task","p":984},{"i":999,"t":"Upwork 및 ScaleAI 에서 40명과 계약 하여 정보 수집을 위한 팀을 고용","s":"3.4 Human data collection","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#34-human-data-collection","p":984},{"i":1001,"t":"먼저, pretrained language model 인 GPT-3 로 시작한다. GPT-3 는 인터넷 데이터를 훈련한 것으로, 넓은 범위에서 downstream task 로 사용된다. 본 논문에서는 GPT-3 를 세 가지의 기술로 훈련한다. Supervised fine-tuning (SFT) supervised learning 으로 입증된 데이터를 통해 GPT-3 를 fine-tuning 한다. 다음 사항들로 훈련을 진행한다. 16 epochs cosine learning rate decay residual dropout 0.2 검증셋의 RM score 를 기반으로 최종 SFT 모델을 선택 SFT 모델이 1 epoch 이후의 검증 loss 가 overfit 하는 것을 발견 overfit 에도 불구하고, 더 많은 에폭을 훈련하면 RM score 와 라벨러의 선호도 랭킹에 도움이 되는 것을 발견 Reward modeling (RM) SFT 모델의 마지막 unembedding layer 를 제거하여 시작 prompt 와 response 를 사용하여 scalar reward 를 출력하도록 훈련시킨다. 175B RM 은 불안정하여 6B RM 을 사용 본 논문에서는 reward model 에 다음 loss function 을 사용한다. loss(θ)=−1(K2)E(x,yw,yl)∼D[log(σ (rθ (x,yw)−rθ(x,yl)))]\\textup{loss}(\\theta) = -\\frac{1}{\\binom{K}{2}}E_{(x,y_w,y_l) \\sim D}[log(\\sigma \\ (r_{\\theta} \\ (x, y_w) - r_{\\theta}(x, y_l)))]loss(θ)=−(2K​)1​E(x,yw​,yl​)∼D​[log(σ (rθ​ (x,yw​)−rθ​(x,yl​)))] rθ(x,y)r_\\theta(x, y)rθ​(x,y) 는 prompt xxx 에 대한 RM 의 scalar output, 파라미터 θ\\thetaθ 와 완성값 yyy ywy_wyw​ 는 ywy_wyw​ 와 yly_lyl​ 의 쌍 중에서 선호되는 완료값 DDD 는 사람이 비교한 데이터셋 RM loss 가 변하지 않아, bias 로 RM 을 normalization 한다. Reinforcement learning (RL) 과도한 optimization 을 막기 위해 SFT 모델로부터 토큰 당 KL 패널티를 추가 이 value function 은 RM 에서 초기화 된다. 이러한 모델을 PPO 라 칭한다. PPO 로 SFT 모델을 fine-tuning 한다. 공개 NLP 데이터셋에 성능 저하를 고치기 위해, PPO gradient 에 pretraining gradient 를 혼합한다. 이를 PPO-ptx 라 칭한다. RL learning 에 objective function 을 결합하여 maximize 한다. objective(ϕ)=E(x,y)∼DπϕRL[rθ(x,y)−βlog(πϕRL(y ∣ x)/πSFT(y ∣ x))]+γEx∼Dpretrain[log(πϕRL(x))]\\textup{objective}(\\phi) = E_{(x,y) \\sim D_{\\pi^{RL}_\\phi}}[r_\\theta(x,y) - \\beta log(\\pi^{RL}_\\phi(y\\ |\\ x) / \\pi^{SFT}(y \\ | \\ x))] + \\gamma E_{x \\sim D_{pretrain}}[log(\\pi^{RL}_\\phi (x))]objective(ϕ)=E(x,y)∼DπϕRL​​​[rθ​(x,y)−βlog(πϕRL​(y ∣ x)/πSFT(y ∣ x))]+γEx∼Dpretrain​​[log(πϕRL​(x))] πϕRL\\pi^{RL}_\\phiπϕRL​ 는 학습된 RL policy πSFT\\pi^{SFT}πSFT 는 supervised trained model DpretrainD_{pretrain}Dpretrain​ 는 pretraining distribution β\\betaβ 는 KL reward 계수, 0.02 γ\\gammaγ 는 pretraining loss 계수 PPO 에선 γ\\gammaγ 를 0, PPT-ptx 에선 γ\\gammaγ 를 27.8 본 논문에서 InstructGPT 는 PPO-ptx 모델을 선호 Baselines SFT 모델과 GPT-3 를 PPO 모델 성능을 비교 또한 InstructGPT 를 FLAN, TO 데이터셋에서 175B GPT-3 를 fine-tuning 한 것과 비교","s":"3.5 Models","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#35-models","p":984},{"i":1003,"t":"aligned 모델을 평가 하기 위해선 context 에서 alignment 의 의미가 무엇인지 명확할 필요가 있다. 하지만 alignment 의 정의는 역사적으로도 애매하고 혼란스러운 주제이기도 하다. 결국 목표는 유저의 의도에 따르는 행동을 하는 훈련 모델인 것이다. 이전에 연구된 논문에서는 모델이 helpful, honest, harmless 하다면 aligned 한 모델이라 정의한다. helpful 모델이 helpful 하기 위해선 지시를 잘 따르고 의도를 잘 추론해야만 한다. 라벨러의 판단에 전적으로 의존하고, 주요 기준은 라벨러의 선호도를 따른다. honest 모델이란 큰 black box 이기 때문에 진실에 대한 추론을 할 수 없다. 대신 다음 두 가지 기준으로 진실함을 측정한다. 폐쇠적인 도메인 작업에 대한 모델의 경향 평가 TruthfulQA 데이터셋 사용 harmless 라벨러가 Playground API 에서 수집된 정보에서 유해한 것인지 평가 또한 RealToxicityPrompt, CrowS-Paris 같은 bias 와 toxicity 를 측정하기 위한 데이터셋을 벤치마킹","s":"3.6 Evaluation","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#36-evaluation","p":984},{"i":1006,"t":"라벨러는 GPT-3 의 출력보다 InstructGPT 의 출력을 더 선호 훈련 데이터를 생성하지 않은 보류된 라벨러 의 선호도를 일반화 공개 NLP 데이터셋에는 InstructGPT 의 방식을 반영하지 않음","s":"4.1 Results on the API distribution","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#41-results-on-the-api-distribution","p":984},{"i":1008,"t":"InstructGPT 모델은 GPT-3 보다 진실함에서 개선됨 InstructGPT 모델은 GPT-3 보다 toxicity 는 조금 개선했으며, bias 에선 개선점이 없음 RLHF fine-tuning 을 개선하여 공개 NLP 데이터셋의 성능 저하를 최소화","s":"4.2 Results on public NLP datasets","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#42-results-on-public-nlp-datasets","p":984},{"i":1010,"t":"InstructGPT 는 RLHF fine-tuning 분포에서 벗어난 지시에 대해서도 일반화를 잘 함 위와 같이 InstructGPT 은 여전히 간단한 실수를 함 잘못된 전제를 가정하는 지시에 대해 혼동 질문에 대한 간단한 대답보다는 과도하게 얼버무림 지시에 여러 제약 조건이 있거나 언어 모델에 어려움이 있을 때 성능 저하를 일으킴","s":"4.3 Qualitative results","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#43-qualitative-results","p":984},{"i":1013,"t":"위의 접근법은 무엇에 work 하고 무엇을 하지 않을지의 feedback loop 이 실증적이란 것을 제공한다. 이 feedback loop 는 alignment 기술을 개선하기 위해 필수적이다. 이러한 alignment 기술인 RLHF 는 초인적인 시스템을 align 하기 위한 몇몇 제안에서 중요한 building block 이다. 이러한 작업들로, 저자는 더 일반적으로 align 연구를 끌어당길 수 있다고 한다. 모델 align 을 증가시키는 비용은 pretraining 보다 상대적으로 적다. 64.9 petaflops/s-days (175B SFT + 175B PPO-ptx) vs 3,640 petaflops/s-days (GPT-3) InstructGPT 에게 지도하지 않은 설정에도 지시를 잘 따라 일반화 fine-tuining 으로 인한 성능 저하 대부분을 완화","s":"5.1 Implications for alignment research","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#51-implications-for-alignment-research","p":984},{"i":1016,"t":"InstructGPT 의 행동은 계약자(라벨러)로부터 얻은 human feedback 에 의해 결정된다 → value judgment 는 라벨러의 성향, 신념, 개인의 살아온 역사 등에 의해 영향을 받는다는 한계 InstructGPT 는 완전히 aligned 이거나 완전히 안전하진 않음 → 분명한 prompt 가 없다면 여전히 toxic, violent, make up fact 를 생성함 InstructGPT 의 최대 한계는 실제 세계에 해롭더라도 유저의 지시에 따른다는 것이다 → 모델이 최대로 bias 되도록 지시하는 프롬프트에 대해, InstructGPT 는 동등한 크기의 GPT-3 보다 더 toxic 한 출력을 생성한다","s":"5.3 Limitations","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#53-limitations","p":984},{"i":1018,"t":"ChatGPT 는 InstructGPT 의 형제와 같은 모델로서, prompt 의 지시에 따라 자세한 응답을 제공하는 모델","s":"ChatGPT","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"","p":984},{"i":1020,"t":"InstructGPT 와 동일한 방법(SFT+RLHF)을 사용하면서도 데이터 수집에서 약간 다르다: InstructGPT dataset + new dialogue dataset (AI Trainer 가 AI 와 대화하며 출력을 수정)","s":"Method","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#method","p":984},{"i":1022,"t":"ChatGPT 는 그럴듯 하지만 부정확하거나 무의미한 답변 작성 RL 훈련 중 진실의 출처가 없음 더 신중하도록 훈련하면 올바르게 대답할 수 있는 질문도 거부 이상적인 답변은 모델이 아는 것에 따라 다르기 때문에 오도를 하기도 함 입력 문구를 수정 하거나 동일한 prompt 의 다중 시도에 민감 한 문구에 대해 모른다고 하거나 문구를 약간의 수정으로 올바르게 대답 가능 이상적인 모델은 모호한 쿼리에 대해 명확한 질문을 해야한다. 현재 모델은 의도를 추측 모델이 부적절한 요청에는 거부하도록 노력했지만 유해하거나 편향된 행동을 보임 지속적인 작업으로 Human Feedback 을 수집해야함","s":"Limitations","u":"/docs/Paper/NLP/Text Generation/InstructGPT","h":"#limitations","p":984},{"i":1024,"t":"You have just learned the basics of Docusaurus and made some changes to the initial template. Docusaurus has much more to offer! Have 5 more minutes? Take a look at versioning and i18n. Anything unclear or buggy in this tutorial? Please report it!","s":"Congratulations!","u":"/docs/tutorial-basics/congratulations","h":"","p":1023},{"i":1026,"t":"Read the official documentation Modify your site configuration with docusaurus.config.js Add navbar and footer items with themeConfig Add a custom Design and Layout Add a search bar Find inspirations in the Docusaurus showcase Get involved in the Docusaurus Community","s":"What's next?","u":"/docs/tutorial-basics/congratulations","h":"#whats-next","p":1023},{"i":1028,"t":"Docusaurus creates a page for each blog post, but also a blog index page, a tag system, an RSS feed...","s":"Create a Blog Post","u":"/docs/tutorial-basics/create-a-blog-post","h":"","p":1027},{"i":1030,"t":"Create a file at blog/2021-02-28-greetings.md: blog/2021-02-28-greetings.md --- slug: greetings title: Greetings! authors: - name: Joel Marcey title: Co-creator of Docusaurus 1 url: https://github.com/JoelMarcey image_url: https://github.com/JoelMarcey.png - name: Sébastien Lorber title: Docusaurus maintainer url: https://sebastienlorber.com image_url: https://github.com/slorber.png tags: [greetings] --- Congratulations, you have made your first post! Feel free to play around and edit this post as much you like. A new blog post is now available at http://localhost:3000/blog/greetings.","s":"Create your first Post","u":"/docs/tutorial-basics/create-a-blog-post","h":"#create-your-first-post","p":1027},{"i":1032,"t":"Documents are groups of pages connected through: a sidebar previous/next navigation versioning","s":"Create a Document","u":"/docs/tutorial-basics/create-a-document","h":"","p":1031},{"i":1034,"t":"Create a Markdown file at docs/hello.md: docs/hello.md # Hello This is my **first Docusaurus document**! A new document is now available at http://localhost:3000/docs/hello.","s":"Create your first Doc","u":"/docs/tutorial-basics/create-a-document","h":"#create-your-first-doc","p":1031},{"i":1036,"t":"Docusaurus automatically creates a sidebar from the docs folder. Add metadata to customize the sidebar label and position: docs/hello.md --- sidebar_label: 'Hi!' sidebar_position: 3 --- # Hello This is my **first Docusaurus document**! It is also possible to create your sidebar explicitly in sidebars.js: sidebars.js module.exports = { tutorialSidebar: [ 'intro', 'hello', { type: 'category', label: 'Tutorial', items: ['tutorial-basics/create-a-document'], }, ], };","s":"Configure the Sidebar","u":"/docs/tutorial-basics/create-a-document","h":"#configure-the-sidebar","p":1031},{"i":1038,"t":"Add Markdown or React files to src/pages to create a standalone page: src/pages/index.js → localhost:3000/ src/pages/foo.md → localhost:3000/foo src/pages/foo/bar.js → localhost:3000/foo/bar","s":"Create a Page","u":"/docs/tutorial-basics/create-a-page","h":"","p":1037},{"i":1040,"t":"Create a file at src/pages/my-react-page.js: src/pages/my-react-page.js import React from 'react'; import Layout from '@theme/Layout'; export default function MyReactPage() { return ( <Layout> <h1>My React page</h1> <p>This is a React page</p> </Layout> ); } A new page is now available at http://localhost:3000/my-react-page.","s":"Create your first React Page","u":"/docs/tutorial-basics/create-a-page","h":"#create-your-first-react-page","p":1037},{"i":1042,"t":"Create a file at src/pages/my-markdown-page.md: src/pages/my-markdown-page.md # My Markdown page This is a Markdown page A new page is now available at http://localhost:3000/my-markdown-page.","s":"Create your first Markdown Page","u":"/docs/tutorial-basics/create-a-page","h":"#create-your-first-markdown-page","p":1037},{"i":1044,"t":"Docusaurus is a static-site-generator (also called Jamstack). It builds your site as simple static HTML, JavaScript and CSS files.","s":"Deploy your site","u":"/docs/tutorial-basics/deploy-your-site","h":"","p":1043},{"i":1046,"t":"Build your site for production: npm run build The static files are generated in the build folder.","s":"Build your site","u":"/docs/tutorial-basics/deploy-your-site","h":"#build-your-site","p":1043},{"i":1047,"t":"Test your production build locally: npm run serve The build folder is now served at http://localhost:3000/. You can now deploy the build folder almost anywhere easily, for free or very small cost (read the Deployment Guide).","s":"Deploy your site","u":"/docs/tutorial-basics/deploy-your-site","h":"#deploy-your-site-1","p":1043},{"i":1049,"t":"Docusaurus supports Markdown and a few additional features.","s":"Markdown Features","u":"/docs/tutorial-basics/markdown-features","h":"","p":1048},{"i":1051,"t":"Markdown documents have metadata at the top called Front Matter: my-doc.md --- id: my-doc-id title: My document title description: My document description slug: /my-custom-url --- ## Markdown heading Markdown text with [links](./hello.md)","s":"Front Matter","u":"/docs/tutorial-basics/markdown-features","h":"#front-matter","p":1048},{"i":1053,"t":"Regular Markdown links are supported, using url paths or relative file paths. Let's see how to [Create a page](/create-a-page). Let's see how to [Create a page](./create-a-page.md). Result: Let's see how to Create a page.","s":"Links","u":"/docs/tutorial-basics/markdown-features","h":"#links","p":1048},{"i":1055,"t":"Regular Markdown images are supported. You can use absolute paths to reference images in the static directory (static/img/docusaurus.png): ![Docusaurus logo](/img/docusaurus.png) You can reference images relative to the current file as well. This is particularly useful to colocate images close to the Markdown files using them: ![Docusaurus logo](./img/docusaurus.png)","s":"Images","u":"/docs/tutorial-basics/markdown-features","h":"#images","p":1048},{"i":1057,"t":"Markdown code blocks are supported with Syntax highlighting. ```jsx title=\"src/components/HelloDocusaurus.js\" function HelloDocusaurus() { return ( <h1>Hello, Docusaurus!</h1> ) } ``` src/components/HelloDocusaurus.js function HelloDocusaurus() { return <h1>Hello, Docusaurus!</h1>; }","s":"Code Blocks","u":"/docs/tutorial-basics/markdown-features","h":"#code-blocks","p":1048},{"i":1059,"t":"Docusaurus has a special syntax to create admonitions and callouts: :::tip My tip Use this awesome feature option ::: :::danger Take care This action is dangerous ::: My tip Use this awesome feature option Take care This action is dangerous","s":"Admonitions","u":"/docs/tutorial-basics/markdown-features","h":"#admonitions","p":1048},{"i":1061,"t":"MDX can make your documentation more interactive and allows using any React components inside Markdown: export const Highlight = ({children, color}) => ( <span style={{ backgroundColor: color, borderRadius: '20px', color: '#fff', padding: '10px', cursor: 'pointer', }} onClick={() => { alert(`You clicked the color ${color} with label ${children}`) }}> {children} </span> ); This is <Highlight color=\"#25c2a0\">Docusaurus green</Highlight> ! This is <Highlight color=\"#1877F2\">Facebook blue</Highlight> ! This is Docusaurus green ! This is Facebook blue !","s":"MDX and React Components","u":"/docs/tutorial-basics/markdown-features","h":"#mdx-and-react-components","p":1048},{"i":1063,"t":"Docusaurus can manage multiple versions of your docs.","s":"Manage Docs Versions","u":"/docs/tutorial-extras/manage-docs-versions","h":"","p":1062},{"i":1065,"t":"Release a version 1.0 of your project: npm run docusaurus docs:version 1.0 The docs folder is copied into versioned_docs/version-1.0 and versions.json is created. Your docs now have 2 versions: 1.0 at http://localhost:3000/docs/ for the version 1.0 docs current at http://localhost:3000/docs/next/ for the upcoming, unreleased docs","s":"Create a docs version","u":"/docs/tutorial-extras/manage-docs-versions","h":"#create-a-docs-version","p":1062},{"i":1067,"t":"To navigate seamlessly across versions, add a version dropdown. Modify the docusaurus.config.js file: docusaurus.config.js module.exports = { themeConfig: { navbar: { items: [ { type: 'docsVersionDropdown', }, ], }, }, }; The docs version dropdown appears in your navbar:","s":"Add a Version Dropdown","u":"/docs/tutorial-extras/manage-docs-versions","h":"#add-a-version-dropdown","p":1062},{"i":1069,"t":"It is possible to edit versioned docs in their respective folder: versioned_docs/version-1.0/hello.md updates http://localhost:3000/docs/hello docs/hello.md updates http://localhost:3000/docs/next/hello","s":"Update an existing version","u":"/docs/tutorial-extras/manage-docs-versions","h":"#update-an-existing-version","p":1062},{"i":1071,"t":"Let's translate docs/intro.md to French.","s":"Translate your site","u":"/docs/tutorial-extras/translate-your-site","h":"","p":1070},{"i":1073,"t":"Modify docusaurus.config.js to add support for the fr locale: docusaurus.config.js module.exports = { i18n: { defaultLocale: 'en', locales: ['en', 'fr'], }, };","s":"Configure i18n","u":"/docs/tutorial-extras/translate-your-site","h":"#configure-i18n","p":1070},{"i":1075,"t":"Copy the docs/intro.md file to the i18n/fr folder: mkdir -p i18n/fr/docusaurus-plugin-content-docs/current/ cp docs/intro.md i18n/fr/docusaurus-plugin-content-docs/current/intro.md Translate i18n/fr/docusaurus-plugin-content-docs/current/intro.md in French.","s":"Translate a doc","u":"/docs/tutorial-extras/translate-your-site","h":"#translate-a-doc","p":1070},{"i":1077,"t":"Start your site on the French locale: npm run start -- --locale fr Your localized site is accessible at http://localhost:3000/fr/ and the Getting Started page is translated. caution In development, you can only use one locale at a same time.","s":"Start your localized site","u":"/docs/tutorial-extras/translate-your-site","h":"#start-your-localized-site","p":1070},{"i":1079,"t":"To navigate seamlessly across languages, add a locale dropdown. Modify the docusaurus.config.js file: docusaurus.config.js module.exports = { themeConfig: { navbar: { items: [ { type: 'localeDropdown', }, ], }, }, }; The locale dropdown now appears in your navbar:","s":"Add a Locale Dropdown","u":"/docs/tutorial-extras/translate-your-site","h":"#add-a-locale-dropdown","p":1070},{"i":1081,"t":"Build your site for a specific locale: npm run build -- --locale fr Or build your site to include all the locales at once: npm run build","s":"Build your localized site","u":"/docs/tutorial-extras/translate-your-site","h":"#build-your-localized-site","p":1070},{"i":1083,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.06674v1.pdf","s":"UNINEXT: Universal Instance Perception as Object Discovery and Retrieval","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1085,"t":"본 논문에서 universal instance perception model 에 대한 next generation 인 UNINEXT 를 제안한다. 기존의 모든 instance perception task 는 category names, language expressionbs, target annotations 와 같은 query 들로 객체를 찾는 것이 목표지만 이들은 모두 독립적인 하위 task 로 분할되어 있는데, 이를 범용적으로 인식할 수 있는 새로운 기술을 제안하는 바이다. 다양한 instance perception task 를 통합된 객체 탐지 및 retrieval paradigm 으로 재구성하고, input prompt 를 단순화하여 객체를 유연하게 인식한다. 이렇게 통합하여 다음 이점을 얻을 수 있다. 서로 다른 tasks 및 label vocabularies 에서 대량의 데이터를 공동으로 훈련하여 일반적인 instance-level 의 표현을 교육하는 데 매우 유용. 특히 훈련 데이터가 부족한 작업에 이점을 제공 통합 모델은 매개 변수 효율적이며, 여러 작업을 동시에 처리할 때 중복 계산을 줄일 수 있음 UNITEXT 는 고전적인 image-level task (object detection, instance segmentation), vision-language task (referring expression comprehension, segmentation) 및 6 개의 video-level object tracking task 를 포함하는 10 개의 instance-level task 로부터 총 20 개의 어려운 벤치마크에 대해 우수한 성능을 보여준다.","s":"Abstract","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1087,"t":"본 논문에서는 위의 정육면체 꼭짓점에 나타낸 10개의 sub-tasks 에 대해 논의한다. 가장 기본적인 task 인 object detection, instance segmentation 은 box 와 mask 로 특정 categories 의 모든 객체를 찾아야 한다. 정적 이미지를 동적 비디오로 입력을 확장할 경우, Multiple Object Tracking (MOT), Multi-Object Tracking and Segmentation (MOTS), Video Instance Segmentation (VIS) 는 비디오에서 특정 category 의 모든 객체 궤적을 찾아야 한다. 위와 같은 category names task 외의 몇몇 task 는 다른 참조 정보를 제공한다. Referring Expression Comprehension (REC), Referring Expression Segmentation (RES), Referring Video Object Segmentation (R-VOS) 는 \"왼쪽에서 네 번째 사람\" 과 같은 language expressions 과 일치하는 객체를 찾아야 한다. Single Object Tracking (SOT), Video Object Segmentation (VOS) 는 첫 번째 프레임에서 제공된 target annotations (box or mask) 을 참조하여 후속 프레임에서 객체의 궤적을 예측해야 한다. 위에서 언급한 모든 tasks 는 특정 속성의 instance 를 인지하려는 것이기 때문에, 이를 instance perception 이라 칭한다. 최근, 대부분의 instance perception 으로 sub-tasks 의 일부분 또는 하나에 대해서만 개발되며, 특정 domain 으로 분리하여 훈련되는데, 이는 다음과 같은 단점을 지닌다. 각 독립적인 설계는 서로 다른 task 및 domain 간의 knowledge 학습을 공유하는 것을 방해하며 중복 매개변수를 초래 서로 다른 task 간의 상호 기여의 가능성이 간과된다. 고정 크기의 classifier 로 제한된 전통적인 object detector 는 다양한 label vocabularies 가 있는 여러 데이터셋을 공동으로 훈련하는 것과 추론 중에 감지할 object categories 를 동적으로 변경하는 것은 어려움 따라서, 본질적으로는 모든 instance perception tasks 는 모든 queries 에 따라 특정 물체를 찾는 것을 목표로 한다. 이에 모든 주요 instance perception tasks 를 한 번에 해결할 수 있는 통합 모델을 설계할 수 있을까? 이 질문에 대한 대답으로 UNINEXT 를 제안 먼저 10 가지의 instance perception 인식 tasks 를 input prompt 에 따라 3 가지 유형으로 재구성 category names 의 prompt (Object Detection, Instance Segmentation, VIS, MOT, MOTS) language expressions 의 prompt (REC, RES, R-VOS) reference annotations 의 prompt (SOT, VOS) 그런 다음, 위 tasks 를 해결하기 위해 통합된 prompt-guieded 객체 발견과 retrieval formulation 를 제안 먼저, prompt 의 가이드 하에 N 개의 object proposals 를 발견 이후, instance-prompt 매칭 점수에 따른 proposals 로부터 최종 instance 를 찾음 위 새로운 formulation 을 기반으로, prompt 를 간단하게 바꿔서 다양한 instance 를 유연하게 찾을 수 있게 된다. 또한 다양한 prompt modalities 를 다루기 위해 다음을 제안 reference text encoder 와 reference visual encoder 로 구성된 prompt generation module 을 채택 early fusion module 을 현재 이미지의 원시 비주얼 특성과 prompt embedding 을 향상 시키기 위해 사용 위 작업으로 깊은 정보 교환이 가능하고 후속 instance 예측 단계에 대해 높은 구별력을 제공한다. 유연한 query-to-instance 방식을 고려하기 위해 다음을 제안 Transformer 기반의 object detector 를 instance decoder 로 선택 특히, 이 decoder 는 먼저 N 개의 instance proposals 를 생성 그후, prompt 를 사용하여 위의 instance proposals 로부터 매칭되는 object 를 찾는다. 이 검색 메커니즘은 전통적으로 사용하는, 고정된 크기의 classifier 를 극복하고 서로 다른 task 와 domain 의 데이터를 공동으로 훈련할 수 있다. 이러한 통합된 모델 아키텍처인 UNINEXT 는 다양한 task 의 대규모 데이터를 강력한 generic representations 를 학습하고 동일한 모델 파라미터로 10 가지의 instance-level perception tasks 를 해결할 수 있다. 실험 결과 20 가지의 벤치마크에서 우수한 결과에 달성했으며 이라한 기여를 다음과 같이 요약한다. universal instance perception 에 대해 통합된 prompt-guided formulation 을 제안하며, 분산된 instance-level 의 sub-tasks 를 하나로 통합 유연한 객체 발견과 검색 파라다임의 이점을 살린 UNINEXT 는 특정 task 헤드가 필요하지 않으므로 서로 다른 tasks 와 domains 를 훈련할 수 있다. 동일한 model parameter 로 10 가지의 instance perception tasks 의 20 가지 벤치마크에 대해 우수한 결과 달성","s":"1. Introduction","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1090,"t":"introduction 에서 언급한 것과 같이, instance perception tasks 를 3 가지의 class 로 분류한다. Object detection, instance segmentation, MOT, MOTS 및 VIS 는 category names 를 prompt 로 사용하여 특정 class 의 모든 instance 를 찾는다. REC, RES 및 R-VOS 는 expression 을 prompt 로 이용하여 특정 타깃을 localizing 한다. SOT 와 VOS 는 첫 프레임에 주어진 annotation 을 prompt 로 사용하여 추적하는 타깃의 궤적을 예측한다. 위 tasks 는 prompt 로 특정 객체를 찾는 것을 목표로 한다. 그리고 이 방법은 모든 instance perception tasks 를 prompt-guided 객체 발견과 retrieval problem 으로 재구성하는 동기를 주며 통합 모델 아키텍처와 학습 파라다임으로 해결한다. 다음 그림으로 입증할 수 있다. UNINEXT 는 다음 세 가지의 주요 컴포넌트를 포함한다. prompt generation image-prompt feature fusion object discovery and retrieval","s":"3. Approch","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1092,"t":"먼저, prompt generation modile 은 원본의 다양한 prompt 입력을 통합된 형태로 변환하기 위해 채택됐다. 다음 두 단락에서 각각의 modalities 에 대한 대응 전략을 소개한다. 언어관련 prompt 를 처리하기 위해 language encoder 인 EncL\\textup{Enc}_LEncL​ 를 채택한다. 구체적으로 category-guided tasks 에 대해, 현재 데이터셋에서 나타난 class names 를 언어 표현으로 연결한다. COCO 를 예로, 표현식을 \"person. bicyle, .. , toothbrush\" 와 같이 작성될 수 있다. 이후 category-guided 및 expression-guided tasks 등의 언어 표현식은 EncL\\textup{Enc}_LEncL​ 에 전달되어, 시퀀스 일이 LLL 인 prompt embedding Fp∈RL×dF_p \\in \\mathbb{R}^{L \\times d}Fp​∈RL×d 가 생성된다. annotation-guided tasks 에 대해선, fine-grained visual 특징을 추출하고 target annotations 를 완전히 활용하기 위해, 추가적인 reference visual encoder 인 EncVref\\textup{Enc}_{\\textup{V}}^{\\textup{ref}}EncVref​ 를 도입한다. 구체적으로, 참조하는 프레임에서의 타깃 위치 중심으로 맞춰진 222^222 배의 타깃 박스 영역 템플릿을 자른다. 이후, 이 템플릿을 256×256256 \\times 256256×256 의 고정된 사이즈로 조정한다. 더 정확한 정보를 도입하기 위해, target prior 이라는 추가된 channel 은 템플릿 이미지에 연결되어 4-channel 입력을 형성한다. 자세히 말해, target prior 의 값 target region 에서는 1 이고, 그 외에는 0 이다. 이후, target prior 과 함께한 이 템플릿 이미지는 reference visual encoder EncVref\\textup{Enc}_{\\textup{V}}^{\\textup{ref}}EncVref​ 에 전달되어, {C3,C4,C5,C6}\\{ C_3, C_4, C_5, C_6 \\}{C3​,C4​,C5​,C6​} hierarchical feature pyramid 를 얻는다. 각 구역의 사이즈는 32×3232 \\times 3232×32, 16×1616 \\times 1616×16, 8×88 \\times 88×8, 4×44 \\times 44×4 이다. 타깃 정보를 유지하고 다른 작업과 동일한 형식의 prompt embedding 을 얻기 위해 병합된 모듈이 적용된다. 다시말해, 피처의 모든 level 는 먼저 32×3232 \\times 3232×32 으로 다운샘플링을 한 후에 추가되며, 최종적으로는 Fp∈R1024×dF_p \\in \\mathbb{R}^{1024 \\times d}Fp​∈R1024×d 의 prompt embedding 으로 flatten 된다. Fine-Grained & Coarse-Grained Fine-Grained 하나의 작업을 작은 단위의 프로세스로 나눈 뒤, 다수의 호출을 통해, 작업 결과를 생성해내는 방식 예를 들어, Do() 라는 함수가 있다면 해당 함수를 First_Do(), Second_Do() 로 나누어 작업 결과를 생성해내는 방식 따라서, 다양한 \"Flexible System\" 상에서 유용하게 쓰일 수 있음 Coarse-Grained 하나의 작업을 큰 단위의 프로세스로 나눈 뒤, \"Single Call\" 을 통해, 작업 결과를 생성해내는 방식 예를 들어, Do() 라는 함수가 있다면 단순히, Do() 를 호출해 작업 결과를 생성해내는 방식 따라서, \"Distributed System\" 상에서 유용하게 쓰일 수 있음 위의 prompt 생성 과정은 다음과 같은 공식으로 나타낼 수 있다. Fp={EncLrefexpression-guiededEncLrefcategory-guiededmerge(EncVref[template, prior])annotation-guiededF_p = \\left \\{ \\begin{array}{ll} \\textup{Enc}_L^{\\textup{ref}} & \\textup{expression-guieded} \\\\ \\textup{Enc}_L^{\\textup{ref}} & \\textup{category-guieded} \\\\ \\textup{merge}( \\textup{Enc}_\\textup{V}^{\\textup{ref}}[ \\textup{template, prior} ]) & \\textup{annotation-guieded} \\end{array} \\right.Fp​=⎩⎨⎧​EncLref​EncLref​merge(EncVref​[template, prior])​expression-guiededcategory-guiededannotation-guieded​","s":"3.1 Prompt Generation","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#31-prompt-generation","p":1082},{"i":1094,"t":"prompt 생성과 병렬로, 현재의 이미지 전체는 다른 visual encoder EncV\\textup{Enc}_{\\textup{V}}EncV​ 로 전달되어, hierarchical visual features FvF_vFv​ 를 얻는다. image contexts 로 원본 prompt embedding 을 강화시키고 원본 visual features 를 prompt-aware 하게 만들기 위해서, early fusion module 를 채택한다. 구체적으로, 다양한 입력의 정보를 찾기위해 bi-directional cross-attention module (Bi-XAtt) 를 사용한다. 이후, retrieved representations 를 원본 features 에 추가한다. 위의 prompt 생성 과정은 다음과 같은 공식으로 나타낼 수 있다. Fp2v,Fv2p=Bi-XAtt(Fv,Fp)Fv′=Fv+Fp2v; Fp′=Fp+Fv2p(1)\\left. \\begin{array}{ll} F_{p2v}, F_{v2p} = \\textup{Bi-XAtt}(F_v, F_p) \\\\ F'_v = F_v + F_{p2v}; \\ F'_p = F_p + F_{v2p} \\\\ \\end{array} \\right. (1)Fp2v​,Fv2p​=Bi-XAtt(Fv​,Fp​)Fv′​=Fv​+Fp2v​; Fp′​=Fp​+Fv2p​​(1) feature 향상을 위해 6 개의 vision-language fusion layer 와 6 개의 추가 BERT layer 를 채택하는 GLIP 과 달리, early fusion module 은 훨씬 더 효율적이다.","s":"3.2 Image-Prompt Feature Fusion","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#32-image-prompt-feature-fusion","p":1082},{"i":1096,"t":"판별적인 visual 과 prompt representations 과 함께, 다음 중요한 단계는 다양한 인식 tasks 에 대해 input features 를 instance 로 변환하는 것이다. UNINEXT 는 Deformable DETR 에서 제안된 encoder-decoder 아키텍처를 채택하여 유연한 query-instance 형식을 사용한다. Transformer encoder 는 hierarchical prompt-aware viusal feature 를 input 으로 사용한다. 효율적인 Multi-scale Deformable Self-Attention 의 도움으로, 서로 다른 스케일의 타깃 정보를 교환할 수 있으며, 후속 instance decoding 에 대한 강력한 instance feature 를 제공해준다. 또한, Deformable DETR 의 두 단계에서 수행처럼, auxiliary prediction head 는 encoder 의 끝에 추가되어, 가장 높은 점수를 가진 NNN 개의 초기화된 reference points 를 생성하여 decoder 의 input 으로 사용한다. Transformer decoder 는 향상된 multi-scale features 인, encoder 의 N 개의 reference points 와 N 개의 object queries 를 input 으로 사용한다. 이전 연구처럼, object queries 는 instance perception tasks 에서 중요한 역할을 한다. 본 연구는 두 가지의 query 생성 전략을 시도한다. 이미지 또는 프롬프트에 상관없이 변하지 않는 static queries nn.Embedding(N, d) 로 쉽게 구현 가능 프롬프트에 의존적인 dynamic queries 먼저 향상된 prompt features Fv′F'_vFv′​ 를 pooling 하여 global representation 을 얻은 다음, NNN 번 반복하여 수행할 수 있음 위 두 방법으로 정적 쿼리가 동적 쿼리보다더 나은 성능을 발휘 한다는 것을 발견했다. 이유는 정적 쿼리가 동적 쿼리보다 더 많은 정보를 포함하고 더 나은 훈련 안정성을 진행하기 때문이다. deformable attention 의 도움으로, object queries 는 효율적으로 prompt visual features 를 찾으며, 강력한 instance embedding Fins∈RN×dF_{ins} \\in \\mathbb{R}^{N \\times d}Fins​∈RN×d 를 학습할 수 있다. decoder 의 끝 부분에서는 최종적인 instance predictions 을 얻기 위해 prediction heads 그룹을 활용한다. 구체적으로, instance head 는 타깃의 boxes 와 masks 를 생성한다. 또한, embedding head 는 현재 감지된 결과와 MOT, MOTS 및 VIS 의 이전 궤적과 연관시키기 위해 도입된다. 지금까지, 위 그림에서 회색 마스크로 나타낸 NNN 개의 잠재적인 instance proposals 를 채굴했지만, 모든 proposals 는 prompt 가 실제로 참조하는 타깃을 나타내는 것은 아니었다. 따라서, 그림의 오른쪽처럼 prompt embedding 에 따라 이러한 proposals 로부터 실제로 일치되는 타깃을 더 검색해야 한다. 구체적으로, early fusion 후의 prompt embedding Fp′F'_pFp′​ 가 주어지면, category-guided tasks 를 위해 각 category name 의 embedding 을 weight matrix W∈R1×dW \\in \\mathbb{R}^{1 \\times d}W∈R1×d 로 사용한다. 또한, expression-guided 와 annotation-guided tasks 를 위해 weight matrix WWW 는 sequence 차원을 따라 global average pooling (GAP) 를 사용하여 prompt embedding Fp′F'_pFp′​ 를 집계하여 얻는다. W={Fp′[i], i∈{0,1,...,C−1}category1L∑i=0LFp′(i,j)expression/annotationW = \\left \\{ \\begin{array}{ll} F'_p[i], \\ i \\in \\{0, 1, ..., C - 1\\} & \\textup{category} \\\\ \\\\ \\frac{1}{L} \\sum_{i=0}^{L} F'_p (i, j) & \\textup{expression/annotation} \\end{array} \\right.W=⎩⎨⎧​Fp′​[i], i∈{0,1,...,C−1}L1​∑i=0L​Fp′​(i,j)​categoryexpression/annotation​ 마지막으로, instance-prompt 매칭 점수 SSS 는 타깃 features 과 전치된 가중치 행렬의 행렬 곱으로 계산할 수 있으며 식으로 S=FinsWTS = F_{ \\textup{ins}}W^TS=Fins​WT 로 나타낸다. 이전 연구에 따르면, 매칭 스코어는 Focal Loss 로 supervise 될 수 있다. 이전의 고정된 크기의 classifiers 와 달리, proposed retrieval head 는 prompt-instance 매칭 메커니즘으로 객체를 선택한다. 이 유연한 설계는 서로 다른 tasks 의 다양한 label vocabularies 을 가진 거대한 데이터셋을 공동으로 학습하여, UNEXT 를 가능케 한다.","s":"3.3 Object Discovery and Retrieval","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#33-object-discovery-and-retrieval","p":1082},{"i":1099,"t":"전체 훈련 프로세스는 세 단계를 포함한다. general perception pretraining UNINEXT 를 객체에 대한 범용적인 지식을 학습시키기 위해 object detection 데이터셋인 Object365 로 pretrain Object365 는 mask annotations 가 없기 때문에, mask brach 를 훈련하기 위해, BoxInst 에서 제안한 auxiliary losses 를 도입한다. 이 loss function 은 다음과 같다. Lstage1=Lretrieve+Lbox+Lmaskboxinst(2)L_{\\textup{stage1}} = L_{\\textup{retrieve}} + L_{\\textup{box}} + L_{\\textup{mask}}^{\\textup{boxinst}} \\qquad (2)Lstage1​=Lretrieve​+Lbox​+Lmaskboxinst​(2) image-level joint training 1 단계의 pretrained weight 를 토대로, image datasets 를 공동적으로 UNINEXT 에 finetuning 한다. 주로 COCO 와 RefCOCO, RefCOCO+ 및 RefCOCOg 를 섞은 데이터셋이다. 수동으로 라벨링된 mask annotations 을 사용하면, Dice Loss 및 Focus Loss 와 같은 전통적인 loss function 을 mask 학습에 사용될 수 있다. 이 스텝을 지나면, UNINEXT 는 object detection, instance segmentation, REC 및 RES 에 우수한 성능을 낼 수 있다. Lstage2=Lretrieve+Lbox+Lmask(3)L_{\\textup{stage2}} = L_{\\textup{retrieve}} + L_{\\textup{box}} + L_{\\textup{mask}} \\qquad (3)Lstage2​=Lretrieve​+Lbox​+Lmask​(3) video-level joint training 다양한 downstream object tracking tasks 와 벤치마크를 위해 video-level 데이터셋에 UNINEXT 를 finetuning 한다. 원본 비디오에서 무작위로 선택된 두 프레임을 학습한다. image-level tasks 에서 학습된 지식을 잊는 것을 방지하기 위해, image-level 데이터셋을 가짜 비디오로 변환하여 공동으로 학습 가짜 영상은 COCO, RefCOCO/g/+, SOT&VOS (GOT-10K, LaSOT, TrackingNet 및 Youtube-VOS), MOS&VIS (BDD10K, VIS19, OVIS) 및 R-VOS (Ref-Youtuve-VOS) 를 포함한다 SOT&VOS 에 대한 reference visual encoder 와 연관성에 대한 추가적인 embedding head 도 도입되어 최적화한다. Lstage3=Lretrieve+Lbox+Lmask+Lembed(4)L_{\\textup{stage3}} = L_{\\textup{retrieve}} + L_{\\textup{box}} + L_{\\textup{mask}} + L_{\\textup{embed}} \\qquad (4)Lstage3​=Lretrieve​+Lbox​+Lmask​+Lembed​(4)","s":"Training","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#training","p":1082},{"i":1101,"t":"category-guided tasks 에 대해, UNINEXT 는 서로다른 categories 의 instance 를 예측하고 이전 궤적과 연관시킨다. 이 연관성 짓는 과정은 온라인 방식으로 이루어지며, 이전 연구처럼 학습된 instance embedding 만을 기반으로 한다. expression-guided 와 annotation-guided 에 대해, 주어진 prompt 와 가장 높은 매칭 점수를 가진 객체를 최종 결과물로 선택한다. 오프라인 방식과 복잡한 후처리 과정에 의해 제한되는 이전 연구와 달리, 이 방법은 간단하고, 온라인 방식이며, 후처리가 필요하지 않다.","s":"Inference","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#inference","p":1082},{"i":1104,"t":"본 저자는 세 가지의 백본 모델 ResNet-50, ConvNeXt-Large 및 ViT-Huge 를 visual encoder 로 시도한다. 또한 BERT 를 text encoder 로 채택하고 파라미터는 1, 2 번째 훈련 단계에서 훈련되며, 마지막 훈련 단계에서 동결 시킨다. Transformer encoder-decoder 아키텍처는 DETR 연구에 따라 6 encoder layer 와 6 decoder layer 를 사용한다. object queries 수 NNN 은 900 optimizer, AdamW, 0.05 weight decay Object365 pretraining 에 대해 32, 16 A 100 GPUs 사용","s":"4.1 Implementation Details","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#41-implementation-details","p":1082},{"i":1107,"t":"UNINEXT 를 COCO val2017 (5k images) 및 test-dev split (20k images) 에서 SOTA object detection 과 instance segmentation AP 점수 비교","s":"Object Detection and Instance Segmentation","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#object-detection-and-instance-segmentation","p":1082},{"i":1109,"t":"REC 및 RES 를 RefCOCO, RefCOCO+ 및 RefCOCOg 로 평가한다. REC 및 RES 평가지표는 Precision@0.5 와 Overall IoU (oIoU) 를 채택했다.","s":"REC and RES","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#rec-and-res","p":1082},{"i":1111,"t":"네 개의 large-scale 벤치마크: LaSOT, LaSOT-ext, TrackingNet 및 TNL-2K 로 SOTA 와 SOT 를 비교했다. 이 벤치마크들은 success curve (AUC), normalized precision (PNormP_{Norm}PNorm​) 및 precision (P) 로 평가했으며, 각각 280, 150, 511 및 700 개의 테스트 셋 비디오를 포함한다.","s":"SOT","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#sot","p":1082},{"i":1113,"t":"VOS 는 DAVIS-2017 및 Youtube-VOS 2018 데이터셋으로 평가한다. DAVIS-2017 은 region similarity J\\mathcal{J}J, contour accuracy F\\mathcal{F}F, averaged score J&F\\mathcal{J} \\& \\mathcal{F}J&F 로 나타낸다. Youtube-VOS 2018 은 J\\mathcal{J}J 와 F\\mathcal{F}F 를 seen 및 unseen categories 로, averaged overall score 는 G\\mathcal{G}G 로 나타낸다.","s":"VOS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#vos","p":1082},{"i":1115,"t":"MOT 에서 자율운전 중 8 개의 class instance 를 추척을 요구하는 BBD100K 에서 SOTA 와 UNINEXT 를 비교한다. 전통적인 평가지표 Multiple-Object Tracking Accuracy (MOTA), Identity F1 Score (IDF1) 및 Identity Switches (IDS) 를 제외하고도, 추가로 도입된 mMOTA 및 mIDF1 로도 성능 평가를 했다.","s":"MOT","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#mot","p":1082},{"i":1117,"t":"MOT 와 비슷하게, BDD100K MOTS 첼린지에서 mMOTSA, mMOTSP, mIDF1 및 ID Sw 로 multi-class 추적을 평가한다.","s":"MOTS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#mots","p":1082},{"i":1119,"t":"Youtube-VIS 와 OVIS 검증셋에서 SOTA 와 UNINEXT 를 비교한다. 특히 위 검증셋은 각각 40 및 25 object categories 와 302 및 140 개 비디오 검증셋을 포함한다. 각 벤치마크에 대해 AP 로 평가한다.","s":"VIS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#vis","p":1082},{"i":1121,"t":"Ref-Youtube-VOS 와 Ref-DAVIS17 은 R-VOS 분야에서 인기 있는 데이터셋으로, object 에 대해 언어표현을 도입한다. VOS 와 비슷하게 region similarity J\\mathcal{J}J, contour accuracy F\\mathcal{F}F, averaged score J&F\\mathcal{J} \\& \\mathcal{F}J&F 를 평가지표로 채택한다.","s":"R-VOS","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#r-vos","p":1082},{"i":1123,"t":"모든 모델에 ResNet-50 백본을 사용하여 다섯 가지 벤치마크 (COCO, RefCOCO, Youtube-VOS, Ref-Youtube-VOS 및 Youtube-VIS 2019) 에 대해 평가를 진행한다.","s":"4.3 Ablations and Other Analysis","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#43-ablations-and-other-analysis","p":1082},{"i":1125,"t":"visual features 와 prompt embedding 사이의 fusion 에 대한 영향력을 연구하기 위해, early fusion 없이 구현을 해보았다. 실험 결과 Early fusion 없으면 성능 저하가 일어났는데 다음 주요 세 가지 이유가 있다. prompt embedding 의 지도가 없는 네트워크는 나무나 싱크대 같은 희귀한 타깃을 찾기가 힘들다. early fusion 없는 네트워크는 첫 번째 프레임에서 fine mask annotation 을 완전히 활용할 수 없어 mask 품질이 저하된다. 또한 feature fusion 을 제거하니 성능 저하가 일어났다. feature fusion 은 object detection 및 VIS 에 최소한의 영향을 미치는데, prompt 에서 참조하는 특정 타깃 하나를 찾는 것이 아니라 가능한 모든 object 를 찾는 것을 목표로 하기 때문으로 이해할 수 있다.","s":"Fusion","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#fusion","p":1082},{"i":1127,"t":"본 저자는 두 가지의 query generation 전략을 비교한다. static queries nn.Embedding(N, d) 로 간단히 구현 가능 VIS task 에서 2.8 AP 로 dynamic queries 전략보다 더 좋은 성능을 냄 잠재적인 이유는 N 개의 다른 object queries 가 단순히 N 번의 query 로 pool 된 prompt 를 복사하는 것보다 서로 다른 타깃간의 풍부한 관계로 인코딩할 수 있기 때문 dynamic queries prompt embedding 에 의존 처음의 4 가지 tasks 에 대해선 static queries 보다 성능이 약간 좋았다.","s":"Queries","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#queries","p":1082},{"i":1129,"t":"모든 tasks (10 tasks) 를 통합한 모델과 5 가지 tasks 를 통합한 mutliple tasks 모델을 비교하였다. 통합 모델은 5 tasks-specific 모델보다 성능이 약간 더 좋았다. 최종적으로는 통합 모델이 많은 파라미터를 아끼고, 파라미터에 더 효율적이었다.","s":"Unification","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"#unification","p":1082},{"i":1131,"t":"UNINEXT 는 prompt-guided 객체 발견과 검색 파라다임으로 10 가지 instance perception tasks 를 통합했다. UNINEXT 는 동일한 모델 파라미터로 단일 모델 만으로 20 가지의 벤치마크에서 우수한 성능에 도달했다.","s":"5. Conclusions","u":"/docs/Paper/Computer Vision/Multi-task/UNINEXT","h":"","p":1082},{"i":1133,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2303.10512.pdf","s":"Adaptive Budget Allocation For Parameter-Efficient Fine-Tuning","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1135,"t":"large pre-trained language models (PLMs) 을 downstream tasks 에 fine-tuning 하는 것은 NLP 의 주요 패러다임 보통 pre-trained model 의 all parameter 를 fine-tuning 하는데, 이는 downstream tasks 이 많으면 비효율적이다. 많은 fine-tuning 방법이 제안되었으며, all pre-trained weights 의 incremental update 로 학습하는 효율적인 방법을 찾는데 사용 이 방법들은 종종 all pre-trained weight matrices 에 대한 incremental updates budget 을 균등하게 분배하며, 다른 weight parameter 의 중요성을 간과함 결과적으로 fine-tuning 성능은 sub-optimal 위 사항을 극복하기 위해 저자는 AdaLoRA 제안 weight matrices 의 importance score 에 따라 parameter budget 을 adaptively allocate AdaLoRA 는 singular value decomposition (SVD) 형식으로 incremental updates 를 parameterize 위 nodel approach 는 unimportant update 의 singular value 를 효과적으로 제거 근본적으로 parameter budget 을 줄이는 것이지만 고사양의 SVD computations 를 피하는 것이다. 저자는 natural language processing, question answering 및 natural language generation 에 여러 pre-trained model 을 광범위하게 실험하여 AdaLoRA 의 효과를 검증 결과 AdaLoRA 는 baseline 대비 획기적으로 개선하며, 특히 low budget setting 에서 높은 효과를 나타냈다.","s":"Abstract","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1137,"t":"fine-tuned PLMs 는 다양한 NLP 에 우수한 성능을 보여주지만 큰 메모리 공간을 필요로 한다. BERT 는 300M, T5 는 11B, GPT-3 175B 등 매우 큰 parameter 로 이루어져 있다. 이러한 PLMs 로 NLP 시스템을 구축할 때, 일반적으로 multiple tasks 를 동시에 다루어야 하는데, 다수의 downstream tasks 가 있을 경우, full fine-tuning 은 각 task 에 별도의 LM copy 를 유지해야하므로 메모리 소비가 과도하게 비싸진다. 이를 해결하기 위해 PLM 의 fine-tuning parameter 수를 줄이며 성능을 유지/향상 시키기 위한 두 가지 주요 연구 방향이 제시됐다. PLM 에 small neural modules 를 추가하고 각 task 에 대한 이 modules 만 fine-tuning base model 은 freezing 하고 tasks 간에 공유 적은 수의 task-specifc parameter 만 도압되고 업데이트되므로 large model 의 실용성 향상 예로, adapter tuning 은 base model 사이에 adapters 라는 small neural modules 삽입 prefix-tuning 및 prompt tuning 은 base model 의 input 또는 hidden layer 에 additional trainable prefix tokens 부착 위 방법들은 full fine-tuning 과 comparable 한 성능 달성하며 parameter 의 1% 미만을 업데이트하기 때문에 메모리 소비도 줄인다. model architecture 수정 없이, pre-trained weight 의 incremental update 를 parameter-efficient 방법으로 모델링 예로, Given pre-trained weight matrix W(0)W^{(0)}W(0) diff pruning 은 incremental update △\\triangle△ 를 sparse matrix 로 모델링 Diff pruning 은 △\\triangle△ 를 W(0)W^{(0)}W(0) 와 same dimension 으로 초기화하고 entry 규모에 기반하여 △\\triangle△ 를 element-wise 제거 diff pruning 은 important updates 를 adaptively retaining 및 unimportant 것은 제거하여 parameter-efficient 효율성 크게 높임 하지만 diff pruning 에는 여러 제한 사항 존재 unstructured sparse matrices 의 computation 을 가속화하기 위해 low-level implementation 에 의존하며, 이는 deep learning 에서 제대로 지원하지 않음 따라서 training 중 △\\triangle△ 를 dense matrix 에 저장해야 함 △\\triangle△ 의 각 entry 를 해당 gradient 로 업데이트하고 제거해야함 이로 인해 full fine-tuning 과 유사한 계산 비용 발생 위 단점을 극복하기 위해, LoRA 라는 메소드도 제안되었으며, 이는 △\\triangle△ 를 두 개의 smaller matrices 의 곱으로 low-rank matrix 로 parameterize W=W(0)+△=W(0)+BA,\\begin{equation} W = W^{(0)} + \\triangle = W^{(0)} + BA, \\end{equation}W=W(0)+△=W(0)+BA,​​ W(0)W^{(0)}W(0), △∈Rd1×d2\\triangle \\in \\mathbb{R}^{d_1 \\times d_2}△∈Rd1​×d2​, A∈Rr×d2A \\in \\mathbb{R}^{r \\times d_2}A∈Rr×d2​, B∈Rd1×rB \\in \\mathbb{R}^{d_1 \\times r}B∈Rd1​×r, r≪{d1,d2}r \\ll \\{ d_1, d_2 \\}r≪{d1​,d2​} fine-tuning 중, AAA, BBB 만 업데이트 rank rrr 은 dimension WWW 보다 작게 선택 (e.g. d1=d2=1024d_1 = d_2 = 1024d1​=d2​=1024 일 때 r=8r = 8r=8) additional trainable parameter 가 0.5% 미만인 상황에서, training overhead 를 full fine-tuning 대비 최대 70% 까지 줄임 LoRA 는 full fine-tuning 과 유사하거나 더 나은 성능 달성 한편, 두 small matrices 의 곱셈은 diff pruning 의 unstructured sparse matrices 보다 implement 및 deploy 가 더 쉬움 LoRA 는 여전히 제한 사항 존재 각 incremental matrix △\\triangle△ 의 rank rrr 을 동일하게 미리 지정 pre-trained models 를 fine-tuning 할 때 weight matrices 의 중요성이 modules 및 layers 간에 크게 다르다는 사실을 무시 이를 설명하기 위해 Fig. 1 에 구체적으로 제시 동일한 trainable parameter 수로 specific modules 또는 layers 를 fine-tuning 할 때 LoRA 의 성능 비교 Fig. 1a 에선 feed-forward networks (FFN) 를 fine-tuning 하면 self-attention modules 보다 더 나은 성능 달성 Fig. 1b 에선 top layers 의 weight matrices 가 bottom layers 보다 더 중요하단 것 보여줌 주요 weight matrices 에 더 맘ㄶ은 trainable parameter 를 추가하면 model performance 향상 가능. 반면, less important weight matrices 를 추가하면 향상되지 않거나 저해 가능 parameter budget, i.e. total trainable parameters 가 주어진 경우, 항상 important modules 에 더 많은 parameter 를 할당하는 것이 좋다. budget 을 모든 weight matrices/layers 에 고르게 분배하는 LoRA 및 다른 방법(e.g. adapter/prefix tuning)은 부적절한 성능을 낼 수 있음 위 사항으로 다음 질문 제기 importance modules 에 따라 parameter budget 을 adaptively 할당하여 PEFT 성능을 향상시키는 방법은 뭘까? 위 질문을 위해 새로운 방법 AdaLoRA (Adaptive Low-Rank Adaptation) 제안 LoRA-alike fine-tuning 동안 weight matrices 사이에서 parameter budget 을 동적으로 할당 구체적으로, AdaLoRA 는 incremental matrices 의 rank 를 조절하여 budget 을 제어한다. Critical incremental matrices 에는 high rank 가 할당되어 fine-grained 및 task-specific information 을 더 capture 가능 Less inportance ones 는 overfitting 을 방지하고 computational budget 절약을 위해 lower rank 로 제거 matrices approximation 의 기존 연구에서 matrices rank 를 제어하는 여러 방법이 있다. 대부분은 matrix 의 SVD 를 직접 계산한 다음 smallest singular value 를 truncate 이런 작업은 rank 를 명시적으로 조작할 수 있으며, resulting matrix 와 original matrix 간의 차이를 최소화한다. 하지만 fine-tuning large models 에서는 high-dimensional weight matrices 에 대한 SVD 를 반복적으로 적용하기엔 비용이 크므로 SVD 를 정확하게 계산하는 대신 △\\triangle△ 를 △=PΛQ\\triangle = P \\Lambda Q△=PΛQ 로 모델링하여 SVD 를 모방한다. diagonal matrix Λ\\LambdaΛ 에는 singular values 가 포함되어 있으며 orthogonal matrices PPP 및 QQQ 는 △\\triangle△ 의 left/right singular vectors 를 나타냄 PPP 와 QQQ 의 orthogonality 를 regularizing 하기 위해 training loss 에 additional penalty 를 추가 이러한 parameterization 은 SVD 의 intensive computations 을 피한다. unimportant singluar values 만 drop 하면서 singular vectors 는 유지 저자는 AdaLoRA 효과 입증을 위해 다양한 task 및 models 에 포괄적 실험 NLU (GLUE) 및 QA (SQuADv1, SQuADv2) dataset 에서 DeBERTaV3-base 성능 평가 BART-large 에 저자의 approach 를 적용하고 NLG (XSum 및 CNN/DailyMail) task 에서의 성능 평가 AdaLoRA 가 low budget setting 에서 우수한 성과 full fine-tuning 의 0.1% 미만의 trainable parameter 로 SQuAD2.0 dataset 에서 SOTA approach 와 비교하여 1.2% F1 개선","s":"1. Introduction","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1140,"t":"전형적인 Transformer model 은 LLL stacked blocks 로 이루어져 있다. 각 블록은 two submodules 를 포함한다 multi-head attention (MHA) 및 full connected FFN Given input sequence X∈Rn×dX \\in \\mathbb{R}^{n \\times d}X∈Rn×d, MHA 는 병렬로 hhh head 에서 attention function 을 수행 MHA(X)=Concat(head1,…,headh)Wo,head)i=Softmax(XWqi(XWki)⊤/dn)XWvi,\\text{MHA} (X) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h)W_o, \\quad \\text{head})i = \\text{Softmax}(XW_{qi}(XW_{ki})^\\top / \\sqrt{d_n})XW_{vi,}MHA(X)=Concat(head1​,…,headh​)Wo​,head)i=Softmax(XWqi​(XWki​)⊤/dn​​)XWvi,​ Wo∈Rd×dW_o \\in \\mathbb{R}^{d \\times d}Wo​∈Rd×d : output projection Wqi,Wki,Wvi∈Rd×dhW_{qi}, W_{ki}, W_{vi} \\in \\mathbb{R}^{d \\times d_h}Wqi​,Wki​,Wvi​∈Rd×dh​ : query, key 및 value projection of head iii dhd_hdh​ : 일반적으로 d/hd/hd/h set 다른 important module 인 FFN 은 two linear transformations 와 그 사이에 ReLU activation 을 포함 FFN(X)=ReLU(XWfi+b1)Wf2+b2\\text{FFN}(X) = \\text{ReLU}(XW_{fi} + b_1)W_{f2} + b_2FFN(X)=ReLU(XWfi​+b1​)Wf2​+b2​ Wf1∈Rd×dmW_{f1} \\in \\mathbb{R}^{d \\times d_m}Wf1​∈Rd×dm​ Wf2∈Rdm×dW_{f2} \\in \\mathbb{R}^{d_m \\times d}Wf2​∈Rdm​×d 마지막으로 residual connection 이 사용되며 layer normalization 수행","s":"Transformer-based Models","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#transformer-based-models","p":1132},{"i":1142,"t":"LoRA 는 two small matrices 의 곱으로 pre-trained weights 를 incremental update 모델링 h=W(0)h = W^{(0)}h=W(0) 의 경우, 수정된 forward pass 는 다음과 같다. h=W(0)x+△x=W(0)x+BAx,\\begin{equation} h = W^{(0)}x + \\triangle x = W^{(0)}x + BAx, \\end{equation}h=W(0)x+△x=W(0)x+BAx,​​ W(0)W^{(0)}W(0), △∈Rd1×d2\\triangle \\in \\mathbb{R}^{d_1 \\times d_2}△∈Rd1​×d2​, A∈Rr×d2A \\in \\mathbb{R}^{r \\times d_2}A∈Rr×d2​, B∈Rd1×rB \\in \\mathbb{R}^{d_1 \\times r}B∈Rd1​×r, r≪{d1,d2}r \\ll \\{ d_1, d_2 \\}r≪{d1​,d2​} 일반적으로 AAA 는 random Gaussian initialization 을 채택하고, BBB 는 training 초기에 △=0\\triangle = 0△=0 이 되도록 0 으로 초기화 Ai∗A_{i*}Ai∗​ 는 AAA 의 iii-th row, B∗iB_{*i}B∗i​ 는 BBB 의 iii-th column, Gi={Ai∗,B∗i}\\mathcal{G}_i = \\{ A_{i*}, B_{*i} \\}Gi​={Ai∗​,B∗i​} 는 iii-th doublet LoRA 는 주로 MHA 의 query 및 value projections 만 적용 [Towards a unified view of parameter-efficient transfer learning. He] 는 FFN 의 weight matrix (i.e. Wf1W_{f1}Wf1​, Wf2W_{f2}Wf2​) 에도 확장하여 성능 향상. 동시에 adapter tuning, prefix tuning 및 LoRA 를 포함한 다양한 efficient tuning 에 대한 통합된 관점 제안","s":"Low Rank Adaptation","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#low-rank-adaptation","p":1132},{"i":1144,"t":"저자는 두 가지 주요 구성 요소 포함 SVD-based adaptation. incremental matrices 를 singluar value decomposition 형태로 고안 Importance-aware rank allocation, 새로 디자인된 importance metric 을 기반으로 redundant singluar values 제거","s":"3. AdaLoRA Method","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1146,"t":"pre-trained weight matrices 의 incremental update 를 singular value decomposition 형식으로 parameterize W=W(0)+△=W(0)+PΛQ,\\begin{equation} W = W^{(0)} + \\triangle = W^{(0)} + P \\Lambda Q, \\end{equation}W=W(0)+△=W(0)+PΛQ,​​ P∈Rd1×rP \\in \\mathbb{R}^{d_1 \\times r}P∈Rd1​×r 및 Q∈Rr×d2Q \\in \\mathbb{R}^{r \\times d_2}Q∈Rr×d2​ : △\\triangle△ 의 left/right singular vectors diagonal matrix Λ∈Rr×r\\Lambda \\in \\mathbb{R}^{r \\times r}Λ∈Rr×r : singular values {λi}1≤i≤r\\{ \\lambda _i \\}_{1 \\leq i \\leq r}{λi​}1≤i≤r​ ( r≪min⁡(d1,d2)r \\ll \\min (d_1, d_2)r≪min(d1​,d2​) ) 를 포함 나아가, iii-th singular value 및 vectors 를 포함하는 triplet 을 G={P∗i,λi,Qi∗}\\mathcal{G} = \\{ P_{*i}, \\lambda_{i}, Q_{i*} \\}G={P∗i​,λi​,Qi∗​} 로 표시 실제론, Λ\\LambdaΛ 는 diagonal 이므로 Rr\\mathbb{R}^rRr 의 vector 로만 저장된다. Λ\\LambdaΛ 는 0 으로 초기화되고 PPP 및 QQQ 는 △\\triangle△ 가 training 초기에 0 이 되도록 하기 위해 random Gaussian 초기화를 채택 PPP 및 QQQ 의 orthogonality 강화를 위해 아래 regularizer 활용 R(P,Q)=∥P⊤P−I∥F2=∥QQ⊤−I∥F2.\\begin{equation} R(P,Q) = \\left \\| P^\\top P - I \\right \\|^2_\\text{F} = \\left \\| QQ^\\top - I \\right \\|^2_\\text{F}. \\end{equation}R(P,Q)=∥∥​P⊤P−I∥∥​F2​=∥∥​QQ⊤−I∥∥​F2​.​​ 저자의 방법에서, 각 gradient decent step 이후 rank 조절을 위해 Λ\\LambdaΛ 가 반복적으로 제거됨 모든 △\\triangle△ 에 대해 직접 SVD 를 계산하여 singular values 를 조작할 수 있다. 하지만 계산 복잡성은 O(min⁡(d1,d2)d1d2)O(\\min (d_1, d_2)d_1d_2)O(min(d1​,d2​)d1​d2​) 에 있다. 큰 수의 high-dimensional incremental matrices 에 대해 반복적으로 SVD 를 적용하는 것은 비용이 크다 반면, 저자의 parameterization 은 intensive SVD computation 을 피하므로 computational overhead 를 크게 줄인다. LoRA 는 structured pruning 을 적용하여 rank 를 제어할 수 있지만 (i.e. prune BABABA doublet-wise) 다음과 같은 단점이 있다. doublet 이 중요하지 않다 측정되면 해당 요소 모두 pruning 해야함 이로 인해, pruned dublet 을 다시 활성화하기가 거의 불가능 doublet entries 는 모두 제거되고 훈련되지 않으므로 잘못 삭제된 doublet 을 재활성화하는 가능성을 보존하지 않음 반면, adaLoRA 는 Eq. 3 에 기반하여 singular values 를 masking 하며 singular vectors 를 항상 유지 LoRA 의 AAA 와 BBB 는 orthogonal 이 아니므로, doublets 간에 종속성이 있을 수 있음 doublets 를 버리면 smallest singular values 를 truncating 하는 것보다 original matrix 와의 larger variation 발생 가능 따라서 rank allocation 의 각 step 에 incremental matrices 가 극도로 변경되어 훈련 불안정성을 유발하고 일반화에도 해를 입힐 수 있다.","s":"3.1 SVD-Based Adaptation","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#31-svd-based-adaptation","p":1132},{"i":1148,"t":"저자는 SVD-based adaptation 을 각 transformer layer 의 weight matrix Wq,Wk,Wv,Wf1W_q, W_k, W_v, W_{f1}Wq​,Wk​,Wv​,Wf1​ 및 Wf2W_{f2}Wf2​ 에 적용 budget 제어를 위해, training 중 importance score 에 대응하여 singular values 를 반복적으로 제거한다. kkk 로 incremental matrix 를 인덱싱. i.e. △k=PkΛkQk\\triangle_k = P_k \\Lambda_k Q_k△k​=Pk​Λk​Qk​ for k=1,…,nk = 1,\\dots, nk=1,…,n nnn : adapted weight matrices 수 Gk,i={Pk,∗i,λk,i,Qk,i∗}\\mathcal{G}_{k,i} = \\{ P_{k,*i}, \\lambda_{k,i}, Q_{k,i*} \\}Gk,i​={Pk,∗i​,λk,i​,Qk,i∗​} : △k\\triangle_k△k​ 의 iii-th triplet Sk,i∗S_{k,i*}Sk,i∗​ : importance score parameter set P={Pk}k=1n\\mathcal{P} = \\{ P_k \\}^n_{k=1}P={Pk​}k=1n​, E={Λk}k=1n\\mathcal{E} = \\{ \\Lambda_k \\}^n_{k=1}E={Λk​}k=1n​, Q={Qk}k=1n\\mathcal{Q} = \\{ Q_k \\}^n_{k=1}Q={Qk​}k=1n​ training cost C(P,E,Q)\\mathcal{C} (\\mathcal{P}, \\mathcal{E}, \\mathcal{Q})C(P,E,Q) With regularization Eq. 4, training objective L(P,E,Q)=C(P,E,Q)+γ∑k=1nR(Pk,Qk)\\mathcal{L}(\\mathcal{P}, \\mathcal{E}, \\mathcal{Q}) = \\mathcal{C}(\\mathcal{P}, \\mathcal{E}, \\mathcal{Q}) + \\gamma \\sum^n_{k=1} R(P_k, Q_k)L(P,E,Q)=C(P,E,Q)+γ∑k=1n​R(Pk​,Qk​) γ>0\\gamma > 0γ>0 : regularization coefficient ttt-th step 에서, 저자는 k=1,…,nk = 1, \\dots, nk=1,…,n 에 대한 Pk(t)P^{(t)}_kPk(t)​, Λk(t)\\Lambda^{(t)}_kΛk(t)​ 및 Qk(t)Q_k^{(t)}Qk(t)​ update 에 stochastic gradient step 사용 특히 Λk(t)\\Lambda_k^{(t)}Λk(t)​ 의 경우 Λ~k(t)=Λk(t)−η▽ΛkL(P(t).E(t),Q(t)),\\begin{equation} \\tilde{\\Lambda}_k^{(t)} = \\Lambda_k^{(t)} - \\eta \\triangledown_{\\Lambda_k} \\mathcal{L}(\\mathcal{P}^{(t)}. \\mathcal{E}^{(t)}, \\mathcal{Q}^{(t)}), \\end{equation}Λ~k(t)​=Λk(t)​−η▽Λk​​L(P(t).E(t),Q(t)),​​ η>0\\eta > 0η>0 : learning rate Given importance score Sk(t)S_k^{(t)}Sk(t)​, singular values 는 다음을 따라 pruning 됨 Λk(t+1)=T(Λ~k(t),Sk(t)),withT(Λ~k(t),Sk(t))ii={Λ~k,iitSk,it is in the top-b(t) of St,0otherwise,\\begin{equation} \\Lambda_k^{(t+1)} = \\mathcal{T} (\\tilde{\\Lambda}_k^{(t)}, S_k^{(t)}), \\text{with} \\mathcal{T}(\\tilde{\\Lambda}_k^{(t)}, S_k^{(t)})_{ii} = \\left\\{\\begin{matrix} \\tilde{\\Lambda}^{t}_{k,ii} & S^{t}_{k,i}\\ \\text{is in the top-}b^{(t)}\\ \\text{of}\\ S^{t}, \\\\ 0 & \\text{otherwise,} \\end{matrix}\\right. \\end{equation}Λk(t+1)​=T(Λ~k(t)​,Sk(t)​),withT(Λ~k(t)​,Sk(t)​)ii​={Λ~k,iit​0​Sk,it​ is in the top-b(t) of St,otherwise,​​​ St={Sk,i(t)}1≤k≤n,1≤i≤rS^{t} = \\{ S_{k,i}^{(t)} \\}_{1 \\leq k \\leq n, 1 \\leq i \\leq r}St={Sk,i(t)​}1≤k≤n,1≤i≤r​ : all triplets 의 importance score 포함 b(t)b^{(t)}b(t) : ttt-th step 에서의 나머지 singular values 의 budget less important singular values 를 제거함으로써 higher priority incremental matrices 에 더 많은 budget 을 부여 저자는 importance score 를 설계하기 위해 몇가지 옵션 도입","s":"3.2 Importance-Aware Rank Allocation","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#32-importance-aware-rank-allocation","p":1132},{"i":1150,"t":"모든 triplet 의 중요성을 quantify 하는 가장 직접적인 방법 중 하나. i.e. Sk,i=λk,iS_{k,i} = \\lambda_{k,i}Sk,i​=λk,i​ 이 방법으로 가장 중요하지 않은 singular values 만 제거된다. 이는 original matrix 와의 차이를 최소화하고 training 을 더욱안정화 시킨다. 기존의 많은 연구에서 이러한 criterion 을 사용하여 matrix rank 를 제어했다. 하지만, 이러한 simple metric 은 parameter 가 model performance 에 미치는 기여를 적절하게 quantify 할 수 없다는 점","s":"Magnitude of singular values","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#magnitude-of-singular-values","p":1132},{"i":1152,"t":"importance scoring 의 다른 대안으로, training loss 에 대한 parameters sensitivity 를 quantify 하지만 이전 연구에선 sensitivity 를 사용하여 single entries 의 importance 를 quantify 하고 weights elemen-wise 제거하는 unstructured pruning 적용 저자의 경우는, triplets 가 group-wise 로 제거되기 때문에, new metric 을 디자인해야 한다. 각 entry 의 sensitivity 를 고려하고 triplets 의 모델 성능에 대한 기여를 quantify 하기 위해 결합 따라서 저자의 triplets Gk,i\\mathcal{G}_{k,i}Gk,i​ 내의 singular value 및 vectors 를 모두 고려한 새로운 importance metric 제안 Sk,i=s(λk,i)+1d1∑j=1d1s(Pk,ji)+1d2∑j=1d2s(Qk,ij),\\begin{equation} S_{k,i} = s(\\lambda _{k,i}) + \\frac{1}{d_1} \\sum^{d_1}_{j=1} s(P_{k,ji}) + \\frac{1}{d_2} \\sum^{d_2}_{j=1} s(Q_{k,ij}), \\end{equation}Sk,i​=s(λk,i​)+d1​1​j=1∑d1​​s(Pk,ji​)+d2​1​j=1∑d2​​s(Qk,ij​),​​ 여기서 저자는 Pk,∗iP_{k, *i}Pk,∗i​ 및 Qk,i∗Q_{k,i*}Qk,i∗​ 의 mean importance 를 계산하여 Sk,iS_{k,i}Sk,i​ 가 Gk,i\\mathcal{G}_{k,i}Gk,i​ 의 parameter 수와 상관없이 조절되도록 함 s(⋅)s(\\cdot)s(⋅) : single entries 에 대한 specific importance function s(⋅)s(\\cdot)s(⋅) 로 sensitivity 를 채택할 수 있으며, 이는 gradient-weight 곱의 크기로 정의 I(wij)=∣wij▽wijL∣,\\begin{equation} I(w_{ij}) = \\left | w_{ij} \\triangledown_{w_{ij}} \\mathcal{L} \\right |, \\end{equation}I(wij​)=∣∣​wij​▽wij​​L∣∣​,​​ wijw_{ij}wij​ : any trainable parameter Eq. 8 은 parameter 가 제거했을 때, loss 의 변화를 근사화하는 것 parameter 의 제거가 큰 영향을 미친다면, 모델은 이에 민감하며 유지해야 한다. 하지만, [Platon] 은 Eq. 8 의 sensitivity 가 아직 신뢰할 수 있는 importance 지표가 아니라는 지적을 함. 이 score 는 sample mini batch 에서 sample 되어 그런 것으로 추정한다. stochastic sampling 및 complicated training 은 Eq. 8 을 사용하여 sensitivity 를 추정할 때 높은 변동성과 큰 불확실성을 초래 따라서 [Platon] 은 sensitivity smoothing 과 uncertainly quantification 제안 I‾(t)(wij)=β1I‾(t−1)(wij)+(1−β1)I(t)(wij)U‾(t)(wij)=β2U‾(t−1)(wij)+(1−β2)∣I(t)(wij)−I‾(t)(wij)∣,\\begin{align} \\overline{I}^{(t)}(w_{ij}) &= \\beta_1 \\overline{I}^{(t-1)}(w_{ij}) + (1-\\beta_1)I^{(t)}(w_{ij}) \\\\ \\overline{U}^{(t)}(w_{ij}) &= \\beta_2 \\overline{U}^{(t-1)}(w_{ij}) + (1-\\beta_2) \\left | I^{(t)}(w_{ij}) - \\overline{I}^{(t)}(w_{ij}) \\right |, \\end{align}I(t)(wij​)U(t)(wij​)​=β1​I(t−1)(wij​)+(1−β1​)I(t)(wij​)=β2​U(t−1)(wij​)+(1−β2​)∣∣​I(t)(wij​)−I(t)(wij​)∣∣​,​​ 0<β1,β2<1.0 < \\beta_1, \\beta_2 < 1.0<β1​,β2​<1. I‾(t)\\overline{I}^{(t)}I(t) : exponential moving average 을 사용한 smoothed sensitivity U‾(t)\\overline{U}^{(t)}U(t) : I(t)I^{(t)}I(t) 및 I‾(t)\\overline{I}^{(t)}I(t) 사이의 local variation 에 의해 quantify 된 uncertainly term importance 를 I‾(t)\\overline{I}^{(t)}I(t) 및 U‾(t)\\overline{U}^{(t)}U(t) 간의 곱으로 정의 이는 s(⋅)s(\\cdot)s(⋅) 에 대한 다른 option 이 될 수 있다. s(t)(wij)=I‾(t)(wij)⋅U‾(t)(wij).\\begin{equation} s^{(t)}(w_{ij}) = \\overline{I}^{(t)}(w_{ij}) \\cdot \\overline{U}^{(t)}(w_{ij}). \\end{equation}s(t)(wij​)=I(t)(wij​)⋅U(t)(wij​).​​ 다양한 importance metrics 비교를 위해 세부적인 ablation 은 Section 4.4 에서 제시 저자는 sensitivity variant (Eq. 11) 을 기반한 metric (Eq. 7)이 우수한 성능을 내는 것을 발견. 저자는 다음과 같은 알고리즘 요약","s":"Sensitivity-based importance","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#sensitivity-based-importance","p":1132},{"i":1154,"t":"rank 조절은 low-rank adaptation 의 맥락에서 parameter budget 을 제어하는 것이다. 따라서 저자는 all incremental matrices 의 total rank (i.e. total singular values 수) 를 budget b(t)b^{(t)}b(t) 로 정의한다. budget allocation 은 fine-tuning 중 반복적으로 수행된다. training 을 용이하게 하기 위해, 저자는 global budget scheduler 를 제안한다. 구체적으로, initial budget b(0)b^{(0)}b(0) 을 target budget b(T)b^{(T)}b(T) 보다 약간 높게 설정 (e.g. b(T)b^{(T)}b(T) 의 약 1.5배) 각 incremental matrix 의 intial rank 를 r=b(0)/nr = b^{(0)} / nr=b(0)/n 으로 설정 저자는 tit_iti​ steps 동아안 warm up training 그리고 budget b(t)b^{(t)}b(t) 가 b(T)b^{(T)}b(T) 에 도달할 때까지 b(t)b^{(t)}b(t) 를 감소시키기 위해 cubic schedule 따름 마지막으로, resulting budget 을 고정하고 모델을 tft_ftf​ 단계 동안 fine-tuning 이는 AdaLoRA 가 먼저 parameter space 을 탐색한 다음 가장 중요한 weight 에 집중할 수 있도록 한다.","s":"3.3 Global Budget Scheduler","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#33-global-budget-scheduler","p":1132},{"i":1156,"t":"AdaLoRa 를 구현하여 DeBERTaV3-base 와 BART-large 를 fine-tuning 하는데 사용 제안된 알고리즘의 효과를 NLU (GLUE), QA (SQuADv1 및 SQuADv2) 및 NLG (XSum 및 CNN/DailyMail) 에서 평가 all gain 이 p<0.05p < 0.05p<0.05 로 유의한 결과 얻음","s":"4. Experiments","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1158,"t":"저자는 PyTorch 로 모든 알고리즘 구현 구현은 publicly available Huggigface Transformers 코드 기반 모든 실험은 NVIDIA V100 GPUs 에 수행 LoRA 는 △x\\triangle x△x 를 α/γ\\alpha / \\gammaα/γ 로 scaling 했다. α\\alphaα : γ\\gammaγ 에 대한 상수 output 의 크기는 서로 다른 γ\\gammaγ 에 대해 일관되게 유지될 수 있으므로 γ\\gammaγ 를 변경할 때 learning rate 에 드는 노력을 줄임 α\\alphaα 는 16 또는 32 로 설정 되며 tuning 하지 않음 LoRA 에 따르면, Eq. 3 에 동일한 scaling 을 추가하고 α\\alphaα 를 LoRA 에 고정 또한, Algorithm 1 에서 저자는 모든 △T\\triangle_T△T​ steps (e.g. △T=100\\triangle_T = 100△T​=100) 에서 singular values 를 제거하므로 pruned triplets 는 이러한 간격 내에서 업데이트될 수 있으며 future iterations 에서 다시 활성화될 수 있음","s":"Implementation Details","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#implementation-details","p":1132},{"i":1160,"t":"AdaLoRA 를 다음 방법들과 비교 full fine-tuning : adaptation 을 위한 가장 일반적인 approach fine-tuning 중, 모델은 pre-trained weights 및 biases 로 초기화되고 모든 model parameter 가 gradient updates Bitfit : 효과적인 parameter-efficient fine-tuning pre-trained model 에서 bias vectors 만 fine-tuning Adapter tuning : transformer blocks 사이에 two-layer adapters 삽입 저자는 두 가지 유형의 adapter 와 비교 Houlsby adapter 는 self-attention module 및 FFN module 사이에 삽입하며 그 뒤 residual connection Adapter-fusion (Pfeiffer) 은 adapter 를 FFN module 과 LayerNorm module 이후에만 적용하는 효율적인 디자인 제안 trainable parameter 수는 layer 수, adapter 의 hidden dimension 및 inputs dimension 에 의해 결정 LoRA : parameter-efficient fine-tuning 의 SOTA method two small matrices 로 incremental updates 를 parameterize 하고 이 두 행렬만 fine-tuning trainable parameter 의 수는 rank rrr 및 adapted weight matrices 의 수 nnn 으로 제어 [Hu] 는 LoRA 에 query 및 value projection 에만 적용 저자는 LoRA 를 all weight matrices (i.e. Wq,Wk,Wv,Wf1,Wf2W_q, W_k, W_v, W_{f_1}, W_{f_2}Wq​,Wk​,Wv​,Wf1​​,Wf2​​) 에 적용하여 성능 향상을 발견 따라서 저자는 이 일반화된 LoRA 와 비교하여 성능 극대화","s":"Baselines","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#baselines","p":1132},{"i":1163,"t":"저자가 제안된 알고리즘으로 DeBERTaV3-base 의 fine-tuning 성능 평가 NLU (GLUE) 에서 실험 진행하며, 이 벤치마크에는 2 single-sentence classification tasks, 3 similarity 및 paraphrase tasks 및 4 natural language inference tasks 포함","s":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#models-and-datasets","p":1132},{"i":1165,"t":"DeBERTaV3-base 는 183M parameter 포함 저자는 여러 budget levels 에서 AdaLoRA 를 baseline 과 비교 trainable parameters 0.3/0.6/1.2M 고려 parameter budget 을 맞추기 위해, 저자는 adapter 의 hidden budget {8,16,32,64}\\{8, 16, 32, 64\\}{8,16,32,64} 에서 선택하며, LoRA 의 rank rrr 을 {2,4,8}\\{2, 4, 8\\}{2,4,8} 로 설정하며, AdaLoRA 의 final budget b(T)b^{(T)}b(T) 를 {144,288,576}\\{144, 288, 576\\}{144,288,576} 에서 선택 이후 AdaLoRA 에 대해 b(0)b^{(0)}b(0) 를 b(T)b^{(T)}b(T) 의 1.5배로 설정, regularization coefficient γ\\gammaγ 를 {0.1,0.3,0.5}\\{0.1, 0.3, 0.5\\}{0.1,0.3,0.5} 에서 선택 exponential moving parameters β1\\beta_1β1​ 및 β2\\beta_2β2​ 를 default value 0.85 로 설정 learning rate 는 {5×10−5,8×10−5,1×10−4,2×10−4}\\{5 × 10^{-5}, 8 × 10^{-5}, 1 × 10{^-4}, 2 × 10{^-4} \\}{5×10−5,8×10−5,1×10−4,2×10−4} 중에서 선택","s":"Implementation Details","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#implementation-details-1","p":1132},{"i":1167,"t":"다양한 budget setting 에서 AdaLoRA 를 baseline 과 비교 GLUE dev set 에서 all dataset 및 all parameter level 에서 AdaLoRA 를 기존 방법과 비교하여 더 나은 또는 동등한 성능 달성 parameter budget 이 0.3M 인 경우 AdaLoRA 는 RTE 에서 87.36% 달성하여 SOTA baseline 보다 1.8% 높음 AdaLoRA 는 매우 낮은 budget 에서도 종종 더 나은 성능","s":"Main results","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#main-results","p":1132},{"i":1170,"t":"제안된 알고리즘을 two QA (SQuADv1 및 SQuADv2) 에서 성능 평가 AdaLoRA 를 DeBERTaV3-base fine-tuning 에 사용 이 task 들은 sequence labeling problem 을 다룸 각 token 이 answer span 의 시작과 끝이 될 probability 예측","s":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#models-and-datasets-1","p":1132},{"i":1172,"t":"다양한 parameter budget 에서 baseline 과 AdaLoRA 비교 trainable parameter 수를 total pre-trained parameter 0.08%/0.16%/0.32%/0.65% 에서 선택 budget 요구사항을 맞추기 위해, adapter hidden dimension 을 {4,8,16,32,64}\\{ 4, 8, 16, 32, 64 \\}{4,8,16,32,64} 에서 선택 LoRA 의 rank rrr 은 {1,2,4,8}\\{ 1, 2, 4, 8\\}{1,2,4,8} 에서 선택 AdaLoRA 의 final total rank b(T)b^{(T)}b(T) 는 {72,144,288,576}\\{ 72, 144, 288, 576 \\}{72,144,288,576} 에서 선택 batch size 16 AdamW optimizer learning rate 1×10−31 \\times 10^{-3}1×10−3","s":"Implementation Details","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#implementation-details-2","p":1132},{"i":1174,"t":"4 가지 budget setting: total pre-trained parameters 0.08%, 0.16%, 0.32%, 0.65% 에서 DeBERTaV3-base fine-tuning 에서 실험 AdaLoRA 는 all budget level 에서 기존 방법를 능가 two metrics: EM 및 F1 에서 더 우수한 성능 발휘 Houlsby adapter 및 Pfeiffer adapter 의 성능은 parameter budget 을 줄이면 감소하는 반면, 저자의 방법은 일관된 성능","s":"Main Results","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#main-results-1","p":1132},{"i":1177,"t":"NLG tasks 의 SOTA 와 비교를 위해, 저자는 AdaLoRA 를 BART-large 모델을 fine-tuning 하는데 적용. 그리고 두 가지 데이터셋에서 모델 성능 평가 (XSum, CNN/DailyMail)","s":"Models and Datasets","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#models-and-datasets-2","p":1132},{"i":1179,"t":"DeBERTaV3-base 와 유사하게, 저자는 low-rank/SVD-based adaptation 을 encoder 및 decoder layer 의 모든 weight matrix 에 적용 ROUGE 1/2/L scores report 15 epochs 8 beam length 64 batch size CNN/DailyMail 의 경우 4 beam search 32 batch size","s":"Implementation Details","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#implementation-details-3","p":1132},{"i":1181,"t":"4 가지 budget 에서 fine-tuning 성능 비교 trainable parameter 수는 total pre-trained parameter 의 0.13%, 0.26%, 1.10% 및 2.20% all budget levels 에서 두 데이터셋에 baseline 과 비교하여 AdaLoRA 는 더 나은 성능 달성","s":"Main Results","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#main-results-2","p":1132},{"i":1184,"t":"Fig. 2 에서 여러 budget levels 에서 DeBERTaV3-base 를 fine-tuning 한 실험 결과 세 데이터셋 (MNLI-m, SQuADv2, XSum) 에서 baseline 과 비교하여 AdaLoRa 는 모든 budget level 에서 일관된 성능 향상 XSum task 의 경우 budget 을 늘릴수록 성능 향상이 두드러지며, 이는 high budget 이 NLG task 에 도움이 되는 것을 시사 MNLI 및 SQuADv2 dataset 에선 low budget levels (≤1\\leq 1≤1%) 에서 AdaLoRA 는 SQuADv2 에서 88.87% F1 달성. 이는 high budget (4.65) 의 성능 (88.89% F1) 과 유사","s":"Different budget levels","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#different-budget-levels","p":1132},{"i":1186,"t":"Section 3.1 에서 언급했듯, LoRA 를 doublet-wise pruning 하여 rank allication 이 경우 doublets 가 완전히 제거되므로, 다시 활성화하는 장벽이 높아진다 crucial doublets 가 실수로 제거될 때 학습 불안정성을 초래하고 일반화에 해를 끼칠 수 있다. 이를 설명하기 위해 Table 4 에서 세 개의 데이터셋 (SST-2, RTE 및 CoLA) 에서 AdaLoRA 와 LoRA 의 pruning 을 비교 all budget levels 에서 AdaLoRA 가 모든 데이터셋에서 LoRA pruning 을 능가","s":"Comparison to low-rank parameterization","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#comparison-to-low-rank-parameterization","p":1132},{"i":1188,"t":"AdaLoRA 에서 importance score 는 Eq. 7 의 triplet 내의 every entry 의 sensitivity 및 uncertainly 로 정의 Table 4 에서 importance score 의 두 variants 조사 Eq. 7 의 s(⋅)s(\\cdot)s(⋅) 를 sensitivity 만으로 변경하는 경우 SiS_iSi​ 를 직접 ∣λi∣|\\lambda_i|∣λi​∣ 로 정의하는 경우 결과에서, 제안된 importance score 가 일반적으로 잘 수행 two variants 는 성능을 최대 0.9% 까지 저하","s":"Variants of the importance score","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#variants-of-the-importance-score","p":1132},{"i":1190,"t":"저자의 방법의 two components 인 SVD adaptation 및 adaptive budget allocation 이 성능 향상에 중요한 역할 하는 것을 언급 이를 증명하기 위해 다음과 같은 변형과 비교 SVD-LoRA : Eq. 3, 4 의 SVD-based adaptation 만으로 fine-tuning LoRAregu_{\\text{regu}}regu​ : LoRA 에 AAA 와 BBB 에 orthogonal regularization (Eq. 4) 적용 AdaLoRAγ=0_{\\gamma = 0}γ=0​ : AdaLoRA 에 orthogonal regularization (Eq. 4) 없이 Table 5 에서, SST-2 및 MNLI 에 DeBERTaVe-base 를 fine-tuning 한 결과 SVD adaptation 만 사용한 fine-tuning 이 LoRA 보다 향상을 보이지만 AdaLoRA 의 성능에 미치지 못함 SVD orthogonal regularization 없는 AdaLoRA 의 성능은 저하됨 이 결과로 두 component 가 모델 성능에 기여하는 것 확인","s":"The role of two components","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#the-role-of-two-components","p":1132},{"i":1192,"t":"Fig. 3 은 AdaLoRA 로 fine-tuning 된 DeBERTaV3-base 의 각 incremental matrix 의 resulting rank AdaLoRA 가 항상 FFN 및 top layers 에 더 많은 budget 을 할당하는 경향이 있다는 것을 발견 이러한 행동은 FFN module 의 weight matrices 와 top layers 의 weight matrices 가 모델 성능에 더 중요하다는 저자의 경험적 결론과 일치 따라서 이는 저자가 제안한 importance metric 기준이 AdaLoRA 를 crucial module 에 집중하도록 guide 한다는 것 확인 한편, AdaLoRA 에 의해 생성된 rank distribution 은 budget levels, task 및 modle 간에 일관 이는 remaining parameter 수가 b(T)b^{(T)}b(T) 와 linearly scaling 되므로 remaining parameter 를 제어하기 위해 b(T)b^{(T)}b(T) 를 조절할 수 있다는 것을 의미","s":"The resulting budget distribution","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"#the-resulting-budget-distribution","p":1132},{"i":1194,"t":"저자는 parameter-efficient fine-tuning method AdaLoRA 제안 importance scoring 에 따라 parameter budget 을 adaptively allocate weight matrices 의 incremental update 를 singular value decomposition (SVD) 형식으로 parameterize 이후 new importance metric 을 기반으로 singular values 를 조작하여 parameter budget 을 incremental matrices 간에 dynamically allocate 이 방식은 효과적으로 모델 성능 및 파라미터 효율성 향상 NLU, QA 및 NLG task 에 광범위하게 실험하여 기존 방법보다 우수한 성능 달성","s":"5. Conclusion","u":"/docs/Paper/NLP/PEFT/AdaLoRA","h":"","p":1132},{"i":1196,"t":"논문 및 이미지 출처 : https://arxiv.org/pdf/2204.03649.pdf","s":"Unsupervised Prompt Learning for Vision-Language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1198,"t":"CLIP 같은 모델이 visual 과 langauge 간의 Contrastive learning 을 통해 훌륭한 tranasfer learning 을 보이고, 추론 과정에 proper prompt (text description) 형태가 필요해졌다. 후속으로, 힘든 prompt engineering 을 피하기 위해 CoOp, CLIP-Adapter 및 Tip-Adapter 같은 연구들은 downstream image recognition task 에 few-shot, zer-shot learning 으로 잘 일반화시키기 위해서 vision-language model (VLM)을 채택하였다. 본 논문은 다른 시나리오에 대해 탐구한다. target 데이터를 제공하지 않는, CLIP-like VLM 의 transfer 성능을 향상하는 동시에 prompt engineering 을 피하는 approach 인 Unsupervised Prompt Learning (UPL) 을 제안한다. unsupervised learning 을 prompt learning 에 도입한 것은 이 논문이 처음이며, 실험적으로도 UPL 은 CLIP 과 prompt engineering 측면에서 ImageNet 이나 다른 데이터셋에서 좋은 성능을 보였다. 향상된 버전의 UPL 은 8-shot CoOp 이나 8-shot TIP-Adapter 와 경쟁력 있었다. 코드는 https://github.com/tonyhuang2022/UPL 에서 확인하자.","s":"Abstract","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1200,"t":"최근, CLIP 및 FLIP 은 기존 visual framework 와 달리, 대규모의 image-text pair 데이터를 두 개의 아키텍처 image encoder 와 text encoder 를 공유된 임베딩 공간에서 align 하도록 훈련한다. downstream task 에 최적화하도록 transfer 하기 위해, 알맞은 텍스트 설명인 prompt 가 필요한데, Figure 1a 처럼 CLIP 에서는 \"a photo of a [CLS]\" 형태의 prompt 템플릿을 사용했다. 하지만 proper prompt 를 식별하는 것은 쉽지 않아, domain knowledge 와 힘든 prompt engineering 이 필요하다. hand-crafted prompt 를 피하고 transfer 성능을 올리기 위해, supervised 방법으로는 CoOp, CLIP-Adapter 및 Tip-Adapter 가 있으며 downstream image recognition task 를 위해 LLM 을 사용하여 target dataset 의 적은 셋을 사용한다 (Figure 1b). CoOp 은 hand-crafted prompt 를 continuous prompt representation 으로 교체 CLIP-Adapter 는 정제된 feature 를 학습하기 위해 추가적인 네트워크 사용 TIP-Adatper 는 few-shot supervision 으로 query-key cache 모델을 구성하여 CLIP-Adapter 확장 위 방법들은 annotated sample 이 필요하므로 모델 확장에 한계가 있다. 저자는 다른 설정을 탐구하며, 이는 target dataset 을 제공하지 않고 UPL 로, downstream image recognition task 에 대한 VLM 을 효과적으로 사용하면서도 prompt engineering 을 피하는 것이다 (Figure 1c). UPL 은 CLIP 을 활용하여 target image 에 대한 pseudo label 을 생성하고, 샘플된 pseudo label 에서 learnable prompt representation 을 최적화하는 것으로 self-training 과정을 수행한다. 그리고 hand-crafted prompt 를 최적화된 prompt representation 으로 바꾸는 것으로 CLIP 의 성능을 향상시킬 수 있다. threshold 기반 self-training 과 대조적으로, 저자는 다음의 관찰된 사항들에 따른 self-training 을 위해 각 class 에서 샘플링된 것을 top-KKK 로 택한다. VLM 은 서로 다른 클래스에 편향된 성능을 가지며, 불확실한 샘플링을 걸러내기 위해 threshold 를 사용하는 것은 불균형한 pseudo label 데이터 분포를 초래함 confidence score 와 pseudo label 정확도 간의 상관관계가 없어, noisy pseudo label 을 동시에 도입할 수 있지만, 실험적으로 모든 클래스에 동일한 prompt representation 을 사용하기 때문에 nosity 가 robust 하다는 것을 발견함. CLIP 에서 제안한 prompt 앙상블 전력에 영감을 받아, pseudo label 앙상블과 prompt representation 앙상블을 도입하여 저자의 방법론을 더 강화하였다. 다음 세 가지 contribution 으로 요약할 수 있다. prompt engineering 을 피하고 VLM 활용을 위해 UPL 을 제안하며, VLM 에 unsupervised learning 을 prompt learning 에 도입한 첫 연구 pseudo-labeling 에 대한 CLIP 의 특성을 분석하여, top-KKK 전략을 사용하며, transfer 성능 향상을 위해 prompt representation 앙상블을 시도 10 가지 image classification task 데이터셋에서 CLIP 의 promnpt engineering 보다 성능이 좋으며, 8-shot CoOp 및 8-shot TIP-Adapter 보다 대부분의 데이터셋에서 성능이 우수했음","s":"Introduction","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1203,"t":"VLM 은 대규모의 iamge-text 쌍을 학습하여 visual representation learning 에 대한 큰 잠재력을 입증했다. CLIP : 4 억개 데이터셋 수집 ALIGN : 18억개 noisy image-text 쌍 이용 FLIP : vision-language pretraining 의 fine-grained 를 위해 3 억개의 수집 Wukong : 서로 다른 multi-modal pre-training 의 벤치마킹에 대한 1 억개 데이터 포함 Florence : FLD-900M 라는 9 억개의 image-text 쌍 데이터셋 포함 위 VLM 은 vision encoder, text encoder 두 아키텍처로 다음을 활용 vision encoder : ResNet, ViT 또는 Swin Transformer text encoder : Standard Transformers image 와 text 를 embedding space 에서 align 하기 위해 contrastive learning 을 채택함. representation framework CLIP 은 object detection, semantic segmentation, action recognition, video caption 및 3D recogmnition 등에 채택되어 왔다.","s":"Vision-language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#vision-language-models","p":1195},{"i":1205,"t":"Pretrained VLM class embedding 생성을 위해 prompt (예; \"a photo of a [CLS]\") 를 사용한다. proper prompt 식별 및 prompt engineering 이 힘드므로 NLP 의 prompt learning 에 영감을 받아, CoOp : continuous prompt optimization 전략을 제안하여 prompt design 을 피한다. CLIP-Adapter : 추가적인 adapter network 를 사용하여 text feature 와 image feature 를 새로운 embedding 공간에서 매핑하여, 더 좋은 target dataset 을 채택하게 된다. Tip-Adapter : key-query cache 모델의 weight 를 만들어 CLIP-Adapter 를 확장한다. 하지만 위 방법들은 few-shot labeled data 에 의존하며, 모델 용량을 스케일링하는데 한계가 있는 반면, UPL 은 VLM 의 trnasfer 성능을 향상시키면서도 annotation target dataset 을 필요로 하지 않는다.","s":"Prompt Learning","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-learning","p":1195},{"i":1207,"t":"Self-training 은 간단한 semi-supervised learning 접근법이다. 잘 학습된 모델로 unlabaled dataset 에서 pseudo label 을 생성한 후 labeled data 와 pseudo-labeld data 를 사용하여 finetuning 한다. 최근, self-training 은 image classification, object detection, semantic segmentation, speech recognition, action recognition 및 machine traslation 분야의 딥러닝에 큰 진보를 보여주고 있다. VLM 은보통 대규모 image-text 쌍에 pretraining 하며 prompting 으로 좋은 성능을 보여준다. 저자는 UPL 을 제안하여 target dataset 에 대한 pseudo label 을 생성하며 self-training 으로 continuous prompt representation 를 최적화한다. 기존의 self-training 은 네트워크의 모든 layer 를 finetuning 하는 반면, UPL 은 네트워크를 고정하여 유지하면서도 (image, text encoder) continuous prompt representation 을 최적화 한다.","s":"Self-training","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#self-training","p":1195},{"i":1209,"t":"UPL 을 도입하며 transfer 성능을 향상시키며 prompt engineering 을 피한다. 기존 supervised 방법과 달리, target dataset 의 annotation 을 필요하지 않는다. UPL 의 overview target image 에 대한 pseudo label 생성 self-training 을 통해 prompt representation 최적화","s":"Method","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1211,"t":"Figure 2 에서 전체 개요를 보여 준다. UPL 은 pseudo label generation 과 prompt representation optimization 두 모듈을 포함한다. pretrained VLM (예; CLIP) 을 활용하여 target dataset 에서 unlabeled image 의 pseudo label 을 생성한다. 이는 다음의 두 가지 관찰을 기반으로 한다. pseudo label 정확도와 confidence score 간의 상관관계가 낮음 VLM 은 각각의 클래스에 편향된 정확도를 가지므로, 각 클래스에 확실한 샘플링을 위해 top-KKK 를 택한다. 이는 threshold 보다 confidence score 가 더 높다. CoOp 에서 영감을 얻어 learnable prompt representation 를 정의 prompt representation 은 모든 카테고리에 교차로 공유되며 생성된 pseudo-label 와 선택된 unlabeled sample 을 최적화한다. 추론 단계에서, hand-crafted prompt 를 최적화된 prompt representation 으로 교체하여 CLIP 의 inference pipeline 을 따름","s":"Overview of UPL","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#overview-of-upl","p":1195},{"i":1214,"t":"저자는 CLIP 의 inference 에 대해 다시 다루었으며, CCC class 를 포함한 target dataset 이 주어지면, CLIP 은 \"a photo of a [CLS]\" 와 같은 prompt 를 소문자의 byte pair encoding (BPE) representation 으로 변환한다. 여기서 각 카테고리에 대한 class embedding 을 생성시키기 위해 CLIP 의 text encoder 를 지난다. 저자는 클래스 임베딩의 집합을 {fctext}c=1C\\{ f^{text}_c \\}^C_{c=1}{fctext​}c=1C​ 로 표기하며, 여기서 fctextf^{text}_cfctext​ 는 ccc-th 카테고리의 클래스 임베딩을 나타낸다. 이미지 III 의 경우, CLIP 의 image encoder 로 추출한 visual feature 를 fimagef^{image}fimage 로 표기한다. 클래스 ccc 가 될 확률은 다음과 같이 계산한다. pc=exp⁡(<fctext,fimage>/τ)∑j=1Cexp⁡(<fjtext,fimage>/τ)(1)p_c = \\frac{ \\exp (< f^{text}_c , f^{image} > / \\tau ) }{ \\sum^C_{j=1} \\exp (< f^{text}_j, f^{image} > / \\tau ) } \\tag{1}pc​=∑j=1C​exp(<fjtext​,fimage>/τ)exp(<fctext​,fimage>/τ)​(1) 여기서 τ\\tauτ 는 CLIP 에서 학습된 temperature parameter 이며, <⋅,⋅>< \\cdot, \\cdot ><⋅,⋅> 은 cosine similarity 이다. 이제 prediction y^\\hat{y}y^​ 를 쉽게 구할 수 있다. y^=arg max⁡c pc(2)\\hat{y} = \\underset{c}{\\argmax} \\ p_c \\tag{2}y^​=cargmax​ pc​(2)","s":"Inference of CLIP","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#inference-of-clip","p":1195},{"i":1216,"t":"pretrained CLIP 으로 식 1, 식 2 를 사용하여 target dataset 으로부터 unlabeled sample 에 대한 pseudo 를 생성할 수 있다. Self-training 과 semi-supervised learning 은 threshold 보다 score 가 높은 confident sample 을 유지하지만, 이를 CLIP 에 바로 적용시키기 힘들다. 이는 두 가지 이유가 있다. CLIP 은 downstream image recognition task 에 transfer 할 때 서로 다른 클래스에 대한 편향된 성능을 보인다. 이는 pretraining dataset 과 target dataset 간의 domain 차이 때문이다. 이 현상은 Figure 3 에서 확인할 수 있다. pseudo-labaled data 의 임밸런스 분포에서 unconfident sample 을 필터링하기 위해 고정된 threshold 를 사용하면 최적화가 저해된다. Self-training 은 condidence (probability) 가 pseudo label 의 퀄리티를 잘 반영할 것으로 예상한다. 따라서 threshold (예; 0.9) 는 하이 퀄리티 샘플을 선택하기 위해 사용될 수 있지만, CLIP 에서 confidence score 와 pseudo label 정확도 간의 상관관계가 비교적 약하다는 것을 관찰하였으며 이는 Figure 4 에서 확인할 수 있다. 그러므로 저자는 최적화를 위해 식 1, 2 를 사용하여 confident sample 을 top-KKK 선택을 지지한다. 이는 대규모의 샘플들이 훈련 중 overwhelm 되는 것을 예방한다. 이는 대규모의 샘플들이 훈련 중에 overwhelm 되는 것을 예방하며, 저자는 K=16K = 16K=16 으로 설정한다.","s":"Pseudo Label Generation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-generation-1","p":1195},{"i":1218,"t":"CLIP 은 다음의 visual model 을 포함한다. ResNet-50, ResNet-101, ResNet50x4, ResNet-50x16, ResNet-50x64 ViT-B/32, ViT-B/16, ViT-L/14 저자는 CLIP 의 여러 아키텍처가 Figure 5 처럼 클래스에 편향된 정확도를 가지는 것을 관찰했다. 이 결과를 바탕으로, pseudo label 의 퀄리티를 향상시키기 위해 간단한 pseudo label ensemble 전략을 제안한다. 특히, 다양한 아키텍처의 CLIP model MMM 이 주어지면, 식 1 을 활용하여 mmm-th CLIP model 로 예측된 pimp^m_ipim​ 확률을 얻는다. 그리고 간단하게 pˉi=∑m=1MpiM/M\\bar{p}_i = \\sum^M_{m=1}p^M_i / Mpˉ​i​=∑m=1M​piM​/M 으로 평균화하여 pˉi\\bar{p}_ipˉ​i​ 확률을 얻을 수 있다. 그 후, 향상된 pseudo label 을 생성하기 위해 pˉi\\bar{p}_ipˉ​i​ 에 식 2 를 적용한다. 위 과정이 끝나면, unsupervised prompt representation 최적화를 위해 pseudo-labeled data 를 사용한다.","s":"Pseudo Label Ensemble","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-ensemble","p":1195},{"i":1220,"t":"기존의 CLIP 에선 transfer learning 을 위해 \"a photo of a [CLS]\" 처럼 다양한 prompt 템플릿을 정의했는데, proper prompt 를 식별하는 것은 domain knowledge 와 prompt engineering 이 요구되어 힘든 작업이다. 그리고 prompt 에 약간의 변화만 있어도 성능이 크게 변한다. CoOp 은 hand-crafted prompt 를 피하기 위해 적은 labeled data 에서 continuous prompt representation 를 최적화하였다. UPL 은 CoOp 과 비슷하지만, target dataset 에서 어떠한 annotation 도 요구하지 않는다.","s":"Prompt Representation Optimization","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-representation-optimization","p":1195},{"i":1222,"t":"목표는 CLIP 의 transfer 성능 향상을 위해 pseudo-labeled data 에 prompt representation 을 학습하는 것이다. learnable prompt representation 을 V∈RD×LV \\in \\mathcal{R}^{D \\times L}V∈RD×L 로 표기하며, DDD 는 word embedding 의 차원 (CLIP 의 경우 512), LLL 은 hypter-parameter 를 표기하는 것으로 default 는 16 이다. CCC classes 를 포함하는 target dataset 이 주어지면, class ccc (1≤c≤C1 \\leq c \\leq C1≤c≤C) 에 대한 continuous prompt Vc∈RD×(L+1)V_c \\in \\mathcal{R}^{D \\times (L + 1)}Vc​∈RD×(L+1) 를 정의한다. Vc=[V,wc],(3)V_c = [V, w_c], \\tag{3}Vc​=[V,wc​],(3) wc∈RDw_c \\in \\mathcal{R}^Dwc​∈RD 는 class ccc 의 fixed word embedding 이다. identical prompt representation VVV 는 모든 클래스에 공유된다. 훈련 과정은 Figure 2 (right part) 에서 보여준다. 각각의 pseudo labeled image 의 경우, 저자는 image 을 CLIP 의 vision encoder 를 지나 visual feature fimagef^{image}fimage 를 추출한다. {Vc}c=1C\\{ V_c \\}^C_{c=1}{Vc​}c=1C​ 는 CLIP 의 text encoder g(⋅)g( \\cdot )g(⋅) 을 지나 class embedding 을 얻는다. ccc-th class 의 확률은 다음과 같이 계산할 수 있다. pc=exp⁡(<g(Vc),fimage>/τ)∑j=1Cexp⁡(<g(Vj),fimage>/τ)(4)p_c = \\frac{ \\exp (< g(V_c), f^{image} > / \\tau) }{ \\sum^C_{j=1} \\exp (< g(V_j), f^{image} > / \\tau) } \\tag{4}pc​=∑j=1C​exp(<g(Vj​),fimage>/τ)exp(<g(Vc​),fimage>/τ)​(4) 여기서 τ\\tauτ 는 temperature parameter 이다. training image 의 경우, 식 4 를 이용하여 모든 클래스의 확률을 계산하고 pseudo label 로 cross-entropy loss 를 최소화한다. gradient 는 text encoder g(⋅)g( \\cdot )g(⋅) 을 통해 back-propagate 하여 text encoder 의 풍부한 knowledge 를 이용한다. 마지막으로, learnable prompt representation VVV 를 업데이트 한다. 여기서 image encoder 와 text encoder 는 훈련 중에는 weight 가 변하지 않는다는 것을 알야야 한다.","s":"Learnable Prompt Representation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#learnable-prompt-representation","p":1195},{"i":1224,"t":"prompt representation VVV 의 최적화가 끝나고, target dataset 이 주어지면, {Vc}c=1C\\{ V_c \\}^C_{c=1}{Vc​}c=1C​ 를 CLIP 의 text encoder 를 지나 모든 클래스에 대한 class embedding 을 얻는다. test image 의 경우, 이미지를 CLIP 의 image encoder 를 지나 visual feature 를 추출하고 식 4를 적용하여 image recongnition 을 위한 확률값을 계산한다.","s":"Inference","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#inference","p":1195},{"i":1226,"t":"기존 CLIP 은 transfer 성능 향상을 위해 다양한 prompt 를 정의하였으며, 이는 저자의 approach 에서 다양한 초기화로 multi prompt representation 학습에 영감을 주었다. 정확히는, NNN 개의 random 하게 초기화된 prompt representation 을 각각 독립적으로 최적화한다. inference 단계에서, 모든 prompt representation 의 예측 확률 값을 계산하고 평균화하여 최종 예측 확률값을 만든다.","s":"Prompt Representation Ensemble","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#prompt-representation-ensemble","p":1195},{"i":1230,"t":"ResNet-50 이 있는 CLIP 을 베이스라인으로 UPL 에 적용한다. 결과는 Figure 5 에서 볼 수 있다. CLIP 의 여러 vision encoder 는 다양한 카테고리에 대한 성능을 가지고 있어, pseudo label 의 퀄리티를 향상시키기 위해 저자는 ResNet-101, ResNet50x4, ResNet50x16, ResNet50x64, ViT-B/32, ViT-B/16 및 ViT-L/14 를 포함하는 다양한 vision 아키텍처의 추가적인 CLIP 모델을 사용한 UPL* 이라는 향상된 버전을 정의했다. Pseudo label 에만 다양한 비전 아키텍처를 사용했기 때문에 UPL* 은 여전히 UPL 과 같은 아키텍처 (CLIP with ResNet-50)을 사용한다.","s":"Vision-language Models","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#vision-language-models-1","p":1195},{"i":1232,"t":"CLIP 에선 ImageNet 에 대해 80 개의 hand-crafted prompt 로 inference 를 설계한다. CLIP 으로 pseudo label 생성된 모든 prompt 를 수반하면 prompt engineering 을 피하는 것이 불리해진다. 따라서, 가장 간단한 prompt 를 사용하여 pseudo label 을 생성한다. 예로, ImageNet 에선 \"a photo of a [CLS]\" prompt 를 사용한다. 그리고 클래스 당 top-16 confident sample 을 하여 prompt representation 을 최적화한다.","s":"Pseudo Label Generation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#pseudo-label-generation-2","p":1195},{"i":1234,"t":"prompt representation 은 zero-mean 가우시안분포와 0.02 표준 편차로 무작위 초기화한다. 식 3 에서 length L=16L = 16L=16 을 설정한다. 그리고 16 개 prompt representation 을 앙상블한다.","s":"Learnable Prompt Representation","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#learnable-prompt-representation-1","p":1195},{"i":1236,"t":"SGD lr 0.002 cosine decay learning rate schedular 50 epoch 32 batch size warm up in the first epoch with lr 1e-5","s":"Training Details","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#training-details","p":1195},{"i":1238,"t":"11 개의 image classification dataset ImageNet Caltech101 DTD EuroSAT FGVCAircraft Food101 Flowers102 OxfordPets SUN397 StandfordCars UCF101","s":"Dataset","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"#dataset","p":1195},{"i":1240,"t":"11 데이터셋에 대한 결과는 위 테이블 1 에서 확인할 수 있다. 저자의 approach 와 다른 모델들을 비교한다. 기존 CLIP 의 prompt engineering supervised method (CoOp, Tip-Adapter) UPL 은 prompt engineering 을 피할 뿐만 아니라 CLIP 보다 4.2 point 성능이 더 좋았다. ResNet-50 의 single CLIP 을 사용하면서 pseudo-labeling 에서 여러 CLIP 모델을 사용하여 정확도를 68.37 로 boost 하였다. 또한 8-shot 의 CoOp 이나 Tip-Adapter 와 경쟁력있는 성능을 보인다.","s":"Main Results","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195},{"i":1242,"t":"처음으로 unsupervised prompt learning UPL 을 도입하여 prompt engineering 을 피하며 CLIP 의 transfer 성능을 끌어올린다. CoOp, CLIP-adapter 및 TIP-Adapter 같은 supervised approach 보다 좋은 성능을 가진다.","s":"Conclusion","u":"/docs/Paper/Computer Vision/Vision-Language/UPL","h":"","p":1195}],"index":{"version":"2.3.9","fields":["t"],"fieldVectors":[["t/3",[0,9.533,1,10.23,2,9.533,3,9.533,4,9.533,5,7.917,6,7.917,7,7.917,8,7.917,9,7.917,10,7.917,11,7.917,12,7.917,13,7.917,14,7.917,15,7.917,16,7.917,17,7.917]],["t/5",[0,10.692,1,11.089,2,10.692,3,10.692,4,10.692,5,9.655,6,9.655,7,9.655,8,9.655,9,9.655,10,9.655,11,9.655,12,9.655,13,9.655,14,9.655,15,9.655,16,9.655,17,9.655,18,2.317,19,2.317,20,1.777,21,3.376,22,3.502,23,1.777,24,0.038,25,2.317,26,2.701,27,2.112,28,1.335,29,2.469,30,2.317]],["t/7",[21,7.888,22,8.182,23,5.732,24,0.074,31,6.357,32,4.959,33,5.732,34,4.083,35,7.472,36,7.964,37,6.357,38,7.104,39,6.811,40,5.497,41,7.964,42,8.711,43,7.964,44,8.711,45,8.711,46,8.711,47,7.964]],["t/9",[21,9.155,22,8.113,23,4.821,31,5.347,32,5.351,33,4.821,34,3.434,35,6.285,38,5.975,48,6.699,49,6.699,50,5.193,51,4.624,52,6.859,53,8.061,54,4.305,55,6.699,56,5.729,57,7.327,58,6.699,59,4.933,60,7.327,61,7.665,62,9.398,63,6.486,64,7.327,65,7.327,66,7.327,67,6.285,68,6.699,69,2.523,70,5.347,71,6.699,72,7.327,73,7.327,74,7.327,75,6.699,76,7.327]],["t/11",[32,5.513,77,7.299,78,9.682,79,7.896,80,4.031,81,8.852]],["t/13",[32,5.441,40,6.031,82,7.794,83,4.949,84,6.774,85,9.557,86,9.557,87,9.557]],["t/15",[88,10.93,89,6.644,90,9.375,91,9.375,92,8.571,93,9.375,94,9.375,95,9.375,96,5.804,97,8.041]],["t/17",[23,5.323,32,5.695,56,6.325,83,4.189,84,5.734,92,7.396,97,6.939,98,3.091,99,9.928,100,4.944,101,6.598,102,4.473,103,7.3,104,10.372,105,5.904,106,7.396,107,8.09,108,7.396,109,5.734,110,1.318,111,8.09,112,9.146,113,7.396,114,4.606,115,8.09,116,8.09,117,6.939]],["t/19",[30,6.511,32,4.322,40,4.79,53,6.511,82,7.84,84,6.813,101,6.191,103,7.699,104,8.788,105,7.015,108,8.788,112,6.94,117,6.511,118,8.788,119,9.613,120,9.613,121,8.245,122,7.591,123,7.84,124,6.94,125,6.511,126,7.591,127,6.191,128,5.722,129,4.46,130,5.722,131,6.94,132,7.591,133,6.94,134,5.54,135,6.511,136,5.38,137,6.511,138,6.94,139,7.591,140,7.591]],["t/21",[24,0.104,141,9.682]],["t/23",[24,0.108,54,4.602,142,5.716,143,4.943,144,5.044,145,7.161,146,5.716,147,5.551,148,5.405,149,4.107,150,3.671,151,6.718,152,5.405,153,2.155,154,3.96,155,2.214,156,6.124]],["t/25",[24,0.109,146,3.515,147,4.992,148,3.324,151,6.042,152,4.861,153,1.938,157,4.403,158,1.596,159,2.785,160,1.174,161,4.403,162,4.403,163,4.816,164,2.558,165,2.591,166,4.816,167,2.039,168,1.647,169,3.604,170,1.738,171,3.039,172,4.131,173,3.324,174,3.515,175,3.631,176,1.813,177,4.131,178,4.403,179,2.982,180,2.982,181,4.816,182,4.816,183,3.766,184,4.816,185,1.703]],["t/27",[24,0.109,69,2.158,143,3.956,144,4.037,146,4.575,152,5.852,153,1.724,160,1.529,161,5.731,162,5.731,171,5.352,178,5.731,186,6.269,187,3.956,188,5.731,189,6.269,190,3.418,191,4.859,192,6.269,193,2.091,194,6.269,195,4.326,196,4.725,197,6.269,198,3.418,199,2.853,200,2.527,201,3.133,202,3.329,203,4.443,204,1.568]],["t/31",[24,0.109,171,4.67,177,6.348,205,7.4,206,7.4,207,2.201,208,1.497]],["t/33",[24,0.109,54,5.238,148,6.153,158,2.238,171,5.627,172,7.647,174,7.282,175,8.315,203,6.319,209,6.177,210,8.916,211,6.757,212,2.681,213,6.757,214,2.389,215,6.757]],["t/35",[24,0.109,147,6.516,171,5.802,173,6.344,216,4.304,217,6.074,218,7.081,219,3.353]],["t/38",[24,0.109,28,3.021,146,4.461,148,4.218,160,1.491,171,5.261,174,4.461,175,6.284,176,2.301,193,1.813,195,4.218,198,5.173,204,1.529,209,5.589,214,2.161,220,4.333,221,4.913,222,4.116,223,4.461,224,5.243,225,6.113,226,3.246,227,4.985,228,4.985,229,6.113,230,2.988,231,2.837,232,2.611,233,4.333,234,5.589,235,6.113,236,2.464,237,4.333,238,6.113,239,5.243,240,5.243]],["t/40",[24,0.109,142,5.777,171,6.229,174,5.777,175,8.107,214,2.799,224,6.79,228,6.456,241,7.238,242,7.238]],["t/42",[24,0.108,80,3.332,142,7.887,173,5.522,219,3.789,226,4.249,228,8.103,243,8.002,244,8.002]],["t/44",[24,0.108,142,6.175,146,6.175,147,5.997,152,5.839,153,2.328,193,1.841,220,5.997]],["t/47",[24,0.109,54,6.539,152,4.382,153,1.747,154,3.211,155,1.795,156,4.965,245,8.554,246,5.989]],["t/49",[24,0.109,152,3.401,153,1.356,158,1.633,196,3.715,214,2.983,222,4.823,230,2.409,246,3.051,247,3.597,248,4.929,249,4.02,250,9.263,251,4.929,252,4.228,253,5.228,254,4.208,255,4.929,256,2.522,257,7.238,258,4.929,259,4.929,260,4.929,261,2.944,262,2.765,263,4.228,264,3.715,265,4.506,266,4.929,267,4.228,268,1.956,269,4.929,270,4.929,271,4.929,272,4.929,273,4.929,274,4.929,275,4.929,276,4.929,277,4.929,278,4.929,279,4.02]],["t/53",[24,0.107,54,4.082,80,2.893,152,4.794,153,1.911,164,3.689,171,4.384,176,2.616,179,5.622,180,4.301,236,2.8,253,5.07,254,4.082,267,5.959,280,6.948,281,6.948,282,6.352,283,5.959,284,6.948,285,6.352,286,3.513,287,7.405,288,6.77,289,7.405,290,6.948,291,5.666,292,5.237,293,6.352,294,6.948,295,5.237,296,6.948,297,6.948,298,5.959,299,5.666,300,4.678,301,6.948,302,6.948,303,6.948,304,6.352]],["t/55",[24,0.108,142,7.478,171,5.309,188,7.691,257,8.789,305,4.864,306,7.691,307,8.413,308,5.806,309,7.691,310,7.691]],["t/58",[24,0.109,63,5.238,180,4.699,214,2.684,283,6.511,311,7.591,312,7.591,313,6.94,314,6.511,315,5.935,316,3.711,317,2.879,318,6.511,319,3.595]],["t/60",[24,0.107,169,4.457,203,6.174,320,8.711,321,7.221,322,7.964,323,8.711,324,8.711]],["t/63",[24,0.105,28,3.955,164,4.249,180,6.151,207,2.38,208,1.619,230,3.912,246,4.954,268,3.175,283,6.864,288,6.271,295,6.032,325,8.523,326,4.196,327,4.489,328,8.002,329,8.002,330,6.257,331,7.316,332,5.84,333,5.266,334,6.032,335,8.002,336,8.002,337,6.032]],["t/65",[24,0.107,142,6.433,310,8.059,321,6.083,325,7.561,327,4.945,338,8.815,339,8.815,340,7.561]],["t/68",[24,0.1,142,7.113,171,6.151]],["t/72",[24,0.104,152,6.638,153,2.646]],["t/74",[24,0.105,54,5.579,155,2.685]],["t/76",[24,0.108,146,5.686,147,5.522,151,6.683,153,2.688,155,2.203,156,6.091,160,1.9,171,6.167,174,5.686,175,5.873,193,1.695,220,5.522,308,5.377,341,7.791]],["t/78",[19,4.898,23,3.758,28,5.465,50,4.048,54,6.332,69,3.711,109,4.048,144,3.678,145,5.221,146,4.168,147,5.638,148,3.941,149,2.994,152,3.941,153,1.571,154,2.888,155,1.615,156,4.465,158,1.892,168,1.953,171,3.604,172,4.898,173,5.489,174,5.805,175,7.462,177,4.898,179,3.536,193,2.264,195,3.941,196,4.305,214,2.812,220,4.048,222,7.008,224,4.898,241,5.221,242,5.221,253,5.805,265,7.272,267,6.823,286,2.888,342,3.678,343,4.657,344,2.65,345,7.272,346,5.711,347,5.292,348,6.514,349,5.221,350,5.711,351,9.154,352,7.955,353,5.711,354,3.536,355,7.955,356,7.955,357,6.823,358,4.898,359,2.922,360,5.711,361,5.711,362,5.221,363,5.711,364,5.711,365,3.845,366,4.048,367,4.657]],["t/80",[80,3.737,114,5.11,149,4.706,176,3.379,179,5.557,236,3.618,285,8.206,287,7.32,288,5.664,289,7.32,292,8.031,293,8.206,295,6.766,368,8.206,369,8.206,370,8.976,371,8.976]],["t/82",[24,0.104,372,9.682]],["t/84",[24,0.108,144,5.387,150,3.921,169,4.28,170,3.977,373,4.23,374,1.288,375,4.938,376,5.773]],["t/86",[24,0.11,129,2.64,150,2.106,153,1.236,159,2.598,167,1.903,168,2.289,170,2.885,180,2.782,187,4.223,373,2.272,376,4.618,377,2.173,378,4.494,379,7.248,380,5.207,381,3.854,382,3.279,383,2.128,384,2.558,385,2.197,386,4.494]],["t/88",[24,0.109,34,2.458,159,3.032,167,4.756,169,2.683,170,3.153,180,4.637,376,6.578,377,5.432,382,3.827,387,4.277,388,3.451,389,3.531,390,5.244,391,5.244,392,4.498,393,5.244,394,4.1,395,4.794,396,4.277,397,4.277]],["t/91",[24,0.109,102,2.436,158,0.877,165,1.424,167,1.865,168,2.255,170,2.851,176,1.658,185,0.936,193,0.958,199,2.575,207,1.31,208,0.891,214,3.409,216,1.609,220,1.877,231,3.397,237,1.877,249,2.159,262,3.173,321,3.04,373,1.339,377,1.28,388,2.899,389,4.929,398,1.886,399,3.796,400,4.027,401,2.5,402,4.613,403,2.648,404,2.648,405,2.648,406,3.593,407,2.648,408,3.444,409,4.405,410,3.04,411,2.966,412,2.648,413,2.648,414,2.648,415,2.07,416,2.648,417,2.648,418,2.648,419,2.648,420,0.811,421,5.172,422,3.001,423,3.444,424,1.424,425,1.323,426,2.648,427,2.648,428,2.679,429,4.405,430,1.582,431,1.333,432,4.62,433,1.783,434,4.55,435,4.892,436,1.671,437,2.159,438,4.405,439,3.122,440,1.877,441,2.648,442,2.648,443,2.648,444,2.648,445,2.648,446,4.405,447,2.648,448,2.648,449,2.648,450,2.648,451,2.648,452,4.405,453,2.648,454,2.648,455,2.648,456,2.648,457,2.648,458,2.648,459,2.648,460,2.648,461,2.648,462,2.648,463,2.648,464,4.405,465,2.648,466,2.648,467,2.648,468,2.648,469,2.648,470,2.648,471,2.648,472,2.648,473,2.648,474,2.648,475,2.648,476,1.034]],["t/93",[24,0.109,129,4.101,167,2.956,169,3.571,170,2.519,207,2.076,208,1.412,376,6.286,377,3.376,379,5.094,380,3.66,399,3.586,402,8.269,434,4.817,435,6.277]],["t/95",[24,0.108,34,4.965,69,2.316,102,5.505,160,1.64,170,2.427,214,3.143,376,6.871,389,7.416,394,8.281,399,3.5,401,3.371,406,7.249,477,5.07,478,6.95,479,6.149]],["t/97",[24,0.109,28,2.913,168,2.016,169,4.159,193,2.183,207,2.768,208,1.883,231,2.735,261,3.521,263,5.055,349,5.388,374,0.907,379,4.301,380,3.09,389,3.968,399,3.201,401,2.235,402,4.806,425,2.946,431,3.036,432,3.719,435,5.033,480,3.251,481,3.648,482,5.893,483,5.893,484,5.055,485,3.407,486,2.881]],["t/99",[24,0.099,169,4.954,187,6.11,477,7.299]],["t/102",[24,0.104,69,3.547,129,4.241,153,1.986,180,6.739,193,1.57,325,7.985,374,1.111,381,6.192,383,4.879,396,5.888,397,5.888,487,3.583,488,7.219,489,7.219,490,5.645,491,7.219,492,7.219,493,7.219,494,4.469,495,6.192,496,5.442,497,7.219,498,7.219,499,7.219,500,7.985,501,6.6,502,7.219,503,6.192,504,5.645,505,3.834,506,5.117,507,7.219,508,7.219,509,7.219,510,5.645,511,7.219]],["t/104",[24,0.109,34,2.616,148,3.852,153,1.535,158,2.593,164,2.964,165,4.212,168,1.909,169,4.626,176,2.947,183,4.364,187,4.94,214,1.973,222,6.087,344,3.633,376,3.852,383,2.643,389,6.949,394,4.364,401,3.429,420,2.397,424,3.003,477,4.207,479,5.103,486,4.42,512,2.268,513,2.286,514,5.103,515,5.581,516,4.073,517,3.393,518,4.552,519,7.828,520,2.181]],["t/106",[24,0.103,28,4.961,160,1.984,164,5.33,169,5.135,183,6.36,187,5.134,193,1.77,207,2.419,208,1.646,236,3.279,288,5.134,330,7.848,521,7.437,522,6.36,523,8.135,524,8.135,525,8.135,526,8.135,527,8.135,528,5.239,529,6.977,530,8.135,531,6.977]],["t/108",[24,0.108,54,4.626,207,2.342,208,1.593,262,4.417,422,3.584,476,3.077,532,3.3,533,3.029,534,3.485,535,7.874,536,7.874,537,7.874,538,6.754,539,5.936]],["t/110",[24,0.108,150,3.711,169,5.05,171,4.996,183,6.19,344,3.674,376,5.463,504,6.19,512,3.216,518,6.456,531,6.79,540,6.79,541,4.05,542,6.456,543,6.79,544,7.917]],["t/112",[24,0.109,54,3.329,148,3.911,153,2.176,169,2.899,180,4.898,187,4.993,193,1.721,207,1.685,208,1.147,236,2.284,253,4.136,262,3.179,288,3.576,317,2.149,379,5.774,380,4.148,382,6.652,383,3.747,396,4.622,397,7.434,431,2.394,532,1.901,533,1.745,545,4.861,546,5.667,547,5.667,548,5.667]],["t/114",[24,0.108,169,5.504,170,2.262,179,6.865,183,7.514,187,3.956,193,2.412,431,3.355,477,6.392,518,6.916,531,5.377,549,6.269,550,6.269,551,6.269,552,6.269,553,8.48,554,8.832,555,6.269,556,7.274,557,6.392,558,7.753,559,5.71,560,6.269,561,6.269,562,6.269]],["t/116",[24,0.109,69,1.506,102,2.418,129,2.57,148,3.018,149,2.293,167,4.317,168,2.243,169,4.026,170,2.367,221,2.265,236,1.763,262,2.453,376,5.43,377,3.171,389,4.416,399,3.871,400,3.999,402,3.567,432,4.139,435,4.871,534,4.144,558,5.996,563,7.868,564,3.297,565,2.238,566,6.749,567,3.1,568,4.374,569,4.374,570,5.128,571,7.868,572,7.868]],["t/118",[24,0.107,153,2.201,169,5.529,176,3.013,180,4.954,373,4.046,374,1.232,377,5.226,389,5.388,424,4.305,541,5.782,557,6.032,573,5.024,574,8.002]],["t/120",[24,0.109,69,2.486,147,5.117,169,4.763,170,2.605,193,2.025,201,3.609,202,3.834,377,3.491,379,5.269,380,3.785,382,5.269,389,4.861,397,5.888,401,2.738,428,2.642,431,2.817,541,4.763,575,3.031]],["t/122",[24,0.104,576,9.682]],["t/124",[24,0.109,69,1.793,110,1.214,200,2.099,201,3.725,202,2.765,305,4.309,319,3.529,373,2.633,374,1.751,375,4.209,385,3.643,398,1.736,401,1.975,520,2.035,573,2.633,577,4.466,578,6.078,579,3.8,580,3.353,581,3.925,582,2.802,583,3.353,584,2.243,585,2.696,586,4.466,587,3.426]],["t/126",[24,0.109,69,2.484,110,0.959,144,2.447,170,1.371,200,2.908,201,4.062,202,3.831,212,1.508,305,3.406,317,1.441,319,2.79,374,1.749,375,3.93,385,3.527,401,2.234,425,1.899,432,3.718,520,2.819,532,1.275,573,1.921,575,1.595,577,3.259,578,5.884,579,2.773,580,2.447,582,3.169,583,4.646,584,2.538,587,3.876,588,3.8,589,1.184,590,1.651,591,1.746,592,1.441,593,2.693,594,3.8,595,1.531,596,2.5,597,3.169]],["t/128",[24,0.107,69,2.77,176,3.029,200,3.243,201,4.983,202,4.273,305,4.652,374,1.743,375,3.891,420,2.463,577,6.901,582,4.329,583,5.182,584,3.466,587,5.294,598,8.046]],["t/130",[24,0.109,69,1.875,80,1.431,185,2.72,200,3.38,201,3.38,202,3.591,214,1.925,316,1.68,317,2.065,319,1.627,374,1.184,385,1.68,398,2.565,401,2.065,420,1.052,425,1.718,481,2.128,505,1.825,520,2.642,573,2.753,578,4.441,579,3.974,580,3.507,582,3.638,583,6.02,584,2.913,585,2.82,587,4.45,589,1.071,593,2.436,599,2.948,600,3.437,601,3.437,602,2.948,603,3.437,604,3.437,605,3.437,606,3.437,607,3.437,608,6.599,609,3.437,610,3.437,611,3.437,612,3.437,613,5.445,614,5.445,615,3.437,616,3.437,617,3.437,618,3.437,619,3.437,620,3.437,621,3.437,622,1.022,623,2.019]],["t/132",[24,0.109,69,3.253,110,1.539,170,1.612,200,1.8,201,2.232,214,1.579,236,1.8,261,2.668,319,2.115,374,1.36,375,2.16,398,2.656,401,3.022,420,2.04,428,2.915,430,3.98,433,3.007,520,3.692,534,3.526,624,3.494,625,4.466,626,4.466,627,4.466,628,2.939,629,4.466,630,4.466,631,2.876,632,4.466,633,4.466,634,4.05,635,2.765,636,4.466]],["t/134",[24,0.108,69,3.053,374,1.628,401,3.363]],["t/136",[24,0.109,69,3.342,246,4.773,374,1.494,401,2.924,487,3.736,637,5.191]],["t/138",[24,0.109,69,3.057,83,2.795,164,4.714,185,1.908,214,1.908,236,3.892,246,4.733,268,2.142,319,2.556,367,4.402,374,1.765,401,2.047,637,5.977,638,2.83,639,3.779,640,5.398,641,3.939]],["t/140",[24,0.109,80,1.948,110,0.762,198,2.551,201,2.339,202,2.485,212,1.856,316,2.287,374,1.391,398,2.73,401,1.774,520,1.828,573,4.569,579,5.032,580,4.441,581,3.527,582,2.517,583,4.441,584,2.016,585,2.423,608,5.915,622,1.391,628,3.079,642,4.679,643,4.679,644,4.679,645,2.423,646,3.816,647,4.679,648,4.679,649,4.679,650,8.189,651,3.658]],["t/143",[24,0.109,169,2.683,170,2.703,176,1.974,179,3.247,200,3.522,201,2.621,202,2.785,212,2.081,295,3.953,317,1.989,327,2.942,330,4.1,374,1.153,375,2.536,398,1.748,425,2.621,428,1.919,487,2.018,490,4.1,532,2.513,573,2.652,579,3.827,580,3.377,582,4.03,583,3.377,584,2.259,602,4.498,622,1.56,623,3.081,624,2.3,638,2.749,652,5.244,653,4.794,654,5.244,655,5.052,656,4.794,657,3.953,658,4.794,659,3.827,660,3.619,661,5.244,662,5.244,663,2.703,664,3.827,665,4.1,666,5.244,667,5.244,668,5.244,669,5.244,670,4.794,671,5.244,672,6.848,673,2.034,674,4.794]],["t/145",[24,0.109,219,3.729,246,4.875,398,2.625,401,2.986,425,3.936,658,8.993,675,7.874]],["t/147",[24,0.109,110,1.285,200,2.275,226,2.998,573,2.854,582,3.037,593,5.593,608,4.842,665,4.414,672,5.161,674,5.161,676,3.317,677,4.885,678,2.96,679,6.169,680,4.604,681,6.768,682,5.645]],["t/149",[24,0.109,160,1.302,200,2.152,201,2.669,214,1.888,236,2.152,319,2.528,401,2.025,528,3.438,579,5.537,580,4.886,582,2.872,583,3.438,593,6.811,602,4.579,638,2.799,657,4.025,679,6.9,680,4.354,681,6.507,683,5.339,684,4.174,685,4.354,686,3.087,687,3.246,688,4.881,689,5.339]],["t/151",[24,0.107,69,2.848,200,3.334,201,5.069,202,4.392,236,4.087,374,1.273,582,4.45,583,5.327,584,3.563,637,5.569,641,6.036,690,8.271,691,8.271,692,8.271,693,6.467]],["t/153",[24,0.109,69,1.621,129,2.766,160,1.148,167,1.994,170,2.966,185,1.665,200,1.898,201,2.354,202,2.5,212,1.868,216,4.211,222,3.17,253,3.436,254,2.766,319,2.23,374,1.487,376,6.971,385,2.302,428,1.723,513,1.929,573,4.156,583,3.032,584,3.541,590,2.047,694,4.305,695,6.334,696,9.659,697,7.16,698,4.039,699,6.928,700,4.305,701,4.709,702,4.305,703,4.709,704,4.039,705,3.337,706,6.928]],["t/155",[24,0.109,69,2.02,149,3.076,160,1.754,176,1.423,200,2.365,201,3.594,202,2.007,212,2.853,214,1.336,236,4.145,268,1.5,319,2.778,374,1.732,385,2.868,436,1.434,582,2.034,583,3.779,584,3.098,593,2.679,641,2.759,681,3.242,693,2.955,707,3.78,708,2.679,709,2.759,710,3.78,711,3.456,712,4.42,713,3.78,714,3.78,715,3.78,716,3.78,717,3.78]],["t/157",[24,0.109,69,1.974,80,2.387,129,3.368,185,2.027,200,3.215,201,4.956,202,4.235,226,3.044,374,1.604,436,3.025,512,2.329,559,3.86,582,4.291,583,5.137,584,3.952,655,3.315,712,4.35]],["t/159",[24,0.11,69,1.353,110,0.985,150,1.843,160,1.475,202,2.087,212,1.56,216,2.39,319,1.862,374,1.561,375,2.925,385,1.922,401,2.294,436,1.491,520,1.536,575,1.65,579,2.869,580,2.532,582,2.115,583,2.532,585,2.036,587,2.587,622,1.169,657,2.963,660,4.173,663,1.419,718,2.273]],["t/161",[24,0.104,719,9.682]],["t/163",[24,0.109,150,2.989,153,1.754,185,2.255,207,1.897,208,1.29,375,4.688,436,2.418,532,2.14,533,1.964,589,3.021,720,2.848,721,6.194,722,4.443,723,5.287,724,2.511]],["t/165",[24,0.109,69,2.68,149,3.393,160,1.048,193,0.935,199,1.956,201,2.148,202,2.282,204,1.075,219,2.035,313,3.929,317,1.63,354,2.66,359,3.311,375,4.723,431,1.3,436,2.952,494,2.66,542,3.505,567,3.046,582,2.312,584,2.788,589,2.017,590,2.813,591,2.974,592,2.454,663,1.551,686,2.485,720,3.477,721,4.651,722,3.352,723,5.068,724,3.411,725,2.712,726,4.297,727,3.929,728,3.136,729,3.505,730,3.239,731,2.312,732,3.685,733,4.168,734,2.447]],["t/169",[24,0.108,34,3.424,69,1.744,98,1.935,150,2.374,159,2.928,160,2.09,165,2.725,167,2.144,170,1.827,200,2.944,201,3.651,202,2.689,317,3.25,359,2.591,375,4.536,398,1.688,401,2.77,420,1.55,428,2.673,436,3.772,520,2.854,539,3.817,564,5.507,567,3.589,589,3.099,590,2.201,622,1.506,624,3.203,663,1.827,676,2.975,720,4.189,721,5.604,723,3.984,724,1.994,725,3.196,729,4.13,730,3.817,733,3.261,735,5.064,736,4.63,737,3.817,738,2.762,739,4.63,740,2.762,741,3.959,742,4.13,743,4.344,744,4.13,745,2.025]],["t/171",[24,0.109,160,1.141,170,2.488,193,1.018,200,1.886,202,2.485,204,1.17,226,2.485,231,3.2,236,2.779,237,4.887,317,3.427,359,2.394,375,3.96,399,1.842,411,3.15,428,1.712,431,1.416,481,2.897,494,4.269,567,4.887,580,3.013,589,1.458,622,2.051,645,2.423,663,2.488,676,2.749,720,4.303,721,2.795,722,2.423,723,5.833,724,1.842,731,2.517,732,4.662,733,5.273,734,2.664,736,6.304,741,3.658,746,4.679,747,4.679,748,4.013,749,4.679,750,4.679,751,4.278,752,4.013,753,4.679,754,4.679,755,4.013,756,4.679,757,4.679,758,4.679,759,4.679,760,2.587,761,4.679,762,4.679,763,4.679,764,4.679,765,4.278]],["t/174",[24,0.109,69,2.079,80,2.514,148,6.996,158,2.739,168,3.467,169,3.089,170,2.179,176,2.273,190,3.293,200,2.434,212,2.396,317,3.135,375,2.92,399,3.991,435,3.738,494,3.738,564,6.231,582,4.448,663,2.983,665,4.721,676,3.547,720,2.697,723,4.508,732,3.438,766,6.038]],["t/176",[24,0.109,34,4.308,153,1.583,167,3.386,256,2.945,375,2.783,377,3.868,389,3.875,399,3.149,406,4.694,420,1.762,421,8.403,428,2.106,436,3.486,589,1.794,624,2.524,663,2.077,708,4.079,720,4.436,723,5.416,724,2.266,730,4.338,738,3.139,767,6.86,768,5.755,769,5.491,770,3.438]],["t/178",[24,0.109,34,3.919,102,4.623,167,2.599,168,2.1,170,2.215,173,4.236,216,3.731,236,2.474,262,3.443,375,4.597,385,3.001,388,4.039,420,2.559,436,2.328,439,4.351,440,4.351,538,5.265,589,3.181,595,2.474,624,2.692,720,2.742,722,3.179,738,3.347,765,5.612,771,6.536,772,9.332,773,5.265,774,5.006,775,6.138]],["t/180",[24,0.108,34,2.819,69,2.07,98,2.297,374,0.926,375,2.908,398,2.005,428,3.016,430,3.592,436,3.126,584,2.591,589,2.569,590,2.614,622,2.452,624,3.615,628,3.957,631,6.058,639,2.972,660,5.689,720,4.201,721,3.592,776,4.262,777,6.214,778,6.013,779,6.013,780,6.013,781,6.013,782,6.013,783,6.013,784,6.013,785,4.533,786,4.262,787,4.533,788,4.904,789,4.15,790,3.795,791,5.498,792,6.013,793,6.013]],["t/183",[24,0.108,169,4.763,344,4.32,375,3.491,428,2.642,513,3.813,557,5.442,564,5.442,589,2.25,624,3.166,663,2.605,721,4.313,723,3.937,760,3.992,767,6.192,794,7.219,795,5.117,796,5.442,797,6.6,798,7.219,799,6.192,800,6.6]],["t/186",[24,0.106,69,3.456,431,2.461,566,6.977,584,4.897,590,3.536,655,4.703,722,4.212,729,8.186,801,7.437,802,9.177,803,7.437,804,8.135,805,6.36,806,8.135,807,8.135,808,8.135]],["t/188",[24,0.109,101,6.487,159,3.302,160,1.94,185,2.019,204,1.99,207,1.698,208,1.156,222,5.356,236,2.302,240,4.898,286,2.888,288,3.604,319,2.704,595,3.206,637,5.356,639,2.823,809,4.305,810,5.711,811,5.711,812,4.048,813,7.851,814,7.955,815,7.272,816,5.221,817,5.711,818,4.657,819,4.657]],["t/190",[24,0.109,28,4.227,69,2.944,110,0.822,134,5.318,158,1.672,198,3.974,199,2.297,207,1.501,373,2.552,398,1.683,420,1.545,584,3.139,622,1.501,624,2.213,628,3.321,631,3.25,646,8.1,820,5.047,821,4.614,822,2.918,823,5.758,824,6.535]],["t/193",[24,0.107,193,1.779,207,2.433,208,1.655,319,3.873,487,3.148,584,4.339,590,3.555,645,4.236,655,5.823,738,4.461,789,5.645,801,7.478,825,6.395,826,5.162,827,7.478,828,6.395,829,6.166]],["t/195",[24,0.108,69,2.711,176,2.965,207,2.342,208,1.593,533,2.425,584,4.238,595,3.174,721,5.876,827,7.199,830,3.485,831,3.55,832,7.199,833,7.874]],["t/197",[24,0.109,169,4.206,176,2.255,180,3.708,199,2.726,207,1.781,208,1.212,317,2.271,321,4.133,374,0.922,375,2.896,425,2.993,532,3.39,533,3.111,584,3.541,628,3.941,631,3.857,639,2.96,659,4.371,721,3.578,723,3.266,741,4.682,830,2.65,834,4.514,835,3.578,836,5.999,837,2.494,838,5.989]],["t/199",[24,0.109,190,4.294,268,3.124,513,3.225,584,3.392,721,4.704,734,4.483,802,7.199,803,7.199,829,5.936,839,7.874,840,9.837]],["t/202",[24,0.109,720,4.453,722,4.167,723,5.437,724,3.168]],["t/204",[24,0.109,317,2.986,567,6.972,659,5.746,722,4.078,723,5.364,724,3.1,841,6.754,842,5.302]],["t/206",[24,0.109,153,1.957,374,1.095,411,4.79,436,2.698,564,5.363,721,5.509,723,5.029,730,5.363,841,7.91]],["t/209",[24,0.109,28,3.603,168,2.494,170,2.631,428,2.668,433,4.909,439,5.167,440,5.167,624,3.197,772,9.988,843,4.797,844,5.946,845,4.695,846,3.872,847,4.797,848,6.254]],["t/211",[24,0.109,216,4.454,420,2.243,564,7.085,721,4.377,733,4.719,767,9.389,843,4.821,844,5.975,845,4.719,846,4.991]],["t/213",[24,0.109,159,4.279,193,2.058,207,2.813,208,1.914,374,1.139,431,2.862,480,2.959,724,2.914,849,5.935,850,7.4]],["t/215",[24,0.107,69,3.616,199,3.988,584,3.775,721,5.235,734,4.989,822,5.066,851,4.38]],["t/217",[24,0.108,110,1.394,532,2.872,533,3.189,595,3.45,721,5.113,837,4.311,852,8.559]],["t/219",[24,0.108,193,2.176,202,4.296,317,3.068,431,3.027,676,5.877,721,4.833,723,5.455]],["t/221",[24,0.109,34,3.577,428,2.792,436,2.894,663,2.753,720,3.408,721,5.761,723,5.766,737,5.751]],["t/223",[24,0.109,158,2.609,200,3.174,201,3.936,317,2.986,721,4.704,722,4.078,723,4.294,853,7.874]],["t/225",[24,0.103,854,9.557,855,9.557,856,9.557]],["t/227",[24,0.108,110,1.443,150,3.138,158,2.936,230,3.273,342,4.312,374,1.031,673,2.596,678,3.51,857,6.467,858,6.68,859,4.225,860,5.168,861,6.695,862,3.572,863,5.743,864,4.886,865,4.886,866,4.886,867,6.695,868,6.121,869,3.171,870,4,871,3.756,872,4.145,873,4.745,874,3.347,875,4.745,876,2.636]],["t/229",[24,0.109,83,1.928,110,1.623,150,1.745,153,1.024,160,1.414,193,0.81,212,1.477,230,1.82,246,2.305,342,2.398,374,1.341,420,2.18,517,3.525,520,2.783,532,2.923,533,2.193,592,1.412,663,1.343,664,4.231,673,2.762,831,2.614,837,1.55,857,4.231,858,4.371,859,2.349,860,4.259,862,2.87,864,5.197,865,4.231,866,5.197,869,1.763,870,2.224,871,2.088,872,2.305,873,2.639,874,1.861,875,2.639,877,1.775,878,2.911,879,3.723,880,3.404,881,1.82]],["t/231",[24,0.109,110,1.292,214,2.011,230,4.831,342,3.664,374,1.221,436,3.009,532,2.662,533,2.443,592,2.157,830,2.517,859,5.007,860,2.781,864,4.152,865,4.152,866,4.152,869,5.231,870,3.398,873,4.032,874,2.843,877,1.742,878,4.448,882,4.288]],["t/233",[24,0.106,110,1.402,150,4.036,204,2.154,374,1.599,575,3.615,673,3.338,860,4.208,864,6.283,869,4.077,872,5.33,875,6.102,877,3.181]],["t/236",[24,0.104,342,7.604,873,7.851,874,5.902,875,5.997,883,8.461,884,8.461,885,7.735,886,9.401,887,7.257]],["t/238",[24,0.102,110,1.489,214,3.232,420,2.799,517,5.558,520,3.572,532,3.067,533,2.815,718,5.286,830,4.046,837,3.807]],["t/240",[24,0.108,110,1.199,176,2.772,214,2.603,343,6.005,532,3.163,533,2.903,678,4.943,830,3.259,831,3.32,869,4.925,870,6.551,885,8.62,888,4.559,889,6.732,890,4.192]],["t/242",[24,0.108,80,3.864,158,2.38,212,2.851,624,3.151,641,5.243,862,2.896,870,5.544,871,4.03,872,4.448,876,2.829,891,6.568,892,6.162,893,6.568,894,4.09,895,7.96,896,7.184,897,6.162,898,8.484,899,7.184,900,6.162,901,5.617,902,6.568,903,7.184,904,7.184,905,8.037]],["t/244",[24,0.109,110,1.497,150,2.272,160,1.726,185,1.714,219,2.296,230,2.37,374,1.089,575,2.035,673,1.88,677,4.381,862,2.853,869,5.116,871,5.155,872,4.381,875,5.016,876,1.909,887,4.158,895,4.158,900,4.158,901,5.533,906,4.432,907,2.574,908,3.001]],["t/246",[24,0.107,110,1.76,843,6.053,869,4.356]],["t/248",[24,0.109,80,2.92,110,1.655,230,4.466,342,4.517,487,2.699,830,3.104,869,4.327,875,4.971,908,4.342,909,9.137,910,4.615]],["t/250",[24,0.109,160,1.778,230,3.564,305,4.215,398,2.431,859,5.912,869,4.902,907,3.872,911,4.601,912,7.291]],["t/252",[24,0.109,110,1.545,193,1.618,431,2.251,724,2.928,869,5.212,907,3.95]],["t/254",[24,0.109,110,1.637,158,1.725,193,1.133,226,3.957,342,3.353,411,3.506,517,3.165,532,1.747,533,1.604,638,4.981,659,3.8,678,2.73,830,3.298,860,2.545,864,3.8,869,5.453,870,5.676,873,3.691,874,2.603,875,5.282,877,1.594,887,4.466,895,4.466,900,4.466,907,2.765,913,6.169,914,5.207,915,4.761]],["t/257",[24,0.109,58,7.123,436,2.955,916,7.123,917,7.123,918,7.123,919,5.873,920,5.873,921,5.123,922,7.123,923,7.123]],["t/259",[24,0.108,226,4.159,326,4.107,374,1.206,532,3.289,533,3.019,869,5.068,881,5.231,916,7.161,917,7.161,919,5.904,920,5.904,923,7.161]],["t/261",[24,0.109,110,1.735,374,1.499,517,4.711,869,4.612,871,4.347,872,4.798]],["t/263",[24,0.108,110,1.427,860,4.283,866,6.395,869,4.149,924,6.605]],["t/265",[24,0.102,374,1.49,925,8.852]],["t/267",[24,0.108,282,7.605,359,4.256,374,1.28,926,8.318,927,7.605,928,8.318,929,8.318]],["t/269",[24,0.109,110,1.494,158,2.642,176,2.158,185,2.027,327,3.216,343,4.676,359,2.933,365,3.86,374,1.228,510,4.482,517,3.485,678,3.006,722,2.969,830,3.53,869,4.696,870,3.425,871,3.216,872,3.549,877,1.755,925,5.241,930,5.733,931,5.733,932,5.733,933,5.733,934,5.733,935,4.917,936,4.184,937,5.241,938,4.322]],["t/271",[24,0.109,110,1.547,160,1.27,219,4.122,230,2.545,374,1.147,436,1.975,517,3.165,532,1.747,533,1.604,638,2.73,673,2.019,860,5.113,862,3.004,864,3.8,865,3.8,866,3.8,869,5.216,870,4.452,877,1.594,913,3.691,937,4.761,938,5.618,939,4.761,940,4.761,941,4.071]],["t/273",[24,0.109,38,5.775,98,2.705,110,1.663,153,1.948,204,1.771,208,1.433,219,3.353,230,4.99,342,4.56,379,5.167,859,4.469,860,3.461,869,3.353,874,3.539,880,6.474,886,6.474,915,6.474,942,5.536,943,7.081,944,3.254]],["t/275",[24,0.109,110,1.211,160,1.814,219,4.493,374,1.145,860,5.38,865,5.428,866,5.428,869,4.948,877,2.905,938,5.607,939,6.8,945,7.438]],["t/277",[24,0.103,946,9.495,947,9.495,948,9.495,949,9.495]],["t/279",[24,0.109,110,1.136,160,1.159,193,1.034,268,1.886,344,2.206,374,1.272,506,4.945,532,1.595,533,2.804,578,3.877,589,1.482,590,2.066,591,3.206,592,2.646,595,3.331,673,1.844,686,2.749,720,2.123,822,5.607,824,7.07,829,3.584,836,3.47,862,4.419,870,2.84,950,4.754,951,5.69,952,3.717,953,5.259,954,3.877,955,4.078,956,2.667,957,4.078,958,4.754,959,4.078,960,3.877,961,4.754]],["t/281",[24,0.109,69,2.339,98,0.887,110,0.378,160,1.657,193,1.119,221,1.203,373,1.174,374,1.331,375,3.573,428,1.444,440,1.646,506,1.646,532,1.726,533,2.756,534,1.028,584,1.001,589,2.584,590,1.009,591,2.787,592,1.496,595,3.342,622,0.691,638,1.218,673,1.995,684,1.816,685,1.894,720,2.709,722,1.203,724,0.914,796,1.751,822,5.786,824,5.889,826,1.466,829,1.751,831,1.047,836,2.88,862,3.966,882,3.878,951,6.425,953,5.569,954,3.218,955,3.384,956,1.303,959,1.992,962,2.323,963,1.412,964,1.992,965,1.218,966,2.323,967,3.085,968,4.357,969,1.816,970,1.412,971,2.323,972,1.992,973,1.695,974,2.323]],["t/284",[24,0.109,69,2.45,591,4.238,592,2.698,622,2.116,663,2.567,673,2.759,724,2.801,822,5.916,952,5.563,975,7.115,976,6.505]],["t/286",[24,0.109,110,1.071,268,2.609,374,1.348,398,2.919,415,5.141,420,2.013,436,2.494,476,3.422,589,2.049,634,3.998,660,4.538,663,2.373,720,2.937,822,5.063,862,4.231,977,6.576,978,5.363,979,6.576,980,6.576,981,6.576,982,6.576,983,5.641,984,6.576,985,6.576,986,4.428,987,6.576]],["t/288",[24,0.109,153,1.689,160,2.039,167,2.599,168,2.1,399,2.417,428,2.246,532,2.059,533,1.89,589,2.605,590,4.436,673,3.242,712,3.347,720,2.742,738,4.559,741,4.799,836,4.48,862,4.114,952,4.799,956,3.443,963,5.779,965,3.218,988,6.138,989,5.265]],["t/290",[24,0.109,69,2.131,532,2.077,533,2.94,534,3.721,584,3.622,591,2.845,595,3.389,663,2.234,712,3.375,837,3.975,859,3.906,862,3.389,870,5.704,965,3.245,967,4.84,968,3.423,990,6.19,991,6.19]],["t/292",[24,0.109,69,2.685,110,0.702,374,1.562,422,1.962,532,1.446,533,2.866,581,3.249,587,2.836,589,1.343,590,1.873,591,2.981,592,2.46,595,3.497,663,1.555,673,1.671,720,2.897,822,5.017,837,2.701,859,2.72,862,4.455,870,5.184,882,3.249,951,7.974,953,4.889,957,3.697,968,4.798,973,3.145,992,3.515,993,5.29]],["t/294",[24,0.109,69,2.523,153,2.016,584,4.049,591,4.319,592,3.564,822,4.236,837,3.051,870,4.377]],["t/296",[24,0.109,98,3.649,100,3.713,143,4.742,149,3.939,533,2.314,591,4.825,592,3.622,595,3.028,822,4.344,994,7.513,995,7.513,996,7.513,997,5.059]],["t/298",[24,0.107,69,3.503,200,3.353,591,3.823,592,4.17,882,6.27,998,8.318,999,8.318,1000,8.318,1001,10.176,1002,10.176,1003,8.318,1004,5.6]],["t/300",[24,0.109,69,1.547,80,1.871,110,1.302,117,3.854,143,2.836,153,1.236,160,1.096,344,2.085,374,1.364,420,1.376,584,3.817,589,1.4,591,4.071,592,3.766,622,1.99,663,2.415,673,2.595,720,2.007,822,4.623,837,3.329,862,2.697,870,5.659,951,6.521,968,5.688,997,5.384,1005,2.128,1006,7.31,1007,7.996,1008,4.108,1009,3.665,1010,4.494,1011,4.494,1012,4.494,1013,4.494,1014,4.494,1015,4.494,1016,4.494]],["t/302",[23,2.215,24,0.109,34,1.578,69,2.858,110,0.872,160,0.821,167,1.425,170,1.215,185,1.19,252,4.594,389,3.606,394,2.632,428,1.96,584,4.378,589,1.049,590,1.463,591,4.67,592,1.277,622,1.593,639,1.664,684,2.632,712,1.836,740,2.921,821,3.078,862,2.689,870,2.011,968,1.861,969,2.632,993,2.745,997,2.266,1017,3.078,1018,2.632,1019,3.366,1020,3.366,1021,2.887,1022,3.366,1023,3.366,1024,3.366,1025,3.366,1026,3.366,1027,3.366,1028,8.301,1029,2.887,1030,5.356,1031,5.356,1032,4.897,1033,3.366,1034,3.078,1035,3.366,1036,3.366,1037,1.683,1038,2.266,1039,4.368,1040,2.745]],["t/304",[24,0.109,63,5.004,110,1.613,157,4.583,327,2.812,398,1.671,420,1.535,584,3.67,591,5.106,592,4.213,622,1.491,624,2.198,641,3.658,796,3.779,836,3.658,837,3.019,860,2.45,862,3.434,870,4.332,968,4.01,973,3.658,1006,4.583,1041,2.877,1042,4.583,1043,5.013,1044,5.013,1045,5.013,1046,7.251,1047,4.3,1048,3.658]],["t/306",[24,0.107,110,1.41,532,2.905,533,3.211,584,3.731,595,3.49,822,5.007,843,5.698,1049,8.66,1050,7.428]],["t/309",[24,0.103,591,5.316,822,4.949,826,7.026,828,6.692,829,6.452,831,3.859,960,6.98,1051,8.559,1052,8.559,1053,6.246,1054,6.98,1055,8.559,1056,8.559,1057,8.559]],["t/311",[24,0.109,29,5.388,69,2.799,110,0.96,167,2.495,168,2.016,327,3.306,428,2.156,533,1.815,539,4.442,584,4.01,591,4.611,592,3.083,595,2.375,622,1.753,684,4.608,737,4.442,738,3.214,796,4.442,822,3.407,843,3.878,844,4.806,862,3.751,969,6.356,1032,7.433,1058,5.893,1059,5.893]],["t/313",[24,0.109,154,4.389,375,3.138,436,2.461,532,2.912,533,3.012,589,2.022,592,2.461,595,3.498,663,2.342,720,2.898,789,4.478,822,3.752,836,4.736,862,2.616,965,3.402,967,6.786,1005,3.073,1060,6.489,1061,6.489,1062,6.489,1063,6.489,1064,6.489,1065,5.933,1066,6.489,1067,6.489]],["t/316",[24,0.108,110,1.262,533,2.999,591,3.562,592,2.939,595,3.926,822,5.631,862,3.926,953,5.842,965,5.106,967,7.615,1054,6.321,1068,7.75,1069,7.75]],["t/318",[24,0.109,158,2.113,204,1.595,326,3.344,591,2.931,592,2.418,709,4.654,822,5.605,862,4.179,893,7.843,894,3.631,960,5.201,1054,5.201,1070,5.83,1071,6.377,1072,6.377]],["t/320",[24,0.109,160,1.702,193,1.518,368,6.382,532,2.342,533,2.805,541,3.571,595,3.671,709,5.094,824,5.993,829,5.262,953,7.643,959,5.987,960,5.693,964,5.987,1073,5.987,1074,6.382,1075,6.98,1076,6.98]],["t/322",[24,0.108,374,1.168,533,2.96,595,3.874,796,5.722,797,6.94,822,4.389,862,3.874,876,3.785,953,7.246,967,5.935,1077,6.511,1078,7.591,1079,7.591]],["t/324",[24,0.109,69,2.523,110,1.193,534,3.242,584,3.157,591,3.367,592,2.779,796,5.523,824,6.184,836,5.347,894,4.172,952,5.729,964,6.285,1073,6.285,1080,7.327,1081,7.327]],["t/326",[24,0.104,1082,9.682]],["t/328",[24,0.109,27,3.741,96,4.34,114,6.128,144,3.082,149,2.509,150,2.243,153,1.316,173,3.302,200,2.825,208,1.418,212,1.899,219,2.266,374,1.564,428,3.036,480,2.803,533,1.474,575,2.009,595,1.929,622,2.085,624,3.638,663,3.296,673,2.718,686,2.767,705,3.391,734,2.724,790,3.02,862,3.344,873,3.391,877,1.465,882,3.607,942,3.741,956,2.684,965,2.509,1041,2.781,1048,3.492,1083,4.785,1084,3.222,1085,4.785,1086,2.243,1087,5.585,1088,3.222,1089,2.962,1090,4.104,1091,4.785,1092,3.607,1093,3.741,1094,4.785]],["t/330",[24,0.109,98,2.753,114,4.826,144,4.035,150,2.937,153,0.843,160,1.212,167,2.104,168,1.7,208,1.005,373,1.55,374,1.519,383,2.353,428,3.402,480,3.39,481,1.898,533,0.944,534,1.357,539,2.311,595,1.236,622,1.478,624,4.077,663,3.059,664,2.237,673,1.189,686,1.772,737,2.311,738,2.709,790,1.935,862,2.904,907,1.628,921,2.605,963,1.864,1005,1.452,1041,1.971,1087,4.218,1089,1.898,1090,2.629,1095,2.629,1096,4.969,1097,3.066,1098,2.397,1099,4.543,1100,3.522,1101,2.803]],["t/333",[24,0.109,98,2.355,114,5.425,134,4.498,200,3.379,268,2.446,374,0.949,428,2.255,534,2.728,622,1.833,624,2.703,663,3.981,720,2.753,738,3.361,837,2.566,862,2.484,921,3.232,1086,2.889,1087,5.645,1102,7.191,1103,6.838,1104,4.254]],["t/335",[24,0.109,114,5.527,268,3.059,374,1.187,622,2.293,837,3.21,1089,4.773,1090,6.613,1095,6.613,1101,7.048,1102,6.613,1105,6.288]],["t/337",[24,0.106,420,2.834,428,3.387,573,4.681,624,4.06,1106,7.94]],["t/339",[24,0.109,98,3.365,326,3.479,374,1.021,401,3.75,428,2.428,476,2.593,520,2.593,539,5.002,624,3.863,737,5.002,837,2.763,1105,7.184,1107,4.804,1108,4.842,1109,6.066]],["t/341",[24,0.108,98,2.841,114,5.949,153,2.046,268,3.765,374,1.461,385,3.636,622,2.822,663,2.684,705,5.272,720,4.238,738,5.175,877,2.277,921,3.9,1092,5.607,1098,5.815,1103,8.522,1110,7.438,1111,7.438]],["t/343",[24,0.109,34,2.272,114,5.811,164,4.439,165,2.608,167,2.053,168,2.421,170,1.749,193,1.055,221,2.51,230,2.37,262,3.97,263,4.158,289,7.495,374,1.287,377,2.344,398,1.616,399,2.786,420,2.559,424,2.608,428,3.735,435,3.001,506,3.436,520,1.894,534,4.067,622,2.907,645,2.51,718,2.803,921,2.542,1112,4.158,1113,5.772,1114,4.848,1115,3.954,1116,3.954,1117,4.848,1118,4.158,1119,3.345,1120,2.228,1121,3.345,1122,4.848,1123,4.158,1124,3.654,1125,7.169,1126,4.848,1127,4.848,1128,4.848]],["t/345",[24,0.109,114,5.795,164,3.238,167,3.524,168,2.847,207,1.182,262,2.229,289,3.241,365,2.675,374,1.142,377,3.588,385,1.942,398,2.474,399,2.921,401,1.507,420,1.867,428,2.231,435,3.775,513,1.627,520,2.383,534,3.683,573,2.009,575,1.668,622,2.818,624,4.155,645,2.058,651,3.107,705,5.899,718,4.29,720,2.723,733,2.559,738,3.325,769,3.643,837,1.654,963,3.707,970,2.415,1037,1.986,1092,4.596,1098,3.107,1103,3.241,1113,8.045,1118,3.408,1129,3.107,1130,5.575,1131,3.973,1132,4.45,1133,4.973,1134,6.098,1135,3.973,1136,3.973,1137,3.633]],["t/347",[24,0.108,98,3.866,114,6.037,153,1.654,200,2.424,374,1.269,385,2.939,398,2.748,401,3.126,420,3.098,428,2.2,480,2.405,622,3.01,624,4.438,645,4.269,663,2.17,673,2.332,720,2.686,738,3.279,877,1.841,952,6.445,1092,4.533,1138,6.013,1139,4.904,1140,6.013,1141,6.013,1142,6.013,1143,6.013,1144,6.013,1145,3.655,1146,4.904]],["t/349",[24,0.109,143,2.907,144,2.966,160,1.123,167,4.053,168,3.428,185,1.628,193,1.002,204,1.705,208,0.932,305,2.663,316,2.251,347,2.663,377,2.227,385,2.251,388,3.031,428,3.502,513,1.886,624,4.669,635,2.851,663,3.236,734,2.622,738,4.89,740,2.512,830,2.038,847,3.031,851,2.302,862,1.856,882,3.472,944,3.132,1005,3.228,1087,3.101,1099,4.211,1100,3.264,1115,5.559,1116,5.559,1147,6.231,1148,6.816,1149,4.606,1150,4.606,1151,4.606]],["t/351",[24,0.108,98,3.232,374,1.774,513,3.465,624,3.71,663,3.053,921,4.436,1087,5.697,1108,6.175]],["t/353",[24,0.108,98,4.261,114,6.049,160,2.367,374,1.187,428,3.888,624,4.257,790,4.865,1087,5.191,1108,5.626,1118,6.613,1145,4.687,1152,7.71]],["t/355",[24,0.108,98,2.772,114,4.131,138,6.633,160,1.769,167,3.072,168,2.482,204,1.815,236,2.924,374,1.117,401,2.751,420,2.221,428,3.417,624,4.782,738,3.956,745,2.901,776,5.142,837,3.021,1087,4.885,1105,5.917,1107,3.956,1153,6.223]],["t/357",[24,0.108,114,5.42,201,3.736,374,1.697,399,2.943,428,3.483,622,2.831,624,3.278,651,5.845,705,5.298,790,6.008,921,3.919,1037,3.736,1087,5.033,1137,6.834,1154,6.097]],["t/360",[24,0.109,98,1.771,114,5.464,214,1.639,268,1.839,374,1.054,385,2.266,398,2.283,411,5.483,480,1.853,487,2.635,512,1.883,534,2.051,622,2.422,663,3.246,677,4.239,687,2.817,705,3.285,732,2.639,790,2.925,835,2.769,1087,5.483,1095,6.985,1102,3.975,1103,6.641,1155,9.596,1156,4.635,1157,4.635,1158,4.635,1159,4.635,1160,4.237,1161,4.635,1162,4.635,1163,4.635,1164,4.635,1165,3.78,1166,4.635]],["t/362",[24,0.109,61,2.843,158,1.155,159,2.015,160,1.343,176,1.312,185,1.232,193,0.758,214,1.232,222,3.707,295,2.627,314,2.99,326,1.827,330,4.305,334,2.627,428,1.275,528,2.245,595,2.219,624,1.528,663,1.258,665,2.725,809,2.627,815,5.034,816,3.187,891,5.034,897,6.651,1005,1.651,1047,2.99,1087,6.559,1105,6.886,1115,2.843,1116,2.843,1123,2.99,1167,3.187,1168,2.99,1169,7.242,1170,8.443,1171,7.754,1172,5.506,1173,3.485,1174,3.485,1175,3.485,1176,3.485,1177,2.082,1178,2.544,1179,3.485,1180,3.485,1181,3.485,1182,3.485,1183,3.187,1184,3.485,1185,3.485,1186,3.485,1187,3.485,1188,3.485,1189,3.485,1190,5.506,1191,3.485,1192,3.485]],["t/364",[24,0.104,1193,9.682]],["t/366",[24,0.108,28,3.695,110,1.217,147,6.747,160,1.823,268,2.966,374,1.465,533,2.302,673,4.062,857,5.455,858,5.635,869,3.54,871,5.34,888,4.628,1005,3.54,1041,3.777,1093,5.845,1194,4.718,1195,5.845,1196,6.097,1197,7.475]],["t/368",[24,0.109,28,2.648,110,0.873,160,1.855,208,1.084,219,2.537,268,2.126,374,1.481,436,2.032,487,2.062,532,1.798,533,2.723,589,1.67,595,2.16,673,3.942,687,3.257,857,3.91,858,4.039,869,4.813,871,4.96,872,3.317,888,3.317,901,4.189,908,3.317,919,4.039,920,4.039,921,2.809,1005,4.558,1041,4.19,1198,5.695,1199,4.899,1200,4.899,1201,4.189,1202,4.899,1203,4.37,1204,5.358,1205,5.551]],["t/370",[24,0.108,100,4.065,158,2.725,185,2.908,359,4.208,673,3.919,830,4.472,1005,3.895,1041,4.01,1198,7.046]],["t/373",[24,0.107,160,1.89,374,1.809,533,2.387,589,2.415,595,3.124,673,3.777,869,3.67,1041,3.075,1194,4.891,1206,5.842,1207,6.648,1208,5.656,1209,4.711,1210,6.648,1211,7.75,1212,6.648,1213,7.75,1214,7.085]],["t/375",[24,0.108,191,4.159,374,1.266,436,3.119,505,4.368,589,2.563,638,4.313,673,3.19,687,5,860,4.94,864,6.003,869,4.786,918,7.52,1194,5.191]],["t/377",[24,0.108,100,5.251,158,2.554,326,4.042,532,2.587,533,2.374,687,4.687,732,4.389,830,3.412,869,3.651,881,3.769,1041,3.852,1207,6.613,1209,4.687,1210,6.613,1212,6.613,1215,7.71,1216,7.71]],["t/379",[24,0.108,28,3.236,153,1.801,164,3.476,193,1.424,212,2.598,230,4.802,253,4.778,254,3.846,286,4.415,316,3.2,374,1.008,398,2.183,401,3.311,420,2.004,476,2.558,673,3.386,871,4.898,881,3.2,888,4.053,936,4.778,1005,4.135,1041,2.598,1130,5.985,1196,5.339,1217,3.727,1218,5.339,1219,5.119,1220,6.547,1221,5.119,1222,6.547,1223,5.985,1224,5.985]],["t/382",[24,0.107,326,3.785,374,1.675,589,2.901,591,3.318,673,2.8,678,3.785,724,2.842,860,3.529,871,4.05,873,5.117,919,5.442,920,5.442,924,5.442,936,5.269,968,3.992,1093,5.645,1198,4.649,1201,5.645,1203,5.888,1221,5.645,1225,5.442,1226,6.6,1227,6.6,1228,7.219,1229,7.219,1230,7.219,1231,5.888,1232,5.269,1233,7.219,1234,6.192]],["t/384",[24,0.108,110,1.829,165,3.847,300,6.229,362,6.536,533,3.34,592,2.711,678,3.748,705,5.067,869,4.381,908,4.426,919,5.389,920,5.389,1165,5.831,1201,5.59,1203,5.831,1231,5.831,1234,6.132,1235,7.15,1236,8.019,1237,4.704,1238,7.15]],["t/386",[24,0.109,216,3.611,219,2.813,374,1.625,436,2.253,663,2.144,673,4.094,724,3.219,869,2.813,871,3.332,872,5.061,898,7.474,901,7.308,1041,2.357,1088,4,1207,5.096,1209,3.611,1210,5.096,1212,5.096,1239,5.941,1240,5.431,1241,5.941,1242,5.431]],["t/388",[24,0.108,77,5.578,230,4.624,268,2.936,374,1.139,533,2.279,595,2.983,673,4.26,869,5.203,871,4.151,919,5.578,920,5.578,1041,2.936,1088,4.983,1198,4.766,1243,6.348]],["t/390",[24,0.109,110,0.956,150,4.928,342,3.78,377,2.839,533,1.808,638,3.078,673,2.276,687,3.568,866,4.284,869,4.978,871,5.619,872,3.634,873,4.16,875,4.16,908,3.634,1088,3.952,1198,5.981,1201,4.589,1202,5.366,1203,4.787,1231,4.787,1234,5.035,1244,5.87,1245,9.288,1246,5.87,1247,5.87]],["t/392",[24,0.109,80,2.556,110,1,208,1.242,216,6.492,374,1.463,673,4.141,687,3.731,830,2.716,869,5.669,911,3.874,1041,3.317,1194,3.874,1248,6.138,1249,4.236]],["t/394",[24,0.108,77,5.469,226,3.852,230,4.565,533,2.876,559,4.885,595,3.764,673,2.813,830,4.133,869,4.891,870,4.334,871,5.793,924,5.469,1041,2.879,1194,4.578,1198,6.014,1231,5.917,1232,5.294,1243,6.223]],["t/396",[24,0.108,154,2.587,155,1.447,160,2.435,165,2.753,193,1.875,200,3.474,208,1.035,216,3.11,219,2.423,230,2.501,300,3.445,305,2.958,398,1.706,428,1.872,431,2.227,517,3.11,589,1.595,624,3.227,663,2.656,673,4.155,871,5.833,872,3.168,877,1.567,901,4.001,902,7.88,906,4.678,944,2.351,1005,4.463,1037,2.558,1041,4.35,1120,3.382,1196,6.002,1198,3.295,1201,4.001,1250,5.117,1251,5.117,1252,4.678,1253,4.001,1254,4.001,1255,5.117]],["t/398",[24,0.109,63,2.595,77,2.835,80,2.984,134,2.745,158,1.246,160,0.917,165,2.023,193,0.818,200,1.516,230,3.504,315,2.94,326,1.972,359,1.924,398,1.254,420,1.789,481,2.328,486,1.838,532,1.961,533,2.978,566,3.226,589,1.172,591,1.728,595,3.528,596,4.716,631,3.764,645,1.947,663,1.357,673,2.779,686,3.379,776,2.666,824,2.475,837,1.566,860,3.504,863,5.013,869,3.394,871,5.425,877,1.151,881,2.857,888,2.328,1037,3.583,1041,2.844,1198,4.616,1243,3.226,1256,5.844,1257,3.761,1258,3.226,1259,5.343,1260,5.844,1261,3.761,1262,2.94,1263,3.761,1264,3.761,1265,2.595,1266,4.033,1267,1.799,1268,2.532,1269,3.761,1270,3.761,1271,2.08,1272,3.846,1273,2.328]],["t/400",[24,0.108,160,2.006,374,1.266,532,2.76,533,3.112,595,3.315,673,4.425,869,4.786,1041,4.01]],["t/402",[24,0.109,219,3.142,374,1.622,673,3.835,938,5.002,1041,3.495,1214,6.066,1242,6.066]],["t/404",[24,0.109,216,6.705,374,1.536,673,4.115,869,5.672,936,4.931,1194,4.264,1221,5.283,1274,6.177]],["t/406",[24,0.108,193,1.578,200,2.924,428,3.417,431,2.195,624,4.782,673,3.621,745,2.901,871,5.239,872,4.491,877,2.859,1005,3.436,1041,3.705,1089,5.782,1092,5.469,1196,5.917,1198,4.672,1275,6.633,1276,8.01,1277,7.255]],["t/408",[24,0.109,193,1.563,200,2.896,216,4.367,398,2.395,431,2.174,481,4.448,596,4.727,664,5.243,673,2.786,723,3.918,776,5.092,860,3.512,863,6.162,869,3.402,871,5.206,888,4.448,924,5.416,1041,2.851,1198,4.627,1259,6.568]],["t/410",[24,0.109,193,1.686,431,2.345,673,4.13,871,4.347,872,4.798,877,2.373,1041,4.226,1240,7.085,1278,6.648]],["t/412",[24,0.108,204,1.861,374,1.461,673,4.268,857,5.428,858,5.607,869,5.212,871,4.172,872,4.605,1041,3.765,1198,4.79,1199,6.8,1274,6.8]],["t/414",[24,0.104,1279,9.682]],["t/416",[24,0.109,83,4.789,110,0.8,150,2.303,153,1.966,155,1.389,160,1.743,193,2.012,195,3.39,204,2.107,207,1.461,208,1.704,226,2.609,305,2.84,337,3.703,347,2.84,359,2.513,374,1.512,384,2.797,387,4.006,420,1.504,422,2.236,431,1.486,513,2.012,532,3.103,533,2.201,575,2.063,589,1.531,596,3.232,639,2.428,837,2.045,877,1.504,881,3.493,944,2.258,956,2.756,1086,2.303,1093,3.841,1194,4.51,1209,2.986,1249,3.39,1280,5.542,1281,4.006,1282,6.227,1283,2.401,1284,4.913,1285,4.491,1286,4.214,1287,2.935,1288,3.585,1289,4.913,1290,4.913,1291,4.491,1292,3.39,1293,2.986,1294,3.841,1295,4.913]],["t/418",[24,0.109,79,3.257,83,2.068,110,1.116,150,1.104,153,1.43,154,2.019,160,2.035,164,2.76,165,1.268,191,1.191,193,1.619,199,1.072,204,1.985,207,2.676,208,1.821,212,2.063,268,2.063,305,1.362,316,1.152,317,1.971,319,1.116,333,1.55,334,1.776,347,1.362,359,1.205,373,1.191,374,1.426,384,1.341,420,1.591,422,1.072,431,2.073,476,2.392,480,2.079,486,1.152,487,0.907,496,1.776,513,2.129,532,2.054,533,1.601,589,1.245,596,2.628,637,2.689,639,1.974,693,1.842,718,2.309,831,2.344,837,0.981,859,1.487,877,1.591,881,2.992,890,1.341,921,1.235,944,1.835,1005,1.116,1041,0.935,1048,1.719,1086,1.872,1088,1.586,1165,1.921,1177,1.407,1194,1.487,1206,3.011,1209,1.432,1217,1.341,1225,1.776,1280,6.094,1282,5.341,1283,2.541,1285,2.154,1288,2.915,1292,2.756,1293,1.432,1294,1.842,1296,1.776,1297,1.776,1298,1.776,1299,3.281,1300,2.356,1301,1.67,1302,2.154,1303,1.921,1304,2.356,1305,2.356,1306,1.921,1307,1.776,1308,1.191]],["t/421",[24,0.109,27,6.445,83,4.871,155,1.7,156,4.702,160,2.01,164,3.193,191,3.041,208,1.217,268,2.386,305,4.766,317,3.126,347,3.477,374,1.632,532,2.018,533,1.852,637,4.049,831,2.711,881,2.939,1086,2.819,1217,3.424,1280,3.957,1282,4.049,1287,4.925,1292,5.689,1309,6.723,1310,6.013,1311,4.262,1312,4.702]],["t/423",[24,0.109,27,2.738,98,2.616,100,3.384,110,1.465,154,1.771,160,1.348,170,1.264,191,1.771,193,1.841,195,2.417,199,3.116,200,1.411,204,0.876,207,2.036,208,1.385,227,2.856,268,1.39,316,1.712,317,2.948,344,1.625,359,1.792,374,1.054,428,1.281,431,1.672,487,2.635,495,3.004,496,2.64,505,1.86,513,1.434,532,2.297,533,2.108,573,1.771,589,1.722,595,2.228,622,2.036,624,1.536,631,2.255,639,1.731,687,2.129,752,3.004,826,4.321,828,4.321,874,1.75,881,3.347,888,2.168,890,3.147,911,2.21,936,2.556,1005,2.617,1086,3.209,1088,3.721,1153,3.004,1194,2.21,1205,2.556,1209,5.932,1221,2.738,1225,2.64,1253,4.321,1266,2.417,1267,2.645,1268,2.358,1282,2.358,1293,2.129,1294,4.321,1299,3.488,1301,2.482,1302,3.202,1313,2.738,1314,2.168,1315,4.741,1316,3.502,1317,2.482,1318,3.502,1319,3.502,1320,3.502,1321,2.738,1322,3.502,1323,2.738,1324,2.255,1325,3.502,1326,2.856,1327,3.202,1328,3.004,1329,3.004,1330,2.738,1331,3.502,1332,3.502,1333,3.502,1334,2.738,1335,2.856,1336,5.053,1337,3.502,1338,1.884]],["t/425",[24,0.109,158,1.005,165,4.539,185,1.073,193,1.353,199,2.831,207,0.902,208,0.997,214,1.073,232,2.104,316,1.483,318,2.602,319,3.995,374,0.467,398,2.074,401,3.371,420,0.929,476,3.077,486,4.124,520,1.185,532,1.653,533,1.517,592,1.869,631,5.433,738,2.687,825,3.852,876,1.195,877,1.508,881,1.483,888,3.05,890,5.45,1037,1.517,1086,1.422,1217,2.805,1266,4.942,1267,3.768,1282,2.043,1292,2.094,1303,5.84,1307,2.287,1314,3.851,1334,3.852,1339,3.034,1340,3.034,1341,3.034,1342,2.774,1343,2.602,1344,3.034,1345,2.474,1346,5.336,1347,3.034,1348,3.034,1349,3.034,1350,3.4,1351,3.034,1352,3.034,1353,3.034,1354,3.034,1355,3.034,1356,3.034,1357,3.034,1358,3.034,1359,3.034,1360,3.034,1361,3.034,1362,3.034,1363,3.034,1364,3.242,1365,1.915,1366,4.505,1367,3.034,1368,3.034,1369,2.774,1370,2.774,1371,3.034,1372,4.226,1373,3.034,1374,3.034,1375,1.954,1376,3.034,1377,3.034,1378,3.034,1379,3.034,1380,3.034,1381,3.034,1382,3.034,1383,3.034,1384,4.505,1385,2.774,1386,3.034,1387,3.034,1388,3.034]],["t/427",[24,0.109,83,1.571,110,0.802,144,1.105,149,2.583,153,1.548,154,2.062,155,1.591,160,1.201,164,3.802,165,0.923,167,2.847,168,1.925,170,1.472,185,1.072,190,0.935,193,0.66,204,1.791,207,1.674,208,1.593,212,0.681,214,0.606,223,1.252,231,0.796,236,0.691,237,2.15,239,1.471,256,0.878,264,2.287,286,0.867,305,1.754,316,3.287,321,1.184,374,1.368,377,1.972,380,0.899,384,4.483,388,2.683,399,1.194,401,1.547,420,0.525,422,3.432,428,1.492,435,3.05,486,0.838,487,0.66,532,1.888,533,1.517,573,0.867,575,2.068,624,1.788,635,1.878,637,3.79,687,1.043,704,1.471,708,1.216,731,2.194,745,1.213,777,4.243,786,1.216,830,0.759,859,1.082,881,1.993,890,0.977,907,1.611,911,1.082,936,1.252,1048,1.252,1086,1.912,1115,1.399,1116,1.399,1124,1.293,1209,1.043,1217,0.977,1221,1.341,1253,1.341,1267,1.451,1280,1.996,1281,4.591,1282,4.528,1283,1.483,1287,1.812,1288,5.226,1308,2.491,1309,1.399,1314,1.062,1389,1.129,1390,1.341,1391,3.498,1392,4.908,1393,4.504,1394,3.033,1395,7.16,1396,3.033,1397,1.715,1398,1.715,1399,1.715,1400,1.715,1401,1.715,1402,1.715,1403,1.568,1404,1.715,1405,1.715,1406,1.341,1407,1.715,1408,1.715,1409,1.715,1410,1.568,1411,1.715,1412,1.715,1413,1.715,1414,1.715,1415,1.184,1416,1.715,1417,1.715,1418,1.715,1419,1.715,1420,1.715,1421,1.568,1422,3.033,1423,3.033,1424,3.033,1425,1.715,1426,1.715,1427,1.715,1428,1.715,1429,1.715,1430,1.715,1431,1.471,1432,1.715,1433,1.715,1434,1.715,1435,1.568,1436,2.396,1437,1.715,1438,0.838,1439,1.715,1440,1.715,1441,1.082,1442,1.341,1443,4.926,1444,1.715,1445,1.568,1446,1.715,1447,1.216,1448,1.341,1449,1.293,1450,0.899,1451,1.715,1452,1.568]],["t/429",[24,0.109,28,2.936,83,3.076,110,1.331,164,3.155,193,2.033,204,2.045,207,2.78,208,2.037,230,2.904,268,2.357,314,5.096,374,1.439,377,2.873,399,3.219,431,2.828,480,3.269,487,2.286,532,1.993,533,1.829,541,3.039,622,1.767,663,2.144,1088,5.504,1177,3.549,1209,3.611,1288,5.966,1292,4.1,1299,5.159,1301,4.211,1453,4.845,1454,5.941,1455,5.941]],["t/431",[24,0.108,28,2.629,100,2.629,110,0.866,153,2.082,155,1.504,160,1.297,164,2.825,165,2.862,191,2.69,193,1.646,200,2.144,204,1.331,208,1.076,230,3.699,254,3.125,262,2.984,286,2.69,288,3.357,315,4.159,319,4.171,374,0.819,401,2.017,431,1.61,480,3.522,486,2.6,487,3.39,517,3.234,532,2.539,533,1.638,589,1.658,622,2.25,678,2.789,828,4.159,881,2.6,890,3.029,1041,2.111,1086,3.547,1088,3.582,1209,4.6,1217,4.308,1218,4.338,1219,4.159,1288,5.522,1291,4.864,1292,6.078,1293,3.234,1299,3.357,1303,4.338,1306,4.338,1312,4.159,1366,4.864,1384,4.864,1385,4.864,1456,5.32,1457,5.32,1458,4.864,1459,4.563]],["t/433",[24,0.108,374,1.259,532,3.379,533,2.519,694,7.478,907,4.344,1205,5.969,1209,6.123,1217,4.657,1253,6.395,1280,5.382,1292,6.95,1293,4.972]],["t/435",[24,0.109,153,2.182,158,3.026,193,1.237,226,3.021,230,2.781,481,3.522,487,2.19,532,3.78,533,3.47,595,3.682,776,4.032,876,3.596,877,2.429,894,4.517,1005,2.694,1088,3.83,1104,3.926,1177,3.398,1209,6.318,1280,6.839,1293,5.553,1460,5.689,1461,5.689,1462,4.64]],["t/437",[24,0.109,38,3.258,153,1.099,160,0.974,168,1.366,170,2.21,191,2.02,193,1.332,203,6.73,204,0.999,212,1.585,214,1.412,231,1.854,305,2.31,319,1.892,359,2.044,392,3.427,398,3.295,401,2.322,420,1.223,428,2.724,476,2.392,481,2.473,486,2.993,487,1.538,496,3.011,512,1.623,513,2.508,520,1.561,532,2.498,533,2.293,624,3.66,831,1.801,837,1.663,876,1.573,877,1.223,881,3.639,888,2.473,890,2.274,1005,1.892,1209,2.428,1225,3.011,1267,1.912,1280,4.899,1287,4.986,1293,2.428,1301,2.831,1306,3.258,1312,6.525,1334,4.787,1336,3.652,1346,3.427,1364,4.029,1463,6.123,1464,3.995,1465,3.995,1466,3.995,1467,3.995,1468,2.915,1469,3.652,1470,3.011,1471,3.011,1472,4.787,1473,3.995,1474,3.995]],["t/439",[24,0.108,158,2.746,191,3.065,203,5.875,212,2.406,231,2.814,256,3.102,305,3.505,420,1.856,422,2.759,476,2.369,532,3.407,533,2.553,708,4.297,837,2.524,876,3.264,881,2.964,890,3.452,894,3.452,1086,2.842,1280,6.682,1287,5.643,1293,5.039,1470,6.249,1471,6.249,1472,4.74,1475,6.063,1476,6.063,1477,6.063,1478,6.063,1479,4.57,1480,6.063,1481,4.944,1482,4.944]],["t/441",[24,0.108,28,2.913,63,4.067,158,2.693,159,3.407,160,1.437,164,3.129,193,2.025,203,5.762,204,1.474,207,1.753,208,1.192,212,3.693,214,2.084,230,2.881,401,2.235,428,2.156,486,2.881,487,2.268,532,3.532,533,2.504,624,2.584,678,4.263,686,4.701,819,4.806,876,3.201,881,3.974,894,4.629,1178,4.301,1205,4.301,1209,3.582,1280,5.35,1283,2.881,1287,4.857,1293,5.658,1459,5.055,1471,6.128,1483,5.893,1484,5.893,1485,5.893,1486,5.893]],["t/443",[24,0.109,154,3.078,155,1.721,160,1.485,204,1.523,212,2.415,221,4.902,334,6.266,374,0.937,398,2.03,422,2.771,518,6.78,532,2.042,664,6.067,813,5.222,837,2.535,881,2.976,1209,5.053,1280,4.006,1287,3.637,1288,6.067,1293,3.701,1309,4.965,1472,4.76,1487,6.088,1488,9.467,1489,6.088,1490,4.663,1491,6.088,1492,6.088,1493,6.088,1494,6.088,1495,8.313,1496,6.088]],["t/445",[24,0.108,159,4.279,160,1.805,191,4.783,193,1.61,204,1.851,212,2.936,384,4.213,532,3.173,639,3.658,818,6.035,859,4.67,1178,5.401,1219,5.786,1292,5.107,1293,5.75,1389,6.86,1469,9.531,1482,6.035,1497,6.766,1498,7.4]],["t/447",[24,0.109,80,2.342,83,2.912,110,0.916,150,2.636,153,1.547,155,1.59,185,1.988,193,1.223,208,1.138,308,3.881,317,2.133,344,2.61,374,1.211,487,3.029,496,6.843,512,2.285,517,3.419,532,3.472,533,1.732,677,3.482,740,3.067,826,4.967,828,6.153,881,2.749,1086,4.255,1225,6.843,1293,5.978,1294,7.098,1315,4.824,1499,4.586,1500,5.624,1501,5.624,1502,5.624]],["t/449",[24,0.109,165,3.942,193,2.044,322,6.699,431,2.217,486,3.582,532,3.153,843,4.821,845,4.719,1209,5.713,1253,5.729,1293,5.713,1306,5.975,1503,7.327,1504,6.699]],["t/451",[24,0.109,63,3.345,98,1.852,153,2.299,159,2.803,191,2.451,199,2.206,203,3.436,204,1.77,207,1.442,208,0.981,212,1.924,305,4.092,319,2.296,374,1.089,384,2.76,422,2.206,486,2.37,520,1.894,532,3.756,533,2.83,592,1.839,596,3.19,819,3.954,862,1.954,890,4.029,944,2.228,968,2.681,1145,2.947,1178,3.538,1266,3.345,1280,4.657,1282,3.264,1286,4.158,1287,4.228,1288,3.538,1292,4.884,1293,6.204,1294,3.79,1303,3.954,1308,2.451,1314,3.001,1393,4.432,1435,4.432,1452,4.432,1459,4.158,1505,3.954,1506,4.848]],["t/453",[24,0.104,1507,9.682]],["t/455",[24,0.108,83,2.765,110,0.869,154,2.7,155,2.982,159,3.087,160,2.343,167,3.212,168,1.826,169,2.732,170,1.927,193,1.65,204,1.336,207,2.625,208,1.786,214,1.888,374,0.822,377,2.582,398,1.78,431,2.296,436,2.025,565,3.881,584,2.3,595,3.557,655,3.087,678,2.799,724,2.102,795,3.784,831,2.407,846,4.029,847,3.513,849,3.04,860,2.61,874,2.669,1041,3.813,1178,3.896,1271,2.952,1287,3.189,1508,5.213,1509,4.174,1510,4.174,1511,4.025,1512,5.339,1513,3.896]],["t/457",[24,0.109,69,1.962,110,1.293,155,2.796,158,1.206,159,2.105,160,2.33,167,2.972,168,1.949,169,1.862,170,1.314,193,1.527,204,1.756,207,2.564,208,1.744,214,2.014,268,1.444,375,1.76,398,1.899,420,1.744,431,1.724,436,2.161,490,2.846,504,2.846,520,1.422,565,3.592,584,1.568,589,1.134,595,2.829,622,1.083,655,2.105,678,1.909,723,1.985,724,1.433,830,1.611,831,1.641,841,3.122,846,3.025,847,3.749,849,3.244,860,1.779,862,1.467,908,2.254,944,2.618,954,2.969,956,2.042,1041,4.034,1074,3.328,1178,2.657,1271,4.391,1508,4.888,1509,2.846,1510,4.455,1511,4.295,1513,2.657,1514,3.328,1515,5.489,1516,2.58,1517,3.244,1518,3.64,1519,3.64,1520,2.512,1521,3.328,1522,3.328]],["t/461",[24,0.108,34,2.303,110,1.6,155,2.02,167,2.08,168,3.507,170,3.546,193,1.069,207,1.461,208,1.446,231,3.909,268,1.949,388,3.232,398,2.382,411,3.307,415,3.841,420,1.504,431,1.486,485,2.84,486,3.493,520,1.919,534,2.174,589,1.531,635,5.214,676,2.886,724,1.934,732,2.797,745,1.964,846,3.795,874,2.455,992,4.006,1039,4.006,1041,3.669,1265,4.931,1271,2.716,1364,3.232,1365,3.1,1508,3.532,1509,3.841,1523,4.913,1524,6.129,1525,4.913,1526,4.913,1527,4.491,1528,4.913,1529,4.344,1530,7.146,1531,5.387,1532,7.146,1533,4.491,1534,3.841,1535,4.913,1536,4.913,1537,4.913,1538,6.533,1539,4.913,1540,4.491,1541,4.913,1542,4.913,1543,4.913,1544,4.006]],["t/463",[24,0.109,34,1.294,83,1.43,102,2.522,110,1.314,155,2.118,167,3.918,168,2.315,170,1.646,193,1.268,207,0.821,208,0.559,223,2.015,226,1.466,231,2.705,256,1.413,261,1.65,262,2.559,318,4.999,365,1.859,385,2.849,398,2.498,410,1.906,411,1.859,420,0.845,431,1.38,432,1.743,436,1.047,485,1.597,520,1.079,565,2.334,595,2.349,635,3.608,676,1.622,708,1.957,724,1.796,733,1.778,734,2.597,769,1.65,846,2.422,847,1.817,874,3.745,1021,2.369,1037,2.28,1041,1.81,1265,1.906,1365,4.271,1375,1.778,1453,2.252,1508,2.88,1516,1.957,1524,3.913,1534,2.159,1540,6.849,1545,2.762,1546,2.762,1547,2.762,1548,2.762,1549,2.762,1550,4.999,1551,2.762,1552,2.762,1553,2.762,1554,4.562,1555,2.762,1556,4.562,1557,2.762,1558,2.369,1559,4.562,1560,2.762,1561,2.762,1562,2.762,1563,4.562,1564,2.762,1565,2.762,1566,2.762,1567,4.562,1568,2.762,1569,2.762,1570,2.762,1571,2.762,1572,4.562,1573,2.762,1574,2.762,1575,2.762,1576,2.762,1577,5.828,1578,2.762,1579,2.762,1580,2.762,1581,2.762,1582,2.762,1583,2.762,1584,2.762,1585,2.762,1586,2.762,1587,2.762,1588,2.762,1589,2.762,1590,2.762,1591,7.492,1592,2.762,1593,2.762,1594,2.762,1595,2.762,1596,2.762,1597,2.762,1598,2.762,1599,2.762,1600,2.762,1601,2.762,1602,2.762,1603,2.762,1604,2.762,1605,2.762,1606,2.762]],["t/465",[24,0.108,34,3.789,69,2.783,98,1.749,110,1.456,149,2.4,155,2.527,168,2.321,170,1.652,193,0.996,207,1.361,208,0.926,219,3.828,231,3.752,374,0.705,375,2.213,398,1.526,411,3.082,420,2.475,428,1.675,431,1.385,436,3.066,485,3.923,486,2.237,589,1.426,590,3.513,592,1.736,622,1.361,635,4.2,720,3.61,755,3.926,760,2.531,837,2.825,846,2.431,921,2.4,1039,5.533,1041,1.816,1195,3.579,1265,3.159,1365,2.889,1415,3.159,1447,3.244,1508,3.353,1524,3.926,1527,4.185,1529,4.124,1534,3.579,1550,5.819,1607,4.577,1608,4.185,1609,4.185,1610,3.733,1611,4.577,1612,6.785,1613,4.577,1614,4.577,1615,4.577,1616,4.577,1617,4.577,1618,4.577,1619,4.577,1620,3.159,1621,4.577,1622,4.577,1623,4.577,1624,4.577,1625,4.577,1626,4.577,1627,4.577,1628,4.577,1629,4.577,1630,4.577,1631,4.577]],["t/467",[24,0.107,110,1.386,155,2.406,160,2.516,167,3.603,344,3.949,374,1.31,375,4.115,565,4.354,589,2.652,595,3.43,1041,3.376]],["t/469",[24,0.108,110,1.249,155,2.168,167,3.248,168,3.31,169,4.95,170,2.768,193,1.668,204,1.919,207,2.281,208,1.552,431,2.321,490,5.997,504,5.997,565,3.924,595,3.091,635,4.748,745,3.067,1308,3.878,1534,5.997]],["t/471",[24,0.107,110,1.249,167,4.097,207,2.281,208,2.145,223,5.597,232,4.132,374,1.489,398,2.557,565,4.95,589,2.39,595,4.272,795,5.436,846,4.073,847,5.047,968,4.241,1520,5.293,1632,4.73]],["t/475",[24,0.108,28,2.948,80,2.483,98,2.279,110,1.335,153,1.641,155,2.318,159,3.449,160,1.455,164,3.167,168,2.804,170,2.152,176,2.246,179,5.075,185,2.109,193,1.297,204,1.492,207,1.774,208,1.207,232,2.547,236,2.404,288,3.764,365,4.016,431,1.805,486,2.916,520,2.331,528,3.841,624,2.616,678,3.127,718,3.449,740,3.253,876,2.348,1041,3.716,1178,4.353,1208,4.353,1262,4.664,1271,4.533,1458,5.453,1508,4.052,1509,4.664,1510,4.664,1515,4.664,1633,5.965,1634,5.965,1635,4.664,1636,5.965,1637,5.116,1638,5.965,1639,5.965,1640,5.965,1641,5.453,1642,5.965,1643,5.965,1644,5.965,1645,4.353,1646,5.453]],["t/477",[24,0.108,155,2.781,167,3.334,176,3.703,226,4.181,565,4.029,595,3.174,830,4.353,876,3.1,1265,5.434,1508,4.862,1515,7.691,1517,4.483,1646,7.199]],["t/479",[24,0.108,155,2.25,204,2.477,207,2.367,208,1.61,214,3.501,512,3.234,846,4.226,862,3.208,1041,3.158,1271,4.401,1508,4.894,1511,6,1647,7.959]],["t/482",[24,0.108,34,3.54,69,2.6,102,4.176,149,3.959,155,2.135,198,4.118,420,2.312,428,2.763,434,5.211,436,3.634,584,3.253,590,3.282,641,5.511,655,4.366,720,3.373,739,6.904,760,4.176,846,4.01,1217,4.3,1508,3.732,1513,5.511,1608,6.904,1609,6.904,1610,6.159,1648,7.552]],["t/484",[24,0.108,102,3.973,149,3.767,154,3.633,155,2.624,160,1.752,185,2.54,204,1.797,436,2.725,584,3.998,589,2.239,655,4.154,720,3.209,822,4.154,969,7.256,1065,6.568,1508,5.081,1511,5.416,1513,5.243,1649,7.184,1650,7.184,1651,7.184,1652,7.184]],["t/487",[24,0.107,168,3.644,170,3.239,204,2.245,1513,6.55]],["t/489",[24,0.108,106,8.458,155,2.021,167,4.592,185,2.528,319,4.381,512,2.905,565,5.247,595,4.134,890,4.07,938,5.389,1508,3.534,1653,7.15,1654,9.251,1655,7.15,1656,4.426]],["t/491",[24,0.109,155,2.674,179,4.581,193,1.61,204,1.851,207,2.201,208,1.497,268,2.936,315,5.786,431,2.239,862,2.983,1106,6.348,1217,4.213,1258,8.113,1508,3.658,1657,8.113]],["t/494",[24,0.106,69,2.88,169,4.28,180,5.179,193,1.82,199,3.807,207,2.488,208,1.693,374,1.288,396,6.822,431,2.531,487,3.22,490,6.54,504,6.54,557,6.306,800,7.648,968,4.626,1520,5.773]],["t/496",[24,0.106,167,3.624,208,1.732,232,3.655,565,4.379,595,3.45,831,3.859,1520,5.907,1521,7.825,1522,7.825,1632,4.184,1658,8.559,1659,8.559,1660,8.559,1661,8.559]],["t/498",[24,0.108,155,2.135,167,3.198,193,1.643,204,1.889,214,2.67,431,2.285,436,2.864,565,3.864,584,3.253,595,3.044,655,4.366,720,3.373,724,2.973,847,4.969,860,3.692,1041,2.996,1508,4.735,1511,5.693,1513,5.511,1515,5.904,1517,5.455,1662,7.552,1663,7.552]],["t/500",[24,0.104,1664,9.682]],["t/502",[24,0.109,69,3.064,134,4.917,155,2.917,160,1.961,168,1.551,176,1.707,191,2.293,193,1.466,204,2.226,219,2.148,268,1.799,291,3.699,348,4.434,359,2.32,380,2.378,381,3.89,398,1.512,420,1.388,436,2.555,487,1.745,589,1.413,590,4.133,622,2.391,718,2.622,720,3.009,723,2.473,724,1.786,824,4.434,846,3.578,860,2.217,862,2.716,876,1.786,921,2.378,944,2.084,963,2.757,1041,4.206,1249,3.13,1271,5.258,1287,2.709,1508,5.239,1632,3.294,1665,2.984,1666,4.146,1667,3.214,1668,4.535]],["t/504",[24,0.109,34,1.982,69,2.82,98,0.963,102,1.394,110,1.256,113,2.305,134,1.84,153,0.693,154,1.275,155,2.935,160,2.415,165,1.356,167,1.067,168,2.637,170,0.91,176,0.949,193,1.391,200,1.016,201,1.26,204,2.235,207,1.258,208,1.56,219,1.194,247,1.84,262,1.414,268,3.25,348,2.782,357,2.162,365,1.697,374,0.651,375,2.045,380,2.217,436,2.924,485,1.458,494,1.561,565,1.29,584,3.321,589,2.402,590,4.219,595,1.016,622,2.118,635,1.561,655,1.458,718,2.445,720,3.443,723,3.884,724,2.15,744,2.056,824,1.659,831,1.137,842,1.697,846,1.339,860,2.067,862,1.704,881,1.232,944,2.938,954,2.056,963,3.887,965,2.217,968,1.394,1041,4.366,1084,2.847,1195,1.971,1271,4.941,1273,1.561,1314,1.561,1364,1.659,1508,4.895,1514,2.305,1515,1.971,1632,2.67,1665,2.782,1667,3.871,1669,2.162,1670,1.971,1671,2.521,1672,3.306,1673,1.84,1674,2.521,1675,2.521,1676,1.697,1677,2.305,1678,2.521,1679,1.9,1680,2.056,1681,2.305,1682,2.521]],["t/508",[24,0.109,83,3.101,110,1.339,155,2.993,167,2.536,168,2.812,170,2.161,204,1.498,207,1.781,208,1.212,223,4.371,261,3.578,398,2.741,565,3.064,595,2.414,724,2.358,745,2.395,847,5.409,849,3.41,874,4.109,944,2.752,956,3.359,1041,3.262,1086,2.807,1271,4.546,1508,5.406,1511,4.514,1683,5.989,1684,3.359]],["t/510",[24,0.107,34,4.296,56,5.51,69,2.426,102,3.897,155,1.992,168,3.135,170,2.543,193,1.533,219,3.337,221,3.649,399,2.775,420,2.157,428,2.579,431,2.132,436,3.476,589,2.196,590,4.86,622,2.096,676,4.14,720,3.147,760,3.897,846,3.742,860,3.445,963,4.284,1265,4.863,1391,6.045,1392,5.143,1508,3.483,1513,5.143,1517,4.012,1685,5.51]],["t/512",[24,0.108,34,3.595,102,4.241,110,1.249,155,3.147,168,2.623,207,2.281,208,1.552,436,2.909,487,2.952,584,3.304,590,4.205,655,4.434,720,3.425,956,4.302,1041,3.043,1271,4.241,1508,4.782,1632,3.749]],["t/515",[24,0.109,56,3.45,83,2.285,110,1.075,125,3.785,155,2.789,165,2.374,167,1.869,168,3.003,170,1.592,193,0.96,204,2.352,207,1.312,208,1.601,214,1.56,219,3.746,223,5.773,228,5.385,236,1.779,237,4.68,261,2.636,262,4.437,268,2.62,380,4.929,410,5.459,431,1.335,494,2.732,565,2.258,595,1.779,659,4.818,724,1.738,831,1.989,842,2.971,846,2.343,847,2.904,862,1.779,944,2.028,965,2.314,1041,3.139,1100,3.128,1271,3.651,1283,2.157,1343,5.663,1345,3.599,1508,4.876,1558,3.785,1632,3.227,1681,4.035,1686,4.413,1687,4.413,1688,3.327,1689,3.221,1690,4.035,1691,5.663,1692,4.413,1693,4.413,1694,4.413,1695,4.413,1696,4.413,1697,4.413,1698,4.035,1699,4.413,1700,4.413]],["t/517",[24,0.108,110,1.09,154,3.385,204,2.485,207,2.636,208,2.225,219,4.197,374,1.031,380,5.208,420,2.713,424,3.602,590,2.91,831,3.018,862,2.699,944,3.077,1267,3.204,1275,6.121,1442,6.929,1450,3.51,1701,8.862,1702,5.743,1703,6.695,1704,6.695,1705,5.743]],["t/519",[20,3.631,24,0.108,56,4.315,69,3.358,102,3.052,110,0.899,125,4.734,155,2.757,168,1.888,193,1.2,204,1.381,219,2.613,223,4.027,268,3.869,291,4.501,380,2.893,436,2.093,516,4.027,565,2.823,584,3.346,589,2.8,590,2.399,595,3.13,622,2.9,718,3.191,720,2.465,731,2.969,847,5.11,881,2.698,921,4.072,1041,4.078,1073,4.734,1249,3.808,1265,3.808,1267,2.641,1271,4.294,1508,3.838,1632,3.796,1667,3.911,1677,5.045,1706,5.519,1707,5.045,1708,5.519]],["t/521",[20,4.09,24,0.108,69,3.294,155,1.757,176,2.34,185,2.198,193,1.352,214,2.198,268,4.256,436,3.198,494,5.22,584,2.678,586,5.332,589,1.937,592,2.357,622,2.508,718,3.594,720,3.766,830,3.731,842,5.677,860,3.038,862,2.505,921,3.259,1041,4.256,1271,4.662,1317,4.406,1505,5.069,1508,3.072,1632,3.038,1667,4.406,1669,5.332,1670,4.86]],["t/523",[24,0.108,102,2.974,110,1.771,155,3.074,167,2.277,168,3.482,170,2.752,174,3.925,193,1.17,207,2.268,208,1.543,348,5.018,359,2.751,365,3.621,375,2.601,398,2.542,420,2.335,428,3.242,436,2.039,476,2.101,487,2.07,565,2.751,589,1.676,590,4.595,595,2.168,597,2.893,635,3.329,720,2.402,846,2.856,860,2.629,874,2.688,965,2.82,1508,4.379,1534,4.205,1632,2.629,1641,4.917,1665,5.018,1667,3.812,1709,3.812,1710,4.613]],["t/525",[24,0.109,69,3.498,155,1.982,160,1.709,193,1.041,198,3.823,201,2.392,207,1.423,208,0.968,268,3.292,374,0.737,420,1.465,428,2.565,431,2.121,436,1.815,480,1.913,584,4.189,590,4.226,622,2.467,655,2.767,720,2.137,723,5.54,744,5.717,831,2.157,837,2.919,860,2.339,862,1.929,921,2.509,944,2.199,956,2.684,997,3.222,1041,1.899,1084,6.84,1271,2.646,1314,2.962,1508,3.465,1632,2.339,1670,3.741,1711,4.785,1712,3.722,1713,4.785,1714,4.785]],["t/529",[24,0.106,155,2.191,176,3.667,212,3.075,268,4.433,584,4.196,590,3.368,655,4.481,862,3.124,876,3.051,1041,3.864,1084,5.218,1139,6.321,1508,3.83,1509,6.059,1632,3.788,1669,6.648,1670,6.059,1715,7.085,1716,7.75,1717,7.75,1718,7.085,1719,6.648]],["t/531",[24,0.108,110,1.69,155,2.071,160,1.787,165,3.942,168,3.871,170,2.644,193,1.594,204,2.351,262,4.11,365,4.933,380,3.842,486,3.582,590,3.184,686,4.236,849,4.172,1283,3.582,1490,4.11,1508,4.645,1510,5.729,1672,5.729,1673,5.347,1720,6.699,1721,6.699]],["t/533",[24,0.109,80,2.256,155,2.515,160,1.321,176,2.04,204,1.355,208,1.551,214,1.915,268,3.041,308,3.738,326,2.84,380,4.019,494,3.354,512,2.201,589,1.688,724,2.133,830,3.937,837,2.256,842,5.161,846,2.877,876,2.133,881,2.648,1037,2.708,1041,3.041,1070,4.953,1084,3.647,1139,4.418,1265,3.738,1271,2.996,1283,2.648,1508,4.78,1510,4.236,1632,4.349,1676,3.647,1718,4.953,1719,8.296,1722,5.417,1723,5.417,1724,4.418]],["t/535",[24,0.108,69,2.415,155,2.873,160,2.478,176,2.64,193,1.526,268,2.783,375,4.418,436,2.66,584,3.936,589,3.167,720,3.132,723,3.825,823,4.722,876,2.761,921,3.677,1041,4.272,1084,4.722,1086,3.288,1271,3.878,1508,5.022,1632,4.466,1725,7.014]],["t/537",[24,0.109,34,2.374,69,3.567,98,1.935,110,1.19,155,2.929,160,1.781,193,1.102,207,1.506,208,1.025,222,3.41,348,3.332,359,2.591,420,1.55,436,1.921,487,1.949,505,2.689,584,4.285,589,1.578,590,3.175,622,2.172,655,2.928,663,1.827,720,2.262,862,2.041,963,3.078,969,3.959,1041,2.898,1271,2.8,1505,4.13,1508,5.279,1517,2.883,1632,4.189,1665,3.332,1667,3.589,1726,6.679,1727,4.344,1728,4.344]],["t/539",[24,0.109,69,3.405,110,1.081,268,2.633,375,3.209,559,4.467,589,2.745,590,2.884,591,3.049,622,1.973,718,3.836,830,2.936,837,3.668,860,3.243,921,3.479,1041,2.633,1447,4.703,1729,5.188,1730,5.188]],["t/541",[24,0.109,69,3.117,155,1.955,160,1.686,191,3.496,584,2.979,590,4.386,622,2.057,678,3.626,687,4.204,723,5.504,744,5.639,830,4.006,837,2.879,921,3.626,997,4.656,1508,3.418,1632,3.38,1729,5.406,1731,6.915]],["t/543",[24,0.108,69,2.746,155,1.621,160,1.398,193,1.735,204,1.434,207,1.705,208,1.614,268,3.165,431,1.735,436,3.025,487,2.207,533,2.825,590,4.31,595,3.697,622,2.372,718,4.612,720,2.561,723,5.002,862,2.311,921,3.006,944,2.635,1041,4.392,1084,5.37,1271,5.763,1282,3.86,1508,2.833,1632,2.802,1667,4.063,1670,4.482,1715,5.241,1719,4.917,1732,5.241]],["t/545",[24,0.104,1733,9.682]],["t/547",[24,0.108,155,2.654,158,3.347,159,3.463,160,2.005,168,2.049,170,2.161,185,2.117,191,3.028,193,1.303,204,2.056,207,2.445,208,1.663,236,2.414,334,4.514,374,0.922,431,1.812,480,2.395,522,4.682,589,1.866,731,3.222,795,4.245,849,3.41,851,4.692,876,3.978,877,1.833,894,4.68,1267,4.491,1450,5.297,1468,4.371,1734,3.463,1735,4.884,1736,5.989]],["t/549",[24,0.109,83,1.784,153,0.948,155,2.525,158,1.807,160,2.281,168,1.866,191,1.742,193,1.473,204,1.365,207,1.622,208,1.37,214,1.218,236,2.73,286,2.758,316,1.684,374,1.44,401,1.306,423,2.693,431,2.049,480,1.378,567,2.442,575,1.446,581,4.112,597,1.853,639,1.703,731,4.145,745,1.378,812,2.442,830,1.524,831,1.553,849,1.961,851,1.722,862,1.388,876,1.356,894,1.961,965,1.806,1104,2.377,1258,2.955,1267,4.273,1308,2.758,1436,3.979,1448,4.265,1450,4.905,1468,2.514,1529,2.094,1689,2.514,1734,1.992,1737,3.149,1738,2.267,1739,3.445,1740,2.597,1741,3.149,1742,2.809,1743,3.445,1744,3.445]],["t/551",[24,0.106,102,3.973,155,2.031,167,3.042,168,2.457,170,3.71,176,2.705,193,1.563,231,3.334,236,2.896,377,3.474,420,2.199,431,2.174,434,4.958,484,6.162,520,2.807,639,3.551,956,5.206,1038,4.837,1283,3.512,1438,4.536,1450,3.767,1497,6.568,1529,5.641,1688,5.416,1745,7.184,1746,7.184,1747,5.416,1748,6.162,1749,5.617,1750,8.484,1751,5.243,1752,5.243,1753,7.184,1754,7.184]],["t/553",[24,0.108,160,1.654,190,3.7,193,1.945,200,2.734,204,2.388,207,2.404,208,1.636,236,1.845,374,1.244,398,1.526,401,1.736,431,2.446,476,1.788,480,2.713,575,1.922,631,4.369,639,2.262,831,2.064,837,1.906,876,1.802,877,2.077,944,2.103,978,3.733,986,5.443,1086,3.18,1112,3.926,1308,2.314,1342,4.185,1450,2.4,1529,2.782,1755,3.926,1756,4.577,1757,4.577,1758,4.577,1759,3.926,1760,4.577,1761,4.577,1762,4.577,1763,4.577,1764,4.577,1765,4.577,1766,8.091,1767,4.577,1768,4.577,1769,6.785,1770,6.785,1771,6.785,1772,4.577,1773,6.785,1774,4.577,1775,7.464,1776,4.577,1777,4.577,1778,3.45,1779,4.577,1780,4.577,1781,4.577,1782,4.577,1783,4.577]],["t/555",[24,0.108,155,2.448,168,3.567,344,4.019,420,2.651,1282,5.83,1468,6.32,1721,7.917]],["t/557",[24,0.109,98,2.279,153,2.255,155,3.088,160,1.455,168,3.737,170,2.958,203,4.228,204,2.343,214,2.898,373,3.016,383,3.882,437,4.865,512,2.423,532,2.001,589,1.859,848,5.116,944,3.767,1299,3.764,1468,5.982,1529,3.626,1784,5.453,1785,5.965,1786,5.965]],["t/559",[24,0.109,155,2.287,208,1.637,401,3.794,480,3.235,745,3.235]],["t/561",[24,0.106,170,3.405]],["t/563",[24,0.109,102,2.296,149,2.177,155,1.174,168,1.42,193,1.852,204,1.039,208,0.84,219,3.611,231,3.538,236,2.542,237,5.404,261,3.767,374,0.639,420,1.271,422,1.89,431,1.908,520,1.622,522,3.246,575,1.743,581,3.13,639,2.052,670,3.796,731,3.393,777,3.13,788,3.386,849,2.364,851,2.075,877,1.271,1038,5.133,1217,2.364,1267,3.648,1283,2.03,1308,2.1,1392,3.03,1436,2.44,1438,2.03,1449,3.13,1529,2.524,1656,3.904,1689,4.602,1734,2.401,1740,4.754,1751,3.03,1752,3.03,1766,4.93,1778,3.13,1787,4.152,1788,4.152,1789,5.765,1790,4.152,1791,4.152,1792,4.152,1793,4.152,1794,4.152,1795,4.152,1796,4.152,1797,3.386,1798,4.152,1799,4.152,1800,3.562,1801,3.246,1802,4.152,1803,6.306,1804,6.306,1805,6.306,1806,4.152,1807,4.152,1808,4.152,1809,6.306,1810,4.152,1811,3.796,1812,4.152,1813,3.562,1814,4.152,1815,5.765,1816,4.152]],["t/565",[20,5.323,24,0.108,208,1.637,236,3.261,380,4.242,401,3.068,420,2.477,434,5.583,697,5.734,745,3.235,1267,4.787,1308,4.091,1436,4.753,1450,4.242]],["t/567",[24,0.108,191,4.379,374,1.333,480,3.463,1468,6.32,1817,7.917,1818,7.917]],["t/569",[24,0.108,155,2.157,167,4.084,170,2.753,176,2.873,204,1.909,236,3.887,374,1.174,377,3.69,428,2.792,434,6.655,480,3.051,624,3.346,849,4.344,944,3.506,956,5.41,1438,3.73,1747,5.751,1748,6.545,1749,5.966,1750,6.976,1819,7.63]],["t/571",[24,0.109,155,1.728,158,2.762,170,2.206,204,2.086,334,4.608,344,2.837,374,0.941,522,4.779,639,3.021,664,4.461,812,4.333,876,3.282,894,4.746,965,3.205,1450,3.205,1747,4.608,1749,4.779,1778,4.608,1818,5.589,1820,6.113,1821,6.113,1822,6.113,1823,8.337,1824,6.113,1825,6.113,1826,5.243,1827,5.243,1828,6.113,1829,5.589,1830,4.779]],["t/573",[24,0.103,98,3.289,185,3.044,374,1.325,505,4.572,589,2.683,769,5.143,795,6.102,876,3.39,921,4.514,1139,7.021,1145,5.233,1450,4.514,1735,7.021,1831,4.303,1832,5.665,1833,8.609,1834,7.871,1835,8.609]],["t/575",[24,0.102]],["t/577",[24,0.106,168,3.186,831,4.2,1836,9.316]],["t/579",[24,0.103,380,5.011,422,4.35,849,5.441]],["t/581",[24,0.108,204,2.013,231,3.734,398,3.324,420,2.463,506,5.703,745,3.987,851,4.022,1837,9.115,1838,8.046,1839,6.562,1840,7.356,1841,8.046,1842,8.046,1843,8.046]],["t/583",[24,0.107,168,3.643,170,3.515,204,1.939,208,1.568,231,4.52,321,5.348,384,6.064,399,3.835,635,4.798,745,3.099,851,3.874,874,3.874,1195,6.059,1839,6.321,1840,7.085,1844,7.75,1845,7.75]],["t/585",[24,0.109,155,3.096,167,2.546,168,3.746,185,2.915,231,4.921,377,2.908,380,3.153,434,4.15,437,6.723,439,4.262,440,5.843,697,5.843,851,3.006,956,3.373,1421,5.498,1665,3.957,1839,6.723,1846,4.904,1847,6.013,1848,6.013,1849,6.013,1850,6.013,1851,6.013,1852,6.013,1853,6.013,1854,6.013,1855,6.013,1856,6.013]],["t/587",[24,0.107,185,2.755,204,1.949,231,4.955,236,3.939,718,4.505,851,4.884,1267,3.728,1436,6.273,1450,5.123,1734,4.505,1747,5.873,1749,6.091,1839,6.354,1857,7.791,1858,7.791,1859,7.791,1860,7.791]],["t/589",[24,0.107,155,2.157,160,2.352,170,2.753,193,2.098,344,3.541,374,1.484,401,2.894,431,2.918,486,3.73,513,3.125,659,5.568,665,5.966,795,7.495,1324,4.914,1450,4,1861,6.976,1862,7.63,1863,7.63,1864,6.545,1865,6.976,1866,6.223]],["t/591",[24,0.107,193,1.906,1338,4.714,1450,4.594,1735,8.565,1867,6.047,1868,6.211]],["t/593",[24,0.106,185,3.154,207,2.653,208,1.805,344,4.14,876,3.513,1308,4.511,1450,4.677,1831,4.459,1869,6.975]],["t/595",[24,0.108,158,3.216,168,2.637,176,2.903,185,2.726,204,1.929,208,1.964,398,2.57,399,3.035,506,5.464,512,3.132,745,3.882,830,3.412,876,3.035,894,4.389,1123,6.613,1490,4.325,1870,4.042]],["t/598",[24,0.109,155,2.191,170,2.797,193,1.686,431,2.345,1038,5.218,1267,3.708,1438,3.788,1450,5.106,1688,5.842,1751,5.656,1752,5.656]],["t/600",[24,0.109,80,2.61,155,2.717,158,2.077,167,4.069,168,2.144,176,2.36,185,2.216,204,2.404,214,2.216,236,3.418,512,2.547,876,2.468,894,3.569,956,3.516,1267,3,1747,4.725,1749,4.901,1751,4.575,1752,4.575,1826,5.377,1827,5.377,1829,5.731,1871,5.731,1872,5.731,1873,6.269,1874,5.112,1875,5.377,1876,5.377,1877,6.269,1878,6.269]],["t/602",[24,0.108,1038,5.477,1267,3.892,1283,3.976,1438,3.976,1448,6.36,1450,4.265,1747,6.132,1751,5.936,1752,5.936,1879,8.135,1880,8.135,1881,6.977,1882,8.135]],["t/604",[24,0.109,158,2.311,160,1.159,165,2.558,193,1.034,214,2.467,256,2.432,261,2.84,410,3.281,422,3.762,431,1.439,570,3.717,740,4.507,830,2.104,876,1.872,970,4.241,1040,3.877,1077,5.984,1415,3.281,1436,2.793,1449,7.31,1529,2.89,1531,6.864,1734,2.749,1775,5.455,1875,5.984,1876,5.984,1883,6.977,1884,6.977,1885,6.245,1886,3.37,1887,4.754,1888,8.265,1889,6.977,1890,4.754,1891,4.754,1892,5.704,1893,4.754,1894,4.754,1895,5.984,1896,4.754,1897,4.754,1898,4.754,1899,4.754,1900,4.078,1901,4.754,1902,4.754,1903,4.754,1904,4.754,1905,4.754,1906,4.754,1907,4.078,1908,4.754,1909,6.379,1910,6.379,1911,4.754,1912,4.754,1913,4.754]],["t/606",[24,0.108,165,4.022,176,2.814,226,3.97,256,3.825,512,3.037,830,3.308,905,5.845,970,4.544,1236,5.845,1267,3.577,1297,5.635,1448,5.845,1449,5.635,1875,8.165,1876,8.165,1885,4.814,1909,6.834,1910,6.834,1914,7.475,1915,7.475]],["t/608",[24,0.109,102,3.063,291,4.518,422,3.544,512,2.251,740,4.246,1038,5.243,1124,4.176,1236,6.088,1438,4.402,1449,4.176,1656,4.821,1688,8.265,1751,7.789,1752,7.789,1826,4.751,1827,4.751,1885,5.799,1916,5.539,1917,5.539,1918,4.751,1919,7.787,1920,5.539,1921,5.539,1922,5.539,1923,5.539,1924,5.539,1925,5.539,1926,5.539]],["t/610",[24,0.109,123,5.666,154,3.513,155,2.567,160,1.694,191,3.513,204,1.738,207,2.7,208,1.837,236,2.8,401,2.635,486,3.396,862,2.8,1267,3.324,1438,3.396,1450,5.624,1468,5.07,1751,5.07,1752,5.07,1927,5.959]],["t/612",[24,0.104,1928,9.682]],["t/614",[24,0.109,110,1.78,154,2.77,155,2.53,160,1.884,193,1.192,204,1.37,208,1.811,212,2.173,316,3.776,344,2.542,374,1.637,383,2.594,422,3.516,431,1.658,476,2.14,480,3.089,575,3.244,589,1.707,597,2.947,673,2.124,724,3.042,731,2.947,738,2.987,770,3.272,831,3.483,862,2.208,907,2.909,1107,2.987,1232,3.997,1267,2.621,1283,2.678,1299,4.876,1308,2.77,1684,3.073,1929,3.167,1930,5.008]],["t/616",[24,0.109,83,1.614,110,1.826,150,1.461,153,1.385,160,0.76,176,1.174,193,0.678,204,1.585,208,1.282,212,1.237,214,1.102,221,1.614,268,1.237,316,2.462,317,1.182,374,1.68,383,4.045,422,2.884,431,0.943,476,2.476,480,1.247,513,1.277,532,1.046,533,0.96,575,3.055,589,0.971,597,3.915,663,1.125,673,3.486,724,1.227,731,2.71,740,1.7,770,1.862,830,2.229,831,2.271,907,1.655,944,1.433,970,1.895,1005,1.476,1107,1.7,1120,1.433,1232,2.275,1267,2.41,1283,1.524,1299,3.999,1308,4.038,1338,1.677,1438,3.904,1490,1.749,1516,2.209,1679,3.796,1684,3.555,1870,1.634,1929,4.207,1930,2.85,1931,5.485,1932,4.081,1933,2.542,1934,2.674,1935,3.117,1936,2.674,1937,3.117,1938,2.674,1939,3.117]],["t/619",[24,0.109,98,1.846,110,1.886,149,2.533,155,1.996,167,2.046,168,1.653,193,1.051,204,1.766,208,2.063,212,1.917,374,1.502,380,2.533,383,3.343,387,3.941,420,1.479,422,2.199,476,2.759,505,2.566,575,2.029,585,2.502,589,1.506,597,2.6,724,1.902,745,1.932,770,2.887,847,3.18,851,2.415,944,2.221,970,2.937,1107,3.85,1120,2.221,1283,2.362,1389,3.18,1441,3.049,1442,3.778,1445,4.418,1447,3.425,1684,2.711,1931,3.642,1933,3.941,1940,4.418,1941,3.425,1942,4.832,1943,4.832,1944,4.832,1945,4.832,1946,4.832,1947,4.832,1948,5.52,1949,4.418,1950,4.832]],["t/621",[24,0.108,96,4.281,110,1.126,153,2.776,155,1.955,160,2.207,204,2.265,212,2.744,316,4.425,374,1.553,383,4.287,476,2.702,532,2.32,533,2.788,575,2.903,595,2.787,597,3.72,673,2.681,831,3.117,877,2.771,944,3.178,1107,3.771,1200,6.322,1299,6.757]],["t/623",[24,0.108,110,1.176,153,2.561,160,1.76,374,1.734,383,4.879,476,2.821,591,3.318,592,2.738,724,3.665,738,3.937,770,4.313,790,4.556,831,3.255,970,4.389,1107,3.937,1299,4.556,1929,4.174,1933,5.888,1951,7.219,1952,6.6,1953,5.269,1954,5.117,1955,7.219]],["t/625",[24,0.108,49,5.431,110,1.522,153,1.634,155,1.68,212,3.709,286,3.004,354,3.678,374,1.679,383,2.813,476,2.321,575,2.494,597,3.196,673,3.17,724,3.219,770,3.549,1107,4.458,1350,5.641,1438,2.904,1447,4.211,1684,4.586,1929,3.435,1956,4.478,1957,5.941,1958,5.941,1959,5.941,1960,5.941,1961,5.941,1962,5.431,1963,5.431,1964,5.431,1965,5.941,1966,5.431,1967,5.941,1968,4.845,1969,8.175,1970,5.941,1971,5.941,1972,5.431]],["t/627",[24,0.109,110,1.555,153,1.114,160,0.988,193,1.633,204,2.388,208,0.819,231,3.484,232,2.642,268,1.607,316,3.024,319,1.918,374,1.469,383,2.93,385,1.98,398,1.35,399,2.956,401,1.536,408,3.166,420,2.573,422,1.843,423,3.166,431,1.225,476,3.284,480,1.619,516,2.955,517,2.462,631,2.608,635,2.507,673,1.57,724,1.594,787,3.053,831,2.789,846,3.286,877,1.894,908,2.507,944,2.843,970,2.462,978,3.303,986,5.055,1107,2.208,1217,2.306,1266,2.795,1293,2.462,1350,2.795,1438,1.98,1516,2.87,1684,2.272,1759,5.307,1929,2.341,1931,4.664,1932,3.985,1933,3.303,1956,3.053,1972,5.657,1973,4.05,1974,4.05,1975,4.05,1976,4.05,1977,4.05,1978,4.05,1979,4.05,1980,4.05,1981,4.05,1982,4.05,1983,3.474,1984,4.05,1985,3.166,1986,4.05,1987,4.05,1988,4.05,1989,4.05,1990,4.05,1991,4.05,1992,4.05,1993,4.05,1994,3.702,1995,2.955]],["t/629",[24,0.107,110,1.737,155,2.544,193,1.49,212,2.718,222,4.612,316,3.349,374,1.751,476,3.515,480,2.74,575,2.876,597,5.405,724,2.697,731,4.841,770,4.093,1107,4.906,1267,4.305,1283,3.349,1438,5.559,1684,3.843,1734,3.961,1929,3.961,1995,5,1996,6.851,1997,6.851]],["t/631",[24,0.108,110,1.664,154,2.459,158,1.611,204,1.217,231,2.257,232,3.03,236,2.859,345,4.447,374,1.767,422,3.229,485,4.842,575,3.865,597,4.506,724,3.297,731,3.817,830,2.152,908,3.011,1086,2.28,1107,4.567,1267,4.007,1365,4.477,1438,2.378,1449,3.666,1684,2.728,1734,4.102,1748,6.085,1968,3.967,1983,4.172,1998,4.864,1999,4.864,2000,4.864,2001,4.864,2002,4.864,2003,4.864,2004,4.864,2005,4.864,2006,6.486,2007,6.085,2008,4.864,2009,6.085,2010,4.864,2011,4.864,2012,7.183,2013,4.172,2014,4.864,2015,4.864,2016,4.172,2017,3.803,2018,4.864,2019,4.864]],["t/633",[24,0.109,110,1.649,149,1.621,158,1.024,160,1.22,165,1.663,185,1.093,193,0.672,204,0.773,208,0.625,212,1.227,232,2.691,279,4.08,319,4.03,374,1.379,383,2.369,385,1.511,401,1.172,420,0.946,422,1.407,425,1.545,433,4.242,476,1.208,485,1.787,487,1.19,520,1.955,538,2.651,543,7.299,545,2.651,575,2.1,597,3.895,724,1.97,734,1.76,738,1.686,770,4.75,785,2.33,786,2.191,812,4.466,859,1.951,978,5.905,986,3.368,1037,1.545,1107,3.948,1262,2.417,1266,2.133,1299,1.951,1365,3.157,1431,2.651,1438,2.445,1676,2.081,1709,2.191,1734,1.787,1759,4.291,1892,2.133,1895,2.651,1931,2.33,1968,2.521,2006,2.826,2007,2.651,2009,5.404,2012,2.651,2020,2.826,2021,6.821,2022,3.091,2023,3.091,2024,3.091,2025,3.091,2026,3.091,2027,4.573,2028,3.091,2029,3.452,2030,3.091,2031,3.091,2032,3.091,2033,5.002,2034,3.091,2035,6.301,2036,5.76,2037,5.002,2038,5.002,2039,3.091,2040,3.091,2041,3.091,2042,3.091,2043,3.091,2044,3.091,2045,3.091,2046,2.651,2047,3.091,2048,2.826,2049,2.521,2050,2.521,2051,3.091,2052,3.091,2053,3.091,2054,3.091,2055,3.091,2056,3.091,2057,3.091,2058,3.091,2059,3.091,2060,3.091,2061,3.091,2062,3.091,2063,3.091,2064,3.091,2065,3.091,2066,3.091,2067,3.091]],["t/635",[24,0.108,54,2.673,80,1.894,110,1.682,153,1.858,155,1.286,164,4.277,185,1.608,193,1.752,208,0.92,212,2.68,214,1.608,232,1.943,254,2.673,319,3.198,374,1.668,383,2.154,385,2.224,431,1.377,476,3.72,485,3.905,516,3.32,575,1.91,597,3.633,645,4.171,724,1.791,731,2.447,770,2.718,911,2.871,1107,3.683,1125,3.902,1267,2.177,1299,5.083,1350,3.139,1375,4.349,1438,3.301,1516,3.224,1929,2.63,1962,4.159,1963,4.159,1964,4.159,1966,4.159,1968,3.71,1994,4.159,2007,3.902,2009,6.909,2012,3.902,2016,3.902,2017,3.557,2021,3.902,2068,4.549,2069,4.549,2070,4.549,2071,4.549,2072,3.429,2073,4.549,2074,4.549,2075,4.549,2076,4.549,2077,4.549,2078,4.549,2079,6.753,2080,6.753,2081,4.549]],["t/637",[24,0.108,110,1.373,193,1.352,204,2.394,212,3.346,214,2.198,231,5.25,321,5.819,374,1.651,476,3.739,512,2.525,516,4.536,575,2.61,597,3.344,851,3.107,1195,7.481,1431,5.332,1438,3.038,1516,4.406,1676,5.677,1679,6.356,1684,3.487,1801,6.592,2082,6.216,2083,6.216,2084,6.216,2085,6.216,2086,6.216,2087,6.216,2088,6.216,2089,6.216,2090,6.216,2091,6.216,2092,5.332]],["t/639",[24,0.106,158,2.819,176,3.204,185,3.009,204,2.129,214,3.009,373,4.303,487,3.275,512,4.192,532,2.855,533,2.621,907,4.519,944,3.911,1308,4.303,1929,4.92,2093,8.51]],["t/642",[24,0.107,98,2.524,155,1.867,176,2.487,185,3.489,226,3.508,374,1.519,476,2.581,505,3.508,591,3.036,638,3.463,659,4.821,1009,5.387,1107,3.602,1232,4.821,1323,5.165,1324,4.254,1326,5.387,1327,6.039,1330,5.165,1338,3.554,1520,4.558,1864,5.666,1865,6.039,1866,7.163,1867,4.558,1929,3.819,2094,5.387,2095,8.783,2096,8.03,2097,7.163,2098,6.039,2099,5.165,2100,6.039,2101,6.039,2102,6.039,2103,6.606,2104,6.606,2105,6.606,2106,6.606,2107,6.039,2108,6.606,2109,6.606,2110,5.387,2111,5.387]],["t/644",[24,0.107,110,1.591,204,1.949,208,1.576,231,3.616,327,4.37,344,3.616,347,4.505,422,3.546,517,4.736,663,2.811,831,3.512,843,5.127,844,6.354,1005,5.056,1167,7.123,1168,6.683,2112,7.791,2113,7.791,2114,7.791,2115,7.791,2116,7.123]],["t/646",[24,0.108,110,1.824,154,4.648,155,2.599,160,1.727,204,2.3,208,1.86,374,1.09,383,3.353,422,3.223,476,3.592,480,2.832,623,4.16,645,3.667,673,2.746,740,3.861,907,3.76,944,3.254,1107,3.861,1308,3.58,1442,5.536,1516,5.019,1870,3.712,1929,4.094,1932,4.56,1936,6.074,1948,5.536]],["t/648",[24,0.109,80,2.504,110,1.343,155,1.7,179,3.723,193,1.793,319,2.848,326,3.153,374,1.558,422,2.737,428,2.2,433,4.049,476,3.221,485,3.477,532,2.018,533,2.539,575,3.461,597,3.235,624,2.637,637,4.049,645,3.114,770,3.592,812,4.262,881,2.939,905,6.445,1005,2.848,1086,2.819,1088,4.049,1107,5.129,1929,5.439,2072,4.533,2117,6.013]],["t/651",[24,0.108,150,3.577,155,2.157,185,2.698,204,2.645,214,3.41,327,4.28,512,4.296,673,2.959,740,4.161,944,4.859,1929,4.412,1932,4.914,1934,6.545,2118,7.63]],["t/653",[24,0.108,83,3.548,153,1.885,154,3.464,158,2.27,176,3.387,193,1.49,374,1.546,476,2.677,485,3.961,487,2.637,512,3.655,532,3.371,533,2.771,881,3.349,1107,3.736,1177,4.093,1323,5.356,1490,3.843,1516,4.856,1929,5.202,1932,5.794,1948,5.356,2099,5.356,2107,6.263]],["t/655",[24,0.108,80,2.879,110,1.474,193,1.504,226,3.672,344,3.209,374,1.788,383,4.287,431,2.092,476,2.702,512,2.809,724,2.723,1005,3.275,1107,4.936,1237,4.55,1734,3.998,1831,5.045,1832,7.046,1929,3.998,1932,4.453,2110,5.639,2111,5.639]],["t/657",[24,0.108,150,3.486,155,2.103,158,2.464,160,2.548,176,2.8,193,1.618,204,2.374,219,3.522,374,1.145,431,2.251,673,2.884,712,4.056,944,3.418,1005,3.522,1168,6.38,1308,3.761,1338,4.002,1870,3.9,1929,6.042,1932,4.79,1936,6.38,2116,6.8]],["t/659",[24,0.109,110,1.695,155,1.819,176,2.422,212,2.552,332,6.297,374,1.785,399,2.533,422,2.928,476,3.372,575,2.701,597,4.643,712,3.508,718,3.719,724,3.397,738,3.508,970,5.246,1237,4.233,1438,3.144,1929,4.989,1948,5.029,2119,6.433]],["t/662",[24,0.109,110,1.9,193,1.698,319,2.633,374,1.586,383,2.633,476,2.173,480,2.223,575,2.334,597,4.2,724,3.074,734,4.445,738,3.032,770,4.664,1107,5.336,1217,3.166,1734,5.217,1929,4.514,2020,7.138,2120,5.56,2121,5.56,2122,5.56]],["t/664",[24,0.109,80,2.702,110,1.593,319,5.416,433,6.585,543,5.566,570,6.786,734,3.695,770,6.238,812,6.932,1338,4.67,1375,4.179,2021,5.566,2049,7.079,2123,5.933,2124,6.489,2125,6.489]],["t/666",[24,0.108,80,3.463,110,1.657,422,3.786,830,3.681,2126,8.318,2127,8.318,2128,8.318,2129,8.318]],["t/668",[24,0.108,110,1.205,155,2.092,374,1.747,383,3.504,422,4.305,476,3.696,575,3.971,597,5.609,734,5.935,849,4.213,1107,4.036,1338,3.982,2130,7.4,2131,7.4]],["t/670",[24,0.106,193,1.964,374,1.39,645,4.676,1299,5.699,1338,4.859,2072,6.807,2123,8.256]],["t/672",[24,0.108,155,2.071,199,3.335,226,4.991,373,3.705,374,1.742,436,2.779,476,2.863,512,2.977,559,4.933,680,7.665,860,3.582,865,5.347,890,4.172,968,4.051,1107,5.125,1929,5.434,2132,5.975,2133,7.327,2134,7.327,2135,6.699,2136,7.327]],["t/674",[24,0.108,110,1.767,153,1.77,155,1.819,204,2.159,208,1.97,212,2.552,316,3.144,373,3.253,374,1.757,383,4.611,476,3.372,480,2.572,575,4.088,597,4.643,673,2.494,724,2.533,734,3.662,770,3.843,908,3.982,944,2.956,1107,4.706,1267,3.078,1299,4.06,1308,3.253,1438,4.218,1734,4.989,2016,5.518,2017,5.029]],["t/676",[24,0.104,2137,9.682]],["t/678",[24,0.109,110,1.369,150,2.902,153,1.703,160,1.509,207,1.841,208,2.073,232,4.078,374,0.953,399,2.437,424,4.524,505,3.287,532,2.077,533,1.906,541,3.167,589,1.929,622,1.841,686,3.579,724,2.437,851,3.094,876,3.759,921,3.245,1120,2.845,1268,4.168,1314,3.832,1338,4.524,1635,4.84,1712,3.287,1831,3.094,2138,4.387,2139,4.168,2140,5.659]],["t/680",[24,0.109,98,1.085,110,1.64,143,1.793,149,1.49,150,2.189,160,1.855,193,1.88,198,2.547,200,1.145,204,0.711,207,2.048,208,2.038,221,1.471,232,3.855,286,1.437,344,1.319,354,1.759,359,3.042,374,0.719,392,2.437,424,4.093,431,2.475,477,2.142,480,1.136,505,2.48,532,2.552,533,2.12,585,3.079,589,2.693,622,0.845,639,1.404,724,1.839,876,3.554,877,2.329,910,1.87,921,1.49,1119,1.961,1120,3.164,1249,1.961,1268,1.913,1311,3.31,1338,3.199,1517,1.618,1709,2.014,1712,1.509,1831,4.088,1832,1.87,2138,3.31,2139,3.144,2141,3.651,2142,2.841,2143,2.841,2144,2.841,2145,2.073,2146,1.961,2147,1.83,2148,2.598,2149,2.598,2150,2.841,2151,2.598,2152,2.598]],["t/682",[24,0.109,110,1.64,158,2.708,160,2.279,193,1.292,198,5.097,207,2.994,208,2.037,219,2.813,249,6.667,374,0.914,383,2.813,480,3.269,533,1.829,585,3.076,639,2.936,645,3.076,862,2.394,876,3.219,1120,2.73,1133,4.845,1311,5.794,1313,4.645,1453,4.845,2153,8.175,2154,5.941,2155,5.431]],["t/684",[24,0.106,110,1.41,193,1.884,208,1.752,232,3.698,399,4.106,420,3.192,431,2.62,520,3.384,585,4.484,2156,8.66,2157,7.917]],["t/686",[24,0.108,100,3.899,110,1.549,168,1.23,193,1.515,199,1.637,208,0.728,232,1.536,261,3.371,319,1.703,385,1.758,398,3.032,399,3.106,401,1.364,420,1.728,431,2.107,476,3.082,480,2.257,520,1.405,573,3.522,585,2.922,623,3.315,751,3.287,786,4.936,837,3.284,851,1.797,877,1.728,1120,2.593,1121,2.481,1317,4,1343,3.084,1345,6.434,1350,5.444,1372,3.084,1441,2.269,1531,5.946,1800,3.084,2139,2.421,2158,5.974,2159,3.596,2160,3.596,2161,3.596,2162,3.596,2163,3.596,2164,3.596,2165,3.596,2166,3.596,2167,3.596,2168,3.596,2169,3.596,2170,3.596,2171,7.889,2172,3.596,2173,3.596,2174,3.287,2175,3.596,2176,5.643,2177,5.643,2178,5.159,2179,3.596,2180,5.643,2181,3.596,2182,3.596,2183,3.596,2184,3.596,2185,3.084,2186,3.596,2187,3.596,2188,3.596,2189,3.596,2190,5.643,2191,3.596,2192,5.643,2193,3.596,2194,2.366,2195,3.596,2196,3.287,2197,2.811,2198,3.596,2199,3.596,2200,3.596,2201,5.643,2202,5.643,2203,3.596,2204,3.596,2205,3.596,2206,3.596,2207,3.596,2208,3.287,2209,3.596,2210,3.596,2211,3.596]],["t/688",[24,0.109,100,1.849,110,1.506,129,2.198,168,1.28,191,1.892,193,1.753,204,0.936,208,0.757,232,1.598,286,1.892,347,2.163,374,0.896,384,2.13,398,2.687,399,3.438,420,1.146,428,1.369,431,1.761,432,4.509,434,2.582,478,2.925,520,1.462,529,3.209,585,4.174,639,1.849,773,3.209,874,1.87,877,1.146,910,2.462,1120,2.675,1324,2.41,1338,2.013,1441,2.361,1558,3.209,1656,2.316,1698,3.421,1831,1.87,2029,2.582,2072,2.821,2148,3.421,2158,4.993,2197,2.925,2212,3.742,2213,5.322,2214,3.742,2215,3.421,2216,5.821,2217,4.551,2218,8.061,2219,3.742,2220,3.742,2221,3.742,2222,3.742,2223,3.742,2224,3.742,2225,3.742,2226,3.742,2227,3.742,2228,3.742,2229,3.742,2230,6.128,2231,3.742,2232,3.742,2233,3.742,2234,3.742]],["t/690",[24,0.107,208,1.742,232,3.677,424,4.632,724,3.39,876,3.39,1338,4.632,1831,5.194,2138,6.102,2139,5.796]],["t/692",[24,0.108,110,1.164,160,1.743,193,2.231,204,1.789,431,3.103,487,2.752,513,2.928,573,3.615,724,2.815,790,4.512,826,4.512,877,2.832,1321,5.59,2138,5.067,2139,4.814,2235,6.536,2236,7.15,2237,7.935,2238,7.15,2239,7.15,2240,6.536]],["t/694",[24,0.109,80,1.705,96,2.535,100,2.024,110,1.482,149,2.147,153,1.126,158,3.014,160,2.061,170,1.478,190,3.402,193,1.839,198,2.233,208,0.829,212,1.625,214,1.448,232,1.749,254,2.406,286,3.155,292,3.087,354,4.68,374,0.63,398,2.818,424,3.357,435,2.535,476,1.6,487,2.909,512,1.664,520,1.6,522,3.201,573,3.155,589,1.944,592,2.366,622,1.218,623,3.666,724,1.612,826,2.584,831,1.846,876,2.457,888,2.535,1048,2.988,1086,3.543,1119,4.306,1254,3.201,1441,3.938,1470,3.087,1691,3.512,2029,2.826,2138,2.902,2139,6.712,2141,4.878,2174,3.744,2230,3.512,2237,5.352,2240,3.744,2241,4.095,2242,4.095,2243,3.744,2244,4.095,2245,4.095,2246,3.744,2247,3.201,2248,4.095,2249,3.744,2250,2.826,2251,6.24]],["t/696",[24,0.109,98,1.252,110,1.601,114,1.865,150,1.536,160,1.278,185,1.158,193,1.14,198,1.787,200,1.321,204,1.639,207,2.598,208,2.29,232,4.397,424,2.82,431,1.586,494,2.028,512,1.331,585,1.697,724,2.58,742,2.672,831,2.363,842,2.206,849,1.865,860,1.602,876,2.58,877,2.675,1119,2.261,1120,2.409,1132,2.391,1205,2.391,1311,5.307,1441,2.068,1870,5.153,2138,2.322,2139,5.042,2141,5.123,2145,2.391,2149,2.996,2151,2.996,2243,2.996,2246,4.793,2247,2.562,2249,2.996,2252,3.277,2253,3.277,2254,3.277,2255,3.277,2256,6.553,2257,3.277,2258,2.996,2259,3.277]],["t/698",[24,0.109,28,1.469,67,2.55,80,2.554,110,1.152,153,1.946,158,0.985,160,2.038,164,1.579,179,3,193,1.539,198,1.621,207,0.884,208,1.783,232,3.328,254,2.847,286,1.503,288,1.876,292,2.241,326,1.559,344,1.38,347,4.091,348,1.956,366,2.107,374,1.199,399,2.415,424,2.607,431,1.466,435,1.84,487,1.865,495,2.55,500,4.157,513,1.985,532,3.279,533,2.927,541,3.139,559,2.002,565,1.521,589,1.912,591,1.366,592,1.127,595,1.198,641,2.17,645,1.54,678,1.559,686,1.719,791,2.718,809,2.241,860,1.453,874,1.486,997,2.002,1009,2.425,1048,2.17,1053,2.17,1086,2.272,1092,2.241,1119,2.052,1121,2.052,1177,1.776,1183,2.718,1206,4.624,1217,4.028,1301,2.107,1324,1.915,1328,2.55,1329,2.55,1338,3.807,1436,1.747,1490,2.718,1632,1.453,1656,1.84,1831,2.422,1846,5.003,1869,2.324,1870,3.71,2098,2.718,2141,2.324,2146,2.052,2152,2.718,2260,2.973,2261,4.846,2262,2.973,2263,2.973,2264,2.973,2265,2.973,2266,5.609,2267,2.973,2268,2.55,2269,2.718,2270,2.973,2271,2.241,2272,2.718,2273,2.973,2274,3.952,2275,2.973]],["t/700",[24,0.109,80,1.979,110,0.774,160,2.365,176,1.79,208,1.962,226,2.525,232,4.141,344,3.238,374,1.688,424,5.636,481,2.943,513,4.29,559,5.565,874,2.376,876,1.872,1009,3.877,1119,3.281,1268,3.201,1324,3.062,1326,3.877,1328,4.078,1329,4.078,1330,7.119,1517,4.706,1728,5.984,1831,3.487,1869,5.455,1870,3.658,2141,3.717,2274,8.543,2276,4.754]],["t/702",[24,0.109,80,1.531,110,1.854,150,3.312,153,1.943,193,0.8,207,1.093,208,2.063,226,3.049,232,4.096,286,3.572,354,3.555,374,1.229,431,1.112,500,6.06,512,2.87,532,3.218,533,2.953,770,3.43,877,1.758,1217,2.093,1268,3.866,1283,1.797,1311,7.531,1323,2.874,1324,2.368,1326,2.998,1330,2.874,1338,3.801,1831,1.838,2146,2.537,2266,5.249,2277,2.998,2278,3.677,2279,3.677]],["t/704",[24,0.109,80,2.272,110,1.455,158,1.808,160,2.178,176,2.055,185,1.929,204,1.365,207,2.292,208,2.352,221,2.826,232,4.537,374,0.84,424,2.936,512,2.217,513,3.658,591,2.508,709,5.623,862,2.2,876,2.149,1249,5.317,1268,3.674,1296,4.114,1311,3.868,1321,4.267,1330,4.267,1831,2.728,1870,2.861,2258,8.166]],["t/707",[24,0.109,110,1.389,150,2.964,160,2.08,193,1.855,208,1.279,221,3.274,232,2.7,424,3.402,431,2.581,622,1.88,826,3.99,862,2.548,876,2.489,877,1.936,1119,4.363,1120,2.905,1338,4.589,1517,3.6,1635,4.943,1831,4.263,2135,5.78,2140,5.78,2146,4.363]],["t/709",[24,0.104,2280,9.682]],["t/711",[24,0.109,110,1.758,155,1.483,158,1.737,160,1.827,193,1.629,204,1.312,207,2.228,208,2.333,232,3.199,286,2.652,317,1.989,374,1.153,401,1.989,431,1.587,505,2.785,528,3.377,589,2.334,745,2.097,849,2.986,877,1.605,907,2.785,921,2.749,1100,3.717,1120,2.41,1132,3.827,1632,3.661,1684,2.942,1831,4.368]],["t/713",[24,0.109,59,1.954,70,2.118,110,1.729,158,0.962,160,1.472,168,1.626,191,1.468,193,1.98,204,2.277,207,2.458,208,2.051,212,1.152,232,1.24,286,1.468,317,1.802,359,1.485,374,1.529,382,2.118,398,0.968,399,1.871,401,2.289,420,1.455,431,2.111,476,1.134,505,1.541,528,1.869,573,2.403,585,2.461,589,0.905,591,1.334,592,1.101,639,1.435,645,1.503,725,1.832,745,1.161,769,1.734,812,2.057,835,1.734,849,1.653,851,1.451,874,1.451,877,2.53,1100,3.368,1120,3.205,1132,4.404,1283,2.323,1441,1.832,1517,1.653,1632,1.419,1684,1.628,1831,3.016,1870,2.492,1932,3.886,2250,2.003,2281,3.368,2282,2.367,2283,2.367,2284,2.49,2285,2.367,2286,2.49,2287,2.654,2288,3.583,2289,4.077]],["t/716",[24,0.107,59,5.417,199,3.662,221,4.167,317,3.781,337,6.065,374,1.667,398,2.682,401,3.781,591,3.697,592,3.051,725,5.078,835,4.807,1132,5.872,1338,4.329,1831,4.022,1867,5.552,2250,5.552]],["t/718",[24,0.108,110,1.757,160,1.398,168,1.961,185,2.027,193,1.247,199,2.609,208,1.856,232,2.448,374,0.882,398,1.911,399,3.904,401,3.025,420,2.808,431,1.735,478,4.482,505,3.044,573,2.899,585,2.969,589,1.787,622,1.705,623,3.368,712,3.126,851,3.987,877,2.808,965,3.006,1120,3.665,1345,4.676,1350,5.504,1517,3.264,1831,2.866,1870,3.006,2158,6.841,2178,5.241,2196,5.241,2197,4.482,2284,4.917,2285,4.676,2288,4.322,2290,5.733,2291,5.733,2292,5.733,2293,5.733,2294,5.733,2295,5.733,2296,3.956,2297,5.733,2298,5.733,2299,5.733,2300,5.733]],["t/721",[24,0.107,110,1.436,208,2.133,232,3.765,373,4.457,1499,7.189,1870,4.622,2296,6.083]],["t/723",[24,0.107,28,4.065,110,1.34,160,2.464,204,2.058,208,1.664,219,3.895,1517,4.683,1869,6.431,1870,5.299,1932,6.509,2288,6.2,2296,5.676,2301,8.225,2302,6.708]],["t/725",[24,0.109,70,7.029,110,1.569,158,2.086,208,2.246,219,2.981,232,4.113,317,2.387,374,1.588,398,2.099,401,3.912,420,1.927,512,2.558,1100,4.462,1479,4.746,1632,3.077,1831,4.251,1870,3.301,1932,4.054,2296,5.869,2303,5.756]],["t/727",[24,0.109,110,1.702,158,1.914,160,1.956,168,2.743,185,2.835,204,2.304,208,2.115,232,3.934,374,1.234,398,1.926,399,3.157,401,3.041,420,2.455,481,4.965,486,2.824,575,2.426,693,4.517,712,3.151,745,2.31,830,2.557,924,4.355,944,2.655,1100,4.095,1120,2.655,1312,4.517,1632,3.92,1679,6.045,1680,4.712,2296,3.987,2304,5.778]],["t/730",[24,0.109,359,4.87,374,1.151,399,2.943,428,2.735,434,6.569,487,4.031,851,3.736,1324,4.814,1831,3.736,2099,5.845,2305,6.097,2306,7.475,2307,7.475]],["t/732",[24,0.108,110,1.82,199,3.527,208,1.568,232,3.31,317,2.939,327,4.347,374,1.639,401,2.939,486,4.761,686,4.481,1132,5.656,1268,5.218,1632,3.788,1831,3.874]],["t/734",[24,0.108,110,1.303,153,2.201,208,1.619,232,3.418,374,1.74,436,3.768,597,4.305,1120,3.677,1632,3.912,1870,4.196]],["t/736",[24,0.108,199,3.473,208,1.951,214,2.698,232,4.119,317,2.894,398,2.544,401,2.894,424,4.105,432,6.086,487,2.937,512,3.1,565,3.904,877,2.336,1308,3.858,1632,4.714,2289,6.545,2308,5.408,2309,7.63]],["t/738",[24,0.109,110,1.439,160,2.155,170,2.405,193,1.45,204,2.48,208,2.136,232,3.774,374,1.36,431,2.017,528,4.292,532,2.236,533,2.053,541,3.41,575,2.798,589,2.077,741,5.211,965,3.495,1120,3.063,1632,3.258,1831,3.331,1846,5.436,1870,3.495,2296,4.6]],["t/740",[24,0.106,59,5.83,208,1.752,232,3.698,317,3.284,591,3.98,592,3.284,676,5.088,725,5.465,835,5.173,1338,4.659,1632,4.233,1831,4.328,2250,5.976,2310,7.428]],["t/742",[24,0.107,160,2.028,344,4.723,374,1.28,382,6.07,424,4.475,795,5.895,1119,5.74,1735,6.784,1831,4.158,2288,6.27,2311,8.318,2312,7.605,2313,8.318]],["t/744",[24,0.107,109,5.997,110,1.378,193,1.841,199,3.851,262,4.746,317,3.209,359,4.329,374,1.583,436,3.209,676,4.971,1086,3.966,1120,3.888,2310,7.257,2314,8.461]],["t/746",[24,0.108,110,1.532,160,1.466,185,2.126,204,1.504,208,2.311,219,5.186,232,4.528,374,1.269,512,2.443,528,3.873,575,2.525,897,5.158,1104,5.689,1338,3.235,1517,4.693,1632,4.598,1870,5.559,1932,3.873,2271,4.533,2288,6.214,2296,6.491,2312,5.498]],["t/748",[24,0.109,110,1.579,153,1.754,158,2.113,168,2.181,208,2.304,212,2.53,232,4.428,374,1.665,436,2.418,512,2.591,591,2.931,968,5.361,1520,5.92,1632,4.194,1870,3.344,2296,5.92,2315,8.579,2316,6.377]],["t/751",[24,0.109,75,7.798,153,1.739,185,2.235,204,1.582,208,1.726,232,2.7,262,4.784,317,2.398,432,6.521,541,3.235,831,2.85,877,2.611,1121,5.886,1217,3.6,1323,4.943,1324,4.072,1632,3.091,1932,4.072,2097,5.156,2099,4.943,2308,6.045,2317,7.316,2318,6.323]],["t/753",[24,0.109,110,1.819,168,3.904,170,2.321,204,1.609,208,1.746,232,2.747,436,2.44,485,3.719,1120,2.956,1324,4.143,1632,3.144,2296,4.439,2319,4.694,2320,6.433]],["t/755",[24,0.108,204,2.421,208,1.958,232,4.132,374,1.181,907,4.073,944,3.525,1517,4.367,1632,4.73,1870,4.021,2288,5.781,2289,6.579,2321,7.67]],["t/757",[24,0.104,2322,9.619,2323,9.619]],["t/759",[24,0.109,98,2.862,110,0.854,160,1.827,185,1.854,193,1.629,204,2.186,207,1.56,208,2.04,268,2.972,344,2.434,374,1.467,398,2.497,401,1.989,422,2.387,431,1.587,480,2.097,505,2.785,512,2.131,528,3.377,575,2.202,589,2.723,622,1.56,731,2.821,745,4.192,849,2.986,876,2.065,877,2.675,881,2.563,1120,2.41,1194,3.309,1308,3.787,1544,4.277,1832,3.451,1870,4.998,2132,4.277,2281,3.717,2324,4.277,2325,3.451]],["t/761",[24,0.109,109,2.209,110,0.82,130,2.35,153,2.002,155,1.424,158,2.099,160,1.228,168,1.723,170,1.125,176,1.174,185,1.781,193,1.378,204,2.539,207,1.498,208,1.893,214,1.781,262,1.749,344,1.447,359,3.242,374,1.592,398,1.039,401,1.91,420,1.94,422,1.419,431,1.917,505,1.655,512,2.046,520,1.968,575,3.055,587,2.051,589,1.569,622,1.498,712,2.746,745,3.741,771,3.938,835,1.862,837,3.029,849,1.775,862,1.256,876,2.865,877,2.958,894,1.775,1041,1.237,1047,2.674,1086,1.461,1104,2.151,1120,1.433,1145,1.895,1283,2.462,1314,3.118,1742,2.542,1831,1.558,1832,2.051,1870,4.187,2147,2.008,2281,4.491,2324,2.542,2326,3.117,2327,3.117,2328,5.036,2329,5.036,2330,3.117,2331,3.117]],["t/764",[18,6.445,24,0.108,185,2.656,262,4.215,268,2.981,398,2.505,401,2.849,420,2.3,430,6.272,512,3.88,520,2.936,587,4.944,622,2.84,634,6.382,712,4.097,837,3.128,1145,4.567,2332,7.513]],["t/766",[24,0.108,143,4.587,160,1.226,168,2.92,185,2.57,190,3.964,230,4.172,231,3.961,359,2.573,365,3.386,384,5.324,385,2.459,398,1.677,401,1.907,410,3.471,422,3.308,430,4.342,589,1.567,623,2.955,634,4.419,660,5.016,712,2.743,776,3.565,837,2.094,876,1.98,877,1.54,1365,3.174,1620,3.471,1738,3.31,1775,3.932,1892,5.016,1895,4.314,2029,3.471,2048,4.598,2049,4.102,2197,3.932,2217,5.683,2333,4.598,2334,4.598,2335,4.598,2336,5.03,2337,5.03,2338,5.03,2339,4.598,2340,5.03,2341,5.03,2342,5.03,2343,5.03,2344,5.03,2345,5.03,2346,5.03,2347,5.03,2348,5.03,2349,5.03,2350,5.03,2351,4.598,2352,4.314,2353,5.03,2354,5.03,2355,5.03,2356,5.03,2357,5.03,2358,5.03,2359,5.03,2360,5.03,2361,5.03]],["t/768",[24,0.108,144,4.273,185,2.346,190,3.618,214,2.346,359,3.395,384,3.778,428,3.855,430,3.964,481,4.108,624,4.337,634,5.355,660,6.079,712,3.618,837,2.763,1119,6.079,1375,4.273,1403,6.066,1620,4.579,2217,5.188,2325,4.366,2333,6.066,2334,6.066,2335,6.066,2362,6.066,2363,6.635,2364,6.635,2365,6.635,2366,6.635]],["t/770",[24,0.107,190,4.036,193,1.61,200,2.983,204,1.851,431,2.239,628,4.87,631,6.714,639,3.658,851,3.699,877,2.266,983,6.348,1283,3.617,1308,3.742,1775,5.786,1870,3.88,2029,5.107,2351,6.766,2352,6.348,2367,7.4,2368,7.4,2369,7.4,2370,7.4,2371,9.459,2372,7.4,2373,7.4,2374,7.4,2375,7.4,2376,7.4,2377,7.4,2378,7.4,2379,7.4]],["t/773",[20,2.717,24,0.109,110,1.023,149,2.165,168,2.148,170,1.49,193,0.898,204,1.033,208,0.835,212,1.638,305,2.387,359,3.887,374,1.481,384,3.575,398,2.533,399,2.472,420,1.922,430,2.467,431,1.249,505,2.193,512,1.678,520,1.613,534,1.827,567,2.927,585,3.935,589,1.287,634,3.817,745,1.651,776,2.927,837,4.005,874,3.798,877,2.796,908,2.556,924,3.113,940,3.775,941,3.228,1041,3.015,1120,1.897,1145,2.51,1271,2.283,1317,4.451,1544,3.367,1832,2.717,2029,2.849,2380,4.129,2381,4.129,2382,4.129,2383,4.129,2384,3.775,2385,4.129]],["t/775",[24,0.108,96,2.934,185,2.461,190,3.796,193,1.031,200,1.91,204,2.423,208,0.959,214,1.675,231,2.199,384,4.697,385,2.316,401,1.797,428,1.734,486,2.316,624,2.078,660,3.27,745,4.293,830,2.097,837,1.973,851,4.123,877,2.131,986,4.686,1086,2.221,1375,4.483,1415,3.27,1438,2.316,1529,2.881,1620,3.27,1738,3.118,1775,3.705,2147,3.052,2197,3.705,2217,6.45,2281,3.359,2339,6.364,2352,4.065,2386,4.739,2387,8.25,2388,4.739,2389,4.739,2390,4.739,2391,6.961,2392,4.739,2393,4.739,2394,4.739,2395,4.739,2396,4.739,2397,4.333,2398,4.739,2399,4.739,2400,4.739,2401,4.739,2402,4.333,2403,4.333,2404,4.739,2405,7.542,2406,4.739,2407,4.739,2408,4.739,2409,4.739,2410,4.739,2411,4.739]],["t/777",[24,0.108,143,4.303,149,3.575,193,1.483,196,5.14,204,2.508,344,3.165,484,5.849,745,2.727,851,3.408,1104,4.706,1283,3.333,1438,4.385,1705,5.849,1907,5.849,2305,7.315,2405,9.164,2412,8.97,2413,8.97,2414,6.819,2415,6.819,2416,6.819,2417,6.819,2418,6.819,2419,6.819]],["t/780",[24,0.108,98,2.731,134,5.218,185,2.528,214,3.271,321,4.934,374,1.424,487,3.561,512,3.759,554,6.132,622,2.126,722,5.311,976,6.536,1145,4.346,2110,7.545,2111,7.545,2420,8.458,2421,5.218,2422,9.376]],["t/782",[24,0.103,98,3.251,155,2.917,168,2.911,185,3.009,207,3.069,208,2.336,374,1.31,512,3.457,622,2.531,740,4.641,745,3.403,1308,5.217,1870,4.462,2423,8.51]],["t/784",[24,0.108,28,4.327,63,3.027,80,2.737,153,2.168,159,3.8,160,1.603,164,4.979,165,2.36,170,1.583,179,5.805,185,2.324,190,2.392,193,0.954,198,2.392,207,2.344,208,1.992,214,1.551,226,2.329,254,4.631,262,2.461,286,2.218,326,4.916,344,3.05,374,1.213,410,3.027,486,3.853,487,1.688,512,3.202,622,2.344,646,5.361,677,2.716,745,3.75,809,3.307,876,2.588,881,2.144,1145,5.322,1217,2.498,1218,3.578,1278,3.763,1861,4.011,1869,3.43,2325,2.887,2421,3.201,2424,4.387,2425,4.387,2426,4.387,2427,4.387,2428,6.573,2429,4.387,2430,4.387,2431,4.387,2432,4.387,2433,3.763,2434,4.387,2435,4.011,2436,4.387,2437,4.011,2438,4.011,2439,4.387]],["t/787",[24,0.109,63,3.401,98,3.224,155,2.782,158,1.633,185,2.983,204,2.317,207,1.466,208,2.304,327,2.765,344,2.287,374,0.759,512,3.763,528,4.613,575,2.069,622,2.13,722,2.552,745,4.236,771,3.854,842,3.319,876,3.322,907,2.617,944,2.265,1283,3.502,1308,2.492,1504,4.506,1517,4.078,1870,3.756,2420,4.506,2440,4.929,2441,4.506,2442,4.929,2443,4.929]],["t/789",[24,0.109,176,2.476,185,2.325,204,2.191,208,1.992,262,3.689,420,2.013,487,3.789,512,4.568,528,4.235,622,3.251,745,3.937,1308,3.325,1870,4.591,2319,4.799,2421,6.391]],["t/791",[24,0.109,28,2.574,80,2.168,185,1.841,193,1.133,204,1.303,207,2.588,208,2.229,268,3.77,326,2.73,327,4.18,354,3.224,487,2.004,512,3.028,622,1.549,645,2.696,678,2.73,731,5.112,745,4.02,881,2.545,1104,3.593,1145,3.165,1729,4.071,2441,4.761,2444,5.207,2445,6.813]],["t/793",[24,0.109,80,2.123,83,3.802,155,1.442,176,1.92,185,2.596,193,1.597,204,1.276,208,1.741,268,2.023,317,1.934,512,4.348,622,2.799,687,3.1,745,2.936,826,3.218,877,1.561,922,4.662,1053,3.721,1145,5.229,1194,5.429,1225,3.844,1870,2.673,2111,4.159,2132,7.015,2446,10.386,2447,6.712,2448,5.099,2449,5.099,2450,5.099]],["t/796",[24,0.109,193,2.064,204,1.861,268,2.951,319,3.522,326,3.9,512,3.022,622,2.212,745,4.179,851,3.718,1145,4.521,2146,5.133,2445,6.8,2451,6.066]],["t/798",[24,0.109,80,2.726,110,1.6,168,3.36,170,2.362,204,1.638,208,1.325,384,3.727,398,2.183,399,4.585,512,2.66,585,5.087,745,2.618,857,4.778,874,3.272,1120,3.009,2147,4.216,2324,5.339]],["t/800",[24,0.109,80,2.726,190,3.57,208,2.209,384,6.215,401,2.483,430,5.869,512,2.66,634,5.308,745,3.491,851,4.91,911,4.132,1837,8.981,2452,6.547,2453,6.547,2454,6.547,2455,6.547,2456,6.547]],["t/802",[24,0.109,98,2.288,193,1.303,208,1.212,268,2.376,374,0.922,384,4.68,431,1.812,494,3.708,565,5.417,622,2.445,731,3.222,745,3.753,877,1.833,1145,3.641,1656,5.811,2145,4.371,2457,5.475,2458,5.989,2459,5.989,2460,5.475]],["t/804",[24,0.109,80,2.69,207,2.902,208,2.263,226,3.431,268,3.434,315,5.051,326,4.537,374,0.994,565,4.993,686,5.004,712,3.523,731,3.476,745,3.902,944,2.969,1208,4.715,1308,3.267,1656,5.358,2110,5.269,2460,5.907,2461,4.35]],["t/807",[24,0.109,208,1.854,214,2.492,374,1.411,745,3.665,2462,6.443,2463,7.047]],["t/809",[24,0.109,155,2.384,159,3.594,168,2.126,170,2.243,208,1.936,374,0.957,597,4.536,657,4.686,745,4.289,877,1.903]],["t/811",[24,0.109,28,1.854,155,2.617,167,1.588,168,1.995,170,1.354,191,1.897,193,1.756,195,2.589,204,2.499,207,2.128,208,2.312,236,1.512,347,2.169,374,0.577,384,4.074,388,2.468,422,1.707,431,2.165,439,2.659,480,1.5,663,2.105,722,1.943,731,2.018,745,4.103,851,2.915,877,2.834,956,2.104,1048,2.738,1086,1.758,1124,2.828,1194,2.367,1283,2.851,1448,2.933,1529,2.28,1737,3.43,2305,3.059,2464,3.751,2465,3.751,2466,3.751]],["t/813",[24,0.104,2467,9.682]],["t/815",[24,0.109,28,2.574,110,1.754,130,3.925,153,2.05,158,2.469,160,2.317,204,1.303,208,1.922,317,1.975,374,0.801,383,2.466,480,2.98,532,1.747,533,1.604,585,2.696,589,1.623,597,2.802,722,2.696,733,3.353,745,2.082,818,4.247,824,4.904,876,2.934,877,1.594,881,2.545,908,3.224,913,3.691,965,4.563,1005,2.466,1517,2.965,1684,4.882,2468,5.207,2469,3.593]],["t/817",[24,0.109,28,1.128,80,0.951,98,0.872,99,2.087,110,1.646,130,1.721,153,0.628,154,1.154,155,1.696,158,1.683,160,2.583,168,2.051,176,0.86,185,1.375,193,1.592,198,1.245,199,1.77,204,1.955,207,1.511,208,2.163,212,0.906,214,0.807,219,1.081,221,1.182,236,0.92,268,0.906,317,0.866,342,1.47,367,1.862,374,1.478,384,1.3,398,0.761,420,1.555,424,1.228,431,1.815,480,2.927,485,1.32,487,0.879,513,0.935,520,1.519,532,1.704,533,1.564,534,1.01,559,1.537,573,1.154,575,2.133,585,1.182,587,2.559,589,1.212,622,1.784,722,2.014,733,1.47,742,1.862,745,2.398,787,1.721,824,2.559,830,1.721,831,1.753,842,4.038,843,1.502,845,3.862,849,1.3,851,1.141,859,1.441,862,1.567,874,1.141,876,2,877,1.836,881,1.116,890,1.3,894,1.3,913,1.618,927,2.087,942,1.785,944,1.049,965,3.527,1005,1.081,1146,1.862,1147,3.555,1177,1.364,1206,1.721,1308,1.154,1311,1.618,1312,1.785,1314,1.413,1479,4.521,1499,1.862,1517,2.214,1657,1.958,1679,1.721,1680,1.862,1684,2.181,1831,1.141,1868,1.618,2247,1.785,2281,1.618,2469,2.683,2470,2.283,2471,1.958,2472,2.283,2473,2.283,2474,2.283,2475,2.283,2476,3.889,2477,3.171,2478,3.555,2479,3.889,2480,2.283,2481,2.087,2482,3.889,2483,2.283,2484,3.555,2485,2.283]],["t/819",[24,0.109,98,2.818,110,1.768,154,1.614,158,1.057,160,1.252,170,1.152,198,2.799,199,1.453,204,1.845,208,1.039,212,2.037,216,1.94,221,1.653,231,2.988,236,1.286,247,2.329,317,1.947,333,3.377,374,0.491,398,3.248,399,3.399,401,1.21,408,2.495,420,1.971,425,3.218,428,1.878,430,4.828,478,2.495,486,1.56,506,3.638,512,1.297,520,1.247,534,1.412,622,1.915,623,1.875,624,2.251,628,3.377,634,3.12,639,1.577,787,4.853,818,2.603,831,2.314,845,2.055,876,1.257,965,2.691,986,4.966,1005,3.049,1266,3.542,1283,3.606,1311,2.262,1346,2.737,1350,3.542,1364,2.1,1438,1.56,1447,2.262,1529,1.94,1684,1.79,1738,4.236,1985,5.034,2157,2.918,2477,2.603,2486,3.192,2487,3.192,2488,3.192,2489,3.192,2490,3.192,2491,3.192,2492,3.192,2493,3.192,2494,3.192,2495,3.192,2496,3.192,2497,3.192,2498,3.192,2499,5.133,2500,3.192,2501,3.192,2502,3.192,2503,3.192,2504,3.192,2505,3.192,2506,3.192,2507,3.192,2508,3.192,2509,3.192,2510,3.192,2511,3.192,2512,3.192,2513,3.192]],["t/821",[24,0.109,83,2.613,110,1.779,149,2.646,160,1.231,191,2.552,193,1.098,199,3.316,204,1.823,208,1.021,374,0.777,398,3.122,399,3.687,420,1.545,425,3.642,476,1.972,478,3.946,486,3.562,505,2.68,520,3.659,532,1.693,533,1.554,534,3.225,565,4.792,589,1.573,591,2.319,622,2.167,623,2.965,845,3.25,874,2.523,965,2.646,1287,3.015,1321,3.946,1529,3.068,1656,3.124,1684,2.831,1948,3.946,1985,3.946,2308,3.577,2514,5.047,2515,4.614,2516,4.614,2517,5.047,2518,5.047,2519,4.614,2520,5.047]],["t/823",[24,0.109,27,2.339,110,1.156,153,0.823,155,2.008,158,1.613,160,1.732,170,1.757,190,2.656,193,2.072,200,2.483,207,0.89,208,1.247,222,2.014,230,1.462,365,3.279,374,0.948,377,1.446,383,1.416,398,1.624,420,2.174,428,1.094,431,2.787,476,3.275,480,2.463,486,1.462,505,3.771,520,3.054,532,1.003,533,0.921,541,1.53,573,2.463,589,0.932,599,2.566,622,2.833,624,2.136,660,2.064,745,1.196,876,1.918,877,1.886,878,2.339,881,1.462,965,3.23,1005,4.362,1089,5.188,1120,1.374,1206,2.255,1276,6.705,1505,2.439,1691,4.177,1707,2.734,1729,2.339,1784,2.734,2094,2.439,2147,1.926,2185,2.566,2477,2.439,2521,2.991,2522,8.421,2523,2.991,2524,4.87,2525,4.87,2526,4.87,2527,4.87,2528,4.87,2529,4.87,2530,4.87,2531,4.87,2532,2.991,2533,1.926,2534,2.991,2535,2.991,2536,2.991,2537,2.991,2538,2.991,2539,2.734,2540,2.566]],["t/825",[24,0.109,28,3.338,80,1.894,89,3.224,110,1.452,153,1.251,155,1.286,160,1.647,164,2.416,168,1.556,176,1.713,193,0.99,204,1.689,208,1.367,219,2.154,230,3.301,231,2.111,236,1.834,254,2.673,286,2.3,288,4.262,292,3.429,317,1.725,319,2.154,326,2.385,327,2.552,347,2.63,348,2.993,374,1.536,398,2.251,420,1.393,425,2.274,431,1.377,436,1.725,486,2.224,487,1.751,513,1.863,517,2.765,575,1.91,622,2.008,637,3.063,664,5.878,678,2.385,738,2.481,745,1.819,825,3.557,830,2.013,835,2.718,877,1.393,881,2.224,965,2.385,1005,3.198,1053,3.32,1086,2.132,1219,3.557,1254,3.557,1315,3.902,1338,4.333,1490,2.552,1645,4.929,1831,2.274,1868,3.224,2094,3.71,2272,4.159,2433,3.902,2437,4.159,2541,4.549,2542,4.159,2543,4.159,2544,4.549,2545,4.549,2546,4.159,2547,4.549]],["t/827",[24,0.108,28,2.444,110,1.727,153,1.36,158,3.073,160,2.403,185,1.748,204,1.237,208,2.353,214,2.539,219,2.342,254,2.905,286,2.501,331,4.521,344,2.295,347,2.859,357,4.242,374,1.632,436,3.206,517,3.006,532,1.659,533,1.523,575,2.076,622,1.471,745,1.978,830,3.178,835,2.954,845,4.624,876,3.653,894,2.816,907,2.626,1005,4.393,1053,3.609,1086,2.318,1177,2.954,1205,3.609,1217,2.816,1219,3.867,1254,3.867,1338,2.661,1517,2.816,1645,3.609,1868,3.505,2548,7.181,2549,4.945,2550,4.945]],["t/830",[24,0.109,80,2.962,110,1.763,212,3.659,327,3.991,398,3.411,486,4.508,686,5.332,830,3.149,1868,5.043,2551,7.115,2552,6.505,2553,7.115,2554,7.115]],["t/832",[24,0.109,28,2.388,110,1.66,153,1.329,160,1.178,193,1.051,256,2.472,317,3.702,332,3.526,374,0.744,398,3.51,399,3.285,425,5.262,431,1.462,436,1.832,480,1.932,486,2.362,513,1.979,534,2.138,565,5.522,570,3.778,623,4.902,628,3.18,645,3.656,830,2.138,843,3.18,908,2.991,1005,2.288,1040,3.941,1104,3.335,1217,2.751,1268,3.253,1297,3.642,1313,3.778,1335,3.941,1645,3.526,1656,2.991,1868,3.425,2451,3.941,2555,4.832,2556,4.832,2557,4.832,2558,4.832,2559,4.145,2560,4.832]],["t/834",[20,2.526,24,0.109,110,1.183,155,2.642,158,1.272,160,1.448,193,1.778,200,3.294,208,1.202,216,3.61,230,2.903,261,2.293,286,1.941,306,3.51,317,1.456,326,2.013,344,1.782,347,2.22,374,0.591,398,1.28,420,1.175,425,1.919,431,2.473,476,1.5,480,1.535,513,1.572,731,2.065,787,2.894,830,3.214,842,2.585,877,2.502,913,2.721,1005,2.812,1037,1.919,1089,5.471,1254,3.002,1276,7.58,1297,2.894,1335,3.131,1441,2.423,1656,2.377,1801,3.002,1868,4.209,2094,3.131,2457,5.429,2519,3.51,2522,6.639,2561,5.938,2562,3.839,2563,3.839,2564,3.839,2565,3.839,2566,3.293,2567,3.839,2568,3.839]],["t/836",[24,0.109,28,1.12,102,1.253,110,1.705,149,1.188,153,1.063,154,1.146,155,1.893,160,2.227,168,2.805,170,2.153,176,1.454,185,1.366,193,0.84,199,1.031,204,2.284,208,2.01,212,1.533,232,1.65,316,1.107,344,1.051,347,2.234,374,1.406,384,1.29,398,1.288,399,0.892,401,1.465,420,2.713,424,1.219,425,1.132,428,1.414,431,1.169,432,1.43,487,0.872,513,1.582,520,1.509,532,0.76,533,0.698,534,3.226,567,1.606,573,2.554,575,2.812,589,0.706,624,0.994,637,1.525,693,1.771,724,0.892,745,3.113,770,1.353,830,1.003,845,2.488,846,3.556,848,1.943,849,1.29,859,1.43,874,1.132,876,0.892,877,1.546,881,1.888,913,2.738,921,1.188,944,1.041,965,1.188,992,1.848,1005,1.073,1120,1.775,1283,1.107,1287,1.353,1314,1.403,1338,2.078,1441,1.43,1684,2.167,1755,1.943,1867,1.563,2049,1.848,2302,1.848,2305,3.151,2325,2.542,2477,4.119,2478,2.071,2569,2.266,2570,1.771,2571,2.266,2572,2.266,2573,2.266,2574,2.266,2575,2.266,2576,3.863]],["t/838",[24,0.109,61,3.006,110,1.497,160,1.726,185,1.303,193,0.802,201,2.876,208,1.942,214,1.303,374,1.477,383,3.351,420,1.128,487,3.077,512,2.337,533,1.772,534,2.546,595,2.319,722,5.506,771,2.882,831,1.662,877,1.128,913,4.078,936,5.835,965,1.932,968,3.913,1236,2.882,1308,1.864,1520,2.543,1738,2.425,1864,4.935,1867,2.543,2096,6.469,2101,3.37,2146,2.543,2271,2.778,2484,6.469,2559,3.161,2577,4.078,2578,5.753,2579,3.686,2580,4.498,2581,3.686,2582,3.686,2583,3.686,2584,3.686,2585,3.686,2586,3.686,2587,3.686]],["t/840",[24,0.109,110,1.747,155,1.336,158,1.565,160,1.693,185,1.67,191,3.511,193,1.028,204,1.182,208,0.956,212,1.874,300,3.18,316,2.309,374,1.489,431,1.429,436,1.791,512,1.919,565,2.417,597,2.541,777,3.561,788,3.852,830,2.09,877,2.126,881,3.394,965,2.477,1005,2.237,1268,3.18,1287,2.822,1338,2.541,1364,5.418,1868,3.348,2469,6.264,2588,4.319,2589,4.319]],["t/842",[24,0.109,80,1.161,96,1.726,110,1.786,129,1.638,153,1.614,160,0.68,208,0.93,217,2.391,221,2.381,317,2.856,327,3.818,332,2.034,359,2.352,374,0.429,398,2.858,399,2.31,401,1.057,422,2.092,425,3.764,487,1.073,505,1.48,510,2.18,520,1.796,534,2.596,570,2.18,575,1.17,585,1.444,589,0.869,623,2.701,645,1.444,676,2.701,686,1.612,722,1.444,740,1.52,837,1.161,874,1.393,965,1.462,970,2.795,1120,1.281,1153,5.032,1237,1.834,1656,2.846,1676,3.95,1684,1.564,1712,1.48,1956,2.101,2099,2.18,2451,2.273,2481,5.363,2540,2.391,2559,2.391,2590,7.53,2591,7.53,2592,2.788,2593,2.788,2594,7.53,2595,10.642,2596,5.867,2597,2.788,2598,2.391,2599,2.788,2600,2.788,2601,2.788]],["t/844",[24,0.108,98,3.141,110,1.529,130,6.197,153,1.647,155,1.693,160,2.289,193,1.788,204,2.056,208,1.899,219,2.836,299,6.704,374,1.555,383,2.836,431,2.487,436,2.271,480,3.287,494,3.708,533,1.844,575,2.514,589,1.866,595,2.414,722,4.257,771,4.682,842,4.032,877,1.833,921,3.14,944,3.778,965,4.31,1146,4.884,1237,3.941,1287,3.578,1309,4.884,1338,3.222,1517,3.41,2145,5.999,2146,4.133,2185,5.137,2469,4.133,2602,5.989,2603,5.989,2604,5.989]],["t/846",[24,0.104,2605,9.682]],["t/848",[24,0.109,109,3.602,114,4.169,150,2.382,153,1.398,176,1.913,207,1.511,208,1.028,236,2.048,256,2.6,374,0.782,589,2.928,622,1.511,733,5.529,843,3.344,860,2.484,862,2.048,876,2.001,907,2.698,1208,3.708,1272,6.182,1389,3.344,1544,4.144,1666,4.646,1730,3.973,2147,3.273,2598,4.359,2606,5.082,2607,5.082,2608,7.786,2609,4.359,2610,6.472,2611,3.831,2612,4.646,2613,3.973,2614,5.082,2615,4.646,2616,3.831,2617,4.646,2618,5.082,2619,5.082,2620,5.082]],["t/850",[20,1.617,24,0.109,98,1.581,114,1.399,121,2.108,150,1.152,153,0.676,158,0.814,199,1.119,204,0.615,212,0.975,214,0.869,230,1.202,233,1.742,256,1.258,308,1.696,337,1.853,358,2.108,374,1.308,377,3.914,422,1.119,428,0.899,431,0.744,476,0.96,503,2.108,513,1.007,622,0.731,639,1.215,651,4.192,673,0.953,676,1.444,686,1.421,712,1.34,724,0.968,733,2.666,826,2.612,837,1.023,860,2.621,862,3.426,888,3.32,890,1.399,907,1.305,942,4.919,972,2.108,1004,4.236,1093,1.922,1272,5.007,1297,1.853,1307,1.853,1314,1.522,1389,3.528,1727,2.108,1728,2.108,1730,4.192,1738,1.617,2102,2.247,2308,2.934,2461,1.655,2566,2.108,2598,2.108,2608,5.95,2610,5.293,2611,5.293,2612,2.247,2613,1.922,2616,4.042,2617,2.247,2621,2.458,2622,1.853,2623,3.376,2624,2.458,2625,2.247,2626,3.784,2627,2.458,2628,2.458,2629,3.236,2630,2.458,2631,2.458,2632,2.458,2633,2.108,2634,2.458,2635,2.458,2636,2.458,2637,2.458,2638,2.458,2639,2.458,2640,1.922,2641,2.458]],["t/853",[24,0.108,160,2.591,358,6.613,377,4.694,520,3.012,622,2.293,888,4.773,1004,5.191,1037,3.854,2308,5.464,2609,6.613,2611,5.812,2642,7.59,2643,9.708,2644,7.71,2645,7.71,2646,7.71]],["t/855",[24,0.109,39,4.986,98,3.704,110,1.039,160,1.555,231,2.96,513,2.612,622,2.551,734,3.631,786,4.52,812,4.52,837,2.655,857,4.654,858,4.807,862,2.57,973,4.654,1004,6.527,1389,4.196,1995,4.654,2608,4.986,2629,6.707,2640,4.986,2642,4.986,2647,6.377,2648,6.377,2649,6.377,2650,6.377,2651,5.83,2652,5.83,2653,5.47]],["t/857",[24,0.109,160,1.336,221,2.837,233,6.889,256,2.803,343,4.467,374,1.578,385,4.375,431,1.658,436,2.077,520,3.497,676,3.218,705,3.882,734,3.119,837,2.281,860,2.678,862,2.208,888,6.018,942,4.283,963,3.33,1037,3.862,1165,4.467,1730,6.04,1995,3.997,2540,4.698,2610,4.129,2616,5.824,2625,5.008,2626,5.008,2642,4.283,2654,4.467,2655,5.008,2656,5.478,2657,5.478,2658,5.478]],["t/859",[24,0.109,160,1.718,230,2.354,231,2.235,233,4.992,377,4.43,436,1.827,651,3.766,733,5.363,786,3.414,831,2.171,862,1.941,973,3.515,1004,5.606,1272,6.029,1389,5.479,1727,4.131,1730,6.511,1927,4.131,1995,3.515,2308,3.414,2566,4.131,2608,7.622,2611,6.906,2613,6.511,2616,6.277,2623,3.928,2652,4.403,2653,6.042,2654,3.928,2659,4.816,2660,4.403,2661,4.816,2662,4.816,2663,7.044,2664,4.816,2665,7.044,2666,7.044,2667,4.816,2668,4.816]],["t/861",[20,6.296,24,0.109,123,5.069,160,1.516,191,3.143,231,2.885,377,3.006,520,2.429,586,8.208,734,3.539,837,2.588,862,2.505,890,3.539,1004,4.185,1227,5.683,1307,8.085,1389,6.752,2608,4.86,2610,6.356,2611,4.686,2613,4.86,2640,4.86,2642,4.86,2654,5.069,2669,6.216]],["t/863",[18,4.514,24,0.109,158,1.743,160,1.831,214,1.861,233,3.73,374,0.81,377,3.631,575,2.21,734,2.996,786,6.205,837,2.191,862,3.027,888,5.42,983,4.514,1037,2.631,1272,4.941,1389,4.941,1709,5.322,2145,3.841,2308,3.73,2610,3.967,2611,5.661,2613,7.893,2623,4.292,2642,5.871,2653,6.441,2654,4.292,2670,5.263,2671,5.263,2672,5.263,2673,7.509,2674,5.263,2675,5.263,2676,5.263,2677,5.263,2678,5.263,2679,5.263,2680,7.509,2681,5.263,2682,5.263,2683,5.263,2684,5.263]],["t/870",[20,3.941,24,0.109,98,3.141,114,3.41,129,3.519,216,4.997,286,4.746,385,4.588,399,2.358,420,1.833,422,2.726,520,3.212,700,5.475,734,3.41,890,3.41,1004,4.032,1307,4.514,1389,5.409,1680,4.884,1834,5.475,2215,5.475,2610,4.514,2622,4.514,2629,6.427,2685,5.989,2686,5.989,2687,5.989,2688,5.989,2689,8.221,2690,5.989,2691,5.989]],["t/872",[24,0.104,2692,9.682]],["t/874",[24,0.109,110,1.73,153,2.669,193,1.187,268,2.165,317,2.07,373,2.759,420,2.359,430,4.603,431,1.651,513,3.156,520,3.011,533,1.681,541,2.792,622,1.623,634,4.684,663,2.781,877,2.359,2693,5.457,2694,5.457,2695,4.681,2696,4.681,2697,5.457,2698,4.989,2699,5.457,2700,5.457,2701,5.457]],["t/876",[24,0.109,34,3.36,110,1.628,143,2.373,144,3.764,149,3.064,153,1.035,160,1.748,193,2.234,200,3.258,207,2.603,208,1.771,268,1.492,319,1.781,373,2.955,374,1.489,379,2.745,380,3.064,385,2.857,431,3.025,476,1.469,480,2.866,481,3.618,541,1.924,575,3.009,589,1.172,622,1.118,877,2.837,997,2.532,1145,2.286,1249,2.595,1298,2.835,1712,4.648,1846,4.766,2698,3.438,2702,3.761,2703,3.761,2704,3.761,2705,5.844,2706,3.761,2707,3.761,2708,3.761,2709,3.761,2710,3.067]],["t/879",[24,0.109,98,2.199,153,1.583,199,2.619,204,1.44,317,3.958,373,2.91,420,3.041,430,6.235,435,3.563,520,3.881,541,2.945,622,3.104,634,6.038,787,4.338,986,3.875,1086,3.749,1113,4.694,2282,4.694,2283,4.694,2285,4.694,2286,4.937,2711,5.755,2712,6.253,2713,5.262,2714,5.755,2715,5.755,2716,5.755]],["t/881",[24,0.107,110,1.686,153,2.848,158,2.836,268,3.396,513,3.506,541,4.379,638,4.488,2717,7.342]],["t/883",[24,0.109,100,4.108,110,1.586,158,1.59,190,5.309,221,2.486,374,0.739,385,2.347,398,1.6,399,1.89,420,2.801,422,2.185,430,2.868,505,2.549,512,1.95,589,1.496,592,1.821,622,2.09,634,5.561,745,1.92,785,3.619,823,3.232,824,4.624,997,3.232,1120,3.229,1335,3.915,1953,3.503,2282,3.915,2283,3.915,2285,7.46,2533,6.767,2695,7.846,2696,6.027,2713,6.424,2718,4.118,2719,4.801,2720,6.027,2721,4.801,2722,4.801,2723,6.424]],["t/885",[24,0.109,110,1.728,185,1.922,198,4.191,512,2.209,520,3.003,592,3.674,622,1.617,645,2.816,663,1.962,785,6.719,877,2.729,986,3.661,1037,4.455,1054,4.434,2268,6.592,2286,4.664,2287,4.971,2317,4.664,2533,4.949,2696,4.664,2712,4.251,2724,4.971,2725,3.968,2726,4.971,2727,5.437,2728,5.437,2729,5.437,2730,5.437,2731,5.437,2732,5.437,2733,5.437,2734,5.437,2735,5.437,2736,5.437,2737,5.437,2738,5.437,2739,5.437]],["t/887",[24,0.109,198,3.937,212,2.864,316,3.529,425,3.609,520,4.253,592,4.128,1037,3.609,2717,6.192,2724,6.6,2726,6.6,2740,7.219,2741,7.219]],["t/889",[24,0.109,80,2.483,100,4.052,110,1.779,158,1.976,160,1.455,176,2.246,193,1.783,204,1.492,226,3.167,374,1.262,431,1.805,513,2.443,592,2.262,663,2.152,877,2.868,890,3.396,1249,4.116,1479,7.602,1712,4.353,2718,5.116,2725,4.353,2742,5.965,2743,4.664,2744,5.965,2745,5.965]],["t/891",[24,0.108,100,4.911,110,1.76,214,2.829,374,1.529,385,3.912,480,3.2,712,4.364,1712,4.249,2718,6.864,2746,6.526]],["t/893",[24,0.109,100,3.152,110,1.854,160,1.555,193,1.387,199,2.902,316,3.117,374,1.492,420,2.626,431,1.93,539,4.807,573,3.224,622,1.897,718,3.687,737,4.807,745,3.877,823,6.527,877,2.626,1415,4.401,1620,4.401,2747,6.377,2748,6.377]],["t/895",[24,0.108,28,2.96,98,3.141,100,4.639,110,1.339,153,1.647,160,2.005,191,3.028,199,3.741,347,3.463,374,1.445,505,4.365,532,3.552,533,3.26,589,3.148,591,3.778,592,2.271,622,3.005,724,2.358,745,2.395,823,4.032,877,1.833,1041,2.376,1086,2.807,1206,6.197,1321,4.682,1953,4.371,2138,4.245,2139,4.032,2516,5.475,2749,5.989,2750,5.475]],["t/897",[24,0.109,100,4.433,110,1.85,374,1.381,585,3.531,877,2.088,1120,3.134]],["t/899",[24,0.109,34,1.673,80,1.486,96,2.21,97,3.062,98,1.364,100,4.994,110,1.792,143,2.253,190,1.947,193,1.508,198,3.06,344,1.657,374,0.864,398,1.871,420,2.615,430,3.352,480,2.244,503,3.062,513,2.839,520,2.192,585,1.849,622,1.062,634,4.214,639,2.773,645,2.906,722,1.849,724,1.405,874,2.805,877,1.718,905,2.791,941,2.791,1005,3.283,1017,3.264,1037,1.784,1133,2.911,1313,2.791,1490,2.002,2268,3.062,2533,2.299,2577,5.569,2695,3.062,2723,5.13,2751,3.57,2752,3.57,2753,3.57,2754,3.57,2755,3.57,2756,3.57,2757,5.13,2758,3.57,2759,3.57,2760,3.57]],["t/901",[24,0.109,69,0.845,82,2.001,96,1.519,100,5.159,110,1.7,143,1.549,149,1.287,153,1.137,193,1.367,199,1.117,204,0.614,208,1.637,232,1.048,354,1.519,374,1.17,398,2.339,399,2.109,420,2.148,422,1.117,428,0.898,431,1.251,477,1.85,480,0.981,513,1.005,532,0.823,533,0.756,534,1.086,565,1.255,575,1.03,585,3.254,589,0.765,590,1.797,628,1.615,631,2.662,645,2.141,663,1.492,673,0.952,709,1.791,745,2.805,846,1.303,877,2.601,965,2.167,986,1.652,1120,3.494,1132,3.017,1133,2.001,1438,1.2,1470,1.85,1471,1.85,1679,3.116,1684,2.319,1892,1.693,2217,1.919,2230,2.105,2247,1.919,2319,1.791,2324,2.001,2461,1.652,2746,2.001,2761,2.454,2762,2.454,2763,2.454,2764,2.454,2765,2.454,2766,2.454,2767,4.134,2768,2.454,2769,2.454,2770,2.454,2771,2.454,2772,4.134,2773,2.454,2774,3.546,2775,2.105,2776,2.243,2777,2.454,2778,2.243,2779,2.454,2780,2.243,2781,2.454,2782,2.454,2783,4.134,2784,2.454,2785,2.454]],["t/903",[24,0.107,221,4.458,520,3.364,592,4.395,845,5.544,1712,4.572,2712,6.731,2725,6.283,2746,7.021,2786,8.609]],["t/905",[24,0.109,59,4.15,96,3.816,110,1.365,193,1.341,199,2.805,221,4.342,327,3.458,374,1.29,398,3.176,431,1.865,436,2.338,591,2.833,592,4.056,623,4.926,725,3.89,745,2.465,823,4.15,877,1.887,890,3.509,1089,5.898,1317,4.369,2250,4.254,2319,4.498,2451,5.027,2746,5.027,2787,6.164,2788,5.027,2789,6.164,2790,5.287,2791,5.635,2792,5.635]],["t/907",[24,0.107,221,5.458,520,4.118,592,3.997,2712,6.892,2725,6.433]],["t/909",[24,0.109,68,4.646,199,2.313,221,4.865,316,3.58,327,2.851,333,3.344,374,1.321,394,3.973,398,1.694,401,1.927,420,1.556,425,2.54,430,3.036,486,2.484,520,1.986,591,3.365,592,3.934,622,2.178,657,3.831,677,3.146,725,4.622,774,4.144,785,3.831,835,3.036,845,3.273,877,1.556,890,4.169,1089,3.146,2132,4.144,2250,3.507,2319,3.708,2712,5.726,2725,6.265,2788,4.144,2790,4.359,2793,5.082,2794,5.082,2795,5.082,2796,5.082,2797,5.082,2798,5.082,2799,5.082,2800,5.082,2801,5.082,2802,5.082,2803,5.082,2804,4.359,2805,5.082]],["t/911",[24,0.109,100,1.777,198,4.674,212,1.427,221,4.438,286,1.818,317,2.992,354,2.226,398,1.881,430,3.371,485,3.263,520,2.205,533,1.107,534,1.591,585,1.862,592,4.362,595,1.449,623,2.113,628,2.366,673,1.394,740,3.077,785,4.254,874,1.797,877,1.101,992,2.933,1086,1.686,1089,2.226,1154,4.602,1462,2.933,1490,2.017,1734,2.079,1941,5.591,1953,2.624,2247,2.811,2308,2.549,2533,3.634,2577,4.936,2806,7.889,2807,3.596,2808,3.596,2809,3.596,2810,3.596,2811,3.596,2812,3.596,2813,3.596,2814,3.596,2815,3.084,2816,3.287,2817,2.711,2818,3.287,2819,3.596,2820,5.643,2821,3.596,2822,3.596]],["t/913",[24,0.109,110,1.199,317,2.793,398,3.656,399,3.712,425,3.681,592,3.576,877,2.254,1684,4.131,2461,4.958]],["t/915",[24,0.104,110,1.773,153,2.995,212,3.696,436,3.533]],["t/917",[24,0.109,98,2.518,100,2.609,110,1.859,199,1.505,212,1.312,217,2.836,236,3.535,300,4.438,316,1.616,374,1.158,398,1.102,401,1.254,476,1.292,480,1.322,485,1.911,520,2.063,585,1.712,592,2.002,622,1.57,638,2.768,673,1.282,724,2.079,770,3.154,831,1.49,877,1.012,1120,1.519,1301,3.742,1471,2.492,1490,1.854,1712,1.755,2461,2.226,2469,5.194,2533,2.129,2588,3.022,2589,3.022,2775,2.836,2817,4.969,2823,3.306,2824,3.306,2825,5.28,2826,5.28,2827,3.306,2828,3.306,2829,3.306,2830,3.306,2831,3.306,2832,4.306,2833,3.306,2834,4.529,2835,4.306,2836,3.306,2837,3.306,2838,3.306,2839,3.306,2840,3.306,2841,3.306,2842,3.306,2843,3.306,2844,3.306,2845,3.306]],["t/919",[24,0.109,100,2.002,110,1.799,124,3.702,153,1.702,246,5.204,304,3.702,398,1.35,420,1.894,435,2.507,532,2.076,533,1.905,592,3.434,634,2.462,645,3.888,825,3.166,837,2.576,877,1.894,997,2.727,1041,1.607,1050,3.474,1113,3.303,1208,2.955,1453,3.303,1490,2.272,2271,3.053,2533,3.985,2846,5.307,2847,4.05,2848,3.474,2849,4.05,2850,3.702,2851,7.508,2852,3.702]],["t/921",[24,0.109,59,4.7,96,4.321,110,1.75,354,4.321,374,1.074,1470,5.262,2853,8.327]],["t/923",[24,0.109,110,1.887,354,5.327,420,2.634,592,2.429,622,1.905,634,3.893,1089,6.431,1734,4.975,2250,4.42,2319,4.674,2854,8.604]],["t/925",[24,0.105,110,1.567]],["t/927",[24,0.109,110,1.365,153,2.942,268,2.446,374,1.574,480,3.81,532,2.068,533,3.149,595,3.84,622,1.833,638,3.232,745,2.465,823,4.15,1086,2.889,1308,3.117,1874,5.027,2855,6.164]],["t/929",[24,0.109,80,3.081,110,1.789,153,2.036,193,1.61,204,2.608,208,2.109,374,1.139,431,2.239,480,2.959,877,2.896]],["t/931",[24,0.109,110,1.365,204,2.097,207,1.833,208,1.696,374,0.949,424,3.316,480,2.465,639,3.047,663,3.025,673,3.251,795,4.369,877,3.13,989,5.287,1472,4.819,1657,5.287,2856,6.164,2857,6.164,2858,6.164,2859,5.635,2860,4.819,2861,4.819]],["t/933",[24,0.109,110,1.85,153,2.346,158,2.095,193,1.375,208,1.953,246,5.28,431,1.913,533,1.947,592,3.661,595,2.548,837,3.551,876,2.489,877,1.936,989,5.423,1712,3.357,2139,4.257,2147,6.216,2859,5.78,2860,4.943,2861,4.943,2862,6.323]],["t/935",[24,0.109,110,1.885,208,2.189,333,4.196,374,0.982,480,2.55,532,2.14,533,2.642,534,2.822,541,3.263,595,2.57,663,2.301,724,2.511,745,2.55,877,2.968,905,4.986,1217,3.631,1712,3.386,2147,5.525,2860,4.986,2861,4.986]],["t/937",[24,0.109,100,4.711,110,1.707,208,1.516,333,3.451,374,1.345,420,1.605,480,2.995,532,2.513,533,2.307,573,2.652,585,2.716,592,3.314,663,1.892,673,3.388,874,2.621,877,2.918,997,3.531,1490,2.942,1712,5.062,2817,3.953,2835,4.277,2860,4.1,2861,4.1,2863,5.244,2864,4.794,2865,5.244]],["t/939",[24,0.109,110,1.511,208,1.878,232,3.068,663,3.349,673,3.599,877,2.199,2860,5.617,2861,5.617,2866,6.162,2867,7.184]],["t/941",[24,0.105]],["t/943",[24,0.109,100,4.406,110,1.452,153,2.114,154,2.749,190,2.965,198,2.965,204,1.36,327,3.05,420,1.665,534,2.406,585,2.816,592,2.062,663,1.962,676,4.515,677,3.366,687,3.305,823,3.661,874,2.718,877,2.966,921,4.029,970,3.305,1120,2.499,1441,3.431,1471,5.793,1830,6.009,1874,4.434,2138,6.318,2139,3.661,2277,4.434,2310,4.664,2469,3.752,2778,4.971,2780,4.971,2832,6.268,2852,4.971,2868,5.437,2869,5.437,2870,5.437,2871,4.971,2872,5.437,2873,5.437,2874,5.437,2875,7.685,2876,5.437,2877,5.437,2878,5.437]],["t/945",[24,0.109,110,1.187,153,2.006,374,1.122,532,2.446,533,2.245,534,3.226,592,2.765,663,2.631,676,5.504,837,3.036,877,2.868,2577,6.64,2879,9.369,2880,7.291]],["t/947",[24,0.109,100,3.74,110,1.862,199,4.366,208,1.076,221,2.755,333,3.5,374,0.819,513,2.179,532,2.539,533,2.33,573,2.69,592,2.87,622,2.619,623,3.125,663,1.92,718,3.076,823,5.095,877,2.317,1490,4.245,1712,4.018,2461,3.582,2533,3.426,2577,3.77,2725,3.882,2775,4.563,2788,4.338,2817,5.704,2818,4.864,2834,4.563]],["t/949",[24,0.109,59,4.406,70,3.182,96,4.051,100,4.623,110,1.659,153,1.2,154,2.205,155,1.233,199,2.978,208,0.882,221,3.389,249,3.556,316,2.132,317,2.482,333,2.869,374,1.343,398,2.619,401,1.654,420,1.335,513,2.68,592,2.979,622,1.946,725,2.752,835,3.909,877,1.335,1050,3.741,1089,4.051,1208,3.182,1462,3.556,1470,3.287,1712,2.316,1938,3.741,2250,5.42,2319,3.182,2325,2.869,2533,2.808,2725,3.182,2804,3.741,2881,4.361,2882,4.361]],["t/951",[24,0.11,190,2.551,373,2.366,399,1.842,663,2.488,687,2.844,860,3.371,865,3.415,877,2.507,1226,4.278,1830,3.658,2533,3.013,2883,4.679,2884,4.278,2885,4.013,2886,4.679,2887,4.679,2888,4.679,2889,4.679,2890,4.679,2891,4.679,2892,4.679,2893,4.679,2894,4.679,2895,4.679]],["t/953",[24,0.109,59,3.786,98,2.148,110,0.916,316,2.749,374,1.211,420,1.722,591,4.172,592,3.729,622,1.673,663,2.84,673,2.181,837,3.78,877,1.722,890,3.202,968,6.212,1005,3.727,1108,5.743,1520,3.881,1954,5.578,2147,3.622,2274,4.586,2325,3.701,2615,5.141,2792,5.141,2815,4.824,2896,5.624,2897,5.624]],["t/955",[24,0.109,98,2.055,100,2.658,110,1.809,153,1.479,190,2.933,208,1.793,246,3.329,268,2.134,316,2.629,333,5.018,374,0.828,398,1.793,420,1.646,532,2.559,533,2.348,592,2.039,622,2.268,660,3.711,663,3.197,687,3.269,745,3.543,837,2.239,846,4.049,877,3.116,1232,3.925,2533,3.463,2774,4.613,2790,4.613,2835,4.386,2866,4.613]],["t/957",[24,0.109,35,6.445,110,1.555,153,2.067,374,1.156,663,3.446,745,3.004,1108,5.483,2898,7.513]],["t/959",[24,0.109,80,1.816,98,1.666,100,2.155,110,0.71,155,1.233,190,2.378,246,2.7,373,2.205,374,1.007,377,4.749,420,2.863,487,1.678,622,1.297,663,1.574,722,2.258,877,2.003,910,2.869,1041,2.596,1108,3.182,1271,2.411,1317,3.091,1481,3.556,2050,3.556,2533,2.808,2757,3.987,2817,3.287,2864,5.983,2899,7.854,2900,4.361,2901,3.987,2902,8.729,2903,4.361,2904,4.361,2905,4.361,2906,4.361,2907,4.361,2908,4.361,2909,4.361,2910,4.361,2911,4.361,2912,4.361,2913,4.361,2914,4.361]],["t/961",[24,0.108,69,2.473,110,1.769,153,2.553,208,1.454,246,4.448,333,4.727,373,3.633,399,2.829,436,2.725,532,3.114,533,2.212,584,3.095,592,2.725,663,2.592,720,3.209,877,2.841,1120,3.301,2776,6.568,2846,6.162]],["t/963",[20,1.154,24,0.11,34,0.822,69,0.604,70,1.28,96,1.086,98,2.601,100,0.867,110,1.631,153,2.566,154,0.887,160,0.428,167,2.883,198,0.956,204,0.439,207,0.522,208,0.84,236,0.707,246,3.536,268,1.228,300,1.181,308,1.21,326,1.622,327,0.984,373,1.564,374,1.31,398,0.585,399,0.691,401,0.665,420,2.085,480,0.701,486,0.857,513,2.789,532,1.038,533,0.953,541,2.561,554,1.504,580,1.13,585,0.908,591,1.422,592,1.173,622,2.154,663,1.806,678,0.92,680,1.43,722,0.908,724,1.218,732,0.999,733,1.992,748,1.504,769,3.412,837,1.288,846,0.931,877,1.93,957,1.504,968,2.768,1021,4.294,1084,1.181,1108,1.28,1109,2.828,1232,2.258,1313,1.371,1314,1.086,1317,1.243,1389,1.154,1712,0.931,1720,1.604,2237,1.504,2271,2.332,2325,1.154,2469,1.21,2577,1.243,2774,1.504,2832,1.43,2848,1.504,2850,1.604,2866,1.504,2915,1.754,2916,1.754,2917,1.754,2918,1.754,2919,5.712,2920,1.754,2921,1.754,2922,1.754,2923,1.604,2924,1.754,2925,1.754,2926,1.754,2927,1.604,2928,3.094,2929,1.754,2930,1.754,2931,1.754,2932,1.754,2933,1.754,2934,1.754,2935,1.504,2936,1.754,2937,1.754,2938,1.754,2939,1.754,2940,1.754,2941,1.754,2942,1.754,2943,1.754,2944,1.754,2945,1.754,2946,1.754,2947,1.604,2948,1.754,2949,1.754,2950,1.754,2951,1.754,2952,1.604]],["t/965",[24,0.107,110,1.48,153,2.499,374,1.399,513,3.721]],["t/967",[24,0.108,110,1.663,153,2.809,513,4.182,663,3.019,877,3.126]],["t/969",[24,0.109,59,3.044,96,2.799,98,2.568,100,4.694,110,1.621,153,1.244,199,3.06,207,1.345,214,1.598,373,2.286,374,1.368,420,1.384,510,5.256,512,1.837,513,2.753,589,1.409,592,3.775,622,2.643,704,3.878,729,3.687,1129,3.535,1447,4.765,1462,3.687,1490,2.536,1712,3.57,2250,3.12,2283,3.687,2461,3.044,2871,4.133,2953,4.521,2954,4.521,2955,6.723,2956,4.521,2957,4.521,2958,4.521]],["t/971",[20,3.957,24,0.109,98,3.594,110,0.979,153,1.654,199,3.752,212,2.386,221,3.114,316,2.939,374,1.448,398,2.005,425,4.12,436,2.28,592,4.153,622,2.452,677,3.723,877,1.841,2155,5.498,2832,4.904]],["t/973",[24,0.109,110,1.269,663,2.811,673,3.021,877,2.385,1472,6.091]],["t/975",[24,0.109,63,2.706,96,2.427,100,1.938,110,1.876,143,2.474,153,2.024,154,1.982,158,1.299,212,1.556,246,3.736,316,2.95,354,2.427,374,1.451,398,1.307,420,1.848,589,1.222,597,3.247,638,2.056,722,2.03,724,2.376,830,1.735,889,3.584,1089,3.736,1734,3.49,2469,5.703,2804,3.363,2817,2.955,2834,3.363,2835,3.197,2846,5.177,2848,3.363,2853,5.518,2959,3.921,2960,3.921,2961,3.921]],["t/977",[24,0.109,110,1.552,153,1.696,208,1.247,216,3.747,317,2.338,374,1.29,480,3.353,513,2.525,575,2.588,663,2.224,684,4.819,685,5.027,1684,3.458,2952,5.635,2962,6.164,2963,6.164,2964,6.164,2965,6.164,2966,6.164]],["t/979",[24,0.109,110,1.805,153,1.885,208,1.386,532,3.019,533,2.771,1874,5.587,2317,5.876]],["t/981",[24,0.109,110,1.555,153,2.067,424,4.042,513,3.077,663,3.789,673,2.914,740,4.097,877,2.3]],["t/983",[24,0.109,110,1.402,212,1.441,317,2.157,374,0.559,380,3.675,398,1.211,420,3.182,435,3.52,496,2.737,592,3.747,663,2.862,837,2.918,874,1.815,877,2.428,968,2.008,1005,1.72,1086,1.702,1297,2.737,1410,3.32,2147,3.662,2274,2.961,2282,7.448,2284,3.115,2325,3.742,2577,2.574,2651,5.199,2815,3.115,2947,6.408,2967,3.631,2968,3.631,2969,3.631,2970,5.687,2971,5.687,2972,5.687,2973,5.687,2974,5.687,2975,5.687,2976,3.631,2977,3.631,2978,3.631,2979,3.631,2980,3.631,2981,3.631,2982,3.631,2983,3.631]],["t/985",[21,6.725,24,0.105,160,2.176,193,1.941,589,2.78,596,5.87,1041,3.54,1271,4.933,1272,5.87,1724,7.276,2984,8.921,2985,8.921]],["t/987",[24,0.109,110,1.389,158,2.826,207,2.537,208,1.726,327,3.547,520,2.47,541,3.235,589,1.97,596,4.16,876,3.358,892,5.423,894,3.6,1272,4.16,1273,3.914,2622,4.766,2986,4.943,2987,5.78]],["t/989",[24,0.109,158,3.33,160,1.672,196,2.646,204,0.878,207,2.52,208,1.714,233,2.488,286,1.775,344,1.629,380,1.84,425,1.755,520,2.164,541,1.796,589,1.726,596,2.31,628,3.644,631,3.566,663,1.267,685,2.863,876,3.957,877,1.075,892,3.011,894,1.999,963,3.366,1041,1.393,1169,3.011,1272,2.31,1273,5.834,1520,2.422,1830,2.745,2461,2.363,2986,5.361,2988,3.51,2989,6.086,2990,2.863,2991,4.516,2992,4.329,2993,3.209,2994,3.51,2995,3.51,2996,3.51,2997,3.51,2998,3.51]],["t/993",[24,0.109,153,1.911,158,2.302,160,2.467,207,2.7,208,1.837,233,7.169,520,2.715,541,5.175,663,2.507,876,2.735,2629,7.909,2991,5.666,2992,7.099]],["t/995",[24,0.109,110,1.676,158,1.835,207,2.316,208,1.576,374,0.853,420,1.696,487,3.466,513,2.269,532,1.858,533,1.706,622,1.647,1041,3.09,1273,3.429,1499,4.518,2462,5.064,2622,4.176,2987,5.064,2989,4.331,2990,6.35,2991,6.35,2992,4.331,2999,5.539,3000,5.539,3001,5.539,3002,5.539,3003,5.539,3004,5.539,3005,5.539]],["t/997",[24,0.107,59,5.538,98,3.142,110,1.646,374,1.556,487,3.89,505,4.368,589,2.563,591,3.78,592,3.119,1145,5,1273,5.092,1732,7.52,2622,6.2,3006,8.225]],["t/999",[24,0.106,2461,6.272,3007,9.316,3008,9.316]],["t/1001",[24,0.109,110,0.783,153,1.935,158,2.755,160,1.715,165,1.584,168,1.007,179,2.976,190,3.322,193,0.64,200,1.186,207,2.092,208,1.423,214,1.041,233,4.985,253,2.148,254,1.729,256,1.506,261,1.758,264,5.302,286,1.488,288,1.857,319,3.331,332,2.148,373,1.488,374,0.453,380,1.543,385,2.978,423,2.301,430,1.758,439,2.086,480,1.177,520,1.15,541,3.117,589,0.917,634,1.789,639,2.376,663,2.538,697,3.407,876,3.275,894,2.737,907,1.563,986,1.982,1037,2.403,1169,2.525,1177,1.758,1198,1.895,1265,2.031,1273,2.976,1278,2.525,1637,2.525,2027,4.395,2029,2.031,2146,3.317,2609,2.525,2623,3.92,2629,2.301,2640,4.764,2990,7.157,2991,7.724,2992,6.861,3009,2.943,3010,2.943,3011,2.943,3012,2.943,3013,6.093,3014,2.943,3015,2.943,3016,2.943,3017,2.943,3018,2.943,3019,2.943,3020,2.943,3021,2.943,3022,4.807,3023,2.943,3024,5.57,3025,2.943,3026,2.943,3027,4.807,3028,2.943,3029,2.943,3030,2.943,3031,4.807,3032,2.943,3033,2.943,3034,2.943,3035,2.943,3036,2.943,3037,2.943,3038,2.943,3039,2.943,3040,2.943,3041,2.943,3042,2.943]],["t/1003",[24,0.11,380,2.915,580,3.581,748,4.769,837,2.315,963,5.948,1112,4.769,2622,4.191,2986,4.347,2993,5.083,3043,9.023,3044,7.807,3045,7.807,3046,5.56,3047,5.56,3048,5.56]],["t/1006",[24,0.108,158,2.819,373,4.303,876,3.351,1273,6.388]],["t/1008",[24,0.108,158,3.371,207,2.474,208,1.683,373,4.206,380,4.361,876,4.007,1273,6.3,2986,6.503,2989,6.503]],["t/1010",[24,0.109,207,2.293,208,1.56,1273,6.01,2989,6.028]],["t/1013",[24,0.109,123,5.069,128,4.686,158,2.059,207,1.849,388,4.09,663,2.243,876,2.447,894,4.801,963,6.52,1272,5.548,1273,3.848,1938,5.332,2989,4.86,2990,5.069,2992,4.86,3024,5.683,3049,8.432,3050,6.216,3051,8.432,3052,8.432,3053,6.216,3054,6.216]],["t/1016",[24,0.109,110,1.076,158,2.188,173,4.558,256,3.38,380,3.463,596,4.346,876,2.601,963,4.015,1272,4.346,1273,6.511,2235,6.039,2616,4.979,2986,6.867,3055,6.606,3056,6.606]],["t/1018",[24,0.107,110,1.489,1273,5.66,1724,7.456]],["t/1020",[24,0.107,83,4.511,487,4.028,1273,6.479,3057,8.711,3058,8.711,3059,10.465,3060,8.711]],["t/1022",[24,0.11,110,1.052,596,4.251,1272,4.251,1724,5.269,2640,5.051]],["t/1024",[32,5.937,80,3.606,81,7.917,89,6.138,100,4.28,121,7.428,153,2.382,565,4.43,1042,7.917,3061,8.66,3062,7.917,3063,7.917,3064,9.533,3065,8.66,3066,7.917,3067,8.66,3068,7.917,3069,8.66,3070,8.66,3071,8.66,3072,7.917,3073,7.917]],["t/1026",[32,5.895,50,7.891,84,6.066,198,4.667,743,7.342,845,5.512,1018,6.692,1390,6.692,1954,6.066,2543,7.825,3074,8.559,3075,6.98,3076,7.342,3077,8.559,3078,7.342,3079,7.342,3080,7.825,3081,8.559,3082,8.559,3083,8.559,3084,8.559,3085,8.559,3086,8.559]],["t/1028",[21,8.178,22,7.238,32,5.271,40,5.842,70,6.756,136,7.69,1084,6.233,1281,7.55,2362,8.463,2515,8.463,3087,9.257]],["t/1030",[21,5.496,22,8.094,32,5.334,40,4.601,51,4.601,55,6.665,67,6.254,70,5.321,83,3.775,137,6.254,214,2.578,835,5.597,955,6.254,1709,5.167,2147,4.695,3062,6.665,3063,6.665,3088,9.369,3089,9.369,3090,9.369,3091,9.369,3092,6.665,3093,10.352,3094,9.464,3095,7.291,3096,7.291,3097,7.291,3098,8.036,3099,7.291,3100,9.369,3101,7.291,3102,7.291,3103,7.291,3104,7.291,3105,7.291,3106,7.291,3107,7.291,3108,7.291,3109,7.291,3110,5.321,3111,5.7,3112,7.291]],["t/1032",[89,6.73,127,7.744,131,8.681,136,6.73,440,6.73,516,6.93,1954,6.73,3113,8.681,3114,9.495]],["t/1034",[24,0.077,32,5.205,33,6.016,40,5.77,51,5.77,83,4.734,1709,6.48,1954,7.633,3110,6.672,3111,7.148,3115,9.238,3116,8.358,3117,8.358]],["t/1036",[24,0.102,32,5.491,40,6.086,50,5.408,52,5.568,101,6.223,109,5.408,158,2.528,317,3.657,435,4.724,1018,5.966,1334,5.966,1709,5.408,1954,6.835,3072,8.817,3079,6.545,3113,9.668,3115,6.545,3116,8.817,3118,5.751,3119,6.976,3120,7.63,3121,7.63,3122,7.63,3123,7.63,3124,9.644,3125,6.223,3126,7.63,3127,7.63,3128,5.265,3129,7.63]],["t/1038",[24,0.097,33,5.942,39,7.061,40,5.699,50,6.401,51,5.699,136,6.401,3130,9.031,3131,9.031,3132,9.031,3133,9.031,3134,9.031,3135,9.031,3136,9.031,3137,9.031]],["t/1040",[24,0.096,39,9.389,40,5.05,51,5.05,83,4.144,136,7.042,385,3.912,1645,5.84,3080,9.88,3110,5.84,3111,6.257,3138,9.084,3139,9.936,3140,6.69,3141,8.002,3142,7.316,3143,8.002,3144,7.316,3145,8.002,3146,8.002,3147,8.002,3148,8.002,3149,7.316]],["t/1042",[24,0.075,33,7.87,40,5.596,51,5.596,83,4.592,136,8.296,3110,6.472,3111,6.933,3138,9.67,3149,8.107,3150,9.67]],["t/1044",[32,5.238,51,5.806,84,7.661,98,3.515,128,6.935,337,6.935,1160,8.41,1673,7.889,3151,7.891,3152,9.2,3153,9.2,3154,9.2]],["t/1046",[51,5.916,52,6.841,84,6.644,98,3.581,103,6.841,105,6.841,128,8.721,1673,6.841,2017,7.33]],["t/1047",[19,7.384,52,7.583,103,6.283,105,6.283,128,8.413,129,5.058,130,7.833,133,7.871,347,4.978,743,7.384,826,5.433,1287,5.143,2017,6.731,2147,5.544,3110,7.583,3155,9.5,3156,8.609,3157,8.609,3158,6.102]],["t/1049",[31,7.066,32,5.513,33,6.371,34,4.539,532,3.248,1314,5.994]],["t/1051",[24,0.073,33,7.325,432,5.402,587,6.813,622,2.546,740,4.667,1954,7.891,2750,7.825,3079,7.342,3092,7.825,3094,9.466,3098,7.342,3118,6.452,3119,7.825,3151,7.342,3159,8.559,3160,8.559,3161,8.881,3162,8.559]],["t/1053",[23,5.665,31,6.283,33,5.665,40,7.043,51,5.433,54,5.058,77,8.413,136,7.365,941,8.124,1296,6.49,3098,7.384,3150,7.871,3163,8.609,3164,7.871,3165,11.161,3166,8.609,3167,8.609]],["t/1055",[23,7.253,31,6.105,32,5.814,33,6.719,51,6.444,53,7.175,54,4.915,69,3.952,71,7.648,366,7.237,823,5.632,941,6.54,973,6.105,1673,6.105,3164,7.648,3168,8.365,3169,8.365,3170,8.365,3171,8.365,3172,8.365,3173,8.365]],["t/1057",[24,0.103,31,6.246,33,5.632,114,4.873,385,5.061,388,5.632,2935,7.342,3144,9.466,3174,7.825,3175,8.559,3176,8.559,3177,10.355,3178,10.355,3179,10.355,3180,8.559]],["t/1059",[23,6.766,24,0.087,32,4.817,34,4.82,37,8.084,40,5.34,506,5.997,1004,6.923,3066,9.401,3174,7.735,3181,8.461,3182,8.461,3183,10.282,3184,9.401,3185,11.077,3186,10.282]],["t/1061",[23,4.727,24,0.104,32,4.09,33,4.727,36,6.568,39,5.617,41,6.568,43,6.568,47,6.568,317,2.725,734,4.09,1089,5.745,1954,5.092,2542,6.568,2616,5.416,2927,6.568,2935,8.817,3064,6.568,3142,6.568,3187,7.184,3188,7.184,3189,7.184,3190,10.28,3191,11.249,3192,7.184,3193,7.184,3194,7.184,3195,7.184,3196,7.184,3197,7.184,3198,7.184,3199,7.184,3200,7.184,3201,7.184,3202,7.184,3203,7.184,3204,7.184,3205,7.184,3206,7.184]],["t/1063",[32,5.549,89,6.908,316,4.764,3118,7.347,3207,9.746]],["t/1065",[32,4.763,40,5.279,52,6.105,89,7.812,102,4.626,103,6.105,105,6.105,185,2.958,688,10.76,973,6.105,2281,5.929,3110,6.105,3118,8.652,3208,8.365,3209,8.365,3210,7.648,3211,8.365,3212,8.365,3213,8.365,3214,8.365,3215,8.365]],["t/1067",[24,0.105,50,5.862,51,5.22,89,7.773,109,5.862,127,6.746,1018,6.467,1390,6.467,3075,8.27,3076,8.698,3078,7.095,3118,6.235,3125,6.746,3216,7.562,3217,9.271,3218,8.271,3219,7.562]],["t/1069",[52,6.756,89,6.561,137,7.94,1283,5.303,1334,7.238,3115,7.94,3117,8.463,3118,6.978,3210,8.463,3220,9.257,3221,9.257,3222,9.257]],["t/1071",[77,7.396,135,8.415,1953,7.16,2710,8.001]],["t/1073",[24,0.102,31,6.511,50,6.323,129,6.237,1390,6.975,3068,8.156,3075,8.657,3125,7.276,3223,9.105,3224,8.921,3225,10.615]],["t/1075",[48,10.255,51,5.497,52,6.357,135,8.976,232,3.72,1729,8.77,1953,6.357,2281,6.174,2710,7.104,3226,8.711,3227,8.711,3228,11.218,3229,8.711,3230,8.711,3231,10.465]],["t/1077",[23,5.698,82,9.125,84,7.391,103,6.32,105,6.32,118,7.917,129,6.823,136,6.138,231,4.019,908,5.361,1481,7.062,1953,6.32,2710,7.062,3223,7.428,3232,8.66,3233,8.66,3234,8.66,3235,8.66]],["t/1079",[24,0.105,50,5.862,51,5.22,109,5.862,127,6.746,129,5.958,589,2.578,1018,6.467,1390,6.467,3075,8.27,3076,8.698,3078,7.095,3110,6.036,3125,6.746,3216,7.562,3217,9.271,3219,7.562,3236,8.271]],["t/1081",[84,7.578,103,7.803,105,7.803,128,8.876,129,6.692,521,8.256,575,3.792,3223,7.746,3237,9.031]],["t/1083",[24,0.104,3238,9.682]],["t/1085",[24,0.109,69,1.647,98,1.828,110,0.779,160,1.167,200,2.825,201,2.392,202,3.722,226,2.541,317,1.815,326,2.509,366,3.391,374,1.657,375,2.314,420,1.465,476,1.87,582,5.466,589,2.184,623,2.811,638,2.509,686,2.767,728,6.054,732,5.2,769,2.859,776,3.391,790,3.02,835,2.859,1249,3.302,1685,3.741,1702,4.104,2471,4.104,3128,3.302,3239,3.222,3240,4.785,3241,4.785,3242,3.607,3243,3.902]],["t/1087",[24,0.109,98,1.35,110,1.507,158,0.677,160,0.498,170,0.737,200,3.639,201,1.767,202,3.923,204,0.511,212,0.811,247,2.58,316,0.999,317,0.775,326,2.919,348,1.344,354,2.892,366,4.882,374,1.57,399,0.804,420,0.625,428,1.293,436,0.775,476,0.798,534,0.904,573,1.787,580,2.276,582,5.605,589,1.101,590,0.888,622,0.608,623,1.2,624,1.55,638,1.853,686,2.044,695,3.232,697,2.505,720,0.912,722,2.883,724,0.804,728,5.703,732,2.012,769,2.112,790,1.289,805,2.764,835,2.112,956,1.983,1154,2.883,1665,1.344,1685,3.653,1702,1.752,1710,4.775,2471,1.752,3128,4.341,3158,1.448,3239,3.145,3242,4.197,3243,3.81,3244,4.353,3245,2.58,3246,2.883,3247,4.197,3248,3.032,3249,1.868,3250,4.672]],["t/1090",[24,0.109,34,2.558,69,1.879,98,2.085,110,1.778,129,3.206,158,1.808,200,3.106,201,2.728,202,2.898,342,3.515,374,1.375,425,3.851,582,5.221,638,2.861,697,3.868,728,5.623,790,4.863,805,4.267,835,3.26,1665,3.591,3128,3.766,3158,3.868,3239,3.674,3242,4.114,3244,6.025,3245,3.983,3246,4.451,3247,5.808,3248,4.681,3251,5.457,3252,5.457]],["t/1092",[24,0.109,34,1.324,98,1.079,110,1.404,176,1.064,207,1.761,212,1.121,214,0.999,231,4.18,261,1.688,366,3.294,374,0.911,399,2.331,406,2.304,425,1.412,428,2.167,476,2.963,589,0.88,590,2.574,593,2.002,635,1.749,638,2.437,655,1.633,657,2.129,720,1.262,732,1.608,755,3.987,835,1.688,1034,4.249,1084,3.129,1129,5.93,1620,1.949,1983,2.423,2029,1.949,2539,6.273,3128,3.207,3151,2.423,3158,4.863,3242,2.129,3249,6.273,3253,2.825,3254,4.648,3255,2.825,3256,2.825,3257,2.825,3258,2.825,3259,4.648,3260,2.825,3261,2.825,3262,2.825,3263,2.825,3264,2.825,3265,2.825,3266,2.825,3267,2.825,3268,2.825,3269,2.423,3270,2.825,3271,4.648,3272,4.648,3273,2.825,3274,2.825,3275,2.825,3276,2.825,3277,2.825,3278,2.825,3279,2.825,3280,2.825,3281,2.825,3282,2.825,3283,2.825,3284,2.825,3285,2.825,3286,2.825,3287,2.825,3288,2.825,3289,2.825,3290,2.423,3291,4.648,3292,2.825,3293,2.583,3294,2.825,3295,2.825,3296,2.825,3297,2.825,3298,2.423,3299,2.825,3300,2.825,3301,2.825,3302,2.825]],["t/1094",[24,0.109,34,4.526,69,1.858,110,1.573,167,2.285,168,2.615,220,3.826,226,4.06,348,5.031,375,2.61,399,2.125,424,2.904,428,1.975,534,2.389,589,1.682,590,3.859,738,2.943,790,3.406,837,2.247,956,4.98,1236,4.22,1415,3.725,1665,5.842,3269,4.63,3290,4.63,3298,4.63,3303,5.398,3304,5.398,3305,7.646,3306,5.398,3307,5.398,3308,5.398,3309,5.398,3310,7.646,3311,7.646,3312,5.398,3313,5.398,3314,7.646,3315,5.398,3316,5.398,3317,4.935,3318,5.398,3319,5.398,3320,5.398,3321,5.398]],["t/1096",[24,0.109,34,3.736,110,1.471,167,1.705,170,1.453,200,2.11,214,1.424,219,1.907,220,1.686,227,3.284,231,1.869,236,1.623,247,2.938,261,1.421,300,1.602,317,0.902,319,1.126,348,1.565,366,2.854,374,1.061,377,1.15,399,2.946,401,0.902,408,1.86,411,1.602,420,1.886,428,2.254,432,4.348,436,1.527,481,3.241,534,1.782,541,1.217,573,1.203,580,1.532,582,5,590,1.75,623,1.398,624,3.022,638,1.247,698,3.454,709,2.938,728,1.736,730,1.793,769,4.761,790,1.501,835,1.421,1077,2.04,1146,1.94,1154,1.94,1364,3.445,1438,1.968,1550,2.04,1610,3.284,1620,1.642,1665,1.565,1672,1.86,1673,1.736,1688,1.793,1690,2.175,1710,5.284,1801,1.86,3128,2.779,3158,3.711,3239,1.602,3242,1.793,3244,3.148,3245,1.736,3269,2.04,3290,2.04,3293,2.175,3298,2.04,3317,2.175,3322,6.16,3323,2.379,3324,2.175,3325,2.379,3326,2.379,3327,2.379,3328,4.027,3329,2.379,3330,2.379,3331,2.379,3332,2.379,3333,2.379,3334,2.379,3335,2.379,3336,2.379,3337,2.379,3338,2.379,3339,2.379,3340,2.379,3341,2.379,3342,2.379,3343,2.379]],["t/1099",[24,0.109,69,2.857,98,1.51,193,1.321,200,2.981,201,3.035,202,2.099,214,1.397,236,1.593,319,4.241,366,2.801,374,0.935,385,2.968,399,1.556,428,1.446,432,2.494,480,1.58,487,1.521,573,4.196,582,2.126,590,1.718,638,3.184,655,3.511,663,2.669,673,2.355,697,2.801,728,2.884,730,2.979,732,5.099,805,3.09,1224,3.613,1667,4.304,1685,4.748,1755,3.39,3239,5.588,3243,3.223,3246,3.223,3247,5.575,3344,5.552,3345,3.952,3346,3.952,3347,3.952,3348,7.395,3349,7.395,3350,3.952,3351,7.395,3352,3.952,3353,5.209,3354,3.613,3355,3.952,3356,3.952,3357,6.073,3358,3.952,3359,3.952,3360,6.073,3361,3.613,3362,3.613,3363,3.09,3364,3.952,3365,3.952,3366,3.952,3367,3.613,3368,3.39,3369,3.952,3370,3.952,3371,3.952,3372,3.952]],["t/1101",[24,0.109,110,1.121,374,1.059,399,2.71,582,4.855,638,3.609,3128,6.228,3158,7.137,3239,4.634,3242,5.188]],["t/1104",[24,0.108,159,3.889,168,3.04,169,3.441,170,2.427,185,2.378,187,4.245,200,2.711,214,2.378,226,4.72,236,2.711,240,5.769,286,3.401,288,4.245,327,3.773,344,3.121,424,3.619,428,3.876,514,6.149,590,2.923,622,2,624,3.898,663,2.427,677,4.164,698,5.769,769,4.018,809,5.07,1177,4.018,1364,4.426,1490,3.773,3344,6.149,3373,6.726,3374,6.726]],["t/1107",[24,0.103,69,3.616,150,4.107,200,3.532,201,4.38,202,4.653,582,4.714,653,8.011,655,5.066,679,6.851,826,5.53,1053,6.395,1252,8.011,3239,5.9,3375,8.763,3376,8.763]],["t/1109",[24,0.106,702,8.059,805,8.24,2720,7.561,3246,8.595,3353,9.04,3354,8.059,3377,8.815,3378,8.815]],["t/1111",[24,0.107,150,3.671,165,4.214,219,3.709,232,3.345,344,3.635,813,8.409,938,5.904,1223,7.161,2552,7.161,2660,7.161,3248,6.718,3361,8.963,3362,7.161,3379,7.832,3380,7.832,3381,7.832,3382,7.832,3383,7.832,3384,7.832,3385,7.832]],["t/1113",[24,0.106,195,5.293,300,6.514,593,5.436,656,8.846,970,4.662,1037,4.836,1194,4.84,2447,7.012,2720,6.579,3128,5.293,3247,7.99,3363,7.565,3386,9.676,3387,9.676,3388,8.846,3389,7.012,3390,8.846,3391,7.012,3392,7.012,3393,7.67]],["t/1115",[24,0.108,150,3.633,195,5.348,200,3.124,316,3.788,425,3.874,582,4.17,678,4.063,774,7.943,1037,3.874,1741,7.085,2580,6.059,3161,6.648,3239,5.218,3243,6.321,3244,6.059,3394,7.75,3395,7.75,3396,7.75,3397,7.75,3398,7.085]],["t/1117",[24,0.104,234,8.256,425,4.514,436,3.425,3161,7.746,3244,8.36,3398,8.256,3399,9.031,3400,9.031,3401,9.031]],["t/1119",[24,0.108,150,3.856,200,3.315,679,6.431,832,7.52,1830,6.431,2461,5.538,3128,5.676,3239,5.538,3245,6.003,3363,6.431,3367,7.52,3402,8.225]],["t/1121",[24,0.107,195,5.614,200,3.279,300,5.477,593,5.766,697,5.766,970,4.945,1037,4.066,3247,8.206,3363,6.36,3368,8.61,3388,7.437,3389,7.437,3390,7.437,3391,7.437,3392,7.437,3403,8.135]],["t/1123",[24,0.106,61,7.062,187,5.465,655,5.007,677,5.361,3245,6.32,3247,7.86,3353,7.428,3363,8.748,3368,7.428]],["t/1125",[24,0.109,34,4.381,110,1.522,200,3.295,201,2.969,207,1.767,348,6.15,399,3.219,573,4.133,590,2.582,638,3.115,1665,7.179,3245,4.335]],["t/1127",[24,0.109,98,2.546,110,1.439,176,2.509,200,2.686,227,5.436,247,6.448,309,6.094,374,1.36,399,2.624,679,5.211,769,6.878,1672,6.908,1673,6.448,1801,5.211,3245,4.864,3324,6.094]],["t/1129",[24,0.108,80,4.179,326,4.265,374,1.797,575,3.415,2791,7.437]],["t/1131",[24,0.108,110,1.37,326,4.411,374,1.295,582,4.526,686,4.864,728,6.14,3158,5.963,3239,6.899]],["t/1133",[24,0.104,3404,9.682]],["t/1135",[24,0.109,98,1.787,155,1.323,160,1.997,193,2.096,204,2.26,207,2.687,208,1.828,236,3.642,256,3.528,286,2.366,305,2.705,344,2.171,354,2.897,373,2.366,374,1.061,431,2.915,480,2.757,505,3.662,589,2.552,591,2.15,592,1.774,731,2.517,831,2.109,907,2.485,1037,2.339,1086,2.193,1283,4.417,1436,4.051,1734,2.705,1738,3.079,1885,4.441,1886,4.887,1931,3.527,1949,4.278,3140,3.15,3405,5.513,3406,5.594,3407,5.144,3408,3.527,3409,4.679,3410,4.278]],["t/1137",[24,0.109,25,1.238,54,0.848,79,2.121,110,0.235,143,1.641,144,0.93,149,0.757,150,0.677,153,0.397,155,1.579,158,0.478,160,1.684,167,0.611,168,1.714,193,1.215,196,1.088,204,2.131,207,2.589,208,1.86,214,0.919,231,1.647,232,0.616,236,2.783,237,1.023,256,1.816,279,2.121,305,2.052,316,0.706,319,0.684,344,1.647,347,2.052,359,1.33,369,2.377,373,1.315,374,1.063,377,0.698,382,1.053,387,2.894,398,0.481,420,0.442,422,1.184,424,0.777,431,1.074,433,0.972,480,0.577,487,1.001,494,1.61,513,1.777,528,0.93,575,1.092,581,1.088,639,0.713,731,2.335,732,0.822,740,0.787,742,1.177,745,1.04,777,1.088,830,1.57,831,1.172,849,0.822,851,2.791,876,0.568,877,0.442,894,0.822,908,0.894,911,0.911,944,1.195,956,3.657,968,0.798,993,2.121,1005,0.684,1008,1.32,1038,1.751,1040,1.177,1086,0.677,1100,1.023,1104,0.996,1124,1.088,1129,1.129,1205,1.053,1267,3.304,1281,1.177,1282,0.972,1283,1.735,1286,1.238,1296,1.088,1308,2.824,1314,2.197,1391,1.238,1392,1.053,1406,2.033,1436,5.004,1438,3.375,1441,0.911,1447,1.023,1450,2.928,1481,1.177,1517,0.822,1529,1.581,1676,0.972,1688,1.088,1689,1.053,1738,1.711,1740,1.088,1742,1.177,1766,5.667,1778,1.088,1797,1.177,1831,0.721,1832,0.95,1867,0.996,1871,1.32,1872,1.32,1885,2.795,1886,3.551,1918,1.238,1931,3.271,1934,1.238,1940,4.58,1941,3.551,1956,1.088,1985,2.033,2145,1.053,2146,0.996,2281,1.023,2302,1.177,2325,0.95,2421,1.053,2438,1.32,2580,1.129,2633,1.238,2923,1.32,3140,2.922,3155,1.32,3405,3.373,3406,3.766,3407,2.471,3410,2.377,3411,1.443,3412,3.244,3413,1.443,3414,2.377,3415,1.443,3416,2.377,3417,1.443,3418,1.443,3419,1.32,3420,2.231,3421,1.32,3422,1.32,3423,1.32,3424,1.32,3425,1.32,3426,1.32,3427,1.238,3428,2.377,3429,1.32,3430,1.443,3431,1.443,3432,1.32,3433,1.129,3434,1.443,3435,1.443,3436,1.443,3437,1.443,3438,1.443,3439,1.443,3440,1.32,3441,1.443,3442,1.443,3443,1.32,3444,2.231,3445,1.443,3446,1.32,3447,1.238,3448,1.177,3449,0.996,3450,1.177]],["t/1140",[24,0.107,102,4.329,160,1.361,165,3.003,167,3.315,168,1.909,170,2.825,190,3.044,231,4.79,256,2.856,262,3.131,384,3.178,385,2.728,388,3.673,401,2.117,408,4.364,420,1.709,432,5.706,436,2.117,439,3.956,440,5.548,520,2.181,635,3.455,708,3.956,769,3.334,773,4.787,910,5.151,956,3.131,1086,2.616,1308,2.822,1350,3.852,1789,8.266,1892,3.852,1956,4.207,2213,5.103,3140,3.758,3433,6.12,3451,5.581,3452,5.581,3453,7.157,3454,5.581,3455,5.581,3456,5.581,3457,5.581,3458,5.581,3459,5.581,3460,5.581,3461,5.581,3462,5.581,3463,5.581,3464,5.581,3465,5.581,3466,5.581,3467,5.581,3468,5.581,3469,5.581,3470,5.581,3471,5.581,3472,5.581,3473,5.581,3474,5.581,3475,5.581,3476,5.581,3477,5.581,3478,5.581,3479,5.581]],["t/1142",[24,0.108,30,4.314,102,2.781,153,1.384,155,1.422,190,2.743,193,1.581,204,1.258,208,1.727,231,3.961,236,2.93,256,2.573,261,3.005,347,2.908,383,2.382,431,1.522,565,2.573,599,4.314,745,2.011,752,4.314,769,3.005,777,3.791,788,4.102,910,3.31,911,3.174,944,3.34,1283,2.459,1365,5.387,1436,2.955,1438,2.459,1450,4.475,1656,3.114,1689,5.305,1705,4.314,1740,5.479,1766,3.932,1778,3.791,1797,4.102,1811,4.598,1813,4.314,1892,5.89,1907,4.314,3405,3.386,3412,4.598,3419,4.598,3420,6.235,3421,4.598,3422,4.598,3423,4.598,3424,4.598,3425,4.598,3426,4.598,3427,4.314,3428,4.598,3429,4.598,3433,3.932,3453,4.598,3480,5.03,3481,5.03,3482,5.03,3483,7.269,3484,5.03,3485,5.03,3486,5.03,3487,5.03,3488,5.03,3489,5.03,3490,5.03,3491,5.03,3492,5.03,3493,4.314,3494,5.03,3495,5.03,3496,4.598]],["t/1144",[24,0.107,155,2.338,220,5.862,256,5.188,513,3.388,1237,5.443,1267,3.958,1436,4.86,1734,4.782,1886,5.862,3140,6.828,3405,5.569,3408,6.235,3446,9.271,3497,8.271]],["t/1146",[24,0.109,25,2.646,54,1.812,158,1.022,193,1.086,230,2.441,231,2.92,232,2.133,236,1.243,237,2.186,256,4.349,261,2.983,279,6.478,305,2.887,422,3.291,431,0.933,494,1.91,510,2.412,573,1.56,639,1.525,911,1.947,993,4.073,1124,2.325,1267,3.011,1283,1.508,1365,1.947,1375,1.987,1392,2.251,1406,2.412,1415,3.446,1436,3.696,1438,2.441,1441,1.947,1450,2.618,1531,3.764,1620,3.446,1656,1.91,1689,2.251,1734,1.784,1738,3.286,1740,2.325,1742,2.516,1766,5.654,1778,2.325,1797,4.073,1800,2.646,1813,2.646,1817,2.82,1885,6.002,1886,4.459,1892,2.129,1918,2.646,1941,5.125,1985,3.904,2271,2.325,2633,2.646,3405,4.236,3407,1.756,3408,2.325,3416,4.566,3420,2.646,3427,4.283,3440,2.82,3443,4.566,3444,4.283,3493,7.292,3498,3.085,3499,3.085,3500,3.085,3501,3.085,3502,3.085,3503,3.085,3504,3.085,3505,3.085,3506,3.085,3507,3.085,3508,3.085,3509,2.82,3510,3.085,3511,3.085,3512,3.085,3513,2.325,3514,3.085,3515,3.085,3516,3.085,3517,3.085,3518,3.085,3519,3.085,3520,3.085,3521,3.085,3522,3.085,3523,4.994,3524,3.085,3525,3.085,3526,3.085,3527,3.085,3528,3.085,3529,3.085,3530,2.82]],["t/1148",[24,0.108,54,3.36,79,2.983,153,1.006,155,1.617,168,1.251,170,1.32,176,1.377,193,1.532,200,1.474,204,0.915,214,2.022,230,3.442,236,2.305,247,2.67,252,3.138,254,2.149,256,4.074,261,2.185,264,2.758,485,2.115,513,1.498,639,1.808,740,3.84,786,4.054,911,2.309,1037,4.319,1086,1.715,1283,1.788,1287,2.185,1350,2.525,1364,2.407,1365,4.444,1372,3.138,1375,2.356,1436,3.36,1438,2.796,1531,6.003,1533,3.345,1881,3.138,1885,5.128,1886,2.593,1892,2.525,1941,2.593,1956,2.758,2013,3.138,2036,6.438,2072,2.758,2397,3.345,2402,3.345,2403,3.345,3140,6.168,3405,3.851,3406,4.36,3496,3.345,3509,3.345,3513,4.311,3531,3.658,3532,3.658,3533,3.658,3534,5.72,3535,5.72,3536,3.658,3537,5.72,3538,3.658,3539,5.72,3540,3.658,3541,3.658,3542,3.658,3543,3.658,3544,3.658,3545,3.658,3546,3.658,3547,3.658,3548,3.658,3549,3.658,3550,3.658,3551,3.658,3552,3.658,3553,3.658,3554,3.658,3555,3.658,3556,3.658,3557,3.658,3558,5.72,3559,3.658,3560,3.658,3561,3.658,3562,3.658,3563,3.658,3564,3.658,3565,3.345,3566,3.658,3567,3.658,3568,3.658,3569,3.658,3570,3.658,3571,5.72,3572,3.658,3573,3.658,3574,3.658,3575,3.658,3576,3.658,3577,3.658,3578,3.658,3579,3.658,3580,3.658,3581,3.658,3582,3.658,3583,5.72,3584,3.658,3585,3.658,3586,3.658,3587,3.658,3588,3.658,3589,3.658,3590,3.658,3591,3.658,3592,3.658,3593,3.658,3594,3.658,3595,3.658,3596,3.658,3597,3.658,3598,3.658,3599,3.658,3600,3.658,3601,2.86,3602,3.658]],["t/1150",[24,0.109,160,1.718,193,1.533,204,1.763,256,3.605,337,5.312,911,4.447,1237,4.637,1267,3.372,1438,4.48,1441,4.447,1885,4.538,2145,5.143,3513,5.312,3603,8.379,3604,7.047,3605,7.047,3606,7.047]],["t/1152",[24,0.109,83,1.568,129,1.779,164,1.608,193,1.07,204,1.968,212,1.952,214,1.739,236,1.983,256,1.549,298,2.597,299,2.469,300,2.039,308,2.089,319,2.329,385,1.48,410,2.089,422,1.378,516,2.21,545,4.219,559,2.039,575,1.271,639,1.496,645,3.217,678,3.257,843,1.992,851,1.513,1037,2.459,1125,2.597,1237,4.707,1307,2.282,1375,5.067,1392,3.59,1406,4.857,1415,3.394,1479,2.282,1620,3.394,1885,1.95,1941,2.146,2050,2.469,2072,2.282,2208,2.768,2277,7.802,3140,6.23,3184,2.768,3414,2.768,3513,4.683,3530,2.768,3603,6.539,3607,3.028,3608,4.919,3609,3.028,3610,3.028,3611,3.028,3612,3.028,3613,3.028,3614,3.028,3615,3.028,3616,3.028,3617,3.028,3618,3.028,3619,3.028,3620,3.028,3621,3.028,3622,3.028,3623,3.028,3624,5.68,3625,3.028,3626,3.028,3627,3.028,3628,3.028,3629,3.028,3630,3.028,3631,4.919,3632,3.028,3633,4.497,3634,3.028,3635,3.028,3636,6.212,3637,4.919,3638,3.028,3639,4.919,3640,3.028,3641,4.919,3642,6.212,3643,3.028,3644,3.028,3645,3.028,3646,3.028,3647,3.028,3648,6.212,3649,4.919,3650,3.028,3651,3.028,3652,3.028,3653,3.028,3654,3.028,3655,2.768]],["t/1154",[24,0.109,155,1.515,173,3.698,193,1.655,204,1.903,207,2.262,208,1.539,221,2.775,230,2.619,236,2.16,256,2.741,340,4.596,359,2.741,476,2.094,565,2.741,731,2.883,911,3.382,1218,6.203,1267,4.605,1296,4.039,1436,3.148,1438,2.619,1538,4.899,1610,4.37,1676,5.121,1885,3.451,3405,5.121,3406,6.871,3407,3.051,3408,4.039,3601,8.256,3656,4.899,3657,5.358,3658,5.358,3659,5.358,3660,5.358,3661,4.899,3662,5.358,3663,5.358]],["t/1156",[24,0.108,207,2.38,208,1.619,344,3.714,513,3.278,868,7.316,968,4.425,1831,4,1832,5.266,1867,5.522,2325,5.266,2421,5.84,3407,4.556,3447,6.864,3448,6.526,3449,5.522,3450,6.526,3664,8.002,3665,8.002]],["t/1158",[24,0.109,153,1.535,158,1.849,159,3.227,170,2.014,208,1.129,214,1.973,219,3.707,230,2.728,254,3.279,256,2.856,264,7.388,359,2.856,367,4.552,520,2.181,819,4.552,1177,3.334,1375,3.594,1450,4.74,1490,3.131,1815,8.96,1885,3.594,1927,4.787,1941,3.956,2435,5.103,3111,4.364,3513,4.207,3666,5.581,3667,5.581,3668,5.581,3669,5.581,3670,5.581,3671,5.581,3672,5.581,3673,5.581,3674,5.581]],["t/1160",[24,0.109,102,2.47,150,2.094,154,2.258,155,3.049,160,1.625,167,1.891,168,2.279,170,1.612,193,1.449,204,2.364,207,2.947,208,2.077,236,3.211,256,2.285,347,2.582,377,2.16,380,2.342,388,2.939,395,4.083,420,1.367,422,2.033,431,2.016,433,3.007,437,3.643,439,3.166,440,3.166,639,2.207,769,2.668,831,2.014,851,3.33,910,4.384,911,2.819,944,3.061,956,4.955,1038,3.007,1267,2.137,1283,3.257,1308,2.258,1364,2.939,1436,4.681,1442,3.492,1450,4.631,1529,4.05,1665,2.939,1738,2.939,1881,3.831,2013,3.831,2901,4.083,3405,3.007,3407,2.543,3433,5.209,3675,4.083,3676,4.083,3677,4.466,3678,4.466,3679,4.466]],["t/1163",[24,0.106,158,2.71,176,3.08,185,2.892,191,4.136,199,3.723,207,2.433,208,1.655,212,3.245,374,1.68,505,4.344,513,3.35,589,2.549,970,4.972,1317,5.797,1831,4.089,1867,5.645,2577,5.797,3449,5.645]],["t/1165",[24,0.108,54,3.381,80,3.33,153,1.583,155,1.627,176,3.46,185,2.035,204,2.485,214,2.035,254,3.381,256,2.945,264,4.338,298,4.937,299,4.694,326,5.208,340,4.937,433,3.875,513,2.357,678,3.018,732,3.277,851,2.877,878,4.5,907,3.056,1038,3.875,1177,3.438,1267,2.754,1450,3.018,1490,3.228,1645,4.2,2433,4.937,2546,5.262,3406,6.149,3407,5.233,3449,3.972,3565,5.262,3601,6.253,3656,5.262,3680,5.755,3681,5.755,3682,5.755,3683,5.755,3684,5.755,3685,5.755,3686,5.755,3687,5.262,3688,5.755,3689,5.755,3690,5.755,3691,5.755,3692,5.755,3693,5.755,3694,5.755]],["t/1167",[24,0.109,150,3.418,204,2.344,487,2.806,732,4.151,907,4.975,1053,5.321,1086,4.391,1324,4.695,1867,5.031,3406,6.409,3407,6.22,3695,7.291,3696,7.291,3697,7.291]],["t/1170",[24,0.108,207,2.393,208,1.628,317,3.051,342,5.182,374,1.238,398,2.682,401,3.051,513,3.295,592,3.051,910,5.294,968,4.449,1089,4.981,1266,5.552,3407,4.581,3447,6.901,3448,6.562,3449,5.552]],["t/1172",[24,0.106,28,3.324,153,1.85,155,1.902,164,3.572,176,3.347,185,2.378,193,1.463,204,2.491,214,2.378,231,3.121,254,3.952,286,3.401,326,3.526,431,2.035,433,4.528,678,3.526,809,5.07,851,3.362,878,5.259,907,3.572,1038,4.528,1177,5.31,1267,4.253,1450,3.526,1490,3.773,1529,4.089,1635,5.259,1676,5.985,2788,5.485,2884,6.149,3406,5.503,3407,5.061,3601,5.259,3687,6.149,3698,6.726,3699,8.889,3700,6.726,3701,6.726,3702,8.889,3703,6.726,3704,6.726,3705,6.726]],["t/1174",[24,0.108,155,2.666,176,2.772,193,1.602,204,2.359,207,2.19,208,1.49,431,2.228,513,3.016,732,4.192,910,4.845,1086,3.452,1237,4.845,1676,4.958,2580,5.757,2655,6.732,3406,6.439,3407,4.192,3449,5.081,3675,6.732,3676,6.732,3706,7.364,3707,7.364,3708,7.364,3709,7.364]],["t/1177",[24,0.107,150,4.012,207,2.546,208,1.732,344,3.972,374,1.317,1832,5.632,2325,5.632,2421,6.246,3407,4.873,3450,6.98]],["t/1179",[24,0.105,28,4.862,155,2.226,164,5.224,168,2.693,176,2.965,179,4.875,198,4.294,236,3.174,428,2.881,486,3.849,513,4.029,624,3.453,646,8.022,678,4.128,731,4.236,1037,3.936,1106,6.754,1438,3.849,1490,4.417,1635,6.156,2422,7.199,3073,7.199,3449,5.434,3450,6.422,3710,7.874,3711,7.874]],["t/1181",[24,0.107,176,3.063,193,1.77,204,2.511,207,2.419,208,1.646,431,2.461,732,4.631,851,4.066,907,4.32,1676,5.477,3406,6.214,3407,4.631,3712,8.135,3713,8.135,3714,8.135,3715,8.135]],["t/1184",[24,0.108,185,2.274,207,1.913,208,1.302,257,5.518,374,1.328,487,2.476,494,5.342,513,2.635,731,3.461,732,5.544,830,2.847,907,3.416,1369,5.881,1370,5.881,1832,4.233,1866,7.037,2421,6.297,2580,6.747,3406,6.916,3407,4.913,3448,7.941,3449,4.439,3716,6.433,3717,6.433,3718,6.433]],["t/1186",[24,0.109,176,2.579,185,2.422,512,2.783,732,3.9,1267,3.278,1324,4.412,1392,5,1450,5.267,1479,5.164,1941,7.121,2097,5.587,2100,6.263,3406,4.241,3407,5.123,3493,8.617,3719,6.851,3720,6.851,3721,6.263]],["t/1188",[24,0.108,176,2.718,287,5.888,512,2.933,559,6.268,910,4.75,1037,5.15,1375,5.995,1406,5.645,2277,7.592,3140,6.937,3407,4.11,3513,5.442,3624,6.6,3633,6.6,3655,8.511,3722,7.219,3723,7.219]],["t/1190",[24,0.109,54,5.378,80,2.378,155,2.799,158,1.892,176,3.446,185,2.019,207,2.722,208,1.852,512,2.32,513,3.258,734,4.529,910,3.758,1375,5.895,1450,4.799,1689,4.168,1740,4.305,1866,4.657,1886,7.377,2097,4.657,3406,3.536,3407,5.211,3408,4.305,3444,7.851,3724,5.711,3725,5.711,3726,5.711,3727,5.711]],["t/1192",[24,0.109,158,1.914,168,2.743,204,2.006,207,1.718,208,1.169,219,2.736,236,3.232,374,0.889,513,2.366,732,3.29,740,4.373,830,2.557,956,4.499,1237,3.802,1267,3.837,1296,4.355,1436,4.712,1438,2.824,2029,3.987,2269,5.282,3140,3.89,3158,4.095,3405,3.89,3406,4.965,3407,5.665,3433,6.27,3449,3.987,3601,6.27,3721,5.282,3728,5.778,3729,8.02]],["t/1194",[24,0.108,83,3.548,154,3.464,155,1.937,204,2.513,207,2.037,208,1.386,236,2.761,256,4.603,374,1.054,944,3.148,968,3.788,1037,3.424,1237,4.508,1283,3.349,1436,5.286,1672,5.356,1734,3.961,1738,4.508,1831,3.424,1832,4.508,1885,5.794,1886,4.856,3140,6.058,3405,6.058,3406,5.57,3407,3.9,3408,6.782]],["t/1196",[24,0.104,3730,9.682]],["t/1198",[24,0.109,37,5.508,69,1.825,110,1.714,153,2.894,155,2.485,160,1.293,180,3.282,374,0.816,375,2.563,383,2.51,476,2.071,480,2.12,532,1.778,533,2.95,587,3.488,589,1.652,590,2.304,622,1.576,678,3.957,725,3.345,760,5.296,789,5.209,831,2.39,1098,4.144,1298,5.69,1712,4.668,2743,4.144,3731,5.301,3732,5.301,3733,5.508,3734,5.301,3735,5.918,3736,5.301]],["t/1200",[24,0.109,34,1.271,37,4.198,69,2.752,110,1.741,153,1.236,155,2.097,193,1.251,199,1.234,317,3.211,326,1.421,374,1.03,377,2.782,383,2.724,425,1.355,428,1.644,476,2.248,480,2.3,485,2.597,487,1.729,532,0.909,533,1.771,534,3.538,541,2.298,542,2.211,590,1.178,622,1.336,638,1.421,645,1.404,678,2.355,708,1.921,712,3.137,718,1.567,722,1.404,724,1.067,725,2.835,740,2.45,760,5.237,769,1.619,789,4.617,834,2.043,846,1.439,862,1.093,913,1.921,935,2.325,963,1.648,972,2.325,1037,1.355,1120,1.246,1121,1.871,1298,2.043,1482,2.211,1712,3.553,1726,2.478,1995,1.978,2194,5.571,2302,2.211,2570,4.497,2743,2.119,3432,2.478,3733,4.198,3735,3.873,3737,4.691,3738,2.711,3739,3.853,3740,2.211,3741,2.711,3742,2.711]],["t/1203",[24,0.108,69,3.069,153,2.114,158,1.801,169,2.782,170,2.773,176,2.047,187,3.431,193,1.183,200,2.192,201,2.718,202,2.887,207,1.617,214,1.922,221,2.816,375,4.311,399,2.141,428,3.545,431,1.645,436,2.062,517,3.305,534,3.401,542,4.434,584,2.342,589,1.694,590,2.363,622,3.155,663,1.962,676,3.194,687,3.305,720,2.428,725,3.431,727,4.971,760,4.25,789,5.304,935,4.664,963,4.672,1004,3.661,1098,4.251,1129,4.251,1685,4.251,1995,3.968,3743,5.437,3744,5.437,3745,5.437,3746,5.437,3747,5.437,3748,5.437,3749,5.437,3750,5.437]],["t/1205",[24,0.109,34,3.79,37,4.267,69,2.013,110,1.768,149,3.065,153,1.608,155,2.827,236,2.356,268,2.32,286,2.956,317,2.217,373,2.956,399,3.183,425,2.922,476,3.159,487,3.112,532,1.962,533,1.8,622,1.739,638,3.065,663,2.11,708,4.144,760,4.471,769,3.493,789,5.58,834,4.407,845,3.765,1120,2.687,1121,4.035,1482,4.768,1712,3.105,2743,4.571,3733,4.267,3735,3.936,3751,5.847]],["t/1207",[24,0.109,69,3.165,110,1.497,153,1.583,168,1.969,193,2.161,199,2.619,200,2.32,201,2.877,202,3.056,268,3.173,317,3.486,377,4.803,428,2.106,476,2.249,487,3.078,534,3.539,540,4.937,541,2.945,622,2.379,663,2.077,673,3.101,676,3.381,711,5.262,725,5.047,789,3.972,1004,3.875,1120,3.675,1952,5.262,2194,6.048,3735,5.385,3752,5.755,3753,5.755,3754,5.755]],["t/1209",[24,0.108,69,2.755,110,1.618,193,1.741,317,3.035,377,3.87,383,3.789,476,3.882,487,3.08,534,3.541,541,4.094,638,4.196,1712,4.249,2194,5.266,3735,6.69,3755,8.002]],["t/1211",[24,0.109,69,1.936,98,2.148,110,1.686,185,1.988,191,2.844,286,2.844,317,3.729,476,2.197,485,3.252,487,2.165,534,4.352,645,2.912,663,2.029,712,3.067,740,3.067,760,4.352,789,5.431,846,2.986,1037,3.934,1301,5.578,2194,6.47,2570,4.397,3733,4.104,3735,3.786,3737,4.586,3739,4.824,3740,6.418,3756,5.624]],["t/1214",[24,0.109,34,2.358,69,1.732,110,0.819,191,2.543,204,1.258,332,3.671,399,1.98,410,5.016,415,6.674,425,3.633,428,3.123,476,1.965,481,3.114,487,1.936,534,2.226,590,2.186,622,1.496,718,2.908,760,5.485,834,3.791,970,3.057,1121,3.471,1262,3.932,1365,3.174,1892,3.471,1900,4.314,2046,6.235,2092,7.322,2717,4.314,3757,5.03,3758,5.03,3759,5.03,3760,7.269,3761,5.03,3762,5.03,3763,4.598,3764,5.03,3765,6.646,3766,4.598,3767,5.03,3768,5.03,3769,5.03,3770,5.03,3771,5.03,3772,5.03,3773,5.03,3774,5.03,3775,5.03]],["t/1216",[24,0.109,69,1.519,153,1.214,158,1.462,176,1.661,185,2.334,193,1.436,214,2.334,268,1.751,287,3.599,317,2.504,374,0.679,377,3.193,383,2.09,476,2.58,480,1.765,485,2.552,487,3.045,540,3.785,541,2.258,645,4.547,663,2.382,712,3.6,722,2.285,725,2.785,740,2.406,760,4.855,1037,3.3,1266,3.045,1301,3.128,2194,5.778,3739,6.785,3740,6.451,3776,4.413,3777,4.413,3778,4.413,3779,6.602,3780,4.413,3781,4.413]],["t/1218",[24,0.109,80,2.369,110,0.926,160,2.227,169,4.673,185,2.011,187,6.237,214,2.011,268,2.257,317,3.748,534,2.517,556,4.88,557,4.288,590,2.473,677,3.522,712,3.102,760,5.465,799,4.88,1039,6.47,1298,4.288,1365,3.59,2194,6.503,2469,3.926,2885,4.88,3782,5.201,3783,5.689,3784,5.689,3785,5.689,3786,5.689,3787,5.689,3788,5.689,3789,7.933]],["t/1220",[24,0.109,110,1.857,153,1.902,268,2.744,317,2.622,383,3.275,476,2.702,487,2.661,534,3.06,638,3.626,722,3.581,724,2.723,760,3.824,834,5.213,1120,3.178,1121,4.772,1712,3.672,2570,5.406,2743,5.406,3733,6.606,3735,4.656,3737,5.639]],["t/1222",[24,0.109,34,1.781,69,2.798,110,1.432,176,1.43,185,1.343,193,0.827,204,1.474,231,2.734,236,1.531,239,3.259,268,1.508,317,2.736,319,1.799,321,2.622,330,2.971,333,2.5,375,1.837,383,1.799,399,2.84,410,4.065,411,2.558,415,6.355,423,2.971,425,4.396,428,3.405,476,1.485,487,1.462,534,3.597,590,1.651,622,2.417,635,2.352,639,1.878,712,2.072,724,1.496,738,2.072,760,4.494,774,3.099,825,2.971,846,3.128,874,2.944,1029,5.053,1120,1.746,1177,2.27,1262,2.971,1365,2.398,1415,2.622,1531,4.441,1645,2.773,1900,3.259,2046,5.053,2092,6.188,2194,4.747,2384,3.474,2816,3.474,3763,3.474,3765,5.386,3766,3.474,3790,3.8,3791,5.891,3792,3.8,3793,3.8,3794,3.8,3795,3.8,3796,3.8,3797,3.8,3798,3.8,3799,3.8,3800,3.8,3801,3.8,3802,3.8,3803,3.8,3804,3.474,3805,3.474,3806,3.474,3807,5.891,3808,5.891,3809,3.8,3810,3.8,3811,3.8,3812,3.8]],["t/1224",[24,0.108,34,3.504,69,3.606,110,1.217,176,2.814,399,2.943,425,3.736,428,3.483,476,2.921,487,2.877,534,3.308,590,3.249,622,2.223,760,5.264,826,4.718,1029,6.412,3804,6.834,3805,6.834,3806,6.834,3813,7.475]],["t/1226",[24,0.109,110,1.799,191,3.799,383,3.558,436,2.849,534,4.646,760,4.155,831,3.387,1364,4.944,1656,4.651]],["t/1230",[24,0.109,80,2.702,169,5.004,187,6.172,317,3.292,375,4.197,428,2.374,556,5.566,557,4.892,677,5.374,712,3.539,760,5.774,799,5.566,2194,5.711,2885,5.566,3735,7.031,3782,5.933,3814,6.489,3815,6.489]],["t/1232",[24,0.108,110,1.874,180,5.727,191,3.615,317,3.508,534,3.164,645,3.702,740,3.899,760,5.115,834,5.389,1121,4.934,1177,4.271,1208,5.218,1712,3.796,2194,6.087,2570,5.59,3737,5.831,3740,5.831]],["t/1234",[24,0.107,110,1.68,158,2.819,486,4.16,534,4.566,595,3.43,1177,5.084,1637,7.299,2050,6.94,3816,8.51,3817,8.51]],["t/1236",[28,4.383,80,3.692,153,2.439,164,4.709,173,6.12,179,6.548,254,5.21,288,5.596,292,6.685,295,7.973,332,6.472,529,7.606,677,5.49,1490,4.974,1709,6.285,3661,8.107,3818,8.868,3819,8.868]],["t/1238",[24,0.077,69,3.128,180,5.625,199,4.135,308,6.27,487,3.497,501,8.307,3820,9.086,3821,9.086,3822,9.086,3823,9.086,3824,9.086,3825,9.086,3826,9.086,3827,9.086,3828,9.086]],["t/1240",[24,0.109,37,6.487,110,1.448,154,3.401,155,2.513,187,4.245,212,2.669,214,2.378,308,4.641,317,2.551,533,2.071,541,3.441,677,4.164,678,3.526,709,4.908,760,5.857,831,3.032,1712,4.72,2194,4.426,2303,6.149,3733,6.487,3735,4.528,3829,6.726,3830,6.726]],["t/1242",[24,0.107,37,6.14,110,1.669,153,2.314,155,2.897,383,3.984,541,4.304,760,5.666,831,3.793,1298,6.342,1712,4.467,3733,6.14,3735,5.664]]],"invertedIndex":[["",{"_index":24,"t":{"5":{"position":[[52,2],[68,1]]},"7":{"position":[[143,2]]},"21":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"23":{"position":[[48,1],[60,2],[63,2],[66,3],[70,2],[73,1],[75,3],[79,2],[82,4],[87,3],[111,2],[119,4],[124,1],[126,4],[136,2],[139,2],[142,3],[146,2],[170,1],[172,5],[178,2],[181,4],[186,5],[192,3],[237,1],[239,2]]},"25":{"position":[[7,2],[10,2],[13,1],[15,3],[19,5],[25,2],[28,3],[32,2],[35,3],[39,6],[46,1],[48,3],[57,1],[59,2],[62,5],[68,3],[72,1],[74,3],[78,3],[82,3],[86,2],[89,4],[94,2],[97,4],[102,4],[107,3],[158,2],[185,3],[189,2],[192,2],[195,2],[214,4],[219,1],[221,5],[227,2],[230,3],[234,2],[237,2],[240,3],[257,2],[260,2],[263,4],[268,5],[274,2],[277,1],[279,3],[283,5],[289,3],[293,2],[318,1],[320,2],[323,5],[329,2],[332,1],[334,4],[339,2],[342,3],[359,6],[366,2],[382,1],[384,5],[394,1],[405,2],[408,4],[413,3],[417,4],[422,4],[427,6],[434,6],[446,4],[451,3],[458,4],[463,2],[510,2],[513,3],[517,4],[522,2],[525,4],[530,4],[535,2],[538,5],[544,4],[549,3],[574,2],[577,2],[587,2],[590,4],[595,2],[598,5],[604,3],[608,3],[612,4],[617,4],[622,1],[624,4],[629,2],[632,3],[636,4],[641,2],[644,1],[646,4],[651,4],[656,5],[662,3],[666,3],[670,4],[684,2],[692,3],[696,2],[699,4],[709,5],[722,4],[727,2],[730,2],[742,2],[751,4],[759,1],[761,2],[764,4],[769,4]]},"27":{"position":[[0,2],[3,1],[5,4],[10,3],[47,2],[50,5],[56,2],[59,4],[64,2],[119,3],[123,2],[140,2],[143,2],[146,2],[149,3],[153,4],[167,2],[180,3],[184,5],[190,1],[192,2],[195,5],[201,5],[228,2],[231,3],[256,1],[268,1],[270,4],[275,2],[292,1],[294,5],[320,1],[322,3],[326,3],[330,2],[333,4],[338,6],[345,3],[349,3],[353,3],[357,3],[447,3],[457,1],[469,2],[472,4],[477,2],[480,6],[487,1],[489,5],[504,1],[516,2],[519,4],[524,2]]},"31":{"position":[[13,2],[16,1],[18,4],[23,2],[26,3],[30,4],[35,3],[39,3],[43,4],[56,1],[58,2],[61,1],[63,1],[65,4],[70,2],[73,2],[76,3],[80,5],[86,2],[89,3],[93,5],[99,2],[102,3],[106,5],[112,2],[115,3],[119,4],[131,1],[133,4],[138,4],[143,1],[145,2],[148,2],[151,2],[154,4],[159,3],[163,2],[171,3],[175,4],[180,3],[184,2],[187,4],[192,4],[197,4],[214,1],[216,4],[221,4]]},"33":{"position":[[13,2],[16,3],[42,1],[64,2],[67,2],[70,5],[82,1],[84,4],[101,1],[103,3],[107,1],[109,2],[112,3],[116,3],[120,3],[131,1],[151,1],[161,1],[186,2],[189,3],[206,1],[208,6],[215,1],[217,3],[221,4],[226,2],[236,1],[238,4],[259,3],[263,3],[280,1],[282,7],[290,2],[293,3],[310,1],[312,3],[316,3],[324,2],[327,3],[331,4],[343,1],[351,1],[353,5],[359,4],[364,4]]},"35":{"position":[[13,2],[16,1],[18,2],[21,4],[38,2],[41,2],[44,7],[52,2],[55,2],[58,2],[61,1],[63,4],[68,4],[73,3],[77,2],[80,4],[85,1],[87,5],[115,4],[120,2],[123,3],[127,3],[131,4],[136,2],[139,2],[142,3],[159,2],[162,4],[176,1],[178,2],[181,1],[183,3],[187,3],[191,2],[194,2],[197,3],[201,4],[206,1],[208,2],[211,3],[215,3],[228,3],[232,2],[235,5],[241,2],[244,3],[248,3],[252,1],[254,1],[256,2],[259,3],[263,3]]},"38":{"position":[[12,1],[14,4],[19,4],[24,4],[29,3],[33,2],[36,4],[41,5],[47,2],[69,1],[71,2],[87,1],[89,4],[107,1],[115,3],[136,1],[138,5],[167,1],[181,1],[194,1],[196,2],[199,4],[204,2],[207,2],[220,1],[222,5],[228,4],[233,4],[238,3],[250,1],[252,2],[268,2],[271,2],[274,3],[278,2],[281,3],[285,3],[289,2],[305,4],[310,2],[384,1],[386,3],[390,2],[393,4],[412,1],[414,2],[417,3],[421,4],[426,4],[433,1],[438,1],[454,1],[465,1]]},"40":{"position":[[0,2],[20,1],[22,6],[29,2],[45,2],[48,4],[53,3],[57,3],[68,1],[70,2],[73,3],[90,2],[100,1],[102,2],[105,3],[109,2],[123,4],[128,2],[144,1],[146,3],[150,4],[164,1],[166,2],[169,1],[171,5],[177,5],[183,5],[189,2]]},"42":{"position":[[0,1],[2,2],[5,4],[10,4],[32,1],[43,2],[65,1],[67,4],[72,2],[75,1],[77,4],[82,1],[84,3],[88,2],[91,1],[93,2],[96,2],[99,5],[105,5],[111,2],[118,2],[121,2],[141,2],[152,3],[156,4],[161,1],[163,2]]},"44":{"position":[[0,2],[3,3],[28,1],[30,2],[33,2],[36,3],[40,3],[44,4],[49,3],[53,3],[76,1],[87,1],[89,3],[108,1],[110,2],[113,3],[117,2],[120,2],[123,2],[126,2],[129,5]]},"47":{"position":[[0,3],[4,4],[9,2],[12,4],[17,1],[19,3],[23,3],[27,4],[32,2],[35,4],[40,6],[47,3],[51,4],[56,2],[59,2],[62,4],[67,4],[87,4],[92,2],[95,3],[99,3],[103,5],[109,2],[138,2],[141,2],[144,5],[150,3],[154,4],[185,3],[189,4],[194,2],[197,2],[200,2],[203,3],[207,4],[212,3],[232,2],[235,4],[240,2],[257,1],[259,4],[264,2],[281,3],[285,2],[288,4],[293,4],[298,3],[302,1],[304,5],[310,2],[313,5],[319,2],[337,2],[340,1],[342,5],[348,2],[366,2],[369,4],[374,4],[379,2],[382,5],[388,5],[394,1],[396,3],[400,3],[425,1],[427,3],[438,1],[473,1],[475,5]]},"49":{"position":[[0,2],[3,2],[6,2],[9,5],[15,3],[40,1],[42,5],[48,2],[51,3],[55,2],[58,4],[63,2],[66,4],[71,4],[76,3],[80,4],[85,3],[89,3],[93,3],[97,3],[101,3],[105,2],[108,4],[113,2],[116,4],[121,4],[126,3],[130,3],[134,3],[142,2],[156,2],[159,3],[163,3],[172,3],[186,3],[190,1],[215,2],[236,1],[238,2],[241,3],[245,2],[252,1],[254,3],[266,1],[268,2],[271,1],[279,1],[283,2],[288,2],[293,3],[297,3],[304,3],[308,4],[316,1],[324,1],[326,4],[331,5],[337,3],[344,1],[349,1],[351,6],[358,1],[360,3],[364,2],[367,4],[372,2],[396,1],[398,5],[404,5],[410,3],[414,3],[418,1],[420,5],[426,2],[431,3],[435,4],[440,4],[455,4],[460,3],[473,2],[511,1],[513,5],[519,3],[523,3],[576,1],[578,6],[585,3],[589,2],[592,1],[594,3],[625,1],[654,1],[656,4],[661,2],[664,1],[666,3],[670,2],[673,5],[706,1],[721,1],[787,1],[802,1]]},"53":{"position":[[6,4],[18,4],[28,4],[33,3],[57,2],[60,5],[66,4],[71,5],[84,4],[89,2],[92,2],[95,3],[112,1],[114,4],[137,1],[163,1],[369,1],[377,1],[382,2],[385,1],[387,5],[393,3]]},"55":{"position":[[0,2],[3,5],[9,3],[13,2],[35,2],[55,1],[73,2],[80,3],[84,3],[97,1],[99,4],[121,1],[128,1],[130,5],[141,1],[143,4],[148,4]]},"58":{"position":[[12,1],[21,4],[30,4],[35,4],[40,4],[45,4],[50,4],[55,4],[69,4],[74,6],[81,4],[86,6],[93,5],[119,1],[121,3],[125,6],[132,2],[135,3],[139,4],[144,2],[147,3],[151,3],[155,2],[158,4],[166,2],[174,2],[177,1],[179,4],[200,1],[202,5],[221,2],[224,2],[230,3],[234,3],[238,2]]},"60":{"position":[[0,1],[2,5],[8,3],[29,1],[37,2],[45,1],[47,2],[50,5],[61,1],[63,2],[73,3],[82,3],[86,2],[89,3],[93,4]]},"63":{"position":[[20,1],[22,4],[62,5],[80,3],[84,2],[87,3],[100,1],[102,5],[108,3],[112,3],[116,3]]},"65":{"position":[[0,2],[3,5],[9,4],[24,2],[44,1],[46,2],[49,2],[72,2],[90,2],[98,1],[100,2],[103,4],[108,4]]},"68":{"position":[[15,1],[31,1],[33,6]]},"72":{"position":[[21,1],[23,2],[26,4],[31,4],[36,5]]},"74":{"position":[[0,3],[4,3],[8,2],[35,4],[40,4],[45,3],[49,5]]},"76":{"position":[[19,1],[36,2],[39,3],[43,3],[69,1],[98,2],[101,3],[105,3],[109,3],[113,5],[119,2],[122,4],[127,2],[130,3],[147,1],[149,4],[154,2],[157,3],[174,1],[176,2],[179,1],[181,4],[186,2],[189,2],[205,4],[215,5],[225,5]]},"82":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"84":{"position":[[9,2],[37,1],[39,4],[44,2],[47,3],[51,1],[53,5],[66,1],[72,3],[76,5],[94,1],[96,3],[100,3],[104,3],[113,1],[115,6],[122,2],[150,1],[152,5]]},"86":{"position":[[0,2],[3,5],[18,4],[23,1],[40,1],[42,4],[47,2],[50,3],[54,4],[59,5],[69,1],[71,2],[74,2],[77,2],[80,3],[84,6],[91,6],[102,2],[105,5],[111,4],[116,3],[120,1],[122,4],[127,3],[138,1],[140,2],[143,5],[149,3],[158,1],[160,2],[163,1],[165,4],[170,2],[173,3],[177,1],[179,2],[182,4],[187,2],[202,1],[204,2],[207,4],[212,4],[217,2],[220,3],[224,2],[227,4],[232,2],[235,3],[239,2],[242,3],[246,3],[250,2],[253,3],[257,4],[266,1],[268,4],[273,4],[290,1],[292,4],[297,2],[300,2],[303,2],[323,4],[328,2],[338,2],[341,4],[346,4],[363,1],[378,1],[389,2],[407,1],[409,4],[414,4],[419,1],[421,2],[424,2],[427,4],[432,4],[437,1],[439,3],[457,6],[464,5],[470,1],[472,3],[476,4],[481,2],[484,5],[508,1],[510,1],[512,2],[515,3],[519,4],[524,4],[559,1],[561,2],[564,3],[568,3],[572,2],[575,2],[578,4],[583,3],[587,3],[591,2],[594,3],[598,4],[603,2],[606,3],[610,6],[617,4],[622,2],[625,1],[627,3],[631,2],[634,1],[636,4],[656,1],[658,2],[667,1],[669,2],[672,1],[680,1],[682,2],[685,2],[708,2],[711,3],[715,3],[719,3],[723,3],[742,1],[744,3],[748,3],[752,2],[755,1],[757,4],[762,5],[768,4],[773,5],[791,2],[794,3],[813,1],[815,3],[819,3],[823,3],[827,3],[831,3],[835,4]]},"88":{"position":[[12,1],[14,3],[18,3],[22,5],[28,1],[30,3],[34,2],[37,2],[40,3],[44,2],[62,1],[64,4],[69,2],[72,3],[76,5],[82,4],[102,3],[106,1],[108,2],[111,3],[115,2],[118,3],[122,3],[141,1],[143,6],[176,2],[179,3],[183,2],[186,1],[188,3],[192,4],[212,1],[214,6],[225,2],[228,5],[234,5],[246,3],[261,3],[269,2],[272,3],[291,1],[293,7],[305,1],[307,6],[314,3],[318,2],[321,2],[324,6],[331,3],[335,4],[340,1],[342,3],[346,2],[349,5],[355,3],[359,5],[407,2],[422,1],[439,1],[441,3],[448,2],[455,1],[457,2],[460,3],[479,2],[482,2],[485,4],[490,4],[499,1],[516,1],[518,3],[522,3],[526,5],[532,3],[536,1],[538,5],[553,2],[556,1],[571,1],[582,1],[584,2],[587,3],[591,7],[599,4],[604,3],[608,2],[615,3],[619,3],[623,4],[628,1],[630,4],[647,1],[649,6]]},"91":{"position":[[0,2],[21,3],[41,1],[55,1],[57,4],[65,1],[67,4],[72,3],[76,3],[80,4],[85,3],[89,2],[92,5],[98,3],[102,2],[115,3],[174,1],[195,1],[206,1],[249,1],[279,1],[281,6],[305,1],[307,2],[310,3],[314,3],[322,1],[324,2],[327,1],[346,1],[348,1],[350,3],[354,3],[358,3],[371,1],[387,1],[389,3],[393,3],[397,2],[412,1],[414,4],[434,2],[449,1],[451,2],[454,5],[460,3],[478,3],[486,1],[488,6],[495,3],[507,2],[528,4],[533,1],[538,2],[545,4],[550,5],[556,1],[569,1],[571,3],[591,2],[594,4],[613,2],[630,1],[632,4],[637,4],[642,4],[647,3],[651,4],[656,1],[658,4],[663,5],[669,5],[675,2],[678,4],[683,3],[687,2],[690,4],[695,4],[700,3],[704,3],[708,5],[714,2],[717,3],[721,4],[726,3],[730,4],[735,4],[740,1],[742,5],[759,1],[761,1],[769,1],[777,1],[779,5],[801,1],[803,2],[806,3],[820,1],[842,1],[875,1],[877,1],[879,2],[902,1],[904,2],[907,2],[910,1],[929,1],[931,1],[933,3],[937,2],[944,1],[946,2],[949,4],[954,1],[972,1],[986,1],[988,3],[992,1],[1014,1],[1033,1],[1035,2],[1071,1],[1088,1],[1106,1],[1151,2],[1154,3],[1158,3],[1181,1],[1199,1],[1201,2],[1232,1],[1234,2],[1237,3],[1241,4],[1246,2],[1249,1],[1273,2],[1293,1],[1304,1],[1314,1],[1316,2],[1365,1],[1377,1],[1379,4],[1390,1],[1392,2],[1410,1],[1412,2],[1421,3],[1425,2],[1448,1],[1450,2],[1453,2],[1456,2],[1459,2],[1466,1],[1487,1],[1489,2],[1492,1],[1494,2],[1497,4],[1502,2],[1535,4],[1582,1],[1642,5],[1665,1],[1704,1],[1718,4],[1750,1],[1794,4],[1841,3],[1845,4],[1850,5],[1862,1],[1864,2],[1867,1],[1869,3],[1873,5],[1879,3],[1900,1],[1902,1],[1904,4],[1909,3],[1913,4],[1938,3],[1974,3],[1990,1],[2033,1],[2059,1],[2063,1],[2065,4],[2102,3],[2128,1],[2130,5],[2161,2],[2191,1],[2193,2],[2196,3],[2209,1],[2236,1],[2238,3],[2270,3],[2285,1],[2325,1],[2353,1],[2357,1],[2359,4],[2392,3],[2407,1],[2409,5],[2415,2],[2418,5],[2439,1],[2470,6],[2492,2],[2502,2],[2505,4]]},"93":{"position":[[4,1],[19,2],[22,4],[27,2],[30,3],[38,1],[44,4],[49,4],[54,4],[74,4],[79,5],[85,3],[94,2],[112,1],[114,3],[130,3],[134,1],[139,2],[142,4],[147,2],[150,3],[154,5],[160,2],[163,2],[166,4],[171,4],[176,3],[180,3],[184,1],[198,1],[200,4],[224,2],[246,1],[248,3],[252,1],[254,4],[271,3],[275,4],[280,2],[283,2],[286,2],[289,3],[293,4],[298,2],[301,3]]},"95":{"position":[[0,4],[17,5],[32,1],[38,1],[52,2],[55,4],[60,2],[63,4],[81,1],[83,4],[119,2],[125,1],[143,2],[146,3],[156,1],[158,5],[164,3],[168,3],[178,1],[184,4],[189,2],[192,3],[196,2],[208,1],[222,1],[224,3],[236,2],[250,2],[265,4],[270,2],[273,1],[275,3],[279,2],[282,5],[304,2],[313,2],[316,1],[326,1],[353,2]]},"97":{"position":[[0,5],[10,1],[12,1],[14,5],[33,2],[52,1],[66,2],[69,2],[72,2],[75,4],[80,5],[102,2],[107,2],[110,4],[132,1],[152,1],[154,2],[157,4],[166,1],[185,2],[201,2],[204,2],[207,4],[222,2],[225,2],[228,2],[231,2],[234,4],[239,1],[241,2],[255,1],[257,4],[262,3],[266,1],[268,1],[270,1],[298,1],[300,2],[313,2],[328,1],[349,1],[351,3],[355,2],[358,3],[374,1],[395,1],[400,2],[419,2],[422,1],[424,2],[427,3],[431,2],[434,1],[436,2],[439,3],[447,1],[449,2],[452,3],[456,3],[475,1],[477,4],[482,2]]},"99":{"position":[[20,1],[22,2],[25,5]]},"102":{"position":[[151,2],[224,2],[240,2],[243,3],[247,2],[250,3],[254,2],[257,4],[271,2],[282,1],[308,1],[348,1]]},"104":{"position":[[8,1],[28,1],[35,1],[37,5],[47,1],[49,5],[55,3],[59,5],[65,2],[68,3],[72,1],[86,4],[91,3],[95,2],[98,5],[113,1],[133,1],[143,2],[162,1],[170,2],[173,3],[177,3],[181,1],[189,1],[191,4],[196,3],[200,2],[207,6],[221,3],[225,3],[229,2],[232,3],[236,5],[262,1],[284,1],[311,3],[315,3],[326,1],[332,1],[334,2],[355,1],[357,2],[360,2],[370,3],[374,3],[378,2],[393,2],[400,1],[402,1],[404,2],[413,1],[421,3],[425,2],[428,2],[431,2],[450,1],[452,2],[493,3],[503,1],[505,3],[509,1],[514,1],[516,1],[543,1],[552,1],[554,6]]},"106":{"position":[[32,1],[48,1],[61,1],[79,1],[96,1],[160,4],[165,2],[168,1]]},"108":{"position":[[9,4],[14,3],[18,2],[21,4],[26,3],[30,2],[33,4],[53,2],[97,1],[99,2],[102,1],[104,4],[146,3],[150,4],[155,2],[158,2],[173,3],[177,3],[181,4],[186,3],[190,2],[193,2],[212,4],[217,3],[221,2]]},"110":{"position":[[9,1],[20,1],[31,4],[36,2],[39,3],[66,2],[85,3],[103,2],[106,3],[116,1],[118,3],[122,6],[129,3],[133,1],[141,2],[144,5],[150,1],[152,3],[156,1],[163,2],[166,3],[170,2],[173,2],[176,5]]},"112":{"position":[[0,2],[36,6],[53,1],[55,2],[67,1],[69,2],[72,4],[77,2],[87,2],[105,1],[107,2],[110,3],[114,2],[117,4],[122,3],[126,2],[129,5],[135,1],[147,1],[149,2],[152,6],[159,3],[163,3],[167,3],[171,1],[173,2],[191,1],[193,5],[236,1],[238,4],[252,1],[254,6],[274,1],[276,3],[280,4],[285,5],[291,2],[294,4],[299,4],[304,4],[309,4],[314,2],[317,2],[320,8],[329,4],[334,5],[340,3],[356,3],[360,2],[379,4],[384,5],[390,1],[392,5],[398,3],[402,2],[405,6],[419,2],[422,4],[427,5],[433,1],[435,3],[439,3],[443,1],[445,1],[447,3],[469,1],[471,2],[474,6],[508,1],[510,2],[531,1],[537,1],[539,1],[541,5],[547,2]]},"114":{"position":[[0,1],[27,1],[29,3],[33,2],[36,2],[39,3],[43,3],[47,2],[334,1],[336,4],[341,3],[345,3],[349,1],[351,3],[359,1],[361,5],[367,3],[375,2],[378,3],[382,2],[385,4],[397,1],[403,2],[406,2],[409,1],[411,2],[418,1],[420,4],[425,3],[429,3],[433,1],[435,3],[439,2],[442,3]]},"116":{"position":[[4,1],[6,4],[11,4],[16,2],[19,4],[24,2],[51,1],[53,5],[83,3],[87,2],[90,3],[94,3],[98,2],[101,4],[106,3],[110,3],[114,5],[120,3],[124,3],[128,2],[131,3],[135,4],[140,2],[158,2],[161,5],[179,3],[183,3],[187,3],[204,6],[224,2],[227,5],[233,1],[245,1],[259,1],[285,3],[289,2],[292,1],[303,1],[309,1],[336,1],[345,1],[354,1],[356,4],[372,1],[374,2],[377,2],[380,1],[391,1],[412,3],[427,1],[448,1],[471,1],[473,2],[476,2],[479,1],[481,3],[485,2],[488,3],[492,3],[496,3],[500,1],[502,3],[525,1],[527,2],[530,1],[538,2],[541,5],[547,1],[549,2],[552,3],[556,1],[563,1],[579,1],[581,2],[597,3],[616,2],[619,2],[622,3],[626,3],[630,2],[633,4],[638,2],[658,1],[660,4],[677,1],[679,2],[682,2],[685,2],[688,1],[709,1],[715,1],[733,1],[735,2],[738,2],[747,1],[769,3],[792,3],[796,1],[802,1],[804,2],[827,1],[829,3],[833,3],[837,2],[840,1],[855,2],[858,3],[862,3],[866,3],[870,4],[875,3],[889,2],[892,1],[894,2],[929,1],[931,3],[935,4],[940,2],[943,4],[948,3],[952,5],[958,4],[963,2]]},"118":{"position":[[9,2],[29,1],[31,2],[34,3],[43,3],[59,2],[75,1],[77,5],[104,2],[124,1],[126,2],[138,3],[151,2],[160,3],[164,2],[187,3],[194,3]]},"120":{"position":[[6,2],[9,4],[44,1],[46,4],[51,2],[54,3],[58,4],[72,2],[75,4],[80,2],[103,1],[105,2],[108,1],[110,6],[127,2],[130,1],[132,2],[135,2],[138,3],[152,2],[155,2],[182,3],[190,1],[192,3],[196,3],[200,3],[220,1],[222,1],[224,3],[252,2],[255,1],[261,1],[272,2],[275,2],[278,2],[281,2]]},"122":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"124":{"position":[[4,3],[8,2],[11,2],[14,3],[18,6],[25,3],[29,1],[31,3],[51,4],[56,2],[59,3],[63,4],[68,2],[71,2],[86,1],[88,2],[91,5],[111,1],[113,4],[118,3],[122,2],[125,3],[145,1],[147,3],[151,2],[159,2],[162,3],[194,3],[198,5],[204,3],[208,1],[210,3],[214,3],[218,3],[235,1],[248,1],[250,2],[253,3],[257,3],[261,3],[265,2],[273,1],[335,1],[354,1],[356,2],[359,1],[361,2],[369,1],[371,3],[375,3],[379,1],[381,3],[385,3],[399,1],[416,1],[418,5],[424,2],[432,1],[434,6],[441,2],[444,2],[447,2],[450,5],[456,2],[464,1],[466,2],[483,2],[486,3],[490,6],[497,2],[505,1],[507,2],[510,3],[527,1],[546,2],[549,4],[554,3],[558,3],[569,1],[571,4],[576,2],[584,1],[593,1],[595,5],[601,3],[605,3],[614,2],[617,1],[619,3],[623,4],[628,3],[632,2],[635,3],[639,4]]},"126":{"position":[[0,3],[9,1],[11,3],[15,1],[17,2],[20,2],[23,4],[28,4],[33,2],[36,2],[39,5],[45,3],[49,5],[55,2],[58,4],[75,1],[77,3],[81,1],[83,2],[86,3],[90,5],[96,2],[99,2],[102,2],[105,1],[107,2],[115,2],[118,2],[121,5],[127,6],[134,3],[138,2],[141,3],[145,3],[166,2],[169,4],[174,5],[180,5],[186,3],[190,3],[194,3],[198,3],[207,2],[210,3],[238,2],[241,3],[245,1],[247,2],[250,5],[256,2],[276,2],[305,2],[324,3],[328,2],[331,5],[337,4],[363,2],[366,4],[371,2],[374,3],[378,1],[380,3],[384,4],[406,1],[458,1],[512,1],[524,3],[528,3],[538,2],[541,2],[544,2],[547,3],[551,5],[571,1],[573,5],[579,2],[582,2],[592,1],[594,4],[599,3],[603,2],[606,4],[611,1],[627,3],[631,5],[642,2],[668,3],[672,5],[683,2],[686,3],[702,1],[704,3],[708,2],[711,3],[715,2],[718,4],[723,2],[726,2],[729,3],[733,1],[740,1],[742,5],[748,2],[751,7],[769,1],[771,3],[775,3],[779,5],[785,1],[787,1],[789,3],[793,4],[798,3],[802,1],[804,2],[807,2],[810,2],[818,1],[820,2],[851,1],[853,4],[858,3],[862,5],[868,1],[870,2],[970,3],[974,2],[977,1],[984,2],[1011,1],[1013,4],[1018,3],[1022,5],[1028,3],[1052,1],[1070,1],[1072,2],[1075,2],[1078,5],[1084,5],[1090,2],[1098,1],[1100,4],[1105,4],[1124,4],[1136,1],[1138,4],[1148,1],[1150,5],[1172,1],[1181,1],[1183,6],[1190,4],[1195,3],[1216,2],[1219,2],[1227,1],[1236,1],[1238,5]]},"128":{"position":[[0,3],[25,1],[45,1],[59,1],[61,3],[65,1],[67,3],[85,1],[87,4],[97,1],[99,3],[103,6],[110,3],[114,2],[119,2],[127,1],[129,3],[133,3]]},"130":{"position":[[0,2],[3,2],[11,1],[13,2],[16,2],[26,1],[28,4],[50,1],[102,1],[156,1],[185,1],[226,2],[229,2],[232,3],[241,1],[243,2],[246,3],[250,3],[254,3],[258,2],[261,2],[264,5],[284,1],[286,5],[292,2],[295,2],[298,3],[302,4],[307,3],[311,3],[326,1],[335,1],[355,1],[385,2],[388,2],[391,5],[397,1],[399,5],[424,1],[426,5],[449,1],[458,1],[460,3],[464,3],[468,4],[473,5],[511,1],[532,1],[534,4],[539,3],[543,3],[558,2],[561,3],[565,2],[568,1],[570,3],[574,1],[576,2],[586,1],[686,1],[688,2],[693,2],[711,1],[713,3],[717,1],[719,2],[738,1],[740,2],[743,4],[748,4],[753,3],[757,4],[762,4],[767,3],[771,3],[775,1],[777,3],[803,2],[806,3],[810,3],[814,3],[818,2],[835,1],[837,4],[850,1],[852,2],[855,2],[858,5],[864,4],[869,3],[873,3],[877,4],[882,4],[887,3],[899,1],[901,4],[906,3],[910,3],[914,3],[918,4],[923,4],[928,3],[932,2],[935,3],[939,2],[942,4],[947,4],[952,2],[955,3],[959,5],[965,2],[976,1],[978,4],[983,1],[993,1],[995,4],[1000,4],[1005,2],[1008,5],[1014,2],[1017,3],[1021,4],[1026,4],[1031,3],[1035,3],[1059,3],[1063,2],[1066,5],[1072,4],[1077,4],[1082,3],[1086,3],[1090,4],[1104,1],[1106,2],[1118,1],[1120,4],[1345,1],[1347,3],[1351,1],[1370,3],[1389,3],[1393,2],[1396,2],[1399,2],[1402,3],[1406,3],[1410,3],[1414,1],[1416,4],[1421,4],[1426,2],[1429,3],[1433,3],[1437,4],[1442,2],[1445,2],[1457,1],[1459,3],[1463,2],[1466,3],[1470,2],[1473,3],[1477,3],[1481,2],[1484,2],[1505,2],[1508,2],[1537,1],[1539,4],[1544,3],[1556,1],[1569,1],[1571,2],[1574,2],[1577,1],[1579,2],[1587,1],[1589,2],[1592,3],[1596,2],[1610,1],[1612,4]]},"132":{"position":[[0,3],[4,3],[20,1],[38,1],[40,4],[45,3],[49,2],[52,5],[58,5],[64,3],[82,1],[101,1],[103,2],[122,5],[128,5],[148,1],[150,2],[153,2],[156,1],[180,2],[183,2],[186,3],[211,1],[233,2],[236,3],[240,4],[245,2],[248,2],[280,2],[283,4],[288,3],[292,3],[296,5],[302,2],[305,3],[309,4],[335,1],[337,4],[342,2],[345,2],[360,1],[362,2],[365,2],[368,2],[371,5],[377,5],[383,2],[386,4],[391,7],[399,6],[406,2],[431,2],[434,4],[452,1],[454,5],[460,4],[465,2],[468,3],[472,3],[488,1],[490,4],[495,3],[499,2],[507,1],[509,3],[520,1],[522,5],[528,3],[532,2],[535,3],[546,1],[548,3],[559,1],[561,3],[565,4],[570,6],[593,3],[597,4],[602,4],[607,3],[618,2],[621,3],[638,1],[640,5],[646,5],[652,2],[655,3],[666,1],[668,4],[673,6],[680,4],[685,3],[689,4],[694,4],[699,3],[703,2],[706,3],[710,4],[715,2],[718,3],[722,4],[727,3],[742,1],[744,5],[750,4],[903,1],[921,1],[927,1],[929,3],[933,3],[937,2],[945,5],[951,3],[959,1],[961,2],[964,3],[975,3],[988,1],[992,2],[995,4],[1005,1],[1007,4],[1012,3],[1016,3]]},"134":{"position":[[0,1],[7,1],[24,2],[27,2],[30,4],[35,4],[40,1],[42,2],[45,4],[55,1],[57,4],[62,4],[67,3],[71,3],[75,1],[77,3]]},"136":{"position":[[0,2],[3,2],[11,2],[14,3],[39,3],[51,1],[53,2],[56,1],[58,4],[63,2],[66,2],[77,3],[86,4],[91,2],[94,3],[98,2],[101,1],[103,3],[107,1],[109,3],[113,5],[119,2],[122,6],[148,1],[150,3],[154,4],[159,2],[162,2],[165,4],[170,5],[176,1],[178,2],[181,4],[186,3],[190,1],[192,3]]},"138":{"position":[[0,1],[2,5],[8,2],[16,1],[18,2],[32,1],[34,2],[37,4],[42,6],[49,1],[56,1],[58,3],[81,1],[83,5],[89,3],[93,4],[113,3],[117,5],[123,1],[125,3],[129,1],[136,1],[138,2],[146,1],[157,1],[159,3],[163,1],[165,3],[169,2],[183,1],[194,1],[196,3],[210,1],[212,3],[216,1],[218,3],[234,1],[238,2],[241,2],[244,1],[246,3],[250,5],[256,1],[258,4],[282,1],[284,4],[289,4],[294,2],[310,3],[314,5],[332,1],[347,1],[349,1],[356,1],[358,2],[361,2],[364,2],[377,1],[379,4],[384,3],[388,2],[391,4],[396,5],[402,3],[406,1],[408,2],[411,3],[420,1],[422,4],[434,3],[438,5],[449,3],[453,6],[460,3],[464,2],[472,1],[474,2],[477,4],[492,1],[494,5],[509,1],[521,1],[523,5],[529,2],[537,1],[539,2],[549,1],[551,2],[554,3],[558,5]]},"140":{"position":[[0,3],[4,2],[7,3],[11,2],[14,1],[23,1],[25,3],[29,3],[44,3],[97,1],[99,3],[103,3],[107,6],[131,1],[133,4],[138,3],[154,1],[156,2],[159,2],[162,2],[165,2],[168,5],[174,3],[178,5],[184,1],[191,1],[193,2],[196,3],[200,4],[205,1],[207,3],[211,2],[214,2],[222,1],[224,2],[227,4],[232,4],[237,2],[240,2],[263,1],[265,3],[269,2],[272,2],[275,5],[281,3],[303,4],[308,2],[311,1],[318,1],[320,5],[326,1],[333,1],[335,2],[338,4],[343,2],[346,3],[350,3],[354,3],[358,3],[377,1],[379,3],[383,4],[390,1],[392,3],[402,1],[404,4],[409,2],[412,3],[416,3],[420,3],[424,3],[428,2],[431,3],[448,2],[464,1],[466,4],[493,1],[495,1],[505,1],[507,4],[512,2],[515,3],[530,1],[532,3],[547,1],[549,5],[555,3],[559,4],[564,4],[569,3],[595,1],[597,2],[600,4],[605,2],[608,1],[610,3],[614,4],[619,3],[623,3],[645,1],[647,5],[658,1],[660,4],[665,3],[688,1],[690,2],[693,2],[696,4],[701,5],[707,4],[731,1],[742,1],[744,3],[748,2],[751,3],[755,5],[774,2],[788,1],[790,3],[809,1],[811,2],[819,1],[821,4]]},"143":{"position":[[5,3],[9,4],[17,3],[21,4],[26,4],[52,2],[55,3],[59,2],[62,1],[64,6],[80,1],[82,5],[88,2],[91,5],[97,4],[122,1],[124,2],[155,1],[157,2],[195,1],[197,2],[210,3],[227,1],[229,5],[235,2],[238,2],[249,1],[251,3],[290,1],[328,5],[334,1],[336,3],[340,1],[347,5],[353,3],[357,3],[361,4],[366,3],[388,2],[408,1],[410,3],[436,1],[438,5],[449,1],[451,5],[457,3],[466,1],[468,1],[470,3],[474,2],[477,3],[481,3],[485,2],[493,3],[497,2],[504,3],[508,2],[511,3],[531,1],[569,1],[619,1],[643,2],[646,3],[650,3],[658,3],[670,3],[674,3],[687,1],[700,1],[710,2],[723,3]]},"145":{"position":[[8,1],[10,2],[13,2],[16,1],[40,1],[42,5],[48,2],[51,1],[65,3],[69,4],[74,3],[78,4],[83,2],[94,3],[98,2],[101,3],[105,3],[109,2],[112,4],[117,2],[120,5],[126,3],[130,2],[133,3],[137,4],[142,2],[145,2],[148,2],[151,3],[155,3],[159,2],[178,1],[180,5]]},"147":{"position":[[8,1],[10,2],[13,3],[21,1],[23,5],[29,4],[34,2],[37,1],[39,2],[42,3],[46,5],[52,5],[58,3],[62,4],[67,4],[72,2],[75,5],[81,2],[84,5],[90,6],[97,1],[99,3],[103,5],[109,4],[114,2],[124,1],[126,3],[144,1],[146,5],[152,1],[154,2],[161,4],[166,4],[171,4],[176,5],[186,3],[190,3],[194,2],[197,5],[203,2],[206,5],[212,3],[220,3],[224,3],[228,2],[231,3],[235,4],[240,3],[244,2],[247,2],[250,3],[254,1],[261,4],[270,3],[274,5],[280,2],[283,3],[287,3],[291,2],[294,2],[297,2],[300,5],[306,2],[309,2],[312,4],[324,1],[342,1],[344,4],[349,4],[369,3],[373,3],[377,3],[381,1],[383,4],[388,2],[391,4],[411,1],[413,4],[418,1],[420,4],[425,5],[439,3],[443,2],[446,6],[460,1],[462,3],[466,7],[484,3],[488,1],[490,6],[497,1],[499,3],[503,4]]},"149":{"position":[[0,3],[20,1],[22,4],[27,4],[46,2],[49,2],[52,1],[54,5],[60,2],[63,3],[67,1],[76,2],[103,1],[105,2],[108,4],[113,2],[116,3],[120,1],[129,2],[155,1],[157,2],[160,5],[166,1],[175,1],[177,3],[194,1],[196,1],[198,1],[200,3],[204,5],[210,2],[213,3],[222,1],[224,5],[230,2],[233,1],[254,3],[258,1],[265,2],[268,3],[272,3],[276,3],[280,3],[284,4],[289,4],[294,3],[298,1],[305,3],[309,4],[314,3],[337,2],[340,3],[344,2],[347,2],[350,3],[354,4],[359,2],[362,3],[366,5],[372,2],[375,2],[378,2],[381,3],[385,2],[388,2],[407,1],[409,5],[415,1],[417,1],[419,4],[424,6],[434,1],[436,1],[438,3],[442,3],[446,7],[458,2],[463,5],[469,3],[477,1],[479,4],[484,2],[487,2],[490,3],[494,3],[505,4],[510,2],[513,3],[517,3],[521,2],[524,3],[528,3],[541,3],[545,3],[549,5],[555,5]]},"151":{"position":[[58,1],[79,2],[110,1],[128,1],[130,5],[136,3],[147,1],[149,2],[152,1],[154,2],[157,3],[166,1],[168,4],[180,3],[184,3]]},"153":{"position":[[17,1],[19,2],[46,1],[61,1],[63,2],[66,3],[97,1],[104,1],[106,5],[125,1],[132,1],[134,2],[150,1],[176,1],[183,1],[185,4],[194,2],[221,2],[224,4],[234,1],[236,2],[239,3],[243,5],[249,7],[257,4],[262,1],[278,4],[283,2],[286,3],[295,1],[297,4],[302,2],[305,4],[310,3],[314,3],[318,3],[322,3],[326,3],[330,3],[344,1],[359,1],[361,4],[379,1],[390,1],[392,4],[397,3],[401,5],[417,1],[419,1],[421,2],[424,2],[427,1],[429,1],[431,3],[435,3],[439,1],[441,4],[446,3],[463,1],[465,3],[474,2],[477,3],[481,5],[487,2],[502,1],[504,3],[518,5],[524,4],[539,5],[545,2],[559,1],[561,3],[565,3],[569,5],[575,1],[577,4],[599,1],[601,1],[603,1],[605,5],[616,1],[618,3],[634,3],[652,1],[654,5],[660,1],[662,3],[686,1],[688,2],[691,3],[695,4],[700,3],[704,2],[707,6],[714,2],[730,1],[732,2],[735,2],[738,3],[757,1],[759,4],[764,3]]},"155":{"position":[[0,1],[2,3],[8,1],[10,3],[14,2],[17,5],[23,2],[26,6],[33,1],[35,3],[39,3],[43,2],[46,3],[62,1],[64,2],[67,3],[89,4],[94,3],[98,4],[103,1],[126,3],[130,1],[137,1],[139,3],[158,1],[160,4],[186,1],[188,2],[193,2],[201,1],[203,2],[206,3],[227,2],[235,1],[237,2],[240,5],[260,1],[262,2],[265,2],[268,5],[274,3],[278,3],[282,3],[286,1],[288,4],[298,1],[300,2],[303,3],[307,3],[311,3],[315,2],[318,4],[323,3],[327,4],[332,2],[335,4],[340,2],[348,1],[350,2],[366,1],[368,4],[373,2],[376,2],[379,4],[384,4],[389,2],[392,4],[397,3],[406,1],[408,3],[412,1],[414,4],[419,3],[423,3],[427,4],[432,2],[435,2],[438,2],[441,3],[445,5],[451,1],[453,4],[477,3],[481,3],[495,1],[497,2],[524,1],[526,2],[529,5],[535,3],[539,4],[544,3],[548,2],[551,3],[555,3],[559,2],[562,3],[578,1],[580,3],[584,2],[587,5],[593,3],[597,1],[599,3],[610,1],[612,1],[619,1],[621,4],[626,3],[645,1],[647,3],[651,2],[661,2],[664,1],[666,1],[668,3],[682,2],[702,1],[726,2],[736,3],[740,5],[746,4],[758,3],[762,2],[765,1],[767,3],[771,3],[775,2],[778,3],[782,4],[787,1],[789,3],[793,2],[807,3],[811,5],[817,3],[843,1],[845,5],[867,1],[869,2],[872,2],[885,3],[889,3],[903,2],[906,3],[910,1],[912,4],[917,3],[921,2],[929,1],[953,1],[955,2],[972,3],[976,5],[982,2],[985,1],[987,1],[989,3],[993,6],[1024,1],[1026,5],[1042,3],[1046,1],[1055,1],[1057,5],[1063,2],[1066,3],[1070,1],[1072,3],[1081,1],[1083,5],[1089,5]]},"157":{"position":[[0,2],[3,5],[9,4],[14,4],[19,3],[23,3],[27,3],[31,4],[36,3],[100,1],[119,1],[121,2],[124,1],[126,2],[129,1],[136,1],[138,2],[146,7],[154,3],[158,4],[163,2],[177,3],[181,3],[185,5],[200,2],[225,3],[229,2],[232,3],[236,1],[238,3],[242,4],[247,5],[253,3],[257,2],[260,4],[265,5],[271,5],[299,1],[320,1],[322,2],[325,3],[329,3],[345,2],[348,5],[354,1],[361,2],[375,3],[389,1],[391,3],[395,3],[399,5],[405,2],[416,2],[419,3],[423,1],[425,2],[436,1],[438,5],[444,3],[448,4],[453,3],[457,3],[461,3],[465,3],[469,3],[473,5],[479,4],[484,2],[487,4],[492,4],[497,2],[500,5],[506,2],[509,3],[524,3],[528,2],[531,3],[535,3],[539,5]]},"159":{"position":[[0,1],[2,5],[34,1],[48,2],[51,3],[73,1],[75,4],[80,3],[84,4],[101,1],[103,3],[107,2],[110,4],[115,2],[118,2],[121,3],[125,6],[132,5],[138,2],[141,4],[146,1],[162,1],[169,2],[172,5],[178,3],[206,1],[208,2],[211,4],[216,2],[219,5],[225,4],[230,3],[234,3],[238,1],[240,3],[264,1],[266,2],[269,3],[273,2],[276,3],[280,2],[283,1],[285,1],[287,3],[291,5],[297,1],[299,4],[304,3],[308,4],[313,2],[316,5],[322,2],[325,4],[330,3],[334,1],[336,5],[342,2],[345,3],[349,3],[353,3],[357,4],[367,1],[369,1],[371,5],[377,4],[382,2],[385,1],[387,1],[389,7],[415,1],[417,2],[432,2],[435,1],[437,1],[439,2],[442,4],[447,4],[452,1],[454,4],[459,3],[463,3],[467,2],[470,2],[473,1],[475,3],[479,4],[484,2],[487,3],[491,4],[511,4],[516,4],[521,3],[525,4],[530,2],[533,2],[536,3],[540,5],[546,2],[549,1],[551,3],[555,4],[560,5],[566,1],[568,2],[571,3],[575,4],[580,3],[612,3],[616,3],[620,5],[626,1],[628,5],[634,2],[637,2],[640,3],[644,3],[648,2],[651,2],[654,3],[658,5],[664,3],[668,2],[671,3],[675,3],[679,4],[684,2],[687,4],[692,3],[696,3],[700,5],[706,2],[709,4],[727,1],[729,3],[740,1],[742,4],[747,5],[753,3],[757,1],[759,3],[763,3],[767,3],[771,3],[775,1],[777,2],[789,1],[791,2],[808,2],[811,5],[839,2],[842,3],[846,3],[850,3],[854,1],[856,3],[860,2],[863,6],[870,2],[873,4],[878,3],[882,1],[884,2],[887,3],[891,4],[896,1],[903,2],[906,3],[910,3],[914,6],[921,4],[926,2],[929,1],[931,3],[935,6],[942,3],[946,3],[955,2],[958,4],[963,3],[967,6],[974,2],[977,2],[980,4],[985,5],[991,2],[994,3],[998,3],[1002,1],[1004,3],[1008,2],[1011,3]]},"161":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"163":{"position":[[0,2],[19,3],[35,3],[39,3],[43,2],[46,3],[50,3],[54,5],[60,2],[71,1],[73,3],[77,1],[79,5],[85,4],[106,1],[108,2],[119,1],[121,2],[124,2],[127,5],[133,5],[139,4],[144,4],[149,2],[152,3],[171,3],[175,4],[180,2],[183,1],[185,2],[188,3],[192,5],[198,2],[201,3],[220,1],[222,3],[234,1],[236,5],[259,1],[261,5],[267,3],[287,2],[290,3],[294,3],[298,1],[300,3],[304,5],[310,2],[316,2],[319,5],[333,1],[340,1],[342,3],[346,4],[351,3],[355,2],[370,1],[390,3],[394,2],[397,3]]},"165":{"position":[[12,1],[14,3],[18,3],[22,3],[26,3],[30,2],[33,3],[37,3],[41,4],[46,3],[50,2],[53,3],[57,1],[59,2],[62,3],[66,3],[70,3],[90,1],[136,2],[139,2],[154,3],[158,5],[212,2],[215,2],[218,3],[222,5],[228,5],[234,3],[238,3],[242,4],[247,3],[251,3],[255,5],[261,4],[266,4],[271,5],[285,2],[288,2],[291,2],[294,3],[310,1],[312,3],[316,4],[338,1],[340,5],[346,4],[351,1],[353,3],[357,2],[360,2],[363,2],[366,4],[371,4],[376,2],[379,3],[400,1],[402,5],[408,3],[412,3],[416,1],[418,3],[434,3],[438,5],[444,4],[449,5],[463,1],[465,2],[468,3],[472,2],[475,3],[479,5],[505,1],[507,2],[510,3],[531,2],[534,2],[557,3],[599,1],[660,1],[662,3],[666,3],[677,3],[681,4],[701,2],[717,1],[719,2],[722,2],[737,2],[740,4],[745,2],[766,1],[768,1],[774,1],[776,4],[781,5],[798,1],[800,5],[814,1],[820,2],[823,4],[894,2],[909,1],[911,2],[914,2],[917,3],[921,4],[926,6],[941,1],[943,2],[946,2],[949,3],[953,5],[973,1],[975,2],[978,2],[981,4],[986,2],[989,2],[992,2],[995,2],[1006,2],[1009,4],[1014,2],[1017,5],[1023,2]]},"169":{"position":[[8,1],[26,1],[46,3],[57,1],[72,1],[84,1],[147,3],[158,1],[164,1],[187,1],[206,1],[249,1],[251,2],[275,1],[277,2],[287,1],[289,3],[299,1],[310,1],[320,1],[322,2],[330,3],[334,3],[338,5],[344,3],[352,3],[356,4],[371,1],[373,3],[395,1],[406,1],[421,3],[425,3],[429,3],[433,2],[456,1],[458,5],[464,2],[482,1],[484,7],[492,2],[537,1],[556,1],[558,3],[562,3],[566,2],[569,3],[588,1],[611,1],[613,2],[637,1],[656,2],[659,2],[662,2],[686,1],[696,1],[698,5],[712,1],[714,2],[717,4],[740,2],[768,2],[787,2],[790,3],[794,2],[797,5]]},"171":{"position":[[8,1],[10,1],[12,3],[36,1],[38,5],[68,1],[79,2],[82,2],[97,5],[103,4],[108,2],[111,5],[128,1],[130,2],[133,2],[136,2],[149,1],[160,1],[179,1],[181,4],[186,2],[201,2],[204,4],[216,1],[218,2],[362,1],[364,4],[387,2],[390,1],[408,1],[420,3],[441,1],[450,1],[452,4],[457,2],[460,3],[464,5],[470,1],[472,1],[491,1],[502,2],[505,1],[507,2],[510,1],[564,1],[579,2],[591,1],[616,2],[630,1],[637,1],[653,1],[660,1],[696,1],[698,4],[703,2],[714,1],[716,3],[720,1],[722,3],[726,2],[729,4],[756,1],[773,1],[775,2],[785,3],[789,2],[792,4],[797,3],[801,3],[809,1],[811,4],[816,4],[827,1],[836,2],[853,3],[857,2],[877,1],[879,2],[882,3],[886,3],[890,2],[893,4],[898,3]]},"174":{"position":[[0,2],[18,1],[20,3],[24,4],[29,4],[52,1],[54,4],[59,2],[62,4],[67,4],[72,2],[96,1],[98,2],[101,3],[113,1],[115,2],[118,3],[122,2],[125,2],[132,1],[134,1],[136,3],[140,1],[169,2],[172,3],[176,2],[210,4],[215,4],[220,4],[225,2],[228,4],[237,2],[240,3],[260,2],[263,3],[267,4],[272,2],[275,2],[278,3],[282,4],[287,4],[302,1],[304,2],[307,1],[333,1],[335,2],[353,4],[376,4],[400,2],[403,2],[432,1],[438,1],[440,5],[464,1],[466,3],[470,3],[506,1],[508,5]]},"176":{"position":[[15,1],[17,2],[20,4],[31,2],[34,6],[58,1],[60,2],[63,2],[66,2],[69,2],[72,4],[77,3],[81,2],[84,3],[88,1],[90,3],[94,4],[99,2],[120,1],[122,5],[150,3],[162,1],[170,2],[173,2],[176,3],[180,2],[193,1],[195,2],[215,1],[232,1],[234,4],[254,3],[258,2],[261,3],[265,4],[270,2],[273,2],[297,2],[300,3],[324,1],[339,2],[342,2],[369,1],[371,2],[374,2],[398,1],[433,4],[451,1],[453,2],[456,3],[460,2],[463,2],[466,4],[471,5],[477,3],[481,1],[483,2],[486,3],[490,2],[514,1],[539,1],[541,4],[546,2],[553,1],[561,1],[563,2]]},"178":{"position":[[21,1],[23,4],[28,4],[33,2],[36,3],[40,2],[50,1],[61,2],[64,3],[68,1],[88,1],[110,1],[112,2],[139,3],[157,1],[173,4],[178,2],[181,4],[202,3],[206,2],[209,4],[214,2],[230,1],[232,5],[238,3],[248,1],[250,2],[253,4],[258,4],[263,2],[280,3],[304,1],[306,5],[330,1],[332,5],[338,2],[359,1],[361,2],[372,1],[374,3],[378,3],[382,1],[392,1],[394,4],[416,2],[441,1],[443,4],[455,1],[464,1],[475,3],[495,1],[497,5],[503,6]]},"180":{"position":[[0,3],[12,1],[25,1],[42,2],[45,4],[50,2],[53,1],[55,2],[58,3],[62,2],[65,4],[70,2],[89,5],[95,2],[98,3],[139,2],[168,1],[250,1],[272,3],[297,1],[303,4],[325,1],[327,3],[331,2],[360,6],[367,2],[370,1],[372,3],[385,3],[389,2],[392,1],[394,2],[410,1],[412,5],[418,2],[426,2],[429,5],[435,6],[442,3],[446,3],[482,1],[484,3],[488,2],[491,4],[517,2],[538,1],[540,2],[575,2],[578,4],[583,4]]},"183":{"position":[[8,4],[31,2],[38,3],[42,3],[46,3],[50,3],[63,1],[65,3],[69,1],[71,3],[90,1],[126,1],[136,1],[138,5],[144,2],[147,3],[151,2],[154,2],[157,3],[165,1],[173,1],[175,5],[181,2],[184,3],[188,2],[191,4],[196,2],[199,4],[216,1],[218,3],[222,3],[226,3],[235,1],[280,1]]},"186":{"position":[[10,4],[38,4],[95,5],[117,1],[130,1],[143,1],[145,4],[150,5],[166,2],[175,1],[188,2],[191,4],[196,3]]},"188":{"position":[[67,1],[69,3],[73,3],[77,4],[82,4],[99,1],[101,2],[104,2],[107,2],[114,1],[116,4],[138,1],[159,1],[161,3],[178,3],[182,2],[196,2],[199,2],[202,1],[204,3],[208,6],[215,5],[221,3],[225,3],[229,3],[233,5],[255,2],[258,2],[261,3],[265,2],[300,2],[318,2],[325,5],[331,2],[334,2],[337,1],[344,6],[351,4],[363,1],[365,6],[372,3],[376,3],[380,2],[388,1],[390,4],[400,1],[402,4],[407,3],[411,4],[416,2],[419,3],[423,2],[442,1],[444,5],[450,3],[454,2],[457,2],[460,3],[464,5],[470,2],[480,3],[484,2],[487,5],[493,3],[497,2],[510,3],[514,3],[518,3],[522,3],[526,1],[528,2],[531,2],[534,3],[538,3],[542,3]]},"190":{"position":[[17,3],[21,2],[24,3],[28,3],[44,2],[59,1],[61,5],[79,1],[98,1],[115,2],[118,3],[129,1],[142,1],[144,4],[149,2],[152,3],[156,3],[160,2],[163,2],[166,5],[176,1],[199,3],[203,4],[208,2],[211,3],[215,2],[218,4],[229,3],[248,1],[250,3],[254,3],[271,4],[276,5],[298,3],[310,4],[315,2],[318,2],[321,3],[325,4],[330,1],[332,1],[334,2],[337,4],[342,2],[345,3],[349,6],[356,2],[359,2],[362,2],[365,2],[368,5],[386,1],[388,5],[394,2],[407,1],[409,3],[413,5],[430,1],[454,1],[456,3],[460,2],[463,2],[466,3],[470,3],[474,4],[479,3],[483,3],[487,3],[491,3],[495,3],[499,3],[503,2],[506,2],[509,3],[513,3],[517,4],[522,4],[527,2],[530,4],[535,4],[540,2],[555,1],[557,2],[560,3],[564,4],[569,3],[573,1],[575,2],[578,3],[582,3],[586,3],[590,3],[594,2],[597,2],[600,2],[603,2],[606,4],[611,4],[616,1],[618,2],[621,3],[625,4],[630,3],[634,4],[639,2],[642,3],[646,1]]},"193":{"position":[[0,2],[22,1],[37,1],[51,2],[54,3],[76,1],[111,1],[144,1],[146,2],[149,2],[157,4],[162,3],[166,2],[169,3],[173,4]]},"195":{"position":[[23,1],[35,3],[39,5],[45,4],[62,2],[82,1],[84,5],[90,3],[94,5],[100,1],[102,2],[105,4],[110,5],[123,7],[136,3],[140,5],[153,1],[155,4],[160,3],[164,3],[168,2],[179,1],[181,3],[193,2],[196,3],[200,5]]},"197":{"position":[[9,2],[21,5],[27,2],[30,3],[34,2],[65,1],[67,2],[70,2],[81,2],[84,1],[86,5],[92,4],[117,1],[119,7],[142,1],[144,4],[149,2],[160,1],[162,3],[166,4],[180,1],[191,4],[196,2],[210,4],[215,6],[222,1],[224,2],[236,3],[240,3],[252,1],[254,3],[270,2],[282,4],[293,1],[295,4],[300,5],[310,2],[322,3],[326,2],[329,3],[333,2],[336,3],[349,2],[352,2],[355,3],[365,1],[373,1],[375,1],[377,3],[381,3],[385,2],[388,1],[390,4],[395,1],[397,2],[414,2],[433,2],[436,3],[440,1],[442,4],[447,1],[449,3],[453,2],[456,2]]},"199":{"position":[[0,3],[12,1],[14,2],[17,4],[22,3],[26,3],[30,2],[33,2],[36,3],[40,3],[44,2],[57,4],[62,1],[64,2],[67,2],[70,3],[79,3],[83,7],[91,1],[101,1],[123,1],[129,1],[131,4],[136,2],[139,5],[145,3],[161,4],[172,1],[174,5]]},"202":{"position":[[0,1],[2,3],[10,1],[12,2],[15,1],[17,2],[37,1],[39,4],[44,2],[47,3],[51,3],[55,3],[59,3],[63,1],[65,2],[85,1],[87,3],[91,1],[93,2],[96,2],[99,3],[103,2],[106,3],[110,5],[116,2],[119,4],[141,1],[143,3],[147,3],[151,4],[156,2]]},"204":{"position":[[0,1],[2,2],[9,1],[11,2],[21,1],[23,4],[28,2],[31,3],[35,2],[38,2],[41,2],[44,3],[61,1],[63,3],[73,1],[75,2],[78,5],[84,3],[88,3],[98,1],[100,4],[105,1],[107,4],[112,2],[131,1],[133,1],[135,3],[156,1],[158,5],[164,3],[168,2]]},"206":{"position":[[0,1],[2,2],[9,1],[21,1],[29,1],[31,4],[43,1],[45,4],[50,3],[54,4],[59,2],[62,2],[69,4],[74,3],[78,1],[80,2],[89,1],[91,3],[95,2],[98,4],[103,3],[107,1],[109,3],[113,5],[119,4],[124,3],[128,1],[130,4],[143,1],[145,6],[159,1],[161,4],[166,4],[171,4],[176,2],[179,3],[183,4],[188,2],[191,2],[194,3],[198,4],[214,1],[235,2],[238,1],[240,4],[245,2],[248,5],[254,2],[257,2]]},"209":{"position":[[8,3],[12,2],[30,1],[32,1],[34,3],[38,3],[42,1],[44,3],[48,2],[71,1],[89,3],[93,4],[98,3],[117,1],[119,2],[122,3],[126,4],[131,1],[151,3],[163,1],[165,5],[188,5],[194,3],[198,3],[202,3],[206,4],[211,3],[215,2],[218,4],[223,4],[228,2],[239,1],[241,1],[266,1],[268,2],[271,3],[275,3],[279,4]]},"211":{"position":[[10,3],[14,2],[32,1],[34,1],[36,3],[40,3],[44,1],[46,3],[50,3],[54,3],[58,3],[62,2],[65,5],[71,4],[90,4],[95,4],[120,2],[123,3],[127,4],[142,1],[148,1],[150,4],[155,2],[171,1],[173,2],[176,3],[196,1],[202,1],[204,3],[208,2],[211,3],[215,2],[218,3],[222,5],[228,5],[244,3],[248,3],[252,3],[256,2],[259,5]]},"213":{"position":[[0,3],[13,1],[15,3],[32,1],[46,1],[48,3],[52,3],[56,2],[80,5],[86,2],[89,3],[93,6],[100,3],[104,1],[106,4],[111,2],[124,1],[126,2],[129,2],[132,5],[138,2],[141,1],[143,6],[159,1],[161,2],[168,4],[173,2],[176,2],[179,2],[187,4],[192,3],[196,2],[215,1],[229,1],[231,2],[234,3],[238,4]]},"215":{"position":[[0,1],[2,3],[6,4],[19,1],[21,2],[24,2],[48,1],[50,5],[100,2],[103,2],[106,3],[110,4],[115,2],[118,4]]},"217":{"position":[[36,1],[38,1],[40,2],[43,4],[48,4],[53,4],[58,2],[69,1],[71,4],[76,3],[80,4],[85,3],[89,2],[92,4],[127,2],[130,3],[134,2]]},"219":{"position":[[0,2],[3,6],[20,1],[42,1],[54,1],[64,1],[66,3],[70,2],[73,3],[77,2],[80,3],[99,1],[101,7],[109,2],[112,2],[124,3],[128,2],[139,1],[141,2],[144,3],[148,4],[153,3],[157,2],[160,3],[164,3]]},"221":{"position":[[0,1],[2,3],[6,5],[20,1],[34,1],[36,1],[38,4],[43,2],[54,1],[77,1],[79,4],[84,2],[87,2],[90,3],[94,2],[97,1],[99,2],[110,1],[112,3],[116,2],[119,3],[123,3],[127,4],[146,2],[149,2],[152,2],[155,4],[168,1],[170,3],[174,2],[185,1],[187,4],[192,4],[197,2],[200,3],[204,3]]},"223":{"position":[[8,1],[10,2],[21,1],[23,2],[26,1],[28,2],[31,1],[33,4],[38,3],[46,3],[50,6],[81,1],[83,3],[87,2],[90,4],[95,3],[99,2],[119,1],[121,4],[126,4],[131,3],[135,4],[140,2],[143,4],[148,4],[153,1],[155,2],[158,3],[162,4],[167,3],[171,3],[175,3],[179,3]]},"225":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"227":{"position":[[17,1],[47,1],[56,1],[58,4],[67,1],[87,3],[91,2],[94,4],[99,2],[102,2],[132,2],[135,3],[139,3],[143,2],[156,3],[160,5],[166,4],[171,2],[174,2],[185,1],[187,2],[214,1],[240,1],[242,2],[245,2],[263,1],[265,3],[269,1],[271,2],[291,1],[303,1],[315,1],[317,3],[339,1],[347,6],[359,2],[363,1],[381,2]]},"229":{"position":[[0,3],[7,1],[9,2],[12,3],[16,2],[19,1],[21,2],[24,4],[29,4],[34,2],[37,3],[41,3],[45,3],[49,2],[52,4],[57,2],[60,5],[90,1],[111,2],[114,3],[123,2],[126,2],[129,3],[133,2],[136,1],[138,3],[142,1],[144,2],[147,5],[153,3],[157,4],[166,1],[178,3],[182,2],[206,3],[223,1],[225,4],[230,3],[234,4],[239,3],[243,2],[246,1],[248,2],[251,4],[256,2],[259,2],[279,1],[292,2],[314,1],[316,3],[320,2],[323,2],[326,2],[329,2],[332,2],[350,3],[354,2],[361,1],[373,1],[375,2],[407,1],[409,4],[414,3],[418,2],[430,2],[433,3],[451,1],[464,2],[467,3],[497,1],[499,4],[504,3],[517,2],[520,1],[522,1],[524,5],[530,2],[533,2],[536,2],[539,2],[542,2],[574,1],[587,1],[589,2],[592,4],[597,4],[602,4],[607,2],[610,3],[627,2],[630,2],[633,4],[638,3],[642,1],[663,1],[665,3],[669,2],[672,3],[676,5],[682,3],[686,2],[689,3],[693,3],[697,2],[700,3],[704,4],[709,2],[712,2],[715,4],[720,2],[723,5],[763,1],[765,3],[769,3],[792,1],[809,1],[811,2],[814,3],[818,2],[830,1],[859,3],[863,4],[892,1],[913,5],[919,4],[943,1],[945,2],[966,1],[974,1],[976,3],[984,1],[986,3],[1000,1],[1021,1],[1023,1],[1025,3],[1029,4],[1039,2],[1063,1],[1065,3],[1069,4],[1074,3],[1078,2],[1081,3],[1109,1],[1111,4],[1116,2],[1119,2],[1122,2],[1130,1],[1132,5],[1138,1],[1140,2],[1143,3],[1147,5],[1153,1],[1155,3],[1159,3],[1167,1],[1182,1],[1189,1],[1191,3],[1195,1],[1197,3],[1201,2],[1204,4],[1209,5]]},"231":{"position":[[0,3],[4,2],[12,1],[43,1],[45,6],[52,5],[58,3],[81,1],[83,4],[88,2],[91,2],[94,1],[109,1],[111,5],[117,3],[121,3],[125,1],[127,2],[130,3],[138,1],[168,1],[170,4],[179,1],[181,3],[185,1],[187,3],[191,2],[194,5],[207,3],[215,1],[228,1],[248,2],[251,3],[255,1],[257,4],[262,1],[264,2],[267,2],[270,3],[274,3],[278,3],[282,4],[287,2],[290,2],[297,1],[299,3],[303,3],[307,2],[310,4],[315,2],[318,3],[322,4],[327,3],[331,2],[334,1],[336,3],[340,2],[343,3],[347,2],[350,2],[353,2],[360,3],[388,1],[409,2],[417,1],[419,2],[422,2],[429,3],[437,1],[458,3],[462,3],[466,4],[488,1],[490,2],[493,2],[496,2]]},"233":{"position":[[3,1],[26,3],[30,2],[51,1],[67,1],[69,4],[74,2],[82,3],[111,4],[116,2],[126,2]]},"236":{"position":[[6,1],[33,1],[35,3],[39,3],[68,1],[70,3],[98,1],[130,1]]},"238":{"position":[[6,1],[8,3],[30,1],[43,3],[47,2]]},"240":{"position":[[0,3],[13,1],[34,1],[36,1],[48,1],[50,3],[54,3],[62,1],[64,4],[69,1],[71,2],[74,5],[91,3],[95,5],[101,3],[128,1],[130,2],[133,2],[142,4],[166,1],[168,3],[172,5],[178,2],[188,1],[190,3],[199,1],[216,5],[235,1],[246,1],[248,2]]},"242":{"position":[[8,2],[111,1],[113,3],[133,2],[136,3],[146,1],[148,3],[152,1],[159,1],[161,2],[164,2],[167,4],[172,2],[184,3],[188,2],[200,2],[203,2],[206,1],[208,2],[216,2],[219,1],[221,3],[225,3],[229,2],[232,4],[237,3],[241,2],[260,2]]},"244":{"position":[[14,1],[28,1],[30,3],[34,2],[37,2],[40,2],[43,3],[47,1],[54,3],[58,3],[62,2],[65,3],[69,2],[72,2],[75,2],[78,2],[81,4],[86,5],[92,5],[98,4],[107,2],[124,1],[126,1],[128,3],[132,4],[137,1],[139,1],[141,2],[144,2],[163,3],[167,2],[170,2],[173,8],[186,1],[193,2],[200,2],[203,3],[207,1],[209,1],[211,2],[214,2],[217,3],[221,2],[224,3],[228,3],[232,3],[242,1],[244,3],[248,2],[251,3],[255,6],[262,2],[265,2],[272,1],[274,2],[291,1],[313,1],[326,1],[328,2],[331,2],[344,1],[350,1],[352,4],[357,2],[365,1],[372,2],[389,1],[391,3],[395,1],[397,1],[399,4],[404,2],[413,1],[415,2],[429,2],[432,3],[440,1],[442,4],[447,2],[454,3],[458,3],[462,3],[470,1],[476,4],[481,2],[484,3],[488,1],[490,5],[496,3],[500,2],[503,3],[507,2],[510,3],[514,3],[518,3],[522,3],[531,3],[535,3],[539,2],[551,2],[554,3],[558,3],[572,3],[576,4],[581,1],[583,3],[591,1],[602,2],[605,1],[607,2],[610,2],[613,3],[617,1],[619,3],[623,2]]},"246":{"position":[[14,1],[16,3],[20,2],[23,3],[37,3],[41,2],[44,1],[46,4],[60,2],[63,2]]},"248":{"position":[[14,1],[16,4],[21,2],[24,1],[26,3],[30,3],[34,3],[38,3],[42,4],[47,3],[51,3],[55,2],[58,2],[61,1],[63,3],[67,3],[71,4],[76,4],[87,1],[89,2],[116,1],[124,1],[126,1],[128,3],[132,2],[135,2],[138,2],[141,2],[144,4],[153,1],[155,2],[158,3],[162,2],[165,4],[170,4],[175,3],[179,2],[191,1],[218,1],[220,3],[224,4],[229,3],[233,3],[237,1],[239,2],[266,1],[268,3],[272,1]]},"250":{"position":[[10,1],[12,3],[16,3],[20,1],[22,2],[25,2],[56,5],[62,4],[67,1],[69,1],[71,2],[74,3],[78,3],[86,1],[88,3],[92,3],[96,5],[102,2],[105,3],[109,3],[113,3],[117,2],[120,2],[123,3],[127,4],[132,4],[137,5],[143,2],[155,1],[157,3],[161,3],[165,4],[192,4],[201,1],[203,2],[206,3],[210,4],[234,1],[236,4],[241,1],[243,4],[248,2],[251,3],[255,2]]},"252":{"position":[[14,1],[16,2],[19,3],[23,3],[40,1],[42,2],[45,3],[49,1],[51,1],[53,5],[59,2],[62,1],[64,2],[67,4],[86,1],[88,4],[93,4],[98,3],[102,1],[104,4],[109,3],[113,2],[116,3],[120,2],[123,2],[130,1],[132,4],[137,2],[140,3],[144,2],[156,1],[158,3],[162,3],[166,4],[175,2],[178,3],[182,3],[196,3],[200,4],[205,5],[211,1],[213,2]]},"254":{"position":[[0,2],[3,2],[17,1],[19,3],[27,1],[29,2],[43,1],[45,2],[62,1],[64,2],[67,3],[90,1],[107,1],[111,1],[113,5],[123,3],[129,1],[131,2],[138,2],[141,1],[143,3],[151,1],[153,2],[206,1],[208,3],[212,2],[215,2],[224,1],[237,1],[245,1],[253,2],[256,3],[275,3],[279,3],[283,4],[297,2],[300,2],[303,2],[310,1],[312,4],[317,3],[321,2],[324,4],[329,4],[334,3],[338,2],[355,1],[357,3],[371,2],[374,1],[376,5],[382,3],[386,2],[395,4],[403,2],[408,2],[411,2],[420,1],[436,1],[438,4],[443,3],[456,1],[458,3],[462,3],[466,3],[489,2],[492,2],[495,2],[498,2],[512,5],[518,3],[527,3],[534,1],[536,2],[550,4],[576,1],[578,2],[595,1],[597,2],[610,1],[612,4],[624,3],[628,2],[631,2]]},"257":{"position":[[5,2],[8,3],[12,3],[16,3],[20,3],[24,2],[27,3],[31,2],[55,2],[58,3],[62,2],[75,1],[77,1],[79,2],[82,2],[85,3],[108,1],[110,3],[114,4],[119,2],[122,2],[146,1],[148,3],[152,2],[155,3],[159,4],[164,5],[170,2],[180,2],[183,2],[186,3],[190,2]]},"259":{"position":[[5,1],[18,2],[21,3],[25,3],[29,4],[55,1],[57,4],[62,2],[65,4],[70,2],[88,1],[90,2],[93,2],[96,4],[101,3],[109,3],[134,1],[136,2],[146,2],[149,5],[166,1],[168,4],[173,4],[182,2]]},"261":{"position":[[0,2],[8,1],[10,3],[14,2],[17,3],[21,3],[25,3],[48,2],[51,5],[71,1],[73,1],[75,1],[77,3],[81,3],[85,1],[87,3],[102,1],[104,3],[122,1],[124,3],[128,2],[131,3],[135,3],[139,3],[143,3],[147,2],[155,1],[157,4],[162,2],[165,3],[169,2],[172,1],[174,3],[178,2]]},"263":{"position":[[14,1],[47,1],[49,3],[53,2],[56,4],[61,2],[64,1],[66,1],[68,2],[71,3],[75,2],[78,4],[83,6],[90,3],[94,2],[97,2],[100,3]]},"265":{"position":[[0,2],[3,1],[14,1],[16,2]]},"267":{"position":[[0,4],[5,4],[10,3],[14,3],[18,3],[22,5],[28,4],[57,1],[65,1],[67,2],[70,4],[75,3],[79,2],[82,2],[85,2],[88,3],[118,2],[121,2],[130,3],[134,3],[138,4],[143,2],[146,2],[149,2]]},"269":{"position":[[0,4],[5,3],[9,4],[14,3],[18,2],[21,3],[25,3],[29,3],[33,4],[38,3],[42,2],[45,3],[55,4],[60,6],[74,1],[76,3],[80,6],[95,1],[97,3],[101,3],[105,3],[109,6],[116,3],[120,3],[124,7],[132,1],[134,6],[167,1],[169,3],[173,3],[180,4],[185,3],[189,3],[196,1],[201,3],[205,3],[209,2],[212,5],[218,2],[231,3],[235,3],[239,3],[243,5],[256,3],[266,3],[280,1],[296,1],[298,2],[306,3],[310,2],[313,2],[329,1],[331,3],[354,1],[356,4],[372,1],[374,2],[397,3],[420,1],[422,1],[429,4],[434,3],[438,3],[446,1],[448,4],[460,1],[462,4],[467,3],[471,3],[478,3],[496,1],[498,4],[503,4],[508,2]]},"271":{"position":[[0,3],[15,1],[17,4],[22,3],[26,5],[46,1],[48,2],[72,2],[75,1],[77,2],[80,2],[83,2],[86,3],[115,1],[124,1],[126,2],[141,5],[161,1],[163,3],[167,5],[173,4],[178,1],[180,2],[192,5],[202,4],[207,1],[209,4],[214,4],[219,2],[222,1],[224,3],[242,2],[264,1],[286,1],[288,2],[306,3],[324,1],[362,1],[368,1],[370,1],[372,3],[376,1],[378,2],[386,3],[390,2],[393,3],[397,2],[400,4],[405,2],[412,1],[414,3],[430,1],[432,4],[455,1],[461,2],[464,3],[468,3],[472,6],[490,1],[492,3],[496,2],[499,1],[501,1],[503,2],[506,3],[525,1],[527,3],[531,1],[533,3],[537,3],[541,7],[549,2],[552,2],[555,2],[558,2],[565,3],[583,1],[585,5],[591,2],[594,5],[600,3],[604,1],[606,1],[608,2],[611,1],[613,2],[616,5],[626,1],[628,4],[633,2],[636,2]]},"273":{"position":[[0,1],[2,3],[6,2],[9,3],[13,2],[16,1],[18,2],[21,3],[25,4],[30,3],[34,2],[47,3],[51,2],[72,1],[74,2],[176,2],[179,4],[197,2],[200,4],[205,2],[208,3],[212,2],[284,1],[286,4],[291,5],[297,3],[301,4],[316,3],[320,5],[326,3],[330,3],[334,2],[337,3],[341,3],[349,1],[351,4],[356,3],[360,2]]},"275":{"position":[[14,1],[19,2],[32,3],[36,4],[41,5],[47,2],[50,3],[54,3],[58,2],[85,1],[96,3],[114,1],[116,2],[119,3],[123,3],[127,5],[147,1],[149,3],[153,1],[158,1],[175,3],[179,3],[203,1],[205,3],[209,2],[212,1],[214,5],[220,2],[223,3],[241,3],[245,3],[249,2],[252,2]]},"277":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"279":{"position":[[28,1],[30,3],[39,1],[41,2],[54,4],[59,5],[107,1],[109,6],[116,3],[120,3],[124,3],[132,1],[138,2],[161,1],[179,5],[201,1],[214,3],[218,2],[221,3],[225,1],[227,4],[232,4],[237,2],[240,2],[243,3],[247,3],[251,2],[254,4],[259,2],[262,3],[274,1],[276,5],[286,1],[299,2],[302,2],[324,1],[326,3],[330,1],[332,3],[357,1],[370,1],[372,5],[397,1],[399,4],[404,3],[408,3],[440,3],[444,3],[448,2],[451,4],[467,1],[469,5],[483,1],[485,2],[496,1],[498,5],[524,1],[526,3],[530,4],[535,5],[541,3],[545,3],[549,3],[559,2],[571,2],[579,3],[583,3],[595,2],[607,4],[612,2],[619,2],[622,3],[626,3],[634,3],[638,2],[645,1],[647,2],[650,3],[654,4],[669,1],[671,2],[696,2],[704,1],[717,1],[719,4],[724,4],[729,3],[750,1],[752,5],[758,5],[764,3],[768,4],[773,3],[844,2],[847,2],[850,5]]},"281":{"position":[[4,1],[6,3],[10,3],[14,3],[39,3],[43,3],[51,5],[57,6],[64,3],[68,3],[72,4],[77,3],[81,3],[85,3],[89,6],[96,3],[100,3],[104,2],[107,2],[110,5],[116,3],[120,3],[124,3],[128,3],[132,2],[135,3],[139,2],[146,4],[151,3],[155,2],[158,4],[163,2],[166,3],[170,4],[175,4],[180,1],[182,4],[187,2],[190,5],[239,1],[241,3],[245,2],[248,2],[265,3],[269,5],[275,1],[277,1],[279,4],[284,3],[292,4],[297,4],[302,5],[308,3],[317,1],[339,1],[341,4],[346,3],[350,2],[353,1],[364,1],[388,1],[390,5],[396,3],[400,3],[404,5],[410,1],[412,3],[416,2],[428,1],[444,2],[452,5],[458,4],[472,1],[479,1],[481,4],[486,1],[488,2],[491,4],[503,1],[514,3],[556,1],[577,3],[597,5],[603,4],[615,1],[647,2],[656,1],[658,2],[665,1],[682,1],[684,5],[701,4],[706,2],[709,2],[712,1],[714,3],[718,3],[722,3],[726,3],[739,1],[741,2],[744,2],[751,1],[753,3],[757,2],[771,2],[785,3],[789,3],[804,1],[817,2],[835,1],[841,3],[845,6],[852,4],[857,2],[864,1],[866,1],[868,4],[873,5],[879,4],[884,2],[887,3],[891,3],[895,1],[897,4],[902,4],[907,3],[915,1],[921,1],[923,4],[939,3],[943,1],[945,4],[975,2],[978,3],[994,1],[996,5],[1002,2],[1005,1],[1007,2],[1010,3],[1014,3],[1018,2],[1021,3],[1025,3],[1029,3],[1037,6],[1044,2],[1047,3],[1071,3],[1095,1],[1113,3],[1117,4],[1127,1],[1135,1],[1145,2],[1148,4],[1153,2],[1156,5],[1162,2],[1168,2],[1175,2],[1185,1],[1187,5],[1193,3],[1197,3],[1201,2],[1204,4],[1209,5],[1215,3],[1219,3],[1223,3],[1227,3],[1240,3],[1244,5],[1250,2],[1253,3],[1265,1],[1267,5],[1273,2],[1295,1],[1311,1],[1313,3],[1317,1],[1319,3],[1323,2],[1347,7],[1355,5],[1361,2],[1364,3],[1368,1],[1370,2],[1373,4],[1386,1],[1388,3],[1414,3],[1424,1],[1452,1],[1454,4],[1459,3],[1463,3],[1470,3],[1474,4],[1479,4],[1484,3],[1488,2],[1494,2],[1497,3],[1501,3],[1505,3],[1509,4],[1531,2],[1538,2],[1549,4],[1570,1],[1572,5],[1578,3],[1582,2],[1588,2],[1602,1],[1613,1],[1615,4],[1620,5],[1631,2],[1634,3],[1655,3],[1679,6],[1686,2],[1689,2],[1692,4],[1697,4],[1702,3],[1706,5],[1712,2],[1715,3],[1738,1],[1740,4],[1745,2],[1756,1],[1758,4],[1783,1],[1785,4],[1790,4],[1795,2],[1798,5],[1804,3],[1822,3],[1826,5],[1832,1],[1834,3],[1851,1],[1853,3],[1857,3],[1861,3],[1879,1],[1881,3],[1885,4],[1896,1],[1898,3],[1905,3],[1909,4],[1928,3],[1940,1],[1942,3],[1946,2],[1956,1],[1967,2],[1990,1],[2010,1],[2016,2],[2035,1],[2037,6],[2052,1],[2054,3],[2058,1],[2080,2],[2083,3],[2090,4],[2095,2],[2116,1],[2132,1],[2134,3],[2138,1],[2140,2],[2143,3],[2147,3],[2151,2],[2154,3],[2158,3],[2162,2],[2165,2],[2168,1],[2170,3],[2178,6],[2185,5],[2191,2],[2194,3],[2206,1],[2208,3],[2216,3],[2231,1],[2233,3],[2237,3],[2241,2],[2244,5],[2250,3],[2268,3],[2272,5],[2278,3],[2288,2],[2300,2],[2308,5],[2314,2],[2330,4],[2335,5]]},"284":{"position":[[4,1],[6,4],[11,2],[14,3],[27,1],[29,4],[34,3],[38,4],[54,2],[57,5],[63,3],[67,2],[70,3],[74,4],[79,3],[106,1],[112,5],[129,1],[131,2],[134,2],[137,3],[141,2],[144,2],[147,3],[151,6],[168,2],[175,3],[179,2],[182,2],[185,3],[200,2],[213,2],[216,2],[219,3],[223,6],[230,3],[234,4],[239,3],[243,3],[247,3],[251,2],[263,1],[265,2],[275,1],[277,3],[281,4],[286,5]]},"286":{"position":[[5,1],[7,1],[9,3],[13,4],[18,4],[23,3],[27,3],[31,3],[35,4],[50,3],[54,3],[63,1],[65,2],[85,2],[101,1],[103,5],[109,5],[126,1],[143,1],[145,5],[155,1],[170,1],[184,1],[186,2],[201,1],[218,1],[220,5],[226,3],[259,1],[286,1],[327,2],[339,1],[341,2],[344,6],[355,1],[357,3],[361,2],[368,3],[372,2],[375,1],[377,2],[380,3],[408,1],[432,1],[434,4]]},"288":{"position":[[0,1],[2,4],[19,2],[22,5],[28,4],[50,1],[52,4],[64,1],[85,1],[93,3],[102,1],[104,5],[121,3],[125,1],[127,2],[130,3],[134,2],[196,5],[217,2],[231,2],[234,2],[237,4],[251,1],[268,5],[274,5],[280,2],[283,4],[310,1],[312,5],[318,3],[322,1],[324,5],[330,1],[332,2],[335,3],[339,3],[343,2],[346,5],[368,1],[374,1],[376,3],[380,5],[386,2],[389,3],[393,2],[396,5],[402,4],[425,3],[434,1],[449,1],[451,2],[454,5],[465,1],[467,2],[470,3],[474,2],[477,1],[479,1],[481,3]]},"290":{"position":[[0,1],[2,5],[8,4],[28,3],[60,2],[63,4],[68,5],[74,2],[89,1],[91,3],[95,2],[98,4],[115,3],[119,2],[122,4],[127,2],[130,4],[135,3],[139,3],[143,3],[158,1],[160,5],[175,4],[185,1],[201,1],[203,5],[229,1],[231,2],[234,3],[238,3],[242,6],[258,1],[260,4],[265,3],[269,2],[272,5],[278,3],[282,4],[297,4],[311,1],[313,3],[325,1],[327,5],[343,4],[348,3],[372,1],[374,3],[378,1],[380,4],[396,3],[400,3],[404,2],[407,1],[409,3],[413,5],[419,1],[421,4],[426,3],[430,3],[434,2],[440,2],[447,1],[461,1],[463,5]]},"292":{"position":[[4,1],[20,1],[22,5],[28,5],[34,2],[37,1],[39,4],[44,3],[71,1],[78,1],[80,4],[85,4],[90,3],[101,3],[110,1],[112,3],[116,1],[118,3],[122,5],[128,2],[131,4],[155,1],[162,1],[164,2],[167,3],[176,2],[179,3],[183,2],[186,3],[190,2],[193,4],[210,3],[219,1],[224,2],[236,1],[238,3],[242,2],[245,3],[256,1],[258,3],[262,1],[275,3],[279,4],[284,3],[288,3],[292,3],[300,2],[323,1],[325,4],[343,2],[380,2],[383,5],[405,1],[436,1],[441,1],[443,2],[457,1],[463,1],[465,4],[470,7],[478,2],[491,3],[495,4],[504,2],[526,1],[528,3],[532,3],[536,4],[541,3],[545,2],[548,3],[552,3],[566,4],[571,4],[580,1],[598,1],[600,4],[605,2],[616,1],[618,5],[624,2],[633,2],[652,1],[654,5],[673,1],[681,1],[683,5],[689,3],[707,1],[729,2],[732,3],[739,2],[742,3],[746,1],[748,3],[752,3],[765,1],[775,1],[777,3],[781,2],[784,3],[788,3],[792,3],[800,1],[802,4],[820,1],[822,2],[835,4],[840,2],[843,5],[857,1],[872,3],[895,1],[897,3],[901,2],[904,3],[908,3],[926,1],[928,5],[934,3],[938,4],[943,5]]},"294":{"position":[[10,2],[33,1],[35,3],[39,3],[43,3],[56,1],[58,4],[63,4],[68,3],[72,2],[75,3],[88,1],[90,2],[103,2],[106,3],[110,1],[112,2],[115,3],[119,4],[133,2],[144,2],[147,3],[151,3],[155,2],[158,2],[169,1],[171,5],[177,2],[180,3],[184,3],[188,8],[197,4],[202,4],[207,5],[213,3],[217,3],[221,1],[223,5],[229,2],[232,2],[235,3],[239,3],[250,3],[254,5]]},"296":{"position":[[0,3],[11,2],[14,2],[56,2],[59,1],[68,4],[73,2],[76,2],[88,1],[90,4],[95,2],[126,1],[128,2],[131,3],[135,1],[137,3],[141,1],[143,5],[158,1],[167,3],[191,4],[196,5],[212,5],[218,4],[223,2],[226,3],[230,3],[238,4],[243,3],[247,2],[250,3],[262,4],[267,3]]},"298":{"position":[[21,1],[23,4],[28,1],[37,1],[39,3],[43,3],[47,1],[53,3],[57,2],[69,4],[74,5],[80,3],[96,1],[154,1]]},"300":{"position":[[46,3],[50,3],[54,3],[69,6],[92,2],[95,3],[99,6],[113,1],[124,1],[126,5],[152,3],[167,3],[171,3],[181,1],[274,1],[276,5],[282,3],[297,9],[341,1],[355,2],[395,1],[410,1],[412,5],[418,2],[421,4],[460,1],[462,3],[473,4],[515,1],[517,2],[520,3],[531,3],[535,3],[547,2],[550,5],[556,3],[562,2],[576,6],[594,3],[646,1],[657,2],[660,5],[666,3],[686,1],[753,1],[755,4],[760,1],[762,2],[789,1],[800,1],[802,5],[808,3],[812,3],[816,4],[829,1],[831,5],[837,5],[861,1],[867,2],[886,1],[888,6],[895,1],[897,4],[914,2],[917,3],[921,5],[927,3],[950,1],[967,2],[970,1],[972,4],[977,5],[983,2],[998,1],[1016,1],[1027,2],[1049,1],[1051,5],[1057,3],[1061,5],[1067,3],[1087,1],[1089,4],[1094,2],[1097,3],[1101,4],[1106,3],[1133,1],[1135,5],[1141,3],[1145,3],[1149,2],[1160,1],[1162,4],[1167,2],[1170,2],[1173,3],[1177,3],[1181,4],[1186,3],[1190,2],[1193,3],[1197,6]]},"302":{"position":[[0,3],[16,2],[19,6],[59,1],[65,1],[67,5],[73,3],[86,1],[88,4],[93,2],[96,3],[100,3],[104,3],[108,2],[111,5],[117,3],[121,4],[134,1],[136,2],[139,3],[143,4],[148,2],[151,1],[153,2],[156,2],[159,5],[165,1],[176,2],[179,1],[277,1],[292,2],[295,5],[301,3],[305,2],[308,5],[314,3],[326,1],[348,1],[350,3],[354,2],[357,4],[362,4],[371,1],[382,1],[384,2],[394,3],[398,2],[401,3],[405,1],[407,3],[411,4],[416,2],[428,2],[431,3],[435,3],[439,2],[450,1],[452,5],[462,2],[465,1],[474,1],[476,6],[483,2],[486,2],[489,3],[498,1],[534,1],[536,4],[550,3],[554,3],[558,3],[562,5],[572,1],[584,1],[607,2],[610,2],[613,3],[617,2],[655,1],[657,5],[667,1],[669,2],[680,3],[704,2],[707,3],[711,4],[716,3],[729,1],[731,2],[740,3],[744,4],[773,1],[775,5],[781,3],[785,3],[797,1],[811,1],[841,3],[845,3],[884,1],[886,2],[898,1],[900,4],[905,5],[917,3],[925,1],[927,2],[930,2],[933,2],[936,4],[941,3],[945,3],[949,3],[953,2],[956,3],[960,6],[967,1],[969,2],[978,5],[984,4],[1003,1],[1013,1],[1015,5],[1021,4],[1034,1],[1036,4],[1041,3],[1045,2],[1070,1],[1085,1],[1087,5],[1097,2],[1100,3],[1112,1],[1114,4],[1119,2],[1122,2],[1129,1],[1131,5],[1137,3],[1141,2],[1152,1],[1154,3],[1158,4],[1163,2],[1174,1],[1176,5],[1182,4],[1193,4],[1198,5],[1204,3],[1208,4],[1227,1],[1229,3],[1233,4],[1238,3],[1242,3],[1246,3],[1250,3],[1254,3],[1258,2],[1261,3],[1265,3],[1269,3],[1273,4],[1278,3],[1286,1],[1288,4],[1293,3],[1297,3],[1301,4],[1315,2],[1318,3],[1322,2],[1325,2],[1328,3],[1332,3],[1336,5],[1342,3],[1346,2],[1349,2],[1356,3],[1360,4],[1365,6],[1372,1],[1374,5],[1389,1],[1391,4],[1396,3],[1400,1],[1402,3],[1406,2],[1409,3],[1413,2],[1416,1],[1418,4],[1430,1],[1441,3],[1445,2],[1448,3],[1452,5]]},"304":{"position":[[0,2],[12,2],[15,3],[35,4],[40,3],[65,1],[79,1],[81,4],[90,1],[92,3],[103,1],[105,5],[128,1],[210,1],[276,2],[279,2],[294,1],[390,2],[393,2],[413,1],[422,3],[426,3],[430,2],[433,2],[436,1],[498,2],[508,1],[510,2],[513,3],[521,2],[540,1],[542,5],[557,1],[559,2],[562,4],[573,1],[575,5],[581,2],[594,2],[597,2],[600,2],[603,3],[607,2],[610,3],[624,2],[634,3],[645,3],[649,2],[661,2],[664,3],[684,2],[694,3],[698,6],[705,3],[709,3],[720,3],[724,3],[728,3],[736,2],[739,3],[743,4],[748,3],[759,3],[763,3],[767,5],[773,3],[777,3],[781,2],[784,2],[790,2],[800,3],[804,4],[809,3],[813,2],[816,1],[818,2],[830,1],[832,5],[838,4],[843,3],[847,2],[850,2],[856,2],[866,1],[868,3],[872,4],[877,2],[880,3],[884,6]]},"306":{"position":[[0,2],[13,1],[28,4],[33,5],[39,1],[41,3],[61,1],[81,3],[85,2],[88,2],[91,3],[95,2],[107,3],[111,5]]},"309":{"position":[[6,1],[50,1],[80,1],[129,1],[131,6],[147,1],[149,5]]},"311":{"position":[[9,2],[27,1],[29,2],[32,3],[41,1],[43,4],[56,5],[77,3],[81,5],[96,2],[99,3],[103,3],[107,4],[112,3],[149,1],[173,3],[185,1],[187,5],[193,2],[196,3],[208,1],[210,4],[223,1],[233,3],[237,3],[241,6],[248,2],[251,3],[259,2],[271,2],[282,1],[284,4],[294,1],[296,3],[300,2],[303,2],[306,3],[310,2],[313,2],[320,3],[324,2],[327,5],[348,1],[350,3],[354,2],[362,1],[364,4],[369,3],[373,3],[377,3],[381,3],[385,5],[391,3],[400,1],[402,4],[425,1],[434,1],[436,5],[454,1],[456,2],[459,3],[463,3],[467,2],[470,4],[489,1],[491,4],[496,3]]},"313":{"position":[[0,2],[7,1],[9,4],[14,1],[16,2],[19,5],[25,4],[35,1],[37,2],[51,1],[53,3],[107,1],[114,1],[116,2],[143,1],[145,4],[183,3],[187,5],[206,1],[216,3],[220,5],[226,1],[228,4],[233,4],[254,5],[260,4],[265,4],[270,3],[274,2],[277,3],[281,1],[283,5],[297,1],[305,1],[307,3],[311,6],[318,3],[329,3],[333,3],[337,1],[339,2],[342,3],[346,5],[352,4],[357,1],[359,3],[363,3],[367,4],[372,4],[377,3]]},"316":{"position":[[8,1],[37,1],[44,2],[47,2],[50,2],[61,2],[69,1],[77,2],[85,1],[98,1],[100,5],[113,3],[117,2],[120,2],[123,3],[127,5],[133,3],[137,3],[145,3],[149,4],[154,3],[174,1],[176,5],[192,5],[198,2]]},"318":{"position":[[15,1],[22,2],[30,1],[32,3],[36,2],[43,2],[57,1],[59,3],[63,5],[69,2],[72,3],[76,2],[79,3],[91,1],[93,1],[95,1],[97,5],[103,1],[105,3],[116,1],[118,3],[122,3],[126,3],[130,4],[135,1],[137,3],[148,1],[158,1],[160,4],[165,3],[169,4],[174,3],[178,5],[193,1],[199,1],[201,4],[206,3],[210,3],[214,2],[217,3],[221,4],[226,5],[232,2],[239,1],[245,1],[247,5],[253,2],[256,6],[263,2],[266,4],[271,2],[279,5],[285,3],[289,1],[291,1],[293,5],[299,4],[308,4],[313,3],[317,4],[322,2],[325,2],[342,3],[346,5]]},"320":{"position":[[8,1],[10,4],[35,3],[39,2],[51,4],[56,3],[60,4],[65,5],[77,2],[80,3],[84,3],[102,1],[104,2],[107,1],[109,2],[112,5],[118,3],[144,2],[157,2],[160,4],[173,2],[184,1],[186,3],[190,4],[204,1],[206,1],[208,1],[210,4],[223,1],[225,4],[247,2],[250,3],[254,4],[259,2],[267,2],[270,4],[275,4],[296,2],[299,7],[307,4],[312,5],[318,5]]},"322":{"position":[[8,1],[14,1],[16,2],[19,2],[22,2],[45,1],[54,2],[57,2],[60,3],[64,5],[70,2],[73,2],[84,1],[105,3],[109,2],[112,3],[121,1],[123,5],[144,1],[152,2],[155,2],[158,5],[164,2],[167,3],[171,3],[175,3],[179,3],[183,4],[188,2],[191,5]]},"324":{"position":[[14,1],[32,3],[36,2],[39,2],[42,2],[52,4],[66,1],[68,2],[71,3],[75,2],[78,1],[86,1],[88,2],[91,2],[94,2],[104,1],[106,2],[109,5],[115,2],[118,1],[120,4],[125,2],[128,4],[133,4],[138,3],[142,4],[147,4],[152,3],[156,3],[160,3],[173,1],[175,3],[188,2],[191,2],[194,4],[199,2],[239,3],[243,3],[247,4]]},"326":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"328":{"position":[[0,2],[13,1],[15,1],[17,2],[20,2],[23,3],[27,2],[81,2],[108,1],[110,2],[113,3],[117,5],[123,2],[140,3],[144,2],[152,1],[154,2],[171,1],[173,3],[184,1],[186,2],[200,3],[204,2],[207,4],[228,1],[254,1],[256,2],[259,2],[262,4],[267,3],[289,1],[291,4],[296,4],[301,2],[304,3],[329,1],[331,3],[356,1],[366,1],[368,2],[371,3],[375,4],[398,5],[404,4],[409,2],[435,1],[446,2],[449,1],[462,1],[464,2],[467,2],[470,3],[479,5],[541,1],[571,2],[574,2],[577,2],[580,3],[584,5],[599,2],[602,2],[613,1],[615,4],[620,4],[625,2],[654,2],[657,5],[663,2],[666,3],[689,1],[691,2],[694,3],[706,1],[737,1],[739,5],[745,3],[749,4],[796,1],[798,5],[849,1],[879,2],[882,3],[904,2],[912,1],[914,2]]},"330":{"position":[[5,1],[7,3],[11,2],[14,2],[17,3],[21,3],[32,2],[35,5],[50,2],[53,3],[57,2],[60,2],[79,1],[90,1],[92,1],[94,3],[98,3],[102,3],[106,2],[109,3],[113,2],[132,1],[134,1],[136,5],[142,3],[146,2],[149,3],[153,2],[156,2],[159,5],[182,2],[185,3],[189,2],[192,1],[194,4],[199,2],[202,3],[206,5],[225,3],[238,1],[254,1],[272,2],[275,1],[277,4],[295,1],[310,3],[314,5],[320,3],[347,2],[368,3],[403,2],[422,1],[424,2],[441,1],[443,3],[447,3],[451,4],[456,3],[460,3],[464,3],[468,3],[472,3],[476,2],[479,2],[482,1],[484,2],[487,4],[510,1],[512,5],[518,4],[523,2],[555,1],[557,2],[560,5],[580,1],[593,3],[597,6],[604,3],[608,3],[612,3],[616,2],[619,4],[634,1],[652,3],[656,2],[659,1],[661,2],[664,2],[667,4],[677,1],[687,1],[702,3],[706,4],[711,3],[715,2],[718,5],[724,1],[726,3],[730,2],[733,2],[736,3],[740,4],[745,2],[748,2],[751,5],[757,4],[762,6],[769,2],[772,5],[778,2],[781,2],[784,3],[788,2],[807,1],[809,1],[811,4],[816,1],[818,3],[822,4],[827,4],[832,2],[835,3],[839,5],[845,5],[870,3],[874,4],[879,2],[898,1],[900,2],[903,3],[907,4],[912,2],[918,2],[921,3],[925,2],[943,4],[948,5],[954,3],[958,2],[961,2],[964,2],[983,1],[985,3],[994,3],[998,4],[1003,3],[1007,3],[1037,2],[1040,2],[1043,3],[1047,4],[1052,4],[1066,3],[1070,2],[1073,3],[1077,1],[1079,2],[1082,3],[1086,2],[1110,1],[1112,6],[1124,1],[1146,3],[1160,1],[1162,5],[1168,3],[1180,1],[1182,2],[1185,3],[1189,4],[1194,2],[1197,2],[1200,4],[1214,3],[1218,4],[1231,1],[1233,2],[1236,3],[1240,6],[1247,4],[1262,1],[1264,5],[1292,1],[1311,1],[1313,5],[1341,1],[1343,4],[1393,1],[1395,5],[1418,1],[1420,5],[1442,1],[1466,1],[1468,4],[1473,4],[1478,3],[1482,2],[1485,2],[1488,3],[1492,2],[1495,3],[1499,2],[1502,2],[1505,4],[1510,6],[1521,3],[1525,2],[1528,4],[1552,2],[1555,5],[1565,3],[1574,2],[1577,6],[1592,1],[1594,5],[1600,5],[1628,1],[1649,1],[1651,5],[1657,3],[1668,1],[1670,2],[1684,4],[1703,1],[1705,2],[1708,3],[1712,2],[1715,3],[1719,5]]},"333":{"position":[[19,1],[37,1],[39,2],[42,3],[61,1],[71,1],[73,3],[93,1],[95,5],[109,1],[120,1],[130,4],[135,2],[138,3],[162,1],[164,2],[167,3],[171,4],[176,2],[179,3],[183,4],[188,3],[192,3],[217,1],[219,4],[224,2],[227,4],[232,4],[237,3],[241,2],[244,4],[278,1],[280,2],[283,4],[300,2],[303,4],[323,1],[339,3],[343,2],[355,1],[357,4],[362,2],[384,1],[386,3],[390,4],[395,2],[398,3],[402,1],[404,2],[407,3],[411,3],[415,3],[419,4],[424,4],[429,3],[456,1],[458,4],[463,1],[465,5],[471,2],[474,2]]},"335":{"position":[[0,3],[11,1],[13,3],[17,2],[34,1],[36,5],[49,1],[51,2],[54,4],[59,2],[62,1],[64,3],[68,4],[73,3],[77,1],[79,4],[94,2],[97,5],[118,1],[129,1],[131,7],[139,1],[141,3],[145,3],[149,3],[153,3],[170,1],[172,4],[177,3],[181,3],[185,1],[187,3],[191,3]]},"337":{"position":[[14,1],[20,3],[24,3],[33,1],[35,5],[49,1],[51,5],[57,3]]},"339":{"position":[[0,1],[2,2],[5,4],[37,1],[39,2],[42,4],[47,3],[51,2],[54,3],[58,5],[64,1],[66,3],[78,1],[96,2],[99,1],[101,2],[104,4],[123,2],[126,3],[130,2],[141,1],[143,2],[146,3],[150,4],[155,2],[158,2],[161,3],[165,2],[177,1],[189,4],[194,4],[199,6],[206,4],[227,1],[229,2],[232,2],[241,1],[243,2],[254,2],[273,2],[276,1],[278,2],[281,3],[285,4],[290,3],[300,3],[312,1],[314,4],[319,5],[333,2],[336,2],[339,2],[342,4],[347,5],[353,3]]},"341":{"position":[[0,1],[2,2],[5,4],[10,3],[37,1],[48,4],[53,3],[57,1],[69,2],[86,1],[88,4],[114,1],[116,5],[122,2],[138,1],[140,2],[143,3],[173,1],[186,1],[188,5],[194,3],[212,1],[257,1],[274,1],[276,5]]},"343":{"position":[[0,1],[8,1],[15,1],[38,1],[54,1],[56,4],[61,2],[89,1],[91,3],[120,1],[122,4],[127,2],[130,3],[134,3],[156,1],[182,2],[185,3],[189,5],[195,1],[202,1],[212,3],[216,6],[228,1],[243,1],[274,1],[276,2],[305,2],[308,6],[320,1],[322,5],[328,3],[338,2],[361,1],[363,4],[368,2],[389,1],[409,1],[411,2],[425,1],[438,1],[456,2],[459,5],[465,3],[482,1],[484,4],[506,1],[508,4],[513,3],[544,1],[546,5],[569,1],[571,4],[576,3],[597,1],[599,4],[604,2],[620,1],[622,4],[627,5],[633,6],[657,1],[659,2],[673,1],[675,3],[687,2],[690,2],[693,3],[708,1],[718,2],[729,4],[734,5],[740,3],[752,1],[771,1],[794,1],[796,2],[816,1],[818,6],[839,2],[857,4],[862,5]]},"345":{"position":[[0,1],[7,1],[17,1],[19,6],[31,1],[46,1],[48,3],[52,3],[56,4],[61,4],[66,2],[69,3],[73,2],[76,2],[84,1],[102,2],[128,1],[130,4],[135,1],[137,2],[164,1],[166,2],[169,3],[173,3],[177,3],[193,1],[195,4],[208,1],[226,1],[256,1],[258,4],[263,2],[296,1],[320,1],[322,4],[335,3],[339,2],[362,1],[364,3],[375,1],[383,3],[415,1],[437,1],[439,1],[441,2],[444,4],[457,1],[492,1],[494,6],[513,1],[526,2],[529,5],[543,1],[572,1],[574,4],[598,1],[600,2],[611,1],[613,3],[617,1],[619,3],[629,1],[648,1],[672,1],[699,2],[702,4],[707,6],[735,1],[737,2],[748,1],[767,2],[783,1],[785,4],[805,1],[824,2],[848,3],[852,5],[858,3],[862,2],[874,1],[876,2],[879,3],[883,3],[908,3],[912,5],[918,3],[922,2],[925,3],[946,1],[948,4],[959,2],[962,2],[965,2],[968,2],[1006,1],[1008,2],[1025,1],[1027,6],[1034,3],[1038,2],[1057,1],[1059,3],[1063,4],[1068,5],[1089,1],[1097,1],[1099,3],[1119,1],[1121,4],[1142,2],[1154,1],[1163,2],[1181,1],[1183,1],[1191,1],[1193,5]]},"347":{"position":[[0,1],[7,1],[17,1],[27,2],[30,7],[51,1],[66,4],[98,1],[100,2],[126,3],[130,3],[134,3],[138,6],[157,1],[165,1],[167,3],[179,1],[196,1],[211,1],[213,2],[216,5],[222,1],[224,3],[236,1],[267,1],[269,5],[275,4],[286,1],[300,1],[302,3],[314,1],[347,1],[349,2],[352,5],[366,1],[398,1],[400,5],[406,2],[409,3],[423,1],[444,2],[486,2],[511,1],[513,3],[517,2],[520,4],[544,1],[546,6]]},"349":{"position":[[0,3],[4,3],[20,2],[23,2],[26,5],[32,4],[37,3],[41,3],[53,1],[114,1],[116,5],[152,3],[156,5],[170,4],[175,1],[177,3],[181,3],[204,1],[206,3],[210,3],[214,2],[220,3],[224,3],[228,3],[240,1],[250,2],[301,1],[303,5],[328,1],[330,4],[350,1],[360,1],[362,2],[365,2],[368,4],[373,1],[375,2],[378,4],[383,4],[388,4],[393,1],[395,2],[416,1],[418,4],[423,3],[427,4],[441,1],[451,1],[461,1],[463,4],[468,3],[472,3],[497,2],[514,1],[516,4],[521,4],[548,1],[550,5],[573,1],[575,3],[601,1],[625,2],[640,5],[660,1],[684,1],[696,3],[700,6],[707,4],[730,1],[732,5],[738,3],[761,3],[765,2],[784,1],[786,5],[792,2],[805,1],[838,1],[840,4],[845,2],[848,3],[852,5],[858,4],[863,3],[867,2],[870,3],[874,4],[879,5],[885,1],[887,2],[890,2],[893,4],[898,2],[901,2],[904,3],[908,2],[911,3],[915,2],[918,2],[921,2],[924,3]]},"351":{"position":[[12,1],[14,1],[16,2],[19,2],[30,1],[32,3],[36,3],[40,4],[45,4],[94,1],[122,1],[124,3],[128,3],[137,1],[139,3],[143,1],[145,3]]},"353":{"position":[[22,1],[32,1],[50,1],[66,2],[93,1],[95,5],[101,3],[105,1],[107,3],[111,3],[123,1],[125,4],[144,1],[146,5],[152,2],[171,1],[173,2],[184,1],[194,2],[197,4],[239,1],[241,3],[245,1],[247,3]]},"355":{"position":[[0,1],[2,5],[22,1],[24,2],[33,3],[37,5],[59,1],[76,1],[86,1],[88,5],[102,1],[112,1],[137,1],[146,1],[148,5],[154,1],[156,3],[168,3],[172,5],[178,5],[184,2],[203,1],[205,1],[207,3],[211,4],[216,3],[251,1],[253,4],[266,1],[276,2],[290,3],[294,5]]},"357":{"position":[[8,1],[30,1],[32,1],[34,2],[37,4],[42,3],[46,1],[48,2],[59,1],[61,4],[86,1],[88,2],[91,2],[109,1],[126,1],[128,2],[149,1],[151,3],[155,1],[157,3],[169,1],[179,1],[181,4],[214,1],[216,2],[244,1],[246,3],[250,1],[252,3]]},"360":{"position":[[0,2],[3,3],[19,5],[25,4],[44,1],[66,1],[68,5],[76,2],[138,6],[145,2],[148,5],[154,2],[157,3],[164,1],[178,1],[180,2],[183,4],[188,3],[192,4],[197,3],[224,1],[226,4],[245,1],[247,2],[267,2],[270,4],[275,3],[279,6],[286,2],[289,4],[306,1],[308,4],[313,5],[319,4],[324,3],[328,2],[331,1],[333,4],[338,1],[340,3],[344,2],[347,3],[351,1],[353,3],[357,3],[361,2],[364,3],[368,5],[374,3],[395,1],[397,4],[402,3],[406,5],[412,7],[420,2],[423,2],[432,2],[435,3],[439,6],[446,2],[463,2],[466,1],[472,1],[474,5],[488,2],[505,1],[544,1],[546,5],[552,3],[556,4],[568,5],[574,3],[578,5],[611,1],[628,2],[631,2],[634,1],[636,3],[640,3],[644,3],[648,3],[652,3],[665,1],[667,1],[669,4],[674,3],[693,1],[695,3],[699,1],[701,2],[704,4],[716,1],[718,2],[721,3],[739,1],[749,5],[763,1],[765,1],[767,2],[770,2],[782,1],[784,5],[790,1],[792,5],[798,2],[811,2],[819,1],[844,1],[857,1],[859,3],[863,6]]},"362":{"position":[[0,3],[19,1],[21,1],[23,4],[37,3],[54,1],[61,1],[66,1],[68,5],[74,2],[77,4],[88,3],[112,1],[122,1],[155,2],[158,5],[172,1],[192,2],[195,6],[209,3],[213,5],[219,3],[231,3],[235,4],[240,3],[252,2],[255,3],[259,3],[263,2],[266,2],[269,3],[273,5],[297,3],[301,2],[309,4],[330,3],[334,3],[338,3],[342,4],[347,1],[349,1],[351,3],[355,4],[360,2],[370,6],[385,6],[392,6],[399,7],[426,3],[453,6],[469,4],[474,3],[478,5],[484,2],[487,2],[490,4],[495,5],[501,2],[504,4],[509,4],[514,8],[523,1],[525,2],[528,5],[543,2],[546,2],[549,2],[552,3],[556,2],[559,3],[563,2],[566,4],[571,3],[575,2],[578,1],[580,2],[587,3],[591,2],[594,4],[599,2],[602,3],[616,2],[619,2],[622,6],[629,2],[632,3],[636,2],[639,3],[643,2],[646,2],[649,2],[660,5],[666,5],[672,2],[675,4],[687,2],[690,3],[694,3],[698,4],[720,6],[727,2],[730,1],[732,2],[735,4],[740,4],[745,2],[748,2],[751,3],[755,2],[758,3],[762,2],[765,3],[774,5],[780,2],[783,2],[791,2],[794,1],[796,2],[799,4],[804,2],[807,3],[811,2],[826,5],[832,3],[836,2],[844,2],[847,3],[860,6],[867,1],[869,2],[872,5],[878,2],[881,3],[885,2],[888,1],[890,1],[892,2],[899,3],[903,3],[907,4],[915,2],[918,2],[921,4],[926,7],[934,2],[937,3],[947,2],[950,3],[954,3],[958,3],[962,3],[966,3],[970,2],[983,6],[990,2],[993,5],[1003,3],[1007,3],[1011,2],[1020,5],[1057,6],[1064,2],[1120,2],[1123,3],[1127,3],[1131,4],[1136,2],[1139,4],[1144,6],[1166,1],[1173,4],[1184,3],[1188,3],[1192,4],[1197,4],[1202,2],[1205,2],[1208,3],[1212,4],[1223,6],[1241,1],[1247,3],[1251,4],[1280,4],[1285,3],[1289,6]]},"364":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"366":{"position":[[12,2],[26,1],[28,3],[32,2],[35,4],[52,1],[54,2],[57,2],[60,3],[64,2],[67,4],[72,3],[76,2],[102,1],[104,2],[196,3],[200,3],[283,1],[285,3],[289,3],[293,2],[296,3],[300,3],[304,2],[307,2]]},"368":{"position":[[0,3],[27,1],[29,1],[31,3],[35,2],[61,1],[71,2],[79,2],[93,1],[95,2],[98,1],[100,2],[103,2],[106,1],[108,2],[134,1],[136,2],[139,2],[142,2],[145,2],[171,1],[173,4],[178,2],[204,1],[210,3],[214,3],[218,3],[238,1],[240,4],[245,2],[248,3],[252,2],[255,1],[257,2],[260,3],[264,2],[272,1],[284,1],[312,2],[364,1],[366,2],[375,2],[383,1],[385,4],[397,1],[408,2],[417,2],[451,3],[475,1],[481,3],[488,2],[491,3],[507,1],[516,2],[519,2],[522,2],[525,1],[527,4],[547,2],[559,2],[562,3],[566,5],[591,1],[622,4],[627,3],[631,2]]},"370":{"position":[[6,1],[8,2],[11,3],[15,3],[19,2],[28,1],[30,2],[33,2],[57,2],[83,1],[85,5],[96,2],[99,3],[103,4],[119,1],[121,2],[124,2],[134,1],[136,4]]},"373":{"position":[[51,1],[65,1],[67,2],[81,1],[88,2],[91,2],[106,1],[108,2],[111,4],[116,2],[119,4],[124,1],[126,5],[132,2],[135,3],[195,1],[201,1],[203,4],[219,1],[221,2]]},"375":{"position":[[15,1],[17,5],[27,1],[29,2],[43,1],[57,1],[59,2],[62,2],[65,2],[68,6],[75,2],[80,2],[83,5],[89,3],[93,4],[98,2],[171,2],[174,5]]},"377":{"position":[[14,1],[21,1],[23,3],[27,4],[32,4],[37,2],[63,1],[65,2],[72,1],[74,3],[80,2],[83,4],[88,3],[95,2],[119,2],[122,2],[143,5],[158,2],[161,3],[174,3],[178,5],[184,2],[187,3],[205,1],[207,2]]},"379":{"position":[[17,1],[19,3],[23,3],[50,1],[52,2],[55,1],[57,4],[62,2],[65,3],[121,1],[123,2],[141,1],[143,4],[148,4],[153,2],[156,3],[169,1],[191,2],[220,1],[238,1],[240,4],[245,2],[253,1],[263,1],[265,6],[278,1],[287,1],[308,1],[310,4],[315,5],[334,1],[351,1],[373,3],[377,3],[381,2],[387,1],[398,3],[402,1],[404,4],[409,4]]},"382":{"position":[[10,1],[28,1],[45,2],[48,3],[52,2],[66,1],[68,4],[73,2],[90,1],[92,2],[100,1],[133,1],[143,1],[159,2],[166,1],[178,3],[202,2],[212,1],[227,2],[255,2],[263,1],[270,2],[273,3],[290,2]]},"384":{"position":[[35,1],[54,1],[56,2],[66,2],[69,1],[85,1],[87,2],[90,2],[93,2],[96,2],[99,2],[120,1],[122,3],[126,3],[130,4],[135,3],[168,3],[172,2],[189,1],[208,3],[212,3],[230,4],[235,2],[238,2],[251,1],[253,2],[298,1],[300,3]]},"386":{"position":[[0,2],[3,3],[7,1],[25,2],[28,2],[39,2],[42,2],[50,2],[61,1],[68,1],[70,2],[73,2],[95,1],[102,1],[104,5],[110,4],[156,1],[172,1],[174,4],[184,1],[192,1],[194,2],[197,2],[216,1],[218,3],[222,2],[225,3],[229,4],[234,2],[247,2],[250,5],[256,3],[260,1],[262,2],[265,3],[269,2],[272,2],[280,1],[282,3],[286,4],[291,2],[294,3],[308,1],[310,3],[314,1],[316,2],[319,2],[334,2],[337,2],[340,2],[353,2],[356,1],[358,3],[362,2],[365,2],[368,2],[371,4],[376,1],[378,3],[382,4],[387,1],[393,1],[406,1],[426,1],[443,2],[446,2],[449,2]]},"388":{"position":[[31,1],[37,1],[39,3],[43,3],[47,2],[50,2],[53,6],[60,2],[63,3],[67,4],[82,1],[84,3],[88,2],[91,2],[114,1],[116,4],[125,2],[139,2],[142,1],[144,3],[148,2],[151,2],[154,2],[172,1],[174,3],[193,2],[223,2],[236,3],[240,3],[244,2],[247,3]]},"390":{"position":[[0,3],[19,1],[23,2],[26,4],[50,1],[52,5],[58,2],[61,2],[64,3],[68,4],[73,2],[76,2],[79,5],[99,1],[120,1],[122,4],[127,2],[130,6],[142,1],[144,2],[152,2],[170,1],[178,2],[181,3],[198,1],[205,2],[212,1],[217,1],[219,2],[222,4],[232,2],[241,2],[254,1],[260,1],[265,1],[273,1],[280,2],[283,3],[287,2],[290,3],[294,3],[298,4],[313,1],[320,1],[322,4],[327,2],[330,2],[333,2],[345,3],[349,4],[363,1],[365,3],[373,1],[378,2],[381,4],[386,2],[405,2],[413,2],[416,3],[420,3],[429,4],[434,3],[438,3],[442,2]]},"392":{"position":[[0,6],[30,1],[40,5],[46,3],[50,3],[58,1],[78,1],[80,3],[84,2],[87,1],[93,1],[106,1],[108,1],[110,2],[113,3],[117,4],[122,2],[125,2],[141,3],[145,3],[149,5],[155,3],[159,2],[168,2],[171,2],[174,3],[178,2],[185,1],[187,2],[201,1],[203,2],[206,2],[209,3],[213,4],[218,2],[221,5],[235,1],[248,2],[251,2],[258,3],[262,3],[266,2],[281,1],[299,1],[301,3],[345,2],[348,2],[370,1],[372,5],[378,2],[381,2],[384,2],[395,1],[401,3],[405,2],[408,2],[411,3],[415,2]]},"394":{"position":[[9,1],[11,5],[17,4],[22,2],[29,4],[34,2],[60,1],[62,2],[65,3],[69,3],[83,3],[87,2],[94,3],[98,4],[103,4],[114,2],[141,1],[147,6],[164,1],[193,3],[197,4],[206,2],[209,2],[212,3],[216,6],[229,2],[237,1],[249,1],[261,1],[263,5]]},"396":{"position":[[23,1],[25,4],[30,3],[34,4],[39,4],[44,1],[65,1],[67,2],[70,3],[74,4],[79,5],[98,5],[109,1],[111,4],[132,5],[141,1],[175,3],[190,1],[204,1],[216,1],[247,1],[263,1],[269,4],[279,2],[294,1],[326,1],[328,2],[337,1],[339,2],[342,1],[344,4],[368,1],[370,2],[396,2],[399,2],[405,1],[407,2],[427,1],[429,4],[471,1],[478,2],[481,4],[486,2],[492,1],[508,3],[512,4],[541,1],[543,3],[547,2],[550,1],[552,3],[556,3],[560,2],[566,1],[579,1],[621,1],[650,1],[652,3],[669,2],[684,1],[713,1],[727,1],[729,5],[735,2],[738,3],[742,5]]},"398":{"position":[[5,3],[9,3],[13,2],[16,2],[23,4],[94,1],[109,2],[125,2],[170,1],[185,2],[192,2],[229,4],[248,2],[251,2],[254,2],[278,1],[303,2],[306,1],[308,4],[326,1],[328,2],[352,1],[364,1],[375,1],[377,4],[395,1],[397,4],[402,2],[426,2],[451,1],[458,2],[467,2],[470,3],[474,4],[494,2],[508,2],[511,1],[513,4],[518,2],[521,2],[524,2],[527,3],[531,2],[534,2],[541,3],[561,1],[567,3],[574,1],[576,2],[579,3],[583,3],[587,2],[590,2],[593,3],[597,5],[608,1],[620,1],[636,1],[638,3],[651,3],[659,1],[661,4],[666,2],[669,2],[682,1],[684,3],[698,1],[700,1],[702,3],[706,4],[711,2],[718,3],[722,3],[726,3],[740,1],[746,2],[749,2],[761,1],[763,3],[767,5],[773,3],[777,4],[805,1],[807,3],[838,1],[840,1],[842,2],[845,3],[849,1],[851,1],[853,2],[856,3],[943,2],[960,1],[977,2],[980,6],[1004,1],[1006,5],[1012,2],[1015,3],[1019,3],[1023,2],[1031,1],[1033,3],[1037,3],[1088,3],[1092,3],[1096,3],[1100,4],[1105,2],[1118,1],[1120,3],[1124,4],[1129,3],[1133,1],[1135,1],[1137,3],[1146,2],[1149,4],[1154,4],[1159,3],[1163,3],[1167,5],[1173,3],[1177,4],[1182,2],[1185,3],[1189,3],[1193,2],[1196,2],[1199,2],[1202,3],[1206,2],[1209,4],[1214,2],[1217,3],[1221,3],[1225,3],[1229,3],[1233,2]]},"400":{"position":[[0,1],[2,3],[29,1],[31,2],[50,1],[52,2],[55,2],[58,3],[62,2],[69,4],[113,2],[136,1],[142,1],[144,3],[148,2],[151,2],[154,3],[158,2],[161,5]]},"402":{"position":[[23,1],[25,2],[28,2],[31,2],[34,3],[38,1],[56,1],[58,3],[62,2],[65,4],[70,5],[76,1],[78,3],[96,1],[98,3],[102,2],[105,2],[108,3],[112,1],[119,2],[122,2],[125,4],[130,2],[133,3],[137,3],[141,3],[145,2],[148,4],[153,2],[165,1],[178,1],[180,1],[182,3],[186,2],[189,3],[193,3],[197,2],[200,2],[203,2],[206,2],[209,3],[213,4],[218,3],[222,3],[249,1],[251,2],[254,2],[257,2],[260,4],[265,3],[269,3],[273,2],[276,2],[279,4],[284,2],[287,3],[291,2],[294,4],[299,3],[303,2],[306,1],[308,3],[312,3]]},"404":{"position":[[15,1],[17,2],[20,3],[24,5],[30,2],[33,4],[58,1],[60,2],[82,1],[84,2],[87,4],[92,2],[95,5],[101,1],[103,4],[108,2],[111,2],[123,1],[125,2],[128,3],[132,4],[137,2],[140,2],[143,5],[157,1],[163,4],[187,1],[189,2],[200,3],[204,4],[209,1],[211,2],[218,3],[222,3],[226,1],[228,1],[230,3],[234,2],[252,1],[268,3],[272,3],[276,4],[289,3],[293,2],[296,2],[299,2]]},"406":{"position":[[0,3],[4,2],[40,3],[52,1],[65,1],[119,1],[131,1],[174,1],[176,5],[182,4],[187,2],[190,2],[206,1],[224,1],[226,5],[232,4],[237,2],[263,1],[270,1],[272,4],[277,3],[281,2],[299,3],[303,1],[305,1],[307,4],[312,2],[315,3]]},"408":{"position":[[23,6],[42,1],[85,3],[89,2],[92,3],[96,3],[100,2],[103,3],[107,3],[111,2],[114,4],[119,3],[123,3],[137,3],[158,2],[161,3],[165,3],[169,2],[201,2],[210,3],[214,2],[217,3],[221,4],[226,7],[239,2],[242,3],[246,3],[250,2],[253,2],[256,2],[282,1],[284,3],[288,3],[292,4],[297,3],[301,4],[306,2],[309,2]]},"410":{"position":[[3,2],[6,3],[10,2],[13,3],[17,7],[25,3],[29,4],[34,2],[60,1],[62,5],[68,2],[71,2],[74,5],[80,3],[84,6],[101,1],[103,3],[130,1],[145,1],[152,1],[154,3],[158,3],[162,2],[165,2],[173,2],[199,1],[201,2],[204,4],[209,3],[213,3],[217,1]]},"412":{"position":[[23,2],[26,4],[41,1],[43,1],[45,2],[63,1],[65,2],[89,1],[91,2],[117,2],[120,2],[123,2],[126,2],[129,3],[133,2],[136,2],[139,2],[142,4],[170,1],[181,1],[183,2],[186,3],[190,6],[201,1],[203,4],[227,1],[229,2],[236,1],[238,2],[241,3],[245,2],[248,2]]},"414":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"416":{"position":[[68,1],[76,1],[78,3],[82,2],[85,2],[106,1],[116,2],[131,1],[157,2],[160,4],[165,3],[173,1],[197,1],[199,4],[204,2],[207,3],[211,3],[215,1],[217,2],[220,3],[224,1],[323,1],[325,3],[338,1],[340,5],[346,3],[370,1],[372,4],[386,1],[388,3],[405,1],[412,1],[414,4],[424,1],[442,1],[469,3],[473,5],[479,1],[481,3],[500,1],[514,1],[516,4],[530,1],[549,2],[571,1],[573,4],[578,1],[580,3],[584,2],[596,1],[598,4],[609,2],[622,1],[624,2],[648,2],[665,2],[668,3],[672,1],[674,2],[691,2],[700,1],[717,1],[719,6],[739,1],[741,2],[744,3],[748,2],[763,3],[767,3],[774,1],[776,4],[786,2]]},"418":{"position":[[15,1],[21,1],[23,3],[27,2],[30,3],[46,1],[48,2],[66,1],[68,2],[71,3],[75,2],[93,1],[95,4],[100,4],[123,1],[156,1],[173,1],[185,1],[187,4],[192,3],[196,3],[223,1],[252,2],[267,1],[274,1],[276,6],[301,2],[304,3],[320,1],[322,3],[326,3],[330,4],[335,2],[354,1],[368,1],[370,2],[373,5],[379,4],[477,2],[480,2],[483,2],[507,1],[535,3],[543,1],[545,3],[566,1],[578,2],[597,1],[599,5],[605,2],[627,1],[648,1],[650,3],[654,3],[683,1],[685,3],[723,1],[733,1],[735,2],[742,1],[768,1],[770,4],[775,3],[792,1],[794,2],[797,3],[806,1],[808,2],[811,2],[814,4],[823,1],[838,2],[841,3],[845,3],[849,4],[854,5],[860,1],[862,4],[867,2],[874,3],[878,3],[882,2],[889,1],[891,1],[893,4],[898,4],[903,2],[906,2],[909,2],[912,3],[916,3],[920,3],[952,1],[954,2],[957,4],[962,3],[966,2],[969,2],[972,2],[979,1],[981,5],[999,2],[1002,2],[1005,3],[1016,1],[1035,3],[1039,2],[1042,1],[1044,2],[1047,2],[1050,4],[1055,3],[1059,3],[1063,3],[1067,3],[1071,2],[1074,3],[1078,2],[1085,1],[1104,1],[1106,4],[1111,1],[1113,4],[1118,2],[1121,5],[1127,3],[1131,2],[1134,3],[1138,7],[1146,2],[1149,2],[1152,2],[1155,3],[1159,3],[1168,4],[1173,4],[1178,5],[1184,1],[1186,3],[1190,1],[1192,3],[1196,2],[1199,6],[1206,2],[1209,3],[1213,3],[1217,2],[1220,7],[1228,2],[1231,3],[1235,5],[1247,1],[1258,3],[1262,2],[1281,1],[1283,3],[1287,5],[1293,4],[1298,5],[1361,1],[1363,2],[1366,2],[1369,3],[1389,1],[1398,2],[1413,2],[1416,2],[1419,3],[1461,3],[1465,4],[1482,1],[1484,3],[1488,2],[1491,2],[1494,2],[1502,1],[1510,2],[1522,1],[1524,3],[1528,4],[1552,1],[1554,4],[1564,1],[1570,1],[1589,3],[1593,2],[1601,1],[1603,3],[1619,1],[1621,2],[1624,3],[1628,6],[1635,2],[1638,2],[1641,2],[1655,1],[1657,2],[1660,3],[1664,2],[1672,3],[1676,1],[1678,6],[1685,2],[1688,3],[1692,3],[1696,1],[1698,3],[1702,2],[1705,3],[1709,1],[1711,3],[1715,3],[1719,2],[1741,1],[1768,1],[1770,5],[1776,3],[1780,2],[1793,1],[1795,6],[1821,2],[1824,3],[1828,3],[1832,4],[1844,2],[1847,3],[1860,1],[1871,1],[1873,2],[1876,1],[1878,3],[1885,1],[1887,4],[1892,3],[1911,1],[1931,1],[1945,1],[1947,1],[1964,1],[1988,2],[1991,3],[1995,2],[2011,1],[2050,2],[2078,1],[2096,1],[2098,3],[2131,2],[2151,1],[2163,1],[2165,2],[2176,2],[2179,6],[2203,2],[2206,3],[2210,2],[2213,2],[2216,3],[2233,1],[2244,1],[2246,3],[2250,3],[2254,1],[2256,2],[2259,3],[2263,1],[2265,2],[2268,2],[2271,2],[2303,4],[2313,2],[2316,4],[2327,2],[2343,1],[2355,1],[2376,2]]},"421":{"position":[[5,1],[33,1],[54,1],[62,1],[73,1],[84,1],[86,4],[91,4],[100,1],[102,4],[107,3],[111,3],[115,3],[133,1],[148,1],[150,5],[166,1],[187,1],[189,4],[219,1],[230,1],[232,2],[235,4],[240,3],[244,1],[246,2],[256,3],[260,2],[263,3],[274,1],[285,2],[288,3],[292,3],[296,4],[307,1],[324,3],[328,5],[348,2],[372,2],[375,3],[379,3],[383,3],[387,1],[389,2],[392,4],[397,2],[400,4],[405,2],[429,1],[431,2],[434,3],[456,2],[468,1],[470,4],[475,4],[480,3],[484,1],[486,3]]},"423":{"position":[[25,1],[39,3],[43,3],[47,2],[50,4],[73,3],[77,3],[93,4],[103,3],[107,3],[114,3],[121,1],[126,5],[152,1],[167,1],[204,1],[219,1],[275,1],[277,4],[285,1],[299,2],[327,2],[371,2],[379,3],[395,1],[397,3],[418,1],[448,1],[467,1],[469,3],[482,3],[515,2],[518,2],[524,1],[529,1],[545,1],[547,4],[552,2],[563,1],[570,1],[572,2],[578,1],[605,1],[607,2],[610,7],[618,3],[642,3],[658,3],[662,3],[666,3],[670,4],[675,2],[678,2],[699,2],[702,4],[707,2],[737,2],[740,3],[749,2],[786,1],[847,1],[882,1],[928,2],[936,6],[949,1],[951,3],[968,2],[971,3],[980,1],[993,1],[1013,2],[1056,4],[1083,1],[1085,5],[1118,1],[1120,2],[1123,3],[1145,1],[1147,3],[1151,5],[1157,2],[1160,2],[1163,3],[1174,1],[1176,1],[1178,3],[1182,2],[1185,2],[1188,2],[1191,3],[1195,4],[1200,2],[1234,1],[1251,1],[1275,3],[1279,2],[1282,2],[1285,3],[1305,1],[1307,2],[1310,2],[1313,4],[1318,1],[1320,5],[1326,2],[1349,1],[1366,1],[1368,2],[1382,1],[1391,1],[1393,2],[1396,2],[1425,2],[1443,1],[1445,2],[1448,4],[1453,2],[1456,4],[1461,3],[1465,3],[1472,5],[1478,2],[1497,2]]},"425":{"position":[[5,2],[8,3],[12,3],[19,1],[42,1],[44,2],[47,3],[51,2],[54,1],[56,2],[81,2],[87,1],[89,2],[142,1],[176,1],[224,1],[226,5],[258,1],[260,2],[310,1],[352,1],[366,1],[368,5],[374,2],[377,3],[381,3],[385,3],[414,1],[428,1],[430,2],[433,2],[456,2],[544,1],[746,3],[776,1],[785,1],[787,4],[792,2],[795,5],[871,1],[949,1],[955,1],[983,1],[1013,1],[1015,4],[1040,3],[1044,3],[1048,3],[1052,2],[1055,2],[1058,3],[1079,1],[1081,1],[1083,2],[1086,3],[1090,5],[1096,5],[1117,1],[1119,2],[1122,2],[1125,3],[1137,1],[1139,4],[1144,3],[1148,3],[1152,2],[1172,1],[1174,2],[1202,1],[1204,3],[1208,5],[1214,2],[1239,2],[1242,1],[1244,4],[1249,1],[1258,1],[1271,1],[1273,2],[1284,3],[1288,3],[1292,1],[1309,1],[1311,5],[1317,2],[1320,1],[1328,1],[1330,3],[1334,3],[1349,2],[1352,5],[1358,2],[1361,4],[1366,2],[1389,2],[1392,2],[1416,3],[1420,5],[1447,1],[1449,3],[1453,1],[1478,1],[1480,2],[1489,1],[1504,2],[1507,3],[1511,4],[1516,2],[1526,2],[1529,4],[1545,1],[1568,1],[1570,3],[1574,2],[1586,1],[1617,1],[1619,1],[1621,3],[1625,4],[1646,2],[1649,3],[1653,3],[1673,1],[1765,1],[1853,1],[1855,2],[1858,1],[1860,2],[1869,1],[1898,1],[1900,7],[1930,1],[1966,3],[2056,1],[2136,1],[2311,1],[2334,1],[2336,4],[2341,3],[2354,1],[2356,1],[2358,1],[2365,2],[2368,3],[2372,4],[2377,2],[2397,1],[2406,2],[2409,3],[2428,3],[2432,3],[2436,2],[2460,3],[2464,4],[2475,1],[2484,2],[2487,2],[2490,4],[2501,1],[2503,1],[2505,2],[2508,3],[2517,2],[2546,1],[2548,4],[2553,3],[2557,3],[2561,6],[2568,3],[2579,1],[2581,4],[2586,2],[2589,2],[2592,4],[2597,2]]},"427":{"position":[[13,1],[15,3],[19,3],[23,2],[26,2],[34,3],[38,2],[49,1],[63,4],[68,2],[71,2],[74,3],[78,1],[94,1],[96,5],[102,4],[116,1],[118,2],[139,3],[143,3],[147,3],[151,2],[158,2],[161,1],[163,3],[186,3],[209,1],[211,5],[222,3],[226,4],[231,2],[234,3],[238,4],[243,4],[248,2],[251,5],[257,3],[267,1],[269,1],[280,1],[282,2],[285,2],[288,2],[311,1],[313,4],[318,3],[330,1],[332,2],[340,1],[342,6],[349,2],[358,1],[360,1],[371,1],[373,5],[379,3],[383,4],[388,2],[391,4],[396,3],[412,1],[414,2],[417,4],[422,3],[426,3],[430,1],[432,3],[450,1],[466,1],[484,1],[497,2],[519,1],[521,4],[526,5],[551,1],[553,4],[591,1],[593,4],[598,3],[602,4],[607,4],[612,2],[615,6],[622,3],[626,2],[629,2],[644,1],[665,1],[667,4],[672,2],[675,1],[677,4],[682,3],[686,3],[695,3],[699,2],[702,5],[708,3],[712,3],[728,1],[745,2],[793,1],[795,2],[798,3],[818,3],[833,2],[863,1],[902,1],[974,1],[988,1],[1034,1],[1036,4],[1057,1],[1091,1],[1119,3],[1123,2],[1126,5],[1144,3],[1148,1],[1165,1],[1167,2],[1195,1],[1197,3],[1201,3],[1205,3],[1209,2],[1212,3],[1231,1],[1259,6],[1277,1],[1296,2],[1334,1],[1360,2],[1380,1],[1382,2],[1385,6],[1392,3],[1396,2],[1409,4],[1414,2],[1444,5],[1450,2],[1453,5],[1459,3],[1463,3],[1467,4],[1472,2],[1475,5],[1481,2],[1484,7],[1492,6],[1520,4],[1525,4],[1530,3],[1534,3],[1538,2],[1551,5],[1557,6],[1626,1],[1671,1],[1734,2],[1772,3],[1840,3],[1844,2],[1856,1],[1892,1],[1918,2],[1921,3],[1944,1],[1971,1],[1973,2],[1976,2],[1979,2],[2018,1],[2038,1],[2044,1],[2083,2],[2110,2],[2135,1],[2142,1],[2187,1],[2215,3],[2219,2],[2231,3],[2235,1],[2237,2],[2259,1],[2275,1],[2277,2],[2283,5],[2289,4],[2294,3],[2306,1],[2308,2],[2311,2],[2314,3],[2318,4],[2323,4],[2328,3],[2332,4],[2337,4],[2342,3],[2346,2],[2349,2],[2352,3],[2373,2],[2376,4],[2446,1],[2448,4],[2470,1],[2478,2],[2481,1],[2504,1],[2526,1],[2528,2],[2531,3],[2535,1],[2537,4],[2551,3],[2574,1],[2576,4],[2581,1],[2583,2],[2586,3],[2602,2],[2605,3],[2609,5],[2632,1],[2634,4],[2639,2],[2642,3],[2662,1],[2664,5],[2670,4],[2702,1],[2704,4],[2709,2],[2731,1],[2733,4],[2738,3],[2742,1],[2744,1],[2746,3],[2750,2],[2770,2],[2773,3],[2805,1],[2807,2],[2832,1],[2834,3],[2838,4],[2843,5],[2872,1],[2899,1],[2901,3],[2920,1],[2922,4],[2944,1],[2976,1],[2978,4],[2983,4],[3005,3],[3009,3],[3027,1],[3046,2],[3067,1],[3069,2],[3072,3],[3076,4],[3081,3],[3104,1],[3106,2],[3111,2],[3114,3],[3123,4],[3128,5],[3141,1],[3158,1],[3176,1],[3193,1],[3231,1],[3253,2],[3266,1],[3280,1],[3300,1],[3330,1],[3332,4],[3345,2],[3362,1],[3376,1],[3378,4],[3415,2],[3428,1],[3449,1],[3451,4],[3456,5],[3479,1],[3481,2],[3499,1],[3526,2],[3542,2],[3559,1],[3567,1],[3581,1],[3583,4],[3610,2],[3618,1],[3639,1],[3650,1],[3652,2],[3655,5],[3661,3],[3691,1],[3723,1],[3725,6],[3732,1],[3734,2],[3737,3],[3748,2],[3751,2],[3754,2],[3774,1],[3802,2],[3805,2],[3808,3],[3812,2],[3815,2],[3823,1],[3842,2],[3871,3],[3892,1],[3894,2],[3897,3],[3901,2],[3904,2],[3917,1],[3931,1],[3950,2],[3970,2],[3973,4],[3978,3],[3996,1],[4015,1],[4017,3],[4021,1],[4023,3],[4027,2],[4030,4],[4035,1],[4037,3],[4041,3],[4068,2],[4071,1],[4073,3],[4077,2],[4080,2],[4083,1],[4085,2],[4088,6],[4095,5],[4101,3],[4105,3],[4118,2],[4121,1],[4123,4],[4128,3],[4132,1],[4134,2],[4137,3],[4141,2],[4144,3],[4148,2]]},"429":{"position":[[0,2],[17,2],[38,1],[53,2],[56,2],[85,1],[99,1],[101,1],[103,2],[106,5],[112,1],[114,3],[118,2],[121,4],[146,1],[148,4],[175,1],[177,5],[197,2],[218,4],[234,1],[236,4],[241,2],[244,5],[250,3],[254,3],[258,3],[279,1],[281,2],[284,3],[302,1],[307,3],[311,3],[315,3],[337,1],[339,3],[356,3],[374,1],[402,1],[431,1],[433,1],[435,2],[457,1],[459,2],[474,3],[491,1],[505,4],[515,2],[523,1],[525,4],[537,1],[539,2]]},"431":{"position":[[0,4],[18,1],[20,3],[24,2],[27,2],[33,3],[37,4],[42,2],[72,1],[74,2],[94,2],[100,1],[102,3],[124,2],[140,1],[159,2],[162,4],[187,2],[262,1],[264,3],[307,1],[353,2],[356,2],[374,1],[376,2],[475,1],[509,1],[521,1],[542,1],[560,1],[562,4],[567,1],[577,1],[604,3],[608,2],[611,3],[615,3],[619,1],[628,1],[630,1],[651,1],[653,3],[657,4],[662,4],[701,1],[717,2],[720,2],[723,2],[733,1],[751,1],[753,2],[782,2],[785,4],[790,4],[795,3],[799,1],[801,3]]},"433":{"position":[[13,1],[21,1],[23,2],[26,1],[28,2],[31,2],[43,1],[45,4],[79,1],[81,2],[84,2],[87,3],[91,2],[99,1],[101,2],[104,3],[115,1],[132,1],[134,2]]},"435":{"position":[[0,2],[6,1],[25,2],[28,3],[40,1],[42,2],[51,2],[54,2],[57,3],[64,1],[85,1],[87,5],[97,1],[99,2],[112,2],[128,1],[130,3],[134,4],[139,2],[142,5],[148,3],[158,2],[178,4],[183,2],[217,1],[227,1],[234,1],[255,1],[257,2],[260,4],[265,2],[268,1],[270,4],[275,2],[278,2],[281,2],[288,2],[291,4],[307,1],[322,2],[328,2],[331,3],[335,2],[352,2],[355,2],[358,1],[360,4],[365,2],[368,2],[377,1],[401,1],[409,1],[424,2],[427,2],[430,3],[434,2]]},"437":{"position":[[6,1],[25,1],[27,2],[30,2],[33,3],[37,6],[44,2],[47,1],[76,2],[79,4],[89,1],[91,5],[97,4],[102,3],[127,1],[129,2],[159,1],[161,5],[167,6],[188,1],[190,2],[240,2],[266,1],[268,4],[282,2],[308,1],[310,5],[316,2],[322,1],[327,2],[346,2],[358,1],[368,1],[370,3],[380,1],[382,1],[384,3],[388,3],[392,3],[396,1],[398,1],[406,1],[416,2],[427,1],[429,3],[433,5],[465,1],[477,1],[488,1],[490,2],[497,1],[506,1],[508,5],[520,1],[552,1],[554,4],[580,1],[594,2],[597,2],[600,3],[604,2],[607,2],[610,3],[614,3],[618,4],[623,3],[627,2],[630,2],[633,3],[637,5],[649,1],[651,3],[655,1],[662,1],[664,2],[667,3],[679,2],[682,2],[685,3],[697,1],[699,2],[702,2],[715,2],[734,1],[754,1],[756,3],[778,1],[780,2],[794,1],[796,2],[799,2],[802,2],[828,1],[830,4],[835,3],[845,1],[867,1],[869,2],[907,2],[910,2],[913,3],[917,3],[921,6],[932,2],[948,1],[950,3],[974,1],[976,2],[994,1],[996,6],[1026,1],[1031,3],[1039,1],[1056,1],[1058,5],[1064,3],[1068,2],[1093,1],[1114,3]]},"439":{"position":[[0,3],[4,3],[8,3],[25,1],[27,3],[31,2],[34,3],[54,1],[56,2],[59,4],[64,1],[72,1],[74,4],[92,1],[112,1],[114,5],[151,1],[181,1],[183,4],[199,1],[201,3],[218,1],[259,1],[264,1],[271,1],[312,1],[314,2],[329,2],[332,6],[368,1],[370,4],[375,1],[381,1],[397,1],[407,2],[414,1],[435,1],[437,2],[440,1],[442,3],[446,2],[449,1],[455,3],[459,7],[483,1],[491,2],[494,3],[498,3],[502,4]]},"441":{"position":[[6,1],[27,1],[29,3],[33,4],[38,3],[56,2],[85,1],[107,1],[122,1],[145,3],[149,1],[178,1],[185,1],[194,1],[198,1],[204,1],[244,1],[246,2],[262,1],[264,3],[279,1],[296,3],[300,3],[310,1],[312,1],[318,1],[320,3],[344,1],[357,1],[359,3],[376,1],[390,5],[396,2],[399,4],[404,2],[422,2],[431,1],[436,1],[450,3],[477,1],[479,1],[485,2],[488,3]]},"443":{"position":[[6,1],[8,2],[11,1],[26,2],[46,1],[48,2],[51,3],[65,1],[91,1],[93,3],[97,2],[117,1],[119,2],[122,3],[137,1],[168,1],[170,5],[176,6],[219,1],[224,1],[234,1],[267,2],[270,3],[280,1],[299,1],[301,4],[306,2],[316,1],[323,1],[325,2],[364,1],[366,4],[371,2],[397,3],[407,2],[410,3],[421,2],[424,5],[430,3],[434,3],[438,3],[442,4],[447,6],[463,3],[467,2],[476,2],[479,3],[483,4],[488,2],[494,7],[513,3],[517,6]]},"445":{"position":[[10,1],[25,1],[43,1],[45,2],[48,2],[57,1],[69,2],[72,1],[74,2],[90,2],[102,3],[122,1],[124,2],[152,1],[162,2],[175,1],[198,3],[202,2],[218,2],[221,3],[225,3],[229,5],[248,1],[271,1],[273,2],[276,2]]},"447":{"position":[[18,1],[20,2],[23,2],[26,3],[30,3],[45,3],[55,3],[59,1],[61,1],[63,4],[68,2],[76,2],[79,2],[87,1],[113,1],[115,4],[123,2],[131,2],[134,1],[150,1],[163,1],[174,3],[191,1],[193,2],[216,1],[218,3],[222,2],[262,2],[274,1],[283,2],[286,4],[291,1],[293,1],[295,3],[299,1],[307,1],[318,2],[321,2],[332,1],[334,2],[337,3],[357,2],[366,4],[379,1],[381,2],[390,1],[397,1],[404,3],[408,2],[411,2],[414,2],[425,2],[428,1],[430,3],[440,1],[442,3],[446,3],[450,4],[455,2],[478,1],[480,2],[483,2],[486,4],[491,2]]},"449":{"position":[[13,3],[23,2],[26,5],[35,2],[53,2],[56,2],[59,1],[61,2],[64,3],[68,6],[75,2],[78,3],[82,1],[84,2],[87,5],[93,4],[98,2],[101,5],[107,4],[112,4],[117,4],[122,2],[125,3],[129,4],[134,2],[150,1],[152,4],[157,4],[167,5],[195,1],[218,1],[220,4],[225,4],[235,5],[241,2],[244,4],[254,5]]},"451":{"position":[[0,3],[17,2],[38,1],[40,2],[62,1],[64,2],[107,2],[110,2],[113,3],[117,2],[126,1],[145,2],[148,3],[157,2],[160,2],[179,1],[199,1],[227,2],[230,2],[233,2],[257,1],[259,1],[261,2],[264,2],[273,1],[292,1],[294,2],[315,1],[328,2],[331,3],[350,1],[359,1],[361,4],[366,2],[369,1],[371,2],[379,2],[388,1],[390,3],[399,1],[401,3],[405,2],[414,3],[418,2],[421,2],[444,1],[472,1],[474,2],[483,1],[498,1],[500,5],[516,1],[525,2],[540,1],[542,2],[568,1],[573,1],[575,2],[578,2],[581,2],[584,2],[587,3],[612,2],[615,3],[633,1],[638,2],[657,1],[659,4],[670,2],[673,3],[677,3],[681,4],[690,1],[692,3],[714,1],[716,4],[721,4],[726,2],[729,2],[732,3],[736,3],[740,3],[744,2],[747,2],[750,2]]},"453":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"455":{"position":[[14,1],[22,1],[52,1],[54,5],[72,2],[75,2],[78,2],[120,2],[138,1],[149,1],[151,2],[168,1],[170,4],[200,1],[202,3],[219,2],[226,3],[247,2],[250,6],[286,1],[288,3],[292,2],[295,3],[317,1],[330,2],[333,2],[363,4],[368,1],[382,2],[401,1],[409,1],[430,2],[433,3],[459,1],[461,5],[467,2],[484,1],[510,2],[513,2],[516,2],[529,1],[544,5],[550,3],[564,2],[567,2],[570,4],[575,2],[578,1],[580,2],[588,2],[637,2],[640,2],[670,5],[676,4],[681,3],[694,1],[696,3],[700,3],[704,2],[707,3]]},"457":{"position":[[4,1],[6,2],[9,5],[15,2],[36,1],[38,2],[41,2],[44,1],[46,3],[50,3],[54,2],[57,5],[79,1],[87,1],[117,1],[131,2],[134,3],[138,4],[143,4],[148,2],[151,3],[155,3],[159,5],[165,3],[169,3],[173,2],[176,5],[182,1],[184,3],[202,4],[213,1],[243,1],[245,5],[263,2],[266,2],[269,2],[281,1],[283,4],[316,2],[325,1],[336,2],[350,2],[359,3],[381,1],[412,1],[438,2],[441,2],[444,2],[447,2],[450,4],[473,1],[481,1],[483,3],[487,3],[497,1],[517,5],[550,2],[553,4],[575,2],[578,2],[595,1],[603,2],[606,1],[608,2],[611,2],[614,2],[654,1],[665,2],[683,1],[703,1],[705,2],[718,1],[798,1],[800,3],[804,2],[825,2],[841,2],[848,4],[860,2],[866,2],[889,2],[892,5],[898,2],[901,2],[912,1],[914,4],[925,1],[927,3],[948,1],[950,4],[955,3],[959,2],[1003,1],[1005,3],[1021,2],[1046,2],[1049,2],[1065,1],[1086,1],[1088,6],[1105,1],[1120,6],[1138,1],[1140,2],[1171,1],[1173,4],[1185,1],[1203,1],[1205,4],[1237,1],[1271,2],[1274,3],[1278,2],[1297,1],[1311,3],[1315,3],[1328,1],[1338,6],[1345,3],[1349,2],[1352,2],[1363,1],[1365,2],[1379,1],[1386,2],[1389,4],[1394,2],[1397,2]]},"461":{"position":[[28,1],[52,1],[54,4],[77,1],[79,4],[84,2],[87,3],[125,1],[127,2],[159,1],[161,2],[200,1],[224,1],[226,2],[288,1],[290,1],[298,1],[300,2],[321,1],[341,1],[368,1],[382,1],[384,2],[387,2],[421,1],[423,3],[427,2],[430,5],[436,2],[462,1],[464,2],[491,1],[493,1],[495,1],[504,3],[508,2],[511,2],[557,1],[559,3],[610,1],[653,1],[655,2],[658,3],[671,2],[702,1],[720,1],[722,2],[734,1],[743,1],[745,2],[868,2],[871,3],[897,1],[917,1],[936,1],[938,2],[972,1],[974,5],[989,2],[992,5],[998,4]]},"463":{"position":[[19,1],[21,4],[26,6],[42,3],[57,1],[59,3],[63,3],[67,1],[69,3],[85,1],[87,4],[92,3],[96,2],[99,1],[101,2],[104,2],[107,2],[110,3],[142,2],[163,5],[169,4],[201,2],[204,2],[229,1],[258,3],[270,1],[288,1],[290,4],[295,3],[299,2],[349,1],[351,2],[394,5],[413,1],[429,1],[438,1],[440,4],[445,2],[466,1],[468,2],[552,1],[558,1],[576,2],[584,2],[587,2],[590,1],[596,1],[614,2],[633,1],[635,2],[638,2],[641,1],[647,1],[665,2],[684,1],[686,2],[779,4],[784,2],[804,2],[816,1],[827,1],[846,1],[848,2],[893,1],[905,1],[992,2],[1013,1],[1015,2],[1041,2],[1064,1],[1066,4],[1071,2],[1074,2],[1086,1],[1088,1],[1100,1],[1102,5],[1108,3],[1148,1],[1250,1],[1275,1],[1310,1],[1321,1],[1323,5],[1329,3],[1333,2],[1336,3],[1340,5],[1346,2],[1349,2],[1352,2],[1355,3],[1359,3],[1363,3],[1367,1],[1369,2],[1442,1],[1499,1],[1501,4],[1516,1],[1531,1],[1557,1],[1559,3],[1572,1],[1574,4],[1586,1],[1588,3],[1592,3],[1596,1],[1604,1],[1606,1],[1608,2],[1633,3],[1637,2],[1640,3],[1644,4],[1649,1],[1651,2],[1654,3],[1663,1],[1665,1],[1677,1],[1679,5],[1702,1],[1704,5],[1710,1],[1712,2],[1715,2],[1727,1],[1729,2],[1793,1],[1828,1],[1830,1],[1946,1],[1948,1],[1950,2],[1953,2],[1974,1],[1976,2],[1979,3],[1983,2],[1995,1],[1997,2],[2003,3],[2007,2],[2010,2],[2041,1],[2043,2],[2055,1],[2057,4],[2062,2],[2065,2],[2078,2],[2081,5],[2087,4],[2092,2],[2104,1],[2106,4],[2122,5],[2128,2],[2131,4],[2136,2],[2139,3],[2143,3],[2147,2],[2150,5],[2156,4],[2161,2],[2168,4],[2173,2],[2176,2],[2179,5],[2185,2],[2188,4],[2193,6],[2200,6],[2230,1],[2239,1],[2265,1],[2267,4],[2272,2],[2321,1],[2423,2],[2453,1],[2455,5],[2480,1],[2482,5],[2500,1],[2502,2],[2505,3],[2531,1],[2533,4],[2538,3],[2548,1],[2572,1],[2574,4],[2579,3],[2592,2],[2595,2]]},"465":{"position":[[17,4],[36,1],[38,2],[58,1],[60,2],[73,3],[77,2],[91,1],[93,2],[96,3],[158,1],[172,1],[174,3],[178,2],[213,1],[215,5],[248,2],[338,1],[353,2],[374,1],[376,2],[398,1],[400,4],[434,2],[489,1],[530,1],[532,2],[550,1],[658,2],[680,1],[682,3],[704,1],[706,2],[709,2],[724,2],[727,2],[739,1],[745,1],[747,5],[753,2],[756,2],[790,1],[803,1],[823,1],[825,4],[830,2],[846,1],[848,2],[851,3],[874,1],[876,3],[880,2],[883,3],[932,1],[938,1],[1042,1],[1058,4],[1082,1],[1084,3],[1106,1],[1108,3],[1112,2],[1121,1],[1145,1],[1147,2],[1159,1],[1161,5],[1179,3],[1209,2],[1212,3],[1232,1],[1234,2],[1237,2]]},"467":{"position":[[27,1],[29,3],[51,1],[71,2],[74,4],[79,3],[90,1],[106,1],[120,2],[123,2],[126,1],[128,3],[132,2],[135,2],[138,2]]},"469":{"position":[[16,1],[18,4],[23,3],[49,2],[70,1],[79,1],[81,2],[84,2],[87,2],[105,1],[117,3],[138,1],[140,2],[147,1],[149,3],[153,1],[155,3],[159,2],[172,1],[174,4],[187,6],[211,1],[213,3],[217,2],[220,2]]},"471":{"position":[[8,1],[10,4],[29,1],[58,1],[60,2],[75,2],[105,1],[107,2],[110,5],[128,1],[142,1],[157,1],[159,3],[182,1],[194,2],[197,2],[200,2],[218,2],[221,4],[226,2]]},"475":{"position":[[16,1],[18,2],[47,3],[80,1],[82,2],[85,2],[102,1],[116,2],[214,1],[222,1],[249,1],[251,2],[272,2],[320,1],[346,1],[348,2],[362,2],[404,1],[421,1],[423,3],[427,4],[449,1],[451,2],[467,2],[476,2],[483,3],[487,2],[518,1],[520,4],[525,5],[531,2],[534,3],[538,1],[540,2],[543,3],[547,2],[550,2],[553,2]]},"477":{"position":[[6,2],[23,1],[32,1],[43,2],[53,1],[66,1],[68,4],[73,2],[76,2],[85,2],[101,2],[104,2],[113,4],[132,1],[134,3],[138,2],[141,3],[145,2],[148,2],[151,2],[181,5],[187,2],[190,2]]},"479":{"position":[[8,2],[11,3],[37,1],[60,2],[63,2],[66,1],[68,2],[71,2],[74,2],[91,1],[114,2],[117,2],[120,1],[124,2],[127,4],[132,3],[136,2],[139,3],[143,2],[146,6],[159,2],[166,1],[180,2]]},"482":{"position":[[12,1],[14,2],[29,1],[58,3],[62,2],[70,1],[87,1],[89,4],[123,1],[125,3],[129,2],[136,2],[139,3],[143,2],[154,2],[171,2],[174,2],[192,1],[208,1],[210,2],[223,1],[238,2],[241,2]]},"484":{"position":[[14,1],[28,1],[46,1],[58,2],[61,2],[83,1],[100,3],[111,2],[114,2],[122,1],[143,1],[145,2],[148,4],[165,1],[174,2],[177,2],[193,3],[202,1],[211,2],[214,3],[218,2],[221,2],[224,3],[228,2],[231,4],[236,4],[255,1],[265,3],[277,2],[280,2],[283,3],[287,2]]},"487":{"position":[[18,1],[20,3],[24,2],[27,3],[37,1],[39,4],[44,2],[57,1],[59,5],[75,2],[78,1],[80,2],[83,2]]},"489":{"position":[[17,5],[37,1],[39,2],[42,2],[45,1],[47,4],[52,2],[55,3],[59,2],[89,2],[100,2],[103,2],[106,2],[109,2],[132,1],[141,1],[143,2],[154,1],[156,2],[159,1],[161,2],[178,1],[180,3],[184,2],[187,2],[217,1],[231,2],[254,2],[257,1],[259,2],[262,4],[267,1],[269,2],[277,1],[279,2]]},"491":{"position":[[4,1],[23,1],[25,2],[40,2],[43,2],[46,4],[51,1],[53,3],[70,3],[74,2],[92,3],[96,4],[101,2],[104,2],[121,1],[136,1],[138,5],[144,4],[149,5],[169,2],[172,3],[176,4],[181,3],[185,4],[190,4],[195,2],[198,1],[200,1],[202,3],[206,2],[219,1],[221,3],[233,1],[235,4],[240,2]]},"494":{"position":[[21,1],[23,2],[47,2],[71,1],[93,4],[98,2],[101,2],[112,1],[114,3],[145,3],[155,1],[157,2],[160,2]]},"496":{"position":[[0,3],[13,1],[19,1],[21,2],[24,2],[50,1],[52,2],[66,1],[73,2],[103,1],[117,2],[120,2]]},"498":{"position":[[14,1],[31,1],[38,4],[50,1],[63,2],[66,3],[70,1],[72,2],[75,3],[79,2],[101,1],[103,2],[133,2],[155,1],[157,5],[163,2],[166,1],[174,1],[198,2],[223,1],[225,1],[227,5],[243,1],[258,1]]},"500":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"502":{"position":[[0,2],[17,1],[24,1],[39,1],[41,3],[45,4],[50,5],[56,3],[90,1],[92,1],[94,4],[99,3],[109,1],[111,4],[116,3],[120,1],[122,5],[173,1],[192,2],[209,1],[211,1],[213,2],[248,1],[256,2],[259,1],[261,4],[266,2],[277,2],[280,2],[295,1],[319,3],[323,2],[339,1],[357,2],[360,4],[378,3],[382,2],[416,2],[435,1],[464,1],[490,1],[492,2],[515,1],[517,3],[521,3],[525,3],[550,1],[574,1],[576,2],[579,2],[582,3],[586,5],[592,2],[595,3],[610,1],[642,3],[646,3],[672,2],[685,2],[702,1],[704,4],[745,1],[747,2],[764,4],[769,2],[792,2],[795,2],[798,2],[801,2],[818,1],[820,4],[842,1],[850,1],[866,5],[907,3],[911,2],[914,3],[918,1],[920,3],[960,1],[962,2],[965,5],[971,2],[974,6],[981,3],[985,3],[989,2]]},"504":{"position":[[0,2],[7,1],[37,1],[39,4],[44,3],[48,2],[67,1],[87,1],[89,3],[114,1],[116,4],[127,1],[157,1],[171,3],[189,1],[191,3],[203,1],[232,1],[234,4],[252,2],[287,2],[312,1],[314,5],[320,2],[323,3],[337,1],[345,2],[348,4],[385,1],[399,1],[401,4],[423,3],[427,4],[432,3],[436,2],[439,3],[443,5],[449,1],[451,3],[500,3],[504,3],[508,3],[526,3],[530,3],[541,1],[560,2],[577,1],[622,1],[643,1],[645,4],[675,1],[677,2],[716,1],[718,4],[723,4],[750,1],[752,3],[756,3],[773,2],[776,3],[794,1],[831,2],[841,1],[843,2],[846,2],[857,1],[859,2],[862,2],[865,3],[886,1],[896,2],[934,2],[948,1],[950,3],[975,1],[977,4],[999,2],[1026,1],[1028,5],[1060,1],[1062,5],[1068,2],[1086,1],[1107,1],[1109,5],[1137,3],[1141,3],[1145,4],[1150,1],[1152,2],[1155,2],[1158,4],[1163,2],[1187,1],[1217,1],[1219,2],[1227,2],[1230,3],[1234,4],[1239,3],[1276,2],[1293,1],[1318,1],[1335,1],[1363,1],[1365,2],[1385,3],[1411,1],[1413,2],[1426,2],[1429,2],[1439,1],[1456,1],[1493,2],[1496,2],[1520,1],[1528,1],[1552,2],[1555,4],[1560,2],[1602,4],[1636,3],[1654,1],[1683,1],[1685,3],[1699,1],[1716,2],[1719,3],[1751,2],[1797,1],[1825,1],[1833,2],[1856,1],[1868,2],[1871,2],[1891,1],[1893,4],[1930,1],[1936,3],[1940,2],[1943,3],[1957,1],[1959,2],[1962,3],[1966,1],[1974,1],[1976,2],[1979,2],[1982,2],[2014,2],[2065,1],[2092,1],[2094,4],[2116,1],[2118,3],[2138,3],[2142,3],[2153,1],[2164,4],[2169,3],[2173,2],[2176,3],[2180,2],[2183,2],[2186,2],[2252,1],[2293,4],[2312,2],[2371,1],[2402,2],[2405,2],[2408,3],[2412,2],[2428,2],[2431,2],[2472,2],[2491,1],[2520,1],[2522,3],[2536,1],[2583,3],[2600,2]]},"508":{"position":[[22,2],[25,3],[29,2],[78,1],[86,1],[97,2],[105,2],[123,1],[125,2],[142,1],[150,1],[170,3],[174,2],[202,1],[215,1],[224,1],[226,2],[252,1],[260,1],[262,4],[267,2],[297,2],[300,2],[303,2],[335,1],[337,2],[340,3],[344,2],[347,3],[355,4],[374,1],[376,4],[381,2],[384,2],[387,1],[396,3],[400,5],[406,3],[416,1],[418,2],[421,1],[423,3],[427,2],[430,3],[440,1],[442,2],[445,2],[448,3],[452,4],[457,3],[461,3],[465,5],[471,4],[476,3],[502,3],[506,4]]},"510":{"position":[[22,1],[24,2],[33,1],[41,2],[44,2],[74,1],[76,2],[84,2],[114,2],[144,1],[146,4],[168,1],[195,1],[207,2],[225,1],[245,4],[271,1],[273,4],[292,1],[299,1],[314,1],[316,4],[330,2],[333,4],[348,2]]},"512":{"position":[[14,1],[16,4],[42,2],[60,1],[86,1],[100,2],[103,2],[106,2],[109,3],[120,3],[142,1],[144,4],[149,3],[153,3],[187,1],[189,5],[195,3],[216,1],[218,5],[236,4],[241,3],[245,5],[251,1]]},"515":{"position":[[14,1],[43,2],[64,1],[79,1],[81,2],[84,2],[101,1],[103,5],[113,2],[126,1],[128,4],[133,3],[154,1],[174,1],[190,1],[192,3],[196,1],[198,3],[219,2],[222,3],[226,5],[232,2],[235,4],[240,2],[243,4],[248,3],[252,2],[267,2],[270,2],[300,1],[320,2],[323,2],[332,1],[334,2],[358,1],[383,1],[385,1],[400,1],[402,2],[425,1],[432,1],[447,2],[450,2],[466,1],[488,1],[501,1],[507,1],[509,2],[529,3],[542,1],[554,1],[556,4],[574,2],[593,1],[626,1],[654,1],[668,2],[684,1],[688,1],[709,1],[752,1],[767,1],[769,2],[774,1],[778,1],[780,5],[786,2],[789,3],[793,3],[809,1],[841,1],[843,4],[848,3],[874,3],[878,2],[881,3],[907,1],[909,2],[918,1],[926,2],[933,1],[935,2],[955,1],[957,3]]},"517":{"position":[[12,1],[14,2],[44,1],[46,2],[66,1],[68,2],[78,1],[101,1],[103,2],[110,1],[112,2],[122,1],[128,1],[150,1],[152,2],[174,1],[176,2],[179,2],[182,3],[195,1],[224,1],[230,2],[233,3],[237,3],[253,1],[261,1],[263,6],[279,1],[281,4],[292,1],[294,4],[304,1],[306,4],[316,2],[319,3],[335,3],[339,1],[341,2]]},"519":{"position":[[0,3],[4,3],[25,2],[51,1],[53,4],[58,3],[88,1],[90,3],[94,4],[99,1],[101,3],[122,1],[124,2],[154,1],[191,1],[193,4],[198,2],[225,2],[250,1],[273,3],[277,4],[282,3],[286,3],[312,3],[316,3],[320,1],[322,1],[324,2],[327,3],[331,4],[364,1],[366,3],[397,1],[423,1],[425,2],[452,1],[454,3],[458,3],[462,2],[491,1],[517,1],[546,1],[565,1],[580,6],[608,1],[610,2],[613,2],[616,2],[644,1],[668,2],[671,2],[674,3],[678,5],[684,2]]},"521":{"position":[[15,2],[18,2],[31,1],[39,2],[84,1],[86,3],[90,2],[110,1],[134,4],[139,2],[150,2],[153,3],[173,1],[182,2],[185,2],[202,1],[204,4],[229,1],[231,2],[238,1],[240,4],[245,3],[249,4],[254,2],[288,1],[314,1],[316,3],[320,3],[324,4],[329,2],[332,5],[338,2],[341,2],[344,7],[352,4],[374,1],[406,2],[409,4],[425,1],[454,3],[458,3],[484,1],[486,2]]},"523":{"position":[[7,1],[30,2],[33,3],[37,3],[41,3],[60,1],[81,2],[84,4],[89,4],[94,3],[98,2],[114,2],[131,2],[154,1],[178,1],[180,2],[183,5],[198,2],[235,1],[237,2],[240,4],[245,1],[262,1],[282,2],[302,1],[326,1],[346,1],[348,4],[371,1],[380,2],[383,2],[386,2],[423,1],[439,1],[441,3],[481,1],[483,2],[507,1],[565,3],[580,1],[582,2],[585,2],[588,1],[603,2],[606,1],[608,2],[630,2],[633,3],[637,5],[643,5],[649,5],[679,1],[681,2],[684,4],[689,3],[715,3],[719,2]]},"525":{"position":[[9,1],[17,4],[35,1],[41,3],[45,2],[48,3],[63,3],[67,2],[70,2],[73,3],[94,1],[96,2],[99,3],[125,1],[139,2],[142,2],[160,3],[164,1],[166,3],[190,3],[194,3],[198,3],[202,2],[205,6],[212,2],[215,2],[218,3],[222,2],[225,1],[227,2],[246,2],[249,1],[251,3],[274,2],[277,3],[294,1],[311,2],[328,1],[330,4],[375,1],[377,4],[382,2],[385,2],[388,3],[411,1],[417,2],[434,2],[466,2],[469,2],[484,1],[486,4],[518,1],[520,4],[540,1],[551,2],[568,2],[587,1],[597,1],[599,5],[605,2],[621,1],[635,1],[651,1],[667,2],[670,2],[673,3],[683,1],[696,2],[713,1],[715,1],[731,2],[734,3],[738,1],[740,3],[744,2],[747,1],[758,1],[760,2],[779,1],[781,2],[784,3],[802,2],[805,2],[808,2],[811,2]]},"529":{"position":[[17,1],[67,1],[108,1],[110,2],[123,1],[131,1],[133,2],[136,3],[164,1],[166,4],[171,2],[174,2],[186,1],[210,1],[212,4],[232,2]]},"531":{"position":[[22,1],[24,3],[43,1],[45,2],[74,1],[91,1],[93,2],[119,1],[135,1],[142,5],[148,1],[150,2],[159,1],[161,2],[204,1],[213,1],[215,2],[228,1],[239,1],[248,3],[258,1],[260,3],[274,1],[285,2]]},"533":{"position":[[12,1],[44,1],[46,3],[67,1],[75,1],[99,3],[103,2],[114,1],[116,4],[121,3],[142,1],[144,3],[148,3],[152,4],[157,3],[161,3],[165,2],[168,2],[190,1],[192,2],[207,1],[209,1],[211,2],[234,1],[236,4],[241,2],[261,1],[263,2],[266,2],[269,3],[273,3],[292,1],[294,3],[298,5],[326,1],[328,6],[335,1],[337,3],[355,2],[366,1],[371,1],[390,3],[394,4],[399,3],[403,5],[409,2],[412,3],[416,2],[419,4],[424,3],[428,3],[436,2],[439,4],[463,1],[465,2],[468,4],[473,3],[477,1],[479,3],[490,3],[500,1],[502,4],[524,3],[545,1],[559,1],[576,1],[578,2],[589,1],[591,3],[595,2],[598,2]]},"535":{"position":[[14,1],[16,2],[46,1],[80,1],[82,3],[103,1],[113,1],[146,1],[164,1],[166,3],[196,2],[199,4],[221,1],[240,2],[243,1],[245,3],[255,2],[258,4],[263,3],[293,5],[299,5],[305,4],[310,2],[327,1],[329,4],[356,3],[360,2],[363,2]]},"537":{"position":[[14,1],[16,3],[39,1],[56,1],[58,4],[81,1],[83,3],[108,1],[122,2],[125,3],[152,1],[154,4],[159,1],[161,4],[180,1],[182,3],[209,2],[217,1],[230,2],[233,4],[238,1],[240,3],[244,3],[252,3],[256,3],[260,3],[264,1],[266,2],[315,2],[318,4],[323,3],[340,1],[357,5],[380,1],[413,1],[432,1],[434,3],[438,2],[441,3],[445,3],[474,1],[476,3],[480,3],[498,1],[517,1],[536,3],[540,5],[560,1],[562,3],[566,2],[569,2],[589,1],[599,2],[609,1],[611,3],[615,5],[634,1],[636,3],[640,5],[646,2],[649,2],[652,2],[655,6],[662,4],[667,1],[669,2],[672,3],[676,3],[680,3],[684,4],[689,3],[693,1],[695,1],[697,3],[701,2],[731,1],[733,3],[737,2],[740,1],[742,3]]},"539":{"position":[[7,2],[10,4],[29,1],[31,2],[41,1],[51,4],[56,1],[71,4],[76,2],[79,3],[83,4],[88,3],[92,3],[115,1],[134,1],[136,4],[141,1],[143,3],[157,1],[168,1],[170,2],[173,2],[176,1],[178,1],[180,3],[190,2],[202,1],[204,4],[209,3],[213,3],[217,4],[222,5],[236,4],[241,2],[244,3],[248,3],[252,4],[257,2],[277,1],[296,2],[299,3],[303,4],[308,3],[312,5],[327,1],[350,1],[352,2],[355,3],[359,2],[362,2],[365,3],[369,2],[372,4],[377,5]]},"541":{"position":[[21,3],[25,3],[39,1],[62,1],[64,4],[69,4],[91,1],[93,2],[103,2],[121,1],[123,3],[144,1],[146,5],[158,1],[176,1],[178,2],[181,4],[186,3],[190,3],[194,5],[207,2],[217,1],[230,1],[232,3],[236,3],[240,1],[242,1],[244,3],[254,2],[257,3],[266,1],[268,4],[273,3],[277,2],[280,2],[283,4],[288,3],[292,3],[296,2],[299,3],[303,3],[307,3]]},"543":{"position":[[0,1],[2,3],[60,1],[79,2],[117,1],[146,2],[149,3],[169,1],[206,1],[208,2],[250,1],[269,1],[298,2],[301,3],[305,2],[308,2],[311,2],[322,1],[324,2],[327,3],[349,3],[353,2],[356,4],[361,3],[365,2],[368,2],[371,3],[375,2],[392,1],[394,2],[404,4],[441,1],[443,2],[460,1],[468,2],[471,5],[484,4],[489,4],[494,2],[497,3],[501,2],[504,1],[506,2],[509,2],[529,3],[533,2],[568,2],[571,2],[579,3],[583,2],[598,2],[601,2]]},"545":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"547":{"position":[[11,1],[13,5],[31,4],[36,2],[39,3],[43,2],[46,3],[76,2],[105,1],[132,1],[163,1],[165,2],[184,1],[186,2],[209,1],[211,2],[214,2],[217,2],[225,2],[240,1],[253,1],[255,5],[266,1],[288,2],[299,3],[307,3],[311,4],[319,2],[346,1],[354,3],[358,1],[360,2],[363,2],[371,1],[381,1],[383,3],[387,4],[410,2],[433,1],[446,2],[465,1],[467,2],[470,3],[474,2],[477,4],[487,1],[489,2],[492,2]]},"549":{"position":[[0,2],[23,1],[25,4],[30,2],[33,3],[41,1],[43,5],[54,1],[67,1],[69,1],[71,5],[89,1],[91,4],[96,2],[99,5],[105,4],[110,2],[113,1],[115,5],[121,3],[125,2],[128,5],[143,3],[156,1],[158,2],[161,2],[164,3],[168,4],[173,3],[177,3],[186,2],[207,1],[209,2],[212,2],[239,1],[241,4],[246,5],[252,2],[255,2],[258,1],[260,3],[264,5],[270,4],[281,4],[295,3],[299,3],[303,1],[305,2],[308,3],[312,5],[328,3],[332,4],[337,3],[341,2],[344,4],[383,1],[385,3],[413,1],[415,5],[421,2],[424,2],[427,3],[431,4],[453,1],[462,1],[464,3],[468,2],[488,1],[490,2],[493,4],[498,3],[502,4],[543,1],[545,2],[568,1],[570,3],[574,2],[594,1],[608,1],[610,3],[614,2],[645,1],[647,5],[653,4],[658,2],[673,1],[675,5],[681,4],[686,1],[688,3],[703,2],[706,2],[714,1],[716,4],[730,1],[748,1],[757,1],[759,3],[763,2],[766,3],[775,1],[777,2],[780,1],[782,2],[785,3],[794,2],[797,2],[818,1],[820,2],[828,1],[830,3],[834,2],[837,2],[845,3],[849,4],[854,2],[857,1],[859,2],[862,2],[878,1],[887,2],[896,1],[898,2],[905,1],[911,1],[913,4],[923,1],[925,5],[931,2],[934,2],[937,4],[942,1],[968,2],[971,2],[979,1],[1000,1],[1002,3],[1006,1],[1008,1],[1010,4],[1015,2],[1018,2],[1021,1],[1043,2],[1046,4],[1061,1],[1063,2],[1083,1],[1085,5],[1100,2],[1103,3],[1107,3],[1137,1],[1139,3],[1143,1],[1145,3],[1149,2],[1152,2],[1174,1],[1191,1],[1193,3],[1197,1],[1199,2],[1202,1],[1226,1],[1228,5],[1252,1],[1254,2],[1262,1],[1264,2],[1267,5],[1273,3],[1277,3],[1295,2],[1298,3],[1302,3],[1306,2],[1309,2]]},"551":{"position":[[12,5],[18,3],[22,5],[28,1],[30,3],[34,2],[37,2],[40,2],[61,1],[69,1],[89,1],[177,1],[244,1],[250,1],[272,2],[303,1],[333,1],[377,1],[400,1]]},"553":{"position":[[5,1],[26,1],[28,4],[33,2],[36,8],[45,1],[47,3],[54,1],[62,2],[65,2],[72,2],[128,1],[130,2],[133,2],[152,1],[175,5],[181,4],[217,1],[219,2],[274,1],[276,2],[288,1],[299,1],[316,2],[331,2],[365,1],[367,3],[371,1],[383,4],[388,2],[400,1],[402,5],[408,6],[427,1],[578,1],[662,1],[664,3],[668,1],[686,2],[689,3],[693,2],[729,1],[731,5],[737,1],[739,1],[751,1],[788,1],[808,1],[810,2],[813,3],[835,1],[837,2],[857,1],[859,4],[864,5],[870,3],[874,2],[877,1],[879,3],[912,1],[914,2],[941,1],[943,2],[969,1],[1003,1],[1005,1],[1007,2],[1010,3],[1037,1],[1039,3],[1043,3],[1088,3],[1111,1],[1113,2],[1116,2],[1128,1],[1130,3],[1268,1],[1299,1]]},"555":{"position":[[0,2],[3,5],[14,1],[16,5],[36,2],[39,1],[53,2],[56,3],[60,5],[66,2],[69,4],[74,3],[91,1],[101,1],[103,5],[109,4]]},"557":{"position":[[0,2],[11,1],[13,3],[17,2],[20,1],[22,3],[26,3],[30,1],[81,1],[95,3],[99,1],[101,2],[209,1],[211,3],[215,3],[233,1],[235,4],[256,1],[268,1],[270,4],[275,2],[286,1],[288,4],[307,1],[309,2],[312,3],[316,4],[335,1],[337,2],[361,1],[363,3],[367,2],[384,4],[389,1],[395,1],[397,4],[402,4],[407,2],[416,1],[418,3],[422,3],[438,1],[448,1],[450,3],[454,2],[457,4],[462,5],[468,5],[488,1],[490,6],[497,2],[508,1],[510,2],[513,2],[516,3],[520,3],[524,2],[527,1],[529,1],[531,3]]},"559":{"position":[[0,1],[2,3],[6,5],[26,1],[28,4],[33,4],[38,3],[42,3],[46,5],[52,4],[57,2],[60,4],[65,3],[69,4],[74,5],[80,5],[95,1],[97,3],[112,1],[114,2],[117,4],[122,2],[136,2],[139,1],[150,3],[154,4],[159,3],[163,4],[168,2],[171,2]]},"561":{"position":[[0,1],[2,3],[18,1],[20,3],[24,4],[29,2],[32,5],[38,2],[41,2]]},"563":{"position":[[0,2],[11,1],[26,1],[28,5],[34,4],[39,3],[43,3],[47,1],[65,1],[67,2],[80,1],[82,4],[87,2],[90,5],[110,1],[121,2],[139,1],[167,1],[169,3],[173,1],[175,2],[187,3],[209,2],[212,3],[216,4],[221,3],[225,2],[228,2],[231,5],[310,1],[312,2],[315,2],[356,1],[370,1],[376,1],[394,1],[396,2],[399,3],[497,1],[547,1],[558,1],[567,1],[585,2],[588,2],[595,1],[601,1],[623,1],[625,2],[637,1],[656,1],[666,1],[668,3],[678,1],[680,5],[686,1],[703,1],[721,1],[723,2],[733,1],[746,1],[748,2],[764,1],[766,3],[770,3],[796,1],[803,1],[818,1],[825,1],[865,1],[883,1],[889,1],[893,2],[896,5],[919,1],[929,1],[940,1],[944,2],[947,2],[950,2],[975,2],[994,1],[1013,1],[1019,1],[1021,2],[1024,2],[1032,2],[1035,3],[1039,2],[1051,1],[1060,2],[1063,2],[1066,4],[1071,3],[1083,2],[1086,2],[1089,2],[1092,1],[1102,1],[1108,1],[1110,4],[1115,1],[1132,1],[1143,1],[1145,3],[1149,4],[1154,2]]},"565":{"position":[[0,2],[19,1],[26,1],[33,4],[38,2],[41,2],[54,1],[63,1],[65,2],[68,4],[73,3],[77,5],[83,3],[87,6],[98,1],[100,4],[119,2],[122,3],[126,2],[149,1],[151,3],[155,3]]},"567":{"position":[[0,2],[19,1],[21,3],[25,2],[35,2],[51,1],[53,4],[58,2],[61,2],[64,1],[66,2],[69,4],[74,2],[77,2],[80,4],[103,1],[105,3],[109,2]]},"569":{"position":[[12,2],[17,2],[34,1],[36,3],[111,1],[121,3],[147,1],[170,1],[172,4],[177,1],[179,1],[181,1],[200,1],[211,1],[213,4],[218,3],[222,4],[231,1],[240,3],[261,2],[264,4],[269,4]]},"571":{"position":[[0,2],[3,1],[5,3],[9,3],[13,1],[15,2],[18,2],[21,3],[25,2],[46,1],[53,2],[56,4],[61,2],[81,1],[83,2],[93,1],[95,3],[99,3],[103,3],[140,1],[142,2],[145,2],[157,3],[161,2],[175,1],[182,3],[192,2],[200,1],[202,2],[210,1],[217,2],[229,1],[240,1],[251,2],[254,2],[268,3],[280,2],[290,1],[298,4],[313,1],[324,3],[328,2],[331,3],[346,2],[349,1],[355,2],[358,2],[366,1],[368,3],[372,2],[375,2],[378,2],[381,2],[389,1],[391,2],[394,2],[410,1],[412,4],[417,4],[422,1]]},"573":{"position":[[17,1],[25,2],[33,2],[41,2],[159,1],[161,4],[166,2]]},"575":{"position":[[0,2],[3,3],[7,3],[11,3]]},"577":{"position":[[0,4],[14,3],[18,3],[22,1],[30,1],[32,3],[36,2],[68,1],[70,2]]},"579":{"position":[[13,1],[15,4],[20,3],[24,2],[27,3]]},"581":{"position":[[12,3],[30,1],[32,4],[37,4],[42,3],[46,5],[52,2],[55,3],[59,5],[65,3],[81,1],[94,1],[96,3],[100,2],[103,2],[126,1],[155,1],[179,1],[216,1],[234,1]]},"583":{"position":[[24,1],[26,5],[47,4],[52,2],[73,3],[88,1],[90,2],[93,2],[102,4],[107,3],[122,1],[124,2],[127,3],[142,2],[145,2],[168,1],[200,1],[228,1],[235,1],[270,1]]},"585":{"position":[[15,1],[37,3],[55,2],[72,1],[74,1],[98,1],[105,3],[122,1],[124,4],[129,3],[133,1],[135,4],[173,1],[175,4],[194,1],[207,3],[221,4],[226,3],[230,4],[235,4],[273,1],[275,4],[280,2],[283,3],[302,1],[304,3],[308,2],[344,1],[346,4],[351,1],[353,1],[355,4],[360,2],[363,2],[380,1],[382,3],[419,1],[421,3],[425,1],[427,2],[430,6],[437,4],[497,1],[550,1],[554,1],[567,1],[659,1],[661,2],[692,1],[708,1],[732,1],[755,1]]},"587":{"position":[[0,2],[19,1],[49,1],[67,1],[69,2],[72,3],[76,6],[83,4],[88,2],[100,1],[111,2],[119,1],[121,2],[144,1],[176,1],[279,1],[286,1],[288,3],[308,1]]},"589":{"position":[[8,2],[16,1],[23,3],[27,2],[30,2],[58,1],[92,1],[115,2],[118,2],[126,1],[128,3],[132,2],[135,2],[138,1],[170,1],[178,1],[180,2],[188,1],[204,1],[206,2]]},"591":{"position":[[8,1],[10,2],[13,1],[15,3],[28,2],[36,1],[48,1],[50,1],[52,2],[55,2],[63,1],[77,3],[81,3],[85,2],[88,2]]},"593":{"position":[[5,1],[11,2],[31,1],[33,5],[39,4],[44,3],[61,1],[69,3],[73,4],[78,2]]},"595":{"position":[[21,1],[23,2],[34,2],[37,4],[46,4],[51,2],[57,1],[59,5],[65,2],[74,2],[77,4],[82,2],[85,3],[89,1],[91,2],[133,1],[140,2],[143,2],[166,1],[168,2],[175,4],[180,2],[183,1],[185,2],[188,2]]},"598":{"position":[[5,1],[7,2],[10,1],[12,1],[14,3],[18,1],[20,3],[24,3],[28,4],[33,3],[37,2],[40,2],[43,1],[45,2],[48,3],[52,3],[80,1],[82,3],[86,3],[90,3],[99,1],[101,4],[106,2],[109,2],[112,3],[116,4],[121,3],[134,1],[136,5],[176,1],[182,2],[185,4]]},"600":{"position":[[0,4],[22,2],[25,5],[31,5],[48,1],[50,3],[75,1],[86,2],[94,1],[101,1],[103,4],[112,2],[120,4],[135,1],[137,5],[164,1],[175,2],[183,1],[190,1],[192,4],[207,1],[209,2],[222,1],[224,4],[229,3],[243,2],[256,1],[279,2],[303,1],[305,2],[308,3],[312,2],[315,6],[331,1],[342,1],[344,1],[355,2],[358,3],[362,3],[366,4],[371,2],[374,2],[382,1],[386,1],[388,2],[391,3],[411,1],[413,3],[417,2],[420,1],[422,3],[426,5]]},"602":{"position":[[0,4],[5,2],[8,2],[15,3],[24,1],[26,5],[32,3],[36,5],[74,2],[86,1],[88,1],[90,2],[93,3],[97,2],[130,1],[132,2],[135,2],[155,1],[157,2],[160,1],[162,3],[166,2]]},"604":{"position":[[17,1],[39,1],[41,4],[46,2],[49,3],[71,1],[73,4],[113,4],[174,1],[203,1],[205,2],[208,2],[263,1],[290,1],[292,3],[305,2],[366,1],[393,1],[404,1],[406,3],[410,5],[416,2],[419,2],[441,4],[446,4],[471,1],[473,2],[563,1],[749,1],[776,1],[778,4],[807,1],[826,1],[834,5],[840,1],[858,2],[863,1],[874,1],[876,3],[880,2],[885,1],[887,3],[891,2],[898,1],[904,1],[906,5],[919,1],[921,3],[925,3],[929,2],[938,2],[941,2],[944,2],[947,2],[950,2],[953,3],[957,1],[959,1],[961,3],[982,1],[1005,3],[1031,1],[1053,1],[1076,3],[1102,1],[1116,1],[1127,1],[1129,4],[1170,3],[1174,3],[1184,1],[1191,1],[1198,1],[1200,4],[1205,2]]},"606":{"position":[[6,1],[15,1],[17,3],[26,1],[28,3],[32,1],[65,1],[73,2],[76,2],[100,1],[123,2],[126,2],[146,1],[148,2],[151,3],[155,4],[181,1],[183,2],[186,1],[188,2],[191,2],[194,3],[230,1],[232,1],[234,2],[237,3],[249,1],[251,3],[255,2]]},"608":{"position":[[0,3],[20,1],[26,2],[29,5],[35,2],[38,3],[46,1],[64,1],[91,1],[121,1],[123,4],[136,3],[150,1],[168,1],[204,3],[208,3],[257,1],[275,2],[293,2],[296,3],[300,2],[314,1],[320,1],[347,2],[364,1],[366,4],[416,2],[419,1],[427,2],[430,2],[433,3],[437,2],[440,1],[442,2],[461,1],[477,1],[479,5],[489,1],[491,1],[493,2],[496,5],[502,4],[523,1],[525,2],[532,1],[534,2],[537,2],[540,3],[544,2],[551,1],[576,1],[578,4],[583,3],[603,1],[609,1],[611,4],[616,2],[629,2],[632,2],[635,2],[638,3],[642,2],[645,2],[653,1],[660,1],[662,3]]},"610":{"position":[[4,1],[18,2],[21,2],[24,2],[27,2],[30,1],[32,3],[36,1],[38,1],[40,3],[49,2],[52,3],[56,2],[77,1],[79,3],[99,1],[101,3],[105,2],[108,2],[111,4],[132,1],[134,4],[139,3],[143,2],[163,1],[165,2],[186,1],[188,4],[193,2],[196,2],[211,2],[219,1],[221,3],[225,4],[235,1],[246,1],[262,2],[281,1],[288,2],[291,4],[296,2]]},"612":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"614":{"position":[[14,1],[34,1],[36,1],[43,1],[45,2],[54,2],[57,3],[61,3],[79,1],[81,4],[113,1],[115,3],[135,1],[137,5],[149,2],[161,1],[163,3],[167,2],[170,3],[174,4],[199,1],[201,2],[214,2],[217,3],[242,1],[244,3],[248,4],[253,3],[257,4],[262,2],[265,2],[268,3],[272,3],[276,2],[346,1],[369,1],[371,3],[402,1],[404,2],[407,1],[432,1],[434,5],[446,2],[449,2],[466,1],[500,1],[502,2],[509,5],[515,2],[518,3],[522,2],[534,1],[543,1],[545,4],[550,3],[554,2],[557,3],[561,2],[564,4],[593,1],[602,1],[611,3],[640,1],[642,2]]},"616":{"position":[[45,1],[63,1],[65,1],[67,2],[70,3],[74,3],[78,1],[80,4],[120,1],[122,2],[129,1],[131,3],[135,2],[138,5],[144,2],[147,4],[152,5],[158,3],[162,4],[167,3],[171,3],[175,4],[180,3],[184,1],[186,3],[195,1],[197,2],[200,5],[206,2],[209,3],[213,4],[234,1],[236,3],[240,2],[243,3],[247,2],[269,1],[305,1],[307,2],[310,4],[319,1],[359,2],[371,1],[373,2],[379,1],[385,5],[391,4],[425,1],[427,2],[430,3],[450,1],[452,1],[454,3],[458,2],[461,4],[466,4],[471,3],[491,2],[494,2],[497,2],[500,2],[503,2],[506,2],[509,1],[511,3],[515,4],[520,2],[523,3],[533,1],[563,1],[565,2],[590,1],[604,2],[607,1],[628,1],[630,5],[655,1],[657,4],[674,1],[676,1],[678,2],[692,2],[695,2],[705,1],[707,3],[724,1],[726,4],[731,1],[733,2],[736,3],[740,4],[775,2],[793,1],[795,4],[812,1],[814,5],[829,1],[831,1],[833,2],[850,2],[873,3],[877,2],[880,2],[888,2],[891,4],[896,4],[901,2],[904,4],[909,4],[914,2],[917,3],[921,1],[928,1],[958,1],[974,1],[1006,1],[1008,3],[1012,2],[1015,1],[1017,3],[1042,2],[1045,5],[1051,2],[1054,1],[1056,3],[1060,4],[1079,2],[1082,2],[1097,1],[1099,2],[1125,1],[1127,2],[1130,2],[1142,1],[1153,2],[1156,3],[1181,1],[1215,2],[1240,1],[1242,2],[1245,3],[1249,3],[1262,1],[1285,2],[1288,5],[1294,2],[1307,1],[1317,1],[1319,3],[1327,1],[1340,1],[1348,2],[1396,2],[1399,2],[1402,2],[1452,1],[1454,1],[1456,2],[1459,2],[1462,2],[1465,5],[1475,1],[1493,1],[1495,4],[1500,2],[1503,5],[1514,1],[1523,1],[1543,1],[1545,2],[1552,1],[1554,1],[1568,1],[1581,1],[1583,4],[1606,1],[1608,5],[1614,2]]},"619":{"position":[[8,1],[10,1],[12,4],[34,1],[36,2],[46,1],[63,1],[65,4],[83,1],[90,1],[105,1],[121,2],[124,2],[141,1],[149,2],[152,2],[175,1],[177,4],[198,1],[200,2],[222,4],[249,1],[258,6],[265,3],[276,3],[280,4],[285,2],[300,1],[328,1],[330,6],[344,2],[351,1],[373,1],[402,1],[420,1],[422,3],[442,1],[444,2],[447,5],[453,4],[458,3],[462,3],[473,1],[491,1],[493,1],[495,2],[589,4],[594,2],[602,1],[604,2],[621,1],[623,3],[627,6],[634,2],[637,1],[644,1],[665,1],[667,2],[670,3],[681,1],[683,2],[693,1],[707,1],[709,2],[719,4],[724,2],[741,1],[743,2],[756,4],[761,3],[765,2],[768,3],[786,1],[788,5],[817,2],[820,3],[836,1],[838,5],[855,2],[858,2],[882,2]]},"621":{"position":[[19,1],[34,1],[59,1],[61,3],[65,5],[71,2],[74,1],[98,2],[117,1],[119,2],[134,1],[172,1],[174,2],[180,1],[192,1],[203,2],[206,3],[237,3],[241,4],[246,1],[248,2],[270,1],[272,2],[275,2],[278,3],[291,1],[296,1],[327,1],[329,2],[358,1],[360,2]]},"623":{"position":[[23,1],[25,2],[33,2],[36,2],[39,1],[41,3],[45,3],[49,2],[130,1],[151,1],[153,2],[162,1],[183,1],[185,3],[201,2],[216,1],[227,3],[231,2],[234,3],[251,1],[269,1],[271,2],[293,1],[295,4],[305,2],[329,1],[331,2]]},"625":{"position":[[52,1],[54,2],[174,1],[176,2],[261,3],[265,3],[269,1],[295,1],[303,1],[305,1],[307,2],[343,1],[345,4],[350,1],[381,2],[403,2],[406,1],[408,2],[411,1],[439,1],[452,3],[467,1],[481,3],[497,1],[499,4],[504,3],[508,4],[513,5],[519,3],[523,3],[527,5],[533,3],[537,2],[540,2],[543,3],[551,1],[576,1],[578,2],[602,1],[626,1],[680,1],[682,5],[709,1],[711,3],[715,5],[739,1],[741,1],[743,3],[773,3]]},"627":{"position":[[125,1],[186,2],[199,1],[201,2],[215,2],[273,3],[317,1],[319,3],[323,2],[326,1],[328,3],[332,5],[338,2],[341,1],[343,2],[346,1],[368,1],[370,3],[413,1],[415,3],[419,2],[462,1],[464,3],[468,4],[473,5],[483,1],[502,2],[505,2],[508,6],[531,1],[537,3],[577,1],[652,1],[654,2],[660,1],[662,3],[666,3],[670,2],[744,1],[762,1],[781,1],[783,2],[786,1],[788,2],[791,3],[795,2],[812,2],[819,1],[821,3],[845,1],[872,1],[900,1],[902,1],[904,1],[947,1],[960,1],[968,1],[1038,1],[1049,1],[1051,2],[1059,1],[1061,3],[1065,7],[1084,1],[1086,2],[1089,2],[1092,2],[1095,3],[1099,2],[1107,2],[1110,3],[1114,3],[1128,4],[1133,2],[1136,3],[1140,2],[1143,2],[1146,2],[1149,4],[1154,2],[1179,1],[1188,1],[1199,3],[1222,1],[1236,1],[1245,1],[1247,5],[1253,3],[1257,3],[1261,3],[1265,2],[1268,4],[1304,2],[1345,2],[1366,1],[1368,1],[1370,5],[1396,1],[1398,3],[1402,2],[1419,2]]},"629":{"position":[[14,1],[16,1],[18,3],[22,2],[54,1],[56,4],[87,1],[89,2],[92,6],[111,1],[113,2],[130,1],[177,1],[232,1],[234,2],[237,3],[269,1],[294,2],[297,2],[318,2],[321,2],[345,1],[378,1],[380,2],[406,1]]},"631":{"position":[[21,2],[24,1],[52,2],[73,1],[75,5],[81,4],[86,4],[91,1],[98,1],[100,2],[114,1],[116,4],[145,1],[147,4],[152,1],[154,2],[157,2],[160,1],[174,1],[176,2],[202,1],[204,1],[206,4],[211,2],[221,3],[271,1],[371,1],[373,1],[384,1],[386,2],[433,1],[464,1],[499,2],[502,2],[514,1],[538,1],[540,3],[544,2],[566,1],[568,2],[595,1],[597,3],[601,2],[604,5],[610,1],[643,1],[659,1],[736,1],[755,2],[779,1],[781,6],[804,1],[806,3],[810,2],[829,1],[831,2],[856,1],[858,4],[863,3],[867,2],[893,1],[913,3],[936,1],[938,2],[965,1],[967,3]]},"633":{"position":[[32,1],[34,2],[58,1],[60,4],[90,1],[92,1],[99,1],[101,5],[107,2],[110,2],[113,2],[116,2],[139,1],[141,4],[146,2],[149,4],[154,5],[160,3],[164,3],[182,1],[207,1],[209,2],[212,4],[231,2],[253,1],[255,2],[312,1],[314,2],[317,4],[362,1],[415,1],[417,4],[422,3],[426,2],[445,1],[455,1],[457,4],[462,3],[466,3],[470,2],[495,1],[497,2],[513,1],[515,4],[541,1],[564,1],[604,1],[640,1],[651,1],[653,2],[670,1],[672,5],[686,1],[696,1],[731,1],[733,5],[739,2],[753,2],[782,1],[792,1],[818,1],[851,1],[877,2],[919,1],[921,1],[923,1],[927,1],[933,1],[939,1],[941,1],[943,1],[970,2],[980,1],[986,1],[988,1],[990,1],[1011,1],[1013,1],[1054,1],[1066,1],[1095,1],[1118,1],[1134,1],[1156,1],[1169,1],[1171,4],[1176,2],[1195,2],[1217,1],[1270,1],[1282,1],[1284,2],[1303,1],[1319,2],[1322,2],[1339,1],[1355,1],[1375,2],[1403,1],[1450,1],[1476,2],[1515,1],[1517,1],[1519,1],[1551,1],[1595,1],[1671,1],[1690,1],[1692,2],[1703,1],[1722,1],[1751,1],[1753,2],[1770,1],[1781,1],[1783,2],[1806,3],[1810,4],[1833,1],[1840,1],[1853,1],[1855,3],[1859,3],[1863,2],[1866,3],[1877,4],[1891,1],[1914,1],[1916,2],[1919,2],[1945,1],[1956,2],[1959,1],[1961,4],[1986,1],[1988,3],[1992,3],[2049,1],[2069,1],[2079,1],[2102,1],[2125,1],[2206,1],[2274,1],[2293,1],[2295,2],[2298,3],[2324,1],[2344,1],[2346,3],[2350,4],[2355,2],[2358,3]]},"635":{"position":[[13,2],[25,1],[48,1],[59,2],[64,2],[67,2],[87,1],[89,2],[108,1],[132,2],[135,3],[175,1],[210,2],[232,4],[242,1],[281,2],[305,1],[307,5],[313,2],[316,3],[346,3],[350,5],[362,1],[369,2],[372,4],[377,2],[398,1],[400,1],[408,1],[410,3],[414,2],[434,2],[441,2],[444,4],[449,2],[466,2],[473,2],[482,1],[484,4],[489,2],[492,2],[503,1],[518,1],[520,2],[541,1],[543,2],[577,1],[579,2],[596,1],[619,1],[658,1],[677,1],[679,3],[713,1],[794,1],[796,2],[804,1],[824,1],[826,3],[858,2],[861,3],[879,1],[881,2],[888,2],[936,1],[938,2],[1025,1],[1033,2],[1055,1],[1057,3],[1061,1],[1063,2],[1066,1],[1068,2],[1079,1],[1095,3],[1099,3]]},"637":{"position":[[0,1],[7,2],[30,1],[32,3],[36,3],[40,3],[75,1],[77,1],[79,2],[82,2],[130,1],[132,2],[135,1],[156,1],[158,2],[180,1],[195,1],[221,1],[247,1],[258,2],[261,2],[285,4],[304,1],[306,2],[309,2],[330,1],[332,2],[353,1],[368,1],[395,1],[433,1],[463,2],[486,1],[488,2],[491,4],[496,2]]},"639":{"position":[[0,3],[4,3],[20,2],[27,1],[29,3],[42,1],[44,3],[48,2],[51,3],[102,2],[105,5]]},"642":{"position":[[4,3],[8,2],[16,1],[18,3],[34,1],[36,2],[42,5],[60,1],[62,2],[101,5],[111,5],[129,1],[131,2],[144,1],[171,1],[181,1],[223,1],[236,1],[274,1],[292,1],[322,1],[350,1],[361,1],[363,2],[370,1]]},"644":{"position":[[14,1],[34,1],[36,3],[40,2],[59,1],[61,2],[64,3],[88,1],[90,3],[94,2],[97,5],[103,2],[127,2],[130,5],[198,3],[217,3],[236,1],[254,3],[258,2]]},"646":{"position":[[4,1],[6,2],[19,1],[21,2],[45,1],[47,2],[67,1],[69,1],[87,1],[100,3],[138,1],[162,1],[181,1],[183,4],[195,2],[198,3],[207,1],[217,1],[219,4],[247,1],[264,2],[267,2],[270,4],[290,3],[303,1],[312,1],[314,4]]},"648":{"position":[[16,1],[18,2],[50,2],[53,1],[80,1],[82,4],[96,2],[103,1],[118,1],[128,2],[131,2],[154,1],[156,2],[162,1],[172,1],[182,1],[198,1],[200,2],[208,2],[229,1],[231,2],[238,1],[254,1],[256,3],[288,1],[290,5],[296,2],[303,1],[326,3],[330,2],[333,2],[336,3],[340,2],[343,2],[351,1],[353,1],[355,1],[357,4],[362,3],[366,4],[371,2],[383,6],[390,1],[397,1],[403,1],[405,2],[408,2],[411,2],[414,3],[423,1],[438,1],[444,5],[450,2],[453,2],[456,2]]},"651":{"position":[[18,1],[51,1],[53,2],[61,2],[64,3],[85,2],[108,4],[113,2],[116,1],[118,4],[123,2],[137,1],[139,2],[142,3],[146,2],[149,4],[154,2],[161,2],[168,2],[171,5],[186,2],[189,2],[192,3],[196,4],[221,3],[225,2]]},"653":{"position":[[27,1],[40,1],[42,2],[45,3],[59,1],[61,3],[65,6],[72,4],[77,2],[90,1],[100,1],[111,2],[126,1],[131,1],[138,2],[141,2],[144,2],[154,2],[175,2],[178,4],[183,2],[186,2],[201,1],[203,4],[216,2],[230,1],[232,1],[234,3],[238,2],[241,1],[243,3],[259,2],[274,1],[276,5],[282,4],[287,3]]},"655":{"position":[[9,2],[12,3],[37,1],[55,1],[57,6],[64,3],[85,1],[87,4],[120,1],[122,1],[124,2],[136,1],[142,1],[151,1],[174,1],[176,2],[186,2],[192,2],[195,1],[197,3],[201,3],[205,2],[212,1],[218,4],[223,4],[228,2],[243,1],[254,3],[267,2],[289,1],[291,5],[297,3]]},"657":{"position":[[19,2],[40,3],[44,6],[55,2],[58,2],[70,4],[79,1],[115,1],[125,1],[127,3],[131,1],[133,2],[136,2],[139,2],[151,1],[153,3],[157,3],[165,1],[192,1],[194,2],[201,1],[218,1],[220,3],[238,2],[241,4]]},"659":{"position":[[4,1],[6,4],[11,3],[22,1],[24,4],[50,1],[52,3],[75,1],[77,5],[95,1],[97,5],[109,4],[114,2],[127,1],[129,5],[135,2],[150,1],[152,2],[161,2],[182,1],[184,4],[189,2],[208,2],[211,1],[218,1],[232,1],[255,1],[257,4],[262,2],[280,1],[282,2],[285,2],[288,4],[302,5],[313,1],[319,1],[346,1],[348,3],[368,1],[370,3],[379,1],[381,5],[387,5],[393,2],[396,1],[398,2]]},"662":{"position":[[0,2],[18,1],[20,4],[45,1],[47,5],[62,1],[71,1],[73,2],[76,3],[80,2],[104,2],[107,3],[111,2],[128,1],[142,1],[169,1],[171,3],[195,1],[197,4],[222,2],[225,2],[228,1],[230,2],[233,2],[236,2],[244,2],[247,2],[254,1],[277,1],[279,4],[284,3],[305,1],[330,1],[332,3],[357,1],[359,5],[365,4],[370,2],[373,3],[397,2],[400,3],[404,2],[407,2],[422,2],[425,3],[443,1],[445,2],[448,4],[460,1],[462,2],[465,1],[467,2],[470,2],[473,2],[481,2],[505,1],[507,4],[518,2],[521,2],[524,2],[527,3],[545,2],[558,1],[560,4],[565,2],[568,2],[591,1],[593,4],[598,2],[601,4],[606,4],[611,3]]},"664":{"position":[[20,1],[22,2],[35,1],[37,4],[42,2],[45,3],[49,3],[53,2],[56,2],[64,1],[84,1],[86,4],[91,2],[94,2],[107,2],[116,3],[120,3],[124,2],[134,1],[136,2],[153,1],[155,5],[161,2],[164,3],[168,4],[173,2],[176,2],[187,1],[204,2],[216,4],[221,2],[229,1],[240,4],[245,1],[254,1],[256,5],[280,2],[301,1],[317,1],[319,4],[334,2],[343,2],[353,1],[368,3],[390,2],[393,3],[397,3]]},"666":{"position":[[0,3],[4,4],[16,1],[42,1],[44,2],[53,2],[56,4],[61,1],[63,1],[72,1],[74,4],[86,1],[97,2],[100,2],[103,5],[109,1],[111,3],[115,4],[120,4],[125,2],[128,5],[134,2]]},"668":{"position":[[7,2],[22,1],[38,1],[49,1],[51,2],[76,1],[78,6],[85,2],[88,3],[114,3],[118,2],[143,1],[145,6],[152,2],[155,3],[181,1],[193,3],[197,3],[212,1],[214,2],[223,1],[232,2],[253,1],[255,2],[258,1],[270,1],[272,4],[277,3]]},"670":{"position":[[25,2],[28,2],[41,2],[50,2],[53,3],[57,3],[61,2],[83,4],[88,3],[92,2]]},"672":{"position":[[0,2],[3,3],[9,2],[21,1],[23,4],[28,3],[44,1],[46,4],[51,1],[70,2],[145,1],[169,2],[183,2],[191,1],[193,4],[202,1],[204,3],[226,1],[228,3],[234,2],[242,1],[244,3],[252,2],[255,2],[258,3],[262,2]]},"674":{"position":[[24,2],[27,2],[30,3],[34,3],[59,1],[89,2],[102,1],[118,2],[134,2],[164,1],[166,2],[181,1],[204,1],[236,1],[255,2],[289,1],[303,1],[314,1],[322,2],[332,2],[335,2],[338,3],[346,6],[376,2],[417,1],[419,2],[422,3],[426,2],[429,2],[432,2],[459,1],[468,2],[487,2]]},"676":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"678":{"position":[[0,4],[17,3],[31,1],[75,1],[77,2],[80,3],[84,4],[89,3],[93,3],[97,3],[140,1],[142,3],[155,1],[157,2],[160,2],[163,3],[167,2],[170,1],[172,4],[202,6],[209,3],[217,1],[219,4],[224,1],[242,2],[255,2],[258,3],[267,1],[285,6],[296,3],[320,3],[324,3],[328,3],[337,1],[339,5],[345,1],[347,2],[350,2],[353,2],[365,1],[386,1],[388,4],[393,3],[402,3],[406,3],[410,6],[417,1],[419,5],[434,1],[455,6],[467,2]]},"680":{"position":[[0,2],[3,4],[21,3],[30,2],[33,1],[35,3],[39,3],[43,3],[47,2],[50,1],[52,2],[55,2],[58,2],[61,3],[65,5],[71,3],[75,5],[81,3],[105,1],[107,2],[142,1],[144,1],[146,2],[149,3],[153,2],[156,1],[158,3],[410,4],[415,3],[431,2],[443,1],[445,2],[448,3],[452,5],[481,1],[483,4],[488,3],[492,6],[499,3],[517,4],[522,4],[527,3],[531,3],[562,1],[578,1],[584,1],[586,4],[591,3],[595,1],[597,3],[601,2],[604,3],[631,1],[633,4],[638,4],[643,3],[647,5],[653,4],[658,2],[661,1],[663,2],[666,5],[672,5],[678,2],[681,7],[708,1],[710,5],[728,3],[732,1],[734,2],[737,3],[741,4],[753,1],[755,2],[758,4],[763,3],[767,3],[771,4],[776,2],[779,3],[800,1],[802,4],[807,5],[813,3],[817,5],[823,3],[827,3],[831,3],[851,1],[864,3],[885,1],[899,1],[901,1],[903,3],[907,1],[909,3],[922,2],[929,1],[935,2],[938,3],[942,3],[946,2],[966,2],[976,1],[978,4],[983,4],[988,3],[992,2],[1026,1],[1028,4],[1048,1],[1050,4],[1055,4],[1067,2],[1088,1],[1116,2],[1136,1],[1138,4],[1143,3],[1147,3],[1160,2],[1167,1],[1169,3],[1173,3],[1177,5],[1183,3],[1196,2],[1203,1],[1205,1],[1207,2],[1214,5],[1220,2],[1252,4],[1257,2],[1283,3],[1293,1],[1295,2],[1298,2],[1320,1],[1334,1],[1336,2],[1339,2],[1342,3],[1346,3],[1355,1],[1357,3],[1361,5],[1367,2],[1370,6],[1377,2],[1385,3],[1389,4],[1403,1],[1405,3],[1409,2],[1412,1],[1414,3],[1418,2],[1428,1],[1439,1],[1441,2],[1444,2],[1447,4],[1471,2],[1479,1],[1481,3],[1489,1],[1491,3],[1495,4],[1500,4],[1505,5],[1511,4],[1525,1],[1542,1],[1560,1],[1562,3],[1566,3],[1570,2],[1585,2],[1588,5],[1594,1],[1596,3],[1600,3],[1604,3],[1608,3],[1621,2],[1628,1],[1634,1],[1641,1],[1654,3],[1658,1],[1660,6],[1682,1],[1684,3],[1688,2],[1691,2],[1703,1],[1714,1],[1728,5],[1738,1],[1745,1],[1747,2],[1750,2],[1776,1],[1797,2],[1805,2],[1811,1],[1826,1],[1828,4],[1833,1],[1835,2],[1838,3],[1842,5],[1848,2]]},"682":{"position":[[6,1],[15,1],[21,1],[23,7],[31,6],[54,1],[56,3],[60,2],[79,1],[93,1],[116,2],[119,2],[122,4],[127,4],[154,3],[158,3],[181,1],[183,4],[188,5],[194,2],[197,3],[201,4],[212,1],[221,1],[234,1],[236,2],[257,1],[259,2],[276,1],[278,4],[283,2],[286,2],[289,4],[294,3],[322,1],[324,1],[326,4],[331,4],[336,4],[341,3],[345,6],[352,2],[382,1],[384,4],[389,2],[392,2],[395,5],[417,1],[460,3],[464,3],[468,4],[473,4],[478,1],[480,2],[501,1],[503,2],[506,1]]},"684":{"position":[[16,1],[18,4],[32,1],[40,1],[42,5],[62,3],[66,2],[98,1],[113,6],[138,1],[140,2]]},"686":{"position":[[29,1],[31,4],[36,2],[60,1],[103,1],[105,2],[205,1],[207,2],[308,2],[311,2],[314,2],[317,6],[343,1],[345,3],[360,3],[364,2],[391,1],[411,3],[415,3],[432,3],[447,1],[465,1],[467,5],[484,1],[493,1],[495,3],[523,3],[538,1],[555,1],[557,5],[574,1],[582,1],[584,3],[606,1],[608,3],[650,1],[665,1],[667,4],[672,1],[674,3],[678,2],[681,3],[685,4],[690,2],[777,3],[784,3],[788,2],[832,1],[842,2],[852,1],[854,3],[858,1],[860,2],[863,4],[868,2],[871,1],[873,3],[894,1],[907,1],[937,1],[965,1],[989,1],[991,3],[995,5],[1026,1],[1028,2],[1115,1],[1117,5],[1123,3],[1156,1],[1158,5],[1164,2],[1209,1],[1211,5],[1221,1],[1223,3],[1227,2],[1230,2],[1283,2],[1355,2],[1410,3],[1423,1],[1447,1],[1463,1],[1465,4],[1479,1],[1481,3],[1485,2],[1488,2],[1535,2],[1599,2],[1691,1],[1721,2],[1724,2],[1741,1],[1777,1],[1779,2],[1782,1],[1784,2],[1806,1],[1808,2],[1811,1],[1813,2],[1816,1],[1857,1],[1859,4],[1923,1],[1925,4],[1930,4],[1935,1],[1937,3],[1996,1]]},"688":{"position":[[19,1],[35,1],[37,5],[43,3],[47,1],[49,2],[52,3],[56,3],[60,2],[90,1],[120,1],[135,1],[137,2],[149,3],[153,2],[160,1],[182,1],[184,1],[220,1],[222,4],[227,3],[250,1],[262,1],[264,3],[268,1],[270,2],[273,1],[285,1],[287,2],[303,1],[305,2],[308,1],[310,2],[352,1],[354,2],[357,4],[362,2],[365,2],[368,5],[374,3],[378,2],[399,1],[401,2],[404,5],[410,2],[413,4],[418,2],[421,1],[423,4],[428,4],[442,2],[454,1],[456,2],[459,4],[464,4],[469,3],[473,2],[476,2],[479,2],[482,2],[485,2],[488,2],[491,3],[495,5],[501,3],[520,1],[522,4],[540,1],[554,2],[557,3],[566,1],[568,4],[602,1],[604,4],[622,2],[642,1],[644,2],[647,2],[679,1],[681,3],[685,2],[688,2],[703,1],[727,1],[777,1],[779,1],[814,1],[816,1],[818,1],[842,2],[845,1],[847,1],[882,1],[884,1],[886,1],[952,1],[977,1],[1006,3],[1029,1],[1040,1],[1042,2],[1045,5],[1051,6],[1068,1],[1083,2],[1086,2],[1089,4],[1104,3],[1129,1],[1131,5],[1147,1],[1149,3],[1153,1],[1155,3],[1159,2],[1162,1],[1164,2],[1181,4],[1186,2],[1199,1],[1201,2],[1213,1],[1215,4],[1220,2],[1223,2],[1235,1],[1237,3],[1307,2],[1310,3],[1320,1],[1335,2],[1338,3],[1342,4],[1347,3],[1351,1],[1353,3],[1357,4],[1362,3],[1380,1],[1382,1],[1384,2],[1387,3],[1391,5],[1397,1],[1399,2],[1402,3],[1406,1],[1416,1],[1418,3],[1422,4],[1427,2]]},"690":{"position":[[4,5],[33,1],[45,1],[47,5],[53,2],[56,3],[69,1],[75,1],[81,3],[85,5],[96,3],[100,4],[105,3],[109,3],[113,3]]},"692":{"position":[[18,2],[36,1],[41,1],[56,2],[59,3],[63,2],[66,3],[70,5],[76,2],[92,1],[108,2],[111,3],[122,2],[125,3],[140,1],[142,2],[145,2],[155,1],[185,2],[205,1],[207,3],[211,2],[217,2],[220,5],[226,2],[247,1],[259,1],[261,4],[266,5],[285,2],[288,2],[291,4],[296,2]]},"694":{"position":[[15,1],[17,2],[28,1],[43,2],[46,3],[74,1],[101,3],[115,1],[117,3],[148,2],[151,3],[171,1],[173,3],[181,1],[188,1],[201,1],[203,2],[206,4],[211,4],[216,4],[221,2],[224,3],[233,1],[235,2],[238,1],[247,1],[249,1],[274,1],[276,5],[282,2],[294,2],[297,2],[309,1],[311,3],[347,1],[356,1],[358,5],[364,2],[367,2],[370,2],[373,2],[376,4],[381,3],[385,3],[400,3],[404,4],[432,1],[447,3],[451,1],[466,1],[477,1],[479,5],[485,2],[488,2],[511,1],[513,3],[517,3],[533,3],[542,1],[552,2],[555,1],[557,3],[561,2],[581,1],[583,5],[589,3],[600,1],[602,6],[621,3],[662,1],[664,3],[674,1],[691,2],[700,1],[715,2],[718,2],[725,2],[758,1],[760,3],[769,1],[771,2],[774,3],[778,2],[796,2],[815,2],[833,1],[835,2],[847,2],[850,2],[874,2],[906,1],[908,2],[933,2],[953,1],[955,2],[958,3],[976,2],[979,5],[985,1],[1010,3],[1014,3],[1031,1],[1033,4],[1038,4],[1052,1],[1073,1],[1090,2]]},"696":{"position":[[30,1],[41,2],[50,1],[58,1],[60,2],[63,2],[75,2],[84,1],[92,2],[95,2],[109,1],[117,2],[155,2],[158,3],[162,1],[164,3],[175,1],[177,4],[194,2],[197,3],[201,1],[203,2],[213,1],[215,6],[225,1],[227,4],[232,2],[235,1],[237,2],[250,1],[260,3],[264,2],[267,2],[297,3],[314,1],[319,1],[321,3],[325,2],[328,3],[332,5],[338,2],[341,2],[344,3],[352,2],[376,2],[388,1],[402,1],[404,4],[409,1],[411,3],[415,2],[418,3],[422,3],[426,1],[428,3],[448,1],[470,1],[481,2],[484,3],[488,3],[492,5],[498,3],[509,3],[513,5],[519,5],[525,2],[537,2],[559,1],[566,1],[591,2],[611,1],[621,1],[623,4],[635,1],[637,4],[642,2],[645,3],[687,1],[693,1],[709,1],[714,1],[728,1],[748,1],[750,5],[787,2],[790,1],[792,2],[795,3],[799,2],[811,4],[816,3],[820,2],[826,1],[831,1],[847,1],[856,4],[870,1],[872,3],[876,3],[880,1],[882,4],[887,3],[891,2],[894,3],[907,1],[912,2],[915,3],[919,5],[925,1],[927,2],[930,2],[951,2],[964,3],[980,1],[982,4],[987,3],[991,3],[998,1],[1000,4],[1005,3],[1009,3],[1013,1],[1015,2],[1018,2],[1030,1],[1059,1],[1061,4],[1066,3],[1088,1],[1090,3],[1104,2],[1112,1],[1118,1],[1129,1],[1131,2],[1134,2],[1137,2],[1140,3],[1144,3],[1148,3],[1152,3],[1156,3],[1160,1],[1178,1],[1183,1],[1185,3],[1201,1],[1203,3],[1207,6],[1218,1],[1225,2],[1234,2],[1237,3],[1241,2],[1244,2],[1256,1],[1276,1],[1278,1],[1280,5],[1286,2],[1289,2],[1296,1],[1298,1],[1300,3],[1316,1],[1318,3],[1325,1],[1327,2],[1330,4],[1335,2],[1338,3],[1351,1],[1353,3],[1357,2],[1360,4],[1370,2]]},"698":{"position":[[9,3],[13,2],[26,2],[29,2],[32,2],[45,1],[47,1],[62,1],[64,2],[74,1],[83,1],[85,4],[99,1],[101,5],[107,4],[112,2],[124,1],[126,2],[246,2],[249,4],[271,1],[282,2],[285,2],[305,2],[308,2],[311,3],[350,4],[355,2],[358,2],[361,1],[385,1],[387,2],[390,3],[423,2],[435,2],[448,1],[459,2],[472,2],[485,1],[495,1],[502,1],[509,2],[512,3],[557,1],[559,3],[573,2],[576,3],[590,2],[640,2],[643,4],[648,4],[653,2],[656,3],[675,1],[677,4],[682,5],[688,7],[696,3],[700,3],[751,3],[755,1],[757,1],[759,4],[764,4],[769,3],[773,5],[779,2],[782,5],[788,2],[824,1],[826,4],[831,2],[834,5],[854,1],[856,4],[861,5],[884,1],[886,4],[891,2],[894,3],[898,2],[952,1],[954,3],[965,2],[968,3],[981,1],[1002,1],[1004,4],[1060,1],[1062,2],[1074,1],[1102,1],[1104,2],[1107,2],[1110,2],[1122,1],[1124,3],[1128,1],[1148,1],[1150,2],[1170,1],[1192,2],[1226,1],[1228,4],[1249,2],[1267,1],[1269,2],[1286,1],[1288,4],[1320,2],[1356,2],[1359,3],[1363,2],[1366,2],[1369,5],[1406,4],[1444,1],[1446,2],[1467,1],[1506,1],[1508,3],[1512,3],[1516,2],[1519,3],[1523,2],[1541,1],[1546,2],[1549,3],[1565,3],[1569,2],[1583,2],[1604,1],[1606,2],[1609,3],[1646,1],[1651,1],[1653,1],[1655,2],[1658,3],[1662,4],[1672,2],[1675,2],[1687,1],[1703,1],[1726,1],[1728,2],[1731,2],[1734,3],[1738,3],[1742,2],[1745,4],[1750,3],[1766,1],[1790,1],[1804,2],[1825,1],[1827,2],[1848,3],[1852,2],[1855,1],[1857,2],[1860,2],[1863,3],[1867,2],[1870,3],[1874,2],[1880,3],[1890,4],[1895,3],[1899,4],[1977,1],[1989,3],[1993,2]]},"700":{"position":[[16,1],[41,2],[53,2],[64,1],[74,1],[76,3],[80,2],[87,1],[97,1],[99,1],[101,4],[106,3],[113,1],[115,1],[117,1],[119,3],[123,2],[136,1],[156,1],[158,2],[170,1],[172,2],[185,1],[187,2],[190,3],[194,2],[197,1],[199,3],[208,1],[214,2],[217,3],[225,2],[228,5],[234,2],[261,1],[271,1],[288,1],[295,2],[298,4],[312,2],[337,1],[339,4],[353,1],[355,3],[371,1],[381,1],[388,3],[396,1],[407,2],[422,3],[426,3],[443,2],[449,1],[451,5],[457,2],[491,1],[521,1],[523,4],[528,3],[532,2],[535,2],[538,4],[552,1],[554,4],[564,1],[583,1],[596,3],[600,1],[602,2],[605,2],[608,2],[611,2],[619,2],[642,1],[653,2],[656,2],[664,1],[666,2],[690,2],[693,1],[695,5],[701,2],[704,3]]},"702":{"position":[[52,1],[68,1],[103,1],[110,2],[113,1],[122,1],[124,6],[143,2],[146,3],[150,5],[170,1],[172,3],[176,3],[180,2],[183,2],[186,2],[189,2],[192,3],[210,1],[221,1],[223,3],[227,2],[240,3],[251,1],[253,3],[257,3],[261,3],[283,2],[286,2],[289,3],[293,2],[296,3],[300,2],[303,5],[309,3],[320,1],[325,1],[327,5],[333,2],[336,1],[338,2],[355,1],[357,2],[360,2],[363,3],[367,1],[369,2],[372,2],[375,3],[394,1],[403,3],[407,2],[410,2],[427,1],[429,4],[434,2],[445,2],[481,4],[505,2],[508,2],[511,3],[524,5],[552,3],[556,3],[560,2],[572,1],[574,2],[577,2],[580,2],[583,4],[588,1],[590,2],[600,1],[602,4],[607,4],[612,1],[614,2],[672,1],[674,2],[701,4],[706,3],[710,3],[714,2],[721,1],[749,3],[753,3],[757,3],[761,3],[765,1],[780,2],[783,2],[786,4],[791,4],[796,2],[799,2],[802,1],[826,1],[828,5],[846,2],[849,2],[852,4],[857,2],[893,2],[896,5],[902,2],[905,2],[908,2],[911,2],[922,1],[933,1],[935,2],[938,4],[957,1],[959,4],[968,1],[979,2],[982,3],[986,2],[998,1],[1014,2],[1017,2],[1020,3],[1031,2],[1034,1],[1050,2],[1053,2],[1056,4],[1061,2],[1077,1],[1083,2],[1091,2],[1103,1],[1105,3],[1109,3],[1113,3],[1117,1],[1132,1],[1134,2],[1137,3],[1150,2],[1153,3],[1157,2],[1160,1],[1162,3],[1175,1],[1195,1],[1197,2],[1200,2]]},"704":{"position":[[11,1],[17,2],[20,3],[24,2],[27,1],[29,2],[54,2],[66,1],[85,2],[88,5],[94,1],[121,2],[133,2],[136,3],[140,2],[143,6],[159,1],[161,3],[170,2],[186,1],[188,7],[200,2],[219,1],[221,5],[227,4],[235,1],[237,3],[241,2],[244,2],[256,1],[264,1],[266,4],[280,1],[282,5],[294,2],[297,1],[299,3],[303,5],[309,2],[318,1],[320,2],[337,3],[341,3],[345,5],[351,2],[363,1],[365,4],[370,1],[372,2],[382,1],[384,2],[387,2],[399,1],[418,1],[430,1],[439,3],[443,4],[461,2],[464,4],[469,3],[489,3],[505,1],[507,3],[515,1],[517,4],[522,1],[524,3],[528,2],[531,3],[535,2]]},"707":{"position":[[0,1],[2,4],[16,2],[36,2],[39,1],[41,2],[51,1],[53,4],[58,4],[81,1],[87,2],[90,2],[93,1],[95,4],[100,1],[102,6],[128,4],[133,3],[137,1],[139,3],[155,2],[163,2],[166,2],[174,1],[176,4],[181,3],[189,1],[191,2],[194,3],[208,2],[221,2],[228,3],[232,4],[241,3],[250,1],[263,1],[265,2],[268,2],[271,4],[276,5],[282,3],[306,1],[308,5],[324,2],[332,2],[335,2],[338,1],[340,3],[347,1],[362,1],[364,4],[369,1],[371,2],[374,2],[377,3],[381,3],[385,2],[388,2]]},"709":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"711":{"position":[[14,1],[36,1],[47,1],[49,4],[72,1],[74,5],[89,1],[96,1],[98,2],[101,1],[103,3],[107,4],[112,2],[115,3],[119,1],[121,3],[162,2],[165,2],[168,4],[187,1],[189,4],[194,3],[216,1],[218,4],[223,1],[225,4],[230,2],[233,3],[251,3],[283,1],[285,3],[289,1],[291,3],[295,1],[297,2],[300,1],[302,3],[306,4],[311,2],[314,3],[318,4],[323,4],[342,1],[344,2],[347,3],[355,3],[359,2],[362,3],[366,2],[369,5],[375,4],[380,1],[382,2],[385,3],[389,4],[394,3],[398,2],[413,1],[415,3],[419,5],[441,1],[447,1],[452,1],[454,2],[469,1],[475,3],[489,1],[548,1],[550,2],[565,1],[567,4],[572,4],[577,5],[595,1],[597,5],[603,2],[606,3],[610,2],[613,3],[626,2],[629,2],[632,2]]},"713":{"position":[[15,1],[17,2],[20,3],[34,1],[36,3],[40,6],[47,2],[50,4],[55,5],[61,3],[65,3],[86,1],[100,1],[102,3],[122,3],[133,2],[136,3],[140,2],[143,3],[162,1],[164,2],[176,1],[195,1],[197,4],[202,3],[215,1],[217,3],[221,3],[225,4],[240,1],[242,1],[249,1],[251,2],[270,1],[277,1],[279,4],[284,3],[288,2],[294,1],[296,2],[299,3],[303,2],[306,4],[321,1],[338,1],[354,1],[365,2],[392,1],[394,4],[402,1],[410,2],[413,2],[435,1],[437,3],[472,1],[483,2],[493,1],[495,4],[515,2],[531,1],[540,1],[548,1],[550,3],[554,5],[560,4],[571,2],[584,1],[595,1],[597,3],[601,2],[604,3],[624,1],[638,1],[640,2],[662,1],[676,1],[678,4],[683,3],[687,4],[692,3],[696,2],[718,1],[737,1],[746,2],[749,4],[785,1],[809,1],[829,1],[831,2],[843,1],[864,1],[877,1],[879,2],[887,2],[900,1],[902,6],[909,2],[912,3],[930,3],[934,2],[940,1],[942,4],[947,2],[978,2],[984,1],[996,1],[998,2],[1001,3],[1005,2],[1008,2],[1011,2],[1014,1],[1016,3],[1020,3],[1024,3],[1028,4],[1036,1],[1038,3],[1042,2],[1045,3],[1058,4],[1063,5],[1081,1],[1094,3],[1098,2],[1101,2],[1104,3],[1108,5],[1114,3],[1122,1],[1124,2],[1130,1],[1132,4],[1137,3],[1141,2],[1144,3],[1148,3],[1152,4],[1157,2],[1160,1],[1162,2],[1165,3],[1169,2],[1172,3],[1225,1],[1227,3],[1231,1],[1233,3],[1237,2],[1252,1],[1254,3],[1273,1],[1275,2],[1284,1],[1304,2],[1326,1],[1339,1],[1341,3],[1345,5],[1351,2],[1354,3],[1368,1],[1370,3],[1374,3],[1378,1],[1380,2],[1395,1],[1397,3],[1401,2],[1404,3],[1408,2],[1411,3],[1415,1],[1417,3],[1421,3],[1425,2],[1428,2],[1431,2],[1434,2],[1437,2],[1452,1],[1459,2],[1476,2],[1479,3],[1483,2],[1486,2],[1489,1],[1521,1],[1548,2],[1578,1],[1580,4],[1585,3],[1594,2],[1609,1],[1611,3],[1615,3],[1619,4],[1629,1],[1651,1],[1653,3],[1662,1],[1679,1],[1681,4],[1695,2],[1698,3],[1702,2],[1705,1],[1712,1],[1714,2],[1717,3],[1721,2],[1724,2]]},"716":{"position":[[9,1],[11,1],[13,3],[17,2],[60,4],[65,2],[68,2],[71,2],[79,1],[91,2],[138,4],[143,2],[146,2],[149,2],[177,1],[209,2]]},"718":{"position":[[17,1],[30,1],[63,1],[104,1],[106,3],[171,1],[173,2],[176,2],[179,3],[183,3],[187,1],[189,3],[193,3],[219,1],[238,1],[240,5],[271,1],[407,1],[409,3],[447,1],[471,1],[473,4],[482,1],[484,2],[512,2],[544,2],[617,1],[619,5],[650,1],[661,2],[769,1],[771,1],[773,1],[775,3],[793,1],[795,3],[819,1],[831,1],[836,1],[849,2],[852,1],[854,1],[856,3]]},"721":{"position":[[34,1],[36,2],[55,2],[58,5],[64,6],[71,3],[75,4],[80,2],[86,1],[88,5],[94,3],[98,2],[101,2]]},"723":{"position":[[24,1],[40,3],[56,1],[58,2],[64,1],[69,1],[82,3],[86,4],[116,1],[122,1],[124,5],[133,1],[138,2],[141,2],[144,3],[148,4]]},"725":{"position":[[34,2],[41,4],[46,1],[48,3],[52,3],[56,5],[84,1],[86,2],[92,1],[94,3],[98,4],[103,4],[125,1],[127,1],[141,1],[143,2],[161,1],[163,4],[173,2],[176,4],[181,4],[186,4],[191,2],[194,1],[196,3],[200,3],[204,4],[222,1],[232,3],[270,2],[276,1],[278,4],[283,4],[310,2],[313,3],[317,2],[320,3],[324,5],[330,1],[332,4],[337,4],[349,1],[360,1],[362,2],[365,4],[370,5],[395,1],[397,3],[413,2]]},"727":{"position":[[34,2],[55,1],[82,2],[85,5],[101,3],[105,2],[108,2],[111,1],[113,2],[126,2],[145,4],[150,2],[172,1],[174,2],[177,3],[198,1],[217,1],[219,5],[225,4],[230,3],[234,2],[237,1],[239,3],[243,4],[248,2],[263,1],[284,4],[289,2],[298,2],[301,5],[307,2],[317,1],[326,1],[342,1],[344,3],[360,1],[362,1],[364,2],[407,1],[412,3],[416,1],[418,3],[422,2],[425,2],[428,1],[448,1],[450,6],[477,1],[479,2],[496,1],[498,3],[509,1],[528,1],[530,1],[532,4],[537,3],[541,2]]},"730":{"position":[[0,2],[3,4],[8,2],[32,1],[34,3],[38,2],[45,2],[75,1],[77,5],[83,3],[91,1],[93,3],[97,1],[99,4],[109,1],[119,1],[121,6],[128,2],[149,1],[160,1],[162,3],[170,1],[172,3],[176,2],[179,3],[183,6],[190,2],[213,1],[224,3],[228,3],[232,5],[238,2],[241,3],[245,4]]},"732":{"position":[[14,1],[28,2],[31,3],[35,3],[39,3],[43,3],[56,1],[58,5],[64,2],[81,1],[88,3],[92,5],[98,5],[104,3],[128,1],[130,1],[132,2],[146,4],[151,5],[185,1],[187,1],[189,1],[198,2],[207,5]]},"734":{"position":[[20,1],[22,2],[31,1],[33,2],[39,2],[68,1],[70,2],[78,1],[80,4],[85,6],[103,1],[117,1],[119,5],[125,2],[128,5],[134,1],[136,2],[139,4],[144,4],[149,3],[153,1],[155,4],[160,1],[162,3]]},"736":{"position":[[12,3],[16,2],[27,1],[29,4],[34,2],[40,1],[42,6],[62,4],[67,5],[91,1],[93,4],[98,4],[103,2],[118,1],[125,1],[127,2],[136,2],[180,1],[182,5],[200,1],[202,2],[205,3],[209,2],[220,1],[222,5]]},"738":{"position":[[12,2],[15,3],[19,2],[22,3],[44,1],[55,1],[57,2],[60,4],[65,2],[68,2],[71,1],[73,3],[80,1],[82,3],[86,2],[89,3],[125,2],[128,5],[134,2],[161,1],[163,3],[167,5],[184,1],[193,4],[198,4],[228,2],[238,1],[258,1],[270,1],[284,1],[296,1],[298,4],[303,2],[306,1],[308,3],[312,2],[315,3],[319,3],[323,2],[335,1],[337,2],[357,4],[362,2]]},"740":{"position":[[12,1],[18,3],[22,5],[28,2],[41,1],[43,5],[49,2],[52,2],[111,1],[136,2]]},"742":{"position":[[0,3],[4,2],[49,1],[70,2],[73,1],[75,4],[80,2],[92,1],[94,2],[97,3],[121,2],[124,1],[131,1],[137,2],[140,3],[144,3],[148,2]]},"744":{"position":[[11,5],[17,1],[29,1],[31,5],[37,2],[99,1],[101,5],[107,2],[110,3],[136,1],[138,5],[162,1],[164,2]]},"746":{"position":[[8,1],[22,1],[37,1],[39,5],[55,2],[92,1],[109,2],[112,3],[116,2],[119,3],[123,1],[125,3],[129,2],[144,1],[161,2],[164,2],[172,2],[178,3],[182,5],[206,1],[213,2],[220,1],[222,4],[227,2],[264,1],[269,2],[272,3],[276,2],[279,3],[293,3],[321,1],[323,3],[327,5],[336,1],[341,1],[354,2],[369,1],[371,2],[380,2],[386,1],[388,4],[398,1],[425,1],[427,3],[431,3],[435,2],[441,1]]},"748":{"position":[[8,2],[11,3],[28,5],[34,2],[42,2],[48,1],[50,3],[54,1],[56,3],[60,2],[71,3],[75,2],[78,3],[90,1],[92,4],[131,2],[134,2],[137,3],[141,2],[178,1],[190,2],[193,2],[196,5],[202,2],[205,2],[208,3],[212,2],[225,2],[250,1],[252,4],[257,2],[287,1],[289,4],[294,4],[299,2],[302,2],[308,1],[310,3],[314,4],[324,2],[347,1],[361,1],[363,2],[366,3],[370,3],[374,1]]},"751":{"position":[[0,2],[15,4],[44,1],[46,3],[50,2],[53,2],[56,3],[60,3],[84,4],[101,1],[103,3],[107,3],[111,1],[113,1],[115,3],[129,1],[131,2],[146,1],[155,2],[158,2],[161,5],[167,3],[171,2],[189,1],[191,4],[208,1],[222,2],[233,1],[235,4],[240,1],[242,2],[245,3],[249,3],[253,2],[256,4],[272,1],[280,1],[282,2],[292,1],[302,1],[304,5],[313,1],[315,2],[334,1],[346,1],[348,2],[351,2],[365,1],[373,1],[375,2],[378,2],[381,4],[386,3],[390,3]]},"753":{"position":[[24,1],[38,3],[42,2],[45,4],[80,3],[84,3],[88,2],[91,3],[95,2],[105,1],[107,3],[122,1],[124,5],[130,2],[133,1],[135,6],[149,1],[151,5],[157,2],[160,2],[163,2],[172,1],[174,2],[177,3],[181,4],[186,3],[196,1],[198,4],[203,3],[207,3],[211,3],[225,1],[235,1],[237,3],[259,4],[264,6],[271,4],[276,2],[279,2],[282,4],[287,2],[290,2],[293,3],[297,3],[305,3],[322,2],[332,1],[334,4],[339,4],[344,2],[353,1],[355,4],[360,2],[363,2],[366,3],[370,2],[373,2]]},"755":{"position":[[12,2],[15,5],[21,4],[26,4],[31,5],[40,1],[42,2],[45,2],[54,1],[77,1],[79,2],[85,1],[98,1],[100,3],[104,3],[108,2],[111,2],[114,4],[139,1],[141,4],[158,1],[160,2],[163,3],[167,3],[180,1],[182,1],[184,1],[186,2],[189,4],[194,2]]},"757":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"759":{"position":[[17,1],[53,1],[71,1],[73,4],[78,2],[81,5],[87,3],[94,1],[126,1],[128,4],[133,1],[140,1],[142,2],[155,1],[157,4],[162,3],[166,1],[168,4],[213,1],[215,2],[221,1],[223,3],[227,3],[245,1],[247,2],[264,1],[279,1],[290,2],[293,2],[329,1],[340,2],[350,1],[352,3],[369,2],[372,3],[376,2],[397,1],[399,1],[408,1],[427,2],[430,3],[434,1],[436,3],[440,3],[458,1],[485,1],[487,2],[496,1],[498,4],[503,3],[507,2],[515,1],[517,2],[535,1],[537,7],[559,1],[571,4],[576,3],[580,2],[583,1],[594,4],[602,1],[604,5],[619,1],[635,1],[637,2],[649,1],[651,1],[653,1],[655,2]]},"761":{"position":[[17,1],[52,1],[54,4],[96,1],[98,4],[103,2],[106,5],[112,3],[119,1],[124,1],[126,2],[139,1],[148,2],[151,4],[156,3],[160,1],[167,2],[170,3],[174,2],[190,1],[197,1],[199,4],[204,3],[208,2],[214,3],[218,4],[223,3],[227,2],[230,2],[233,3],[237,3],[247,1],[271,1],[288,1],[290,3],[294,3],[298,1],[300,3],[328,3],[347,4],[362,1],[373,2],[398,1],[407,2],[410,4],[415,3],[434,1],[451,1],[460,3],[496,1],[498,5],[519,1],[525,1],[531,2],[534,3],[538,3],[542,3],[549,1],[551,3],[555,3],[559,4],[564,1],[571,3],[599,1],[601,5],[607,5],[619,1],[621,3],[638,1],[640,4],[645,2],[668,1],[670,4],[675,2],[678,5],[704,1],[716,1],[718,1],[720,4],[759,1],[761,1],[763,2],[766,3],[781,1],[783,2],[786,3],[790,2],[796,2],[811,3],[815,3],[831,1],[833,3],[837,3],[856,1],[858,2],[867,2],[870,3],[874,1],[876,3],[900,1],[902,2],[905,2],[908,5],[914,5],[920,1],[922,5],[938,1],[940,3],[944,2],[962,1],[978,1],[980,2],[994,1],[1036,1],[1058,2],[1068,1],[1087,3],[1132,1],[1140,1],[1184,1],[1193,1],[1195,2],[1198,2],[1201,1],[1210,1],[1221,4],[1226,1],[1228,2],[1231,4],[1236,2],[1239,1],[1241,2],[1244,2],[1247,2],[1253,1],[1262,1],[1264,3],[1268,1],[1270,4],[1282,1],[1309,2],[1312,5],[1325,1],[1327,2],[1330,3],[1334,4],[1339,2],[1357,2],[1360,2],[1363,2],[1375,3],[1379,1],[1384,1],[1386,2],[1402,1],[1411,2],[1414,1],[1421,2],[1436,1],[1443,1],[1445,4],[1450,1],[1452,6],[1459,3],[1467,1],[1498,1],[1505,1],[1507,4],[1512,3],[1516,1],[1534,1],[1536,2],[1539,2],[1542,2],[1554,2]]},"764":{"position":[[10,1],[20,1],[33,1],[50,1],[52,3],[56,2],[59,3],[63,2],[75,6],[82,2],[85,2],[88,1],[90,2],[93,3],[97,3],[101,3],[119,3],[127,1],[151,1],[153,4],[162,1],[181,3],[199,3],[207,1],[217,2],[224,1],[234,3]]},"766":{"position":[[20,1],[22,2],[81,1],[97,2],[108,1],[113,1],[115,3],[119,5],[134,4],[139,2],[142,1],[144,3],[157,1],[173,3],[181,1],[187,1],[189,2],[223,1],[229,1],[231,4],[253,1],[255,3],[290,1],[296,1],[298,2],[301,4],[306,2],[323,3],[345,1],[379,3],[406,1],[460,1],[462,1],[474,1],[498,1],[500,2],[524,1],[540,3],[557,1],[602,1],[604,3],[608,2],[624,2],[636,1],[655,1],[666,2],[678,2],[717,1],[796,1],[809,1],[831,1],[872,2],[887,1],[933,1],[960,1],[975,3],[979,2],[982,2],[999,1],[1022,1],[1042,2],[1045,4],[1050,2],[1053,2]]},"768":{"position":[[5,1],[21,2],[32,1],[37,4],[42,2],[86,1],[88,3],[92,1],[94,3],[102,1],[126,1],[128,2],[131,4],[136,1],[146,1],[152,1],[192,1],[207,1],[209,3],[213,1],[215,3],[219,3],[232,1],[254,1],[265,4],[270,1],[272,2],[275,2],[319,1],[343,1],[345,2],[348,2],[392,1],[394,2],[397,1],[408,1],[416,1],[418,4],[446,1],[448,2]]},"770":{"position":[[8,3],[12,3],[45,1],[47,6],[54,3],[72,1],[100,3],[104,2],[132,1],[134,2],[153,1],[155,5],[176,1],[203,1],[267,2],[273,1],[352,2],[393,1],[423,1]]},"773":{"position":[[10,1],[22,1],[24,4],[29,2],[35,1],[37,3],[41,1],[43,2],[46,3],[58,1],[60,3],[64,3],[68,2],[74,1],[94,1],[96,4],[101,4],[106,2],[109,3],[113,4],[118,4],[131,1],[133,3],[137,1],[139,3],[161,1],[163,3],[167,3],[171,2],[174,1],[176,2],[179,3],[183,5],[201,1],[212,3],[216,3],[220,3],[234,1],[236,4],[244,1],[255,1],[257,5],[263,4],[276,1],[278,3],[282,4],[295,1],[312,2],[315,3],[319,3],[323,7],[346,1],[348,4],[353,3],[357,2],[360,1],[362,3],[390,1],[392,6],[415,1],[417,4],[422,3],[426,2],[429,1],[431,3],[435,3],[439,3],[451,1],[453,5],[459,4],[464,4],[558,1],[560,4],[573,1],[580,1],[582,5],[588,3],[592,4],[597,1],[599,4],[604,2],[607,3],[626,3],[630,5],[657,4],[662,2],[665,1],[667,1],[669,4],[717,3],[721,3],[737,1],[739,3],[770,1],[772,4],[777,1],[779,4],[784,1],[786,3],[824,1],[844,2],[864,2],[877,3],[881,2],[884,2],[887,3],[902,1],[904,4],[925,2],[928,4],[933,3],[951,1],[953,4],[958,5],[964,1],[966,3],[992,1],[994,7],[1002,5],[1008,2],[1011,5],[1031,1],[1033,2],[1059,1],[1061,3],[1065,2],[1084,1],[1086,2],[1089,3],[1093,1],[1095,3]]},"775":{"position":[[14,1],[34,1],[43,1],[45,3],[65,1],[103,1],[105,3],[117,1],[127,3],[138,1],[140,3],[168,1],[230,1],[232,4],[244,3],[248,4],[284,1],[301,1],[349,1],[371,1],[393,1],[395,4],[415,1],[428,1],[445,3],[536,1],[586,1],[588,2],[606,1],[608,2],[611,5],[680,1],[717,3],[721,1],[761,2],[795,1],[921,1],[929,1],[931,4],[936,3],[965,1],[967,5],[994,1],[996,4],[1028,1],[1051,3],[1055,3],[1059,1],[1070,1],[1096,1],[1107,3],[1152,1],[1154,2],[1166,1],[1182,1],[1184,2],[1192,2],[1195,3],[1205,3],[1254,1],[1256,2],[1277,1],[1279,2],[1295,1],[1297,3],[1318,1],[1320,3],[1324,3],[1328,2],[1331,3],[1335,3],[1348,1],[1350,3],[1368,1],[1370,6]]},"777":{"position":[[14,1],[16,5],[29,2],[32,2],[35,4],[40,4],[45,3],[49,2],[52,3],[56,2],[59,3],[63,3],[101,1],[163,1],[165,3],[229,1],[292,1],[294,4],[299,2],[323,1],[342,1],[371,1],[383,1],[385,5],[405,1],[424,1],[431,2],[434,3],[445,2],[448,4],[462,1],[464,5],[470,2],[503,1],[510,2],[536,1],[538,4],[543,3]]},"780":{"position":[[19,1],[21,2],[24,1],[26,2],[48,1],[62,1],[69,2],[72,2],[83,1],[85,4],[90,3],[94,2],[97,3],[105,1],[107,4],[112,3],[132,1],[150,1],[162,1],[182,2],[204,1],[206,3],[210,2],[213,3],[217,2],[220,2],[223,4],[233,2],[253,1],[263,1],[265,2]]},"782":{"position":[[30,2],[47,1],[49,2],[52,1],[54,2],[57,3],[61,2]]},"784":{"position":[[14,1],[16,2],[32,1],[46,2],[68,1],[70,3],[85,2],[88,3],[92,3],[121,1],[123,2],[135,1],[153,1],[168,1],[170,2],[173,3],[177,2],[211,2],[229,1],[265,1],[281,2],[284,2],[375,1],[386,2],[409,2],[412,2],[429,1],[448,1],[450,2],[459,1],[465,2],[468,2],[483,1],[491,1],[497,2],[500,2],[523,1],[536,2],[539,2],[555,1],[563,1],[570,2],[573,2],[590,1],[604,2],[607,1],[613,2],[616,4],[621,2],[628,3],[632,6],[652,1],[654,2],[671,1],[673,1],[679,4],[688,2],[691,1],[705,1],[711,2],[714,3],[718,2],[740,1],[742,2],[757,4],[762,3],[787,2],[797,1],[824,2],[841,1],[843,3],[853,3],[857,2],[860,2],[863,2],[866,1],[888,1],[890,3],[908,1],[910,4],[915,3],[925,2]]},"787":{"position":[[5,1],[31,1],[40,3],[58,1],[85,2],[88,3],[92,2],[125,1],[136,1],[138,4],[153,1],[159,2],[169,4],[184,1],[211,1],[228,1],[240,2],[248,1],[250,4],[263,2],[280,1],[290,2],[293,1],[295,3],[299,2],[302,5],[308,4],[313,1],[324,2],[346,1],[370,1],[372,4],[391,1],[393,1],[395,4],[411,2],[414,2],[417,2],[420,2],[437,1],[454,2],[474,3],[497,2],[500,1],[512,1],[514,2],[517,2],[525,2],[528,2],[531,3],[535,5],[555,1],[557,3],[568,1],[570,2],[579,1],[581,4],[586,1],[588,3],[592,2],[595,5],[615,1],[623,1],[650,1],[652,6],[659,5],[665,2],[668,4],[673,3],[677,2],[692,1],[694,4],[699,2],[702,3],[706,5],[718,2],[721,5],[727,1],[729,1],[731,4],[736,5],[742,4],[747,3],[751,2]]},"789":{"position":[[0,3],[4,3],[21,1],[37,1],[42,2],[45,2],[48,3],[62,1],[69,1],[71,2],[88,1],[98,1],[100,5],[128,1],[135,3],[153,1],[169,2],[172,3],[176,3],[180,3],[184,2],[187,4],[192,3],[201,1],[203,5],[209,1],[211,2],[236,2],[242,2],[245,2],[248,2],[251,2],[254,4],[259,5],[287,1],[312,2],[319,1],[321,4],[326,5],[332,2],[335,3],[339,4],[344,3],[362,2],[365,2]]},"791":{"position":[[14,1],[30,3],[34,5],[54,1],[73,2],[76,2],[79,1],[81,3],[85,3],[89,2],[101,3],[105,2],[108,5],[114,4],[119,2],[122,2],[125,5],[142,1],[144,2],[147,1],[149,3],[153,2],[160,2],[163,5],[169,5],[179,2],[182,2],[185,4],[190,3],[194,3],[198,3],[211,4],[221,3],[225,7],[233,2],[236,4],[254,1],[256,3],[260,2],[263,3],[267,6],[283,2],[300,1],[302,5],[317,1],[319,2],[322,3],[326,3],[348,1],[350,5],[356,2],[359,5],[365,4],[370,2],[373,3],[377,4],[382,3],[400,1],[414,3],[418,2],[421,3],[429,5],[435,1],[437,2],[440,2],[452,4],[471,1],[473,4],[478,3],[482,4],[501,1],[515,2],[518,3],[522,3],[526,3],[530,3],[534,2],[560,1],[562,2],[565,2],[568,2],[571,3],[575,2],[578,4],[583,3],[612,1],[614,4],[619,4],[624,3],[628,5]]},"793":{"position":[[14,1],[30,1],[45,2],[62,2],[65,2],[82,3],[86,2],[89,2],[92,5],[98,4],[112,1],[119,1],[121,2],[130,1],[132,4],[137,1],[153,1],[155,2],[165,5],[183,2],[192,2],[204,1],[210,1],[212,4],[220,5],[237,2],[240,4],[249,5],[262,2],[265,2],[273,5],[279,4],[291,5],[297,3],[315,1],[317,2],[320,1],[322,2],[344,3],[348,2],[365,3],[369,2],[372,3],[376,4],[381,3],[385,3],[389,3],[404,3],[430,3],[434,4],[439,3],[443,2],[446,6],[453,3],[471,1],[487,4],[506,1],[516,1],[526,1],[528,3],[532,2],[535,2],[538,2],[541,5],[550,2],[567,3],[571,2],[574,2],[592,1],[608,1],[610,3],[628,2],[631,5],[645,2],[648,3],[652,1],[654,3],[658,3],[675,1],[677,4],[682,2],[699,1],[701,4],[706,3],[710,4],[715,2],[718,2]]},"796":{"position":[[14,1],[16,1],[18,2],[41,1],[43,2],[46,1],[48,1],[50,4],[55,2],[65,3],[69,2],[72,3],[76,4],[81,4],[86,2],[104,1],[125,1],[131,1],[133,3],[137,2],[140,2],[143,5],[149,1],[158,1],[160,2],[177,1],[179,5],[185,2],[188,1],[190,2],[193,3],[197,3],[201,4],[220,1],[234,4],[239,2]]},"798":{"position":[[16,1],[39,1],[41,5],[47,2],[65,1],[67,4],[87,1],[104,2],[107,3],[129,1],[143,1],[145,2],[148,5],[162,4],[167,2],[170,3],[174,5],[196,1],[198,4],[203,2],[206,3],[210,4],[215,4],[220,2],[223,2],[241,1],[259,4],[264,2],[267,4],[272,5],[278,3],[298,1],[316,1],[318,4],[323,2],[326,3],[340,1],[342,6],[349,4],[354,5],[360,3],[364,3],[368,2],[371,4],[376,3],[386,1],[388,3],[411,1],[428,1]]},"800":{"position":[[9,3],[35,3],[39,2],[42,2],[45,2],[48,3],[73,1],[75,2],[78,2],[127,1],[129,5],[135,2],[159,1],[165,1],[171,2],[224,2],[227,4],[232,2],[248,2],[251,3],[263,4],[268,2],[284,1],[300,2],[303,2],[306,3],[310,3],[314,2],[317,5],[323,2],[340,1],[346,1],[352,1],[365,1],[367,3],[371,2],[374,1],[376,3],[393,1],[399,1],[412,2],[415,3],[419,2],[422,1],[424,2],[427,5]]},"802":{"position":[[0,3],[11,1],[18,3],[22,3],[41,4],[46,3],[50,1],[52,3],[56,3],[60,2],[63,2],[88,1],[121,1],[123,2],[126,2],[129,3],[144,2],[147,5],[153,2],[167,1],[169,2],[172,4],[177,2],[194,1],[214,1],[216,2],[219,3],[223,3],[227,5],[244,1],[255,2],[258,2],[261,2],[264,4],[269,2],[272,1],[274,2],[277,3],[281,3],[307,1],[309,1],[311,2],[314,3],[318,2],[321,2],[324,2],[327,3],[331,4],[357,1],[359,3],[363,3],[367,3],[393,1],[395,3],[399,3],[403,2],[406,2],[416,1],[433,1],[435,2],[438,3],[442,2],[445,3],[460,2],[463,5],[469,3],[473,1],[475,3],[493,3],[497,2]]},"804":{"position":[[16,5],[44,1],[46,3],[64,1],[66,2],[81,1],[83,3],[87,4],[101,1],[107,3],[111,2],[134,1],[141,2],[144,2],[147,2],[159,1],[165,3],[169,4],[174,3],[178,1],[194,1],[208,2],[211,3],[215,4],[220,4],[225,3],[229,3],[237,1],[239,2],[264,1],[266,3],[284,1],[303,1],[305,5],[311,2],[314,1],[316,2],[319,3],[323,4],[328,1],[339,4],[344,3],[348,5],[354,2],[378,1],[380,4],[385,2]]},"807":{"position":[[2,2],[5,5],[25,1],[27,4],[32,3],[36,2],[44,1],[46,2],[49,1],[51,3],[68,3],[72,2],[75,1],[77,4],[82,4],[87,4],[92,1],[94,4],[99,2],[102,3],[106,4],[111,3],[115,5],[121,2],[124,2],[127,1],[129,4],[134,4],[144,1],[146,3],[150,1],[152,2],[155,3],[159,2],[162,4],[167,2],[170,2],[187,1],[189,1],[191,4],[196,2],[199,5],[205,3],[209,4],[214,4],[219,5],[225,3],[229,1],[231,2],[234,2],[237,4],[242,3],[246,1],[248,3]]},"809":{"position":[[0,3],[20,5],[40,1],[42,2],[52,1],[54,3],[58,2],[61,4],[66,3],[70,3],[74,2],[77,2],[80,2],[83,4],[88,4],[93,4],[102,1],[104,4],[109,3],[113,3],[117,3],[121,2],[124,2],[127,5],[133,3],[151,1],[163,1],[165,3],[169,5],[175,3],[179,3],[183,2],[186,3],[190,4],[202,1],[204,4],[209,3],[213,3],[217,4],[222,3],[226,3],[230,4],[235,4],[240,3],[259,1],[286,3],[290,4],[303,1],[305,2],[308,2],[311,2],[314,2],[317,4],[322,3],[326,3],[330,1],[332,3],[336,3],[340,2],[343,3],[347,3],[356,1],[358,3],[362,2],[372,1],[374,4],[379,4],[384,4],[389,1],[391,3],[395,1],[397,2],[400,3]]},"811":{"position":[[12,1],[39,1],[41,6],[48,3],[66,1],[83,1],[85,5],[94,1],[96,4],[101,3],[113,2],[128,5],[147,1],[149,4],[163,2],[180,1],[182,2],[185,4],[190,2],[193,2],[196,2],[199,2],[216,1],[233,1],[245,4],[250,1],[252,2],[255,3],[259,3],[263,2],[266,2],[276,3],[280,3],[284,3],[288,3],[292,3],[296,6],[303,3],[307,4],[312,2],[315,2],[332,1],[349,1],[351,1],[353,1],[377,1],[379,5],[397,1],[416,1],[418,3],[422,3],[426,2],[429,2],[468,1],[473,1],[475,3],[479,4],[491,1],[521,1],[523,4],[528,2],[542,1],[544,3],[548,4],[553,3],[572,1],[583,3],[604,1],[606,4],[622,1],[624,2],[644,3],[648,4],[667,1],[684,1],[686,2],[689,2],[692,2],[705,1],[707,3],[711,2],[714,2],[717,6],[724,2],[741,1],[758,1],[760,3],[764,1],[766,3],[770,5],[791,2],[798,1],[800,4],[805,5],[811,5],[817,2],[820,3],[844,1],[846,4],[863,1],[865,3],[869,3],[873,2],[911,2],[914,4],[919,4],[924,1],[942,2],[945,2],[948,2],[961,1],[970,2],[973,2],[976,4],[981,2],[984,1],[986,4],[991,5],[997,3],[1001,3],[1018,1],[1027,4],[1032,2],[1035,2],[1038,3],[1042,2],[1045,1],[1047,3],[1051,5],[1057,3],[1075,1],[1077,3],[1101,1],[1103,4],[1108,3],[1112,2],[1132,1],[1134,4],[1139,4],[1144,2],[1147,4],[1152,3],[1156,2],[1159,4],[1164,1],[1166,2],[1193,1],[1195,4],[1200,2],[1228,3],[1232,4],[1237,2],[1240,4],[1245,2]]},"813":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"815":{"position":[[0,1],[2,3],[20,2],[39,3],[43,2],[73,2],[88,1],[90,4],[95,2],[98,5],[104,4],[109,4],[120,1],[138,1],[140,3],[156,1],[174,2],[177,5],[183,2],[203,1],[213,1],[215,4],[220,2],[230,2],[233,3],[264,1],[272,1],[292,1],[294,1],[296,3],[300,2],[306,1],[319,1],[321,2],[324,5],[330,2],[333,1],[335,3],[349,1],[351,3],[369,1],[382,1],[384,2],[387,3],[391,1],[393,3],[397,1],[399,3],[411,1],[419,1],[421,3],[425,2],[428,5],[451,1],[453,2],[467,1],[469,3],[473,3],[477,3],[481,1],[483,3],[487,3],[491,3],[495,3],[513,1],[515,4],[520,4],[525,3],[529,2],[532,3],[536,5],[554,1],[556,3],[573,1],[575,4],[580,2],[599,1],[601,2],[615,1],[617,4],[622,4],[645,4],[650,1]]},"817":{"position":[[4,1],[6,4],[27,1],[29,2],[39,2],[42,2],[45,3],[54,1],[81,1],[108,1],[131,1],[133,4],[138,1],[140,2],[147,1],[154,3],[158,3],[173,3],[204,2],[218,1],[240,1],[249,1],[329,1],[331,4],[349,4],[354,2],[404,2],[431,1],[446,1],[448,3],[464,1],[466,2],[469,4],[481,1],[483,4],[488,2],[491,3],[502,1],[504,5],[527,1],[529,2],[541,1],[543,5],[560,1],[562,4],[567,2],[588,1],[599,2],[602,2],[605,6],[628,2],[631,3],[646,1],[648,4],[653,3],[657,3],[661,3],[665,3],[669,2],[677,1],[679,3],[683,1],[685,3],[689,3],[717,2],[720,2],[723,3],[727,3],[748,1],[750,2],[753,3],[757,2],[760,2],[763,3],[767,2],[777,1],[779,3],[795,1],[797,3],[801,2],[822,1],[828,1],[830,1],[832,3],[836,2],[863,1],[865,3],[881,1],[891,1],[893,4],[898,1],[900,2],[914,1],[925,3],[947,2],[950,3],[965,1],[971,2],[974,3],[992,4],[997,2],[1000,2],[1003,3],[1007,5],[1032,1],[1079,1],[1081,2],[1084,5],[1110,3],[1131,2],[1155,1],[1157,5],[1176,1],[1178,4],[1183,3],[1187,3],[1221,1],[1239,1],[1241,3],[1245,3],[1249,3],[1276,1],[1285,1],[1287,1],[1295,1],[1319,1],[1328,2],[1353,1],[1365,1],[1373,1],[1393,1],[1395,3],[1419,2],[1437,1],[1439,4],[1444,2],[1447,3],[1451,1],[1453,3],[1469,1],[1471,2],[1474,1],[1476,3],[1494,2],[1526,2],[1529,1],[1547,2],[1561,1],[1593,1],[1603,1],[1617,1],[1630,1],[1641,2],[1665,1],[1675,4],[1696,1],[1698,4],[1716,2],[1731,2],[1734,1],[1736,2],[1748,3],[1777,1],[1799,1],[1801,6],[1821,1],[1841,2],[1844,2],[1856,3],[1867,1],[1920,1],[1922,3],[1940,4],[1958,1],[2008,2],[2052,3],[2056,3],[2060,4],[2077,1],[2079,3],[2092,1],[2094,2],[2097,4],[2102,3],[2106,4],[2111,2],[2124,3],[2128,3],[2141,1],[2143,2],[2171,1],[2177,1],[2179,3],[2207,3],[2211,5],[2217,4],[2222,4],[2227,3],[2231,2],[2234,1],[2236,2],[2249,3],[2260,3],[2280,1],[2290,3],[2316,1],[2318,6],[2339,1],[2341,2],[2355,5],[2361,5],[2392,2],[2395,5],[2401,3],[2415,2],[2438,1],[2440,2],[2443,2],[2446,2],[2449,3],[2453,3],[2457,3],[2475,2],[2478,1],[2484,5],[2503,1],[2516,2],[2543,1],[2553,1],[2577,1],[2579,2],[2582,3],[2600,1],[2624,1],[2626,2],[2642,1],[2644,2],[2665,4],[2670,5],[2676,3]]},"819":{"position":[[3,1],[27,1],[29,2],[41,1],[59,2],[73,1],[75,2],[91,1],[105,2],[157,4],[162,3],[189,2],[192,3],[200,1],[202,3],[206,2],[213,1],[237,1],[253,1],[290,1],[292,6],[303,1],[317,1],[319,4],[355,1],[357,3],[373,1],[391,1],[416,1],[429,1],[441,1],[443,2],[464,1],[466,4],[480,3],[495,1],[507,1],[517,2],[520,2],[535,1],[595,1],[597,3],[620,1],[622,2],[631,3],[665,1],[667,2],[687,1],[714,1],[732,1],[740,1],[758,3],[762,2],[781,1],[796,3],[800,3],[811,1],[813,4],[831,1],[833,4],[838,3],[842,2],[859,2],[895,1],[897,6],[918,1],[931,1],[942,1],[957,3],[961,3],[965,3],[969,5],[975,2],[985,1],[987,4],[1017,1],[1019,3],[1030,1],[1032,1],[1034,2],[1037,5],[1057,1],[1077,1],[1096,2],[1113,1],[1115,4],[1120,2],[1123,3],[1127,3],[1145,1],[1162,1],[1177,1],[1179,4],[1184,3],[1188,3],[1192,1],[1194,4],[1199,2],[1217,1],[1230,1],[1239,2],[1242,3],[1269,1],[1335,3],[1343,1],[1356,1],[1358,5],[1364,2],[1383,2],[1386,5],[1392,3],[1410,2],[1429,1],[1431,5],[1441,2],[1481,1],[1504,1],[1506,5],[1515,1],[1517,2],[1520,3],[1530,1],[1542,2],[1561,1],[1573,1],[1579,1],[1581,2],[1631,1],[1633,5],[1639,3],[1655,1],[1714,1],[1716,3],[1724,1],[1740,2],[1750,1],[1767,1],[1769,4],[1834,1],[1867,1],[1869,4],[1890,1],[1892,5],[1898,3],[1902,3],[1910,1],[1924,1],[1926,5],[1932,2],[1935,6],[1969,1],[1978,3]]},"821":{"position":[[22,1],[35,1],[37,2],[40,3],[44,3],[70,2],[108,1],[127,2],[130,3],[144,2],[162,5],[168,3],[184,1],[201,1],[203,3],[213,2],[221,1],[223,3],[227,4],[232,6],[264,1],[266,2],[289,2],[292,5],[318,1],[320,3],[437,1],[453,1],[455,5],[468,1],[485,1],[487,3],[501,2],[504,5],[510,1],[512,3],[516,3],[527,2],[530,3],[540,1],[542,5],[548,5],[561,1],[563,3],[581,1],[593,2],[596,6],[603,3],[614,1],[637,1],[639,5],[645,5],[651,1],[653,2],[663,2],[666,3],[684,2],[687,3],[691,3],[710,1],[719,3],[727,1],[759,1],[782,1],[784,4],[796,3],[815,1],[817,2],[820,3],[824,3],[828,3],[832,3],[836,4],[841,3],[845,3],[849,3]]},"823":{"position":[[15,1],[23,1],[25,2],[28,3],[32,3],[39,3],[59,2],[88,1],[103,3],[110,1],[123,2],[149,1],[151,3],[167,1],[184,2],[192,2],[214,1],[216,3],[239,1],[250,1],[252,5],[273,1],[275,5],[281,3],[342,2],[366,2],[369,2],[378,1],[476,1],[661,1],[663,2],[666,5],[695,1],[727,2],[730,5],[736,6],[743,1],[745,3],[763,1],[765,2],[768,2],[771,2],[774,3],[791,1],[793,5],[799,4],[804,3],[808,2],[827,1],[842,1],[847,1],[849,3],[853,3],[857,2],[905,1],[907,1],[909,2],[912,2],[915,2],[933,1],[935,4],[940,4],[945,2],[951,1],[983,1],[993,4],[998,2],[1021,1],[1032,1],[1034,5],[1040,2],[1071,3],[1087,2],[1090,2],[1093,3],[1097,1],[1099,4],[1111,1],[1113,4],[1118,2],[1121,3],[1125,5],[1131,3],[1135,3],[1139,5],[1160,1],[1162,3],[1166,1],[1168,2],[1171,5],[1177,1],[1179,6],[1195,1],[1197,1],[1199,2],[1202,4],[1207,5],[1251,3],[1255,4],[1276,1],[1278,2],[1302,3],[1306,3],[1326,1],[1337,3],[1341,3],[1345,5],[1373,1],[1384,1],[1394,2],[1410,2],[1413,3],[1424,1],[1426,4],[1431,2],[1451,1],[1478,1],[1480,2],[1483,1],[1485,2],[1488,2],[1504,1],[1512,2],[1535,1],[1537,2],[1547,2],[1576,2],[1579,1],[1592,1],[1594,1],[1596,2],[1599,5],[1621,3],[1639,1],[1641,2],[1644,2],[1647,4],[1652,1],[1654,2],[1670,2],[1687,2],[1690,3],[1697,1],[1705,1],[1707,3],[1711,3],[1715,5],[1721,5],[1727,2],[1730,4],[1740,1],[1742,4],[1754,1],[1773,1],[1775,1],[1777,5],[1783,3],[1787,1],[1815,1],[1817,4],[1835,1],[1837,2],[1840,4],[1845,3],[1849,5],[1855,5],[1861,3],[1883,1],[1885,4],[1890,2],[1904,2],[1907,5]]},"825":{"position":[[13,1],[42,2],[45,5],[51,2],[103,1],[105,2],[123,1],[125,3],[151,1],[156,1],[158,2],[172,1],[174,3],[210,3],[225,1],[255,2],[275,2],[278,3],[282,3],[286,3],[302,1],[311,2],[314,3],[318,3],[322,2],[325,2],[352,2],[355,3],[359,3],[363,2],[373,3],[377,2],[391,3],[395,2],[398,2],[401,2],[411,1],[413,2],[416,3],[420,2],[423,2],[426,2],[429,3],[443,2],[446,2],[449,2],[456,3],[469,1],[471,4],[476,1],[478,1],[480,5],[486,3],[498,2],[501,3],[505,2],[508,1],[517,1],[519,3],[538,1],[540,2],[543,2],[570,1],[590,1],[592,2],[608,4],[613,3],[630,1],[643,1],[645,4],[650,2],[681,1],[683,4],[701,2],[711,2],[761,2],[775,2],[778,2],[781,3],[789,1],[791,2],[877,3],[886,1],[888,2]]},"827":{"position":[[22,3],[26,3],[33,2],[36,3],[106,2],[109,1],[111,2],[114,2],[117,2],[133,1],[152,3],[156,3],[160,1],[167,2],[203,1],[226,1],[228,2],[231,2],[237,1],[257,2],[260,3],[264,1],[266,2],[269,3],[282,1],[284,2],[294,2],[307,1],[309,4],[326,1],[328,2],[338,2],[347,1],[349,3],[353,2],[370,1],[385,1],[413,2],[430,1],[456,1],[461,1],[463,2],[466,4],[471,4],[509,1],[511,2],[528,3],[532,2],[553,1],[561,1],[572,2],[575,3],[586,2],[603,1],[625,1],[627,1],[629,3],[633,2],[658,1],[674,3],[678,3],[704,1],[723,3],[727,2]]},"830":{"position":[[56,1],[58,3],[76,1],[78,2],[81,3],[85,3],[89,2],[92,1],[94,2],[97,3],[101,2],[111,1],[113,2],[126,2],[129,4],[134,2],[137,4],[156,1],[171,4],[176,3],[180,2],[183,2],[186,3],[190,2],[193,4],[198,3],[206,3],[230,1],[232,3],[236,3],[240,2],[243,2],[246,2],[249,4],[263,2],[266,2],[269,3],[273,3],[277,3],[281,2]]},"832":{"position":[[0,2],[3,4],[8,2],[25,1],[42,1],[44,4],[71,1],[73,3],[108,1],[110,3],[146,2],[149,4],[154,3],[177,3],[194,2],[197,3],[204,1],[231,1],[254,2],[257,2],[260,1],[273,1],[295,1],[308,1],[310,2],[340,1],[342,3],[362,1],[364,1],[394,1],[396,2],[409,1],[411,3],[422,1],[434,1],[436,6],[443,2],[458,1],[472,1],[474,1],[492,1],[494,2],[519,3],[523,2],[539,5],[545,2],[560,1],[562,5],[575,1],[577,3],[581,2],[598,4],[603,3],[617,2],[620,2],[623,3],[642,3],[646,2],[649,2],[652,3],[683,1],[709,2],[727,2],[730,1],[732,3],[736,4],[745,4],[750,3],[754,4],[786,3],[802,1],[804,5],[825,1],[827,4],[832,2],[835,3],[877,4],[882,3],[892,1],[894,4],[899,3],[903,2]]},"834":{"position":[[13,2],[36,1],[60,1],[62,3],[66,3],[70,2],[73,1],[75,1],[77,2],[83,1],[111,1],[130,1],[132,4],[137,2],[155,1],[157,2],[160,3],[175,1],[183,1],[194,1],[196,2],[199,2],[202,2],[205,4],[210,3],[224,2],[245,1],[256,1],[258,3],[275,2],[278,2],[281,3],[285,4],[304,1],[306,2],[309,2],[312,4],[317,3],[321,2],[328,3],[332,2],[335,5],[357,2],[360,3],[364,2],[367,2],[384,1],[386,3],[390,5],[396,3],[400,4],[414,1],[416,3],[420,3],[424,2],[437,2],[456,1],[458,2],[461,2],[464,2],[467,2],[481,2],[484,2],[503,2],[519,2],[522,3],[526,4],[531,4],[536,4],[541,4],[591,1],[605,5],[611,1],[613,2],[616,2],[619,3],[623,5],[633,3],[647,4],[659,2],[671,3],[675,2],[706,2],[709,2],[712,4],[717,4],[722,2],[737,1],[739,1],[741,1],[755,1],[760,3],[764,4],[769,3],[773,2],[776,2],[779,2],[782,2],[785,3],[789,2],[797,1],[799,2],[820,1],[822,4],[827,3],[831,4],[836,3],[849,1],[851,3],[855,1],[857,2],[873,1],[881,2],[892,1],[894,4],[899,2],[915,1],[917,4],[922,2],[925,3],[929,4],[934,3],[952,1],[970,3],[974,2],[977,1],[979,4],[987,4],[1005,1],[1007,4],[1012,4],[1017,1],[1019,1],[1021,3],[1051,1],[1066,1],[1068,3],[1072,4],[1077,2],[1080,6],[1101,1],[1103,3],[1107,2],[1110,5],[1116,1]]},"836":{"position":[[28,2],[31,2],[34,1],[36,3],[40,3],[44,2],[47,3],[51,3],[55,2],[58,1],[60,3],[64,1],[66,3],[70,3],[74,2],[101,1],[103,1],[105,3],[116,2],[119,1],[121,1],[123,3],[154,1],[170,1],[172,2],[175,3],[182,3],[186,3],[196,3],[224,1],[226,3],[230,2],[233,2],[270,1],[294,2],[297,2],[337,2],[340,2],[349,2],[361,2],[364,3],[379,1],[381,4],[386,2],[389,2],[392,2],[409,1],[426,1],[436,1],[467,1],[469,4],[474,1],[476,2],[489,1],[491,2],[494,3],[498,3],[516,1],[532,1],[574,1],[583,1],[585,1],[587,3],[603,1],[605,2],[622,1],[630,1],[637,1],[639,2],[642,3],[649,1],[657,2],[671,3],[675,2],[678,2],[681,1],[694,1],[696,2],[706,2],[709,3],[713,2],[716,2],[724,4],[743,1],[769,1],[771,2],[781,1],[783,2],[800,1],[810,2],[820,2],[837,1],[839,2],[842,4],[847,2],[872,4],[877,2],[880,1],[882,2],[895,2],[898,3],[917,4],[922,3],[941,1],[943,2],[946,2],[949,3],[965,1],[984,1],[998,1],[1000,2],[1013,1],[1015,2],[1018,4],[1036,1],[1061,1],[1063,4],[1073,1],[1087,2],[1104,1],[1120,1],[1122,5],[1128,4],[1148,2],[1151,3],[1169,1],[1177,2],[1199,1],[1201,2],[1204,3],[1208,3],[1212,4],[1217,2],[1234,1],[1236,3],[1253,1],[1255,3],[1259,3],[1263,2],[1275,1],[1304,1],[1312,2],[1315,3],[1319,2],[1322,3],[1326,3],[1330,4],[1335,4],[1340,4],[1351,1],[1360,1],[1362,2],[1365,1],[1367,3],[1381,3],[1385,4],[1399,1],[1414,1],[1416,2],[1419,4],[1424,1],[1426,3],[1437,1],[1439,2],[1452,1],[1454,6],[1461,2],[1464,3],[1483,1],[1485,5],[1509,1],[1511,2],[1526,1],[1539,1],[1541,4],[1561,2],[1587,1],[1589,2],[1599,1],[1601,4],[1606,2],[1616,1],[1649,1],[1651,4],[1662,1],[1664,4],[1669,4],[1674,1],[1682,2],[1725,1],[1727,4],[1744,1],[1746,2],[1764,2],[1794,1],[1822,2],[1837,1],[1839,3],[1848,1],[1859,4],[1864,1],[1866,4],[1871,2],[1894,3],[1898,2],[1901,3],[1905,2],[1923,1],[1925,3],[1929,3],[1944,1],[1964,2],[1987,1],[1989,2],[1992,2],[1995,2],[1998,3],[2013,1],[2015,4],[2020,1],[2034,1],[2036,3],[2040,4],[2045,2],[2060,1],[2062,2],[2065,3],[2080,1],[2082,3],[2086,3],[2090,3],[2102,1],[2107,1],[2133,1],[2135,4],[2173,3],[2177,5],[2207,1],[2209,3],[2213,1],[2215,2],[2218,6],[2236,1],[2247,2],[2255,1],[2257,2],[2270,3],[2279,3],[2296,1],[2298,4],[2303,5],[2309,3],[2330,1],[2332,4],[2356,2],[2382,2],[2385,4],[2390,3],[2394,3],[2413,1],[2415,4],[2420,3],[2424,4],[2429,3],[2433,3],[2445,1],[2447,3],[2472,1],[2474,4],[2479,2],[2482,3],[2486,4],[2506,1],[2508,4],[2513,3],[2531,1],[2533,3],[2537,4],[2542,3],[2567,1],[2569,6],[2576,2],[2585,3],[2589,3],[2593,3],[2597,3]]},"838":{"position":[[10,3],[28,1],[30,3],[34,3],[38,2],[41,4],[46,4],[51,4],[56,3],[60,3],[64,2],[89,1],[91,5],[118,1],[120,5],[126,2],[129,3],[133,2],[142,1],[144,3],[148,5],[154,4],[159,5],[177,2],[180,2],[183,2],[200,1],[215,1],[217,2],[231,1],[233,3],[237,2],[240,3],[244,1],[246,2],[258,1],[281,1],[283,2],[312,2],[318,1],[320,2],[333,2],[336,3],[340,3],[344,3],[359,1],[361,4],[384,2],[387,3],[391,3],[417,1],[419,3],[423,5],[429,3],[439,2],[442,4],[447,1],[463,1],[465,2],[476,1],[492,1],[508,4],[513,5],[532,2],[535,3],[539,2],[542,3],[557,1],[559,2],[562,1],[573,2],[585,3],[589,3],[613,1],[615,2],[626,1],[651,1],[680,1],[682,1],[684,1],[686,2],[689,2],[705,1],[707,2],[721,4],[726,2],[734,1],[736,1],[765,2],[777,2],[789,2],[796,5],[802,3],[806,1],[808,2],[811,3],[815,4],[820,2],[833,2],[836,2],[839,4],[844,3],[848,1],[850,3],[854,5],[860,4],[865,2],[890,1],[907,1],[909,5],[915,3],[919,2],[939,2],[942,4],[968,2],[981,2],[992,1],[1006,2],[1028,1],[1030,4],[1040,2],[1043,2],[1064,2],[1067,2],[1070,2],[1073,2],[1076,2],[1095,3],[1099,3],[1103,5],[1109,5],[1115,2],[1118,3],[1125,3],[1129,2],[1132,3],[1136,5],[1142,1],[1144,3],[1161,1],[1172,1],[1174,4],[1192,2],[1195,2],[1205,1],[1207,3],[1216,1],[1218,3],[1222,4],[1227,4],[1232,4],[1237,1],[1239,1],[1241,3]]},"840":{"position":[[17,1],[19,3],[23,5],[29,2],[47,2],[50,3],[54,2],[57,3],[61,4],[71,3],[75,5],[81,1],[83,3],[87,2],[90,2],[93,3],[97,3],[101,4],[106,6],[113,2],[116,3],[120,3],[124,2],[127,3],[135,2],[138,3],[142,4],[147,1],[149,3],[168,1],[170,2],[173,5],[179,2],[182,4],[187,2],[204,1],[221,1],[243,1],[245,5],[251,1],[253,4],[258,2],[261,2],[264,2],[272,1],[278,2],[288,1],[290,4],[295,3],[307,1],[309,6],[329,1],[331,2],[360,1],[372,1],[374,1],[376,5],[382,4],[387,3],[391,1],[401,3],[405,2],[412,2],[415,2],[418,3],[435,1],[437,4],[450,1],[452,2],[455,3],[459,4],[471,1],[473,4],[478,2],[481,2],[484,1],[486,3],[497,1],[513,2],[516,1],[518,1],[520,2],[523,2],[526,2],[547,4],[552,4],[557,2],[560,1],[577,1],[579,2],[582,2],[585,2],[595,1],[611,4],[616,4],[621,2],[624,3],[639,2],[642,2],[645,3],[649,2],[652,3],[672,1],[674,2],[685,1],[696,2],[699,4],[726,1],[728,5],[734,2],[749,1],[751,5],[757,2]]},"842":{"position":[[0,2],[3,3],[14,1],[21,1],[23,3],[27,4],[49,1],[51,4],[56,2],[59,3],[63,2],[66,2],[69,1],[71,3],[75,5],[81,5],[87,2],[90,3],[94,5],[100,4],[105,2],[108,4],[113,3],[131,1],[148,1],[150,2],[180,2],[183,4],[188,3],[192,1],[194,4],[199,3],[223,2],[226,4],[231,5],[237,2],[240,1],[255,1],[257,2],[278,1],[306,2],[309,5],[333,1],[363,1],[393,3],[413,1],[415,5],[421,2],[445,1],[447,2],[474,1],[500,1],[502,4],[507,2],[510,5],[516,3],[532,1],[545,1],[560,1],[576,1],[605,1],[607,2],[621,1],[623,2],[639,1],[641,2],[658,1],[660,2],[690,1],[703,1],[718,1],[734,1],[750,1],[752,2],[771,1],[773,2],[786,1],[799,1],[809,1],[822,1],[829,3],[842,1],[844,2],[858,1],[860,2],[871,1],[873,2],[887,1],[889,2],[898,1],[912,1],[925,1],[935,1],[948,1],[955,1],[957,1],[959,2],[962,1],[964,3],[984,1],[986,2],[989,2],[992,2],[1003,1],[1005,3],[1016,1],[1045,1],[1047,4],[1052,3],[1056,2],[1059,3],[1063,3],[1083,2],[1086,3],[1104,1],[1106,2],[1109,3],[1133,1],[1135,4],[1140,2],[1143,2],[1146,2],[1149,5],[1162,1],[1178,4],[1183,4],[1188,2],[1191,2],[1206,1],[1208,2],[1211,3],[1215,5],[1221,6],[1241,1],[1255,1],[1257,4],[1262,3],[1266,2],[1275,1],[1289,1],[1309,1],[1311,3],[1315,2],[1318,3],[1322,3],[1341,2],[1358,4],[1363,5],[1369,4],[1386,1],[1395,1],[1415,2],[1418,4],[1423,3],[1427,3],[1431,2],[1434,3],[1445,1],[1471,1],[1473,3],[1477,5],[1490,1],[1505,1],[1507,5],[1513,2],[1516,1],[1518,2],[1532,3],[1536,2],[1539,5],[1570,1],[1572,3],[1576,1],[1578,2],[1581,3],[1603,1],[1605,2],[1608,2],[1625,1],[1627,2],[1630,1],[1632,3],[1636,2],[1646,1],[1648,3],[1652,3],[1656,3],[1682,1],[1705,1],[1707,4],[1712,3],[1716,2],[1719,3],[1723,3],[1736,2],[1739,2],[1742,4],[1747,2],[1750,5],[1765,1],[1767,3],[1786,1],[1788,2],[1791,4],[1796,4],[1815,2],[1818,3],[1829,1],[1831,3],[1856,1],[1871,2],[1874,3],[1878,2],[1881,3],[1885,5],[1891,3],[1895,3],[1903,1],[1922,3],[1926,4],[1931,2],[1941,1],[1943,1],[1945,2],[1948,3],[1958,1],[1976,2],[2005,2],[2008,3],[2012,5],[2018,4],[2023,2],[2026,1],[2028,3],[2032,2]]},"844":{"position":[[14,1],[38,1],[56,1],[67,2],[81,1],[83,4],[88,2],[101,2],[121,1],[148,1],[173,3],[177,2],[184,2],[213,2],[230,1],[247,2],[266,1],[301,1],[303,4],[328,1],[362,4],[383,1],[397,2],[400,1],[402,3],[406,2],[429,4],[442,1],[457,3],[493,1],[495,3],[499,2],[502,3],[506,1],[513,1],[544,1],[590,2],[593,4],[598,1]]},"846":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"848":{"position":[[0,2],[8,1],[29,1],[31,4],[36,2],[39,4],[44,3],[48,4],[53,3],[80,1],[82,2],[85,3],[89,2],[92,4],[97,3],[113,2],[116,3],[120,2],[123,3],[127,3],[146,1],[148,7],[156,3],[160,5],[166,4],[171,2],[174,3],[178,4],[183,3],[197,1],[199,5],[212,6],[219,2],[222,3],[226,5],[247,1],[249,4],[254,4],[269,1],[287,1],[289,3],[293,2],[296,3],[316,1],[334,1],[336,4],[358,2],[361,1],[363,2],[366,5],[372,5],[388,1],[390,3],[394,2],[411,1],[433,1],[435,2],[438,7],[446,6],[453,1],[471,1],[473,4],[478,5],[484,3],[550,2],[568,1],[570,2],[573,3],[577,3],[581,4],[612,2],[626,4],[631,5],[637,2],[645,1],[653,1],[659,1],[661,2],[664,4],[669,3],[713,1],[726,1],[728,2],[731,2],[734,1],[745,4],[750,3],[754,5]]},"850":{"position":[[0,2],[3,4],[17,1],[19,3],[23,2],[26,4],[37,1],[39,4],[44,5],[50,1],[52,3],[61,1],[63,4],[72,2],[75,1],[77,4],[82,3],[86,1],[88,2],[96,1],[107,1],[109,3],[113,1],[115,3],[119,3],[123,3],[127,4],[132,2],[135,2],[138,3],[142,3],[146,5],[152,3],[156,5],[162,5],[168,3],[172,3],[176,4],[181,4],[186,3],[190,4],[195,3],[199,2],[202,4],[207,2],[210,2],[213,3],[223,2],[226,4],[231,4],[236,4],[241,3],[245,1],[247,3],[257,1],[259,3],[263,5],[269,3],[273,2],[276,4],[281,3],[285,3],[289,4],[304,2],[307,3],[311,4],[316,5],[322,2],[325,6],[339,2],[358,1],[360,3],[364,2],[367,3],[387,2],[390,5],[396,2],[399,2],[402,6],[419,1],[421,2],[443,1],[445,5],[451,1],[478,1],[507,3],[511,3],[515,4],[520,2],[523,3],[527,4],[532,3],[536,1],[538,1],[540,5],[546,5],[552,2],[555,3],[559,1],[561,2],[564,3],[568,3],[572,4],[577,4],[582,3],[586,3],[590,4],[595,2],[598,5],[604,3],[617,2],[636,1],[668,1],[670,2],[702,1],[719,1],[721,4],[726,2],[729,3],[733,3],[737,5],[743,3],[747,3],[751,3],[755,3],[779,3],[783,3],[787,6],[794,1],[796,4],[801,3],[805,3],[809,2],[812,3],[816,2],[819,3],[823,4],[828,3],[832,5],[838,2],[841,3],[845,5],[851,3],[855,3],[859,3],[863,2],[868,2],[871,3],[875,5],[968,1],[970,3],[996,2],[1035,1],[1037,2],[1056,2],[1059,5],[1083,1],[1102,1],[1104,3],[1108,1],[1110,2],[1113,3],[1117,4],[1122,5],[1138,1],[1147,2],[1171,2],[1174,3],[1178,5],[1184,4],[1189,2],[1192,3],[1196,3],[1200,4],[1220,3],[1231,2],[1248,1],[1250,4],[1255,2],[1258,2],[1261,1],[1263,3],[1267,3],[1280,3],[1291,1],[1293,2],[1315,5],[1321,3],[1343,1],[1345,3],[1349,4],[1354,2],[1357,2],[1360,4],[1365,1],[1367,5],[1389,1],[1391,2],[1394,3],[1398,2],[1401,2],[1404,5],[1417,1],[1419,2],[1422,1],[1424,4],[1429,3],[1433,2],[1436,3],[1444,1],[1491,1],[1493,2],[1496,4],[1501,3],[1505,4],[1510,3],[1514,2],[1517,3],[1521,3],[1525,3],[1529,3],[1533,2],[1536,2],[1539,2],[1563,1],[1565,1],[1567,3],[1571,2],[1619,1],[1699,1],[1710,1],[1724,2],[1727,2],[1730,3],[1734,5],[1740,3],[1744,1],[1746,3],[1755,3],[1780,1],[1791,2],[1814,1],[1825,2],[1850,1],[1862,2],[1865,2],[1872,2],[1875,6],[1882,2],[1898,1],[1900,3],[1904,3],[1917,3],[1921,2],[1924,3],[1938,5],[1944,3],[1948,2],[1958,1],[1966,1],[1984,1],[2000,1],[2002,3],[2006,4],[2011,4],[2033,2],[2036,4],[2057,1],[2059,3],[2063,5],[2085,1],[2087,3],[2091,4],[2096,3],[2100,3],[2104,4],[2109,1],[2111,2],[2114,5],[2120,2],[2123,5],[2129,3],[2149,1],[2151,5],[2162,5],[2168,3],[2172,3],[2181,3],[2194,3],[2198,3],[2202,2],[2205,2],[2215,5],[2231,1],[2233,3],[2246,3],[2250,2],[2253,2],[2256,4],[2261,3],[2265,4],[2270,3],[2301,2],[2309,2]]},"853":{"position":[[0,3],[4,1],[6,2],[9,3],[13,3],[17,2],[20,3],[36,1],[43,1],[52,1],[54,3],[83,1],[94,1],[96,3],[107,1],[115,1],[117,4],[153,1],[172,1],[180,1],[182,4],[187,2],[216,1],[218,3]]},"855":{"position":[[6,1],[14,3],[18,3],[27,1],[36,3],[40,2],[43,3],[60,1],[62,4],[67,4],[72,3],[92,3],[96,5],[111,3],[146,4],[158,2],[181,1],[183,3],[187,3],[212,3],[216,3],[220,4],[242,1],[250,1],[252,3],[256,3],[264,3],[268,5],[274,3],[278,3],[299,1],[321,2],[329,1],[349,1],[351,2],[354,3],[358,4],[363,3],[367,3],[371,2],[374,3],[378,4],[383,2],[386,3],[396,2],[399,4],[412,1],[414,4],[446,1],[448,5]]},"857":{"position":[[20,1],[42,1],[50,1],[52,3],[63,1],[65,4],[70,4],[75,1],[77,3],[81,3],[85,1],[87,3],[102,1],[104,4],[109,3],[113,3],[130,2],[133,3],[137,4],[155,1],[157,2],[175,1],[177,4],[182,4],[193,1],[211,3],[215,6],[222,3],[242,1],[244,5],[265,1],[267,3],[278,1],[298,1],[300,4],[311,3],[315,4],[345,1],[347,3],[367,2],[391,1],[413,1],[415,4],[420,2],[423,4],[459,2],[478,1],[497,1],[499,2],[509,4],[524,2],[531,1],[533,2],[536,5],[542,4],[547,2],[550,2],[567,5],[573,3],[584,1],[586,2],[589,3],[601,3],[605,5],[611,3],[620,1],[622,2],[625,4],[630,4],[635,2],[638,4],[643,5]]},"859":{"position":[[4,1],[28,1],[44,1],[46,2],[67,1],[69,4],[74,2],[101,1],[103,5],[129,2],[132,3],[136,3],[140,3],[181,2],[218,1],[248,1],[250,5],[278,1],[280,5],[286,4],[300,1],[302,5],[308,1],[319,1],[336,2],[339,2],[342,3],[346,3],[350,2],[359,1],[371,1],[373,5],[379,2],[409,3],[419,1],[436,1],[438,3],[442,1],[444,2],[447,2],[459,1],[461,3],[465,3],[493,1],[512,2],[515,3],[519,1],[521,3],[525,2],[528,2],[537,1],[539,2],[561,1],[563,4],[568,3],[572,2],[595,1],[617,1],[619,3],[623,3],[627,2],[630,2],[633,3],[644,1],[646,2],[649,3],[659,2],[668,1],[670,2],[673,3],[677,2],[689,3],[718,3],[722,2],[744,1],[746,2],[749,2],[782,1],[802,3],[806,2],[815,1],[817,3],[821,2],[840,1],[842,4],[847,3],[851,4],[872,3],[876,3],[880,2]]},"861":{"position":[[10,3],[14,2],[17,5],[34,1],[53,3],[72,2],[81,1],[89,1],[109,1],[111,4],[116,2],[119,4],[124,2],[127,3],[131,2],[134,5],[140,4],[145,2],[148,4],[153,3],[157,3],[161,4],[166,2],[169,5],[178,5],[203,1],[223,1],[225,5],[253,1],[262,1],[281,1],[283,5],[289,1],[291,1],[311,2],[322,3],[326,2],[329,2],[332,6],[339,2],[348,2],[351,2],[354,3],[358,3],[362,4],[367,2],[386,1],[388,2],[415,1],[417,2],[420,3],[424,3],[428,3],[432,3],[436,4]]},"863":{"position":[[12,3],[22,1],[24,3],[28,6],[58,1],[60,2],[73,1],[88,1],[114,2],[117,4],[137,1],[139,2],[151,1],[163,1],[165,2],[182,3],[212,1],[214,4],[219,2],[222,3],[238,2],[245,2],[248,2],[251,3],[255,3],[259,1],[261,2],[273,4],[287,1],[289,4],[294,2],[319,1],[355,3],[359,4],[384,1],[386,4],[401,1],[403,2],[418,1],[430,1],[432,2],[479,1],[503,1],[505,3],[509,2],[512,4],[517,5],[551,1],[553,3],[557,3],[561,3],[565,3],[569,2],[579,4],[584,5],[600,1],[619,1],[621,4],[626,5],[632,1],[644,2],[659,1],[671,1],[673,5],[679,3],[683,2],[686,2],[689,2],[692,1],[703,3],[713,4],[734,3],[738,2]]},"870":{"position":[[9,1],[14,1],[36,2],[39,3],[43,5],[69,1],[71,3],[75,2],[92,3],[96,6],[128,1],[130,2],[133,1],[135,3],[139,1],[141,3],[162,1],[181,2],[199,1],[201,6],[208,2],[211,4],[243,2],[246,4],[264,2],[267,2],[270,3],[284,1],[303,1],[305,4],[310,2],[313,5],[335,1],[337,5],[385,1],[387,6],[411,4],[416,3],[420,2],[430,1],[432,2],[445,2],[448,2],[451,2],[454,3],[458,4],[463,2],[466,2],[469,2],[472,3],[489,3],[493,4],[498,1],[500,2],[503,3],[507,2],[510,3],[514,2],[517,1],[519,3]]},"872":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"874":{"position":[[4,1],[6,3],[10,6],[39,1],[41,2],[44,2],[47,2],[80,1],[82,4],[98,1],[100,5],[125,1],[127,2],[152,4],[157,2],[160,5],[166,3],[170,3],[184,1],[186,4],[191,2],[213,2],[216,3],[220,2],[237,1],[239,4],[244,2],[247,1],[249,2],[252,4],[257,3],[261,5],[267,2],[270,2],[273,3],[289,1],[291,3],[295,2],[298,2],[312,2],[315,3],[319,1],[321,3],[325,3],[329,2],[332,3],[336,3],[343,1],[345,3],[358,1],[372,1],[374,1],[376,2],[379,1],[381,3],[395,3],[399,5],[425,1],[450,2],[453,1],[455,3],[469,5],[475,4],[502,1],[504,2],[507,3],[511,3],[515,2],[518,3],[522,3],[526,3],[530,4],[535,1],[537,3],[558,4],[563,5],[569,5],[575,6],[582,2],[585,1],[587,2],[590,3],[594,5]]},"876":{"position":[[26,1],[48,3],[64,1],[66,2],[69,5],[75,2],[98,1],[100,3],[104,2],[107,5],[122,2],[133,1],[135,4],[140,3],[144,4],[149,2],[152,3],[156,4],[161,4],[171,1],[173,2],[201,1],[207,1],[230,1],[232,5],[238,2],[249,1],[251,1],[253,4],[279,3],[283,3],[287,1],[289,3],[293,4],[298,3],[317,1],[319,2],[332,1],[338,1],[340,1],[342,3],[363,5],[369,3],[406,1],[428,1],[430,3],[434,6],[452,3],[489,2],[502,1],[504,5],[532,1],[547,1],[561,3],[575,2],[578,3],[582,2],[585,3],[589,2],[592,3],[610,1],[612,4],[632,1],[653,1],[655,2],[658,3],[662,5],[683,1],[685,3],[689,5],[711,1],[713,2],[716,5],[722,4],[739,3],[748,1],[750,2],[753,1],[755,3],[759,3],[789,2],[825,1],[827,3],[862,1],[867,1],[880,1],[901,2],[904,5],[910,2],[929,1],[931,4],[951,1],[953,3],[957,3],[961,3],[965,3],[969,2],[972,2],[975,2],[978,5],[984,3],[995,2],[998,3],[1005,2],[1008,4],[1016,2],[1019,3],[1023,4],[1028,2],[1075,2],[1078,3],[1082,5],[1088,3],[1092,3],[1096,2],[1099,3],[1103,3],[1114,1],[1116,4],[1144,2],[1147,3],[1151,3],[1155,3],[1159,1],[1161,2],[1164,4],[1169,3],[1180,1],[1195,2],[1201,1],[1203,2],[1206,2],[1214,2],[1217,2],[1220,3],[1231,1],[1233,2],[1255,1],[1257,2]]},"879":{"position":[[4,1],[6,2],[29,1],[41,3],[51,2],[65,1],[67,5],[103,3],[107,5],[117,1],[131,2],[134,2],[137,3],[148,1],[150,1],[152,3],[175,1],[177,5],[183,3],[193,1],[202,2],[205,5],[211,5],[217,2],[220,2],[223,2],[226,4],[231,3],[235,6],[242,2],[265,2],[277,1],[303,3],[317,1],[319,4],[324,3],[347,2],[360,1],[382,1],[408,1],[410,4],[415,2],[418,2],[422,1],[426,1],[448,3],[452,1],[464,1],[466,2],[469,1],[471,5],[477,3],[509,2],[512,4],[527,1],[546,1],[548,2],[562,1],[579,1],[581,5]]},"881":{"position":[[20,1],[22,4],[42,1],[44,5],[72,1],[74,1],[76,3],[80,4],[85,2],[90,3],[104,2],[107,2],[110,2],[113,3],[130,1],[132,5]]},"883":{"position":[[10,1],[47,1],[121,1],[132,1],[134,4],[139,4],[144,1],[146,2],[154,1],[156,2],[184,1],[186,2],[208,1],[210,3],[223,1],[225,2],[259,2],[271,1],[273,2],[276,3],[299,1],[301,3],[305,2],[308,3],[312,3],[320,1],[352,1],[395,1],[447,2],[450,2],[453,4],[462,1],[464,5],[470,3],[486,1],[488,3],[492,3],[524,1],[526,1],[528,1],[530,4],[535,1],[537,2],[540,3],[552,2],[555,1],[557,1],[559,3],[563,1],[565,3],[569,3],[573,2],[576,3],[580,2],[583,2],[593,1],[597,1],[599,3],[603,2],[606,1],[608,3],[624,1],[626,4],[644,1],[667,1],[673,3],[686,1],[711,1],[713,2],[716,3],[720,2],[723,1],[725,3],[746,2],[759,1],[761,1],[763,2],[766,2],[769,2],[795,1],[801,3],[810,1],[812,2],[815,4],[820,3],[824,1],[826,2]]},"885":{"position":[[3,1],[11,1],[13,6],[20,2],[23,2],[32,1],[51,1],[53,3],[57,3],[65,1],[67,2],[70,2],[73,3],[77,2],[80,2],[83,3],[87,1],[89,3],[93,3],[111,1],[160,1],[176,1],[178,4],[183,2],[186,2],[190,1],[194,1],[196,2],[199,3],[203,1],[205,3],[223,1],[229,1],[242,1],[244,2],[286,2],[289,2],[306,1],[308,1],[310,3],[314,3],[341,1],[355,1],[357,3],[368,3],[424,2],[441,1],[443,3],[447,4],[463,1],[465,2],[509,1],[557,1],[630,1],[639,3],[643,3],[647,2],[664,1],[666,2],[669,2],[678,1],[687,1],[689,2],[692,2],[704,1],[709,2],[712,3],[716,2],[719,3],[730,2]]},"887":{"position":[[0,3],[4,4],[9,2],[18,1],[20,2],[42,2],[65,1],[67,3],[71,2],[74,2],[77,2],[80,4],[92,1],[94,2],[104,3],[108,4],[129,1],[131,2],[134,3],[145,1],[147,2],[150,3],[154,3],[158,3],[175,3],[179,4],[184,4],[189,2],[192,2],[195,2],[198,3],[241,3],[245,1],[247,3],[251,1],[253,3],[273,1],[282,2],[285,3],[289,5]]},"889":{"position":[[0,3],[4,3],[8,5],[24,3],[28,2],[31,4],[36,2],[39,5],[45,3],[95,1],[97,3],[101,3],[152,1],[154,2],[171,2],[174,5],[180,3],[190,4],[195,2],[198,2],[211,2],[249,1],[260,3],[264,2],[298,1],[300,2],[317,2],[320,2],[323,3],[327,3],[331,2],[334,3],[338,2],[341,3],[345,1],[347,1],[349,2],[362,3],[366,3],[370,2],[406,2],[409,2],[412,5],[418,4],[423,2],[426,4],[431,2],[434,4],[439,3],[443,3],[447,2],[494,2],[507,1],[509,5],[515,3],[519,2],[532,2],[535,3],[539,3],[543,4],[548,3],[552,2]]},"891":{"position":[[28,1],[46,1],[48,4],[53,3],[57,3],[115,1],[117,4],[122,2],[130,1],[132,2],[135,3],[148,1],[150,4],[164,1],[166,2],[169,1],[171,2],[174,5],[180,3],[190,1],[199,1],[201,2],[204,1],[206,3]]},"893":{"position":[[0,2],[16,1],[32,1],[34,5],[40,2],[48,1],[56,1],[58,2],[61,3],[65,4],[70,2],[73,2],[81,1],[83,2],[105,1],[107,2],[110,1],[126,1],[128,1],[130,2],[147,3],[151,3],[155,3],[169,1],[171,2],[174,1],[189,1],[191,2],[212,3],[216,2],[219,3],[223,3],[227,3],[231,2],[234,1],[249,1],[265,2],[268,2],[271,2],[299,2],[317,1],[319,2],[322,1],[340,1],[353,1],[355,2],[364,2],[367,1],[369,3],[373,5]]},"895":{"position":[[0,2],[3,5],[16,1],[18,3],[22,3],[26,3],[30,4],[44,1],[46,4],[51,4],[56,4],[61,3],[70,5],[79,1],[91,1],[93,4],[98,2],[101,4],[106,3],[125,1],[127,5],[171,4],[208,1],[223,1],[225,2],[228,4],[233,2],[241,1],[243,3],[247,3],[251,3],[255,4],[260,2],[277,1],[279,4],[284,3],[523,4],[548,1],[571,2],[600,2],[603,2],[606,3],[619,1],[621,2]]},"897":{"position":[[0,2],[3,3],[16,1],[18,5],[24,3],[33,1],[35,2],[38,2],[41,3],[45,1],[47,3],[51,1],[53,2],[56,3],[60,3],[71,1],[73,4],[78,4],[83,2],[86,1],[88,3],[92,3],[96,2],[99,2],[102,4],[107,3],[116,1],[118,1],[120,2],[123,3],[127,2],[137,5],[143,3],[154,1],[156,5],[162,3],[166,1],[168,2],[171,1],[173,3],[177,4],[182,2],[194,1],[196,4],[201,4],[206,5],[212,3],[232,1],[234,2],[237,3],[241,3],[263,1],[268,1],[270,3],[274,3],[278,2],[281,4]]},"899":{"position":[[16,3],[20,3],[24,3],[65,1],[78,2],[81,4],[95,1],[97,2],[100,3],[104,2],[125,3],[129,6],[136,3],[163,1],[165,2],[177,2],[184,1],[190,2],[206,2],[225,1],[227,2],[266,1],[268,2],[271,2],[281,2],[295,2],[298,2],[301,2],[304,4],[309,4],[314,2],[324,1],[326,2],[329,3],[333,3],[337,1],[339,5],[345,2],[348,4],[353,3],[357,3],[361,2],[364,3],[368,3],[372,3],[399,4],[404,2],[407,2],[410,1],[412,3],[420,1],[431,1],[433,3],[437,1],[450,2],[453,1],[455,3],[465,1],[467,2],[481,2],[484,2],[513,2],[516,3],[520,2],[545,1],[547,5],[553,2],[556,4],[561,2],[564,2],[567,2],[570,2],[573,1],[582,3],[586,2],[589,2],[603,1],[605,2],[624,1],[626,4],[631,3],[635,3],[639,3],[665,3],[669,2],[672,3],[683,1],[685,2],[688,3],[692,3],[696,4],[701,3],[708,1],[710,3],[717,1],[719,2],[731,2],[749,1],[751,3],[755,2],[758,2],[764,1],[781,1],[783,3],[787,3],[807,2],[813,1],[822,2],[825,3],[829,2],[832,2],[835,3],[839,5],[845,1],[849,1],[854,1],[856,1],[864,1],[897,1],[899,5],[905,4],[910,3],[914,2],[917,4],[922,2],[929,4],[934,3],[938,5],[944,3],[948,3],[952,1],[960,1],[962,4],[976,1],[978,4],[999,1],[1001,2],[1004,2],[1007,2],[1032,1],[1049,1],[1056,1],[1058,2],[1061,1],[1066,1],[1068,4],[1100,2],[1112,2],[1115,3],[1128,2],[1131,4],[1136,4],[1147,1],[1161,1],[1163,2],[1173,1],[1175,2],[1178,1],[1180,2],[1183,3],[1190,2],[1207,1],[1209,4],[1214,2],[1217,2],[1220,3],[1224,2]]},"901":{"position":[[18,1],[23,1],[25,5],[36,1],[38,5],[44,3],[48,2],[51,3],[55,4],[60,3],[67,1],[69,3],[73,3],[77,2],[90,1],[92,5],[98,2],[101,5],[107,1],[109,3],[113,1],[115,2],[118,3],[122,4],[136,3],[140,4],[145,3],[149,3],[153,4],[158,4],[163,3],[167,2],[170,2],[182,1],[198,1],[200,5],[206,2],[209,3],[213,2],[216,2],[219,3],[239,1],[241,4],[246,2],[249,3],[253,1],[255,2],[258,2],[261,5],[267,2],[270,2],[273,4],[278,4],[283,3],[322,1],[330,1],[364,1],[366,4],[371,4],[376,4],[381,3],[385,3],[399,5],[405,2],[502,1],[624,6],[652,1],[669,1],[671,4],[685,1],[687,4],[692,1],[709,3],[713,2],[716,6],[752,1],[814,1],[829,1],[831,2],[834,2],[852,2],[855,5],[861,2],[873,1],[892,1],[920,2],[923,2],[926,3],[930,2],[947,2],[950,5],[956,3],[960,3],[979,2],[982,5],[991,1],[1026,1],[1028,2],[1031,4],[1052,2],[1055,4],[1060,4],[1065,4],[1070,1],[1072,4],[1077,2],[1080,2],[1086,1],[1094,4],[1099,2],[1102,3],[1106,4],[1120,1],[1122,2],[1125,2],[1128,3],[1132,4],[1137,2],[1150,1],[1152,5],[1158,1],[1160,3],[1164,2],[1167,5],[1173,4],[1178,3],[1182,1],[1184,2],[1187,5],[1193,2],[1200,1],[1202,2],[1205,3],[1209,3],[1223,1],[1225,4],[1230,4],[1235,3],[1239,4],[1244,5],[1265,1],[1267,2],[1291,1],[1293,2],[1314,1],[1316,3],[1320,2],[1323,3],[1327,1],[1329,1],[1331,3],[1335,3],[1346,1],[1348,3],[1352,2],[1355,4],[1375,1],[1377,2],[1392,1],[1409,3],[1473,2],[1476,4],[1481,3],[1492,1],[1512,1],[1514,5],[1520,2],[1527,1],[1540,1],[1542,2],[1554,2],[1557,4],[1571,1],[1573,2],[1576,1],[1585,1],[1587,4],[1592,2],[1595,3],[1599,3],[1603,1],[1605,3],[1609,3],[1613,2],[1616,4],[1632,2],[1644,1],[1646,5],[1652,2],[1655,4],[1660,1],[1662,2],[1680,1],[1682,3],[1686,2],[1689,1],[1691,2],[1698,1],[1700,1],[1708,1],[1710,2],[1727,1],[1729,3],[1733,5],[1739,1],[1750,1],[1752,4],[1757,5],[1779,1],[1781,2],[1784,5],[1790,2],[1802,2],[1805,4],[1810,4],[1829,4],[1834,4],[1842,1],[1844,2],[1863,1],[1871,1],[1873,3],[1897,1],[1899,5],[1940,3],[1970,2],[1973,3],[1998,1],[2008,4],[2013,4],[2018,2],[2024,1],[2035,1],[2037,2],[2058,1],[2060,2],[2063,3],[2067,3],[2086,1],[2088,4],[2093,3],[2110,2],[2113,5],[2119,3],[2140,1],[2149,1],[2151,4],[2156,3],[2160,2],[2163,3],[2167,2],[2179,1],[2181,3],[2198,1],[2200,2],[2206,1],[2239,2],[2242,2],[2245,4],[2250,3],[2263,1],[2265,3],[2269,2],[2272,2],[2275,3],[2293,1],[2295,2],[2315,3],[2319,2],[2338,1],[2340,3],[2368,1],[2370,2],[2381,2],[2384,3],[2388,2],[2395,1],[2412,1],[2427,1],[2443,2],[2475,1],[2477,3]]},"903":{"position":[[25,1],[27,2],[30,4],[62,1],[64,4],[90,1],[92,4],[97,2],[100,2],[116,1],[132,3],[136,2],[139,5]]},"905":{"position":[[7,1],[9,3],[13,4],[18,2],[21,4],[26,4],[31,3],[35,3],[39,3],[49,1],[66,1],[79,1],[81,2],[90,1],[92,2],[95,2],[109,1],[111,4],[121,1],[123,2],[144,2],[160,1],[162,3],[175,1],[177,2],[180,2],[183,3],[187,2],[204,1],[206,2],[222,1],[229,1],[231,2],[234,4],[255,1],[270,1],[287,3],[291,3],[325,2],[350,1],[352,2],[355,5],[387,1],[402,1],[404,2],[407,2],[414,2],[460,2],[463,2],[466,5]]},"907":{"position":[[0,3],[31,1],[33,4],[38,3],[49,1],[51,2],[61,2],[64,4],[69,2],[72,2],[102,1],[104,4],[109,5]]},"909":{"position":[[15,1],[44,1],[46,3],[64,1],[66,2],[69,4],[74,4],[79,3],[83,2],[107,1],[136,1],[138,2],[141,2],[144,2],[151,1],[175,1],[177,2],[199,3],[220,2],[234,1],[247,1],[249,2],[252,4],[257,2],[260,3],[283,1],[305,1],[327,1],[364,1],[366,2],[369,3],[373,2],[376,3],[380,2],[388,1],[390,3],[394,1],[396,4],[401,2],[408,1],[421,1],[423,3],[427,3],[431,2],[434,3],[438,2],[520,1],[522,4],[527,2],[533,1],[571,1],[573,2],[597,2],[600,3],[604,4],[609,2],[612,1],[614,1],[616,2],[619,2],[622,3],[647,1],[669,2],[672,3],[676,2],[683,1],[725,1],[727,3],[734,1],[736,4],[741,2],[744,2],[747,1],[749,3],[753,2],[756,2],[759,3],[763,3]]},"911":{"position":[[0,2],[3,3],[14,2],[17,4],[22,2],[25,3],[29,2],[32,2],[35,2],[50,3],[77,1],[79,4],[118,2],[151,1],[153,5],[172,1],[174,4],[192,1],[194,2],[204,1],[233,5],[264,1],[281,1],[283,4],[288,2],[291,2],[294,2],[304,1],[306,2],[316,1],[318,2],[321,2],[324,3],[328,3],[363,1],[430,1],[449,3],[453,2],[456,2],[459,3],[463,3],[467,3],[471,2],[474,3],[478,2],[500,1],[502,4],[525,1],[527,4],[557,1],[559,2],[582,1],[584,3],[588,2],[591,6],[598,2],[608,2],[611,4],[616,2],[628,1],[640,2],[666,1],[668,4],[673,3],[677,3],[692,2],[695,1],[697,2],[700,1],[702,2],[705,3],[709,3],[713,3],[717,2],[720,2],[723,2],[726,5],[732,4],[748,1],[750,5],[766,1],[768,2],[782,2],[785,3],[789,2],[803,1],[815,1],[847,1],[849,4],[854,3],[878,1],[880,2],[883,2],[886,5],[892,3],[916,1],[932,1],[934,2],[937,3],[941,4],[953,2],[959,1],[961,2],[964,3],[968,3],[976,3],[980,4],[985,4],[1009,3],[1013,5],[1056,1],[1058,2],[1061,2],[1064,3],[1078,4],[1083,4],[1105,1],[1107,2],[1110,3],[1114,4],[1132,1],[1134,2],[1145,1],[1147,2],[1150,5],[1156,3],[1169,1],[1171,2],[1181,3],[1185,4],[1193,1],[1206,1],[1208,2],[1211,2],[1214,4],[1219,4],[1224,2],[1227,2],[1241,1],[1243,2],[1269,1],[1271,2],[1274,2],[1277,2],[1280,2],[1283,3],[1287,2],[1290,2],[1293,3],[1297,4],[1302,4],[1314,1],[1316,2],[1319,2],[1340,1],[1342,3],[1366,1],[1368,5],[1386,1],[1388,3],[1392,1],[1394,3],[1398,3],[1402,3],[1406,2]]},"913":{"position":[[0,2],[3,3],[7,7],[15,4],[20,1],[22,2],[43,1],[45,4],[50,4],[55,5],[64,3],[68,1],[82,1],[84,2],[87,2],[90,3],[94,4],[122,1],[124,2],[127,1],[129,4],[134,2],[153,1],[155,6],[175,1],[177,3],[181,3],[185,2],[188,4],[193,1],[195,3],[202,2],[205,3],[209,4],[214,4],[219,2],[222,1],[224,3],[228,4],[233,5]]},"915":{"position":[[22,1],[47,1],[49,4],[54,4],[59,3],[63,2]]},"917":{"position":[[18,1],[20,2],[23,2],[26,2],[47,1],[49,3],[53,4],[74,1],[92,2],[113,1],[115,1],[117,3],[121,2],[124,4],[136,1],[138,3],[142,2],[164,2],[167,2],[186,1],[188,3],[192,3],[214,1],[216,2],[219,3],[223,1],[225,2],[228,1],[230,2],[233,4],[238,3],[242,3],[246,3],[250,3],[254,4],[259,2],[262,4],[267,3],[271,2],[292,1],[294,2],[304,1],[306,4],[311,2],[351,2],[476,1],[494,1],[496,2],[499,2],[502,4],[511,1],[520,2],[523,2],[526,2],[529,2],[532,3],[536,4],[545,3],[562,1],[564,2],[567,2],[570,2],[577,1],[589,5],[604,2],[607,2],[610,3],[614,3],[618,3],[622,1],[624,3],[628,3],[632,2],[645,1],[668,3],[672,3],[683,1],[685,4],[690,2],[693,2],[696,4],[701,3],[705,2],[727,1],[736,1],[738,2],[741,1],[750,1],[767,1],[769,4],[774,3],[785,1],[794,3],[798,2],[801,3],[805,5],[811,6],[821,1],[823,5],[843,4],[848,5],[854,1],[863,1],[872,2],[879,1],[881,2],[884,3],[897,3],[901,3],[905,3],[909,2],[912,2],[924,1],[926,5],[932,4],[937,4],[942,1],[951,1],[960,1],[962,2],[981,1],[1003,3],[1007,3],[1018,1],[1020,3],[1024,4],[1029,2],[1032,3],[1036,3],[1040,2],[1075,1],[1077,2],[1080,3],[1084,2],[1087,3],[1091,3],[1095,2],[1098,4],[1140,1],[1142,2],[1145,3],[1165,3],[1169,2],[1172,2],[1175,1],[1177,4],[1182,2],[1195,5],[1213,1],[1215,4],[1220,3],[1233,2],[1236,3],[1240,2],[1297,1],[1299,2],[1320,3],[1324,5],[1330,2],[1349,1],[1351,2],[1354,3],[1358,4],[1363,2],[1423,2],[1536,1],[1538,4],[1550,2],[1559,1],[1561,1],[1623,1],[1625,2],[1628,3],[1632,3],[1636,2],[1639,3],[1656,1],[1658,4],[1663,4],[1668,2],[1671,2],[1674,1],[1676,3],[1680,3],[1684,4],[1689,3],[1693,2],[1696,3],[1700,3],[1704,4],[1709,2]]},"919":{"position":[[20,1],[45,1],[47,1],[52,2],[65,1],[67,6],[74,2],[77,5],[83,2],[93,1],[95,5],[101,3],[105,1],[107,2],[126,1],[128,3],[132,4],[137,1],[139,4],[144,3],[153,3],[157,4],[162,3],[166,3],[170,3],[174,3],[178,3],[182,3],[186,3],[195,1],[197,2],[207,1],[209,3],[213,1],[215,2],[241,2],[244,3],[248,2],[251,3],[255,2],[258,3],[262,4],[267,1],[269,5],[275,5],[281,5],[287,2],[290,4],[295,2],[315,1],[317,2],[320,4],[325,2],[328,3],[332,3],[345,5],[351,3],[355,2],[358,3],[362,4],[374,1],[376,2],[379,5],[391,1],[393,3],[397,3],[401,3],[408,1],[422,1],[424,3],[431,1],[433,4],[438,4],[443,3],[447,3],[451,3],[455,4],[486,1],[488,2],[491,2],[510,1],[512,3],[516,3],[520,4],[525,4],[530,3],[534,3],[541,1],[559,1],[561,3],[565,2],[568,3],[572,3],[576,4],[581,1],[583,2],[586,1],[588,3],[592,2],[595,3],[599,4],[604,2],[615,2],[618,2],[621,2],[627,1],[649,2],[652,2],[655,3],[659,2],[662,3],[666,3],[677,3],[697,1],[699,4],[704,2],[707,2],[714,1],[726,1],[728,2],[747,1],[749,4],[766,1],[768,4],[773,2],[776,2],[782,1],[804,1],[806,2],[825,1],[827,4],[832,3],[836,5],[842,2],[845,3],[849,2],[852,3],[856,2],[862,1],[867,3],[878,2],[881,4],[886,5],[892,2],[898,2],[901,4],[926,1],[937,1],[946,1],[948,4],[953,3],[981,1],[983,3],[987,3],[991,1]]},"921":{"position":[[19,1],[21,2],[24,2],[27,5],[33,4],[38,1],[40,2],[43,3],[47,5],[53,2],[56,2],[59,5],[65,4],[87,1],[89,4],[94,2],[122,1],[124,3],[128,1],[130,2],[133,2],[136,3],[140,4],[145,4],[150,2],[153,2],[156,1],[158,2],[161,3],[165,3],[169,2],[172,4],[177,3],[181,1],[183,3],[190,1],[192,2],[195,2],[198,1],[200,2],[203,3],[207,2],[210,2],[213,3],[217,2],[231,1],[233,5],[239,2],[242,2],[245,3],[249,4],[254,3],[265,1],[267,2]]},"923":{"position":[[0,1],[2,3],[6,2],[9,3],[13,4],[18,3],[22,2],[35,1],[37,2],[56,1],[58,2],[61,4],[66,3],[70,3],[95,1],[113,1],[115,2],[130,1],[132,4],[137,1],[151,1],[153,5],[166,2],[169,2],[172,2],[175,2],[178,5],[190,1],[202,3],[206,5],[212,3],[216,1],[223,1],[225,2],[228,2],[231,2],[251,4],[256,5],[269,1],[271,1],[273,3],[277,2],[285,2],[288,4],[293,1],[300,1],[302,2],[305,2],[315,1],[317,4],[322,5],[328,5],[337,1],[339,2],[342,3],[346,2],[370,1],[372,4],[377,2]]},"925":{"position":[[7,1],[9,2],[12,3],[16,4],[21,3],[25,3]]},"927":{"position":[[19,1],[39,3],[43,4],[48,3],[52,3],[56,4],[61,2],[70,1],[86,1],[88,3],[92,2],[95,3],[99,1],[101,3],[105,2],[108,2],[116,1],[118,2],[121,2],[124,4],[129,2],[159,2],[162,3],[185,1],[187,2],[190,2],[193,3],[197,3],[201,2],[222,1],[224,2],[227,2],[230,3],[234,2],[237,2],[240,2],[243,3],[247,4],[252,2],[255,3],[259,4],[264,5],[270,3],[284,2],[287,3],[307,2],[310,1],[312,4],[317,4],[338,1],[340,3],[351,4],[356,3],[360,5],[366,3],[373,1],[375,4],[396,1],[398,3],[421,1],[423,4],[428,3]]},"929":{"position":[[7,2],[35,1],[37,1],[39,3],[43,5],[49,3],[77,3],[81,5],[87,2],[90,3],[94,3],[98,3],[102,4],[107,4],[112,3],[116,5],[122,2],[125,3],[129,2],[134,2],[144,3],[148,2],[164,1],[173,2],[183,2],[196,1],[198,2],[201,2],[204,2],[214,1],[216,2],[219,3],[223,2],[236,1],[245,2]]},"931":{"position":[[23,1],[39,1],[41,2],[54,3],[58,2],[69,1],[87,2],[90,4],[102,2],[114,1],[116,2],[119,6],[126,2],[134,1],[144,1],[146,1],[148,4],[167,1],[180,1],[182,3],[186,4],[191,4],[196,2],[199,6],[206,2],[209,6],[216,3],[220,1],[222,4],[227,3],[231,2],[234,1],[236,2],[242,1],[244,3],[248,3],[276,1],[278,3],[282,2],[288,1],[301,2],[304,1],[306,2],[309,1],[311,1],[313,2],[316,2],[319,1],[332,1],[334,3],[345,2],[348,4],[356,1],[368,1],[377,2],[380,1],[382,5],[392,2],[409,1],[411,2],[414,6],[421,3],[425,1],[427,3]]},"933":{"position":[[22,1],[31,3],[50,1],[52,5],[58,4],[63,2],[66,2],[76,1],[78,4],[83,2],[102,1],[104,5],[123,4],[148,2],[173,1],[195,1],[197,2],[200,2],[203,5],[231,1],[233,2],[241,1],[249,1],[251,2],[265,1],[267,4],[272,4],[277,4],[282,2],[285,3],[313,3],[327,2],[330,2],[333,2],[350,1],[352,2],[355,4],[360,3],[382,3],[406,3],[410,2],[429,1],[431,4],[436,3],[440,3],[444,3],[448,3],[452,4],[457,2],[460,2],[463,2]]},"935":{"position":[[23,1],[32,2],[35,5],[41,4],[46,4],[67,2],[70,3],[74,2],[89,1],[91,4],[103,1],[105,4],[110,2],[113,8],[136,1],[138,3],[142,2],[145,2],[148,5],[168,1],[184,1],[186,2],[200,1],[224,1],[226,5],[235,1],[247,2],[250,1],[261,1],[263,3],[267,2],[292,2],[295,3],[299,2],[316,1],[328,4],[333,3],[337,6],[359,1],[361,4],[381,1],[396,3],[400,2],[422,3],[426,3],[430,2],[433,1],[435,3],[439,1],[441,2]]},"937":{"position":[[23,1],[37,1],[50,2],[56,1],[65,4],[70,3],[74,5],[87,1],[89,4],[94,3],[98,3],[102,4],[107,2],[119,3],[123,4],[128,2],[131,3],[135,3],[139,5],[145,3],[149,2],[152,2],[155,1],[157,3],[161,3],[165,4],[196,1],[198,4],[203,1],[205,5],[220,1],[225,1],[227,2],[233,1],[249,3],[279,1],[281,4],[305,1],[307,2],[310,1],[312,3],[316,2],[325,1],[332,1],[348,2],[360,1],[362,2],[365,3],[369,3],[373,3],[389,1],[391,2],[394,3],[398,2],[401,4],[406,2],[420,1],[431,1],[452,1],[454,2],[462,1],[464,1],[466,3],[470,2],[473,1],[475,4],[480,3],[484,2],[487,2],[499,3],[503,3],[521,1],[530,1],[532,3],[545,1],[566,1],[568,3],[572,3],[576,1],[594,1],[607,1],[612,1],[614,2],[633,1],[635,4]]},"939":{"position":[[17,1],[33,1],[35,5],[41,3],[45,3],[56,2],[59,5],[65,2],[79,2],[82,2],[85,5],[96,1],[107,1],[109,2],[112,2],[127,1],[140,5],[146,6],[160,3],[164,2],[167,2],[170,2],[173,1],[175,2],[178,4],[183,2],[197,1],[199,4],[204,2],[207,3],[211,3],[215,2],[218,3],[222,4],[227,2],[244,1],[246,2],[249,3],[253,5],[259,4],[264,3],[268,3],[272,2],[275,6],[282,3]]},"941":{"position":[[0,2],[3,3],[7,6],[14,4],[19,2],[22,2]]},"943":{"position":[[16,1],[35,1],[37,4],[42,3],[46,4],[51,2],[54,3],[58,6],[68,1],[85,1],[87,3],[91,3],[95,3],[99,2],[102,3],[106,5],[112,1],[127,1],[129,5],[135,2],[138,1],[140,4],[145,3],[149,1],[151,2],[167,1],[184,1],[186,4],[191,3],[195,2],[203,1],[213,1],[215,2],[218,4],[223,2],[233,1],[235,2],[238,5],[244,4],[258,1],[260,3],[264,3],[268,2],[271,3],[275,3],[377,1],[413,1],[415,3],[438,1],[440,3],[458,1],[560,1],[590,2],[593,1],[595,3],[602,1],[604,5],[610,3],[614,3],[618,3],[641,3],[645,4],[650,2]]},"945":{"position":[[17,1],[19,4],[24,4],[29,4],[34,4],[54,1],[56,4],[61,2],[68,1],[73,2],[102,1],[104,2],[112,1],[114,2],[117,4],[122,2],[125,3],[142,4],[147,3],[151,3],[155,2],[158,3],[162,3],[166,4],[171,3],[195,2],[198,3],[202,3],[206,4],[211,3],[231,2],[248,2],[251,4],[256,3],[260,2],[276,4],[281,3],[285,2]]},"947":{"position":[[27,1],[29,3],[33,3],[37,3],[41,3],[45,2],[48,4],[53,2],[56,3],[60,1],[62,3],[66,2],[79,1],[81,3],[92,1],[94,4],[99,4],[104,3],[112,3],[116,2],[119,3],[123,3],[133,2],[143,1],[145,5],[151,1],[160,1],[162,3],[166,3],[170,2],[194,1],[196,5],[222,2],[225,5],[231,3],[248,2],[292,1],[335,1],[337,5],[366,2],[378,2],[381,3],[385,3],[389,2],[399,4],[404,2],[432,1],[434,1],[436,2],[439,2],[442,2],[445,5],[451,2],[454,3],[458,4],[463,2],[477,3],[481,3],[485,3],[489,3],[493,3],[497,2],[500,2],[503,2],[506,2],[529,1],[531,5],[550,5],[556,2],[579,1],[590,1],[592,3],[596,3],[627,1],[640,2],[643,4],[648,4],[653,2],[656,2]]},"949":{"position":[[7,1],[9,4],[14,2],[17,4],[42,2],[45,1],[47,2],[70,1],[72,2],[75,2],[78,1],[80,2],[83,2],[86,2],[89,2],[95,1],[117,2],[120,4],[148,2],[151,2],[154,1],[176,1],[178,3],[192,3],[196,4],[201,1],[203,3],[207,2],[210,1],[212,1],[226,3],[234,2],[237,2],[243,2],[246,2],[249,3],[253,1],[281,1],[283,1],[285,3],[289,2],[292,2],[295,4],[315,1],[317,2],[326,2],[329,4],[334,3],[338,1],[340,2],[343,3],[347,3],[384,2],[417,2],[429,2],[447,1],[449,4],[454,2],[457,2],[460,2],[463,3],[472,2],[478,1],[480,2],[483,5],[505,1],[507,2],[510,2],[513,2],[516,3],[520,2],[548,1],[550,2],[553,2],[569,2],[572,3],[576,2],[579,3],[583,3],[600,1],[624,3],[628,3],[632,2],[635,3],[644,1],[646,2],[655,2],[663,1],[677,2],[680,4],[685,3],[689,2],[695,1],[702,1],[723,2],[726,2],[739,2],[742,1],[744,2],[747,3],[760,3],[764,1],[766,3],[770,2],[773,2],[776,2],[779,5],[785,2],[788,3],[792,3],[796,1],[798,4],[803,5],[813,5],[819,2],[831,2],[834,2],[864,1],[866,5],[872,4],[877,1],[879,2],[882,3],[886,2]]},"951":{"position":[[0,4],[5,4],[10,1],[12,3],[16,4],[21,1],[23,6],[30,3],[34,5],[40,2],[43,2],[46,3],[50,2],[53,3],[57,5],[63,4],[68,4],[73,3],[77,4],[82,3],[86,3],[112,1],[118,1],[120,2],[123,3],[127,3],[131,2],[134,2],[137,2],[140,4],[145,4],[150,2],[175,1],[177,3],[181,4],[186,2],[189,5],[195,2],[198,2],[201,1],[203,3],[207,5],[213,4],[218,4],[223,2],[226,3],[230,3],[234,5],[240,2],[243,3],[247,1],[249,4],[254,3],[258,2],[261,3],[265,2],[268,4],[273,1],[275,5],[281,4],[286,2],[289,3],[293,3],[306,1],[308,4],[313,3],[317,5],[323,3],[327,3],[335,1],[337,3],[341,5],[347,2],[350,4],[355,4],[360,5],[366,5],[372,3],[380,1],[382,3],[386,3],[390,3],[394,2],[397,3],[401,4],[420,2],[423,2],[426,2],[429,3],[433,3],[437,2],[440,2],[446,1],[448,1],[450,3],[454,2],[457,3],[461,4],[466,2],[469,2],[472,3],[476,4],[481,2],[484,2],[510,1],[512,3],[516,2],[519,2],[522,2],[525,2],[528,3],[532,4],[537,1],[560,1],[565,1],[567,2],[570,4],[575,3],[579,6],[586,3],[590,2],[593,4],[598,2],[601,2],[621,1],[623,3],[627,2],[630,2],[633,2],[636,2],[639,3],[656,1],[660,1],[695,3],[699,1],[701,3],[705,2],[708,3],[712,5],[721,2],[724,2]]},"953":{"position":[[24,1],[43,1],[45,4],[65,1],[67,2],[77,3],[81,2],[87,1],[89,3],[93,2],[96,2],[121,1],[140,2],[150,1],[152,4],[157,2],[160,2],[189,1],[191,3],[195,2],[198,3],[202,2],[205,2],[235,1],[237,3],[241,3],[245,3],[249,4],[261,1],[263,2],[266,2],[269,3],[273,3],[277,2],[280,2],[283,3],[287,6],[294,6],[311,1],[313,3],[317,1],[319,6],[326,3],[330,1],[332,3],[336,3],[340,3],[347,1],[357,1],[368,2],[371,3],[375,4],[380,1],[404,1],[417,2],[428,1],[446,3],[450,3],[457,1],[499,2],[510,1],[512,5],[518,3],[522,4],[527,3],[534,3],[538,4],[543,3],[547,1],[549,2]]},"955":{"position":[[16,1],[18,2],[21,3],[25,2],[28,4],[33,4],[38,4],[43,3],[57,3],[75,1],[77,2],[109,2],[112,2],[115,2],[118,2],[125,1],[127,5],[133,3],[148,2],[158,1],[160,4],[165,3],[169,2],[172,1],[174,3],[178,2],[181,3],[185,3],[189,2],[192,2],[197,1],[199,3],[203,3],[227,3],[256,1],[258,2],[261,3],[265,1],[278,1],[280,2],[290,2],[297,1],[299,2],[302,3],[315,1],[326,3],[330,3],[334,2],[360,2],[366,1],[377,2],[380,3],[384,2],[387,1],[402,3],[406,2],[432,1],[434,2],[460,1],[468,2],[471,2],[488,1],[490,5],[496,2],[502,1],[504,3],[508,2],[516,2],[536,2],[539,2],[566,2],[569,1],[585,1],[587,5],[593,2],[596,4]]},"957":{"position":[[4,1],[6,3],[10,4],[15,2],[18,3],[38,2],[41,3],[45,1],[47,3],[51,2],[73,1],[75,4],[80,3],[84,4],[89,3],[93,3],[97,2],[100,3],[104,5],[127,1],[129,3],[133,5],[139,2],[156,2],[159,5],[165,3],[169,4],[184,3],[188,5],[194,3],[198,2],[201,2],[204,4],[209,3],[213,2],[216,3],[220,3],[224,1],[226,3],[230,2]]},"959":{"position":[[10,3],[23,1],[25,3],[29,2],[37,2],[40,3],[44,4],[49,1],[51,3],[55,3],[59,2],[80,1],[82,1],[84,5],[90,2],[93,5],[99,2],[102,3],[106,1],[108,3],[112,2],[115,1],[117,2],[120,4],[127,1],[129,2],[132,3],[142,1],[157,2],[160,2],[183,2],[186,1],[196,3],[200,3],[204,2],[207,2],[224,1],[230,1],[239,1],[262,1],[264,2],[282,1],[299,1],[301,3],[305,1],[307,3],[311,2],[329,1],[331,2],[334,4],[339,3],[343,6],[365,2],[368,3],[419,2],[422,2],[430,1],[432,3],[440,1],[442,2],[445,3],[449,3],[459,1],[466,1],[468,3],[472,2],[475,3],[479,6],[486,3],[490,2],[503,1],[505,2],[514,1],[516,4],[521,2],[524,3],[528,2],[548,1],[579,2],[603,1],[605,2],[614,1],[616,4],[621,2],[624,3],[628,2],[661,1],[730,2],[733,2],[736,3],[740,2],[743,2],[746,1],[748,2],[751,3],[755,4],[760,3],[764,2],[767,3],[771,2],[799,1],[801,2],[816,1],[818,4],[823,5],[829,4],[834,2],[851,3],[855,2],[858,5],[864,3],[868,4],[873,4],[878,3],[882,3],[886,1],[894,3],[898,3],[902,2],[914,1],[916,3],[920,1],[922,3],[981,3],[985,2],[988,3],[992,4],[997,3],[1001,3],[1005,1],[1007,3]]},"961":{"position":[[4,1],[10,1],[28,1],[42,2],[45,2],[74,1],[96,2],[99,1],[101,4],[127,1],[129,4],[134,4],[139,5],[145,3],[163,2],[166,7],[188,1],[190,2],[193,1],[195,3],[217,3],[221,3],[225,1],[263,1],[265,2],[268,4],[273,3],[277,3],[281,3],[285,5],[291,2],[294,3],[298,3],[302,2]]},"963":{"position":[[22,1],[24,2],[27,1],[29,2],[48,2],[51,3],[55,5],[79,1],[81,2],[84,4],[110,1],[112,3],[116,4],[126,1],[128,2],[131,3],[135,2],[138,4],[143,2],[146,4],[151,5],[157,2],[160,3],[164,3],[168,2],[171,2],[174,3],[178,4],[183,2],[202,1],[204,2],[207,2],[210,2],[213,3],[217,4],[222,3],[226,2],[229,2],[232,1],[234,3],[238,3],[242,2],[245,2],[248,3],[268,2],[271,1],[273,2],[276,4],[281,3],[285,2],[288,2],[314,1],[316,2],[319,2],[322,3],[326,4],[331,2],[334,3],[338,4],[343,2],[346,3],[350,3],[354,2],[357,2],[394,1],[396,3],[405,1],[407,2],[410,4],[423,2],[449,1],[451,3],[455,3],[459,2],[462,4],[467,1],[469,3],[473,3],[477,3],[481,3],[512,1],[514,1],[516,3],[520,5],[526,3],[572,1],[583,1],[585,2],[588,4],[593,1],[595,1],[597,3],[601,4],[613,2],[630,2],[643,1],[645,4],[650,2],[653,3],[657,1],[659,2],[662,2],[689,1],[697,1],[699,2],[702,4],[712,2],[715,2],[718,3],[722,2],[730,2],[733,3],[737,4],[742,2],[745,3],[762,2],[765,3],[769,4],[774,2],[777,2],[800,1],[808,1],[810,2],[813,2],[816,3],[820,6],[851,2],[854,4],[859,2],[862,4],[867,3],[871,4],[876,3],[880,1],[902,1],[916,1],[918,3],[922,3],[926,5],[945,1],[947,4],[952,3],[956,2],[959,4],[964,4],[969,2],[972,2],[975,2],[978,2],[986,1],[1006,2],[1009,2],[1034,1],[1056,2],[1059,4],[1064,2],[1067,2],[1070,2],[1073,4],[1078,1],[1080,1],[1082,4],[1087,2],[1090,3],[1094,3],[1098,2],[1101,2],[1104,4],[1109,5],[1125,3],[1129,4],[1134,3],[1138,3],[1142,3],[1146,4],[1151,1],[1153,3],[1157,2],[1160,2],[1183,1],[1185,2],[1188,4],[1212,1],[1229,1],[1231,2],[1256,1],[1258,2],[1261,4],[1269,2],[1272,2],[1275,1],[1277,3],[1288,3],[1292,2],[1295,3],[1299,4],[1304,2],[1307,2],[1310,1],[1312,5],[1318,5],[1344,1],[1362,1],[1364,3],[1368,1],[1398,1],[1400,3],[1413,1],[1431,3],[1435,3],[1439,2],[1442,2],[1445,2],[1448,2],[1456,1],[1458,4],[1463,4],[1468,2],[1485,1],[1487,4],[1492,3],[1506,3],[1510,2],[1520,1],[1522,3],[1535,1],[1540,6],[1547,3],[1551,3],[1555,2],[1558,2],[1561,2],[1564,2],[1577,1],[1579,3],[1583,2],[1591,1],[1593,1],[1595,4],[1600,2],[1603,2],[1616,1],[1618,4],[1623,2],[1626,3],[1630,4],[1635,3],[1639,1],[1641,3],[1645,2],[1648,3],[1652,3],[1678,1],[1691,2],[1694,3],[1698,3],[1702,4],[1707,2],[1710,3],[1714,4],[1719,2],[1722,2],[1741,1],[1811,2],[1814,3],[1818,4],[1823,4],[1828,2],[1831,4],[1836,3],[1840,2],[1843,3],[1847,1],[1849,3],[1853,3],[1857,4],[1862,3],[1866,4],[1871,2],[1913,2],[1958,1],[1960,2],[1963,3],[1967,1],[1969,4],[1981,1],[1988,3],[1992,5],[1998,2],[2001,1],[2003,2],[2006,3],[2010,4],[2015,3],[2019,1],[2021,2],[2024,2],[2027,3],[2031,2],[2045,1],[2047,3],[2051,5],[2057,3],[2080,1],[2102,2],[2129,1],[2162,1],[2164,5],[2176,4],[2188,1],[2212,3],[2216,2],[2235,2],[2238,2],[2241,3],[2245,2],[2255,1],[2260,5],[2273,3],[2304,1],[2335,1],[2337,2],[2348,1],[2350,2],[2353,5],[2359,2],[2362,5],[2368,2],[2380,4],[2385,3],[2394,3],[2398,3],[2416,1],[2418,5],[2424,2],[2443,1],[2452,2],[2455,3],[2464,2],[2467,1],[2483,2],[2502,1],[2520,1],[2522,2],[2525,4],[2530,4],[2535,2],[2556,1],[2558,2],[2566,2],[2569,5],[2581,4],[2586,2],[2589,6],[2622,2],[2625,4],[2630,4],[2635,6],[2658,1],[2660,2],[2663,2],[2666,3],[2670,3],[2674,3],[2678,2],[2681,3],[2706,1],[2708,3],[2712,2],[2725,1],[2727,4],[2732,1],[2734,3],[2738,3],[2752,1],[2765,1],[2767,4],[2772,2],[2775,2],[2783,2],[2786,3],[2800,2],[2803,3],[2855,2],[2884,1],[2886,2],[2889,4],[2894,3],[2898,3],[2902,5],[2908,4],[2913,2],[2932,1],[2955,1],[2957,3],[2961,3],[2965,2],[2968,3],[2972,4],[2977,5],[2983,4],[2988,1],[2990,3],[2994,3],[2998,4],[3003,3],[3007,2],[3010,4],[3015,3],[3040,1],[3042,4],[3047,4],[3059,2],[3077,3],[3081,2],[3084,2],[3087,2],[3090,3],[3094,4],[3099,3],[3103,2],[3138,1],[3140,2],[3143,4],[3148,4],[3153,3],[3157,3],[3161,3],[3165,2],[3168,3],[3172,2],[3189,1],[3198,3],[3202,2],[3205,2],[3208,3],[3212,2],[3220,3],[3224,3],[3228,3],[3232,3],[3236,3],[3240,3],[3244,3],[3248,5],[3254,2],[3257,1],[3259,3],[3263,2],[3282,1],[3284,2],[3294,3],[3316,1],[3318,5],[3324,4],[3329,2],[3332,5],[3338,2],[3341,2]]},"965":{"position":[[22,1],[24,3],[33,1],[35,3],[39,2],[42,3],[46,4],[51,6],[58,2],[61,2],[64,4],[69,3]]},"967":{"position":[[0,3],[8,1],[10,3],[36,1],[38,1],[40,1],[42,4],[47,2],[50,4],[55,2],[58,5],[64,4],[69,3],[87,1],[89,2],[114,3],[118,4],[123,3],[127,2],[130,3],[134,5]]},"969":{"position":[[43,1],[67,1],[89,1],[113,1],[115,2],[141,1],[162,1],[164,1],[166,6],[173,3],[184,3],[188,1],[190,5],[196,5],[202,3],[206,3],[210,3],[214,4],[219,4],[224,3],[228,4],[233,4],[264,3],[268,3],[272,2],[275,1],[277,2],[280,4],[285,4],[290,3],[294,3],[298,2],[339,1],[350,2],[359,1],[402,1],[404,4],[409,3],[413,1],[415,4],[429,1],[450,2],[453,3],[457,1],[459,5],[465,2],[471,1],[473,2],[476,3],[495,3],[499,2],[502,3],[506,5],[512,4],[523,1],[532,1],[534,4],[539,3],[543,5],[551,1],[575,3],[579,2],[609,1],[611,4],[616,4],[628,2],[631,3],[635,1],[637,3],[641,3],[645,3],[649,3],[653,3],[657,4],[662,2],[665,2],[668,4],[673,3],[677,4],[682,2],[685,3],[689,1],[691,3],[731,1],[733,2],[736,3],[740,2],[743,2],[755,1],[757,2],[760,2],[770,1],[772,2],[775,5],[790,1],[799,1],[801,3],[805,3],[809,3],[813,5],[819,4],[824,3],[828,3],[832,3],[836,2],[839,2],[851,2],[854,2],[864,1],[866,5],[882,1],[887,3],[891,1],[893,3],[897,2],[900,3],[904,4],[909,2]]},"971":{"position":[[32,1],[40,1],[42,2],[45,2],[48,3],[52,3],[69,1],[71,4],[76,3],[80,3],[84,3],[88,2],[124,1],[145,1],[147,4],[152,3],[160,1],[162,4],[167,2],[170,3],[174,1],[176,5],[182,3],[186,2],[189,4],[194,5],[200,1],[202,2],[205,2],[208,2],[211,3],[215,3],[219,6],[232,3],[236,4],[241,2],[282,1],[300,1],[302,3],[306,3],[317,1],[319,3],[323,5],[329,6],[336,2],[339,2],[342,2],[345,3],[363,1],[365,4],[386,1],[404,1],[406,5],[412,4],[417,3],[421,2],[424,2],[432,2],[435,5],[441,2],[444,3],[448,1],[450,5],[456,3],[460,3],[464,2],[467,4],[472,2],[475,2]]},"973":{"position":[[13,2],[16,1],[18,3],[22,4],[27,4],[32,3],[36,3],[40,3],[44,1],[46,2],[49,3],[53,2],[56,5],[62,3],[66,3],[70,3],[74,3],[78,2],[81,4],[86,3],[90,5],[96,3],[100,3],[104,2],[107,3],[111,2],[114,4],[119,3],[132,1],[143,5],[149,4],[154,2],[157,3],[161,3],[165,2],[168,1],[170,2],[173,3]]},"975":{"position":[[18,1],[38,3],[49,1],[51,2],[54,5],[60,2],[63,1],[65,2],[68,4],[73,2],[76,3],[80,5],[96,1],[98,4],[103,3],[107,2],[110,3],[114,4],[119,2],[131,1],[137,1],[139,3],[143,3],[147,4],[152,3],[156,5],[172,3],[176,2],[179,3],[183,5],[200,1],[202,4],[207,3],[211,3],[215,5],[221,4],[226,3],[230,2],[233,3],[237,4],[242,2],[245,3],[249,2],[252,3],[256,3],[285,1],[287,3],[291,5],[297,5],[303,2],[306,3],[310,5],[316,3],[320,3],[324,3],[328,4],[333,2],[345,1],[347,1],[349,7],[382,2],[422,1],[424,2],[438,1],[440,4],[445,3],[460,1],[462,4],[467,4],[472,2],[475,3],[479,2],[482,3],[486,2],[489,2],[492,2],[495,2],[509,1],[521,2],[529,3],[538,1],[540,3],[565,1],[567,3],[571,1],[573,2],[595,2],[603,3],[607,2],[610,3],[614,1],[616,3],[640,1],[642,1],[644,2],[647,3],[651,2],[674,1],[676,3],[700,1],[702,2],[705,3],[709,3],[713,3],[717,3],[721,2],[724,2],[741,1],[749,2],[752,3],[756,2],[759,6],[766,3],[770,2],[787,1],[789,4],[794,4],[799,4],[804,3],[808,4],[813,4],[818,3],[842,1],[844,3],[848,2],[881,1],[883,2],[893,6],[909,1],[911,4],[932,1],[934,4],[954,1],[956,3],[960,1],[962,3],[966,3],[975,2],[978,2],[988,1],[990,2],[993,1],[995,3],[999,5],[1005,3],[1009,2],[1012,2],[1015,4],[1020,2],[1023,4],[1028,2],[1031,2],[1041,2],[1057,1],[1059,2],[1087,4],[1108,1],[1110,4],[1115,2],[1118,4]]},"977":{"position":[[0,2],[3,4],[8,6],[37,1],[39,3],[43,3],[47,3],[51,5],[61,1],[82,1],[104,3],[124,1],[146,1],[148,4],[153,3],[157,2],[160,3],[191,2],[194,3],[198,2],[201,3],[205,5],[211,3],[215,1],[217,4],[222,1],[224,3],[228,2],[231,2],[248,3],[252,4],[257,2],[260,4],[269,1],[271,3],[275,2],[278,3],[282,2],[285,2],[288,4],[293,4],[298,1],[300,3],[304,5],[310,2],[313,4],[318,2],[321,2],[335,3],[339,1],[341,1],[343,3],[347,3],[355,1],[357,2],[360,2],[363,3],[367,2],[377,1],[379,2],[382,3],[386,3],[390,2],[393,2],[396,4],[401,3],[405,3],[409,2],[412,5],[418,3]]},"979":{"position":[[7,1],[9,3],[13,3],[17,3],[21,4],[33,1],[35,4],[40,5],[46,1],[48,2],[51,3],[55,2],[61,2],[88,2],[99,1],[101,4],[106,2],[109,1],[111,1],[113,4],[118,2],[121,5],[127,3],[138,1],[140,3],[144,3],[148,3],[152,1],[154,5],[160,3],[178,2],[181,3],[185,3],[189,1],[191,1],[193,2],[196,5],[202,3],[213,1],[215,4],[220,5],[226,2],[229,2],[232,2],[235,4],[240,2],[243,3],[247,1],[249,2],[252,4],[257,3],[261,2],[264,1],[266,3],[270,4],[275,3]]},"981":{"position":[[10,5],[16,3],[25,2],[37,1],[48,2],[51,3],[70,1],[76,2],[79,6],[86,4],[91,3],[95,2],[98,4],[115,3],[119,3],[123,3],[127,3],[131,1],[133,4],[138,2],[141,2],[144,4],[149,5],[177,1],[179,2],[182,4],[187,1],[189,3],[193,1],[195,3],[199,3],[203,2],[206,5],[212,2],[215,2],[218,3],[222,3],[226,4],[231,4]]},"983":{"position":[[12,5],[18,3],[22,2],[25,3],[29,3],[33,1],[35,1],[37,2],[40,3],[44,3],[59,3],[63,2],[81,3],[91,1],[93,2],[96,2],[99,2],[102,2],[105,2],[108,3],[112,5],[118,1],[120,4],[125,2],[128,2],[131,3],[135,3],[139,3],[146,1],[156,3],[175,3],[195,1],[197,3],[201,1],[203,5],[209,1],[211,2],[218,1],[236,1],[238,4],[243,2],[261,1],[263,2],[273,1],[275,4],[280,4],[285,1],[287,2],[290,3],[294,4],[344,3],[348,3],[352,2],[371,1],[388,3],[392,3],[411,1],[413,5],[419,3],[423,2],[426,4],[431,2],[453,3],[464,1],[582,4],[587,2],[590,2],[593,2],[605,1],[607,3],[622,3],[633,1],[754,1],[756,4],[761,2],[764,2],[776,1],[778,4],[783,1],[785,1],[787,3],[791,4],[796,3],[800,2],[803,2],[806,3],[810,4],[815,1],[817,3],[821,1],[823,2],[826,3],[830,3],[834,3],[857,3],[867,1],[876,1],[878,4],[883,4],[888,2],[891,2],[894,2],[897,2],[915,1],[917,2],[920,3],[924,3],[928,4],[933,2],[936,3],[940,2],[943,3],[947,4],[958,1],[960,2],[982,3],[986,1],[988,3],[992,3],[996,3],[1000,3],[1004,3],[1008,2],[1011,3],[1015,3],[1019,2],[1022,3],[1026,5],[1032,2],[1035,2],[1041,3],[1062,1],[1076,4],[1081,2],[1084,2],[1087,3],[1091,5],[1097,2],[1100,4],[1105,3],[1119,3],[1123,3],[1127,3],[1131,4],[1136,1],[1138,1],[1140,2],[1143,3],[1147,4],[1152,5],[1158,2],[1161,4],[1166,2],[1182,1],[1184,4],[1205,1],[1207,5],[1213,4],[1244,1],[1246,2],[1249,2],[1252,3],[1264,2],[1267,2],[1270,3],[1274,4],[1279,2]]},"985":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1],[83,2],[86,2],[89,1]]},"987":{"position":[[0,1],[2,3],[15,3],[19,3],[29,1],[31,4],[36,3],[40,1],[42,3],[46,2],[49,3],[53,3],[57,4],[62,3],[66,2],[69,4],[74,3],[78,4],[83,1],[85,5],[91,2],[94,3],[98,5],[104,4],[109,1],[118,1],[131,1],[133,3],[144,1],[146,3],[150,3],[154,5],[160,2],[163,2],[166,4],[177,1],[200,3],[204,2],[214,1],[216,3],[220,2],[238,2],[241,2],[244,3],[248,4],[253,2],[256,3],[260,3],[274,1],[276,3],[280,2],[283,3],[287,2],[290,3],[306,1],[308,4],[313,1],[315,3],[330,2],[338,2],[346,5],[352,3],[356,3],[360,5],[366,6]]},"989":{"position":[[0,3],[32,1],[34,4],[39,4],[44,4],[49,4],[54,3],[58,4],[63,3],[67,4],[72,2],[75,1],[77,3],[81,3],[85,2],[88,3],[92,3],[96,3],[100,6],[107,1],[109,1],[111,3],[115,3],[119,4],[124,3],[128,4],[133,3],[137,3],[141,3],[145,2],[157,1],[159,2],[162,3],[166,4],[171,3],[199,1],[201,2],[214,4],[219,3],[223,4],[228,3],[259,1],[267,1],[279,2],[282,2],[300,2],[303,5],[309,3],[313,1],[320,1],[322,1],[324,2],[341,3],[345,3],[349,3],[358,6],[365,3],[369,5],[375,2],[384,1],[413,4],[418,4],[430,2],[433,3],[437,1],[439,3],[461,2],[464,2],[467,1],[472,1],[491,2],[494,2],[497,2],[500,1],[502,3],[512,1],[514,6],[521,4],[551,1],[553,4],[558,2],[561,3],[565,3],[569,3],[573,4],[584,4],[601,3],[605,1],[607,2],[622,1],[630,1],[645,1],[647,2],[662,1],[670,1],[681,1],[683,2],[686,3],[690,3],[699,1],[701,3],[705,3],[709,2],[731,6],[747,1],[749,2],[758,2],[765,1],[767,2],[783,1],[785,2],[800,1],[813,5],[825,2],[828,2],[831,3],[835,3],[839,4],[849,1],[851,4],[856,2],[859,5],[865,2],[868,3],[872,3],[893,2],[896,2],[932,6],[945,1],[947,4],[952,2],[955,3],[959,5],[969,1],[983,3],[1002,1],[1004,3],[1008,4],[1013,2],[1016,3],[1020,2],[1023,4],[1028,4],[1033,2],[1036,4],[1041,4],[1046,4],[1051,3],[1055,2],[1058,6],[1077,1],[1079,3],[1083,3],[1087,4],[1092,2],[1107,1],[1126,1],[1128,3],[1132,4],[1137,2],[1140,4],[1145,2],[1160,1],[1162,3],[1166,3],[1170,3],[1174,2],[1192,2],[1195,2],[1198,4],[1203,3],[1207,4],[1212,3],[1216,4],[1221,4],[1226,1],[1228,4],[1233,3],[1237,4],[1242,2],[1245,3],[1249,3],[1253,1],[1255,2],[1258,2],[1261,4],[1266,2]]},"993":{"position":[[0,4],[5,2],[8,1],[10,2],[13,3],[17,4],[22,3],[26,4],[31,3],[53,2],[56,6],[63,3],[67,3],[71,2],[91,1],[113,2],[128,2],[131,4],[136,3],[153,2],[156,2],[166,1],[168,5],[174,4],[179,2],[182,2],[185,5],[191,2],[194,2],[197,2],[213,1],[215,2],[222,1],[237,1],[239,2],[249,1],[251,3],[258,1],[264,5],[270,4],[293,1],[295,5]]},"995":{"position":[[0,1],[2,3],[6,6],[24,1],[26,3],[42,1],[44,4],[49,3],[53,2],[68,1],[70,3],[74,2],[77,5],[83,3],[94,1],[96,5],[102,5],[108,1],[110,3],[114,3],[118,3],[122,4],[127,2],[151,2],[154,3],[158,5],[164,2],[167,5],[173,3],[181,3],[192,1],[194,4],[199,5],[211,1],[213,3],[232,1],[234,6],[241,4],[246,4],[251,1],[262,1],[276,1],[278,2],[281,4],[286,4],[291,2],[305,1],[319,1],[333,5],[339,3],[343,5],[349,5],[355,2],[358,3],[362,4],[374,1],[376,5],[382,2],[385,1],[387,3],[391,5],[397,4],[414,1],[416,5],[426,3],[430,4],[435,3],[460,3],[464,4],[469,4],[474,3],[478,3],[482,4],[487,3],[491,2],[511,3],[515,3],[536,1],[538,2],[547,2],[550,3]]},"997":{"position":[[0,2],[8,1],[10,1],[12,3],[16,3],[20,4],[25,4],[30,3],[54,1],[68,1],[70,3],[89,2],[99,1],[194,1],[196,4],[201,3]]},"999":{"position":[[7,1],[17,2],[25,2],[28,2],[31,2],[34,3],[38,2],[41,2],[44,2]]},"1001":{"position":[[0,3],[30,1],[38,1],[40,5],[52,1],[54,3],[58,4],[63,3],[67,4],[72,2],[75,4],[96,1],[98,5],[104,1],[106,5],[118,1],[120,1],[122,3],[126,3],[130,5],[185,2],[188,3],[192,4],[197,2],[206,1],[220,3],[224,2],[227,4],[232,3],[236,5],[300,4],[314,1],[316,4],[321,2],[328,3],[332,2],[339,3],[351,3],[355,2],[363,1],[373,2],[376,2],[379,2],[390,2],[393,5],[399,1],[401,2],[404,3],[408,4],[422,1],[424,4],[429,3],[433,3],[437,3],[441,2],[444,2],[447,2],[475,3],[479,3],[501,1],[503,4],[508,2],[518,1],[529,1],[531,4],[550,1],[552,5],[558,6],[573,1],[575,5],[587,1],[589,2],[592,1],[594,5],[613,1],[615,2],[632,1],[634,5],[717,1],[776,1],[790,1],[919,1],[932,1],[934,2],[940,1],[957,4],[971,1],[973,3],[990,1],[1001,1],[1012,1],[1014,1],[1016,3],[1020,4],[1025,3],[1033,1],[1035,3],[1039,3],[1043,4],[1056,1],[1058,3],[1062,3],[1071,1],[1076,1],[1092,3],[1124,3],[1141,1],[1143,2],[1146,2],[1153,5],[1159,2],[1162,1],[1167,4],[1172,2],[1175,1],[1192,1],[1197,2],[1200,3],[1204,3],[1208,3],[1212,3],[1220,1],[1222,4],[1231,1],[1237,3],[1253,3],[1257,2],[1264,5],[1270,2],[1273,3],[1277,3],[1281,3],[1298,1],[1321,1],[1323,5],[1329,2],[1340,1],[1342,4],[1359,1],[1380,1],[1382,4],[1396,3],[1446,1],[1458,1],[1517,1],[1595,2],[1601,1],[1615,1],[1617,1],[1619,1],[1626,1],[1733,1],[1745,1],[1806,1],[1808,3],[1840,1],[1899,1],[1934,1],[1946,3],[1964,1],[1983,2],[1990,2],[2002,1],[2015,2],[2027,1],[2034,1],[2036,4],[2053,1],[2063,3],[2067,2],[2084,3],[2094,1],[2100,2],[2103,3],[2107,2],[2110,2],[2125,1],[2136,6],[2154,1],[2168,1],[2170,2],[2173,2]]},"1003":{"position":[[8,3],[12,2],[15,2],[18,3],[30,2],[43,1],[45,3],[49,4],[54,3],[58,3],[62,3],[66,3],[80,1],[82,3],[86,6],[93,4],[98,5],[104,5],[110,3],[114,2],[117,3],[121,3],[125,3],[129,3],[133,3],[137,2],[140,2],[143,3],[147,4],[152,3],[156,3],[160,5],[166,3],[196,3],[208,1],[210,4],[215,5],[229,3],[241,2],[244,3],[248,3],[252,1],[254,3],[258,3],[262,1],[264,5],[270,3],[274,4],[279,3],[283,4],[288,5],[294,2],[297,3],[301,4],[306,4],[311,4],[323,4],[328,1],[340,2],[343,3],[347,3],[351,2],[354,3],[358,1],[360,1],[362,3],[366,2],[369,2],[372,1],[374,2],[377,4],[382,4],[387,5],[393,4],[398,3],[402,3],[406,2],[409,3],[413,2],[416,2],[430,4],[435,2],[447,4],[467,2],[470,3],[474,4],[479,3],[483,3],[487,2],[490,2],[525,2],[533,1],[544,1],[546,4],[551,2],[554,5],[560,4]]},"1006":{"position":[[0,4],[11,1],[13,4],[30,1],[32,3],[36,1],[38,2],[41,2],[44,4],[49,4],[54,2],[57,3],[61,3],[65,1],[67,4],[72,3],[76,2],[83,6],[102,1],[104,3],[108,4],[113,2]]},"1008":{"position":[[12,3],[22,2],[25,5],[31,3],[47,3],[57,2],[69,1],[71,2],[74,6],[86,2],[89,4],[94,2],[114,1],[116,4],[121,2],[128,5],[134,2],[137,3],[141,3]]},"1010":{"position":[[12,1],[31,4],[36,3],[40,3],[44,4],[49,4],[54,1],[56,1],[58,2],[61,2],[76,1],[78,3],[82,3],[86,3],[90,1],[92,3],[96,3],[100,4],[105,3],[109,2],[112,2],[115,3],[119,2],[122,3],[126,5],[132,4],[137,4],[142,3],[146,2],[149,2],[152,3],[156,3],[160,2],[163,3],[167,4],[172,2],[175,1],[177,2],[180,3],[184,3]]},"1013":{"position":[[0,2],[3,4],[8,3],[17,2],[20,3],[24,2],[27,4],[46,1],[48,5],[54,2],[57,5],[63,1],[79,1],[91,3],[95,4],[100,2],[103,6],[110,3],[124,3],[133,1],[135,4],[140,4],[151,2],[154,2],[157,2],[160,4],[165,3],[184,3],[188,3],[192,5],[198,3],[202,1],[204,5],[216,3],[220,4],[225,1],[227,3],[231,3],[235,2],[244,1],[246,5],[252,3],[268,2],[271,5],[277,3],[313,1],[375,2],[378,4],[383,2],[386,4],[391,3],[395,1],[397,2],[400,3],[417,2],[420,2],[423,2],[426,2],[429,4],[434,2]]},"1016":{"position":[[12,1],[14,3],[18,11],[30,2],[48,1],[50,2],[53,4],[58,1],[75,1],[77,4],[82,3],[86,3],[90,3],[94,3],[98,2],[101,2],[104,2],[107,3],[111,4],[116,2],[131,1],[133,3],[145,3],[149,3],[153,4],[158,2],[161,1],[163,3],[174,1],[176,3],[180,3],[213,1],[215,3],[231,1],[233,2],[236,3],[240,2],[243,3],[247,5],[253,3],[257,3],[261,4],[266,3],[270,1],[272,3],[276,3],[285,3],[289,4],[294,5],[300,3],[316,1],[318,3],[322,3],[332,2],[335,1],[343,1],[345,3],[349,4]]},"1018":{"position":[[8,1],[22,1],[24,3],[28,2],[31,5],[44,1],[46,3],[50,2],[53,3],[57,3],[61,4],[66,2]]},"1020":{"position":[[12,1],[14,3],[32,6],[39,3],[43,4],[48,2],[51,4],[76,1],[111,1],[116,1],[118,4],[123,3],[127,3]]},"1022":{"position":[[8,1],[10,3],[14,3],[18,6],[25,4],[30,2],[33,2],[39,2],[42,1],[44,3],[48,3],[52,2],[55,1],[57,5],[63,4],[68,4],[73,3],[77,1],[79,2],[82,3],[86,2],[89,4],[94,3],[98,3],[102,2],[105,2],[108,2],[111,3],[115,3],[119,3],[123,3],[127,1],[129,2],[132,3],[136,2],[139,3],[143,3],[154,1],[156,2],[159,3],[163,2],[166,1],[168,3],[172,2],[175,4],[180,3],[184,3],[188,3],[192,4],[197,4],[202,2],[205,2],[208,4],[213,3],[217,3],[221,3],[225,2],[228,3],[232,3],[236,5],[242,2],[245,3],[249,3],[253,2],[256,3],[260,4],[265,4],[270,5],[276,5],[282,5],[288,3],[292,3],[296,2],[299,4],[304,4],[324,1],[326,5]]},"1034":{"position":[[55,1]]},"1036":{"position":[[186,1],[333,1],[335,1],[354,1],[374,1],[459,2],[462,2],[465,2]]},"1038":{"position":[[89,1],[124,1],[166,1]]},"1040":{"position":[[173,1],[182,1],[254,2],[257,1]]},"1042":{"position":[[78,1]]},"1051":{"position":[[180,2]]},"1057":{"position":[[137,1],[146,1],[176,1],[178,1],[180,3],[245,1],[283,1]]},"1059":{"position":[[114,3],[163,3]]},"1061":{"position":[[127,1],[149,2],[152,1],[266,2],[281,2],[284,1],[349,3],[372,2],[439,1],[502,1],[529,1],[553,1]]},"1067":{"position":[[138,1],[140,1],[155,1],[165,1],[174,1],[176,1],[207,2],[210,2],[213,2],[216,2],[219,2]]},"1073":{"position":[[98,1],[100,1],[108,1],[154,2],[157,2]]},"1079":{"position":[[138,1],[140,1],[155,1],[165,1],[174,1],[176,1],[202,2],[205,2],[208,2],[211,2],[214,2]]},"1083":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1085":{"position":[[0,1],[2,4],[43,1],[45,2],[64,1],[74,1],[76,5],[82,3],[86,2],[114,1],[174,1],[176,2],[185,2],[188,3],[192,2],[195,2],[198,4],[203,3],[207,2],[210,4],[215,2],[223,1],[225,4],[230,4],[235,2],[238,5],[244,3],[248,1],[250,2],[253,3],[257,3],[261,4],[266,4],[271,3],[300,1],[302,3],[306,2],[309,2],[312,1],[333,2],[336,6],[356,1],[358,5],[364,3],[368,4],[373,5],[379,3],[383,4],[388,2],[391,3],[395,2],[398,1],[400,3],[404,2],[407,2],[416,1],[437,2],[440,3],[444,4],[449,4],[454,4],[459,4],[479,1],[481,3],[485,4],[490,1],[492,2],[495,3],[499,2],[502,2],[505,4],[510,3],[514,3],[518,3],[522,2],[525,2],[528,3],[532,2],[535,2],[538,6],[545,2],[548,3],[552,3],[556,3],[560,1],[562,2],[565,3],[569,2],[572,1],[574,2],[585,1],[587,4],[724,1],[728,2],[764,1],[766,4],[774,2],[797,3],[801,1],[806,2],[809,3],[813,5],[819,2],[822,3],[826,3],[830,5]]},"1087":{"position":[[0,1],[2,5],[8,2],[11,4],[16,4],[21,3],[40,1],[42,2],[45,5],[51,2],[54,4],[64,1],[106,1],[112,1],[119,1],[121,2],[135,1],[137,2],[140,3],[144,3],[148,3],[152,2],[155,4],[160,2],[163,4],[168,3],[172,3],[176,3],[293,1],[295,5],[301,2],[313,1],[315,2],[318,2],[321,3],[325,3],[329,3],[333,2],[336,2],[359,2],[362,2],[370,1],[372,2],[375,2],[378,3],[382,5],[515,1],[517,5],[523,1],[525,2],[528,3],[532,1],[534,2],[558,1],[560,4],[565,3],[569,3],[573,3],[639,1],[641,1],[643,2],[646,5],[652,3],[689,1],[691,4],[696,2],[699,5],[705,3],[709,3],[713,4],[718,3],[722,3],[726,3],[730,2],[739,1],[741,2],[744,3],[757,1],[759,5],[765,3],[769,4],[774,2],[797,2],[800,4],[805,3],[809,4],[834,2],[847,1],[849,3],[853,2],[856,3],[860,4],[865,5],[871,2],[881,2],[884,4],[889,6],[896,2],[899,3],[903,2],[906,3],[910,4],[915,1],[917,4],[922,3],[926,2],[929,2],[937,1],[946,2],[959,3],[963,4],[968,2],[971,4],[976,2],[979,5],[985,2],[988,2],[991,2],[999,2],[1002,2],[1005,3],[1009,4],[1014,5],[1020,2],[1023,3],[1038,1],[1040,3],[1044,4],[1065,1],[1067,3],[1090,1],[1092,2],[1095,2],[1098,5],[1104,4],[1109,4],[1114,2],[1117,2],[1120,2],[1123,3],[1145,1],[1147,4],[1152,4],[1157,2],[1160,3],[1164,4],[1169,6],[1176,2],[1205,1],[1207,2],[1218,1],[1220,2],[1223,2],[1226,3],[1230,2],[1233,2],[1236,3],[1240,3],[1244,2],[1247,2],[1250,2],[1279,1],[1281,1],[1283,2],[1286,3],[1290,1],[1292,2],[1295,2],[1298,3],[1302,3],[1306,1],[1308,4],[1313,1],[1315,3],[1319,2],[1322,4],[1335,1],[1337,2],[1340,2],[1346,3],[1370,2],[1379,1],[1394,1],[1396,2],[1401,2],[1404,4],[1409,3],[1428,1],[1516,1],[1565,1],[1585,2],[1588,3],[1592,1],[1600,1],[1602,4],[1607,2],[1610,3],[1629,2],[1632,3],[1658,1],[1660,2],[1663,3],[1674,1],[1676,3],[1680,2],[1685,2],[1705,1],[1707,2],[1710,3],[1730,2],[1733,3],[1737,2],[1750,3],[1754,2],[1766,1],[1768,2],[1771,1],[1773,3],[1789,1],[1791,5],[1804,1],[1806,4],[1811,3],[1815,3],[1828,1],[1830,4],[1835,2],[1838,1],[1840,2],[1843,3],[1847,2],[1850,3],[1872,1],[1874,3],[1878,2],[1881,3],[1885,2],[1911,1],[1938,1],[1940,3],[1969,1],[1971,2],[1994,1],[1996,2],[1999,4],[2004,2],[2007,3],[2011,3],[2032,1],[2034,2],[2037,3],[2041,2],[2044,2],[2047,1],[2049,4],[2054,2],[2057,2],[2060,3],[2064,4],[2069,2],[2081,2],[2084,3],[2088,2],[2091,2],[2094,4],[2099,5],[2105,3],[2127,3],[2131,4],[2136,2],[2139,3],[2143,2],[2158,3],[2178,1],[2197,1],[2199,2],[2202,3],[2206,1],[2216,1],[2218,2],[2223,2],[2245,1],[2247,2],[2250,3],[2261,1],[2263,4],[2268,2],[2290,3],[2294,4],[2306,1],[2308,4],[2313,1],[2315,2],[2318,5],[2324,5],[2330,5],[2336,3],[2340,3],[2355,1],[2357,4],[2362,2],[2365,2],[2373,1],[2382,1],[2384,4],[2389,4],[2394,3],[2398,1],[2400,3],[2404,3],[2408,3],[2412,2],[2415,5],[2429,1],[2431,3],[2440,1],[2442,3],[2446,4],[2451,3],[2479,1],[2481,4],[2486,3],[2490,2],[2493,5],[2502,3],[2538,1],[2540,3],[2544,1],[2546,3],[2550,2],[2553,2],[2559,3],[2563,6],[2570,3],[2574,3],[2578,5],[2584,3],[2588,3],[2592,3],[2596,2],[2599,5],[2635,1],[2637,2],[2640,3],[2670,1],[2672,5],[2678,3],[2697,1],[2709,1],[2711,3],[2715,2],[2718,3],[2722,2],[2725,3],[2729,2],[2732,5],[2738,3],[2742,2],[2753,1],[2755,2],[2763,3],[2767,4],[2772,4],[2777,2],[2780,2],[2789,1],[2799,1],[2801,3],[2805,1],[2807,3],[2811,3],[2831,1],[2836,3],[2866,1],[2871,2],[2874,5],[2880,2],[2883,3],[2887,2],[2890,2]]},"1090":{"position":[[13,2],[16,3],[20,2],[23,3],[53,1],[57,3],[67,1],[69,5],[126,1],[132,1],[149,1],[158,1],[160,4],[165,2],[174,1],[176,2],[188,1],[190,4],[204,1],[212,1],[225,1],[234,1],[236,4],[241,2],[244,3],[259,3],[267,1],[273,1],[275,1],[277,4],[282,3],[297,1],[306,1],[308,4],[313,4],[318,3],[322,3],[326,5],[332,1],[340,1],[349,1],[351,2],[354,3],[358,2],[361,2],[364,3],[368,3],[372,3],[376,1],[378,3],[382,2],[411,1],[427,2],[430,3],[452,2],[455,5],[461,3],[465,2],[468,2],[471,2],[474,5],[480,2],[483,6],[490,5],[496,2],[499,4],[504,3],[508,1],[510,3],[522,1],[524,2],[527,1],[529,3],[533,2],[536,5],[542,5]]},"1092":{"position":[[0,3],[29,1],[31,3],[35,3],[46,3],[50,3],[54,3],[58,4],[63,2],[66,5],[72,2],[75,1],[77,4],[82,3],[97,1],[99,2],[102,2],[105,3],[109,5],[115,4],[127,1],[129,4],[134,2],[154,1],[180,1],[182,5],[188,5],[216,1],[218,3],[222,2],[225,6],[232,3],[248,1],[250,2],[253,4],[258,5],[269,1],[271,3],[275,4],[297,2],[300,1],[314,1],[316,2],[319,3],[323,1],[325,3],[329,2],[348,1],[374,2],[377,2],[380,4],[409,1],[411,5],[417,3],[421,2],[428,1],[494,1],[496,5],[526,1],[528,4],[553,3],[557,4],[581,1],[583,3],[587,4],[592,3],[596,4],[626,1],[684,1],[686,5],[692,6],[699,4],[704,6],[711,2],[714,2],[717,4],[722,3],[734,2],[737,2],[740,2],[743,2],[746,4],[751,4],[756,3],[760,1],[762,4],[796,1],[798,3],[802,4],[807,5],[813,1],[815,3],[819,3],[823,4],[828,3],[845,3],[849,3],[861,1],[863,3],[867,4],[872,4],[887,3],[891,5],[897,3],[901,3],[918,1],[920,1],[936,3],[942,3],[946,1],[948,3],[954,3],[958,3],[975,1],[977,3],[981,1],[983,3],[987,4],[1073,1],[1075,5],[1165,1],[1167,4],[1172,1],[1174,3],[1178,4],[1266,3],[1270,2],[1273,3],[1277,4],[1282,2],[1285,3],[1289,3],[1293,3],[1314,1],[1316,2],[1319,2],[1322,3],[1326,3],[1330,5],[1336,5],[1342,3],[1346,2],[1355,1],[1357,2],[1383,2],[1386,6],[1393,1],[1395,2],[1398,5],[1404,6],[1467,1],[1486,2],[1497,3],[1514,1],[1544,3],[1548,3],[1552,2],[1555,3],[1559,5],[1565,2],[1568,2],[1571,3],[1575,3],[1579,3],[1583,2],[1586,3],[1590,5],[1596,2],[1599,2],[1602,3],[1611,2],[1614,3],[1618,3],[1622,2],[1625,3],[1653,1],[1655,3],[1659,2],[1662,3],[1666,5],[1672,2],[1675,4],[1680,3],[1702,3],[1706,4],[1711,2],[1714,1],[1716,2],[1734,3],[1738,3],[1742,1],[1744,3],[1748,5],[1754,2],[1757,2],[1774,1],[1776,3],[1780,2],[1783,3],[1787,5],[1793,2],[1796,2],[1799,3],[1808,2],[1811,3],[1815,3],[1819,4],[1829,1],[1831,3],[1835,2],[1838,3],[1842,5],[1848,2],[1851,4],[1877,3],[1881,4],[1886,2],[1889,1],[1891,2],[1894,2],[1904,2],[1907,3],[1911,3],[1915,2],[1918,4],[1923,3],[1927,1],[1929,3],[2038,1],[2046,2],[2097,1],[2127,2],[2160,1],[2188,2],[2272,2],[2275,1]]},"1094":{"position":[[7,3],[11,4],[16,3],[20,3],[24,3],[28,2],[81,1],[83,5],[127,1],[129,4],[149,1],[151,2],[171,1],[173,5],[179,2],[198,1],[213,2],[216,3],[220,4],[245,1],[247,5],[253,6],[260,3],[264,3],[268,3],[272,4],[325,1],[327,5],[333,3],[363,1],[365,2],[377,1],[379,5],[385,2],[395,2],[398,3],[402,3],[406,2],[409,4],[414,3],[418,1],[420,3],[517,1],[546,2],[554,1],[560,1],[571,1],[578,1],[584,1],[594,2],[691,3],[695,2],[700,2],[732,1],[736,2],[739,2],[753,1],[755,4],[765,1],[767,3],[791,1],[793,2],[796,1],[798,6]]},"1096":{"position":[[0,4],[12,1],[37,1],[39,3],[43,2],[46,3],[50,3],[54,3],[58,2],[67,1],[69,2],[87,1],[98,1],[100,4],[105,4],[118,1],[136,2],[139,3],[159,5],[165,4],[170,3],[189,3],[193,5],[219,1],[262,1],[270,2],[273,5],[279,4],[322,1],[324,5],[330,2],[333,2],[336,4],[341,2],[344,3],[348,3],[352,1],[354,4],[359,2],[380,1],[382,2],[385,3],[406,1],[408,6],[415,3],[435,1],[437,1],[439,4],[444,5],[476,1],[486,1],[488,2],[491,5],[497,2],[500,2],[503,3],[507,2],[514,2],[517,4],[539,1],[541,4],[554,1],[562,2],[565,5],[591,1],[593,3],[618,2],[629,1],[633,2],[653,1],[657,2],[675,1],[683,2],[686,5],[692,2],[695,5],[716,1],[744,2],[747,3],[751,3],[755,3],[759,1],[761,3],[765,1],[767,3],[777,2],[780,3],[784,5],[790,3],[794,2],[797,5],[803,4],[808,3],[812,2],[849,1],[851,2],[854,2],[857,2],[860,5],[866,4],[887,2],[890,3],[922,1],[932,2],[957,1],[959,2],[962,3],[970,1],[972,4],[977,3],[981,1],[983,2],[986,1],[988,1],[990,4],[995,2],[998,3],[1002,2],[1005,5],[1011,2],[1014,3],[1018,2],[1021,3],[1025,2],[1028,5],[1034,3],[1038,2],[1041,3],[1045,2],[1048,4],[1053,1],[1055,2],[1058,3],[1062,4],[1067,1],[1069,2],[1072,2],[1075,4],[1080,4],[1085,5],[1112,1],[1114,5],[1135,1],[1137,5],[1166,1],[1168,4],[1173,3],[1251,1],[1253,3],[1257,1],[1259,3],[1271,1],[1273,1],[1275,5],[1281,4],[1307,1],[1309,2],[1312,2],[1332,3],[1336,5],[1342,6],[1363,1],[1365,3],[1375,1],[1383,1],[1385,5],[1391,3],[1410,1],[1412,2],[1415,3],[1419,3],[1433,1],[1439,1],[1441,2],[1444,3],[1448,5],[1454,2],[1457,5],[1463,5],[1469,1],[1471,4],[1476,2],[1479,4],[1484,3],[1492,2],[1495,4],[1519,1],[1521,6],[1528,2],[1541,1],[1550,1],[1552,3],[1556,4],[1561,3],[1565,4],[1570,2],[1573,5],[1579,4],[1584,3],[1588,5],[1611,1],[1613,2],[1616,3],[1630,3],[1634,3],[1638,4],[1643,3],[1647,1],[1649,4],[1654,3],[1658,6],[1678,2],[1710,1],[1712,5],[1740,1],[1742,2],[1745,1],[1761,1],[1773,1],[1831,1],[1833,5],[1839,3],[1861,1],[1887,1],[1889,2],[1910,1],[1921,3],[1925,2],[1957,1],[1959,4],[1993,1],[1995,4],[2000,4],[2077,1],[2085,2],[2115,1],[2131,4],[2144,1],[2164,2],[2167,2],[2209,1],[2341,6],[2364,2],[2367,2],[2374,1],[2376,2],[2388,1],[2390,3],[2394,3],[2398,3],[2402,2],[2405,3],[2409,3],[2413,1],[2415,3],[2419,3],[2433,1],[2465,1],[2467,5],[2473,2],[2476,3],[2480,4],[2485,2],[2488,4],[2504,1],[2516,1],[2518,1],[2520,3],[2524,3],[2528,3],[2532,3],[2548,1],[2550,3],[2578,1],[2596,2],[2599,6],[2606,3],[2610,5],[2616,1],[2618,3],[2622,3],[2626,2],[2629,2],[2638,1],[2640,3],[2663,1],[2665,2],[2668,3],[2672,5],[2678,4],[2683,5],[2695,1],[2697,3],[2701,3]]},"1099":{"position":[[0,2],[3,2],[6,5],[12,1],[14,3],[18,5],[63,1],[65,3],[69,2],[72,4],[77,3],[81,5],[87,2],[107,5],[123,1],[144,1],[163,1],[165,2],[168,4],[184,1],[186,4],[191,3],[203,2],[206,3],[227,1],[229,5],[235,1],[251,1],[253,3],[257,3],[319,1],[343,1],[362,1],[483,3],[505,1],[507,4],[527,1],[529,5],[543,1],[556,3],[560,2],[568,1],[588,1],[599,1],[601,2],[604,7],[612,4],[617,4],[639,1],[641,5],[657,1],[670,1],[672,2],[675,4],[694,1],[701,3],[705,3],[709,1],[711,3],[715,1],[717,3],[721,4],[734,1],[781,1],[787,1],[789,3],[793,3],[797,1],[799,1],[801,3],[856,1],[880,1],[899,1],[992,3],[1029,1],[1031,5],[1037,2],[1052,5],[1066,1],[1079,3],[1083,2],[1086,5],[1092,4],[1097,3],[1101,1],[1103,4],[1108,5],[1132,2],[1135,3],[1139,3],[1143,2],[1146,2],[1149,4],[1154,3],[1170,5],[1176,2],[1179,4],[1184,4],[1189,4],[1194,2],[1197,2],[1200,3],[1260,1],[1306,1],[1332,1],[1334,4],[1347,1],[1349,2],[1377,1],[1379,4],[1384,2],[1387,4],[1407,1],[1409,4],[1414,6],[1479,1],[1503,1],[1522,1],[1542,1]]},"1101":{"position":[[22,1],[24,3],[36,1],[38,4],[54,1],[65,1],[67,4],[72,2],[75,3],[79,6],[86,1],[88,3],[92,2],[95,3],[99,3],[103,4],[108,6],[115,2],[118,4],[123,3],[146,2],[149,4],[154,3],[176,1],[196,1],[198,3],[202,3],[213,1],[215,2],[218,2],[221,2],[224,3],[228,2],[231,3],[235,2],[238,4],[243,5],[249,4],[254,3],[258,3],[262,3],[266,3],[270,2],[273,4],[278,2],[281,3],[285,3],[289,1],[291,3],[295,5],[301,3],[305,5],[311,4],[316,4],[321,3]]},"1104":{"position":[[0,1],[2,3],[6,1],[8,3],[12,2],[15,2],[44,1],[55,1],[72,1],[74,5],[80,2],[88,1],[103,1],[105,4],[110,5],[121,2],[124,2],[127,4],[132,5],[138,3],[142,2],[145,4],[150,2],[153,4],[186,5],[197,3],[201,2],[220,1],[238,1],[240,5],[261,1],[267,1],[331,1],[333,2],[354,2]]},"1107":{"position":[[8,1],[35,1],[65,2],[90,1],[117,2],[120,2]]},"1109":{"position":[[4,1],[10,1],[30,1],[41,1],[43,5],[53,1],[59,5],[79,1],[100,1],[102,5]]},"1111":{"position":[[0,1],[2,2],[17,5],[53,1],[62,1],[69,1],[75,1],[77,5],[83,1],[85,6],[156,1],[172,1],[174,6],[181,2],[198,1],[204,2],[207,3],[211,1],[213,4],[218,5]]},"1113":{"position":[[4,1],[17,1],[36,6],[43,5],[60,1],[157,2],[175,1],[177,5],[200,1],[216,1],[232,1],[239,1],[259,2],[285,1],[301,1],[303,5]]},"1115":{"position":[[4,2],[7,4],[12,1],[16,2],[34,1],[36,3],[40,4],[53,2],[61,1],[71,1],[73,5],[79,4],[84,4],[156,1],[182,1],[184,6],[191,3],[195,3],[205,1],[213,2],[216,2],[219,3],[223,3]]},"1117":{"position":[[4,1],[6,5],[25,5],[53,1],[61,1],[75,3],[79,5]]},"1119":{"position":[[12,1],[19,5],[30,1],[40,1],[42,5],[48,2],[51,1],[53,4],[58,2],[64,1],[87,1],[93,1],[99,1],[101,3],[105,4],[110,5],[116,1],[118,5],[124,2],[130,1],[132,5]]},"1121":{"position":[[16,1],[30,1],[38,4],[43,2],[46,2],[49,7],[64,1],[66,2],[69,5],[75,5],[85,1],[87,4],[187,2],[205,1],[207,5],[213,5]]},"1123":{"position":[[0,2],[3,3],[17,3],[21,4],[26,2],[29,2],[32,4],[82,1],[102,1],[104,2],[107,3],[111,5]]},"1125":{"position":[[16,1],[35,3],[46,1],[48,2],[51,4],[56,4],[61,3],[78,2],[81,3],[85,5],[91,2],[94,2],[110,3],[114,2],[117,3],[121,5],[127,2],[130,2],[133,1],[135,2],[138,3],[142,3],[163,1],[165,3],[169,2],[172,5],[178,3],[182,3],[186,2],[189,3],[193,3],[197,3],[201,4],[219,2],[222,5],[228,1],[230,2],[233,5],[260,1],[262,3],[266,3],[270,1],[272,2],[280,3],[284,5],[290,2],[308,1],[310,4],[315,2],[318,3],[322,5],[343,1],[362,1],[368,1],[370,4],[375,3],[379,5],[392,2],[395,4],[400,2],[403,2],[406,3],[410,2],[413,2],[416,3],[420,3],[424,2],[434,1],[436,2],[439,2],[442,3],[446,2],[449,4],[454,3],[458,1],[460,3]]},"1127":{"position":[[0,1],[2,3],[6,1],[8,3],[29,3],[33,5],[73,1],[75,3],[79,2],[82,2],[94,2],[104,1],[122,4],[127,1],[129,2],[132,3],[136,1],[138,4],[143,3],[149,2],[152,2],[170,1],[172,3],[178,2],[187,1],[194,1],[203,1],[205,4],[210,3],[214,2],[217,2],[220,4],[225,3],[229,3],[233,4],[238,1],[240,2],[243,2],[279,1],[281,2],[284,3],[290,2],[299,1],[301,3],[320,2],[323,3],[327,2],[330,4]]},"1129":{"position":[[0,2],[20,1],[22,3],[26,3],[32,2],[41,1],[43,3],[62,3],[66,6],[73,2],[76,3],[97,4],[102,3],[106,2],[109,1],[111,4],[116,6],[123,2],[126,3],[130,2],[133,5],[139,4],[144,5],[150,1],[152,7]]},"1131":{"position":[[8,1],[24,2],[27,3],[31,2],[34,6],[44,2],[73,1],[75,5],[89,1],[91,3],[95,2],[98,5],[104,2],[107,2],[110,3],[117,3],[121,6],[128,3],[132,3],[136,5]]},"1133":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1135":{"position":[[41,1],[60,1],[74,2],[77,2],[84,1],[86,2],[89,4],[94,2],[115,1],[131,1],[145,4],[150,2],[170,1],[172,3],[176,7],[184,2],[199,3],[203,7],[235,1],[256,1],[258,4],[263,4],[268,3],[272,3],[276,2],[279,1],[281,4],[286,2],[321,1],[323,2],[353,1],[355,4],[360,5],[366,2],[386,1],[388,4],[393,3],[397,5],[415,3],[431,1],[433,3],[437,4],[442,2],[445,3],[457,2],[476,1],[495,1],[497,2],[517,1],[547,1],[584,4],[609,1],[624,1],[641,1],[662,1],[679,1],[681,5],[687,2],[690,5],[713,1],[715,3],[719,4],[724,4],[746,1],[748,3],[752,4],[757,3],[809,1],[839,1],[841,2],[862,1],[864,5],[870,4],[883,1],[885,3],[889,2],[892,2],[903,1],[914,2],[917,5],[923,5],[929,2],[951,2],[954,2],[957,3],[961,5]]},"1137":{"position":[[16,1],[18,3],[26,1],[28,3],[32,3],[36,5],[42,1],[44,3],[48,3],[52,3],[56,3],[65,1],[76,1],[94,1],[96,2],[99,1],[111,1],[113,4],[118,3],[122,3],[131,1],[137,4],[142,3],[146,2],[149,5],[170,1],[172,3],[176,4],[181,4],[186,3],[207,1],[209,2],[212,3],[233,1],[235,1],[242,1],[244,3],[256,1],[258,7],[266,3],[270,3],[274,4],[279,5],[285,2],[288,4],[293,2],[300,1],[324,2],[327,3],[331,3],[335,5],[341,3],[345,2],[348,1],[350,2],[353,2],[356,2],[359,3],[363,5],[373,1],[396,1],[398,4],[403,1],[410,1],[412,2],[415,1],[425,1],[450,1],[461,2],[470,2],[473,2],[476,2],[479,2],[505,1],[507,4],[512,7],[532,1],[534,3],[538,2],[541,3],[560,1],[573,3],[586,2],[610,2],[627,1],[643,1],[656,1],[664,2],[680,1],[717,2],[720,1],[722,4],[744,1],[757,1],[759,2],[762,4],[777,1],[782,3],[786,6],[793,3],[797,3],[801,3],[805,4],[829,2],[832,3],[855,1],[876,1],[898,4],[903,3],[907,3],[972,1],[1005,1],[1021,1],[1023,3],[1040,1],[1054,1],[1072,1],[1089,2],[1092,5],[1104,3],[1108,4],[1125,1],[1140,2],[1156,1],[1176,1],[1199,1],[1213,2],[1216,4],[1241,3],[1245,2],[1248,2],[1251,3],[1268,2],[1271,2],[1274,2],[1277,2],[1280,2],[1312,1],[1326,1],[1328,5],[1334,2],[1362,1],[1364,5],[1370,2],[1387,2],[1390,3],[1394,4],[1399,2],[1402,3],[1415,1],[1429,1],[1444,1],[1446,4],[1451,1],[1465,1],[1467,1],[1475,1],[1477,2],[1489,1],[1491,6],[1498,5],[1504,2],[1507,2],[1527,1],[1529,3],[1533,2],[1536,2],[1539,2],[1542,1],[1544,3],[1548,4],[1553,3],[1562,2],[1565,4],[1570,7],[1578,2],[1593,1],[1595,1],[1597,2],[1617,1],[1619,3],[1639,1],[1690,1],[1700,1],[1712,1],[1722,1],[1951,2],[1989,2],[2001,1],[2003,4],[2017,1],[2033,2],[2036,2],[2039,2],[2062,1],[2068,1],[2087,1],[2089,1],[2096,1],[2135,1],[2142,3],[2146,5],[2170,1],[2189,2],[2192,2],[2199,2],[2202,2],[2210,1],[2229,1],[2231,5],[2237,1],[2239,2],[2242,2],[2245,2],[2248,3],[2252,1],[2269,1],[2271,3],[2288,1],[2319,2],[2332,1],[2341,1],[2343,1],[2345,2],[2353,1],[2355,3],[2359,2],[2362,2],[2365,2],[2368,1],[2401,1],[2412,1],[2414,4],[2419,2],[2422,2],[2444,1],[2458,1],[2460,1],[2478,1],[2480,4],[2493,1],[2502,2],[2505,2],[2508,4],[2513,3],[2517,2],[2520,2],[2523,4],[2528,2],[2538,1],[2540,5],[2546,2],[2549,3],[2573,2],[2593,2],[2603,1],[2617,1],[2619,1],[2626,1],[2628,2],[2631,2],[2642,2],[2673,1],[2687,2],[2713,2],[2716,1],[2718,2],[2721,2],[2724,2],[2735,2],[2749,1],[2767,1],[2783,2],[2786,1],[2788,4],[2793,1],[2795,3],[2799,2],[2818,1],[2820,1],[2822,3],[2846,1],[2848,4],[2871,2],[2874,3],[2878,3],[2913,1],[2915,4],[2920,4],[2925,3],[2929,2],[2932,2],[2985,1],[2987,3],[2991,3],[2995,2],[3016,1],[3018,1],[3020,2],[3033,1],[3035,4],[3040,2],[3043,3],[3054,1],[3056,2],[3082,1],[3084,3],[3088,4],[3098,1],[3100,2],[3135,4],[3140,3],[3144,1],[3146,1],[3148,2],[3151,1],[3153,4],[3158,2],[3161,2],[3164,2],[3186,1],[3188,2],[3208,1],[3221,4],[3231,3],[3235,5],[3241,3],[3245,3],[3249,1],[3251,3],[3255,2],[3258,3],[3262,2],[3304,2],[3330,2],[3349,4],[3371,1],[3373,4],[3378,2],[3381,6],[3396,1],[3419,1],[3426,1],[3428,4],[3440,1],[3442,5],[3478,2],[3491,1],[3493,4],[3511,1],[3539,1],[3541,1],[3551,2],[3575,1],[3589,1],[3591,4],[3617,3],[3621,2],[3635,1],[3637,2],[3663,1],[3665,2],[3668,4],[3687,1],[3689,4],[3694,2],[3697,3],[3701,3],[3705,4],[3717,1],[3723,1],[3725,2],[3728,3],[3732,2],[3759,1],[3770,2],[3773,3],[3782,1],[3784,5],[3790,3],[3794,1],[3796,4],[3818,1],[3836,2],[3839,3],[3843,6],[3850,3],[3879,3],[3916,1],[3918,2],[3925,1],[3927,5],[3933,5],[3939,3],[3943,3],[3951,1],[3953,4],[3958,4],[3963,2],[3978,1],[3995,1],[4014,1],[4016,5],[4026,1],[4028,5],[4060,2],[4079,1],[4081,4],[4086,3],[4114,1],[4120,1],[4134,1],[4164,1],[4166,3],[4174,1],[4180,1],[4196,1],[4211,2],[4214,2],[4231,1],[4252,1],[4254,2],[4257,3],[4278,1],[4284,1],[4309,1],[4311,4],[4344,1],[4351,3],[4372,1],[4374,2],[4377,3],[4389,2],[4392,3],[4396,2],[4399,3],[4408,1],[4417,1],[4419,3],[4423,2],[4437,1],[4469,2],[4487,2],[4490,2],[4504,1],[4506,3],[4519,1],[4521,4],[4536,1],[4558,3],[4562,2],[4565,2],[4576,1],[4597,2],[4600,3],[4604,2],[4624,1],[4631,3],[4655,1],[4674,2],[4691,1],[4693,4],[4706,2]]},"1140":{"position":[[0,4],[23,1],[44,1],[46,4],[51,3],[55,1],[57,3],[76,1],[78,4],[110,1],[199,1],[201,3],[214,2],[236,1],[238,2],[322,1],[399,1],[438,1],[581,1],[692,1],[705,1],[745,1],[747,5],[767,2],[787,1],[793,1],[822,1],[824,1],[826,3],[846,1],[848,2],[891,1],[913,1],[926,1],[1076,5],[1102,1],[1104,4],[1129,2]]},"1142":{"position":[[5,1],[26,1],[28,3],[52,1],[73,3],[85,1],[101,1],[103,3],[107,3],[124,1],[126,3],[130,3],[174,1],[185,1],[199,1],[210,1],[444,2],[470,5],[480,1],[513,1],[515,5],[525,1],[536,3],[553,1],[560,1],[562,3],[568,2],[571,3],[589,1],[595,1],[623,1],[629,1],[672,1],[674,2],[710,1],[732,1],[734,2],[741,1],[749,1],[769,1],[771,2],[844,1],[850,1],[902,2],[905,4],[910,2],[913,3],[917,3],[951,1],[958,1],[960,3],[964,3],[985,1],[987,2],[990,3],[994,2],[997,2]]},"1144":{"position":[[0,3],[4,1],[6,2],[9,2],[12,2],[15,2],[18,2],[64,1],[95,3],[99,2],[136,2],[139,4],[162,1],[164,4],[195,2]]},"1146":{"position":[[28,1],[49,1],[80,4],[135,1],[145,1],[157,1],[167,1],[264,1],[313,1],[327,1],[421,1],[494,1],[545,1],[547,1],[549,2],[552,4],[579,1],[589,1],[591,4],[604,1],[632,1],[634,2],[685,1],[687,2],[690,4],[705,1],[716,3],[737,1],[746,2],[749,5],[765,1],[769,2],[772,5],[782,1],[788,1],[802,1],[813,3],[819,1],[821,3],[825,2],[828,2],[847,4],[852,2],[859,1],[865,1],[881,3],[885,2],[888,2],[903,2],[957,1],[965,2],[1002,1],[1010,2],[1101,3],[1105,5],[1111,1],[1134,2],[1142,3],[1146,2],[1159,1],[1161,5],[1167,3],[1171,2],[1186,1],[1188,2],[1191,2],[1198,1],[1200,4],[1221,1],[1223,3],[1227,1],[1229,3],[1233,3],[1237,2],[1240,4],[1309,1],[1311,3],[1315,1],[1317,2],[1358,1],[1360,2],[1363,5],[1373,1],[1375,4],[1380,2],[1383,3],[1387,2],[1390,3],[1394,3],[1415,1],[1443,1],[1445,4],[1473,1],[1475,2],[1478,4],[1488,1],[1509,1],[1511,4],[1521,1],[1523,3],[1527,1],[1529,3],[1566,3],[1570,2],[1573,3],[1577,3],[1589,1],[1591,4],[1596,2],[1599,4],[1604,2],[1607,2],[1610,2],[1621,3],[1625,2],[1628,3],[1646,1],[1648,2],[1651,6],[1658,2],[1661,3],[1681,1],[1683,2],[1686,4],[1691,4],[1696,4],[1701,2],[1704,3],[1716,1],[1718,6],[1725,4],[1730,4],[1735,2],[1738,3],[1750,1],[1758,1],[1760,4],[1781,1],[1791,2],[1811,1],[1813,2],[1816,2],[1824,1],[1830,1],[1836,1],[1849,1],[1851,5],[1866,2],[1869,4],[1874,2],[1877,1],[1879,2],[1891,1],[1893,3],[1922,1],[1935,2],[1938,3],[1958,2],[1978,2],[1981,2],[1984,3],[2004,1],[2006,1],[2013,1],[2036,1],[2038,3],[2042,4],[2047,2],[2050,5],[2056,4],[2061,5],[2067,2],[2070,2],[2073,1],[2075,3]]},"1148":{"position":[[0,3],[25,1],[27,1],[47,1],[113,1],[129,1],[131,2],[141,3],[145,3],[158,1],[177,1],[179,4],[200,1],[202,5],[208,5],[218,1],[239,1],[241,4],[272,1],[318,1],[342,1],[368,1],[411,1],[413,2],[480,1],[499,1],[536,1],[591,1],[593,2],[646,1],[648,2],[707,1],[709,2],[950,1],[1003,1],[1082,1],[1089,1],[1130,3],[1134,3],[1147,1],[1168,1],[1170,2],[1222,1],[1252,1],[1279,2],[1282,2],[1312,1],[1314,2],[1393,1],[1578,1],[1585,1],[1662,1],[1664,3],[1668,2],[1679,1],[1812,1],[1929,1],[1980,1],[2043,2],[2048,1],[2240,1],[2242,2],[2322,1],[2337,1],[2356,2],[2375,1],[2389,3],[2393,3],[2413,1],[2453,1],[2455,6],[2499,1],[2501,1],[2503,2],[2513,1],[2515,2],[2518,3],[2539,1],[2541,4],[2546,2],[2549,3],[2553,2],[2556,2]]},"1150":{"position":[[0,2],[11,1],[13,4],[27,2],[30,2],[33,4],[38,2],[41,1],[43,3],[69,1],[96,1],[98,4],[103,2],[106,4],[111,2],[130,1],[132,5],[138,2],[157,2],[160,3],[164,5],[179,1],[181,5],[187,4],[192,3],[196,2],[199,4],[204,3],[218,1],[220,4],[237,1],[239,5],[245,4],[250,3],[268,1],[280,1],[300,1],[302,3],[306,3],[310,4],[324,1],[326,1],[328,3],[332,1]]},"1152":{"position":[[19,1],[21,2],[24,5],[44,1],[46,2],[72,1],[83,3],[87,2],[90,4],[107,1],[109,4],[129,1],[142,1],[153,2],[176,4],[202,2],[205,3],[209,4],[223,1],[236,1],[238,4],[243,4],[259,1],[261,5],[267,3],[271,1],[279,1],[293,1],[295,4],[309,1],[311,2],[314,3],[318,2],[321,3],[334,2],[337,2],[340,2],[343,3],[347,3],[387,2],[405,1],[415,1],[417,2],[420,3],[424,3],[446,2],[523,1],[543,1],[588,1],[712,3],[716,3],[741,1],[763,1],[781,1],[783,4],[805,1],[834,1],[846,2],[849,4],[854,5],[860,1],[879,1],[896,1],[898,2],[947,1],[961,1],[963,3],[967,1],[969,4],[974,2],[993,2],[996,3],[1000,2],[1048,1],[1056,1],[1107,2],[1167,1],[1199,1],[1211,1],[1213,4],[1218,2],[1226,1],[1228,3],[1232,5],[1238,1],[1250,1],[1252,3],[1256,1],[1258,3],[1262,5],[1268,3],[1272,2],[1275,4],[1280,4],[1285,3],[1289,4],[1303,1],[1311,1],[1325,1],[1327,2],[1330,3],[1334,1],[1336,2],[1350,3],[1354,4],[1359,3],[1363,2],[1366,1],[1374,1],[1394,2],[1404,2],[1407,2],[1410,3],[1414,5],[1440,1],[1463,1],[1471,1],[1473,4],[1490,1],[1492,3],[1496,1],[1498,2],[1501,4],[1506,1],[1508,5],[1514,2],[1517,3],[1530,1],[1554,1],[1583,2],[1723,2],[1763,1],[1792,2],[1822,2],[1862,1],[1882,1],[1936,2],[2072,1],[2091,1],[2136,1],[2165,1],[2167,3],[2220,1],[2238,1],[2268,3],[2288,1],[2290,2],[2302,1],[2332,1],[2362,1],[2392,2],[2395,3],[2399,2],[2402,2],[2422,1],[2424,2],[2427,2],[2437,1],[2439,1],[2441,1],[2443,3],[2512,1],[2625,3],[2648,3],[2652,2],[2655,4],[2669,1],[2683,2],[2686,2],[2689,3],[2722,1],[2724,3],[2744,3],[2748,3],[2752,2],[2755,2],[2758,3],[2762,3],[2766,3],[2770,2],[2773,4],[2778,2]]},"1154":{"position":[[5,3],[29,1],[31,4],[53,1],[55,4],[60,4],[65,3],[69,3],[98,1],[139,2],[142,1],[167,1],[169,5],[193,1],[207,1],[209,5],[215,5],[230,1],[232,4],[237,2],[240,3],[244,3],[272,1],[274,5],[280,6],[318,1],[350,2],[353,2],[356,2],[359,2],[384,1],[386,1],[394,1],[415,1],[429,1],[441,1],[451,1],[463,2],[466,2],[469,3],[488,3],[509,3],[536,1],[554,1],[556,3],[560,3],[580,1],[582,5],[588,2],[606,2],[609,6],[633,1],[635,4],[640,3],[653,2],[656,2],[671,2],[682,1],[684,2],[703,1],[705,3],[709,2],[712,2],[715,3],[726,1],[728,3],[732,1],[734,3],[738,3]]},"1156":{"position":[[8,1],[10,4],[30,1],[43,1],[57,3],[61,2],[64,3],[68,5],[74,3],[102,1],[113,1],[125,1],[142,2],[145,2],[157,1],[167,1],[180,1],[182,3],[186,2],[189,2]]},"1158":{"position":[[0,3],[12,1],[14,2],[17,4],[22,2],[25,3],[72,2],[75,2],[78,2],[81,3],[102,1],[104,2],[112,1],[130,1],[142,1],[154,1],[164,3],[177,1],[188,1],[190,2],[193,2],[203,1],[205,3],[209,2],[212,2],[224,1],[226,2],[229,4],[234,3],[238,1],[240,4],[254,1],[256,3],[260,1],[276,1],[278,2],[281,3],[285,2],[297,1],[302,2],[308,1],[310,2],[313,2],[323,2],[326,2],[334,1],[336,4],[347,1],[349,3],[361,1],[363,4],[377,1],[384,1],[386,2],[389,3],[405,2],[408,3],[412,2],[462,1],[476,2],[495,1],[497,5],[519,1],[521,3],[525,2],[528,3],[532,5],[538,1],[540,3],[562,2],[565,2],[568,4],[573,1],[575,2]]},"1160":{"position":[[8,1],[10,2],[13,4],[18,2],[38,1],[51,1],[53,2],[56,2],[59,4],[85,2],[88,3],[112,1],[121,1],[123,5],[129,2],[148,1],[174,1],[176,4],[231,2],[247,1],[276,1],[297,3],[320,2],[323,3],[327,1],[329,2],[332,3],[344,1],[346,2],[365,1],[389,1],[402,3],[406,4],[411,1],[413,1],[461,1],[471,1],[484,1],[503,4],[508,4],[513,4],[518,3],[522,2],[545,2],[554,2],[565,1],[584,1],[603,1],[605,2],[608,2],[616,1],[650,1],[683,1],[705,1],[720,2],[723,1],[725,1],[727,3],[763,1],[765,2],[777,1],[803,1],[805,1],[811,2],[814,2],[822,1],[829,1],[837,1],[856,2],[859,2],[862,3],[871,1],[971,1],[973,4],[978,2],[981,3],[985,2],[988,3],[992,3],[996,1],[998,4],[1008,1],[1010,4],[1015,2],[1018,3]]},"1163":{"position":[[0,3],[4,3],[8,6],[30,1],[44,2],[47,2],[61,2],[64,2],[67,5],[73,1],[75,6],[135,1],[154,1],[191,2]]},"1165":{"position":[[15,1],[32,2],[35,3],[39,2],[56,2],[67,1],[78,1],[80,2],[117,2],[137,1],[139,3],[143,3],[147,3],[159,1],[217,2],[220,5],[231,1],[242,1],[270,1],[272,5],[286,1],[317,1],[363,2],[366,2],[369,2],[380,1],[382,2],[401,1],[419,1],[427,3],[467,1],[513,2],[516,2],[562,1],[577,1],[598,1],[600,2],[617,1],[652,1],[665,1],[678,1],[691,1],[733,3],[737,2]]},"1167":{"position":[[0,3],[19,2],[30,1],[41,1],[43,2],[59,2],[74,1],[96,2],[107,1],[109,2],[112,3],[116,4],[121,1],[123,2],[126,2],[129,3],[133,2],[136,2],[156,1],[163,1],[165,2],[176,1],[182,2],[192,4],[211,2],[219,2],[230,1],[232,2],[235,2],[245,3],[249,2],[252,1],[254,2],[257,2]]},"1170":{"position":[[0,3],[4,5],[26,1],[37,2],[40,2],[43,2],[54,1],[83,1],[85,2],[88,1],[95,2],[124,1],[126,2],[129,1],[137,1],[151,1],[153,3],[157,2],[160,1],[174,2]]},"1172":{"position":[[0,3],[21,2],[33,1],[43,2],[66,2],[121,2],[124,2],[134,5],[140,3],[144,3],[173,1],[226,2],[229,2],[237,1],[248,1],[284,2],[287,2],[298,1],[333,1],[391,2],[394,2]]},"1174":{"position":[[2,2],[77,2],[107,2],[110,2],[121,1],[140,2],[143,2],[146,3],[150,2],[169,1],[174,2],[177,1],[179,3],[183,2],[186,2],[205,1],[224,1],[226,3],[247,1],[249,3],[253,4],[258,3],[262,3],[266,3],[270,3],[274,2]]},"1177":{"position":[[10,1],[17,1],[19,3],[23,3],[27,3],[39,1],[52,3],[68,3],[72,3],[76,3],[80,1],[82,2],[85,6],[92,2],[95,2],[98,2]]},"1179":{"position":[[15,1],[17,5],[23,3],[57,1],[67,1],[83,1],[85,2],[102,1],[104,2],[185,1],[187,2]]},"1181":{"position":[[2,2],[12,2],[27,2],[30,2],[53,2],[84,1],[106,1],[132,2],[135,1],[137,5],[152,1],[154,4],[167,1],[169,1],[171,2],[174,2],[177,2]]},"1184":{"position":[[7,2],[10,2],[27,2],[45,1],[59,1],[61,2],[64,2],[67,1],[69,4],[98,2],[110,1],[112,4],[125,1],[127,2],[143,2],[146,3],[150,2],[153,2],[166,1],[168,2],[178,1],[180,4],[185,2],[188,3],[192,6],[199,2],[214,1],[225,1],[227,3],[231,2],[234,2],[237,2],[245,1],[263,2],[298,2],[309,1],[319,2],[332,3],[336,2],[358,1],[360,2],[375,1],[377,2]]},"1186":{"position":[[12,2],[15,5],[26,1],[49,2],[68,1],[70,2],[82,1],[84,3],[88,6],[95,2],[98,5],[104,3],[108,4],[130,1],[132,3],[136,3],[140,1],[142,2],[145,5],[151,4],[156,4],[161,2],[164,2],[167,1],[169,3],[173,2],[176,4],[181,2],[192,2],[195,1],[197,2],[200,4],[217,1],[225,2],[236,1],[243,1],[253,1],[255,2],[276,2],[287,1],[289,2],[292,6],[312,1],[314,2]]},"1188":{"position":[[8,2],[28,1],[36,1],[46,2],[61,1],[75,1],[89,1],[91,2],[102,2],[122,1],[124,1],[135,2],[144,1],[163,1],[177,3],[181,4],[186,2],[198,1],[200,2],[224,1],[226,4],[231,2],[234,5],[240,3],[261,1],[263,5],[269,1],[271,2],[287,1],[289,3],[293,2],[301,2],[304,2]]},"1190":{"position":[[0,3],[4,3],[23,1],[40,1],[69,1],[71,2],[74,3],[78,3],[82,2],[85,2],[88,2],[91,2],[94,2],[97,4],[102,2],[105,3],[109,2],[112,3],[116,2],[128,1],[139,1],[162,3],[206,1],[213,1],[219,1],[225,1],[261,2],[283,1],[292,1],[302,1],[338,2],[349,3],[359,1],[366,1],[383,1],[397,1],[399,2],[417,1],[419,3],[435,1],[442,2],[445,3],[449,4],[462,1],[464,3],[468,3],[472,2],[505,2],[516,1],[518,3],[522,3],[526,1],[528,3],[532,1],[544,1],[546,2],[549,3],[553,4],[558,1],[560,2]]},"1192":{"position":[[7,1],[17,1],[31,1],[48,1],[50,1],[71,1],[96,1],[98,2],[105,1],[118,1],[120,1],[122,2],[132,1],[134,4],[139,3],[143,3],[147,2],[150,2],[153,3],[157,3],[172,1],[190,1],[203,1],[221,1],[223,2],[226,3],[230,1],[232,5],[238,3],[242,3],[246,3],[250,2],[253,3],[257,2],[260,3],[264,3],[286,3],[298,1],[315,1],[317,5],[329,3],[333,1],[335,2],[338,3],[350,1],[352,2],[355,3],[377,1],[399,1],[407,2],[410,2],[413,2],[436,2],[455,1],[474,3],[498,1],[500,4],[505,2],[524,1],[526,3],[530,1],[532,3],[536,2],[539,2]]},"1194":{"position":[[0,3],[51,2],[73,1],[75,2],[95,1],[133,1],[154,1],[191,4],[209,2],[234,1],[236,4],[257,1],[259,4],[281,1],[304,2],[328,1],[330,3],[334,5],[340,2],[343,2],[346,1],[348,4],[353,3],[357,2],[368,1],[379,1],[381,5],[387,4],[392,2],[395,4],[400,3],[404,2],[407,2]]},"1196":{"position":[[0,2],[3,1],[5,3],[9,2],[12,1]]},"1198":{"position":[[5,2],[8,3],[19,1],[30,2],[54,1],[56,2],[59,3],[82,1],[84,4],[89,2],[92,3],[129,3],[133,6],[140,5],[146,2],[168,1],[170,3],[174,2],[196,1],[210,2],[213,4],[252,1],[282,2],[285,1],[287,6],[294,3],[327,6],[334,1],[336,3],[340,2],[343,5],[349,2],[352,5],[365,4],[370,4],[375,3],[393,1],[404,3],[408,4],[413,3],[436,1],[438,3],[451,1],[488,1],[490,5],[518,1],[536,1],[538,3],[542,2],[545,1],[547,3],[551,5],[557,6],[568,1],[575,1],[596,4],[610,2],[613,2],[616,6],[623,2],[626,3],[630,4],[635,3],[639,3],[647,1],[661,2],[683,1],[685,3],[689,4],[694,3],[735,2],[738,5]]},"1200":{"position":[[0,3],[9,1],[16,1],[18,2],[38,1],[40,3],[44,4],[65,4],[70,1],[72,2],[75,4],[94,1],[109,1],[111,3],[115,3],[119,4],[130,3],[134,5],[156,1],[158,6],[174,2],[177,3],[181,3],[185,3],[189,3],[200,1],[202,5],[218,2],[226,3],[251,3],[262,4],[267,5],[273,3],[291,1],[293,4],[298,2],[301,2],[304,3],[325,1],[327,2],[349,1],[351,5],[377,1],[379,3],[392,3],[396,3],[400,3],[415,5],[440,1],[454,1],[456,3],[494,1],[496,2],[503,1],[505,4],[525,1],[527,2],[530,2],[533,4],[556,1],[578,1],[613,2],[616,2],[632,1],[634,3],[646,1],[648,4],[653,2],[656,4],[661,4],[666,2],[681,1],[704,2],[723,3],[727,4],[745,2],[748,1],[750,4],[772,1],[774,5],[780,2],[783,3],[787,3],[791,3],[795,3],[799,2],[802,3],[806,5],[812,2],[830,1],[832,4],[837,2],[844,2],[881,1],[883,2],[890,1],[892,5],[898,6],[924,1],[926,3],[930,3],[951,1],[958,1],[960,4],[978,1],[980,2],[996,1],[998,5],[1004,3],[1021,2],[1056,1],[1058,5],[1064,3],[1082,3],[1086,5],[1092,3],[1116,1],[1118,4],[1145,2],[1148,3],[1152,3],[1161,1],[1163,3],[1167,4],[1172,1],[1174,3],[1188,2],[1205,1],[1207,6],[1214,3],[1218,3],[1222,3],[1226,4],[1231,2],[1248,1],[1250,2],[1253,1],[1261,2],[1264,4],[1269,2],[1280,1],[1282,4],[1291,1],[1293,2],[1296,2],[1299,4],[1304,3],[1308,3],[1312,4],[1317,4],[1322,4],[1327,4],[1332,2],[1345,1],[1347,4],[1352,2],[1355,4],[1373,3],[1377,3],[1381,3],[1402,1],[1417,3],[1421,2],[1424,5],[1430,3],[1453,1],[1455,3],[1459,3],[1463,1],[1465,4],[1470,5],[1476,2],[1479,4],[1484,3],[1510,1],[1512,4],[1517,3],[1528,1],[1537,3],[1541,2],[1544,4],[1554,2],[1557,3],[1568,3],[1572,3],[1576,3],[1580,3],[1597,4],[1624,4],[1629,4],[1634,3],[1638,4],[1643,1],[1645,6],[1652,2],[1655,1],[1657,2],[1673,2],[1676,3],[1680,1],[1682,3],[1705,1],[1707,3],[1715,3],[1719,2],[1726,1],[1728,5],[1738,1],[1762,1],[1780,1],[1782,3],[1786,1],[1788,2],[1807,1],[1809,2],[1817,1],[1819,3],[1823,5],[1837,3],[1841,5],[1856,2],[1859,3],[1863,2],[1888,4],[1893,2],[1899,2],[1928,6],[1940,1],[1962,2],[1965,3],[1969,4],[1986,1],[2007,2],[2010,4],[2015,6],[2022,3],[2026,4]]},"1203":{"position":[[4,1],[6,4],[22,2],[25,4],[61,1],[63,2],[66,1],[68,4],[73,5],[84,1],[88,2],[91,4],[96,2],[105,1],[129,1],[131,2],[139,1],[169,1],[184,1],[186,2],[191,3],[195,2],[205,1],[207,2],[210,2],[238,1],[240,5],[246,2],[251,2],[254,3],[258,2],[270,1],[281,2],[286,3],[301,1],[303,4],[308,2],[311,1],[317,1],[348,1],[350,5],[356,3],[360,2],[378,1],[392,2],[425,1],[455,1],[462,1],[480,2],[489,2],[492,2],[516,1],[518,4],[553,1],[630,1],[648,2],[651,4],[656,3]]},"1205":{"position":[[31,3],[35,2],[45,3],[71,1],[73,5],[93,2],[96,1],[117,1],[119,4],[128,1],[146,1],[148,3],[152,3],[161,1],[194,3],[198,4],[217,1],[219,4],[237,1],[239,4],[260,1],[262,4],[280,1],[296,1],[298,3],[312,4],[317,5],[323,1],[325,2],[343,1],[345,4],[350,3],[366,1],[384,3],[395,1],[397,3],[414,1],[416,5],[422,3],[426,1],[428,4],[455,1],[457,5],[463,2],[466,3],[470,7],[478,3],[482,2],[485,3],[493,1],[499,1],[510,3],[514,7],[548,1],[550,3],[554,2],[557,4]]},"1207":{"position":[[14,1],[16,3],[45,6],[52,1],[54,3],[58,3],[80,2],[96,1],[98,3],[102,1],[117,1],[138,1],[140,4],[156,3],[160,3],[178,1],[282,1],[303,3],[307,4],[312,1],[314,3],[318,4],[323,3],[331,3],[335,3],[350,2],[365,2],[378,2],[381,2],[384,3],[388,5],[394,3],[402,1],[404,4],[424,1],[426,2],[442,1],[444,4],[463,2],[499,1],[501,6],[508,3],[526,1],[528,5],[534,2],[543,1],[556,2],[559,3],[567,1],[569,5],[575,4],[580,6],[642,1],[644,3],[648,3]]},"1209":{"position":[[4,1],[6,4],[20,3],[24,5],[49,1],[51,4],[56,2],[70,3],[74,3],[93,1],[106,1],[108,4],[113,4],[122,1],[146,1],[148,2],[164,2],[181,1],[183,2],[208,3]]},"1211":{"position":[[9,2],[12,2],[15,3],[19,2],[22,3],[30,1],[56,1],[93,1],[95,3],[99,5],[120,3],[130,1],[132,4],[152,2],[171,1],[186,1],[188,5],[194,2],[197,3],[201,1],[203,2],[206,3],[210,4],[215,3],[232,4],[254,2],[257,5],[263,2],[270,1],[272,3],[276,4],[281,3],[285,4],[290,5],[296,1],[298,4],[303,3],[307,4],[312,2],[323,1],[325,4],[330,2],[343,2],[363,1],[365,1],[367,3],[376,2],[379,3],[383,2],[418,1],[420,2],[445,1],[447,2],[450,5],[456,3],[460,4],[465,3],[482,1],[484,3],[505,1],[507,6],[514,2],[517,5],[543,1],[545,4],[572,2],[575,4],[585,1],[606,1],[608,2]]},"1214":{"position":[[0,3],[9,1],[21,1],[23,2],[26,2],[29,6],[46,1],[48,3],[67,1],[69,5],[80,1],[103,1],[105,2],[115,1],[117,4],[162,2],[165,5],[171,3],[175,1],[177,5],[183,2],[202,1],[204,5],[210,2],[218,1],[233,1],[235,4],[240,3],[244,3],[248,4],[253,3],[308,1],[310,5],[316,3],[344,1],[353,5],[359,3],[363,4],[368,5],[374,3],[382,1],[384,3],[393,1],[409,1],[411,3],[430,1],[454,1],[456,5],[462,3],[470,1],[472,1],[474,3],[478,3],[482,2],[485,5],[552,1],[566,2],[580,1],[592,1],[594,1],[601,1],[603,2],[624,2],[649,1],[651,1],[658,1],[660,1],[730,3],[741,1],[748,2],[751,3],[777,3],[781,6],[801,6],[808,1],[828,3],[832,2],[859,1],[861,2],[864,2],[867,1],[869,3],[899,1],[923,1]]},"1216":{"position":[[16,2],[19,1],[24,1],[28,1],[30,4],[50,4],[72,1],[74,2],[84,1],[86,3],[90,1],[92,3],[110,1],[137,1],[149,2],[158,1],[160,2],[180,1],[182,6],[189,2],[197,1],[199,2],[202,5],[208,4],[213,2],[216,1],[218,2],[221,3],[225,3],[234,1],[270,1],[281,1],[283,1],[285,2],[288,2],[291,4],[296,2],[299,3],[303,3],[307,4],[312,2],[335,1],[352,2],[362,2],[365,5],[371,1],[373,3],[386,2],[389,3],[393,1],[395,3],[419,1],[421,4],[426,4],[450,1],[452,5],[458,2],[461,3],[475,1],[477,4],[482,4],[487,5],[507,1],[534,1],[549,1],[551,4],[556,1],[558,3],[562,3],[566,5],[572,3],[586,3],[595,1],[597,2],[600,3],[604,3],[608,4],[613,2],[616,3],[620,1],[622,4],[632,2],[652,1],[667,3],[671,2],[674,5],[680,3],[684,4],[689,2],[692,6],[699,2],[711,2],[714,3],[718,1],[720,3],[724,4],[729,3],[733,4],[738,2],[741,1],[748,1],[750,4],[772,1],[782,3],[786,5],[792,2],[795,4],[800,4],[805,2],[808,1],[820,2],[823,2],[826,5],[832,2],[835,4],[840,4],[845,2],[848,2],[861,2],[864,2],[867,5],[873,3],[883,1],[892,2],[895,5]]},"1218":{"position":[[5,1],[7,3],[24,1],[26,5],[123,3],[132,1],[134,2],[137,5],[152,2],[155,4],[160,3],[164,4],[169,3],[173,2],[176,5],[182,1],[184,3],[188,5],[207,1],[209,4],[214,5],[220,2],[223,3],[249,3],[253,5],[259,3],[263,3],[267,5],[288,1],[290,5],[296,1],[300,1],[302,4],[325,1],[327,3],[344,3],[348,4],[353,3],[357,4],[386,1],[406,1],[428,2],[431,5],[455,3],[459,2],[462,1],[464,3],[468,1],[470,2],[473,3],[490,1],[492,4],[497,2],[518,1],[520,1],[524,1],[526,5],[532,1],[534,3],[538,4],[578,4],[583,2],[606,1],[608,5]]},"1220":{"position":[[0,3],[9,2],[30,1],[32,2],[56,2],[59,3],[70,4],[75,6],[96,1],[98,4],[103,2],[123,1],[144,1],[146,4],[151,2],[154,5],[160,3],[171,1],[173,3],[177,3],[181,3],[185,3],[189,2],[192,4],[202,1],[224,1],[226,3],[230,2],[233,2],[249,2],[285,1],[287,7],[299,1],[306,1],[308,6],[330,2],[333,3],[348,1],[350,4],[355,4]]},"1222":{"position":[[0,3],[9,1],[20,2],[23,3],[27,2],[50,1],[74,1],[76,4],[81,4],[118,1],[163,1],[165,5],[175,1],[192,1],[194,2],[203,1],[205,2],[218,1],[237,1],[239,4],[244,3],[256,1],[261,3],[277,1],[279,4],[299,1],[301,5],[345,1],[347,2],[412,1],[430,1],[432,5],[455,1],[523,1],[535,1],[558,3],[598,1],[600,2],[603,4],[608,5],[614,2],[617,3],[643,2],[646,5],[652,3],[677,1],[679,3],[683,3],[693,1],[700,1],[717,1],[719,2],[759,1],[761,5],[803,1],[810,1],[844,1],[846,2],[865,1],[867,4],[885,1],[887,3],[891,3],[895,2],[898,3],[902,1],[904,3],[967,1],[981,2],[1002,1],[1004,1],[1012,2],[1033,2],[1054,1],[1056,1],[1064,1],[1132,3],[1143,1],[1167,3],[1186,1],[1188,3],[1192,1],[1196,1],[1198,4],[1203,2],[1206,4],[1211,3],[1215,4],[1233,1],[1254,1],[1256,6],[1272,1],[1306,1],[1308,2],[1326,2],[1342,1],[1344,3],[1358,1],[1360,5],[1366,6],[1409,1],[1411,4],[1416,3],[1420,3],[1438,1],[1453,1],[1455,2],[1458,3],[1469,1],[1471,3],[1475,4],[1480,2],[1483,3],[1487,3]]},"1224":{"position":[[26,1],[28,4],[33,4],[53,1],[55,5],[97,1],[104,1],[119,1],[121,2],[124,2],[127,4],[132,2],[151,1],[153,4],[169,1],[171,3],[175,4],[185,1],[201,1],[203,2],[221,1],[223,4],[228,1],[233,4],[257,1],[259,2],[262,4],[267,5]]},"1226":{"position":[[0,2],[8,1],[19,2],[22,3],[26,2],[29,3],[40,1],[42,7],[50,2],[53,3],[66,2],[69,3],[73,4],[106,3],[110,3],[114,4],[119,5],[129,2],[139,2],[142,4],[169,1],[171,2],[174,5],[180,6],[197,5],[203,2],[228,1],[230,2],[233,2],[236,2],[239,4],[244,5],[250,2],[253,2],[256,4],[261,4]]},"1230":{"position":[[10,1],[12,2],[20,1],[22,7],[34,1],[36,5],[42,3],[55,2],[58,1],[60,1],[62,3],[71,1],[73,2],[91,1],[93,3],[97,5],[103,2],[106,3],[110,3],[114,3],[131,1],[133,4],[138,5],[144,2],[147,3],[220,1],[231,1],[233,4],[238,3],[249,5],[255,4],[265,3],[269,3],[278,3],[282,3],[286,3],[290,5],[309,2],[312,3],[316,2],[319,5],[325,4],[330,3],[339,1],[341,3],[349,1],[351,2],[354,4],[382,5]]},"1232":{"position":[[5,2],[17,1],[19,2],[25,2],[48,1],[60,1],[62,5],[73,2],[89,3],[93,2],[103,1],[105,4],[129,1],[131,3],[135,2],[138,6],[145,4],[150,2],[153,3],[164,1],[166,4],[184,1],[186,5],[192,3],[205,2],[236,1],[238,5],[244,3],[248,3],[252,1],[278,1],[280,2],[305,1],[307,6]]},"1234":{"position":[[22,1],[34,7],[47,2],[50,3],[54,3],[58,6],[65,1],[69,2],[85,1],[94,1],[96,5],[102,3],[109,1],[133,1],[135,6]]},"1238":{"position":[[3,2]]},"1240":{"position":[[3,5],[9,2],[12,3],[16,1],[18,3],[24,2],[27,3],[31,1],[33,3],[37,3],[50,1],[52,2],[55,4],[60,5],[66,2],[74,1],[137,1],[158,1],[160,2],[163,2],[166,3],[175,2],[188,3],[192,1],[194,4],[209,1],[223,1],[225,5],[247,2],[250,2],[258,3],[262,4],[267,4],[278,1],[286,4],[291,2],[301,1],[308,2],[323,1],[325,5],[331,3],[335,4]]},"1242":{"position":[[0,4],[38,1],[40,4],[64,1],[66,3],[75,1],[86,3],[90,6],[116,1],[130,2],[153,2],[156,2],[159,3],[163,4]]}}}],["0",{"_index":261,"t":{"49":{"position":[[346,2]]},"97":{"position":[[105,1]]},"132":{"position":[[990,1]]},"463":{"position":[[2000,2]]},"508":{"position":[[351,3]]},"515":{"position":[[772,1]]},"563":{"position":[[891,1],[942,1]]},"604":{"position":[[883,1]]},"686":{"position":[[1663,2],[1895,2]]},"834":{"position":[[840,2]]},"1001":{"position":[[2004,2]]},"1092":{"position":[[952,1]]},"1096":{"position":[[2123,4]]},"1142":{"position":[[566,1]]},"1146":{"position":[[767,1],[817,1]]},"1148":{"position":[[2046,1]]}}}],["0+△ϕ\\phi_0",{"_index":1765,"t":{"553":{"position":[[415,11]]}}}],["0,1",{"_index":1904,"t":{"604":{"position":[[636,5]]}}}],["0,1][0,1][0,1",{"_index":1908,"t":{"604":{"position":[[842,15]]}}}],["0,r0",{"_index":2675,"t":{"863":{"position":[[321,9]]}}}],["0.0",{"_index":689,"t":{"149":{"position":[[473,3]]}}}],["0.001",{"_index":331,"t":{"63":{"position":[[135,5]]},"827":{"position":[[78,6]]}}}],["0.002",{"_index":3818,"t":{"1236":{"position":[[7,5]]}}}],["0.007",{"_index":238,"t":{"38":{"position":[[457,5]]}}}],["0.009",{"_index":1636,"t":{"475":{"position":[[177,5]]}}}],["0.01",{"_index":693,"t":{"151":{"position":[[105,4]]},"155":{"position":[[1076,4]]},"418":{"position":[[1446,7]]},"727":{"position":[[400,6]]},"836":{"position":[[190,5]]}}}],["0.02",{"_index":1637,"t":{"475":{"position":[[196,4]]},"1001":{"position":[[1950,4]]},"1234":{"position":[[42,4]]}}}],["0.035",{"_index":1930,"t":{"614":{"position":[[595,6]]},"616":{"position":[[1516,6]]}}}],["0.04",{"_index":1681,"t":{"504":{"position":[[1968,5]]},"515":{"position":[[920,5]]}}}],["0.05",{"_index":240,"t":{"38":{"position":[[468,4]]},"188":{"position":[[30,4]]},"1104":{"position":[[291,4]]}}}],["0.05p<0.05",{"_index":3665,"t":{"1156":{"position":[[169,10]]}}}],["0.08",{"_index":3706,"t":{"1174":{"position":[[50,6]]}}}],["0.08%/0.16%/0.32%/0.65",{"_index":3698,"t":{"1172":{"position":[[97,23]]}}}],["0.099",{"_index":692,"t":{"151":{"position":[[98,6]]}}}],["0.1",{"_index":528,"t":{"106":{"position":[[127,3]]},"149":{"position":[[403,3]]},"362":{"position":[[999,3]]},"475":{"position":[[377,3]]},"711":{"position":[[443,3]]},"713":{"position":[[1657,4]]},"738":{"position":[[231,6]]},"746":{"position":[[393,4]]},"759":{"position":[[520,4]]},"787":{"position":[[0,4],[243,4]]},"789":{"position":[[64,4]]},"1137":{"position":[[4626,4]]}}}],["0.1,0.3,0.5}\\{0.1",{"_index":3689,"t":{"1165":{"position":[[469,19]]}}}],["0.13",{"_index":3712,"t":{"1181":{"position":[[86,6]]}}}],["0.16",{"_index":3707,"t":{"1174":{"position":[[57,6]]}}}],["0.1782",{"_index":690,"t":{"151":{"position":[[82,7]]}}}],["0.2",{"_index":1278,"t":{"410":{"position":[[147,4]]},"784":{"position":[[461,3]]},"1001":{"position":[[296,3]]}}}],["0.256",{"_index":294,"t":{"53":{"position":[[218,5]]}}}],["0.26",{"_index":3713,"t":{"1181":{"position":[[93,6]]}}}],["0.3",{"_index":2433,"t":{"784":{"position":[[493,3]]},"825":{"position":[[714,3]]},"1165":{"position":[[489,4]]}}}],["0.3/0.6/1.2m",{"_index":3681,"t":{"1165":{"position":[[104,12]]}}}],["0.32",{"_index":3708,"t":{"1174":{"position":[[64,6]]}}}],["0.3m",{"_index":3695,"t":{"1167":{"position":[[158,4]]}}}],["0.5",{"_index":1040,"t":{"302":{"position":[[1352,3]]},"604":{"position":[[1156,5]]},"832":{"position":[[126,4]]},"1137":{"position":[[2137,4]]}}}],["0.5,0.5",{"_index":2555,"t":{"832":{"position":[[114,11]]}}}],["0.5>0.5",{"_index":1911,"t":{"604":{"position":[[1162,7]]}}}],["0.5\\}{0.1,0.3,0.5",{"_index":3690,"t":{"1165":{"position":[[494,18]]}}}],["0.5][−0.5,0.5",{"_index":2556,"t":{"832":{"position":[[131,14]]}}}],["0.6",{"_index":310,"t":{"55":{"position":[[136,4]]},"65":{"position":[[75,5]]}}}],["0.65",{"_index":3709,"t":{"1174":{"position":[[71,5]]}}}],["0.6m",{"_index":1651,"t":{"484":{"position":[[117,4]]}}}],["0.7128",{"_index":691,"t":{"151":{"position":[[90,7]]}}}],["0.75top",{"_index":1643,"t":{"475":{"position":[[406,7]]}}}],["0.7\\tau",{"_index":1263,"t":{"398":{"position":[[354,9]]}}}],["0.7τ=0.7",{"_index":1264,"t":{"398":{"position":[[366,8]]}}}],["0.8",{"_index":2437,"t":{"784":{"position":[[799,3]]},"825":{"position":[[832,3]]}}}],["0.85",{"_index":3692,"t":{"1165":{"position":[[593,4]]}}}],["0.9",{"_index":287,"t":{"53":{"position":[[139,3],[150,3]]},"80":{"position":[[44,3]]},"1188":{"position":[[296,4]]},"1216":{"position":[[590,4]]}}}],["0.97",{"_index":296,"t":{"53":{"position":[[236,4]]}}}],["0.99",{"_index":290,"t":{"53":{"position":[[165,4]]}}}],["0.9999",{"_index":302,"t":{"53":{"position":[[290,6]]}}}],["0.999β2​=0.999",{"_index":526,"t":{"106":{"position":[[81,14]]}}}],["0.9β1​=0.9",{"_index":524,"t":{"106":{"position":[[50,10]]}}}],["000",{"_index":1485,"t":{"441":{"position":[[190,3]]}}}],["02",{"_index":3089,"t":{"1030":{"position":[[27,2],[57,2]]}}}],["05",{"_index":62,"t":{"9":{"position":[[239,2],[261,2]]}}}],["0<β1,β2<1.0",{"_index":3646,"t":{"1152":{"position":[[2060,11]]}}}],["0\\eta",{"_index":3579,"t":{"1148":{"position":[[1570,7]]}}}],["0\\gamma",{"_index":3563,"t":{"1148":{"position":[[1072,9]]}}}],["0\\phi_0ϕ0",{"_index":1764,"t":{"553":{"position":[[353,11]]}}}],["0\\tau_0τ0",{"_index":2670,"t":{"863":{"position":[[46,11]]}}}],["0\\triangl",{"_index":3485,"t":{"1142":{"position":[[540,12]]}}}],["0}γ=0",{"_index":3726,"t":{"1190":{"position":[[285,6]]}}}],["0γ>0",{"_index":3564,"t":{"1148":{"position":[[1084,4]]}}}],["0η>0",{"_index":3580,"t":{"1148":{"position":[[1580,4]]}}}],["0​,r0",{"_index":2678,"t":{"863":{"position":[[343,11]]}}}],["0∣|\\phi_0|∣ϕ0",{"_index":1776,"t":{"553":{"position":[[790,17]]}}}],["0∣|\\theta",{"_index":1777,"t":{"553":{"position":[[1047,17]]}}}],["0△=0",{"_index":3486,"t":{"1142":{"position":[[555,4]]}}}],["1",{"_index":214,"t":{"33":{"position":[[320,1]]},"38":{"position":[[210,3]]},"40":{"position":[[162,1]]},"49":{"position":[[281,1],[723,2],[804,2]]},"58":{"position":[[227,2]]},"78":{"position":[[827,2],[881,1]]},"91":{"position":[[535,2],[1073,1],[1108,1],[1505,3],[1752,2],[1970,3],[2028,4],[2046,4],[2061,1],[2098,3],[2355,1]]},"95":{"position":[[122,2],[356,2]]},"104":{"position":[[6,1]]},"130":{"position":[[1199,4],[1225,4]]},"132":{"position":[[846,4]]},"138":{"position":[[232,1]]},"149":{"position":[[461,1]]},"155":{"position":[[6,1]]},"231":{"position":[[205,1]]},"238":{"position":[[4,1]]},"240":{"position":[[140,1]]},"360":{"position":[[486,1]]},"362":{"position":[[851,2]]},"425":{"position":[[590,2]]},"427":{"position":[[2280,2]]},"437":{"position":[[677,1]]},"441":{"position":[[187,2]]},"455":{"position":[[222,3]]},"457":{"position":[[601,1],[844,3]]},"479":{"position":[[6,1],[122,1]]},"498":{"position":[[33,4]]},"515":{"position":[[776,1]]},"521":{"position":[[148,1]]},"533":{"position":[[112,1]]},"549":{"position":[[894,1]]},"557":{"position":[[391,3],[506,1]]},"600":{"position":[[54,3]]},"604":{"position":[[861,1],[1114,1]]},"616":{"position":[[716,2]]},"635":{"position":[[802,1]]},"637":{"position":[[461,1]]},"639":{"position":[[74,2]]},"651":{"position":[[6,1],[74,1]]},"694":{"position":[[550,1]]},"736":{"position":[[218,1]]},"761":{"position":[[1219,1],[1373,1]]},"768":{"position":[[414,1]]},"775":{"position":[[369,1]]},"780":{"position":[[116,1],[242,2]]},"784":{"position":[[639,1]]},"807":{"position":[[0,1]]},"817":{"position":[[1745,2]]},"827":{"position":[[336,1],[584,1]]},"838":{"position":[[474,1]]},"850":{"position":[[615,1]]},"863":{"position":[[707,1]]},"891":{"position":[[162,1]]},"969":{"position":[[549,1]]},"1001":{"position":[[343,1]]},"1030":{"position":[[175,1]]},"1092":{"position":[[940,1]]},"1096":{"position":[[2128,2],[2140,3]]},"1099":{"position":[[481,1]]},"1104":{"position":[[116,2]]},"1137":{"position":[[779,2],[2536,1]]},"1148":{"position":[[1149,2],[2280,1]]},"1152":{"position":[[1765,2],[1864,2]]},"1158":{"position":[[403,1]]},"1165":{"position":[[676,1]]},"1172":{"position":[[262,2]]},"1203":{"position":[[249,1]]},"1216":{"position":[[21,2],[743,2]]},"1218":{"position":[[298,1]]},"1240":{"position":[[22,1]]}}}],["1(a",{"_index":988,"t":{"288":{"position":[[14,4]]}}}],["1(b",{"_index":990,"t":{"290":{"position":[[110,4]]}}}],["1)(m+1",{"_index":1548,"t":{"463":{"position":[[272,7]]}}}],["1)fp2v​,fv2p​=bi",{"_index":3318,"t":{"1094":{"position":[[617,17]]}}}],["1)}(w_{ij",{"_index":3639,"t":{"1152":{"position":[[1751,11],[1850,11]]}}}],["1)}vc​∈rd×(l+1",{"_index":3797,"t":{"1222":{"position":[[414,15]]}}}],["1,000",{"_index":1459,"t":{"431":{"position":[[488,5]]},"441":{"position":[[124,5]]},"451":{"position":[[518,6]]}}}],["1,1",{"_index":536,"t":{"108":{"position":[[67,3]]}}}],["1,100",{"_index":1056,"t":{"309":{"position":[[82,5]]}}}],["1,1}k",{"_index":535,"t":{"108":{"position":[[56,9]]}}}],["1,2,4,8",{"_index":3700,"t":{"1172":{"position":[[250,11]]}}}],["1,5,20,100,150",{"_index":2553,"t":{"830":{"position":[[37,18]]}}}],["1,5,20,100,150}\\{1",{"_index":2551,"t":{"830":{"position":[[0,20]]}}}],["1,836",{"_index":1214,"t":{"373":{"position":[[208,5]]},"402":{"position":[[167,5]]}}}],["1,\\dot",{"_index":3538,"t":{"1148":{"position":[[320,8]]}}}],["1,xkeypoint",{"_index":610,"t":{"130":{"position":[[1136,11]]}}}],["1,ykeypoint",{"_index":611,"t":{"130":{"position":[[1148,11]]}}}],["1.0",{"_index":688,"t":{"149":{"position":[[454,3]]},"1065":{"position":[[18,3],[71,3],[129,3],[194,3],[245,3]]}}}],["1.0/hello.md",{"_index":3221,"t":{"1069":{"position":[[89,12]]}}}],["1.0<β1​,β2​<1",{"_index":3647,"t":{"1152":{"position":[[2093,14]]}}}],["1.1",{"_index":2121,"t":{"662":{"position":[[476,4]]}}}],["1.10",{"_index":3714,"t":{"1181":{"position":[[100,5]]}}}],["1.1e1211e9×103=1.1e12",{"_index":1476,"t":{"439":{"position":[[153,21]]}}}],["1.2",{"_index":2438,"t":{"784":{"position":[[868,5]]},"1137":{"position":[[4698,4]]}}}],["1.25",{"_index":2436,"t":{"784":{"position":[[565,4]]}}}],["1.28m",{"_index":280,"t":{"53":{"position":[[0,5]]}}}],["1.2m",{"_index":1511,"t":{"455":{"position":[[175,4]]},"457":{"position":[[617,4],[668,4]]},"479":{"position":[[93,4]]},"484":{"position":[[85,4]]},"498":{"position":[[16,4]]},"508":{"position":[[100,4]]}}}],["1.2tb",{"_index":1824,"t":{"571":{"position":[[186,5]]}}}],["1.3",{"_index":682,"t":{"147":{"position":[[453,3]]}}}],["1.3b",{"_index":892,"t":{"242":{"position":[[24,5]]},"987":{"position":[[341,4]]},"989":{"position":[[526,5]]}}}],["1.3m",{"_index":491,"t":{"102":{"position":[[38,5]]}}}],["1.4e152×175e9×(41×98+103)=1.4e15",{"_index":1478,"t":{"439":{"position":[[273,32]]}}}],["1.5",{"_index":340,"t":{"65":{"position":[[93,4]]},"1154":{"position":[[388,5]]},"1165":{"position":[[421,5]]}}}],["1.6",{"_index":1503,"t":{"449":{"position":[[162,4]]}}}],["1.77",{"_index":1661,"t":{"496":{"position":[[43,6]]}}}],["1.8",{"_index":3697,"t":{"1167":{"position":[[214,4]]}}}],["1.8k",{"_index":1199,"t":{"368":{"position":[[286,7]]},"412":{"position":[[68,4]]}}}],["1/2/l",{"_index":3711,"t":{"1179":{"position":[[113,5]]}}}],["10",{"_index":326,"t":{"63":{"position":[[33,3]]},"259":{"position":[[105,3]]},"318":{"position":[[48,2]]},"339":{"position":[[179,3]]},"362":{"position":[[912,2]]},"377":{"position":[[92,2]]},"382":{"position":[[277,2]]},"398":{"position":[[742,3]]},"533":{"position":[[450,4]]},"648":{"position":[[440,3]]},"698":{"position":[[1543,2]]},"784":{"position":[[287,2],[324,4],[352,2],[684,3],[894,2]]},"791":{"position":[[216,4]]},"796":{"position":[[127,3]]},"804":{"position":[[114,5],[233,3]]},"825":{"position":[[266,2]]},"834":{"position":[[593,3]]},"963":{"position":[[996,4],[1224,4]]},"1085":{"position":[[771,2]]},"1087":{"position":[[25,4],[1343,2],[2499,2],[2833,2]]},"1129":{"position":[[9,3]]},"1131":{"position":[[41,2]]},"1165":{"position":[[654,4],[667,4],[680,4],[693,4]]},"1172":{"position":[[456,4]]},"1200":{"position":[[1896,2]]}}}],["10,000",{"_index":334,"t":{"63":{"position":[[164,6]]},"362":{"position":[[534,8]]},"418":{"position":[[2168,7]]},"443":{"position":[[309,6],[454,8]]},"547":{"position":[[291,7]]},"571":{"position":[[272,7]]}}}],["10/100",{"_index":497,"t":{"102":{"position":[[183,6]]}}}],["100",{"_index":327,"t":{"63":{"position":[[43,4]]},"65":{"position":[[20,3]]},"143":{"position":[[536,3]]},"269":{"position":[[301,4]]},"304":{"position":[[732,3]]},"311":{"position":[[255,3]]},"644":{"position":[[106,5]]},"651":{"position":[[157,3]]},"732":{"position":[[201,5]]},"787":{"position":[[339,6]]},"791":{"position":[[549,5],[601,5]]},"825":{"position":[[214,3]]},"830":{"position":[[28,4]]},"842":{"position":[[824,4],[892,5],[950,4],[1565,4]]},"905":{"position":[[321,3]]},"909":{"position":[[147,3]]},"943":{"position":[[325,4]]},"963":{"position":[[3215,4]]},"987":{"position":[[333,4]]},"1104":{"position":[[345,3]]}}}],["100,000",{"_index":314,"t":{"58":{"position":[[60,8]]},"362":{"position":[[606,9]]},"429":{"position":[[376,7]]}}}],["1000",{"_index":282,"t":{"53":{"position":[[23,4]]},"267":{"position":[[124,5]]}}}],["100b",{"_index":906,"t":{"244":{"position":[[49,4]]},"396":{"position":[[473,4]]}}}],["100k",{"_index":2094,"t":{"642":{"position":[[11,4]]},"823":{"position":[[1893,4]]},"825":{"position":[[161,4]]},"834":{"position":[[470,4]]}}}],["100l=100",{"_index":2127,"t":{"666":{"position":[[18,8]]}}}],["100m",{"_index":2301,"t":{"723":{"position":[[110,5]]}}}],["100△t​=100",{"_index":3673,"t":{"1158":{"position":[[464,11]]}}}],["101",{"_index":2885,"t":{"951":{"position":[[162,4]]},"1218":{"position":[[50,4]]},"1230":{"position":[[158,4]]}}}],["102",{"_index":2949,"t":{"963":{"position":[[3115,4]]}}}],["1024",{"_index":1186,"t":{"362":{"position":[[854,5]]}}}],["1024d1​=d2​=1024",{"_index":3431,"t":{"1137":{"position":[[2070,16]]}}}],["1024x1024",{"_index":674,"t":{"143":{"position":[[713,9]]},"147":{"position":[[474,9]]}}}],["103",{"_index":1471,"t":{"437":{"position":[[928,3]]},"439":{"position":[[147,3],[266,4]]},"441":{"position":[[87,3],[200,3]]},"901":{"position":[[1694,3]]},"917":{"position":[[875,3]]},"943":{"position":[[368,3],[408,4]]}}}],["10341×98+103",{"_index":1474,"t":{"437":{"position":[[1095,12]]}}}],["105",{"_index":2790,"t":{"905":{"position":[[410,3]]},"909":{"position":[[195,3]]},"955":{"position":[[121,3]]}}}],["107",{"_index":2886,"t":{"951":{"position":[[167,4]]}}}],["107,394",{"_index":1052,"t":{"309":{"position":[[26,7]]}}}],["109",{"_index":2951,"t":{"963":{"position":[[3180,4]]}}}],["10b",{"_index":2288,"t":{"713":{"position":[[916,3],[1462,3]]},"718":{"position":[[821,3]]},"723":{"position":[[26,3]]},"742":{"position":[[133,3]]},"746":{"position":[[208,4],[283,3]]},"755":{"position":[[56,3]]}}}],["10k",{"_index":1224,"t":{"379":{"position":[[389,3]]},"1099":{"position":[[1236,4]]}}}],["10px",{"_index":3197,"t":{"1061":{"position":[[239,7]]}}}],["11",{"_index":308,"t":{"55":{"position":[[76,3]]},"76":{"position":[[221,3]]},"447":{"position":[[120,2]]},"533":{"position":[[363,2]]},"850":{"position":[[1868,3]]},"963":{"position":[[707,4]]},"1152":{"position":[[2718,3]]},"1238":{"position":[[0,2]]},"1240":{"position":[[0,2]]}}}],["110",{"_index":2892,"t":{"951":{"position":[[617,3]]}}}],["112",{"_index":2933,"t":{"963":{"position":[[1883,6]]}}}],["113",{"_index":2966,"t":{"977":{"position":[[265,3]]}}}],["114",{"_index":2952,"t":{"963":{"position":[[3185,3]]},"977":{"position":[[351,3]]}}}],["115",{"_index":2818,"t":{"911":{"position":[[624,3]]},"947":{"position":[[325,4]]}}}],["116",{"_index":2877,"t":{"943":{"position":[[586,3]]}}}],["117",{"_index":2817,"t":{"911":{"position":[[619,4]]},"917":{"position":[[573,3],[915,4],[1126,4]]},"937":{"position":[[211,4]]},"947":{"position":[[330,4],[559,5]]},"959":{"position":[[795,3]]},"975":{"position":[[133,3]]}}}],["118",{"_index":2835,"t":{"917":{"position":[[1131,4],[1553,5]]},"937":{"position":[[216,3]]},"955":{"position":[[293,3]]},"975":{"position":[[122,4]]}}}],["118k",{"_index":652,"t":{"143":{"position":[[0,4]]}}}],["11b",{"_index":1205,"t":{"368":{"position":[[503,3],[512,3]]},"423":{"position":[[531,3]]},"433":{"position":[[37,5]]},"441":{"position":[[59,3]]},"696":{"position":[[1292,3]]},"827":{"position":[[407,5]]},"1137":{"position":[[78,4]]}}}],["11e9",{"_index":1484,"t":{"441":{"position":[[180,4]]}}}],["11e9×103=1.1e1211e9",{"_index":1475,"t":{"439":{"position":[[120,19]]}}}],["11m",{"_index":806,"t":{"186":{"position":[[156,3]]}}}],["12",{"_index":680,"t":{"147":{"position":[[266,3]]},"149":{"position":[[498,3]]},"672":{"position":[[53,4],[180,2]]},"963":{"position":[[1586,4]]}}}],["12,288",{"_index":1739,"t":{"549":{"position":[[750,6]]}}}],["12.5",{"_index":2579,"t":{"838":{"position":[[576,5]]}}}],["12.7m",{"_index":807,"t":{"186":{"position":[[169,5]]}}}],["120",{"_index":2834,"t":{"917":{"position":[[920,3],[1136,3]]},"947":{"position":[[565,4]]},"975":{"position":[[127,3]]}}}],["121",{"_index":2900,"t":{"959":{"position":[[220,3]]}}}],["123",{"_index":2929,"t":{"963":{"position":[[1760,5]]}}}],["124",{"_index":2880,"t":{"945":{"position":[[64,3]]}}}],["125",{"_index":2871,"t":{"943":{"position":[[330,4]]},"969":{"position":[[877,4]]}}}],["125m",{"_index":1862,"t":{"589":{"position":[[85,6]]}}}],["128",{"_index":665,"t":{"143":{"position":[[500,3]]},"147":{"position":[[17,3]]},"174":{"position":[[329,3]]},"362":{"position":[[978,4]]},"589":{"position":[[140,3]]}}}],["129",{"_index":2943,"t":{"963":{"position":[[2831,5]]}}}],["12m",{"_index":804,"t":{"186":{"position":[[87,3]]}}}],["13",{"_index":1462,"t":{"435":{"position":[[224,2]]},"911":{"position":[[1266,2]]},"949":{"position":[[92,2]]},"969":{"position":[[468,2]]}}}],["130",{"_index":2944,"t":{"963":{"position":[[2844,5]]}}}],["131",{"_index":2875,"t":{"943":{"position":[[537,4],[556,3]]}}}],["132m",{"_index":661,"t":{"143":{"position":[[342,4]]}}}],["134",{"_index":2889,"t":{"951":{"position":[[376,3]]}}}],["135",{"_index":2776,"t":{"901":{"position":[[1196,3]]},"961":{"position":[[0,3]]}}}],["136",{"_index":2920,"t":{"963":{"position":[[1001,4]]}}}],["137b",{"_index":900,"t":{"242":{"position":[[68,5]]},"244":{"position":[[424,4]]},"254":{"position":[[232,4]]}}}],["139",{"_index":2891,"t":{"951":{"position":[[612,4]]}}}],["13b",{"_index":1072,"t":{"318":{"position":[[335,6]]}}}],["13k",{"_index":3003,"t":{"995":{"position":[[451,5]]}}}],["13m",{"_index":313,"t":{"58":{"position":[[26,3]]},"165":{"position":[[816,3]]}}}],["14",{"_index":554,"t":{"114":{"position":[[109,2],[148,2],[233,2],[324,2]]},"780":{"position":[[134,2]]},"963":{"position":[[1806,4]]}}}],["14.9",{"_index":1204,"t":{"368":{"position":[[411,5]]}}}],["140",{"_index":832,"t":{"195":{"position":[[131,4]]},"1119":{"position":[[95,3]]}}}],["141",{"_index":2962,"t":{"977":{"position":[[57,3]]}}}],["142",{"_index":2924,"t":{"963":{"position":[[1572,4]]}}}],["144",{"_index":2788,"t":{"905":{"position":[[295,5]]},"909":{"position":[[404,3]]},"947":{"position":[[108,3]]},"1172":{"position":[[358,4]]}}}],["144,288,576}\\{144",{"_index":3686,"t":{"1165":{"position":[[319,19]]}}}],["145",{"_index":2849,"t":{"919":{"position":[[710,3]]}}}],["146",{"_index":2946,"t":{"963":{"position":[[2879,4]]}}}],["147",{"_index":2898,"t":{"957":{"position":[[0,3]]}}}],["149",{"_index":2945,"t":{"963":{"position":[[2850,4]]}}}],["14m",{"_index":381,"t":{"86":{"position":[[443,8]]},"102":{"position":[[65,4]]},"502":{"position":[[852,3]]}}}],["15",{"_index":1106,"t":{"337":{"position":[[16,3]]},"491":{"position":[[155,2]]},"1179":{"position":[[133,2]]}}}],["15.5",{"_index":1241,"t":{"386":{"position":[[186,5]]}}}],["150",{"_index":2552,"t":{"830":{"position":[[33,3]]},"1111":{"position":[[189,4]]}}}],["151",{"_index":2968,"t":{"983":{"position":[[214,3]]}}}],["151m",{"_index":1176,"t":{"362":{"position":[[324,5]]}}}],["152",{"_index":2778,"t":{"901":{"position":[[1523,3]]},"943":{"position":[[372,4]]}}}],["154",{"_index":2934,"t":{"963":{"position":[[1907,5]]}}}],["155",{"_index":2805,"t":{"909":{"position":[[679,3]]}}}],["1554",{"_index":1213,"t":{"373":{"position":[[182,5]]}}}],["16",{"_index":1177,"t":{"362":{"position":[[407,4]]},"418":{"position":[[2239,4]]},"429":{"position":[[360,2]]},"435":{"position":[[284,3]]},"653":{"position":[[32,3]]},"698":{"position":[[1422,3]]},"817":{"position":[[967,3]]},"827":{"position":[[669,4]]},"1001":{"position":[[242,2]]},"1104":{"position":[[340,2]]},"1158":{"position":[[299,2]]},"1165":{"position":[[192,3]]},"1172":{"position":[[198,3],[408,2]]},"1222":{"position":[[258,2]]},"1232":{"position":[[258,2]]},"1234":{"position":[[106,2]]}}}],["16.14",{"_index":90,"t":{"15":{"position":[[16,5]]}}}],["16.3",{"_index":1935,"t":{"616":{"position":[[1342,5]]}}}],["160",{"_index":1261,"t":{"398":{"position":[[257,4]]}}}],["1616×16",{"_index":3274,"t":{"1092":{"position":[[1222,8]]}}}],["1641×98×32bits=16kb",{"_index":1493,"t":{"443":{"position":[[236,19]]}}}],["16b",{"_index":1170,"t":{"362":{"position":[[108,3],[145,3],[293,3],[1168,4],[1243,3]]}}}],["16k=16",{"_index":3781,"t":{"1216":{"position":[[885,6]]}}}],["16l=16",{"_index":3817,"t":{"1234":{"position":[[87,6]]}}}],["16x16",{"_index":515,"t":{"104":{"position":[[115,5]]}}}],["16×1616",{"_index":3273,"t":{"1092":{"position":[[1207,7]]}}}],["17",{"_index":2319,"t":{"753":{"position":[[316,2]]},"789":{"position":[[315,3]]},"901":{"position":[[319,2]]},"905":{"position":[[347,2]]},"909":{"position":[[530,2]]},"923":{"position":[[334,2]]},"949":{"position":[[692,2]]}}}],["17.7",{"_index":1069,"t":{"316":{"position":[[71,5]]}}}],["175",{"_index":1634,"t":{"475":{"position":[[51,3]]}}}],["175b",{"_index":894,"t":{"242":{"position":[[36,5]]},"318":{"position":[[25,4]]},"324":{"position":[[57,4]]},"435":{"position":[[229,4],[302,4]]},"439":{"position":[[194,4]]},"441":{"position":[[274,4],[352,4]]},"547":{"position":[[6,4],[248,4]]},"549":{"position":[[698,4]]},"571":{"position":[[170,4],[341,4]]},"595":{"position":[[6,4]]},"600":{"position":[[43,4]]},"761":{"position":[[273,4]]},"817":{"position":[[909,4]]},"827":{"position":[[712,4]]},"987":{"position":[[319,4]]},"989":{"position":[[536,4]]},"1001":{"position":[[565,4],[2143,4]]},"1013":{"position":[[303,5],[315,4]]},"1137":{"position":[[89,4]]}}}],["18",{"_index":3744,"t":{"1203":{"position":[[107,4]]}}}],["183m",{"_index":3680,"t":{"1165":{"position":[[17,4]]}}}],["18k",{"_index":492,"t":{"102":{"position":[[82,3]]}}}],["18m",{"_index":1873,"t":{"600":{"position":[[108,3]]}}}],["19",{"_index":503,"t":{"102":{"position":[[227,2]]},"850":{"position":[[2157,4]]},"899":{"position":[[1029,2]]}}}],["190",{"_index":1256,"t":{"398":{"position":[[0,4],[622,4]]}}}],["193",{"_index":1211,"t":{"373":{"position":[[164,4]]}}}],["1=0.9\\beta_1",{"_index":523,"t":{"106":{"position":[[34,13]]}}}],["1\\beta_1β1",{"_index":3691,"t":{"1165":{"position":[[549,12]]}}}],["1\\leq",{"_index":1369,"t":{"425":{"position":[[1338,6]]},"1184":{"position":[[284,7]]}}}],["1a",{"_index":3432,"t":{"1137":{"position":[[2639,2]]},"1200":{"position":[[215,2]]}}}],["1b",{"_index":2302,"t":{"723":{"position":[[118,3]]},"836":{"position":[[179,2]]},"1137":{"position":[[2732,2]]},"1200":{"position":[[546,4]]}}}],["1c",{"_index":3738,"t":{"1200":{"position":[[942,4]]}}}],["1c=1",{"_index":757,"t":{"171":{"position":[[639,5]]}}}],["1d",{"_index":400,"t":{"91":{"position":[[43,2],[1251,2]]},"116":{"position":[[211,2]]}}}],["1e",{"_index":292,"t":{"53":{"position":[[190,2]]},"80":{"position":[[16,2],[25,2]]},"694":{"position":[[1068,2]]},"698":{"position":[[1389,2]]},"825":{"position":[[814,2]]},"1236":{"position":[[108,2]]}}}],["1e−41",{"_index":666,"t":{"143":{"position":[[515,8]]}}}],["1k",{"_index":490,"t":{"102":{"position":[[35,2]]},"143":{"position":[[587,2]]},"457":{"position":[[1335,2]]},"469":{"position":[[184,2]]},"494":{"position":[[90,2]]}}}],["1r=1",{"_index":1913,"t":{"604":{"position":[[1193,4]]}}}],["1x1",{"_index":479,"t":{"95":{"position":[[180,3]]},"104":{"position":[[407,5]]}}}],["1})p(yj​∣x,y1:j−1",{"_index":643,"t":{"140":{"position":[[77,19]]}}}],["1}slm+1​∈r(m+1)×1",{"_index":1589,"t":{"463":{"position":[[1424,17]]}}}],["1}y={yi​}i=1n",{"_index":980,"t":{"286":{"position":[[203,14]]}}}],["1}zϱ−1",{"_index":468,"t":{"91":{"position":[[2228,7]]}}}],["1×10−31",{"_index":3704,"t":{"1172":{"position":[[441,7]]}}}],["1​,xkeypoint",{"_index":616,"t":{"130":{"position":[[1300,12]]}}}],["1​,ykeypoint",{"_index":617,"t":{"130":{"position":[[1313,12]]}}}],["1≤1",{"_index":1370,"t":{"425":{"position":[[1345,3]]},"1184":{"position":[[292,5]]}}}],["1≤c≤c1",{"_index":3794,"t":{"1222":{"position":[[317,7]]}}}],["1≤i≤641",{"_index":1893,"t":{"604":{"position":[[335,8]]}}}],["1≤i≤81",{"_index":1890,"t":{"604":{"position":[[235,7]]}}}],["2",{"_index":185,"t":{"25":{"position":[[756,2]]},"91":{"position":[[1942,3]]},"130":{"position":[[1172,3],[1251,4],[1277,4],[1339,5]]},"138":{"position":[[236,1]]},"153":{"position":[[29,1]]},"157":{"position":[[414,1]]},"163":{"position":[[313,2]]},"188":{"position":[[176,1]]},"244":{"position":[[472,3]]},"269":{"position":[[177,2]]},"302":{"position":[[174,1]]},"349":{"position":[[167,2]]},"362":{"position":[[1089,1]]},"370":{"position":[[4,1]]},"425":{"position":[[1867,1]]},"427":{"position":[[2222,1],[3746,1]]},"447":{"position":[[377,1]]},"475":{"position":[[152,1]]},"484":{"position":[[209,1]]},"489":{"position":[[152,1]]},"521":{"position":[[180,1]]},"547":{"position":[[344,1]]},"573":{"position":[[23,1]]},"585":{"position":[[521,2],[569,1]]},"587":{"position":[[178,1]]},"593":{"position":[[52,1]]},"595":{"position":[[72,1]]},"600":{"position":[[143,3]]},"633":{"position":[[1553,3]]},"635":{"position":[[62,1]]},"639":{"position":[[77,2]]},"642":{"position":[[83,1],[229,1],[311,2]]},"651":{"position":[[132,1]]},"696":{"position":[[809,1]]},"704":{"position":[[96,1]]},"718":{"position":[[659,1]]},"727":{"position":[[99,1],[296,1]]},"746":{"position":[[6,1]]},"751":{"position":[[265,2]]},"759":{"position":[[494,1]]},"761":{"position":[[245,1],[566,1]]},"764":{"position":[[73,1]]},"766":{"position":[[17,2],[132,1]]},"768":{"position":[[263,1]]},"775":{"position":[[242,1],[927,1]]},"780":{"position":[[251,1]]},"782":{"position":[[96,1]]},"784":{"position":[[23,1],[38,1]]},"787":{"position":[[261,1],[621,1],[684,1]]},"789":{"position":[[8,2]]},"791":{"position":[[175,3]]},"793":{"position":[[524,1],[643,1]]},"817":{"position":[[1853,2],[2048,1]]},"827":{"position":[[458,2]]},"836":{"position":[[628,1],[2250,1]]},"838":{"position":[[990,1]]},"840":{"position":[[495,1]]},"885":{"position":[[378,2]]},"1065":{"position":[[182,1]]},"1104":{"position":[[119,1]]},"1163":{"position":[[82,1]]},"1165":{"position":[[689,1]]},"1172":{"position":[[265,2]]},"1184":{"position":[[5,1]]},"1186":{"position":[[210,2]]},"1190":{"position":[[357,1]]},"1211":{"position":[[7,1]]},"1216":{"position":[[26,1],[746,1]]},"1218":{"position":[[522,1]]},"1222":{"position":[[628,1]]}}}],["2(4",{"_index":2058,"t":{"633":{"position":[[1618,5]]}}}],["2(4)\\mathcal{l}_{hidden",{"_index":2053,"t":{"633":{"position":[[1424,25]]}}}],["2)lstage1​=lretrieve​+lbox​+lmaskboxinst​(2",{"_index":3352,"t":{"1099":{"position":[[408,45]]}}}],["2,4,8}\\{2",{"_index":3684,"t":{"1165":{"position":[[244,11]]}}}],["2,k][2",{"_index":2073,"t":{"635":{"position":[[417,8]]}}}],["2,xkeypoint",{"_index":612,"t":{"130":{"position":[[1160,11]]}}}],["2.0",{"_index":2315,"t":{"748":{"position":[[186,3],[221,3]]}}}],["2.00",{"_index":1660,"t":{"496":{"position":[[35,7]]}}}],["2.1",{"_index":1480,"t":{"439":{"position":[[325,3]]}}}],["2.2",{"_index":206,"t":{"31":{"position":[[166,4]]}}}],["2.20",{"_index":3715,"t":{"1181":{"position":[[108,5]]}}}],["2.4",{"_index":297,"t":{"53":{"position":[[247,3]]}}}],["2.5",{"_index":322,"t":{"60":{"position":[[40,4]]},"449":{"position":[[249,4]]}}}],["2.6",{"_index":2439,"t":{"784":{"position":[[919,5]]}}}],["2.7e163×11e9×1,000×8×103=2.7e16",{"_index":1486,"t":{"441":{"position":[[206,31]]}}}],["2.8",{"_index":309,"t":{"55":{"position":[[123,4]]},"1127":{"position":[[97,3]]}}}],["2.9",{"_index":2444,"t":{"791":{"position":[[308,3]]}}}],["2/3",{"_index":1822,"t":{"571":{"position":[[148,3]]}}}],["20",{"_index":686,"t":{"149":{"position":[[260,4]]},"165":{"position":[[770,3]]},"279":{"position":[[615,3]]},"328":{"position":[[708,4]]},"330":{"position":[[1561,3]]},"398":{"position":[[112,3],[564,2]]},"441":{"position":[[314,3],[378,2]]},"531":{"position":[[137,4]]},"678":{"position":[[269,5]]},"698":{"position":[[1469,2]]},"732":{"position":[[142,3]]},"804":{"position":[[120,4],[161,3]]},"830":{"position":[[24,3],[254,2]]},"842":{"position":[[1899,3]]},"850":{"position":[[1828,4]]},"1085":{"position":[[803,2]]},"1087":{"position":[[2556,2],[2868,2]]},"1131":{"position":[[114,2]]}}}],["200",{"_index":2445,"t":{"791":{"position":[[555,4],[607,4]]},"796":{"position":[[106,4]]}}}],["2000",{"_index":1163,"t":{"360":{"position":[[166,4]]}}}],["2012",{"_index":489,"t":{"102":{"position":[[21,4]]}}}],["2015",{"_index":2998,"t":{"989":{"position":[[927,4]]}}}],["2017",{"_index":656,"t":{"143":{"position":[[39,4]]},"1113":{"position":[[12,4],[55,4]]}}}],["2017~2019",{"_index":2702,"t":{"876":{"position":[[322,9]]}}}],["2018",{"_index":3387,"t":{"1113":{"position":[[31,4],[195,4]]}}}],["2019",{"_index":61,"t":{"9":{"position":[[234,4],[256,4]]},"362":{"position":[[1050,6]]},"838":{"position":[[328,4]]},"1123":{"position":[[96,5]]}}}],["2020",{"_index":1192,"t":{"362":{"position":[[1107,6]]}}}],["2021",{"_index":2704,"t":{"876":{"position":[[743,4]]}}}],["2022",{"_index":1117,"t":{"343":{"position":[[149,6]]}}}],["2022b",{"_index":1148,"t":{"349":{"position":[[197,6],[321,6]]}}}],["2023",{"_index":948,"t":{"277":{"position":[[53,4]]}}}],["2048",{"_index":1047,"t":{"304":{"position":[[627,6]]},"362":{"position":[[703,5]]},"761":{"position":[[861,5]]}}}],["20b",{"_index":903,"t":{"242":{"position":[[99,5]]}}}],["20k",{"_index":1252,"t":{"396":{"position":[[265,3]]},"1107":{"position":[[52,4]]}}}],["20k′=20",{"_index":1059,"t":{"311":{"position":[[225,7]]}}}],["20px",{"_index":3194,"t":{"1061":{"position":[[207,7]]}}}],["21,841",{"_index":312,"t":{"58":{"position":[[14,6]]}}}],["21.5≈6.91/0.3221.5",{"_index":1924,"t":{"608":{"position":[[666,18]]}}}],["214,354",{"_index":1051,"t":{"309":{"position":[[8,7]]}}}],["21k",{"_index":396,"t":{"88":{"position":[[567,3]]},"102":{"position":[[61,3]]},"112":{"position":[[22,4]]},"494":{"position":[[35,3]]}}}],["22",{"_index":2637,"t":{"850":{"position":[[1794,4]]}}}],["22,000",{"_index":2432,"t":{"784":{"position":[[431,7]]}}}],["220",{"_index":2550,"t":{"827":{"position":[[717,5]]}}}],["220m",{"_index":1167,"t":{"362":{"position":[[49,4]]},"644":{"position":[[43,4]]}}}],["222^222",{"_index":3260,"t":{"1092":{"position":[[726,7]]}}}],["224",{"_index":840,"t":{"199":{"position":[[149,4],[156,4]]}}}],["23",{"_index":1232,"t":{"382":{"position":[[182,2]]},"394":{"position":[[117,4]]},"614":{"position":[[505,3]]},"616":{"position":[[1232,2]]},"642":{"position":[[107,3]]},"955":{"position":[[499,2]]},"963":{"position":[[2371,4],[2874,4]]}}}],["232k",{"_index":1939,"t":{"616":{"position":[[1446,5]]}}}],["24",{"_index":2320,"t":{"753":{"position":[[319,2]]}}}],["24.4",{"_index":1081,"t":{"324":{"position":[[80,5]]}}}],["25",{"_index":1830,"t":{"571":{"position":[[351,3]]},"943":{"position":[[483,3],[513,3]]},"951":{"position":[[443,2]]},"989":{"position":[[761,3]]},"1119":{"position":[[66,2]]}}}],["25,000",{"_index":284,"t":{"53":{"position":[[77,6]]}}}],["250k",{"_index":2331,"t":{"761":{"position":[[1563,4]]}}}],["256",{"_index":1123,"t":{"343":{"position":[[517,3]]},"362":{"position":[[941,5]]},"595":{"position":[[135,4]]}}}],["256256×256",{"_index":3262,"t":{"1092":{"position":[[785,10]]}}}],["256×256256",{"_index":3261,"t":{"1092":{"position":[[767,10]]}}}],["26",{"_index":2950,"t":{"963":{"position":[[3175,4]]}}}],["27",{"_index":2928,"t":{"963":{"position":[[1755,4],[2376,3]]}}}],["27.8",{"_index":3042,"t":{"1001":{"position":[[2029,4]]}}}],["28",{"_index":3090,"t":{"1030":{"position":[[30,2],[60,2]]}}}],["280",{"_index":3383,"t":{"1111":{"position":[[184,4]]}}}],["282",{"_index":1242,"t":{"386":{"position":[[237,3]]},"402":{"position":[[156,3]]}}}],["288",{"_index":3687,"t":{"1165":{"position":[[339,4]]},"1172":{"position":[[363,4]]}}}],["29",{"_index":2916,"t":{"963":{"position":[[389,4]]}}}],["29,000",{"_index":2244,"t":{"694":{"position":[[251,6]]}}}],["29k",{"_index":2246,"t":{"694":{"position":[[290,3]]},"696":{"position":[[71,3],[783,3]]}}}],["2:8",{"_index":714,"t":{"155":{"position":[[796,3]]}}}],["2=0.999\\beta_2",{"_index":525,"t":{"106":{"position":[[63,15]]}}}],["2\\beta_2β2",{"_index":2546,"t":{"825":{"position":[[836,12]]},"1165":{"position":[[564,12]]}}}],["2_\\text{f",{"_index":3523,"t":{"1146":{"position":[[988,13],[1032,14]]}}}],["2_f}{\\min",{"_index":1903,"t":{"604":{"position":[[611,12]]}}}],["2b",{"_index":897,"t":{"242":{"position":[[55,3]]},"362":{"position":[[100,3],[137,3],[279,9],[1159,3]]},"746":{"position":[[202,3]]}}}],["2d",{"_index":402,"t":{"91":{"position":[[62,2],[186,2],[1204,2]]},"93":{"position":[[16,2],[136,2],[259,2]]},"97":{"position":[[397,2]]},"116":{"position":[[191,2]]}}}],["2d_v",{"_index":1429,"t":{"427":{"position":[[2137,4]]}}}],["2d_{ff})l(2dk​+2dv​+2dff",{"_index":1430,"t":{"427":{"position":[[2144,26]]}}}],["2e",{"_index":1183,"t":{"362":{"position":[[680,2]]},"698":{"position":[[1395,2]]}}}],["2k",{"_index":1223,"t":{"379":{"position":[[384,2]]},"1111":{"position":[[59,2]]}}}],["2n2n2n",{"_index":1465,"t":{"437":{"position":[[243,6]]}}}],["2x2",{"_index":391,"t":{"88":{"position":[[265,3]]}}}],["2×175e9×(41×98+103)=1.4e152×175e9",{"_index":1477,"t":{"439":{"position":[[220,34]]}}}],["2×l^lora×dmodel×r|\\theta",{"_index":1857,"t":{"587":{"position":[[146,29]]}}}],["2​,xkeypoint",{"_index":618,"t":{"130":{"position":[[1326,12]]}}}],["3",{"_index":158,"t":{"25":{"position":[[5,1]]},"33":{"position":[[322,1]]},"49":{"position":[[429,1]]},"78":{"position":[[830,3]]},"91":{"position":[[2242,3]]},"104":{"position":[[491,1],[541,1]]},"174":{"position":[[105,2],[110,2]]},"190":{"position":[[42,1]]},"223":{"position":[[42,3]]},"227":{"position":[[177,3],[379,1]]},"242":{"position":[[15,1]]},"254":{"position":[[406,1]]},"269":{"position":[[193,2],[254,1]]},"318":{"position":[[46,1]]},"362":{"position":[[1277,2]]},"370":{"position":[[26,1]]},"377":{"position":[[215,2]]},"398":{"position":[[572,1]]},"425":{"position":[[1524,1]]},"435":{"position":[[215,1],[300,1],[350,1]]},"439":{"position":[[192,1],[471,1]]},"441":{"position":[[272,1],[350,1]]},"457":{"position":[[863,2]]},"547":{"position":[[4,1],[246,1],[316,2],[352,1]]},"549":{"position":[[696,1],[1040,2]]},"571":{"position":[[168,1],[339,1]]},"595":{"position":[[4,1],[42,3]]},"600":{"position":[[41,1]]},"604":{"position":[[936,1],[1182,1]]},"631":{"position":[[219,1]]},"633":{"position":[[1105,4]]},"639":{"position":[[96,2]]},"653":{"position":[[120,1]]},"657":{"position":[[0,3]]},"682":{"position":[[4,1],[210,1]]},"694":{"position":[[877,3],[886,2],[894,2],[936,3],[945,2]]},"698":{"position":[[1764,1]]},"704":{"position":[[6,2]]},"711":{"position":[[449,2]]},"713":{"position":[[1664,2]]},"725":{"position":[[230,1]]},"727":{"position":[[409,2]]},"748":{"position":[[6,1]]},"761":{"position":[[269,1],[617,1],[854,1]]},"787":{"position":[[716,1]]},"815":{"position":[[118,1],[270,1]]},"817":{"position":[[444,1],[907,1],[2050,1]]},"819":{"position":[[629,1]]},"823":{"position":[[21,1],[1703,1]]},"827":{"position":[[559,1],[609,1],[664,1],[710,1]]},"834":{"position":[[984,2]]},"840":{"position":[[683,1]]},"850":{"position":[[866,1]]},"863":{"position":[[709,3]]},"881":{"position":[[88,1]]},"883":{"position":[[550,1]]},"889":{"position":[[209,1]]},"933":{"position":[[247,1]]},"975":{"position":[[1039,1]]},"987":{"position":[[175,1],[328,1]]},"989":{"position":[[265,1],[382,1],[510,1],[582,1],[628,1],[668,1],[756,1],[823,1],[943,1]]},"993":{"position":[[89,1]]},"995":{"position":[[177,3]]},"1001":{"position":[[36,1],[50,1],[116,1],[204,1],[2092,1],[2152,1]]},"1006":{"position":[[9,1]]},"1008":{"position":[[20,1],[55,1]]},"1013":{"position":[[360,2]]},"1016":{"position":[[330,1]]},"1036":{"position":[[180,1]]},"1087":{"position":[[1399,1]]},"1090":{"position":[[55,1]]},"1137":{"position":[[87,1]]},"1146":{"position":[[1756,1]]},"1158":{"position":[[345,1]]},"1163":{"position":[[122,1]]},"1190":{"position":[[134,2]]},"1192":{"position":[[5,1]]},"1203":{"position":[[189,1]]},"1216":{"position":[[384,1]]},"1234":{"position":[[67,1]]}}}],["3(a",{"_index":2554,"t":{"830":{"position":[[121,4]]}}}],["3(b",{"_index":2560,"t":{"832":{"position":[[612,4]]}}}],["3(c",{"_index":2561,"t":{"834":{"position":[[5,4],[219,4]]}}}],["3(d",{"_index":2564,"t":{"834":{"position":[[432,4]]}}}],["3)\\mathcal{l}_{logit",{"_index":2034,"t":{"633":{"position":[[827,23]]}}}],["3)lstage2​=lretrieve​+lbox​+lmask​(3",{"_index":3358,"t":{"1099":{"position":[[926,38]]}}}],["3,640",{"_index":3053,"t":{"1013":{"position":[[332,5]]}}}],["3.0",{"_index":2442,"t":{"787":{"position":[[363,6]]}}}],["3.1",{"_index":3719,"t":{"1186":{"position":[[8,3]]}}}],["3.26",{"_index":1659,"t":{"496":{"position":[[27,7]]}}}],["3.5",{"_index":2120,"t":{"662":{"position":[[239,4]]}}}],["3.6",{"_index":323,"t":{"60":{"position":[[56,4]]}}}],["30",{"_index":63,"t":{"9":{"position":[[242,2],[264,2]]},"58":{"position":[[169,4]]},"304":{"position":[[787,2],[853,2]]},"398":{"position":[[313,3]]},"441":{"position":[[481,3]]},"451":{"position":[[570,2]]},"784":{"position":[[609,3]]},"787":{"position":[[155,3]]},"975":{"position":[[516,4]]}}}],["30,000",{"_index":2544,"t":{"825":{"position":[[688,6]]}}}],["300",{"_index":2118,"t":{"651":{"position":[[164,3]]}}}],["300l=300",{"_index":2129,"t":{"666":{"position":[[88,8]]}}}],["300m",{"_index":382,"t":{"86":{"position":[[452,4]]},"88":{"position":[[577,4]]},"112":{"position":[[31,4],[62,4],[247,4]]},"120":{"position":[[146,5]]},"713":{"position":[[1454,4]]},"742":{"position":[[126,4]]},"1137":{"position":[[67,5]]}}}],["302",{"_index":3402,"t":{"1119":{"position":[[89,3]]}}}],["303m",{"_index":493,"t":{"102":{"position":[[86,5]]}}}],["30b",{"_index":1071,"t":{"318":{"position":[[304,3]]}}}],["30m",{"_index":547,"t":{"112":{"position":[[265,4]]}}}],["31",{"_index":1720,"t":{"531":{"position":[[81,2]]},"963":{"position":[[3106,4]]}}}],["31k",{"_index":3005,"t":{"995":{"position":[[566,5]]}}}],["32",{"_index":1490,"t":{"443":{"position":[[183,2],[226,2]]},"531":{"position":[[0,2]]},"595":{"position":[[171,3]]},"616":{"position":[[1572,2]]},"653":{"position":[[36,3]]},"698":{"position":[[504,4],[1426,2]]},"825":{"position":[[732,2]]},"899":{"position":[[714,2]]},"911":{"position":[[956,2]]},"917":{"position":[[1210,2]]},"919":{"position":[[367,3]]},"937":{"position":[[222,2]]},"947":{"position":[[279,4],[320,4]]},"969":{"position":[[872,4]]},"1104":{"position":[[336,3]]},"1158":{"position":[[305,2]]},"1165":{"position":[[196,3]]},"1172":{"position":[[202,3]]},"1179":{"position":[[204,2]]},"1236":{"position":[[59,2]]}}}],["3232×32",{"_index":3272,"t":{"1092":{"position":[[1198,8],[1375,7]]}}}],["32bit",{"_index":817,"t":{"188":{"position":[[356,6]]}}}],["32k",{"_index":669,"t":{"143":{"position":[[571,3]]}}}],["32n=32",{"_index":1639,"t":{"475":{"position":[[224,6]]}}}],["32×3232",{"_index":3271,"t":{"1092":{"position":[[1183,7],[1360,7]]}}}],["33",{"_index":1410,"t":{"427":{"position":[[1514,5]]},"983":{"position":[[48,3]]}}}],["330m",{"_index":2321,"t":{"755":{"position":[[48,5]]}}}],["335m",{"_index":1863,"t":{"589":{"position":[[108,6]]}}}],["33k",{"_index":3004,"t":{"995":{"position":[[505,5]]}}}],["34",{"_index":2937,"t":{"963":{"position":[[1949,4]]}}}],["34,039",{"_index":2242,"t":{"694":{"position":[[76,8]]}}}],["34k",{"_index":2243,"t":{"694":{"position":[[110,4]]},"696":{"position":[[37,3]]}}}],["350",{"_index":293,"t":{"53":{"position":[[208,3]]},"80":{"position":[[6,3]]}}}],["3500",{"_index":2273,"t":{"698":{"position":[[1667,4]]}}}],["350b",{"_index":1825,"t":{"571":{"position":[[195,4]]}}}],["350gb",{"_index":1828,"t":{"571":{"position":[[283,6]]}}}],["350m",{"_index":891,"t":{"242":{"position":[[17,6]]},"362":{"position":[[187,4],[304,4]]}}}],["35k",{"_index":668,"t":{"143":{"position":[[547,3]]}}}],["35mb",{"_index":1829,"t":{"571":{"position":[[292,5]]},"600":{"position":[[115,4]]}}}],["36",{"_index":2756,"t":{"899":{"position":[[810,2]]}}}],["36m",{"_index":1174,"t":{"362":{"position":[[314,4]]}}}],["37",{"_index":2851,"t":{"919":{"position":[[779,2],[864,2],[895,2]]}}}],["38",{"_index":2918,"t":{"963":{"position":[[725,4]]}}}],["3b",{"_index":1253,"t":{"396":{"position":[[563,2]]},"423":{"position":[[526,2],[559,3]]},"427":{"position":[[3064,2]]},"433":{"position":[[18,2]]},"449":{"position":[[20,2]]}}}],["3c=3",{"_index":759,"t":{"171":{"position":[[662,6]]}}}],["3d",{"_index":727,"t":{"165":{"position":[[198,2]]},"1203":{"position":[[632,2]]}}}],["3e",{"_index":2270,"t":{"698":{"position":[[1401,2]]}}}],["3e−3",{"_index":1456,"t":{"431":{"position":[[393,7]]}}}],["3m",{"_index":839,"t":{"199":{"position":[[93,2]]}}}],["3n3n3n",{"_index":1467,"t":{"437":{"position":[[499,6]]}}}],["3x3",{"_index":224,"t":{"38":{"position":[[183,5]]},"40":{"position":[[112,3]]},"78":{"position":[[917,3]]}}}],["3}1×10−3",{"_index":3705,"t":{"1172":{"position":[[461,8]]}}}],["3}e−3",{"_index":1457,"t":{"431":{"position":[[401,5]]}}}],["3~9",{"_index":181,"t":{"25":{"position":[[687,4]]}}}],["3×11e9×1,000×8×103=2.7e163",{"_index":1483,"t":{"441":{"position":[[151,26]]}}}],["4",{"_index":176,"t":{"25":{"position":[[455,2]]},"38":{"position":[[214,2]]},"53":{"position":[[371,5]]},"80":{"position":[[19,1]]},"91":{"position":[[956,2],[2424,3]]},"104":{"position":[[472,1],[511,2]]},"118":{"position":[[191,2]]},"128":{"position":[[117,1]]},"143":{"position":[[71,3]]},"155":{"position":[[191,1]]},"174":{"position":[[233,3]]},"195":{"position":[[4,1]]},"197":{"position":[[291,1]]},"240":{"position":[[222,3]]},"269":{"position":[[198,2]]},"362":{"position":[[683,3]]},"475":{"position":[[474,1]]},"477":{"position":[[4,1],[111,1]]},"502":{"position":[[107,1]]},"504":{"position":[[335,1]]},"521":{"position":[[29,1]]},"529":{"position":[[61,1],[121,1]]},"533":{"position":[[498,1]]},"535":{"position":[[253,1]]},"551":{"position":[[402,1]]},"569":{"position":[[15,1]]},"595":{"position":[[32,1]]},"600":{"position":[[384,1]]},"606":{"position":[[71,1]]},"616":{"position":[[1570,1]]},"639":{"position":[[99,2]]},"642":{"position":[[98,2]]},"653":{"position":[[29,2],[195,1]]},"657":{"position":[[68,1]]},"659":{"position":[[300,1]]},"700":{"position":[[383,4]]},"704":{"position":[[9,1]]},"761":{"position":[[568,2]]},"789":{"position":[[239,2]]},"793":{"position":[[514,1]]},"817":{"position":[[2122,1]]},"825":{"position":[[371,1]]},"836":{"position":[[114,1],[2252,2]]},"848":{"position":[[651,1]]},"889":{"position":[[360,1]]},"1092":{"position":[[877,1]]},"1127":{"position":[[288,1]]},"1148":{"position":[[845,2]]},"1163":{"position":[[156,1]]},"1165":{"position":[[256,2],[685,3],[698,2]]},"1172":{"position":[[192,2],[268,2]]},"1174":{"position":[[0,1]]},"1179":{"position":[[190,1]]},"1181":{"position":[[0,1]]},"1186":{"position":[[190,1]]},"1188":{"position":[[100,1]]},"1190":{"position":[[137,1],[258,2],[335,2]]},"1203":{"position":[[86,1]]},"1216":{"position":[[709,1]]},"1222":{"position":[[1194,1]]},"1224":{"position":[[230,2]]}}}],["4)lstage3​=lretrieve​+lbox​+lmask​+lembed​(4",{"_index":3372,"t":{"1099":{"position":[[1570,46]]}}}],["4,8,16,32,64",{"_index":3699,"t":{"1172":{"position":[[175,16],[209,16]]}}}],["4.1",{"_index":1504,"t":{"449":{"position":[[230,4]]},"787":{"position":[[315,3]]}}}],["4.2",{"_index":2303,"t":{"725":{"position":[[218,3]]},"1240":{"position":[[178,3]]}}}],["4.2mb",{"_index":1488,"t":{"443":{"position":[[100,5],[274,5],[414,6]]}}}],["4.3",{"_index":1332,"t":{"423":{"position":[[964,3]]}}}],["4.4",{"_index":3654,"t":{"1152":{"position":[[2679,3]]}}}],["4.65",{"_index":3717,"t":{"1184":{"position":[[351,6]]}}}],["4.9m",{"_index":1647,"t":{"479":{"position":[[109,4]]}}}],["40",{"_index":2461,"t":{"804":{"position":[[125,4]]},"850":{"position":[[2176,4]]},"901":{"position":[[1839,2]]},"913":{"position":[[61,2]]},"917":{"position":[[1043,4]]},"947":{"position":[[284,3]]},"969":{"position":[[884,2]]},"989":{"position":[[353,4]]},"999":{"position":[[20,4]]},"1119":{"position":[[61,2]]}}}],["40.77",{"_index":1655,"t":{"489":{"position":[[134,6]]}}}],["400~20000",{"_index":2264,"t":{"698":{"position":[[563,9]]}}}],["4096",{"_index":527,"t":{"106":{"position":[[109,4]]}}}],["40g",{"_index":1179,"t":{"362":{"position":[[417,3]]}}}],["41",{"_index":1470,"t":{"437":{"position":[[710,4]]},"439":{"position":[[255,3],[451,3]]},"694":{"position":[[50,4]]},"901":{"position":[[2203,2]]},"921":{"position":[[187,2]]},"949":{"position":[[475,2]]}}}],["41.5gb",{"_index":1495,"t":{"443":{"position":[[388,8],[502,10]]}}}],["41×98+10341",{"_index":1473,"t":{"437":{"position":[[1071,11]]}}}],["41×98×32bits=1641",{"_index":1492,"t":{"443":{"position":[[201,17]]}}}],["420",{"_index":1187,"t":{"362":{"position":[[973,4]]}}}],["422m",{"_index":896,"t":{"242":{"position":[[48,6]]}}}],["43",{"_index":2870,"t":{"943":{"position":[[304,4]]}}}],["43.08",{"_index":1653,"t":{"489":{"position":[[92,7]]}}}],["43.3",{"_index":2252,"t":{"696":{"position":[[44,5]]}}}],["44×4",{"_index":3278,"t":{"1092":{"position":[[1261,4]]}}}],["45",{"_index":2979,"t":{"983":{"position":[[1038,2]]}}}],["45.2",{"_index":2151,"t":{"680":{"position":[[1287,5]]},"696":{"position":[[78,5]]}}}],["45.6",{"_index":1068,"t":{"316":{"position":[[64,4]]}}}],["46",{"_index":2857,"t":{"931":{"position":[[61,3]]}}}],["47",{"_index":2883,"t":{"951":{"position":[[153,4]]}}}],["48",{"_index":2863,"t":{"937":{"position":[[230,2]]}}}],["480",{"_index":244,"t":{"42":{"position":[[114,3]]}}}],["49",{"_index":2948,"t":{"963":{"position":[[3111,3]]}}}],["4a",{"_index":713,"t":{"155":{"position":[[679,2]]}}}],["4b",{"_index":715,"t":{"155":{"position":[[900,2]]}}}],["4c",{"_index":717,"t":{"155":{"position":[[1039,2]]}}}],["4r=4",{"_index":1827,"t":{"571":{"position":[[212,4]]},"600":{"position":[[185,4]]},"608":{"position":[[655,4]]}}}],["4}1e−4",{"_index":667,"t":{"143":{"position":[[524,6]]}}}],["4×44",{"_index":3277,"t":{"1092":{"position":[[1249,4]]}}}],["5",{"_index":80,"t":{"11":{"position":[[39,1]]},"42":{"position":[[144,1]]},"53":{"position":[[193,1]]},"80":{"position":[[28,1]]},"130":{"position":[[691,1]]},"140":{"position":[[388,1]]},"157":{"position":[[198,1]]},"174":{"position":[[75,1]]},"242":{"position":[[0,3],[191,3]]},"248":{"position":[[85,1]]},"300":{"position":[[560,1]]},"392":{"position":[[166,1]]},"398":{"position":[[19,3],[382,3],[537,3]]},"447":{"position":[[364,1]]},"475":{"position":[[119,1]]},"533":{"position":[[488,1]]},"600":{"position":[[240,2]]},"635":{"position":[[240,1]]},"648":{"position":[[87,1]]},"655":{"position":[[168,1]]},"664":{"position":[[62,1]]},"666":{"position":[[51,1]]},"694":{"position":[[1071,1]]},"698":{"position":[[1392,2],[1398,2],[1404,1]]},"700":{"position":[[66,2]]},"702":{"position":[[920,1]]},"704":{"position":[[124,1]]},"784":{"position":[[297,1],[766,1]]},"791":{"position":[[156,3]]},"793":{"position":[[245,3]]},"798":{"position":[[160,1]]},"800":{"position":[[261,1]]},"804":{"position":[[103,3]]},"817":{"position":[[2247,1]]},"825":{"position":[[817,1]]},"830":{"position":[[21,2]]},"842":{"position":[[454,1]]},"889":{"position":[[404,1]]},"899":{"position":[[847,1]]},"929":{"position":[[132,1]]},"959":{"position":[[125,1]]},"1024":{"position":[[134,1]]},"1129":{"position":[[30,1],[80,1]]},"1165":{"position":[[659,3],[672,3]]},"1190":{"position":[[347,1]]},"1218":{"position":[[150,1]]},"1230":{"position":[[53,1]]},"1236":{"position":[[111,1]]}}}],["5,000",{"_index":2558,"t":{"832":{"position":[[248,5]]}}}],["5,046",{"_index":1055,"t":{"309":{"position":[[52,5]]}}}],["5.6",{"_index":959,"t":{"279":{"position":[[574,4]]},"281":{"position":[[2303,4]]},"320":{"position":[[147,3]]}}}],["50",{"_index":677,"t":{"147":{"position":[[157,3],[182,3]]},"244":{"position":[[450,3],[526,4]]},"360":{"position":[[161,2],[468,3]]},"447":{"position":[[196,2]]},"784":{"position":[[707,3]]},"909":{"position":[[172,2]]},"943":{"position":[[309,3]]},"971":{"position":[[226,5]]},"1104":{"position":[[25,3]]},"1123":{"position":[[14,2]]},"1218":{"position":[[39,3]]},"1230":{"position":[[7,2],[377,4]]},"1236":{"position":[[50,2]]},"1240":{"position":[[206,2]]}}}],["50,000",{"_index":281,"t":{"53":{"position":[[11,6]]}}}],["50.6",{"_index":2253,"t":{"696":{"position":[[52,5]]}}}],["50/80",{"_index":1723,"t":{"533":{"position":[[561,5]]}}}],["500b",{"_index":1250,"t":{"396":{"position":[[179,4]]}}}],["500k",{"_index":1073,"t":{"320":{"position":[[88,4]]},"324":{"position":[[179,4]]},"519":{"position":[[228,4]]}}}],["50k",{"_index":1706,"t":{"519":{"position":[[252,3]]}}}],["50x16",{"_index":3783,"t":{"1218":{"position":[[74,6]]}}}],["50x64",{"_index":3784,"t":{"1218":{"position":[[88,5]]}}}],["51",{"_index":2815,"t":{"911":{"position":[[427,2]]},"953":{"position":[[454,2]]},"983":{"position":[[143,2]]}}}],["511",{"_index":3384,"t":{"1111":{"position":[[194,3]]}}}],["512",{"_index":330,"t":{"63":{"position":[[120,3]]},"106":{"position":[[156,3],[170,3]]},"143":{"position":[[654,3]]},"362":{"position":[[715,4],[769,4]]},"1222":{"position":[[208,5]]}}}],["5150",{"_index":1166,"t":{"360":{"position":[[426,5]]}}}],["518",{"_index":530,"t":{"106":{"position":[[186,3]]}}}],["52",{"_index":2832,"t":{"917":{"position":[[491,2],[818,2]]},"943":{"position":[[313,3],[404,3]]},"963":{"position":[[291,4]]},"971":{"position":[[427,4]]}}}],["52.4",{"_index":1255,"t":{"396":{"position":[[586,5]]}}}],["52k",{"_index":1509,"t":{"455":{"position":[[99,3]]},"457":{"position":[[288,3]]},"461":{"position":[[0,3]]},"475":{"position":[[21,3]]},"529":{"position":[[19,3]]}}}],["53",{"_index":2917,"t":{"963":{"position":[[507,4]]}}}],["540b",{"_index":872,"t":{"227":{"position":[[298,4]]},"229":{"position":[[995,4]]},"233":{"position":[[33,4]]},"242":{"position":[[89,5]]},"244":{"position":[[339,4],[567,4]]},"261":{"position":[[96,5]]},"269":{"position":[[275,4]]},"368":{"position":[[267,4]]},"386":{"position":[[63,4],[408,6]]},"390":{"position":[[165,4]]},"396":{"position":[[242,4]]},"406":{"position":[[59,5]]},"410":{"position":[[96,4]]},"412":{"position":[[48,4]]}}}],["55",{"_index":2792,"t":{"905":{"position":[[452,2]]},"953":{"position":[[344,2]]}}}],["56",{"_index":2931,"t":{"963":{"position":[[1788,5]]}}}],["567k",{"_index":1716,"t":{"529":{"position":[[69,4]]}}}],["57",{"_index":1229,"t":{"382":{"position":[[135,2]]}}}],["576",{"_index":3703,"t":{"1172":{"position":[[368,3]]}}}],["576\\}{144,288,576",{"_index":3688,"t":{"1165":{"position":[[344,18]]}}}],["5k",{"_index":653,"t":{"143":{"position":[[14,2]]},"1107":{"position":[[23,3]]}}}],["5m",{"_index":1699,"t":{"515":{"position":[[929,3]]}}}],["5x5",{"_index":225,"t":{"38":{"position":[[189,4]]}}}],["5}5⋅10−5",{"_index":2427,"t":{"784":{"position":[[329,8]]}}}],["5~11",{"_index":184,"t":{"25":{"position":[[745,5]]}}}],["5×10−5,8×10−5,1×10−4,2×10−4",{"_index":3694,"t":{"1165":{"position":[[701,31]]}}}],["5×10−5,8×10−5,1×10−4,2×10−4}\\{5",{"_index":3693,"t":{"1165":{"position":[[619,32]]}}}],["5⋅10−55",{"_index":2426,"t":{"784":{"position":[[310,7]]}}}],["6",{"_index":226,"t":{"38":{"position":[[217,2]]},"42":{"position":[[146,5]]},"147":{"position":[[256,1]]},"157":{"position":[[340,2]]},"171":{"position":[[369,1]]},"254":{"position":[[222,1],[418,1]]},"259":{"position":[[155,2]]},"394":{"position":[[112,1]]},"416":{"position":[[771,2]]},"435":{"position":[[325,2]]},"463":{"position":[[1661,1]]},"477":{"position":[[83,1]]},"606":{"position":[[247,1]]},"642":{"position":[[39,2]]},"655":{"position":[[68,4]]},"672":{"position":[[7,1],[232,1]]},"700":{"position":[[273,4]]},"702":{"position":[[237,2],[443,1]]},"784":{"position":[[790,1]]},"804":{"position":[[157,1]]},"889":{"position":[[530,1]]},"1085":{"position":[[726,1]]},"1094":{"position":[[698,1],[734,1]]},"1104":{"position":[[204,1],[222,1]]}}}],["6,700",{"_index":1057,"t":{"309":{"position":[[109,5]]}}}],["6.4",{"_index":2465,"t":{"811":{"position":[[269,6]]}}}],["6.7",{"_index":1461,"t":{"435":{"position":[[219,4]]}}}],["6.7b",{"_index":893,"t":{"242":{"position":[[30,5]]},"318":{"position":[[17,4],[328,6]]}}}],["6.8",{"_index":151,"t":{"23":{"position":[[131,4]]},"25":{"position":[[441,4],[704,4]]},"76":{"position":[[210,4]]}}}],["6.88",{"_index":1652,"t":{"484":{"position":[[167,6]]}}}],["6.91/0.3221.5≈6.91/0.32",{"_index":1926,"t":{"608":{"position":[[693,23]]}}}],["60",{"_index":315,"t":{"58":{"position":[[163,2]]},"398":{"position":[[128,3]]},"431":{"position":[[429,2]]},"491":{"position":[[160,2]]},"804":{"position":[[130,3]]}}}],["60.7",{"_index":1386,"t":{"425":{"position":[[2469,5]]}}}],["600",{"_index":1185,"t":{"362":{"position":[[819,6]]}}}],["60m",{"_index":2116,"t":{"644":{"position":[[230,5]]},"657":{"position":[[197,3]]}}}],["61",{"_index":2921,"t":{"963":{"position":[[1513,3]]}}}],["62",{"_index":2848,"t":{"919":{"position":[[624,2]]},"963":{"position":[[567,4]]},"975":{"position":[[822,4]]}}}],["62.5",{"_index":2130,"t":{"668":{"position":[[217,5]]}}}],["62.71",{"_index":1387,"t":{"425":{"position":[[2477,6]]}}}],["62b",{"_index":901,"t":{"242":{"position":[[84,4]]},"244":{"position":[[547,3],[587,3]]},"368":{"position":[[555,3]]},"386":{"position":[[57,3],[395,3],[402,3]]},"396":{"position":[[171,3]]}}}],["63.3",{"_index":1388,"t":{"425":{"position":[[2495,5]]}}}],["64",{"_index":1635,"t":{"475":{"position":[[165,2]]},"678":{"position":[[245,3]]},"707":{"position":[[198,3]]},"1172":{"position":[[206,2]]},"1179":{"position":[[157,2]]}}}],["64.2",{"_index":2149,"t":{"680":{"position":[[1246,5]]},"696":{"position":[[86,5]]}}}],["64.6",{"_index":1454,"t":{"429":{"position":[[510,4]]}}}],["64.9",{"_index":3050,"t":{"1013":{"position":[[281,4]]}}}],["640x640",{"_index":672,"t":{"143":{"position":[[662,7],[702,7]]},"147":{"position":[[431,7]]}}}],["641≤i≤64",{"_index":1894,"t":{"604":{"position":[[356,9]]}}}],["64\\}{8,16,32,64",{"_index":3683,"t":{"1165":{"position":[[200,16]]}}}],["64c=64",{"_index":764,"t":{"171":{"position":[[829,6]]}}}],["64r=64",{"_index":1915,"t":{"606":{"position":[[8,6]]}}}],["65.8",{"_index":1455,"t":{"429":{"position":[[518,4]]}}}],["650b",{"_index":1704,"t":{"517":{"position":[[203,4]]}}}],["65b",{"_index":1722,"t":{"533":{"position":[[432,3]]}}}],["66",{"_index":2961,"t":{"975":{"position":[[590,4]]}}}],["67",{"_index":2775,"t":{"901":{"position":[[1083,2]]},"917":{"position":[[1048,3]]},"947":{"position":[[288,3]]}}}],["67m",{"_index":1175,"t":{"362":{"position":[[319,4]]}}}],["68",{"_index":2887,"t":{"951":{"position":[[172,2]]}}}],["68.37",{"_index":3829,"t":{"1240":{"position":[[272,5]]}}}],["68b",{"_index":899,"t":{"242":{"position":[[63,4]]}}}],["6b",{"_index":1169,"t":{"362":{"position":[[104,3],[141,3],[289,3],[1163,2],[1238,2]]},"989":{"position":[[532,3]]},"1001":{"position":[[581,2]]}}}],["6n6n6n",{"_index":1466,"t":{"437":{"position":[[285,6]]}}}],["6~7",{"_index":324,"t":{"60":{"position":[[77,4]]}}}],["7",{"_index":559,"t":{"114":{"position":[[199,1],[288,1]]},"157":{"position":[[343,1]]},"394":{"position":[[227,1]]},"539":{"position":[[5,1]]},"672":{"position":[[178,1]]},"698":{"position":[[115,3]]},"700":{"position":[[56,2],[263,2],[373,2]]},"817":{"position":[[2413,1]]},"1152":{"position":[[2740,3]]},"1188":{"position":[[34,1],[142,1]]}}}],["70",{"_index":2923,"t":{"963":{"position":[[1567,4]]},"1137":{"position":[[2195,3]]}}}],["700",{"_index":3385,"t":{"1111":{"position":[[200,3]]}}}],["70b",{"_index":1703,"t":{"517":{"position":[[197,3]]}}}],["71",{"_index":2774,"t":{"901":{"position":[[988,2],[1147,2]]},"955":{"position":[[363,2]]},"963":{"position":[[2561,4]]}}}],["71.3",{"_index":2131,"t":{"668":{"position":[[225,6]]}}}],["72",{"_index":2884,"t":{"951":{"position":[[158,3]]},"1172":{"position":[[354,3]]}}}],["72,144,288,576",{"_index":3702,"t":{"1172":{"position":[[335,18],[372,18]]}}}],["73.5",{"_index":1502,"t":{"447":{"position":[[417,7]]}}}],["73.6",{"_index":2125,"t":{"664":{"position":[[337,5]]}}}],["73.7",{"_index":2123,"t":{"664":{"position":[[110,5]]},"670":{"position":[[44,5]]}}}],["74",{"_index":2847,"t":{"919":{"position":[[371,2]]}}}],["74.1",{"_index":2122,"t":{"662":{"position":[[512,5]]}}}],["75",{"_index":2942,"t":{"963":{"position":[[2826,4]]}}}],["75.2",{"_index":1202,"t":{"368":{"position":[[369,5]]},"390":{"position":[[172,5]]}}}],["75.8",{"_index":1501,"t":{"447":{"position":[[392,4]]}}}],["76",{"_index":2941,"t":{"963":{"position":[[2778,4]]}}}],["768",{"_index":1184,"t":{"362":{"position":[[814,4]]}}}],["77",{"_index":2780,"t":{"901":{"position":[[2021,2]]},"943":{"position":[[364,3]]}}}],["77.6k",{"_index":1937,"t":{"616":{"position":[[1436,6]]}}}],["770m",{"_index":1168,"t":{"362":{"position":[[56,4]]},"644":{"position":[[247,6]]},"657":{"position":[[203,4]]}}}],["774m",{"_index":2327,"t":{"761":{"position":[[249,4]]}}}],["78",{"_index":2938,"t":{"963":{"position":[[1954,3]]}}}],["78.31",{"_index":1650,"t":{"484":{"position":[[104,6]]}}}],["79",{"_index":1270,"t":{"398":{"position":[[655,3]]}}}],["79.9",{"_index":574,"t":{"118":{"position":[[154,5]]}}}],["7b",{"_index":1510,"t":{"455":{"position":[[129,2]]},"457":{"position":[[651,2],[708,2]]},"475":{"position":[[201,2]]},"531":{"position":[[34,2]]},"533":{"position":[[368,2]]}}}],["8",{"_index":678,"t":{"147":{"position":[[216,3]]},"227":{"position":[[274,3]]},"240":{"position":[[105,3],[181,2]]},"254":{"position":[[400,2]]},"269":{"position":[[264,1]]},"382":{"position":[[230,1]]},"384":{"position":[[180,2]]},"431":{"position":[[464,1]]},"441":{"position":[[109,1],[196,1]]},"455":{"position":[[206,3]]},"457":{"position":[[828,3]]},"475":{"position":[[104,2]]},"541":{"position":[[101,1]]},"698":{"position":[[49,3]]},"791":{"position":[[425,3]]},"825":{"position":[[452,3]]},"963":{"position":[[445,3]]},"1115":{"position":[[14,1]]},"1152":{"position":[[1197,1],[1309,1],[1469,1]]},"1165":{"position":[[663,1]]},"1172":{"position":[[195,2]]},"1179":{"position":[[143,1]]},"1198":{"position":[[649,1],[664,1]]},"1200":{"position":[[1974,1],[1988,1]]},"1240":{"position":[[294,1]]}}}],["8,16,32,64}\\{8",{"_index":3682,"t":{"1165":{"position":[[175,16]]}}}],["80",{"_index":1208,"t":{"373":{"position":[[146,3]]},"475":{"position":[[479,3]]},"804":{"position":[[136,4]]},"848":{"position":[[655,3]]},"919":{"position":[[538,2]]},"949":{"position":[[230,3]]},"1232":{"position":[[22,2]]}}}],["80gb",{"_index":1498,"t":{"445":{"position":[[257,4]]}}}],["80k",{"_index":1718,"t":{"529":{"position":[[188,3]]},"533":{"position":[[304,3]]}}}],["80m",{"_index":1275,"t":{"406":{"position":[[48,3]]},"517":{"position":[[130,3]]}}}],["81",{"_index":2960,"t":{"975":{"position":[[504,4]]}}}],["81≤i≤8",{"_index":1891,"t":{"604":{"position":[[255,7]]}}}],["83",{"_index":2922,"t":{"963":{"position":[[1517,2]]}}}],["83.9",{"_index":1246,"t":{"390":{"position":[[267,5]]}}}],["84",{"_index":2858,"t":{"931":{"position":[[239,2]]}}}],["87",{"_index":304,"t":{"53":{"position":[[379,2]]},"919":{"position":[[405,2]]}}}],["87.36",{"_index":3696,"t":{"1167":{"position":[[185,6]]}}}],["87.7",{"_index":182,"t":{"25":{"position":[[715,6]]}}}],["88",{"_index":2890,"t":{"951":{"position":[[608,3]]}}}],["88.87",{"_index":3716,"t":{"1184":{"position":[[322,6]]}}}],["88.89",{"_index":3718,"t":{"1184":{"position":[[363,7]]}}}],["88×8",{"_index":3276,"t":{"1092":{"position":[[1243,5]]}}}],["8\\}{1,2,4,8",{"_index":3701,"t":{"1172":{"position":[[271,12]]}}}],["8\\}{2,4,8",{"_index":3685,"t":{"1165":{"position":[[259,10]]}}}],["8b",{"_index":898,"t":{"242":{"position":[[59,3],[79,4]]},"386":{"position":[[53,3],[389,3]]}}}],["8r=8",{"_index":1872,"t":{"600":{"position":[[96,4]]},"1137":{"position":[[2098,5]]}}}],["8xa100",{"_index":1080,"t":{"324":{"position":[[45,6]]}}}],["8×88",{"_index":3275,"t":{"1092":{"position":[[1231,4]]}}}],["9",{"_index":687,"t":{"149":{"position":[[300,1]]},"360":{"position":[[74,1]]},"368":{"position":[[222,3]]},"375":{"position":[[78,1]]},"377":{"position":[[78,1]]},"390":{"position":[[21,1]]},"392":{"position":[[32,3]]},"423":{"position":[[1469,2]]},"427":{"position":[[3109,1]]},"541":{"position":[[205,1]]},"793":{"position":[[217,2]]},"943":{"position":[[470,2]]},"951":{"position":[[604,3]]},"955":{"position":[[195,1]]},"1203":{"position":[[284,1]]}}}],["9.4",{"_index":1240,"t":{"386":{"position":[[179,4]]},"410":{"position":[[168,4]]}}}],["90",{"_index":1109,"t":{"339":{"position":[[185,3]]},"963":{"position":[[981,4],[1207,4]]}}}],["900",{"_index":3374,"t":{"1104":{"position":[[269,3]]}}}],["900m",{"_index":3748,"t":{"1203":{"position":[[276,4]]}}}],["90m",{"_index":548,"t":{"112":{"position":[[270,3]]}}}],["91",{"_index":2619,"t":{"848":{"position":[[615,3]]}}}],["96",{"_index":1874,"t":{"600":{"position":[[212,3]]},"927":{"position":[[370,2]]},"943":{"position":[[317,3]]},"979":{"position":[[58,2]]}}}],["98",{"_index":1472,"t":{"437":{"position":[[1028,2],[1090,2]]},"439":{"position":[[261,2]]},"443":{"position":[[221,2]]},"931":{"position":[[65,3]]},"973":{"position":[[177,5]]}}}],["99",{"_index":2852,"t":{"919":{"position":[[859,2]]},"943":{"position":[[321,3]]}}}],["9:1",{"_index":716,"t":{"155":{"position":[[958,3]]}}}],["9m",{"_index":546,"t":{"112":{"position":[[261,3]]}}}],["_",{"_index":2705,"t":{"876":{"position":[[1002,2],[1072,2]]}}}],["_i",{"_index":3508,"t":{"1146":{"position":[[459,2]]}}}],["_{1",{"_index":3509,"t":{"1146":{"position":[[462,5]]},"1148":{"position":[[2259,5]]}}}],["_{i=1",{"_index":1760,"t":{"553":{"position":[[233,8]]}}}],["_{k,i",{"_index":3612,"t":{"1152":{"position":[[535,7]]}}}],["a100",{"_index":1178,"t":{"362":{"position":[[412,4]]},"441":{"position":[[468,4]]},"445":{"position":[[262,4]]},"451":{"position":[[559,4]]},"455":{"position":[[210,4]]},"457":{"position":[[832,4]]},"475":{"position":[[107,4]]}}}],["a^}j=1u",{"_index":994,"t":{"296":{"position":[[17,10]]}}}],["a_{i",{"_index":3490,"t":{"1142":{"position":[[677,7]]}}}],["a_{r=64",{"_index":1899,"t":{"604":{"position":[[547,9]]}}}],["a_{r=8",{"_index":1898,"t":{"604":{"position":[[537,9]]}}}],["aaa",{"_index":1740,"t":{"549":{"position":[[901,3]]},"563":{"position":[[591,3],[861,3]]},"1137":{"position":[[1992,4]]},"1142":{"position":[[476,3],[591,3]]},"1146":{"position":[[1826,3]]},"1190":{"position":[[215,3]]}}}],["abil",{"_index":2784,"t":{"901":{"position":[[2307,7]]}}}],["ablat",{"_index":843,"t":{"209":{"position":[[15,8]]},"211":{"position":[[17,8]]},"246":{"position":[[51,8]]},"306":{"position":[[98,8]]},"311":{"position":[[333,8]]},"449":{"position":[[44,8]]},"644":{"position":[[202,8]]},"817":{"position":[[2534,8]]},"832":{"position":[[77,8]]},"848":{"position":[[736,8]]},"1152":{"position":[[2660,8]]}}}],["abov",{"_index":91,"t":{"15":{"position":[[25,6]]}}}],["absolut",{"_index":3168,"t":{"1055":{"position":[[51,8]]}}}],["acceler",{"_index":209,"t":{"33":{"position":[[89,11]]},"38":{"position":[[0,11]]}}}],["access",{"_index":3232,"t":{"1077":{"position":[[90,10]]}}}],["accord",{"_index":1043,"t":{"304":{"position":[[168,9]]}}}],["accumul",{"_index":1497,"t":{"445":{"position":[[186,11]]},"551":{"position":[[275,11]]}}}],["accuraci",{"_index":195,"t":{"27":{"position":[[278,8]]},"38":{"position":[[323,8]]},"78":{"position":[[692,8]]},"416":{"position":[[433,8]]},"423":{"position":[[1488,8]]},"811":{"position":[[1169,8]]},"1113":{"position":[[103,8]]},"1115":{"position":[[114,8]]},"1121":{"position":[[133,8]]}}}],["accuray",{"_index":1337,"t":{"423":{"position":[[1358,7]]}}}],["act",{"_index":2651,"t":{"855":{"position":[[260,3]]},"983":{"position":[[481,7],[650,7]]}}}],["action",{"_index":1004,"t":{"298":{"position":[[162,6]]},"850":{"position":[[98,8],[1284,6],[1410,6],[1585,6]]},"853":{"position":[[45,6]]},"855":{"position":[[29,6],[151,6],[331,6]]},"859":{"position":[[469,6],[542,6],[725,6]]},"861":{"position":[[395,6]]},"870":{"position":[[78,6]]},"1059":{"position":[[143,6],[221,6]]},"1203":{"position":[[596,6]]},"1207":{"position":[[263,6]]}}}],["activ",{"_index":384,"t":{"86":{"position":[[688,10]]},"416":{"position":[[502,11]]},"418":{"position":[[2066,11]]},"427":{"position":[[400,11],[486,10],[558,10],[716,11],[976,11],[1150,10],[1349,10],[2433,12],[2483,11],[3569,11]]},"445":{"position":[[140,11]]},"451":{"position":[[187,11]]},"583":{"position":[[77,10],[111,10],[131,10]]},"688":{"position":[[578,9]]},"766":{"position":[[327,10],[480,10],[559,10],[643,11]]},"768":{"position":[[234,10]]},"773":{"position":[[806,10],[974,10]]},"775":{"position":[[417,10],[1266,10],[1307,10]]},"798":{"position":[[111,10]]},"800":{"position":[[23,11],[62,10],[148,10],[354,10],[401,10]]},"802":{"position":[[133,10],[449,10]]},"811":{"position":[[399,10],[531,10],[611,10]]},"817":{"position":[[1307,11]]},"836":{"position":[[368,10]]},"1140":{"position":[[835,10]]}}}],["actor",{"_index":2642,"t":{"853":{"position":[[24,5],[174,5]]},"855":{"position":[[0,5]]},"857":{"position":[[44,5]]},"861":{"position":[[75,5]]},"863":{"position":[[16,5],[462,6]]}}}],["actual",{"_index":2785,"t":{"901":{"position":[[2414,6]]}}}],["ad",{"_index":56,"t":{"9":{"position":[[151,5]]},"17":{"position":[[102,5]]},"510":{"position":[[265,5]]},"515":{"position":[[891,5]]},"519":{"position":[[554,5]]}}}],["adafactor",{"_index":1219,"t":{"379":{"position":[[171,9]]},"431":{"position":[[444,9]]},"445":{"position":[[165,9]]},"825":{"position":[[794,9]]},"827":{"position":[[85,9]]}}}],["adalora",{"_index":3407,"t":{"1135":{"position":[[449,7],[539,7],[875,7],[895,7]]},"1137":{"position":[[3265,7],[3388,7],[4381,7],[4568,7]]},"1146":{"position":[[1742,7]]},"1154":{"position":[[674,7]]},"1156":{"position":[[0,7]]},"1160":{"position":[[0,7]]},"1165":{"position":[[59,7],[278,7],[372,7]]},"1167":{"position":[[22,7],[99,7],[168,7],[222,7]]},"1170":{"position":[[46,7]]},"1172":{"position":[[35,7],[290,7]]},"1174":{"position":[[113,7]]},"1177":{"position":[[31,7]]},"1181":{"position":[[159,7]]},"1184":{"position":[[117,7],[301,7]]},"1186":{"position":[[228,7],[279,7]]},"1188":{"position":[[0,7]]},"1190":{"position":[[294,7],[454,7],[508,7]]},"1192":{"position":[[9,7],[88,7],[290,7],[342,7]]},"1194":{"position":[[43,7]]}}}],["adaloraγ=0_{\\gamma",{"_index":3725,"t":{"1190":{"position":[[264,18]]}}}],["adam",{"_index":522,"t":{"106":{"position":[[27,4]]},"547":{"position":[[220,4]]},"563":{"position":[[1027,4]]},"571":{"position":[[48,4]]},"694":{"position":[[1075,4]]}}}],["adamw",{"_index":809,"t":{"188":{"position":[[10,5]]},"362":{"position":[[1014,5]]},"698":{"position":[[1233,5]]},"784":{"position":[[137,5]]},"1104":{"position":[[284,6]]},"1172":{"position":[[411,5]]}}}],["adapt",{"_index":155,"t":{"23":{"position":[[204,10]]},"47":{"position":[[440,10]]},"74":{"position":[[11,8]]},"76":{"position":[[71,10]]},"78":{"position":[[434,10]]},"396":{"position":[[413,7]]},"416":{"position":[[271,7]]},"421":{"position":[[75,8]]},"427":{"position":[[822,10],[2390,7],[3085,10],[3167,8],[3337,7]]},"431":{"position":[[61,10]]},"443":{"position":[[328,10]]},"447":{"position":[[309,8]]},"455":{"position":[[6,7],[81,10],[160,7],[267,10],[411,10],[476,7]]},"457":{"position":[[194,7],[393,10],[455,10],[587,7],[685,10],[807,10],[904,7],[1067,10]]},"461":{"position":[[140,10],[684,10]]},"463":{"position":[[0,10],[1256,10],[1533,10],[1956,10],[2461,10]]},"465":{"position":[[28,7],[661,10],[805,10],[1088,10]]},"467":{"position":[[33,10]]},"469":{"position":[[52,10]]},"475":{"position":[[94,7],[302,10]]},"477":{"position":[[15,7],[124,7]]},"479":{"position":[[83,7]]},"482":{"position":[[200,7]]},"484":{"position":[[6,7],[247,7]]},"489":{"position":[[29,7]]},"491":{"position":[[113,7],[225,7]]},"498":{"position":[[6,7]]},"502":{"position":[[9,7],[181,7],[201,7],[269,7],[694,7],[810,7],[831,7]]},"504":{"position":[[181,7],[195,7],[518,7],[549,7],[569,7],[624,10],[786,7],[937,10],[967,7],[1088,10],[1285,7],[1344,10],[1374,7],[1789,7],[2105,7],[2304,7]]},"508":{"position":[[70,7],[108,7],[128,7],[233,8],[306,10]]},"510":{"position":[[284,7]]},"512":{"position":[[6,7],[45,7],[124,10],[205,7]]},"515":{"position":[[6,7],[46,10],[156,10],[302,10],[518,7],[944,7]]},"519":{"position":[[14,7],[111,7],[498,10],[596,11]]},"521":{"position":[[363,7]]},"523":{"position":[[62,10],[123,7],[264,10],[291,7],[328,10],[404,10],[431,7]]},"525":{"position":[[83,7],[643,7]]},"529":{"position":[[6,7]]},"531":{"position":[[55,10]]},"533":{"position":[[56,7],[131,7],[534,7]]},"535":{"position":[[6,7],[92,7],[210,7]]},"537":{"position":[[6,7],[20,10],[172,7],[369,7],[490,7],[506,7]]},"541":{"position":[[133,7]]},"543":{"position":[[68,7]]},"547":{"position":[[59,11],[373,7],[435,10]]},"549":{"position":[[56,10],[134,8],[442,10],[516,10],[583,10],[981,8]]},"551":{"position":[[261,10]]},"555":{"position":[[22,7]]},"557":{"position":[[3,7],[104,7],[219,7],[293,7],[321,7],[474,7]]},"559":{"position":[[101,10]]},"563":{"position":[[112,8]]},"569":{"position":[[202,8]]},"571":{"position":[[242,8]]},"585":{"position":[[41,7],[58,7],[180,7],[287,7],[366,7],[694,7]]},"589":{"position":[[190,7]]},"598":{"position":[[142,10]]},"600":{"position":[[77,8],[166,8],[346,8]]},"610":{"position":[[168,10],[237,8]]},"614":{"position":[[48,5],[143,5],[440,5]]},"619":{"position":[[0,7],[844,10]]},"621":{"position":[[318,8]]},"625":{"position":[[297,5]]},"629":{"position":[[307,10],[408,5]]},"635":{"position":[[530,10]]},"642":{"position":[[352,8]]},"646":{"position":[[89,10],[294,8]]},"648":{"position":[[218,10]]},"651":{"position":[[177,8]]},"657":{"position":[[103,8]]},"659":{"position":[[103,5]]},"668":{"position":[[242,10]]},"672":{"position":[[215,10]]},"674":{"position":[[316,5]]},"711":{"position":[[491,7]]},"761":{"position":[[419,7],[504,7]]},"782":{"position":[[127,7],[142,9]]},"787":{"position":[[116,8],[213,7],[282,7],[348,7],[439,7]]},"793":{"position":[[577,7]]},"809":{"position":[[244,7],[295,7]]},"811":{"position":[[68,7],[218,7],[334,7],[557,7],[669,7],[776,7]]},"817":{"position":[[162,10],[207,10],[706,10],[1457,8]]},"823":{"position":[[1437,10],[1581,10],[1676,10],[1865,10]]},"825":{"position":[[181,7]]},"834":{"position":[[293,10],[373,10],[405,8],[445,10],[662,8],[1090,10]]},"836":{"position":[[1850,8],[2069,10],[2094,7],[2322,7],[2437,7]]},"840":{"position":[[232,10]]},"844":{"position":[[58,8]]},"949":{"position":[[351,8]]},"959":{"position":[[69,10]]},"1135":{"position":[[519,10]]},"1137":{"position":[[545,7],[577,8],[1178,10],[3210,10],[3273,9],[3292,11]]},"1142":{"position":[[921,7]]},"1144":{"position":[[31,11]]},"1148":{"position":[[14,10],[344,7]]},"1154":{"position":[[18,10]]},"1160":{"position":[[40,10],[261,7],[311,8],[336,7],[357,7],[435,7],[463,7],[557,7],[779,7]]},"1165":{"position":[[151,7]]},"1172":{"position":[[148,7]]},"1174":{"position":[[197,7],[216,7]]},"1179":{"position":[[46,10]]},"1190":{"position":[[29,10],[42,8],[151,10],[406,10]]},"1194":{"position":[[97,10]]},"1198":{"position":[[188,7],[202,7],[675,7]]},"1200":{"position":[[432,7],[446,7],[624,7],[737,7],[1999,7]]},"1205":{"position":[[229,7],[244,7],[358,7],[406,7]]},"1240":{"position":[[124,8],[315,7]]},"1242":{"position":[[108,7],[122,7]]}}}],["adapter/prefix",{"_index":3435,"t":{"1137":{"position":[[3111,14]]}}}],["adapterd\\text{adapter}^dadapterd",{"_index":1850,"t":{"585":{"position":[[386,32]]}}}],["adapterh\\text{adapter}^hadapterh",{"_index":1847,"t":{"585":{"position":[[140,32]]}}}],["adapterl\\text{adapter}^ladapterl",{"_index":1848,"t":{"585":{"position":[[240,32]]}}}],["adapterp\\text{adapter}^padapterp",{"_index":1849,"t":{"585":{"position":[[311,32]]}}}],["adaptert_tt",{"_index":1649,"t":{"484":{"position":[[70,12]]}}}],["adaptor",{"_index":772,"t":{"178":{"position":[[102,7],[131,7],[364,7],[384,7]]},"209":{"position":[[0,7],[102,7],[155,7],[231,7]]}}}],["adatp",{"_index":1726,"t":{"537":{"position":[[552,7],[578,7]]},"1200":{"position":[[673,7]]}}}],["add",{"_index":50,"t":{"9":{"position":[[68,3]]},"78":{"position":[[626,3]]},"1026":{"position":[[89,3],[134,3],[165,3]]},"1036":{"position":[[65,3]]},"1038":{"position":[[0,3]]},"1067":{"position":[[40,3]]},"1073":{"position":[[31,3]]},"1079":{"position":[[41,3]]}}}],["addit",{"_index":1314,"t":{"423":{"position":[[336,10]]},"425":{"position":[[59,10],[1630,10],[2520,10]]},"427":{"position":[[2946,10]]},"451":{"position":[[236,10]]},"504":{"position":[[2017,10]]},"525":{"position":[[335,10]]},"678":{"position":[[226,10]]},"761":{"position":[[464,10],[1518,10]]},"817":{"position":[[1563,10]]},"836":{"position":[[300,10]]},"850":{"position":[[424,10]]},"963":{"position":[[2061,10]]},"1049":{"position":[[39,10]]},"1137":{"position":[[682,10],[2104,10],[4233,10]]}}}],["adipisc",{"_index":6,"t":{"3":{"position":[[40,10]]},"5":{"position":[[160,10],[339,10],[518,10],[697,10],[876,10],[1055,10],[1234,10],[1413,10],[1592,10],[1771,10],[1950,10],[2129,10],[2308,10],[2487,10],[2666,10],[2845,10]]}}}],["adjust",{"_index":156,"t":{"23":{"position":[[215,6]]},"47":{"position":[[451,6]]},"76":{"position":[[82,6]]},"78":{"position":[[445,6]]},"421":{"position":[[360,11]]}}}],["admonit",{"_index":3181,"t":{"1059":{"position":[[42,11]]}}}],["advantag",{"_index":2860,"t":{"931":{"position":[[321,10]]},"933":{"position":[[254,10]]},"935":{"position":[[189,10]]},"937":{"position":[[409,10]]},"939":{"position":[[186,10]]}}}],["adversari",{"_index":2135,"t":{"672":{"position":[[129,11]]},"707":{"position":[[109,11]]}}}],["agent",{"_index":2608,"t":{"848":{"position":[[22,6],[140,5],[241,5],[562,5],[715,5]]},"850":{"position":[[31,5],[217,5],[251,5],[413,5],[630,5],[1960,5]]},"855":{"position":[[390,5]]},"859":{"position":[[353,5],[413,5],[531,5],[662,5],[809,5]]},"861":{"position":[[380,5]]}}}],["agnost",{"_index":957,"t":{"279":{"position":[[382,8]]},"292":{"position":[[863,8]]},"963":{"position":[[366,8]]}}}],["agument",{"_index":1152,"t":{"353":{"position":[[212,9]]}}}],["ai",{"_index":3059,"t":{"1020":{"position":[[99,3],[113,2]]}}}],["ai+1a_{i+1}ai+1",{"_index":2665,"t":{"859":{"position":[[476,16],[495,16]]}}}],["ai+1′a'_{i+1}ai+1",{"_index":2667,"t":{"859":{"position":[[575,19]]}}}],["ai+2′a'_{i+2}ai+2",{"_index":2668,"t":{"859":{"position":[[597,19]]}}}],["aia_iai",{"_index":2664,"t":{"859":{"position":[[450,8]]}}}],["aim",{"_index":161,"t":{"25":{"position":[[117,3]]},"27":{"position":[[20,3]]}}}],["aip",{"_index":2999,"t":{"995":{"position":[[20,3]]}}}],["ai′a'_iai",{"_index":2666,"t":{"859":{"position":[[549,11],[732,11]]}}}],["ai∗a_{i*}ai",{"_index":3487,"t":{"1142":{"position":[[575,13]]}}}],["al",{"_index":1116,"t":{"343":{"position":[[145,3]]},"349":{"position":[[192,4],[316,4]]},"362":{"position":[[1102,4]]},"427":{"position":[[1510,3]]}}}],["albert",{"_index":2152,"t":{"680":{"position":[[1421,6]]},"698":{"position":[[1830,6]]}}}],["alert('button",{"_index":44,"t":{"7":{"position":[[146,13]]}}}],["alert(`y",{"_index":3200,"t":{"1061":{"position":[[286,10]]}}}],["alfworld",{"_index":2636,"t":{"850":{"position":[[1782,8]]}}}],["algebra",{"_index":886,"t":{"236":{"position":[[100,9],[132,9]]},"273":{"position":[[151,9]]}}}],["algo",{"_index":1247,"t":{"390":{"position":[[358,4]]}}}],["algorithm",{"_index":367,"t":{"78":{"position":[[958,9]]},"138":{"position":[[222,9]]},"817":{"position":[[1121,9]]},"1158":{"position":[[393,9]]}}}],["align",{"_index":963,"t":{"281":{"position":[[650,5]]},"288":{"position":[[33,9],[87,5],[419,5]]},"330":{"position":[[1150,9]]},"345":{"position":[[118,9],[674,9]]},"502":{"position":[[540,9]]},"504":{"position":[[1050,9],[1177,9],[1510,9],[2361,9]]},"510":{"position":[[197,9]]},"537":{"position":[[715,9]]},"857":{"position":[[305,5]]},"989":{"position":[[148,8],[175,8]]},"1003":{"position":[[0,7],[33,9],[70,9],[200,7]]},"1013":{"position":[[81,9],[114,9],[145,5],[210,5],[238,5]]},"1016":{"position":[[137,7]]},"1200":{"position":[[124,5]]},"1203":{"position":[[99,5],[483,5]]}}}],["alik",{"_index":3436,"t":{"1137":{"position":[[3312,5]]}}}],["aliquam",{"_index":16,"t":{"3":{"position":[[133,7]]},"5":{"position":[[253,7],[432,7],[611,7],[790,7],[969,7],[1148,7],[1327,7],[1506,7],[1685,7],[1864,7],[2043,7],[2222,7],[2401,7],[2580,7],[2759,7],[2938,7]]}}}],["allic",{"_index":3720,"t":{"1186":{"position":[[57,10]]}}}],["alloc",{"_index":3408,"t":{"1135":{"position":[[530,8]]},"1144":{"position":[[124,11]]},"1146":{"position":[[1993,10]]},"1154":{"position":[[182,10]]},"1190":{"position":[[58,10]]},"1194":{"position":[[108,8],[319,8]]}}}],["allow",{"_index":3187,"t":{"1061":{"position":[[53,6]]}}}],["alpaca",{"_index":1515,"t":{"457":{"position":[[72,6],[711,6],[853,6]]},"475":{"position":[[9,6]]},"477":{"position":[[25,6],[46,6]]},"498":{"position":[[43,6]]},"504":{"position":[[60,6]]}}}],["alpha",{"_index":1815,"t":{"563":{"position":[[1004,8],[1042,8]]},"1158":{"position":[[132,9],[168,8],[288,8],[368,8]]}}}],["altern",{"_index":1300,"t":{"418":{"position":[[486,11]]}}}],["altogeth",{"_index":2596,"t":{"842":{"position":[[811,10],[876,10],[937,10]]}}}],["amaz",{"_index":2284,"t":{"713":{"position":[[454,8]]},"718":{"position":[[221,8]]},"983":{"position":[[732,8]]}}}],["amet",{"_index":4,"t":{"3":{"position":[[22,5],[174,4]]},"5":{"position":[[142,5],[294,4],[321,5],[473,4],[500,5],[652,4],[679,5],[831,4],[858,5],[1010,4],[1037,5],[1189,4],[1216,5],[1368,4],[1395,5],[1547,4],[1574,5],[1726,4],[1753,5],[1905,4],[1932,5],[2084,4],[2111,5],[2263,4],[2290,5],[2442,4],[2469,5],[2621,4],[2648,5],[2800,4],[2827,5],[2979,4]]}}}],["ami",{"_index":926,"t":{"267":{"position":[[45,4]]}}}],["amp",{"_index":814,"t":{"188":{"position":[[294,5],[321,3]]}}}],["amplifi",{"_index":1434,"t":{"427":{"position":[[2416,10]]}}}],["analog",{"_index":2873,"t":{"943":{"position":[[460,9]]}}}],["analysi",{"_index":2283,"t":{"713":{"position":[[426,8]]},"879":{"position":[[338,8]]},"883":{"position":[[290,8]]},"969":{"position":[[148,8]]}}}],["anchor",{"_index":2230,"t":{"688":{"position":[[1167,6],[1322,6],[1366,6]]},"694":{"position":[[1018,6]]},"901":{"position":[[2185,6]]}}}],["anger",{"_index":2797,"t":{"909":{"position":[[441,9]]}}}],["angin",{"_index":2983,"t":{"983":{"position":[[1232,11]]}}}],["anli",{"_index":1322,"t":{"423":{"position":[[837,6]]}}}],["annot",{"_index":638,"t":{"138":{"position":[[21,10]]},"143":{"position":[[127,11]]},"149":{"position":[[92,10]]},"254":{"position":[[6,10],[92,9],[264,10],[501,10]]},"271":{"position":[[90,11]]},"281":{"position":[[228,10]]},"375":{"position":[[4,10]]},"390":{"position":[[8,10]]},"642":{"position":[[22,11]]},"881":{"position":[[27,9]]},"917":{"position":[[595,8],[1201,8]]},"927":{"position":[[274,9]]},"975":{"position":[[189,10]]},"1085":{"position":[[162,11]]},"1087":{"position":[[663,11],[1553,11]]},"1090":{"position":[[286,10]]},"1092":{"position":[[502,10],[569,11]]},"1096":{"position":[[1863,10]]},"1099":{"position":[[151,11],[627,11]]},"1101":{"position":[[178,10]]},"1125":{"position":[[249,10]]},"1200":{"position":[[755,9]]},"1205":{"position":[[522,10]]},"1209":{"position":[[95,10]]},"1220":{"position":[[337,10]]}}}],["answer",{"_index":592,"t":{"126":{"position":[[295,9]]},"165":{"position":[[126,9],[884,9]]},"229":{"position":[[216,6]]},"231":{"position":[[102,6]]},"279":{"position":[[81,9],[430,9]]},"281":{"position":[[218,9],[567,9]]},"284":{"position":[[268,6]]},"292":{"position":[[249,6],[825,9]]},"294":{"position":[[93,9],[243,6]]},"296":{"position":[[4,6],[61,6]]},"298":{"position":[[30,6],[89,6],[147,6]]},"300":{"position":[[106,6],[183,8],[343,6],[466,6],[524,6],[679,6]]},"302":{"position":[[387,6]]},"304":{"position":[[28,6],[149,6],[347,7],[490,7],[501,6],[677,6],[752,6],[793,6],[859,6]]},"311":{"position":[[427,6],[442,6]]},"313":{"position":[[322,6]]},"316":{"position":[[167,6]]},"318":{"position":[[109,6]]},"324":{"position":[[25,6]]},"384":{"position":[[59,6]]},"425":{"position":[[1464,6],[1916,6]]},"451":{"position":[[335,6]]},"465":{"position":[[63,9]]},"521":{"position":[[194,7]]},"623":{"position":[[120,9]]},"694":{"position":[[20,7],[491,6]]},"698":{"position":[[138,9]]},"713":{"position":[[1511,9]]},"716":{"position":[[199,9]]},"740":{"position":[[101,9]]},"883":{"position":[[228,6]]},"885":{"position":[[231,6],[325,8],[348,6],[452,6]]},"887":{"position":[[23,6],[85,6],[122,6],[266,6]]},"889":{"position":[[274,6]]},"895":{"position":[[185,10]]},"903":{"position":[[6,6],[35,6],[103,6],[118,6]]},"905":{"position":[[0,6],[209,6],[257,6],[389,6],[442,9]]},"907":{"position":[[4,6],[42,6]]},"909":{"position":[[17,6],[109,6],[223,6],[354,9],[626,6],[710,9]]},"911":{"position":[[7,6],[63,6],[84,6],[98,6],[121,6],[179,6],[197,6],[239,6],[309,6],[493,6],[532,7],[569,6],[601,6],[650,6],[771,6],[946,6],[1174,6],[1307,6],[1374,6]]},"913":{"position":[[30,6],[162,6]]},"917":{"position":[[1158,6],[1333,6]]},"919":{"position":[[86,6],[110,8],[543,8],[731,8],[939,6]]},"923":{"position":[[159,6]]},"933":{"position":[[69,6],[86,8],[413,8]]},"937":{"position":[[260,6],[433,6],[547,6]]},"943":{"position":[[226,6]]},"945":{"position":[[215,8]]},"947":{"position":[[301,6],[600,6]]},"949":{"position":[[262,6],[360,6],[837,6]]},"953":{"position":[[9,9],[70,6],[143,6],[254,6]]},"955":{"position":[[240,8]]},"961":{"position":[[245,9]]},"963":{"position":[[1281,6],[1424,6]]},"969":{"position":[[245,6],[431,6],[724,6],[763,6],[792,6],[857,6]]},"971":{"position":[[56,6],[96,6],[138,6],[253,7],[310,6],[356,6]]},"983":{"position":[[52,6],[220,8],[266,6],[355,8],[975,6],[1069,6],[1194,6],[1225,6]]},"997":{"position":[[123,7]]},"1135":{"position":[[799,9]]},"1170":{"position":[[139,6]]}}}],["answer]\\textup{[answer]}[answ",{"_index":1006,"t":{"300":{"position":[[192,34],[307,33],[426,33]]},"304":{"position":[[355,34]]}}}],["anyth",{"_index":3069,"t":{"1024":{"position":[[186,8]]}}}],["anywher",{"_index":3156,"t":{"1047":{"position":[[151,8]]}}}],["ap",{"_index":679,"t":{"147":{"position":[[258,2],[457,2]]},"149":{"position":[[302,2],[431,2],[502,2]]},"1107":{"position":[[114,2]]},"1119":{"position":[[127,2]]},"1127":{"position":[[101,2]]}}}],["api",{"_index":2622,"t":{"850":{"position":[[68,3]]},"870":{"position":[[381,3]]},"987":{"position":[[127,3]]},"995":{"position":[[315,3]]},"997":{"position":[[50,3]]},"1003":{"position":[[463,3]]}}}],["appear",{"_index":3219,"t":{"1067":{"position":[[248,7]]},"1079":{"position":[[241,7]]}}}],["appl",{"_index":2548,"t":{"827":{"position":[[135,6],[145,6]]}}}],["appli",{"_index":346,"t":{"78":{"position":[[63,5]]}}}],["applic",{"_index":1499,"t":{"447":{"position":[[100,12]]},"721":{"position":[[43,11]]},"817":{"position":[[1045,11]]},"995":{"position":[[321,11]]}}}],["appoach",{"_index":2468,"t":{"815":{"position":[[256,7]]}}}],["approach",{"_index":831,"t":{"195":{"position":[[14,8]]},"229":{"position":[[821,8],[1054,8]]},"240":{"position":[[4,8]]},"281":{"position":[[419,8]]},"309":{"position":[[138,8]]},"418":{"position":[[147,8],[498,8],[1851,8]]},"421":{"position":[[459,8]]},"437":{"position":[[67,8]]},"455":{"position":[[685,8]]},"457":{"position":[[1319,8]]},"496":{"position":[[4,8]]},"504":{"position":[[2005,8]]},"515":{"position":[[988,8]]},"517":{"position":[[186,8]]},"525":{"position":[[749,8]]},"549":{"position":[[534,8]]},"553":{"position":[[903,8]]},"577":{"position":[[5,8]]},"614":{"position":[[152,8],[525,8]]},"616":{"position":[[362,8],[1253,8]]},"621":{"position":[[282,8]]},"623":{"position":[[242,8]]},"627":{"position":[[177,8],[1040,8]]},"644":{"position":[[25,8]]},"694":{"position":[[336,10]]},"696":{"position":[[146,8],[528,8]]},"751":{"position":[[6,8]]},"817":{"position":[[2083,8],[2132,8]]},"819":{"position":[[18,8],[471,8]]},"838":{"position":[[564,8]]},"859":{"position":[[709,8]]},"917":{"position":[[888,8]]},"1135":{"position":[[632,8]]},"1137":{"position":[[4510,8],[4682,8]]},"1160":{"position":[[64,8]]},"1198":{"position":[[442,8]]},"1226":{"position":[[57,8]]},"1240":{"position":[[41,8]]},"1242":{"position":[[144,8]]}}}],["approx",{"_index":1925,"t":{"608":{"position":[[685,7]]}}}],["approxim",{"_index":3439,"t":{"1137":{"position":[[3649,13]]}}}],["aqua",{"_index":885,"t":{"236":{"position":[[93,4]]},"240":{"position":[[161,4],[194,4]]}}}],["ar=64a_{r=64}ar=64",{"_index":1884,"t":{"604":{"position":[[19,19],[1033,19]]}}}],["ar=8,ar=64,i,j)=∣∣uar=8i⊤uar=64j∣∣f2min⁡(i,j)∈[0,1](4)\\phi",{"_index":1897,"t":{"604":{"position":[[476,60]]}}}],["ar=8a_{r=8}ar=8",{"_index":1883,"t":{"604":{"position":[[0,16],[965,16]]}}}],["arbitrari",{"_index":3001,"t":{"995":{"position":[[217,9]]}}}],["arc",{"_index":2134,"t":{"672":{"position":[[124,4]]}}}],["architectur",{"_index":144,"t":{"23":{"position":[[23,12]]},"27":{"position":[[368,12]]},"78":{"position":[[795,12]]},"84":{"position":[[24,12]]},"126":{"position":[[1039,12]]},"328":{"position":[[39,12]]},"330":{"position":[[212,12],[542,12],[1380,12]]},"349":{"position":[[288,12]]},"427":{"position":[[2718,12]]},"768":{"position":[[61,12]]},"876":{"position":[[176,12],[266,12]]},"1137":{"position":[[816,12]]}}}],["area",{"_index":569,"t":{"116":{"position":[[592,4]]}}}],["arg",{"_index":982,"t":{"286":{"position":[[261,4]]}}}],["argmax",{"_index":2739,"t":{"885":{"position":[[650,6]]}}}],["argrank",{"_index":2925,"t":{"963":{"position":[[1606,9]]}}}],["arithmar",{"_index":945,"t":{"275":{"position":[[61,11]]}}}],["arithmet",{"_index":864,"t":{"227":{"position":[[190,11]]},"229":{"position":[[66,11],[185,10],[868,11]]},"231":{"position":[[364,11]]},"233":{"position":[[5,10]]},"254":{"position":[[555,10]]},"271":{"position":[[51,10]]},"375":{"position":[[101,10]]}}}],["around",{"_index":3109,"t":{"1030":{"position":[[474,6]]}}}],["articl",{"_index":2332,"t":{"764":{"position":[[209,7]]}}}],["asdiv",{"_index":884,"t":{"236":{"position":[[62,5]]}}}],["ask",{"_index":2119,"t":{"659":{"position":[[213,4]]}}}],["assign",{"_index":2631,"t":{"850":{"position":[[1332,10]]}}}],["associ",{"_index":2216,"t":{"688":{"position":[[313,11],[542,11]]}}}],["assumpt",{"_index":2965,"t":{"977":{"position":[[179,11]]}}}],["ata_tat",{"_index":2648,"t":{"855":{"position":[[172,8]]}}}],["attemp",{"_index":1950,"t":{"619":{"position":[[686,6]]}}}],["attempt",{"_index":1936,"t":{"616":{"position":[[1386,9]]},"646":{"position":[[209,7]]},"657":{"position":[[117,7]]}}}],["atten",{"_index":568,"t":{"116":{"position":[[584,7]]}}}],["attend",{"_index":768,"t":{"176":{"position":[[332,6]]}}}],["attent",{"_index":167,"t":{"25":{"position":[[169,9]]},"86":{"position":[[30,9]]},"88":{"position":[[52,9],[92,9],[131,9],[202,9],[281,9],[391,9],[429,9],[469,9],[506,9]]},"91":{"position":[[1355,9],[2175,9]]},"93":{"position":[[64,9]]},"116":{"position":[[194,9],[606,9],[641,9],[690,9],[754,9],[773,9],[879,9]]},"153":{"position":[[508,9]]},"169":{"position":[[239,9]]},"176":{"position":[[5,9],[244,9]]},"178":{"position":[[425,9]]},"288":{"position":[[294,9]]},"302":{"position":[[820,9]]},"311":{"position":[[157,9]]},"330":{"position":[[1325,9],[1450,9]]},"343":{"position":[[264,9]]},"345":{"position":[[240,9],[271,9],[304,9],[557,9]]},"349":{"position":[[481,9],[532,9],[585,9],[668,9],[822,9]]},"355":{"position":[[120,9]]},"427":{"position":[[1221,9],[1249,9],[1399,9],[1541,9],[2177,9],[2205,9],[3183,9]]},"455":{"position":[[353,9],[660,9]]},"457":{"position":[[507,9],[540,9],[1227,9]]},"461":{"position":[[919,9]]},"463":{"position":[[153,9],[191,9],[384,9],[829,9],[1277,9],[1506,9],[2068,9],[2214,9],[2443,9]]},"467":{"position":[[17,9]]},"469":{"position":[[107,9]]},"471":{"position":[[48,9],[95,9]]},"477":{"position":[[171,9]]},"489":{"position":[[79,9],[122,9],[207,9],[244,9]]},"496":{"position":[[93,9]]},"498":{"position":[[123,9]]},"504":{"position":[[222,9]]},"508":{"position":[[287,9]]},"515":{"position":[[33,9]]},"523":{"position":[[555,9]]},"551":{"position":[[119,9]]},"569":{"position":[[45,9],[183,9]]},"585":{"position":[[5,9]]},"600":{"position":[[5,9],[58,9],[147,9]]},"619":{"position":[[746,9]]},"811":{"position":[[505,9]]},"963":{"position":[[2696,9],[2715,9],[2742,9],[2790,9],[2945,9],[3030,9],[3067,9]]},"1094":{"position":[[298,9]]},"1096":{"position":[[312,9],[1102,9]]},"1137":{"position":[[2695,9]]},"1140":{"position":[[94,9],[217,9]]},"1160":{"position":[[372,9]]}}}],["attribut",{"_index":1033,"t":{"302":{"position":[[692,11]]}}}],["auc",{"_index":3381,"t":{"1111":{"position":[[106,6]]}}}],["augment",{"_index":246,"t":{"47":{"position":[[216,15],[243,13],[267,13]]},"49":{"position":[[563,12]]},"63":{"position":[[210,12]]},"136":{"position":[[135,12]]},"138":{"position":[[68,12],[269,12]]},"145":{"position":[[27,12]]},"229":{"position":[[555,9]]},"919":{"position":[[7,12],[636,12],[791,12],[913,12]]},"933":{"position":[[110,12],[182,12]]},"955":{"position":[[267,10]]},"959":{"position":[[144,12]]},"961":{"position":[[83,12]]},"963":{"position":[[554,12],[749,12],[787,12],[3125,12],[3303,12]]},"975":{"position":[[661,12],[687,12]]}}}],["author",{"_index":55,"t":{"9":{"position":[[136,7]]},"1030":{"position":[[114,8]]}}}],["authors.yml",{"_index":57,"t":{"9":{"position":[[160,12]]}}}],["auto",{"_index":737,"t":{"169":{"position":[[208,4]]},"221":{"position":[[132,4]]},"311":{"position":[[407,4]]},"330":{"position":[[1011,4]]},"339":{"position":[[10,4]]},"893":{"position":[[86,4]]}}}],["autogress",{"_index":1756,"t":{"553":{"position":[[87,12]]}}}],["automat",{"_index":101,"t":{"17":{"position":[[85,13]]},"19":{"position":[[432,13]]},"188":{"position":[[268,9],[500,9]]},"1036":{"position":[[11,13]]}}}],["autoprompt",{"_index":2247,"t":{"694":{"position":[[389,10]]},"696":{"position":[[98,10]]},"817":{"position":[[1013,12]]},"901":{"position":[[1529,10]]},"911":{"position":[[792,10]]}}}],["autoregress",{"_index":660,"t":{"143":{"position":[[304,14]]},"159":{"position":[[496,14],[588,14]]},"180":{"position":[[27,14],[110,14]]},"286":{"position":[[68,16]]},"766":{"position":[[39,14],[577,14]]},"768":{"position":[[154,16],[423,14]]},"775":{"position":[[16,14]]},"823":{"position":[[0,14]]},"955":{"position":[[80,14]]}}}],["auxiliari",{"_index":730,"t":{"165":{"position":[[537,9]]},"169":{"position":[[517,9]]},"176":{"position":[[400,9]]},"206":{"position":[[216,9]]},"1096":{"position":[[450,9]]},"1099":{"position":[[210,9]]}}}],["avail",{"_index":3111,"t":{"1030":{"position":[[541,9]]},"1034":{"position":[[127,9]]},"1040":{"position":[[277,9]]},"1042":{"position":[[139,9]]},"1158":{"position":[[38,9]]}}}],["averag",{"_index":300,"t":{"53":{"position":[[276,7]]},"384":{"position":[[267,7],[289,8]]},"396":{"position":[[360,7]]},"840":{"position":[[718,7]]},"917":{"position":[[282,9],[717,9],[759,7]]},"963":{"position":[[539,7]]},"1096":{"position":[[1935,7]]},"1113":{"position":[[127,8],[262,8]]},"1121":{"position":[[157,8]]},"1152":{"position":[[2157,7]]}}}],["awar",{"_index":220,"t":{"38":{"position":[[59,5]]},"44":{"position":[[66,5]]},"76":{"position":[[9,5]]},"78":{"position":[[935,5]]},"91":{"position":[[1207,5]]},"1094":{"position":[[207,5]]},"1096":{"position":[[241,5]]},"1144":{"position":[[113,5]]}}}],["awesom",{"_index":3183,"t":{"1059":{"position":[[91,7],[183,7]]}}}],["a∈rr×d2a",{"_index":3422,"t":{"1137":{"position":[[1840,8]]},"1142":{"position":[[333,8]]}}}],["a∈rr×ka",{"_index":1796,"t":{"563":{"position":[[446,7]]}}}],["b",{"_index":659,"t":{"143":{"position":[[279,2]]},"197":{"position":[[363,1]]},"204":{"position":[[5,3]]},"254":{"position":[[105,1]]},"515":{"position":[[656,3],[686,1]]},"589":{"position":[[176,1]]},"642":{"position":[[198,2]]}}}],["b(0)b^{(0)}b(0",{"_index":3656,"t":{"1154":{"position":[[302,15]]},"1165":{"position":[[385,15]]}}}],["b(t",{"_index":3583,"t":{"1148":{"position":[[1755,4],[2186,4]]}}}],["b(t)b^{(t)}b(t",{"_index":3601,"t":{"1148":{"position":[[2359,15]]},"1154":{"position":[[151,15],[334,15],[368,15],[520,15],[538,15],[564,15]]},"1165":{"position":[[301,15],[403,15]]},"1172":{"position":[[317,15]]},"1192":{"position":[[439,15],[508,15]]}}}],["b/16",{"_index":557,"t":{"114":{"position":[[168,5],[257,5]]},"118":{"position":[[133,4]]},"183":{"position":[[241,4]]},"494":{"position":[[66,4]]},"1218":{"position":[[108,5]]},"1230":{"position":[[215,4]]}}}],["b/32",{"_index":556,"t":{"114":{"position":[[162,5],[251,5]]},"1218":{"position":[[98,5]]},"1230":{"position":[[205,5]]}}}],["b4",{"_index":213,"t":{"33":{"position":[[256,2]]}}}],["b7",{"_index":307,"t":{"55":{"position":[[70,2]]}}}],["b^{(0",{"_index":3659,"t":{"1154":{"position":[[443,7]]}}}],["b^{(t",{"_index":3593,"t":{"1148":{"position":[[2015,9]]}}}],["b_1)w_{f2",{"_index":3473,"t":{"1140":{"position":[[915,10]]}}}],["b_2ffn(x)=relu(xwfi​+b1​)wf2​+b2",{"_index":3474,"t":{"1140":{"position":[[928,33]]}}}],["b_{*i",{"_index":3491,"t":{"1142":{"position":[[685,6]]}}}],["ba",{"_index":3417,"t":{"1137":{"position":[[1724,3]]}}}],["baas",{"_index":2112,"t":{"644":{"position":[[82,5]]}}}],["bababa",{"_index":1817,"t":{"567":{"position":[[28,6]]},"1146":{"position":[[1545,6]]}}}],["bachmark",{"_index":2618,"t":{"848":{"position":[[603,8]]}}}],["back",{"_index":2816,"t":{"911":{"position":[[432,4]]},"1222":{"position":[[1311,4]]}}}],["backbon",{"_index":741,"t":{"169":{"position":[[412,8]]},"171":{"position":[[44,8]]},"197":{"position":[[424,8]]},"288":{"position":[[359,8]]},"738":{"position":[[115,9]]}}}],["backgroundcolor",{"_index":3192,"t":{"1061":{"position":[[169,16]]}}}],["backpropag",{"_index":818,"t":{"188":{"position":[[426,15]]},"445":{"position":[[106,15]]},"815":{"position":[[158,15]]},"819":{"position":[[1367,15]]}}}],["bad",{"_index":2287,"t":{"713":{"position":[[542,5]]},"885":{"position":[[141,6]]}}}],["balanc",{"_index":1682,"t":{"504":{"position":[[2315,8]]}}}],["bar",{"_index":3081,"t":{"1026":{"position":[[178,3]]}}}],["barack",{"_index":2381,"t":{"773":{"position":[[149,8]]}}}],["barrier",{"_index":1744,"t":{"549":{"position":[[1032,7]]}}}],["bart",{"_index":2325,"t":{"759":{"position":[[510,4]]},"768":{"position":[[80,5]]},"784":{"position":[[74,4]]},"836":{"position":[[632,4],[719,4]]},"949":{"position":[[697,4]]},"953":{"position":[[487,5]]},"963":{"position":[[2153,8]]},"983":{"position":[[85,5],[179,5]]},"1137":{"position":[[4493,4]]},"1156":{"position":[[32,4]]},"1177":{"position":[[41,4]]}}}],["bartscor",{"_index":2833,"t":{"917":{"position":[[635,9]]}}}],["base",{"_index":513,"t":{"104":{"position":[[10,5]]},"153":{"position":[[82,5]]},"183":{"position":[[211,4],[230,4]]},"199":{"position":[[74,4]]},"345":{"position":[[983,5]]},"349":{"position":[[338,5]]},"351":{"position":[[110,5]]},"416":{"position":[[142,5]]},"418":{"position":[[234,5],[753,5],[2034,5]]},"423":{"position":[[356,5]]},"437":{"position":[[12,5],[118,5]]},"589":{"position":[[80,4]]},"616":{"position":[[1312,4]]},"692":{"position":[[103,4]]},"698":{"position":[[1759,4],[1773,5]]},"700":{"position":[[5,4],[131,4],[180,4],[242,4],[283,4],[500,5],[571,5]]},"704":{"position":[[39,5],[73,5],[109,5]]},"817":{"position":[[700,5]]},"825":{"position":[[62,5]]},"832":{"position":[[662,5]]},"834":{"position":[[743,5]]},"836":{"position":[[1933,4],[2002,4]]},"850":{"position":[[1156,5]]},"855":{"position":[[83,5]]},"874":{"position":[[24,5],[137,5]]},"881":{"position":[[57,5]]},"889":{"position":[[457,5]]},"899":{"position":[[500,5],[532,5],[1044,4]]},"901":{"position":[[1011,5]]},"947":{"position":[[15,5]]},"949":{"position":[[609,5],[713,5]]},"963":{"position":[[7,5],[492,5],[1019,5],[1241,5],[1373,5],[2313,5],[2868,5]]},"965":{"position":[[7,5]]},"967":{"position":[[21,5],[99,5]]},"969":{"position":[[52,5],[102,5]]},"977":{"position":[[22,5]]},"981":{"position":[[162,5]]},"995":{"position":[[299,5]]},"1137":{"position":[[439,4],[562,4],[645,4],[4482,4]]},"1144":{"position":[[25,5]]},"1148":{"position":[[8,5]]},"1156":{"position":[[25,4]]},"1163":{"position":[[25,4]]},"1165":{"position":[[10,4]]},"1170":{"position":[[66,4]]},"1174":{"position":[[90,4]]},"1179":{"position":[[10,4],[40,5]]},"1184":{"position":[[40,4]]},"1190":{"position":[[145,5],[378,4]]},"1192":{"position":[[43,4]]}}}],["baselin",{"_index":907,"t":{"244":{"position":[[153,9]]},"250":{"position":[[146,8]]},"252":{"position":[[147,8]]},"254":{"position":[[288,8]]},"330":{"position":[[1694,8]]},"427":{"position":[[3665,8],[3793,8]]},"433":{"position":[[70,8]]},"614":{"position":[[631,8]]},"616":{"position":[[1377,8]]},"639":{"position":[[33,8]]},"646":{"position":[[9,9]]},"711":{"position":[[617,8]]},"755":{"position":[[171,8]]},"787":{"position":[[107,8]]},"827":{"position":[[217,8]]},"848":{"position":[[553,8]]},"850":{"position":[[2237,8]]},"1001":{"position":[[2070,9]]},"1135":{"position":[[905,8]]},"1165":{"position":[[69,8]]},"1167":{"position":[[32,8],[202,8]]},"1172":{"position":[[24,8]]},"1181":{"position":[[143,8]]},"1184":{"position":[[101,8]]}}}],["basic",{"_index":3061,"t":{"1024":{"position":[[26,6]]}}}],["basics/cr",{"_index":3129,"t":{"1036":{"position":[[431,13]]}}}],["batch",{"_index":164,"t":{"25":{"position":[[138,5]]},"53":{"position":[[170,5]]},"63":{"position":[[124,5]]},"104":{"position":[[242,5]]},"106":{"position":[[98,5],[145,5]]},"138":{"position":[[177,5],[297,5],[334,5]]},"343":{"position":[[612,7],[667,5],[702,5]]},"345":{"position":[[1091,5],[1185,5]]},"379":{"position":[[84,5]]},"418":{"position":[[1504,5],[1544,7],[2368,7]]},"421":{"position":[[179,7]]},"427":{"position":[[178,7],[201,7],[261,5],[352,5],[543,7],[657,7],[2472,5],[2566,7]]},"429":{"position":[[363,5]]},"431":{"position":[[477,5]]},"441":{"position":[[111,5]]},"475":{"position":[[154,5]]},"635":{"position":[[356,5],[402,5],[510,7]]},"698":{"position":[[1411,5]]},"784":{"position":[[239,5],[299,5],[641,5],[847,5],[897,5]]},"825":{"position":[[735,5]]},"1152":{"position":[[1388,5]]},"1172":{"position":[[397,5]]},"1179":{"position":[[160,5],[207,5]]},"1236":{"position":[[62,5]]}}}],["bath",{"_index":2981,"t":{"983":{"position":[[1056,5]]}}}],["bathtub",{"_index":2982,"t":{"983":{"position":[[1109,9]]}}}],["baw0​+△w=w0​+ba",{"_index":1793,"t":{"563":{"position":[[378,15]]}}}],["bax",{"_index":1811,"t":{"563":{"position":[[827,3]]},"1142":{"position":[[212,4]]}}}],["ba△w=ba",{"_index":1805,"t":{"563":{"position":[[658,7],[921,7]]}}}],["bbb",{"_index":1689,"t":{"515":{"position":[[538,3]]},"549":{"position":[[907,3]]},"563":{"position":[[597,3],[885,3]]},"1137":{"position":[[1997,3]]},"1142":{"position":[[521,3],[625,3]]},"1146":{"position":[[1832,3]]},"1190":{"position":[[221,3]]}}}],["bbd100k",{"_index":3394,"t":{"1115":{"position":[[45,7]]}}}],["bbh",{"_index":1231,"t":{"382":{"position":[[162,3]]},"384":{"position":[[18,3]]},"390":{"position":[[354,3]]},"394":{"position":[[143,3]]}}}],["bdd100k",{"_index":3399,"t":{"1117":{"position":[[12,7]]}}}],["bdd10k",{"_index":3365,"t":{"1099":{"position":[[1284,8]]}}}],["be",{"_index":1001,"t":{"298":{"position":[[114,5],[172,5]]}}}],["beam",{"_index":646,"t":{"140":{"position":[[142,4]]},"190":{"position":[[32,4],[47,4],[282,4],[374,5],[397,4]]},"784":{"position":[[745,4],[792,4]]},"1179":{"position":[[145,4],[192,4]]}}}],["beauti",{"_index":2972,"t":{"983":{"position":[[518,9],[687,9]]}}}],["bebias",{"_index":2903,"t":{"959":{"position":[[289,9]]}}}],["begin{align",{"_index":1558,"t":{"463":{"position":[[536,15]]},"515":{"position":[[577,13]]},"688":{"position":[[758,14]]}}}],["begin{array}{l",{"_index":3290,"t":{"1092":{"position":[[2049,17]]},"1094":{"position":[[482,17]]},"1096":{"position":[[2088,17]]}}}],["behavior",{"_index":2576,"t":{"836":{"position":[[2404,8],[2497,8]]}}}],["bello",{"_index":393,"t":{"88":{"position":[[401,5]]}}}],["bench",{"_index":920,"t":{"257":{"position":[[69,5]]},"259":{"position":[[77,5]]},"368":{"position":[[536,5]]},"382":{"position":[[172,5]]},"384":{"position":[[245,5]]},"388":{"position":[[182,5]]}}}],["benchmark",{"_index":1093,"t":{"328":{"position":[[726,10]]},"366":{"position":[[272,10]]},"382":{"position":[[217,9]]},"416":{"position":[[707,9]]},"850":{"position":[[2290,10]]}}}],["benefit",{"_index":958,"t":{"279":{"position":[[488,7]]}}}],["bert",{"_index":424,"t":{"91":{"position":[[754,4]]},"104":{"position":[[30,4]]},"118":{"position":[[38,4]]},"343":{"position":[[315,4]]},"517":{"position":[[49,4]]},"678":{"position":[[332,4],[397,4]]},"680":{"position":[[319,5],[1350,4],[1380,4],[1636,4],[1740,4]]},"690":{"position":[[91,4]]},"694":{"position":[[155,4],[183,4]]},"696":{"position":[[1107,4],[1220,4]]},"698":{"position":[[1754,4],[1779,4]]},"700":{"position":[[0,4],[18,4],[203,4],[278,4],[326,4],[566,4],[614,4]]},"704":{"position":[[68,4]]},"707":{"position":[[245,4]]},"736":{"position":[[120,4]]},"742":{"position":[[7,4]]},"817":{"position":[[149,4]]},"836":{"position":[[2225,4]]},"931":{"position":[[129,4]]},"981":{"position":[[20,4]]},"1094":{"position":[[742,4]]},"1104":{"position":[[83,4]]},"1137":{"position":[[60,4]]}}}],["best",{"_index":1268,"t":{"398":{"position":[[497,4]]},"423":{"position":[[98,4]]},"678":{"position":[[262,4]]},"680":{"position":[[608,4]]},"700":{"position":[[290,4]]},"702":{"position":[[486,4],[974,4]]},"704":{"position":[[173,4]]},"732":{"position":[[83,4]]},"832":{"position":[[685,4]]},"840":{"position":[[737,4]]}}}],["beta",{"_index":3031,"t":{"1001":{"position":[[1568,5],[1926,7]]}}}],["beta_1",{"_index":3637,"t":{"1152":{"position":[[1726,7],[2074,8]]}}}],["beta_1)i^{(t)}(w_{ij",{"_index":3640,"t":{"1152":{"position":[[1768,23]]}}}],["beta_2",{"_index":3642,"t":{"1152":{"position":[[1825,7],[1867,8],[2083,7]]}}}],["better",{"_index":1285,"t":{"416":{"position":[[426,6]]},"418":{"position":[[125,6]]}}}],["beyond",{"_index":2953,"t":{"969":{"position":[[6,6]]}}}],["bi",{"_index":3305,"t":{"1094":{"position":[[277,2],[315,3]]}}}],["bia",{"_index":380,"t":{"86":{"position":[[402,4],[539,4],[554,4],[651,4],[737,4],[808,4]]},"93":{"position":[[107,4]]},"97":{"position":[[470,4]]},"112":{"position":[[100,4],[503,4]]},"120":{"position":[[39,4]]},"427":{"position":[[3143,4]]},"502":{"position":[[243,4]]},"504":{"position":[[1754,4],[1820,4]]},"515":{"position":[[255,4],[427,4],[533,4],[747,4],[797,4]]},"517":{"position":[[0,4],[241,4],[299,4]]},"519":{"position":[[560,4]]},"531":{"position":[[199,4]]},"533":{"position":[[0,4],[195,4]]},"565":{"position":[[21,4]]},"579":{"position":[[0,4]]},"585":{"position":[[100,4]]},"619":{"position":[[48,4]]},"876":{"position":[[166,4],[312,4]]},"983":{"position":[[305,5],[318,5],[337,6]]},"989":{"position":[[694,4]]},"1001":{"position":[[1066,4]]},"1003":{"position":[[528,4]]},"1008":{"position":[[81,4]]},"1016":{"position":[[280,4]]},"1160":{"position":[[234,4]]}}}],["bias",{"_index":2901,"t":{"959":{"position":[[232,6]]},"1160":{"position":[[114,6]]}}}],["bicyl",{"_index":3255,"t":{"1092":{"position":[[289,7]]}}}],["bidirect",{"_index":1119,"t":{"343":{"position":[[245,13]]},"680":{"position":[[242,13]]},"694":{"position":[[625,13],[853,13]]},"696":{"position":[[450,13]]},"698":{"position":[[1689,13]]},"700":{"position":[[622,13]]},"707":{"position":[[286,13]]},"742":{"position":[[101,13]]},"768":{"position":[[104,13],[321,13]]}}}],["big",{"_index":919,"t":{"257":{"position":[[65,3]]},"259":{"position":[[73,3]]},"368":{"position":[[532,3]]},"382":{"position":[[168,3]]},"384":{"position":[[241,3]]},"388":{"position":[[178,3]]}}}],["bigotim",{"_index":2007,"t":{"631":{"position":[[470,10],[676,10]]},"633":{"position":[[379,10]]},"635":{"position":[[730,10]]}}}],["bilstm",{"_index":2781,"t":{"901":{"position":[[2142,6]]}}}],["bimod",{"_index":1103,"t":{"333":{"position":[[122,7],[258,7]]},"341":{"position":[[24,7],[125,7],[198,7]]},"345":{"position":[[140,7]]},"360":{"position":[[507,7],[598,7],[741,7]]}}}],["bin",{"_index":671,"t":{"143":{"position":[[614,4]]}}}],["binari",{"_index":651,"t":{"140":{"position":[[676,6]]},"345":{"position":[[714,6]]},"357":{"position":[[131,6]]},"850":{"position":[[332,6],[888,6],[974,6]]},"859":{"position":[[144,6]]}}}],["bioasq",{"_index":2581,"t":{"838":{"position":[[618,7]]}}}],["biomed",{"_index":2582,"t":{"838":{"position":[[628,11]]}}}],["biparit",{"_index":703,"t":{"153":{"position":[[197,8]]}}}],["bit",{"_index":518,"t":{"104":{"position":[[328,3]]},"110":{"position":[[43,3]]},"114":{"position":[[15,4],[371,3]]},"443":{"position":[[186,3],[229,4]]}}}],["bitfit",{"_index":1442,"t":{"427":{"position":[[3134,6]]},"517":{"position":[[71,6],[115,6]]},"619":{"position":[[39,6]]},"646":{"position":[[305,6]]},"1160":{"position":[[167,6]]}}}],["black",{"_index":748,"t":{"171":{"position":[[410,5]]},"963":{"position":[[1115,5]]},"1003":{"position":[[330,5]]}}}],["blackground",{"_index":1020,"t":{"302":{"position":[[222,11]]}}}],["blank",{"_index":2267,"t":{"698":{"position":[[983,5]]}}}],["bleu",{"_index":2441,"t":{"787":{"position":[[319,4]]},"791":{"position":[[312,4]]}}}],["blip",{"_index":969,"t":{"281":{"position":[[1418,5]]},"302":{"position":[[493,4]]},"311":{"position":[[36,4],[116,4]]},"484":{"position":[[197,4],[204,4]]},"537":{"position":[[212,4]]}}}],["block",{"_index":388,"t":{"88":{"position":[[170,5]]},"91":{"position":[[1371,5],[1415,5]]},"178":{"position":[[435,5]]},"349":{"position":[[508,5]]},"427":{"position":[[1912,5],[1992,5],[2096,5]]},"461":{"position":[[911,5]]},"811":{"position":[[515,5]]},"1013":{"position":[[178,5]]},"1057":{"position":[[14,6]]},"1140":{"position":[[37,6]]},"1160":{"position":[[290,6]]}}}],["blog",{"_index":21,"t":{"5":{"position":[[35,4],[87,4]]},"7":{"position":[[0,4],[111,4]]},"9":{"position":[[11,8],[48,4],[107,4],[131,4],[177,4],[286,4],[334,4],[356,4],[408,5],[450,5]]},"985":{"position":[[167,4]]},"1028":{"position":[[35,4],[57,4]]},"1030":{"position":[[524,4]]}}}],["blog/2021",{"_index":3088,"t":{"1030":{"position":[[17,9],[47,9]]}}}],["bloom",{"_index":797,"t":{"183":{"position":[[167,5]]},"322":{"position":[[47,6]]}}}],["blue",{"_index":3206,"t":{"1061":{"position":[[548,4]]}}}],["blue</highlight",{"_index":3204,"t":{"1061":{"position":[[485,16]]}}}],["boat",{"_index":1027,"t":{"302":{"position":[[343,4]]}}}],["bookqa",{"_index":1010,"t":{"300":{"position":[[615,6]]}}}],["boolq",{"_index":2099,"t":{"642":{"position":[[155,6]]},"653":{"position":[[80,6]]},"730":{"position":[[207,5]]},"751":{"position":[[274,5]]},"842":{"position":[[1801,5]]}}}],["boost",{"_index":3830,"t":{"1240":{"position":[[280,5]]}}}],["borderradiu",{"_index":3193,"t":{"1061":{"position":[[193,13]]}}}],["born",{"_index":2239,"t":{"692":{"position":[[168,4]]}}}],["both",{"_index":2586,"t":{"838":{"position":[[868,4]]}}}],["botnet",{"_index":192,"t":{"27":{"position":[[133,6]]}}}],["bottleneck",{"_index":848,"t":{"209":{"position":[[243,10]]},"557":{"position":[[340,10]]},"836":{"position":[[2115,10]]}}}],["bottom",{"_index":1934,"t":{"616":{"position":[[1224,7]]},"651":{"position":[[76,8]]},"1137":{"position":[[2769,6]]}}}],["bound",{"_index":579,"t":{"124":{"position":[[222,8]]},"126":{"position":[[408,8]]},"130":{"position":[[52,8],[496,8]]},"140":{"position":[[362,8],[451,8]]},"143":{"position":[[109,8]]},"149":{"position":[[181,8],[240,9]]},"159":{"position":[[714,8]]}}}],["box",{"_index":580,"t":{"124":{"position":[[231,3]]},"126":{"position":[[417,6]]},"130":{"position":[[61,6],[505,5]]},"140":{"position":[[371,5],[460,3]]},"143":{"position":[[118,3]]},"149":{"position":[[190,3],[250,3]]},"159":{"position":[[723,3]]},"171":{"position":[[416,3]]},"963":{"position":[[1121,3]]},"1003":{"position":[[336,3]]},"1087":{"position":[[108,3],[675,4]]},"1096":{"position":[[1369,5]]}}}],["boxinst",{"_index":3346,"t":{"1099":{"position":[[195,7]]}}}],["bpe",{"_index":3758,"t":{"1214":{"position":[[141,5]]}}}],["brach",{"_index":3345,"t":{"1099":{"position":[[178,5]]}}}],["britain",{"_index":2177,"t":{"686":{"position":[[734,7],[799,9]]}}}],["broad",{"_index":2988,"t":{"989":{"position":[[232,5]]}}}],["broadcast",{"_index":1402,"t":{"427":{"position":[[1010,13]]}}}],["brown",{"_index":927,"t":{"267":{"position":[[50,6]]},"817":{"position":[[397,6]]}}}],["bu",{"_index":2708,"t":{"876":{"position":[[1053,3]]}}}],["budget",{"_index":3406,"t":{"1135":{"position":[[346,6],[510,6],[706,6],[936,6]]},"1137":{"position":[[2945,7],[3047,6],[3201,6],[3364,6],[3433,6],[3610,6],[4582,6]]},"1148":{"position":[[134,6],[2415,6],[2506,6]]},"1154":{"position":[[46,6],[144,6],[175,6],[255,6],[295,6],[327,6],[513,6],[626,6]]},"1165":{"position":[[42,6],[130,6],[168,6],[294,6]]},"1167":{"position":[[4,6],[149,6],[238,6]]},"1172":{"position":[[14,6],[127,6]]},"1174":{"position":[[5,6],[127,6],[240,6]]},"1181":{"position":[[5,6],[118,6]]},"1184":{"position":[[13,6],[130,6],[171,6],[207,6],[270,6],[344,6]]},"1186":{"position":[[262,6]]},"1190":{"position":[[51,6]]},"1192":{"position":[[125,6],[379,6]]},"1194":{"position":[[88,6],[274,6]]}}}],["buggi",{"_index":3071,"t":{"1024":{"position":[[206,5]]}}}],["build",{"_index":128,"t":{"19":{"position":[[242,6]]},"1013":{"position":[[169,8]]},"1044":{"position":[[65,6]]},"1046":{"position":[[0,5],[40,5],[84,5]]},"1047":{"position":[[21,5],[54,5],[131,5]]},"1081":{"position":[[0,5],[47,5],[71,5],[131,5]]}}}],["busi",{"_index":2450,"t":{"793":{"position":[[420,9]]}}}],["button",{"_index":42,"t":{"7":{"position":[[123,7]]}}}],["byte",{"_index":3757,"t":{"1214":{"position":[[122,4]]}}}],["b′a′b'a'b′a",{"_index":1818,"t":{"567":{"position":[[38,12]]},"571":{"position":[[397,12]]}}}],["b∈rd1×rb",{"_index":3424,"t":{"1137":{"position":[[1888,8]]},"1142":{"position":[[381,8]]}}}],["b∈rd×rb",{"_index":1794,"t":{"563":{"position":[[403,7]]}}}],["b∗ib_{*i}b∗i",{"_index":3488,"t":{"1142":{"position":[[609,13]]}}}],["c",{"_index":411,"t":{"91":{"position":[[261,1],[1716,1]]},"171":{"position":[[589,1]]},"206":{"position":[[5,3]]},"254":{"position":[[109,1]]},"360":{"position":[[125,2],[128,4],[133,4]]},"461":{"position":[[821,2]]},"463":{"position":[[2376,2]]},"465":{"position":[[984,2]]},"1096":{"position":[[2136,1]]},"1222":{"position":[[330,1]]}}}],["c(p,e,q)\\mathcal{c",{"_index":3554,"t":{"1148":{"position":[[753,19]]}}}],["c1",{"_index":2761,"t":{"901":{"position":[[287,3]]}}}],["c1≤c≤c",{"_index":3795,"t":{"1222":{"position":[[337,7]]}}}],["c2",{"_index":2777,"t":{"901":{"position":[[1413,3]]}}}],["c3",{"_index":2779,"t":{"901":{"position":[[1905,3]]}}}],["c3,c4,c5,c6",{"_index":3263,"t":{"1092":{"position":[[1081,15]]}}}],["c3​,c4​,c5​,c6",{"_index":3268,"t":{"1092":{"position":[[1116,19]]}}}],["c=1c",{"_index":756,"t":{"171":{"position":[[632,4]]}}}],["c=3c",{"_index":758,"t":{"171":{"position":[[655,4]]}}}],["c=64c",{"_index":763,"t":{"171":{"position":[[821,5]]}}}],["c][ymin​,xmin​,ymax​,xmax​,c",{"_index":607,"t":{"130":{"position":[[656,29]]}}}],["c_3",{"_index":3264,"t":{"1092":{"position":[[1097,4]]}}}],["c_4",{"_index":3265,"t":{"1092":{"position":[[1102,4]]}}}],["c_5",{"_index":3266,"t":{"1092":{"position":[[1107,4]]}}}],["c_6",{"_index":3267,"t":{"1092":{"position":[[1112,3]]}}}],["c_{c=1}{fctext​}c=1c",{"_index":3761,"t":{"1214":{"position":[[283,24]]}}}],["c_{c=1}{vc​}c=1c",{"_index":3806,"t":{"1222":{"position":[[782,20]]},"1224":{"position":[[76,20]]}}}],["cach",{"_index":1482,"t":{"439":{"position":[[399,7]]},"445":{"position":[[154,7]]},"1200":{"position":[[717,5]]},"1205":{"position":[[378,5]]}}}],["calibr",{"_index":2967,"t":{"983":{"position":[[0,11]]}}}],["call",{"_index":3151,"t":{"1044":{"position":[[44,6]]},"1051":{"position":[[44,6]]},"1092":{"position":[[1768,5]]}}}],["callout",{"_index":3182,"t":{"1059":{"position":[[58,9]]}}}],["caltech101",{"_index":3820,"t":{"1238":{"position":[[44,10]]}}}],["capabl",{"_index":2632,"t":{"850":{"position":[[1462,12]]}}}],["capac",{"_index":1680,"t":{"504":{"position":[[1882,8]]},"727":{"position":[[439,8]]},"817":{"position":[[2068,8]]},"870":{"position":[[172,8]]}}}],["capit",{"_index":2176,"t":{"686":{"position":[[723,7],[766,7]]}}}],["caption",{"_index":584,"t":{"124":{"position":[[343,10]]},"126":{"position":[[265,10],[959,10]]},"128":{"position":[[201,10]]},"130":{"position":[[174,10],[1511,10],[1548,7]]},"140":{"position":[[777,10]]},"143":{"position":[[218,8]]},"151":{"position":[[47,10]]},"153":{"position":[[588,10],[638,7],[666,7]]},"155":{"position":[[827,10],[851,10],[937,10]]},"157":{"position":[[108,10],[428,7],[513,10]]},"165":{"position":[[98,11],[834,11]]},"180":{"position":[[313,7]]},"186":{"position":[[54,8],[67,8],[107,9],[135,7]]},"190":{"position":[[6,10],[87,10]]},"193":{"position":[[29,7],[63,7]]},"195":{"position":[[71,10],[185,7]]},"197":{"position":[[73,7],[152,7]]},"199":{"position":[[114,8]]},"215":{"position":[[62,11]]},"281":{"position":[[1137,7]]},"290":{"position":[[193,7],[317,7]]},"294":{"position":[[136,7],[161,7]]},"300":{"position":[[36,9],[539,7],[952,7],[1152,7]]},"302":{"position":[[50,8],[126,7],[318,7],[442,7],[1005,7],[1026,7],[1104,7],[1144,7],[1166,7],[1213,7]]},"304":{"position":[[57,7],[195,7],[265,10]]},"306":{"position":[[63,7]]},"311":{"position":[[12,7],[48,7],[274,7]]},"324":{"position":[[6,7]]},"455":{"position":[[536,7]]},"457":{"position":[[1112,7]]},"482":{"position":[[230,7]]},"484":{"position":[[185,7],[257,7]]},"498":{"position":[[250,7]]},"504":{"position":[[765,7],[807,7],[849,7],[1646,7],[2042,12],[2475,10]]},"512":{"position":[[26,7]]},"519":{"position":[[138,10],[381,10]]},"521":{"position":[[157,10]]},"525":{"position":[[109,10],[281,8],[392,8],[589,7],[613,7]]},"529":{"position":[[74,10],[100,7]]},"535":{"position":[[105,7],[229,10]]},"537":{"position":[[92,7],[135,10],[291,7],[421,10],[525,10]]},"541":{"position":[[106,7]]},"961":{"position":[[180,7]]},"1203":{"position":[[622,7]]}}}],["captioning/ocr",{"_index":1668,"t":{"502":{"position":[[729,15]]}}}],["captions]\\textup{[al",{"_index":1044,"t":{"304":{"position":[[228,21]]}}}],["captions]}[al",{"_index":1045,"t":{"304":{"position":[[250,14]]}}}],["captur",{"_index":742,"t":{"169":{"position":[[539,7]]},"696":{"position":[[252,7]]},"817":{"position":[[2282,7]]},"1137":{"position":[[3543,7]]}}}],["car",{"_index":329,"t":{"63":{"position":[[57,4]]}}}],["care",{"_index":3186,"t":{"1059":{"position":[[133,4],[211,4]]}}}],["case",{"_index":1728,"t":{"537":{"position":[[629,4]]},"700":{"position":[[10,5],[29,5]]},"850":{"position":[[957,5]]}}}],["catastroph",{"_index":2859,"t":{"931":{"position":[[252,12]]},"933":{"position":[[289,12]]}}}],["categori",{"_index":3128,"t":{"1036":{"position":[[382,11]]},"1085":{"position":[[116,8]]},"1087":{"position":[[124,10],[304,8],[339,8],[1134,10],[1413,8]]},"1090":{"position":[[134,8]]},"1092":{"position":[[194,8],[332,8]]},"1096":{"position":[[1718,8],[1747,8]]},"1101":{"position":[[0,8],[43,10]]},"1113":{"position":[[248,10]]},"1119":{"position":[[76,10]]}}}],["caus",{"_index":361,"t":{"78":{"position":[[684,7]]}}}],["causal",{"_index":1092,"t":{"328":{"position":[[543,6]]},"341":{"position":[[259,6]]},"345":{"position":[[228,6],[545,6]]},"347":{"position":[[413,6]]},"406":{"position":[[91,7]]},"698":{"position":[[203,6]]}}}],["caution",{"_index":3235,"t":{"1077":{"position":[[174,7]]}}}],["cb",{"_index":1323,"t":{"423":{"position":[[844,2]]},"642":{"position":[[173,2]]},"653":{"position":[[87,2]]},"702":{"position":[[1064,3]]},"751":{"position":[[310,2]]}}}],["ccc",{"_index":415,"t":{"91":{"position":[[318,3]]},"286":{"position":[[122,3]]},"461":{"position":[[317,3]]},"1214":{"position":[[36,3],[346,3],[466,3]]},"1222":{"position":[[265,3],[313,3],[531,3],[872,3]]}}}],["cd",{"_index":120,"t":{"19":{"position":[[28,2],[60,2]]}}}],["cdec",{"_index":1140,"t":{"347":{"position":[[198,6]]}}}],["cdot",{"_index":410,"t":{"91":{"position":[[255,5],[1710,5]]},"463":{"position":[[1818,5]]},"515":{"position":[[597,5],[630,5],[639,5]]},"604":{"position":[[828,5]]},"766":{"position":[[420,7]]},"784":{"position":[[318,5]]},"1152":{"position":[[2541,5]]},"1214":{"position":[[788,6],[795,5]]},"1222":{"position":[[832,5],[1294,5]]}}}],["cdots;h^{(n)}_{<i}]h<i​=[h<i(1)​;⋯;h<i(n",{"_index":2771,"t":{"901":{"position":[[769,44]]}}}],["cdots][ykeypoint",{"_index":615,"t":{"130":{"position":[[1282,17]]}}}],["central",{"_index":2597,"t":{"842":{"position":[[1521,10]]}}}],["chain",{"_index":857,"t":{"227":{"position":[[0,5],[105,5]]},"229":{"position":[[737,5],[832,5]]},"366":{"position":[[174,5]]},"368":{"position":[[152,6]]},"412":{"position":[[94,5]]},"798":{"position":[[380,5]]},"855":{"position":[[225,5]]}}}],["challeng",{"_index":924,"t":{"263":{"position":[[16,11]]},"382":{"position":[[185,11]]},"394":{"position":[[129,11]]},"408":{"position":[[44,8]]},"727":{"position":[[116,9]]},"773":{"position":[[690,11]]}}}],["chang",{"_index":121,"t":{"19":{"position":[[71,7],[464,8]]},"850":{"position":[[1305,9]]},"1024":{"position":[[61,7]]}}}],["channel",{"_index":755,"t":{"171":{"position":[[608,7]]},"465":{"position":[[356,7]]},"1092":{"position":[[853,7],[879,7]]}}}],["character",{"_index":1506,"t":{"451":{"position":[[455,16]]}}}],["chatbot",{"_index":1719,"t":{"529":{"position":[[217,7]]},"533":{"position":[[277,7],[341,7],[373,7],[455,7]]},"543":{"position":[[314,7]]}}}],["chatgpt",{"_index":1724,"t":{"533":{"position":[[581,7]]},"985":{"position":[[159,7]]},"1018":{"position":[[0,7]]},"1022":{"position":[[0,7]]}}}],["check",{"_index":94,"t":{"15":{"position":[[80,5]]}}}],["checkbox",{"_index":95,"t":{"15":{"position":[[90,10]]}}}],["checkpoint",{"_index":664,"t":{"143":{"position":[[425,10]]},"229":{"position":[[440,10],[1098,10]]},"330":{"position":[[1281,10]]},"408":{"position":[[12,10]]},"443":{"position":[[288,10],[377,10]]},"571":{"position":[[257,10]]},"825":{"position":[[30,11],[91,11],[764,10]]}}}],["children",{"_index":3190,"t":{"1061":{"position":[[129,11],[335,13],[353,10]]}}}],["choic",{"_index":890,"t":{"240":{"position":[[209,6]]},"418":{"position":[[1975,6]]},"423":{"position":[[1167,6],[1262,6]]},"425":{"position":[[407,6],[1072,6],[1110,6],[1226,6],[1251,6],[1302,6],[1471,6],[1491,6],[1923,6]]},"427":{"position":[[4060,7]]},"431":{"position":[[254,7]]},"437":{"position":[[821,6]]},"439":{"position":[[105,6]]},"451":{"position":[[285,6],[342,7]]},"489":{"position":[[171,6]]},"672":{"position":[[101,6]]},"817":{"position":[[2526,7]]},"850":{"position":[[1592,6]]},"861":{"position":[[402,6]]},"870":{"position":[[85,6]]},"889":{"position":[[64,6]]},"905":{"position":[[426,6]]},"909":{"position":[[338,6],[694,6]]},"953":{"position":[[172,6]]}}}],["cifar",{"_index":325,"t":{"63":{"position":[[27,5],[37,5]]},"65":{"position":[[14,5]]},"102":{"position":[[177,5],[290,5]]}}}],["circ",{"_index":2012,"t":{"631":{"position":[[649,5],[665,5],[728,7]]},"633":{"position":[[368,5]]},"635":{"position":[[719,5]]}}}],["cl",{"_index":1121,"t":{"343":{"position":[[355,5]]},"686":{"position":[[576,5]]},"698":{"position":[[1884,5]]},"751":{"position":[[196,5],[367,5]]},"1200":{"position":[[244,6]]},"1205":{"position":[[63,7]]},"1214":{"position":[[96,6]]},"1220":{"position":[[49,6]]},"1232":{"position":[[222,6]]}}}],["class",{"_index":425,"t":{"91":{"position":[[763,5]]},"97":{"position":[[179,5]]},"126":{"position":[[424,5]]},"130":{"position":[[68,5]]},"143":{"position":[[631,5]]},"145":{"position":[[53,5]]},"197":{"position":[[51,6]]},"633":{"position":[[1272,5]]},"819":{"position":[[85,5],[222,5],[305,5]]},"821":{"position":[[477,7],[629,7]]},"825":{"position":[[197,5]]},"832":{"position":[[313,5],[366,5],[446,5],[548,5],[656,5],[759,5],[790,5]]},"834":{"position":[[808,5]]},"836":{"position":[[1075,5]]},"842":{"position":[[1164,6],[1194,5],[1374,5],[1463,7],[1499,5]]},"887":{"position":[[169,5]]},"909":{"position":[[649,5]]},"913":{"position":[[70,5]]},"971":{"position":[[5,5],[34,5]]},"989":{"position":[[238,5]]},"1090":{"position":[[61,5],[168,5]]},"1092":{"position":[[236,5]]},"1115":{"position":[[19,5]]},"1117":{"position":[[69,5]]},"1200":{"position":[[1255,5]]},"1205":{"position":[[15,5]]},"1214":{"position":[[40,5],[186,5]]},"1222":{"position":[[269,7],[307,5],[525,5],[849,5],[879,5]]},"1224":{"position":[[135,5]]}}}],["classfic",{"_index":2488,"t":{"819":{"position":[[239,13]]}}}],["classic",{"_index":99,"t":{"17":{"position":[[41,7],[63,7],[189,7]]},"817":{"position":[[2367,7]]}}}],["classif",{"_index":199,"t":{"27":{"position":[[400,15]]},"91":{"position":[[994,14],[1038,14],[2477,14]]},"165":{"position":[[852,15]]},"190":{"position":[[184,14]]},"197":{"position":[[97,14]]},"215":{"position":[[85,14]]},"418":{"position":[[1949,14]]},"423":{"position":[[1067,15],[1208,14],[1236,14]]},"425":{"position":[[441,14],[1025,14],[1374,14]]},"451":{"position":[[591,14]]},"494":{"position":[[6,14]]},"672":{"position":[[79,15]]},"686":{"position":[[508,14]]},"716":{"position":[[27,14]]},"718":{"position":[[799,14]]},"732":{"position":[[108,14]]},"736":{"position":[[160,14]]},"744":{"position":[[121,14]]},"817":{"position":[[298,15],[1422,14]]},"819":{"position":[[108,14]]},"821":{"position":[[298,14],[370,14]]},"836":{"position":[[1133,14]]},"850":{"position":[[981,14]]},"879":{"position":[[250,14]]},"893":{"position":[[284,14]]},"895":{"position":[[333,14],[533,14]]},"901":{"position":[[2455,14]]},"905":{"position":[[272,14]]},"909":{"position":[[290,14]]},"917":{"position":[[983,14]]},"947":{"position":[[0,14],[207,14],[417,14],[514,14]]},"949":{"position":[[22,14],[156,14]]},"969":{"position":[[13,14],[74,14]]},"971":{"position":[[11,14],[103,14]]},"1163":{"position":[[100,14]]},"1200":{"position":[[1908,14]]},"1207":{"position":[[186,15]]},"1238":{"position":[[12,14]]}}}],["classifi",{"_index":1154,"t":{"357":{"position":[[138,10]]},"911":{"position":[[867,10],[905,10]]},"1087":{"position":[[1027,10],[2344,10]]},"1096":{"position":[[2536,11]]}}}],["clear",{"_index":2408,"t":{"775":{"position":[[1199,5]]}}}],["click",{"_index":47,"t":{"7":{"position":[[191,5]]},"1061":{"position":[[297,7]]}}}],["clicked!')}>click",{"_index":45,"t":{"7":{"position":[[160,17]]}}}],["clip",{"_index":760,"t":{"171":{"position":[[745,4]]},"183":{"position":[[103,5]]},"465":{"position":[[208,4]]},"482":{"position":[[65,4]]},"510":{"position":[[79,4]]},"1198":{"position":[[0,4],[183,4],[379,4],[570,4]]},"1200":{"position":[[4,4],[221,4],[427,4],[619,4],[732,4],[953,4],[1156,4],[1549,4],[1812,4],[1935,4]]},"1203":{"position":[[79,4],[548,4]]},"1205":{"position":[[224,4],[401,4]]},"1211":{"position":[[124,5],[580,4]]},"1214":{"position":[[4,4],[75,4],[213,4],[388,4],[743,4]]},"1216":{"position":[[11,4],[192,4],[229,4],[627,4]]},"1218":{"position":[[0,4],[127,4],[273,4],[314,4]]},"1220":{"position":[[4,4]]},"1222":{"position":[[4,4],[197,5],[695,4],[805,4]]},"1224":{"position":[[99,4],[180,4]]},"1226":{"position":[[3,4]]},"1230":{"position":[[15,4],[66,4],[260,4],[359,5]]},"1232":{"position":[[0,4],[68,4]]},"1240":{"position":[[69,4],[170,4],[218,4],[253,4]]},"1242":{"position":[[70,4],[103,4]]}}}],["clipcap",{"_index":1065,"t":{"313":{"position":[[208,7]]},"484":{"position":[[269,7]]}}}],["clipclap",{"_index":1076,"t":{"320":{"position":[[195,8]]}}}],["clm",{"_index":1105,"t":{"335":{"position":[[120,3]]},"339":{"position":[[235,5],[294,5]]},"355":{"position":[[27,5]]},"362":{"position":[[583,3],[709,5],[786,4],[839,4],[895,3]]}}}],["close",{"_index":823,"t":{"190":{"position":[[258,6],[432,5],[543,5]]},"535":{"position":[[48,5]]},"883":{"position":[[631,5]]},"893":{"position":[[3,5],[176,5],[236,5]]},"895":{"position":[[110,5]]},"905":{"position":[[147,5]]},"927":{"position":[[64,5]]},"943":{"position":[[154,5]]},"947":{"position":[[235,5],[537,5]]},"1055":{"position":[[289,5]]}}}],["cloud",{"_index":1181,"t":{"362":{"position":[[437,5]]}}}],["cloze",{"_index":1321,"t":{"423":{"position":[[794,5]]},"692":{"position":[[129,5]]},"704":{"position":[[203,5]]},"821":{"position":[[336,5]]},"895":{"position":[[299,5]]}}}],["cluster",{"_index":2594,"t":{"842":{"position":[[491,8],[763,7],[976,7],[995,7],[1122,10]]}}}],["cnn",{"_index":376,"t":{"84":{"position":[[68,3]]},"86":{"position":[[9,3],[65,3]]},"88":{"position":[[377,3],[451,3],[495,3],[611,3]]},"93":{"position":[[0,3],[89,4]]},"95":{"position":[[34,3],[127,3],[288,3]]},"104":{"position":[[203,3]]},"110":{"position":[[22,3]]},"116":{"position":[[361,3],[711,3],[798,3]]},"153":{"position":[[57,3],[121,3],[146,3],[355,3],[459,3],[555,3]]}}}],["cnn/dailymail",{"_index":3450,"t":{"1137":{"position":[[4538,14]]},"1156":{"position":[[127,14]]},"1177":{"position":[[108,14]]},"1179":{"position":[[171,13]]}}}],["co",{"_index":67,"t":{"9":{"position":[[324,2]]},"698":{"position":[[179,2]]},"1030":{"position":[[150,2]]}}}],["coars",{"_index":1034,"t":{"302":{"position":[[749,6]]},"1092":{"position":[[1516,6],[1719,6]]}}}],["coco",{"_index":655,"t":{"143":{"position":[[34,4],[444,4],[488,4]]},"157":{"position":[[141,4]]},"186":{"position":[[15,4]]},"193":{"position":[[24,4],[58,4]]},"455":{"position":[[531,4]]},"457":{"position":[[1107,4]]},"482":{"position":[[225,4]]},"484":{"position":[[180,4]]},"498":{"position":[[245,4]]},"504":{"position":[[760,4]]},"512":{"position":[[21,4]]},"525":{"position":[[608,4]]},"529":{"position":[[95,4]]},"537":{"position":[[87,4]]},"1092":{"position":[[264,4]]},"1099":{"position":[[563,4],[1204,5]]},"1107":{"position":[[10,4]]},"1123":{"position":[[37,6]]}}}],["code",{"_index":114,"t":{"17":{"position":[[307,4]]},"80":{"position":[[85,4]]},"328":{"position":[[3,4],[319,4],[474,4],[527,4],[713,4],[804,4],[859,4],[886,4]]},"330":{"position":[[229,4],[332,4],[387,4],[1126,4],[1252,4],[1569,4]]},"333":{"position":[[0,4],[51,4],[308,4]]},"335":{"position":[[84,4],[157,4]]},"341":{"position":[[19,4],[64,4],[72,4]]},"343":{"position":[[17,4],[78,4],[109,4],[158,4],[230,4],[433,4]]},"345":{"position":[[33,4],[86,4],[181,4],[417,4],[464,4],[515,4],[655,4],[795,4]]},"347":{"position":[[46,4],[53,4],[238,4],[288,4],[425,4]]},"353":{"position":[[34,4],[130,4],[155,4]]},"355":{"position":[[230,4]]},"357":{"position":[[194,4],[224,4]]},"360":{"position":[[14,4],[500,4],[520,4],[806,4],[829,4]]},"696":{"position":[[973,6]]},"848":{"position":[[522,7],[596,6]]},"850":{"position":[[2274,4]]},"870":{"position":[[319,4]]},"1057":{"position":[[9,4]]}}}],["code/text",{"_index":1136,"t":{"345":{"position":[[1103,9]]}}}],["codegen",{"_index":1171,"t":{"362":{"position":[[124,7],[174,7],[223,7],[377,7]]}}}],["codesearchnet",{"_index":1155,"t":{"360":{"position":[[30,13],[231,13],[449,13],[584,13],[725,13]]}}}],["codet",{"_index":1101,"t":{"330":{"position":[[1661,6]]},"335":{"position":[[4,6]]}}}],["codet5",{"_index":1087,"t":{"328":{"position":[[358,7],[605,7],[698,7]]},"330":{"position":[[1172,7],[1223,7],[1584,7]]},"333":{"position":[[63,7],[101,7]]},"349":{"position":[[45,7]]},"351":{"position":[[22,7]]},"353":{"position":[[24,7]]},"355":{"position":[[258,7]]},"357":{"position":[[0,7]]},"360":{"position":[[378,6],[709,6],[755,7]]},"362":{"position":[[4,7],[41,7],[92,7],[244,7],[363,6],[460,8],[1151,7],[1230,7]]}}}],["codex",{"_index":904,"t":{"242":{"position":[[105,5]]}}}],["coeffici",{"_index":3565,"t":{"1148":{"position":[[1106,11]]},"1165":{"position":[[446,11]]}}}],["coffe",{"_index":2329,"t":{"761":{"position":[[1044,6],[1109,8]]}}}],["coin",{"_index":934,"t":{"269":{"position":[[221,4]]}}}],["cola",{"_index":2100,"t":{"642":{"position":[[188,5]]},"1186":{"position":[[219,5]]}}}],["collect",{"_index":1333,"t":{"423":{"position":[[1045,10]]}}}],["coloc",{"_index":3172,"t":{"1055":{"position":[[273,8]]}}}],["color",{"_index":3191,"t":{"1061":{"position":[[141,7],[186,6],[215,6],[309,5],[315,8]]}}}],["color=\"#1877f2\">facebook",{"_index":3203,"t":{"1061":{"position":[[460,24]]}}}],["color=\"#25c2a0\">docusauru",{"_index":3201,"t":{"1061":{"position":[[394,26]]}}}],["column",{"_index":1907,"t":{"604":{"position":[[809,7]]},"777":{"position":[[438,6]]},"1142":{"position":[[638,7]]}}}],["comapr",{"_index":2602,"t":{"844":{"position":[[70,10]]}}}],["comb",{"_index":2314,"t":{"744":{"position":[[46,7]]}}}],["combin",{"_index":392,"t":{"88":{"position":[[365,11]]},"437":{"position":[[872,8]]},"680":{"position":[[352,9]]}}}],["command",{"_index":104,"t":{"17":{"position":[[142,8],[215,7],[228,7],[324,7]]},"19":{"position":[[63,7],[234,7]]}}}],["comment",{"_index":26,"t":{"5":{"position":[[70,7]]}}}],["common",{"_index":1297,"t":{"418":{"position":[[140,6]]},"606":{"position":[[198,6]]},"832":{"position":[[233,8]]},"834":{"position":[[860,6]]},"850":{"position":[[942,6]]},"983":{"position":[[324,6]]}}}],["commons",{"_index":962,"t":{"281":{"position":[[366,11]]}}}],["commonsens",{"_index":865,"t":{"227":{"position":[[202,11]]},"229":{"position":[[78,11],[880,11]]},"231":{"position":[[376,11]]},"271":{"position":[[129,11]]},"275":{"position":[[73,11]]},"672":{"position":[[147,11]]},"951":{"position":[[90,11]]}}}],["commonsenseqa",{"_index":1011,"t":{"300":{"position":[[622,13]]}}}],["commun",{"_index":3086,"t":{"1026":{"position":[[258,9]]}}}],["compact",{"_index":1443,"t":{"427":{"position":[[3256,9],[3268,11],[3907,9],[3919,11]]}}}],["compar",{"_index":1517,"t":{"457":{"position":[[720,10],[1127,10]]},"477":{"position":[[55,10]]},"498":{"position":[[52,10],[260,10]]},"510":{"position":[[351,10]]},"537":{"position":[[219,10]]},"680":{"position":[[1643,10]]},"700":{"position":[[315,10],[410,11],[585,10]]},"707":{"position":[[252,10]]},"713":{"position":[[1083,10]]},"718":{"position":[[838,10]]},"723":{"position":[[71,10]]},"746":{"position":[[343,10],[443,10]]},"755":{"position":[[87,10]]},"787":{"position":[[186,10],[400,10]]},"815":{"position":[[371,10]]},"817":{"position":[[1960,10],[2505,10]]},"827":{"position":[[387,10]]},"844":{"position":[[150,10]]},"1137":{"position":[[746,10]]}}}],["competit",{"_index":2549,"t":{"827":{"position":[[205,11]]}}}],["compil",{"_index":2634,"t":{"850":{"position":[[1701,8]]}}}],["complementar",{"_index":2915,"t":{"963":{"position":[[89,20]]}}}],["complet",{"_index":1153,"t":{"355":{"position":[[235,10]]},"423":{"position":[[761,10]]},"842":{"position":[[788,10],[847,10],[914,10]]}}}],["complex",{"_index":863,"t":{"227":{"position":[[69,7]]},"398":{"position":[[66,7],[141,8]]},"408":{"position":[[172,8]]}}}],["complic",{"_index":3632,"t":{"1152":{"position":[[1442,11]]}}}],["compon",{"_index":734,"t":{"165":{"position":[[787,10]]},"171":{"position":[[117,10]]},"199":{"position":[[47,9]]},"215":{"position":[[37,10]]},"328":{"position":[[271,9]]},"349":{"position":[[55,9]]},"463":{"position":[[1090,9],[1667,9]]},"633":{"position":[[72,9]]},"662":{"position":[[158,10],[295,9]]},"664":{"position":[[25,9]]},"668":{"position":[[66,9],[171,9],[260,9]]},"674":{"position":[[279,9]]},"855":{"position":[[426,9]]},"857":{"position":[[32,9]]},"861":{"position":[[300,10]]},"863":{"position":[[609,9]]},"870":{"position":[[293,9]]},"1061":{"position":[[76,10]]},"1190":{"position":[[12,10],[534,9]]}}}],["composit",{"_index":2853,"t":{"921":{"position":[[7,11],[70,9]]},"975":{"position":[[392,11],[628,11]]}}}],["comprehens",{"_index":1702,"t":{"517":{"position":[[155,13]]},"1085":{"position":[[695,14]]},"1087":{"position":[[409,13]]}}}],["compress",{"_index":1951,"t":{"623":{"position":[[58,12]]}}}],["comput",{"_index":305,"t":{"55":{"position":[[16,9]]},"124":{"position":[[35,8],[129,8]]},"126":{"position":[[308,8],[342,8]]},"128":{"position":[[4,8]]},"250":{"position":[[179,7]]},"349":{"position":[[122,7]]},"396":{"position":[[748,7]]},"416":{"position":[[450,13]]},"418":{"position":[[2335,7]]},"421":{"position":[[35,13],[119,13]]},"427":{"position":[[291,13],[2957,13]]},"437":{"position":[[533,13]]},"439":{"position":[[416,13]]},"451":{"position":[[43,13],[424,13]]},"773":{"position":[[1041,11]]},"1135":{"position":[[733,12]]},"1137":{"position":[[1314,11],[3596,13],[4296,12]]},"1146":{"position":[[1431,11],[1450,13]]}}}],["computation",{"_index":2383,"t":{"773":{"position":[[674,15]]}}}],["concaten",{"_index":933,"t":{"269":{"position":[[153,13]]}}}],["conceptnet",{"_index":975,"t":{"284":{"position":[[189,10]]}}}],["conceptu",{"_index":802,"t":{"186":{"position":[[43,10],[76,10]]},"199":{"position":[[103,10]]}}}],["condid",{"_index":3778,"t":{"1216":{"position":[[509,10]]}}}],["condit",{"_index":787,"t":{"180":{"position":[[334,12]]},"627":{"position":[[218,11]]},"817":{"position":[[804,12]]},"819":{"position":[[166,11],[431,9],[1246,11]]},"834":{"position":[[120,9]]},"879":{"position":[[481,11]]}}}],["conference.pdf",{"_index":856,"t":{"225":{"position":[[112,14]]}}}],["confid",{"_index":3740,"t":{"1200":{"position":[[1385,10]]},"1211":{"position":[[237,10],[346,10]]},"1216":{"position":[[163,9],[635,10],[755,9]]},"1232":{"position":[[261,9]]}}}],["config",{"_index":76,"t":{"9":{"position":[[481,7]]}}}],["configur",{"_index":2543,"t":{"825":{"position":[[137,13]]},"1026":{"position":[[49,13]]}}}],["congratul",{"_index":3107,"t":{"1030":{"position":[[408,16]]}}}],["coninu",{"_index":2569,"t":{"836":{"position":[[1287,9]]}}}],["conll04",{"_index":2306,"t":{"730":{"position":[[151,8]]}}}],["conll12",{"_index":2307,"t":{"730":{"position":[[215,8]]}}}],["connect",{"_index":440,"t":{"91":{"position":[[1437,10]]},"178":{"position":[[293,10]]},"209":{"position":[[60,10]]},"281":{"position":[[1523,7]]},"585":{"position":[[26,10],[82,9]]},"1032":{"position":[[30,9]]},"1140":{"position":[[117,9],[1091,10]]},"1160":{"position":[[424,10]]}}}],["connet",{"_index":166,"t":{"25":{"position":[[161,7]]}}}],["consectetur",{"_index":5,"t":{"3":{"position":[[28,11]]},"5":{"position":[[148,11],[327,11],[506,11],[685,11],[864,11],[1043,11],[1222,11],[1401,11],[1580,11],[1759,11],[1938,11],[2117,11],[2296,11],[2475,11],[2654,11],[2833,11]]}}}],["consequat",{"_index":17,"t":{"3":{"position":[[141,10]]},"5":{"position":[[261,10],[440,10],[619,10],[798,10],[977,10],[1156,10],[1335,10],[1514,10],[1693,10],[1872,10],[2051,10],[2230,10],[2409,10],[2588,10],[2767,10],[2946,10]]}}}],["consist",{"_index":1244,"t":{"390":{"position":[[107,12]]}}}],["const",{"_index":3189,"t":{"1061":{"position":[[111,5]]}}}],["constrain",{"_index":2795,"t":{"909":{"position":[[264,11]]}}}],["construct",{"_index":2912,"t":{"959":{"position":[[782,12]]}}}],["cont",{"_index":1251,"t":{"396":{"position":[[206,4]]}}}],["contain",{"_index":2904,"t":{"959":{"position":[[392,8]]}}}],["content",{"_index":1729,"t":{"539":{"position":[[21,7]]},"541":{"position":[[167,8]]},"791":{"position":[[463,7]]},"823":{"position":[[206,7]]},"1075":{"position":[[86,7],[151,7],[217,7]]}}}],["context",{"_index":837,"t":{"197":{"position":[[202,7]]},"217":{"position":[[13,7],[109,7]]},"229":{"position":[[381,7]]},"238":{"position":[[35,7]]},"290":{"position":[[212,7],[355,7],[388,7]]},"292":{"position":[[419,7],[712,7]]},"294":{"position":[[16,7]]},"300":{"position":[[227,8],[397,7],[772,7]]},"304":{"position":[[185,9],[212,10]]},"333":{"position":[[433,7]]},"335":{"position":[[162,7]]},"339":{"position":[[70,7]]},"345":{"position":[[603,7]]},"355":{"position":[[68,7]]},"398":{"position":[[56,9]]},"416":{"position":[[12,7]]},"418":{"position":[[512,7]]},"437":{"position":[[957,7]]},"439":{"position":[[347,7]]},"443":{"position":[[152,7]]},"465":{"position":[[150,7],[1050,7]]},"525":{"position":[[532,7],[579,7]]},"533":{"position":[[253,7]]},"539":{"position":[[126,7],[228,7]]},"541":{"position":[[82,8]]},"553":{"position":[[154,7]]},"686":{"position":[[324,7],[612,7],[791,7],[834,7]]},"761":{"position":[[651,7],[687,7],[841,7],[883,7]]},"764":{"position":[[12,7]]},"766":{"position":[[616,7]]},"768":{"position":[[199,7]]},"773":{"position":[[50,7],[123,7],[268,7],[287,7],[443,7],[565,7]]},"775":{"position":[[1287,7]]},"842":{"position":[[1979,7]]},"850":{"position":[[435,7]]},"855":{"position":[[404,7]]},"857":{"position":[[122,7]]},"861":{"position":[[314,7]]},"863":{"position":[[722,7]]},"919":{"position":[[817,7],[964,7]]},"933":{"position":[[131,7],[389,7]]},"945":{"position":[[178,7]]},"953":{"position":[[26,7],[123,7],[349,7]]},"955":{"position":[[210,7]]},"963":{"position":[[672,7],[834,7]]},"983":{"position":[[434,7],[838,7],[1256,7]]},"1003":{"position":[[22,7]]},"1094":{"position":[[140,8]]}}}],["context]\\textup{[context]}[context",{"_index":1007,"t":{"300":{"position":[[236,37],[358,36],[478,36]]}}}],["contextsquestionoptionansw",{"_index":1609,"t":{"465":{"position":[[114,28]]},"482":{"position":[[258,28]]}}}],["contextu",{"_index":992,"t":{"292":{"position":[[264,10]]},"461":{"position":[[952,10]]},"836":{"position":[[518,13]]},"911":{"position":[[817,14]]}}}],["continu",{"_index":1120,"t":{"343":{"position":[[279,10]]},"396":{"position":[[627,9],[690,9]]},"616":{"position":[[279,10]]},"619":{"position":[[203,10]]},"678":{"position":[[111,10]]},"680":{"position":[[853,10],[949,10],[999,10],[1070,10]]},"682":{"position":[[483,10]]},"686":{"position":[[1787,10],[1864,10]]},"688":{"position":[[0,10],[1010,10]]},"696":{"position":[[730,10],[1070,10]]},"707":{"position":[[19,10]]},"711":{"position":[[54,10]]},"713":{"position":[[754,10],[845,10],[1286,10],[1328,10]]},"718":{"position":[[525,10],[557,10]]},"727":{"position":[[37,10]]},"734":{"position":[[49,10]]},"738":{"position":[[240,10]]},"744":{"position":[[144,10]]},"753":{"position":[[62,10]]},"759":{"position":[[296,10]]},"761":{"position":[[1142,10]]},"773":{"position":[[743,10]]},"798":{"position":[[18,10]]},"823":{"position":[[1563,12]]},"836":{"position":[[0,10],[1491,10]]},"842":{"position":[[153,10]]},"883":{"position":[[729,10],[772,10]]},"897":{"position":[[245,10]]},"901":{"position":[[0,10],[332,10],[993,10],[1494,10],[1877,10],[2040,10]]},"917":{"position":[[95,10]]},"943":{"position":[[335,10]]},"961":{"position":[[106,10]]},"1200":{"position":[[580,10]]},"1205":{"position":[[163,10]]},"1207":{"position":[[466,10],[609,10]]},"1220":{"position":[[252,10]]},"1222":{"position":[[350,10]]}}}],["contol",{"_index":2940,"t":{"963":{"position":[[2596,9]]}}}],["contour",{"_index":3389,"t":{"1113":{"position":[[95,7]]},"1121":{"position":[[125,7]]}}}],["contras",{"_index":1091,"t":{"328":{"position":[[501,10]]}}}],["contrast",{"_index":1098,"t":{"330":{"position":[[1089,11]]},"341":{"position":[[226,11]]},"345":{"position":[[971,11]]},"1198":{"position":[[33,11]]},"1203":{"position":[[495,11]]}}}],["contribut",{"_index":972,"t":{"281":{"position":[[1838,12]]},"850":{"position":[[1885,12]]},"1200":{"position":[[1660,12]]}}}],["control",{"_index":1021,"t":{"302":{"position":[[255,7]]},"463":{"position":[[1544,7]]},"963":{"position":[[1656,10],[2105,11],[2282,10],[2340,7]]}}}],["conv1x1",{"_index":211,"t":{"33":{"position":[[153,7]]}}}],["conv3x3",{"_index":210,"t":{"33":{"position":[[143,7],[178,7]]}}}],["conveni",{"_index":66,"t":{"9":{"position":[[310,10]]}}}],["convers",{"_index":1139,"t":{"347":{"position":[[87,10]]},"529":{"position":[[192,12]]},"533":{"position":[[308,12]]},"573":{"position":[[130,13]]}}}],["convnet",{"_index":626,"t":{"132":{"position":[[213,8]]}}}],["convnext",{"_index":3373,"t":{"1104":{"position":[[29,8]]}}}],["convolut",{"_index":148,"t":{"23":{"position":[[91,11]]},"25":{"position":[[306,11]]},"33":{"position":[[30,11],[52,11]]},"38":{"position":[[169,11]]},"78":{"position":[[108,12]]},"104":{"position":[[299,11]]},"112":{"position":[[481,11]]},"116":{"position":[[807,13]]},"174":{"position":[[34,11],[77,11],[149,13],[381,13]]}}}],["coop",{"_index":3733,"t":{"1198":{"position":[[177,5],[656,4]]},"1200":{"position":[[421,5],[551,4],[1981,4]]},"1205":{"position":[[156,4]]},"1211":{"position":[[371,4]]},"1220":{"position":[[197,4],[301,4]]},"1240":{"position":[[113,6],[303,4]]},"1242":{"position":[[97,5]]}}}],["coordin",{"_index":670,"t":{"143":{"position":[[590,10]]},"563":{"position":[[705,10]]}}}],["cop",{"_index":683,"t":{"149":{"position":[[32,6]]}}}],["copa",{"_index":1318,"t":{"423":{"position":[[772,6]]}}}],["copi",{"_index":2281,"t":{"713":{"position":[[272,4],[633,4]]},"759":{"position":[[150,4]]},"761":{"position":[[192,4],[1438,4],[1500,4]]},"775":{"position":[[1187,4]]},"817":{"position":[[641,4]]},"1065":{"position":[[94,6]]},"1075":{"position":[[0,4]]},"1137":{"position":[[251,4]]}}}],["cordonni",{"_index":390,"t":{"88":{"position":[[250,10]]}}}],["core",{"_index":2621,"t":{"850":{"position":[[12,4]]}}}],["corefer",{"_index":1325,"t":{"423":{"position":[[854,11]]}}}],["corpora",{"_index":2464,"t":{"811":{"position":[[105,7]]}}}],["corpu",{"_index":1313,"t":{"423":{"position":[[160,6]]},"682":{"position":[[410,6]]},"832":{"position":[[288,6]]},"899":{"position":[[118,6]]},"963":{"position":[[3052,6]]}}}],["correct",{"_index":1346,"t":{"425":{"position":[[263,7],[1102,7],[1908,7]]},"437":{"position":[[979,7]]},"819":{"position":[[523,7]]}}}],["correct/incorrect",{"_index":1352,"t":{"425":{"position":[[389,17]]}}}],["corrupt",{"_index":1276,"t":{"406":{"position":[[108,10],[138,12]]},"823":{"position":[[67,10],[816,10],[958,10],[1218,10],[1315,10]]},"834":{"position":[[90,10],[346,10],[492,10],[695,10],[1030,10]]}}}],["cosin",{"_index":332,"t":{"63":{"position":[[145,6]]},"659":{"position":[[164,6],[321,6]]},"832":{"position":[[859,6]]},"842":{"position":[[397,6]]},"1001":{"position":[[252,6]]},"1214":{"position":[[810,6]]},"1236":{"position":[[13,6]]}}}],["cost",{"_index":1287,"t":{"416":{"position":[[464,4]]},"421":{"position":[[49,4],[143,4]]},"427":{"position":[[58,4],[2971,4]]},"437":{"position":[[84,4],[547,4],[588,5],[657,4]]},"439":{"position":[[48,5],[430,4],[477,5]]},"441":{"position":[[51,4],[339,4]]},"443":{"position":[[21,4]]},"451":{"position":[[57,4],[438,5]]},"455":{"position":[[242,4]]},"502":{"position":[[759,4]]},"821":{"position":[[705,4]]},"836":{"position":[[1759,4]]},"840":{"position":[[163,4]]},"844":{"position":[[452,4]]},"1047":{"position":[[191,4]]},"1148":{"position":[[748,4]]}}}],["cot",{"_index":869,"t":{"227":{"position":[[278,3]]},"229":{"position":[[980,3]]},"231":{"position":[[134,3],[175,3],[211,3],[293,3],[356,3],[425,3],[433,3]]},"233":{"position":[[53,3]]},"240":{"position":[[58,3],[147,3],[184,3]]},"244":{"position":[[0,3],[103,3],[110,3],[277,3],[346,3],[375,3],[436,3],[466,3]]},"246":{"position":[[0,3]]},"248":{"position":[[0,3],[149,3]]},"250":{"position":[[0,3],[82,3],[197,3]]},"252":{"position":[[0,3],[72,3],[126,3],[171,3]]},"254":{"position":[[23,3],[48,3],[119,3],[134,3],[147,3],[260,3],[306,3],[341,3],[422,3],[522,4],[581,3]]},"259":{"position":[[43,3],[122,3],[178,3]]},"261":{"position":[[57,3],[108,3]]},"263":{"position":[[0,3]]},"269":{"position":[[282,3],[316,3],[442,3],[482,3]]},"271":{"position":[[32,3],[147,3],[310,3],[348,3],[408,3],[457,3],[569,3],[622,3]]},"273":{"position":[[345,3]]},"275":{"position":[[0,3],[100,3],[133,3]]},"366":{"position":[[255,5]]},"368":{"position":[[148,3],[206,3],[226,3],[301,3],[477,3]]},"373":{"position":[[197,3]]},"375":{"position":[[0,3],[23,3]]},"377":{"position":[[68,3]]},"384":{"position":[[71,3],[216,3]]},"386":{"position":[[76,4]]},"388":{"position":[[33,3],[94,3],[121,3],[157,3]]},"390":{"position":[[4,3],[85,3],[208,3],[256,3],[369,3]]},"392":{"position":[[36,3],[54,3],[64,3],[89,3],[132,3],[181,3],[231,3],[254,3],[334,4],[339,5],[391,3],[397,3]]},"394":{"position":[[25,3],[90,3],[202,3]]},"398":{"position":[[188,3],[234,3],[714,3]]},"400":{"position":[[65,3],[138,3]]},"404":{"position":[[0,3],[49,3],[67,3],[114,3],[153,3],[159,3],[196,3],[214,3],[237,3],[285,3]]},"408":{"position":[[204,5]]},"412":{"position":[[111,5],[172,3],[197,3],[232,3]]}}}],["count",{"_index":726,"t":{"165":{"position":[[188,9]]}}}],["cp",{"_index":3230,"t":{"1075":{"position":[[108,2]]}}}],["craft",{"_index":3737,"t":{"1200":{"position":[[362,7],[563,7],[1101,7]]},"1211":{"position":[[528,7]]},"1220":{"position":[[209,7]]},"1232":{"position":[[33,7]]}}}],["creat",{"_index":40,"t":{"7":{"position":[[92,6]]},"13":{"position":[[15,8]]},"19":{"position":[[147,7]]},"1028":{"position":[[11,7]]},"1030":{"position":[[0,6]]},"1034":{"position":[[0,6]]},"1036":{"position":[[25,7],[259,6]]},"1038":{"position":[[44,6]]},"1040":{"position":[[0,6]]},"1042":{"position":[[0,6]]},"1053":{"position":[[95,7],[145,7],[207,6]]},"1059":{"position":[[35,6]]},"1065":{"position":[[154,8]]}}}],["creativ",{"_index":1257,"t":{"398":{"position":[[28,12]]}}}],["creator",{"_index":3097,"t":{"1030":{"position":[[153,7]]}}}],["credit",{"_index":2630,"t":{"850":{"position":[[1325,6]]}}}],["criteria",{"_index":2657,"t":{"857":{"position":[[404,8]]}}}],["criterion",{"_index":3606,"t":{"1150":{"position":[[208,9]]}}}],["critic",{"_index":3437,"t":{"1137":{"position":[[3448,8]]}}}],["croiss",{"_index":1036,"t":{"302":{"position":[[813,6]]}}}],["crop",{"_index":681,"t":{"147":{"position":[[354,7],[396,7]]},"149":{"position":[[217,4],[235,4]]},"155":{"position":[[500,7]]}}}],["cross",{"_index":738,"t":{"169":{"position":[[233,5]]},"176":{"position":[[326,5]]},"178":{"position":[[419,5]]},"193":{"position":[[3,5]]},"288":{"position":[[253,5],[288,5]]},"311":{"position":[[151,5]]},"330":{"position":[[1319,5],[1444,5]]},"333":{"position":[[288,5]]},"341":{"position":[[147,5],[214,5]]},"345":{"position":[[298,5],[660,5]]},"347":{"position":[[103,5]]},"349":{"position":[[526,5],[579,5],[662,5],[816,5]]},"355":{"position":[[114,5]]},"425":{"position":[[92,5],[1879,5]]},"614":{"position":[[221,5]]},"623":{"position":[[308,5]]},"633":{"position":[[520,5]]},"659":{"position":[[29,5]]},"662":{"position":[[336,5]]},"825":{"position":[[662,5]]},"1094":{"position":[[292,5]]},"1222":{"position":[[1235,5]]}}}],["crow",{"_index":3048,"t":{"1003":{"position":[[513,5]]}}}],["crowspair",{"_index":2995,"t":{"989":{"position":[[802,10]]}}}],["crucial",{"_index":3721,"t":{"1186":{"position":[[113,7]]},"1192":{"position":[[300,7]]}}}],["csqa",{"_index":916,"t":{"257":{"position":[[0,4]]},"259":{"position":[[0,4]]}}}],["css",{"_index":3154,"t":{"1044":{"position":[[120,3]]}}}],["cubic",{"_index":3662,"t":{"1154":{"position":[[591,5]]}}}],["cue",{"_index":2645,"t":{"853":{"position":[[211,4]]}}}],["current",{"_index":973,"t":{"281":{"position":[[1865,7]]},"292":{"position":[[693,7]]},"304":{"position":[[396,7]]},"855":{"position":[[115,7]]},"859":{"position":[[199,7]]},"1055":{"position":[[220,7]]},"1065":{"position":[[254,7]]}}}],["curriculum",{"_index":197,"t":{"27":{"position":[[300,10]]}}}],["cursor",{"_index":3198,"t":{"1061":{"position":[[247,7]]}}}],["curv",{"_index":938,"t":{"269":{"position":[[453,6]]},"271":{"position":[[279,6],[341,6]]},"275":{"position":[[196,6]]},"402":{"position":[[90,5]]},"489":{"position":[[224,6]]},"1111":{"position":[[100,5]]}}}],["custom",{"_index":3079,"t":{"1026":{"position":[[140,6]]},"1036":{"position":[[81,9]]},"1051":{"position":[[165,6]]}}}],["cvpr",{"_index":947,"t":{"277":{"position":[[48,4]]}}}],["c}im​∈r1×c",{"_index":1615,"t":{"465":{"position":[[323,10]]}}}],["c}ip​∈r1×c",{"_index":1625,"t":{"465":{"position":[[647,10]]}}}],["c}pl​∈rk×c",{"_index":1528,"t":{"461":{"position":[[273,10]]}}}],["c}rh×w×c",{"_index":750,"t":{"171":{"position":[[548,8]]}}}],["c}ti​∈rm×c",{"_index":1537,"t":{"461":{"position":[[599,10]]}}}],["c}tl​∈r1×c",{"_index":1551,"t":{"463":{"position":[[338,10]]}}}],["c}x∈rh×w×c",{"_index":405,"t":{"91":{"position":[[163,10]]}}}],["d",{"_index":1801,"t":{"563":{"position":[[521,3]]},"637":{"position":[[218,2],[392,2]]},"834":{"position":[[10,2]]},"1096":{"position":[[846,2]]},"1127":{"position":[[70,2]]}}}],["d)(l×d",{"_index":2085,"t":{"637":{"position":[[122,7]]}}}],["d)(l×d)+(l×d",{"_index":2087,"t":{"637":{"position":[[233,13]]}}}],["d)\\tau(l×d)+(l×d",{"_index":2091,"t":{"637":{"position":[[407,18]]}}}],["d/hd/hd/h",{"_index":3470,"t":{"1140":{"position":[[753,9]]}}}],["d1",{"_index":2751,"t":{"899":{"position":[[28,3]]}}}],["d1=d2=1024d_1",{"_index":3430,"t":{"1137":{"position":[[2048,13]]}}}],["d2",{"_index":2752,"t":{"899":{"position":[[230,3]]}}}],["d3",{"_index":2754,"t":{"899":{"position":[[487,3]]}}}],["d4",{"_index":2755,"t":{"899":{"position":[[643,3]]}}}],["d5",{"_index":2758,"t":{"899":{"position":[[1010,3]]}}}],["d^2l×d2",{"_index":2089,"t":{"637":{"position":[[277,7]]}}}],["d_1",{"_index":3427,"t":{"1137":{"position":[[1954,4]]},"1142":{"position":[[447,4]]},"1146":{"position":[[520,5],[1270,5]]}}}],["d_2",{"_index":3428,"t":{"1137":{"position":[[1959,3],[2064,3]]},"1142":{"position":[[452,3]]}}}],["d_2)d_1d_2)o(min(d1​,d2​)d1​d2",{"_index":3528,"t":{"1146":{"position":[[1276,32]]}}}],["d_2)r≪min(d1​,d2",{"_index":3512,"t":{"1146":{"position":[[526,18]]}}}],["d_2}a∈rr×d2",{"_index":3423,"t":{"1137":{"position":[[1874,13]]},"1142":{"position":[[367,13]]}}}],["d_2}q∈rr×d2",{"_index":3504,"t":{"1146":{"position":[[300,12]]}}}],["d_2}△∈rd1​×d2",{"_index":3421,"t":{"1137":{"position":[[1824,15]]},"1142":{"position":[[317,15]]}}}],["d_h}wqi​,wki​,wvi​∈rd×dh",{"_index":3468,"t":{"1140":{"position":[[666,25]]}}}],["d_m}wf1​∈rd×dm",{"_index":3476,"t":{"1140":{"position":[[1003,15]]}}}],["d_v",{"_index":1426,"t":{"427":{"position":[[2040,3]]}}}],["d_{\\pi^{rl}_\\phi}}[r_\\theta(x,i",{"_index":3030,"t":{"1001":{"position":[[1533,32]]}}}],["d_{ff})l(dk​+dv​+dff",{"_index":1427,"t":{"427":{"position":[[2046,22]]}}}],["d_{model",{"_index":1839,"t":{"581":{"position":[[157,9]]},"583":{"position":[[211,9]]},"585":{"position":[[531,9],[556,10]]},"587":{"position":[[209,9]]}}}],["d_{model}dffn​=4×dmodel",{"_index":1754,"t":{"551":{"position":[[411,24]]}}}],["d_{model}r≪dmodel",{"_index":1821,"t":{"571":{"position":[[121,18]]}}}],["d_{model}∣θ∣=l^adpt​×(2×dmodel​×r+r+dmodel​)+2×l^ln​×dmodel",{"_index":1854,"t":{"585":{"position":[[598,60]]}}}],["d_{pretrain}}[log(\\pi^{rl}_\\phi",{"_index":3035,"t":{"1001":{"position":[[1645,31]]}}}],["dall",{"_index":2153,"t":{"682":{"position":[[8,4],[214,4]]}}}],["danger",{"_index":3185,"t":{"1059":{"position":[[118,9],[153,9],[231,9]]}}}],["dant",{"_index":2238,"t":{"692":{"position":[[157,6]]}}}],["dart",{"_index":2420,"t":{"780":{"position":[[64,4],[145,4]]},"787":{"position":[[520,4]]}}}],["data",{"_index":268,"t":{"49":{"position":[[558,4]]},"63":{"position":[[205,4]]},"138":{"position":[[320,4]]},"155":{"position":[[573,4]]},"199":{"position":[[96,4]]},"279":{"position":[[196,4]]},"286":{"position":[[45,4]]},"333":{"position":[[318,4]]},"335":{"position":[[29,4]]},"341":{"position":[[32,4],[133,4]]},"360":{"position":[[606,4]]},"366":{"position":[[191,4]]},"368":{"position":[[305,6]]},"388":{"position":[[109,4]]},"418":{"position":[[51,4],[118,4],[1650,4]]},"421":{"position":[[424,4]]},"423":{"position":[[147,4]]},"429":{"position":[[141,4]]},"457":{"position":[[311,4]]},"461":{"position":[[23,4]]},"491":{"position":[[18,4]]},"502":{"position":[[459,4]]},"504":{"position":[[711,4],[1631,4],[1678,4],[2288,4],[2467,4],[2486,4],[2515,4]]},"515":{"position":[[295,4],[836,4]]},"519":{"position":[[149,4],[268,4],[392,4],[486,4]]},"521":{"position":[[79,4],[168,4],[283,4],[401,4],[449,4]]},"525":{"position":[[120,4],[145,4],[241,4]]},"529":{"position":[[47,4],[85,4],[159,4],[205,4]]},"533":{"position":[[39,4],[321,4]]},"535":{"position":[[141,4]]},"539":{"position":[[291,4]]},"543":{"position":[[141,4],[293,4]]},"616":{"position":[[788,4]]},"627":{"position":[[97,4]]},"759":{"position":[[566,4],[589,4]]},"764":{"position":[[140,4]]},"791":{"position":[[96,4],[206,4],[278,4],[447,4]]},"793":{"position":[[339,4]]},"796":{"position":[[215,4]]},"802":{"position":[[13,4]]},"804":{"position":[[0,4],[334,4]]},"817":{"position":[[1074,4]]},"874":{"position":[[420,4]]},"876":{"position":[[117,4]]},"881":{"position":[[37,4]]},"927":{"position":[[171,4]]},"955":{"position":[[389,4]]},"963":{"position":[[3120,4],[3298,4]]},"1205":{"position":[[450,4]]},"1207":{"position":[[112,4],[133,4]]},"1216":{"position":[[414,4]]},"1218":{"position":[[601,4]]},"1220":{"position":[[244,4]]},"1222":{"position":[[45,4]]}}}],["databas",{"_index":2689,"t":{"870":{"position":[[233,9],[255,8]]}}}],["dataset",{"_index":487,"t":{"102":{"position":[[6,7],[125,7]]},"136":{"position":[[43,7],[69,7]]},"143":{"position":[[44,7]]},"193":{"position":[[103,7]]},"248":{"position":[[210,7]]},"360":{"position":[[58,7],[536,7]]},"368":{"position":[[230,7]]},"418":{"position":[[1903,7]]},"423":{"position":[[249,7],[401,7],[800,9]]},"427":{"position":[[3038,7]]},"429":{"position":[[449,7]]},"431":{"position":[[534,7],[643,7],[671,7]]},"435":{"position":[[32,7]]},"437":{"position":[[689,7]]},"441":{"position":[[414,7]]},"447":{"position":[[141,8],[324,7]]},"494":{"position":[[39,7]]},"502":{"position":[[634,7]]},"512":{"position":[[34,7]]},"523":{"position":[[389,7]]},"537":{"position":[[100,7]]},"543":{"position":[[560,7]]},"633":{"position":[[10,7]]},"639":{"position":[[12,7]]},"653":{"position":[[208,7]]},"692":{"position":[[84,7]]},"694":{"position":[[0,9],[140,7],[424,7]]},"698":{"position":[[1435,8],[1497,8]]},"730":{"position":[[111,7],[131,7],[193,7]]},"736":{"position":[[54,7]]},"780":{"position":[[40,7],[75,7]]},"784":{"position":[[547,7]]},"789":{"position":[[120,7],[228,7],[279,7]]},"791":{"position":[[241,7]]},"817":{"position":[[1657,7]]},"825":{"position":[[582,7]]},"836":{"position":[[1915,7]]},"838":{"position":[[351,7],[376,7],[409,7],[998,7]]},"842":{"position":[[1807,7]]},"959":{"position":[[774,7]]},"995":{"position":[[443,7],[497,7],[558,7]]},"997":{"position":[[42,7],[81,7]]},"1020":{"position":[[68,7],[91,7]]},"1099":{"position":[[518,8]]},"1137":{"position":[[4461,7],[4666,7]]},"1167":{"position":[[66,7]]},"1184":{"position":[[255,7]]},"1200":{"position":[[517,7],[822,7]]},"1205":{"position":[[335,7],[540,7]]},"1207":{"position":[[72,7],[416,7]]},"1209":{"position":[[85,7]]},"1211":{"position":[[144,7]]},"1214":{"position":[[59,7]]},"1216":{"position":[[42,7],[327,7],[344,7]]},"1220":{"position":[[322,7]]},"1222":{"position":[[291,7]]},"1224":{"position":[[45,7]]},"1238":{"position":[[27,7]]}}}],["date",{"_index":58,"t":{"9":{"position":[[187,4]]},"257":{"position":[[89,4]]}}}],["datset",{"_index":2093,"t":{"639":{"position":[[60,6]]}}}],["davi",{"_index":3386,"t":{"1113":{"position":[[6,5],[49,5]]}}}],["davis17",{"_index":3403,"t":{"1121":{"position":[[22,7]]}}}],["day",{"_index":3052,"t":{"1013":{"position":[[298,4],[350,4]]}}}],["ddd",{"_index":423,"t":{"91":{"position":[[482,3],[541,3]]},"549":{"position":[[742,5]]},"627":{"position":[[533,3]]},"1001":{"position":[[1029,3]]},"1222":{"position":[[171,3]]}}}],["ddev32\\mathcal{d}_{dev32}ddev32",{"_index":2266,"t":{"698":{"position":[[716,34],[791,32],[1323,32]]},"702":{"position":[[448,32],[860,32]]}}}],["ddev\\mathcal{d}_{dev}ddev",{"_index":2261,"t":{"698":{"position":[[394,28],[1293,26]]}}}],["de",{"_index":648,"t":{"140":{"position":[[285,3]]}}}],["deberta",{"_index":1735,"t":{"547":{"position":[[331,8]]},"573":{"position":[[9,7]]},"591":{"position":[[0,7],[65,7]]},"742":{"position":[[34,7]]}}}],["debertav",{"_index":3727,"t":{"1190":{"position":[[368,9]]}}}],["debertav3",{"_index":3449,"t":{"1137":{"position":[[4472,9]]},"1156":{"position":[[15,9]]},"1163":{"position":[[15,9]]},"1165":{"position":[[0,9]]},"1170":{"position":[[56,9]]},"1174":{"position":[[80,9]]},"1179":{"position":[[0,9]]},"1184":{"position":[[30,9]]},"1192":{"position":[[33,9]]}}}],["debias",{"_index":2899,"t":{"959":{"position":[[210,9],[241,8],[493,9]]}}}],["decay",{"_index":288,"t":{"53":{"position":[[143,6],[202,5],[228,7],[297,5]]},"63":{"position":[[152,5],[191,6]]},"80":{"position":[[37,6]]},"106":{"position":[[121,5]]},"112":{"position":[[206,5]]},"188":{"position":[[23,6]]},"431":{"position":[[414,5]]},"475":{"position":[[190,5]]},"698":{"position":[[1204,7]]},"825":{"position":[[826,5],[849,5]]},"1001":{"position":[[273,5]]},"1104":{"position":[[303,5]]},"1236":{"position":[[20,5]]}}}],["decent",{"_index":3526,"t":{"1146":{"position":[[1122,6]]}}}],["decis",{"_index":1730,"t":{"539":{"position":[[159,8]]},"848":{"position":[[505,8]]},"850":{"position":[[673,8],[1542,8],[1759,8]]},"857":{"position":[[370,8],[462,8]]},"859":{"position":[[393,8],[693,8],[856,8]]}}}],["decod",{"_index":624,"t":{"132":{"position":[[93,7],[114,7],[260,7]]},"143":{"position":[[319,8]]},"169":{"position":[[18,7],[198,7]]},"176":{"position":[[207,7]]},"178":{"position":[[408,7]]},"180":{"position":[[81,7],[289,7]]},"183":{"position":[[118,7]]},"190":{"position":[[302,7]]},"209":{"position":[[81,7]]},"242":{"position":[[124,8]]},"304":{"position":[[531,8]]},"328":{"position":[[67,7],[92,7],[343,7]]},"330":{"position":[[297,7],[427,7],[534,7],[644,7],[689,7],[1303,7],[1371,8],[1406,7]]},"333":{"position":[[85,7]]},"337":{"position":[[41,7]]},"339":{"position":[[246,7],[325,7]]},"345":{"position":[[9,7],[200,7],[449,7],[535,7],[584,7],[740,7]]},"347":{"position":[[19,7],[171,7],[228,7],[306,7]]},"349":{"position":[[75,9],[242,7],[279,8],[352,7],[453,7],[500,7],[611,7],[712,7]]},"351":{"position":[[75,7]]},"353":{"position":[[8,7],[186,7]]},"355":{"position":[[78,7],[104,7],[160,7],[268,7]]},"357":{"position":[[171,7]]},"362":{"position":[[114,7]]},"396":{"position":[[85,7],[124,7]]},"406":{"position":[[7,8],[30,9],[193,7],[216,7]]},"423":{"position":[[229,7]]},"427":{"position":[[1241,7],[2102,7],[2197,7]]},"437":{"position":[[193,7],[338,7],[360,7],[419,7]]},"441":{"position":[[71,7]]},"475":{"position":[[440,8]]},"569":{"position":[[113,7]]},"648":{"position":[[174,7]]},"768":{"position":[[53,7],[138,7],[438,7]]},"775":{"position":[[119,7]]},"819":{"position":[[347,7],[1882,7]]},"823":{"position":[[51,7],[1145,7]]},"836":{"position":[[753,7]]},"1087":{"position":[[2189,7],[2208,7]]},"1096":{"position":[[151,7],[371,8],[546,7],[583,7],[1263,7]]},"1104":{"position":[[178,7],[224,7]]},"1179":{"position":[[69,7]]}}}],["decompos",{"_index":2020,"t":{"633":{"position":[[119,12]]},"662":{"position":[[175,12],[571,12]]}}}],["decomposit",{"_index":1734,"t":{"547":{"position":[[149,13]]},"549":{"position":[[622,13]]},"563":{"position":[[327,13]]},"587":{"position":[[26,13]]},"604":{"position":[[93,13]]},"629":{"position":[[217,14]]},"631":{"position":[[7,13],[765,13]]},"633":{"position":[[44,13]]},"655":{"position":[[23,13]]},"662":{"position":[[90,13],[263,13],[491,13]]},"674":{"position":[[104,13],[258,13]]},"911":{"position":[[1252,13]]},"923":{"position":[[81,13],[356,13]]},"975":{"position":[[408,13],[551,13]]},"1135":{"position":[[564,13]]},"1144":{"position":[[81,13]]},"1146":{"position":[[66,13]]},"1194":{"position":[[171,13]]}}}],["deem",{"_index":2682,"t":{"863":{"position":[[533,5]]}}}],["deep",{"_index":1100,"t":{"330":{"position":[[1366,4],[1401,4]]},"349":{"position":[[274,4]]},"515":{"position":[[202,4]]},"711":{"position":[[499,4]]},"713":{"position":[[1176,4],[1307,4]]},"725":{"position":[[376,4]]},"727":{"position":[[265,4]]},"1137":{"position":[[1373,4]]}}}],["deeper",{"_index":2304,"t":{"727":{"position":[[482,6]]}}}],["deepspe",{"_index":1190,"t":{"362":{"position":[[1067,10],[1256,9]]}}}],["default",{"_index":1645,"t":{"475":{"position":[[432,7]]},"825":{"position":[[129,7],[258,7]]},"827":{"position":[[40,7]]},"832":{"position":[[11,7]]},"1040":{"position":[[142,7]]},"1165":{"position":[[579,7]]},"1222":{"position":[[248,7]]}}}],["defaultlocal",{"_index":3224,"t":{"1073":{"position":[[110,14]]}}}],["deffer",{"_index":363,"t":{"78":{"position":[[766,10]]}}}],["defici",{"_index":1736,"t":{"547":{"position":[[454,10]]}}}],["defin",{"_index":2625,"t":{"850":{"position":[[919,7]]},"857":{"position":[[432,7]]}}}],["definit",{"_index":2483,"t":{"817":{"position":[[2269,10]]}}}],["deform",{"_index":3322,"t":{"1096":{"position":[[120,10],[296,10],[419,10],[1091,10]]}}}],["degeneraci",{"_index":2964,"t":{"977":{"position":[[168,10]]}}}],["delet",{"_index":74,"t":{"9":{"position":[[419,6]]}}}],["demonstr",{"_index":2846,"t":{"919":{"position":[[22,13],[227,13]]},"961":{"position":[[231,13]]},"975":{"position":[[727,13],[773,13]]}}}],["denois",{"_index":1090,"t":{"328":{"position":[[490,10]]},"330":{"position":[[933,9]]},"335":{"position":[[108,9]]}}}],["dens",{"_index":581,"t":{"124":{"position":[[237,5]]},"140":{"position":[[536,5]]},"292":{"position":[[330,5]]},"549":{"position":[[596,5],[661,5]]},"563":{"position":[[13,5]]},"1137":{"position":[[1431,5]]}}}],["densenet",{"_index":186,"t":{"27":{"position":[[24,9]]}}}],["deocder",{"_index":1144,"t":{"347":{"position":[[358,7]]}}}],["depend",{"_index":97,"t":{"15":{"position":[[112,13]]},"17":{"position":[[360,12]]},"899":{"position":[[209,10]]}}}],["deploy",{"_index":3155,"t":{"1047":{"position":[[120,6],[206,10]]},"1137":{"position":[[2334,6]]}}}],["depth",{"_index":567,"t":{"116":{"position":[[573,5]]},"165":{"position":[[592,6]]},"169":{"position":[[111,6]]},"171":{"position":[[264,6],[624,5]]},"204":{"position":[[48,5],[67,5]]},"549":{"position":[[275,5]]},"773":{"position":[[1025,5]]},"836":{"position":[[1738,5]]}}}],["depthwis",{"_index":172,"t":{"25":{"position":[[296,9]]},"33":{"position":[[20,9],[133,9]]},"78":{"position":[[98,9]]}}}],["dequant",{"_index":650,"t":{"140":{"position":[[435,12],[519,10],[761,12]]}}}],["dequeu",{"_index":1127,"t":{"343":{"position":[[710,7]]}}}],["descent",{"_index":2148,"t":{"680":{"position":[[1128,7]]},"688":{"position":[[206,7]]}}}],["describ",{"_index":1111,"t":{"341":{"position":[[103,10]]}}}],["descript",{"_index":587,"t":{"124":{"position":[[534,11]]},"126":{"position":[[154,11],[1204,11]]},"128":{"position":[[47,11]]},"130":{"position":[[204,12],[437,11],[520,11]]},"159":{"position":[[13,11]]},"292":{"position":[[368,11]]},"761":{"position":[[1075,11]]},"764":{"position":[[169,11]]},"817":{"position":[[515,11],[736,11]]},"1051":{"position":[[118,12],[143,11]]},"1198":{"position":[[116,12]]}}}],["design",{"_index":845,"t":{"209":{"position":[[110,6]]},"211":{"position":[[189,6]]},"449":{"position":[[6,6]]},"817":{"position":[[414,6],[985,6],[1148,6],[2519,6]]},"819":{"position":[[1050,6]]},"821":{"position":[[656,6]]},"827":{"position":[[521,6],[618,6]]},"836":{"position":[[699,6],[1623,8]]},"903":{"position":[[125,6]]},"909":{"position":[[8,6]]},"1026":{"position":[[147,6]]},"1205":{"position":[[210,6]]}}}],["detail",{"_index":1505,"t":{"451":{"position":[[446,8]]},"521":{"position":[[295,8]]},"537":{"position":[[602,6]]},"823":{"position":[[985,7]]}}}],["detect",{"_index":201,"t":{"27":{"position":[[423,10]]},"120":{"position":[[158,10]]},"124":{"position":[[282,10],[325,9]]},"126":{"position":[[396,9],[502,9],[893,10],[942,10]]},"128":{"position":[[144,9],[185,9]]},"130":{"position":[[40,9],[146,9],[486,9]]},"132":{"position":[[416,9]]},"140":{"position":[[721,9]]},"143":{"position":[[398,9]]},"149":{"position":[[139,9]]},"151":{"position":[[7,10],[69,9]]},"153":{"position":[[7,9]]},"155":{"position":[[467,9],[692,9],[1009,9]]},"157":{"position":[[47,10],[90,9],[210,9],[310,9]]},"165":{"position":[[177,10]]},"169":{"position":[[594,9],[646,9]]},"223":{"position":[[64,9]]},"357":{"position":[[94,9]]},"504":{"position":[[2055,9]]},"525":{"position":[[401,9]]},"838":{"position":[[271,9],[749,9]]},"1085":{"position":[[617,10]]},"1087":{"position":[[73,10],[1445,10]]},"1090":{"position":[[82,10]]},"1099":{"position":[[97,9],[743,10]]},"1107":{"position":[[80,9]]},"1125":{"position":[[352,9]]},"1203":{"position":[[562,10]]},"1207":{"position":[[209,10]]}}}],["detector",{"_index":695,"t":{"153":{"position":[[37,8],[88,8]]},"1087":{"position":[[1056,8],[2169,8]]}}}],["determinist",{"_index":2690,"t":{"870":{"position":[[347,13]]}}}],["detr",{"_index":698,"t":{"153":{"position":[[99,4]]},"1096":{"position":[[131,4],[430,4]]},"1104":{"position":[[192,4]]}}}],["dev",{"_index":1053,"t":{"309":{"position":[[39,3]]},"698":{"position":[[708,3]]},"793":{"position":[[206,3]]},"825":{"position":[[490,3]]},"827":{"position":[[545,3]]},"1107":{"position":[[42,3]]},"1167":{"position":[[51,3]]}}}],["develop",{"_index":118,"t":{"19":{"position":[[8,11],[294,11]]},"1077":{"position":[[185,12]]}}}],["dffn=4×dmodeld_{ffn",{"_index":1753,"t":{"551":{"position":[[379,20]]}}}],["dhd_hdh",{"_index":3469,"t":{"1140":{"position":[[736,8]]}}}],["diagnosi",{"_index":2902,"t":{"959":{"position":[[272,9],[319,9],[355,9],[587,9]]}}}],["diagon",{"_index":3443,"t":{"1137":{"position":[[4034,8]]},"1146":{"position":[[357,8],[707,8]]}}}],["dialog",{"_index":1732,"t":{"543":{"position":[[342,6]]},"997":{"position":[[131,7]]}}}],["dialogu",{"_index":3058,"t":{"1020":{"position":[[82,8]]}}}],["dice",{"_index":3355,"t":{"1099":{"position":[[647,4]]}}}],["diff",{"_index":1940,"t":{"619":{"position":[[70,4]]},"1137":{"position":[[959,4],[1027,4],[1143,4],[1255,4],[2275,4]]}}}],["differenti",{"_index":2157,"t":{"684":{"position":[[100,12]]},"819":{"position":[[866,14]]}}}],["dignissim",{"_index":10,"t":{"3":{"position":[[80,9]]},"5":{"position":[[200,9],[379,9],[558,9],[737,9],[916,9],[1095,9],[1274,9],[1453,9],[1632,9],[1811,9],[1990,9],[2169,9],[2348,9],[2527,9],[2706,9],[2885,9]]}}}],["dimens",{"_index":1529,"t":{"461":{"position":[[351,9],[710,9]]},"465":{"position":[[364,9],[694,9]]},"549":{"position":[[403,9]]},"551":{"position":[[78,10],[367,9]]},"553":{"position":[[753,9]]},"557":{"position":[[351,9]]},"563":{"position":[[156,10]]},"604":{"position":[[1104,9]]},"775":{"position":[[449,9]]},"811":{"position":[[834,9]]},"819":{"position":[[1563,9]]},"821":{"position":[[745,9]]},"1137":{"position":[[1079,9],[2019,9]]},"1160":{"position":[[574,9],[593,9]]},"1172":{"position":[[163,9]]}}}],["dimension",{"_index":1124,"t":{"343":{"position":[[521,11]]},"427":{"position":[[3505,11]]},"608":{"position":[[70,11]]},"811":{"position":[[880,11]]},"1137":{"position":[[3888,11]]},"1146":{"position":[[1325,11]]}}}],["direct",{"_index":1236,"t":{"384":{"position":[[37,6],[139,6],[191,6]]},"606":{"position":[[220,9]]},"608":{"position":[[566,9],[619,9]]},"838":{"position":[[1085,9]]},"1094":{"position":[[280,11]]}}}],["directori",{"_index":53,"t":{"9":{"position":[[112,10],[431,10]]},"19":{"position":[[83,9]]},"1055":{"position":[[100,9]]}}}],["direict",{"_index":2587,"t":{"838":{"position":[[873,11]]}}}],["disabl",{"_index":335,"t":{"63":{"position":[[177,7]]}}}],["disadvantag",{"_index":2861,"t":{"931":{"position":[[395,13]]},"933":{"position":[[336,13]]},"935":{"position":[[302,13]]},"937":{"position":[[507,13]]},"939":{"position":[[230,13]]}}}],["disambigu",{"_index":1329,"t":{"423":{"position":[[907,14]]},"698":{"position":[[231,14]]},"700":{"position":[[471,14]]}}}],["disconnect",{"_index":951,"t":{"279":{"position":[[150,10],[168,10]]},"281":{"position":[[527,10],[586,10],[1084,10],[1102,10],[1559,10],[1979,10],[2024,10]]},"292":{"position":[[57,13],[141,13],[312,10],[394,10],[512,13],[587,10]]},"300":{"position":[[875,10],[1035,13],[1119,13]]}}}],["discov",{"_index":78,"t":{"11":{"position":[[6,8]]}}}],["discoveri",{"_index":3252,"t":{"1090":{"position":[[601,9]]}}}],["discret",{"_index":585,"t":{"124":{"position":[[401,8]]},"130":{"position":[[696,8],[1522,8]]},"140":{"position":[[794,8]]},"159":{"position":[[55,8]]},"619":{"position":[[426,8]]},"680":{"position":[[783,8],[868,8],[1090,8]]},"682":{"position":[[355,8]]},"684":{"position":[[0,8]]},"686":{"position":[[39,8],[1139,8]]},"688":{"position":[[63,12],[140,8],[527,12],[609,12]]},"696":{"position":[[120,8]]},"713":{"position":[[643,8],[720,8]]},"718":{"position":[[85,8]]},"773":{"position":[[636,8],[702,8],[909,8]]},"798":{"position":[[243,8],[282,8],[392,8]]},"815":{"position":[[122,8]]},"817":{"position":[[1095,8]]},"842":{"position":[[133,8]]},"897":{"position":[[216,8]]},"899":{"position":[[0,8]]},"901":{"position":[[1036,8],[1441,8],[1457,8],[1545,8]]},"911":{"position":[[54,8]]},"917":{"position":[[76,8]]},"937":{"position":[[170,8]]},"943":{"position":[[279,8]]},"963":{"position":[[252,8]]}}}],["discrimin",{"_index":793,"t":{"180":{"position":[[555,14]]}}}],["disjoint",{"_index":1677,"t":{"504":{"position":[[1583,8]]},"519":{"position":[[336,10]]}}}],["disk",{"_index":1494,"t":{"443":{"position":[[256,4]]}}}],["display",{"_index":140,"t":{"19":{"position":[[450,8]]}}}],["dist",{"_index":1489,"t":{"443":{"position":[[106,4]]}}}],["distanc",{"_index":570,"t":{"116":{"position":[[700,8],[783,8]]},"604":{"position":[[432,8]]},"664":{"position":[[207,8],[303,8]]},"832":{"position":[[866,10]]},"842":{"position":[[404,8]]}}}],["distil",{"_index":770,"t":{"176":{"position":[[420,12]]},"614":{"position":[[348,10]]},"616":{"position":[[1112,12]]},"619":{"position":[[804,12]]},"623":{"position":[[10,12]]},"625":{"position":[[563,12]]},"629":{"position":[[281,12]]},"633":{"position":[[194,12],[500,12],[1815,12],[1842,10],[2326,12]]},"635":{"position":[[254,12]]},"648":{"position":[[141,12]]},"662":{"position":[[209,12],[384,12]]},"664":{"position":[[7,12],[262,12],[283,12],[372,12]]},"674":{"position":[[121,12]]},"702":{"position":[[767,12],[1119,12]]},"836":{"position":[[1574,12]]},"917":{"position":[[1062,12],[1113,12]]}}}],["distribut",{"_index":2029,"t":{"633":{"position":[[717,13],[1143,12]]},"688":{"position":[[169,12]]},"694":{"position":[[498,12]]},"766":{"position":[[962,12]]},"770":{"position":[[87,12]]},"773":{"position":[[377,12]]},"1001":{"position":[[1913,12]]},"1092":{"position":[[1856,12]]},"1192":{"position":[[364,12]]}}}],["diverg",{"_index":2028,"t":{"633":{"position":[[659,10]]}}}],["divid",{"_index":2459,"t":{"802":{"position":[[246,8]]}}}],["dl×d",{"_index":2083,"t":{"637":{"position":[[70,4]]}}}],["dmodeld_{model}dmodel",{"_index":1745,"t":{"551":{"position":[[91,22]]}}}],["dmodel×(lp+li)|\\theta",{"_index":1838,"t":{"581":{"position":[[128,26]]}}}],["doc",{"_index":3118,"t":{"1036":{"position":[[52,4]]},"1051":{"position":[[86,3]]},"1063":{"position":[[48,5]]},"1065":{"position":[[79,4],[168,4],[249,4],[327,4]]},"1067":{"position":[[226,4]]},"1069":{"position":[[33,4]]}}}],["doc.md",{"_index":3160,"t":{"1051":{"position":[[68,6]]}}}],["docs/curr",{"_index":3229,"t":{"1075":{"position":[[94,13]]}}}],["docs/current/intro.md",{"_index":3231,"t":{"1075":{"position":[[159,21],[225,21]]}}}],["docs/hello.md",{"_index":3115,"t":{"1034":{"position":[[26,14],[41,13]]},"1036":{"position":[[123,13]]},"1069":{"position":[[143,13]]}}}],["docs/intro.md",{"_index":135,"t":{"19":{"position":[[368,13]]},"1071":{"position":[[16,13]]},"1075":{"position":[[9,13],[111,13]]}}}],["docs:vers",{"_index":3209,"t":{"1065":{"position":[[58,12]]}}}],["docstr",{"_index":1110,"t":{"341":{"position":[[93,9]]}}}],["docsversiondropdown",{"_index":3218,"t":{"1067":{"position":[[184,22]]}}}],["document",{"_index":1954,"t":{"623":{"position":[[132,8]]},"953":{"position":[[34,8],[131,8]]},"1026":{"position":[[18,13]]},"1032":{"position":[[0,9]]},"1034":{"position":[[93,11],[111,8]]},"1036":{"position":[[224,11],[447,11]]},"1051":{"position":[[9,9],[103,8],[134,8]]},"1061":{"position":[[18,13]]}}}],["docusauru",{"_index":32,"t":{"7":{"position":[[19,10]]},"9":{"position":[[0,10],[470,10]]},"11":{"position":[[15,10]]},"13":{"position":[[43,10]]},"17":{"position":[[15,10],[389,11]]},"19":{"position":[[155,10]]},"1024":{"position":[[36,10],[94,10]]},"1026":{"position":[[207,10],[247,10]]},"1028":{"position":[[0,10]]},"1030":{"position":[[164,10],[289,10]]},"1034":{"position":[[82,10]]},"1036":{"position":[[0,10],[213,10]]},"1044":{"position":[[0,10]]},"1049":{"position":[[0,10]]},"1055":{"position":[[139,12],[329,12]]},"1059":{"position":[[0,10]]},"1061":{"position":[[512,10]]},"1063":{"position":[[0,10]]},"1065":{"position":[[47,10]]}}}],["docusaurus!</h1",{"_index":3179,"t":{"1057":{"position":[[159,16],[265,17]]}}}],["docusaurus.config.j",{"_index":3075,"t":{"1026":{"position":[[68,20]]},"1067":{"position":[[75,20],[102,20]]},"1073":{"position":[[7,20],[62,20]]},"1079":{"position":[[75,20],[102,20]]}}}],["docusaurus.new",{"_index":87,"t":{"13":{"position":[[71,15]]}}}],["docusaurus@latest",{"_index":107,"t":{"17":{"position":[[160,17]]}}}],["docvqa",{"_index":1731,"t":{"541":{"position":[[210,6]]}}}],["dolor",{"_index":2,"t":{"3":{"position":[[12,5],[164,5]]},"5":{"position":[[132,5],[284,5],[311,5],[463,5],[490,5],[642,5],[669,5],[821,5],[848,5],[1000,5],[1027,5],[1179,5],[1206,5],[1358,5],[1385,5],[1537,5],[1564,5],[1716,5],[1743,5],[1895,5],[1922,5],[2074,5],[2101,5],[2253,5],[2280,5],[2432,5],[2459,5],[2611,5],[2638,5],[2790,5],[2817,5],[2969,5]]}}}],["domain",{"_index":722,"t":{"163":{"position":[[156,6],[205,6]]},"165":{"position":[[321,6],[383,6]]},"171":{"position":[[162,6]]},"178":{"position":[[448,6]]},"186":{"position":[[3,6]]},"202":{"position":[[68,6]]},"204":{"position":[[139,6]]},"223":{"position":[[102,6]]},"269":{"position":[[384,6]]},"281":{"position":[[327,6]]},"780":{"position":[[118,6],[137,7],[169,6]]},"787":{"position":[[561,6]]},"811":{"position":[[173,6]]},"815":{"position":[[583,6]]},"817":{"position":[[2325,6],[2602,6]]},"838":{"position":[[202,6],[296,6],[369,6],[402,6],[456,6],[501,6],[600,6],[692,6],[926,7],[955,7],[1198,6]]},"842":{"position":[[1969,6]]},"844":{"position":[[197,6],[376,6]]},"899":{"position":[[866,6]]},"959":{"position":[[62,6]]},"963":{"position":[[1794,6]]},"975":{"position":[[864,7]]},"1087":{"position":[[874,6],[939,6],[2375,6],[2791,7]]},"1200":{"position":[[308,6]]},"1216":{"position":[[355,6]]},"1220":{"position":[[106,6]]}}}],["don't",{"_index":72,"t":{"9":{"position":[[395,5]]}}}],["donwstream",{"_index":2326,"t":{"761":{"position":[[59,10]]}}}],["dot",{"_index":1350,"t":{"425":{"position":[[323,6],[896,6]]},"625":{"position":[[87,6],[209,6]]},"627":{"position":[[590,6]]},"635":{"position":[[971,6]]},"686":{"position":[[118,6],[267,6],[1543,5],[1576,5]]},"718":{"position":[[594,6],[709,6]]},"819":{"position":[[680,6],[1475,5]]},"1140":{"position":[[353,6]]},"1148":{"position":[[1152,6]]}}}],["dots,n,}z={(xi​,yi​)}i=1,…,n",{"_index":1761,"t":{"553":{"position":[[242,31]]}}}],["dots,s_k",{"_index":2070,"t":{"635":{"position":[[184,9]]}}}],["doublet",{"_index":3493,"t":{"1142":{"position":[[719,7]]},"1146":{"position":[[1552,7],[1581,7],[1665,7],[1708,7],[1857,8],[1882,8]]},"1186":{"position":[[28,7],[73,8],[121,8]]}}}],["down",{"_index":765,"t":{"171":{"position":[[839,4]]},"178":{"position":[[186,4]]}}}],["downstream",{"_index":480,"t":{"97":{"position":[[36,10],[168,10]]},"213":{"position":[[199,10]]},"328":{"position":[[212,10],[308,10]]},"330":{"position":[[63,10],[116,10],[791,10],[882,10],[967,10],[1673,10]]},"347":{"position":[[469,10]]},"360":{"position":[[250,10]]},"418":{"position":[[207,10],[338,10],[581,10]]},"429":{"position":[[59,10],[438,10]]},"431":{"position":[[45,10],[523,10],[632,10]]},"525":{"position":[[763,10]]},"547":{"position":[[168,10]]},"549":{"position":[[12,10]]},"553":{"position":[[136,10],[670,10]]},"559":{"position":[[125,10]]},"567":{"position":[[3,10]]},"569":{"position":[[244,11]]},"614":{"position":[[119,10],[409,10]]},"616":{"position":[[47,10]]},"627":{"position":[[1307,10]]},"629":{"position":[[383,10]]},"646":{"position":[[71,10]]},"662":{"position":[[314,10]]},"674":{"position":[[360,10]]},"680":{"position":[[1544,10]]},"682":{"position":[[63,10],[223,10]]},"686":{"position":[[349,10],[1818,10]]},"759":{"position":[[55,10]]},"811":{"position":[[926,10]]},"815":{"position":[[23,10],[456,10]]},"817":{"position":[[11,10],[612,10],[839,10],[1034,10],[1531,10],[1783,10]]},"823":{"position":[[1260,10],[1355,10],[1605,10]]},"832":{"position":[[346,10]]},"834":{"position":[[234,10]]},"844":{"position":[[40,10],[308,10]]},"876":{"position":[[695,10],[869,10],[913,10]]},"891":{"position":[[30,10]]},"899":{"position":[[592,10],[983,10]]},"901":{"position":[[223,10]]},"917":{"position":[[170,10]]},"927":{"position":[[291,10],[322,10],[380,10]]},"929":{"position":[[10,10]]},"931":{"position":[[71,10]]},"935":{"position":[[51,10]]},"937":{"position":[[578,10],[617,10]]},"963":{"position":[[3266,10]]},"977":{"position":[[84,10],[108,10]]},"1001":{"position":[[80,10]]},"1099":{"position":[[996,10]]},"1135":{"position":[[43,10],[153,10]]},"1137":{"position":[[190,10]]},"1198":{"position":[[218,10]]},"1200":{"position":[[140,10],[460,10],[847,10]]},"1216":{"position":[[236,10]]}}}],["dp",{"_index":1142,"t":{"347":{"position":[[331,2]]}}}],["dpretraind_{pretrain}dpretrain",{"_index":3040,"t":{"1001":{"position":[[1867,31]]}}}],["dret",{"_index":699,"t":{"153":{"position":[[127,4],[178,4]]}}}],["drf",{"_index":2757,"t":{"899":{"position":[[890,6],[925,3]]},"959":{"position":[[178,4]]}}}],["driven",{"_index":2607,"t":{"848":{"position":[[15,6]]}}}],["drop",{"_index":196,"t":{"27":{"position":[[287,4]]},"49":{"position":[[464,8]]},"78":{"position":[[701,4]]},"777":{"position":[[505,4]]},"989":{"position":[[906,5]]},"1137":{"position":[[4346,4]]}}}],["dropdown",{"_index":3217,"t":{"1067":{"position":[[54,9],[239,8]]},"1079":{"position":[[54,9],[228,8]]}}}],["dropout",{"_index":253,"t":{"49":{"position":[[202,7],[445,7]]},"53":{"position":[[340,7]]},"78":{"position":[[558,8],[740,7]]},"112":{"position":[[212,7]]},"153":{"position":[[717,7]]},"379":{"position":[[96,8]]},"1001":{"position":[[288,7]]}}}],["dtd",{"_index":3821,"t":{"1238":{"position":[[55,3]]}}}],["dtrain32\\mathcal{d}_{train32}dtrain32",{"_index":2263,"t":{"698":{"position":[[516,40]]}}}],["dtrain\\mathcal{d}_{train}dtrain",{"_index":2260,"t":{"698":{"position":[[315,34]]}}}],["dual",{"_index":1138,"t":{"347":{"position":[[71,4]]}}}],["dublet",{"_index":3529,"t":{"1146":{"position":[[1639,6]]}}}],["dunlabeled\\mathcal{d}_{unlabeled}dunlabel",{"_index":2265,"t":{"698":{"position":[[593,46]]}}}],["dynam",{"_index":1672,"t":{"504":{"position":[[1295,7],[1389,7]]},"531":{"position":[[96,7]]},"1096":{"position":[[871,7]]},"1127":{"position":[[106,7],[246,7]]},"1194":{"position":[[307,11]]}}}],["d}[log(\\sigma",{"_index":3014,"t":{"1001":{"position":[[762,13]]}}}],["d}[p;t]∈r(l+n)×d",{"_index":1993,"t":{"627":{"position":[[1021,16]]}}}],["d}fins​∈rn×d",{"_index":3327,"t":{"1096":{"position":[[1238,12]]}}}],["d}fp​∈r1024×d",{"_index":3281,"t":{"1092":{"position":[[1453,13]]}}}],["d}fp​∈rl×d",{"_index":3258,"t":{"1092":{"position":[[483,10]]}}}],["d}p^k​∈r100×d",{"_index":2115,"t":{"644":{"position":[[183,14]]}}}],["d}p∈rl×d",{"_index":1984,"t":{"627":{"position":[[730,8]]}}}],["d}p∗∈rl×d",{"_index":2000,"t":{"631":{"position":[[261,9]]}}}],["d}t=[t1​,t2​,…,tn​]∈rn×d",{"_index":1981,"t":{"627":{"position":[[627,24]]}}}],["d}wf2​∈rdm​×d",{"_index":3479,"t":{"1140":{"position":[[1062,13]]}}}],["d}wo​∈rd×d",{"_index":3464,"t":{"1140":{"position":[[570,10]]}}}],["d}w∈r1×d",{"_index":3330,"t":{"1096":{"position":[[1822,8]]}}}],["d}x∈rn×d",{"_index":3455,"t":{"1140":{"position":[[185,9]]}}}],["d}x∈rt×d",{"_index":1401,"t":{"427":{"position":[[965,8]]}}}],["d}zo​=[xclass",{"_index":454,"t":{"91":{"position":[[1762,15]]}}}],["d×kd",{"_index":482,"t":{"97":{"position":[[115,4]]}}}],["e",{"_index":249,"t":{"49":{"position":[[167,2]]},"91":{"position":[[1677,1]]},"682":{"position":[[13,1],[219,1]]},"949":{"position":[[467,4]]}}}],["e([\\text{p}_{0:i",{"_index":2189,"t":{"686":{"position":[[1286,20]]}}}],["e([\\text{p}_{i+1:m",{"_index":2191,"t":{"686":{"position":[[1320,22]]}}}],["e([p0:i]),e(x),e([pi+1:m]),e(y)}\\begin{equ",{"_index":2188,"t":{"686":{"position":[[1233,49]]}}}],["e(\\text{\"[mask]\"})][e(x),e(\"it\"),e(\"is\"),e(\"[mask",{"_index":2295,"t":{"718":{"position":[[353,53]]}}}],["e(\\text{\"[mask]\"})][e(x),h0​,…,hi​,e(\"[mask",{"_index":2300,"t":{"718":{"position":[[721,47]]}}}],["e(\\text{\"i",{"_index":2294,"t":{"718":{"position":[[337,15]]}}}],["e(\\text{\"it",{"_index":2293,"t":{"718":{"position":[[321,15]]}}}],["e(\\text{i",{"_index":2192,"t":{"686":{"position":[[1343,11],[1587,11]]}}}],["e(\\text{x",{"_index":2190,"t":{"686":{"position":[[1307,12],[1554,12]]}}}],["e(x),e(\"it\"),e(\"is\"),e(\"[mask]\")][e(\\text{x",{"_index":2292,"t":{"718":{"position":[[273,47]]}}}],["e(x),h0,…,hi,e(\"[mask]\")][e(\\text{x",{"_index":2299,"t":{"718":{"position":[[664,39]]}}}],["e(x0),e(x1),…,e(xn",{"_index":2166,"t":{"686":{"position":[[227,23]]}}}],["e(x0​),e(x1​),…,e(xn",{"_index":2170,"t":{"686":{"position":[[281,26]]}}}],["e(x_0",{"_index":2167,"t":{"686":{"position":[[251,7]]}}}],["e(x_1",{"_index":2168,"t":{"686":{"position":[[259,7]]}}}],["e(x_n",{"_index":2169,"t":{"686":{"position":[[274,6]]}}}],["e.g",{"_index":359,"t":{"78":{"position":[[551,6]]},"165":{"position":[[586,5],[627,5]]},"169":{"position":[[105,5]]},"171":{"position":[[619,4]]},"267":{"position":[[39,5]]},"269":{"position":[[49,5]]},"370":{"position":[[141,5]]},"398":{"position":[[195,5]]},"416":{"position":[[265,5]]},"418":{"position":[[1440,5]]},"423":{"position":[[1399,5]]},"437":{"position":[[218,5]]},"502":{"position":[[723,5]]},"523":{"position":[[461,5]]},"537":{"position":[[276,5]]},"680":{"position":[[231,5],[313,5],[386,5]]},"713":{"position":[[448,5]]},"730":{"position":[[139,5],[201,5]]},"744":{"position":[[40,5]]},"761":{"position":[[75,5],[1013,5],[1557,5]]},"766":{"position":[[7,5]]},"768":{"position":[[74,5]]},"773":{"position":[[81,5],[143,5],[503,5]]},"842":{"position":[[1559,5],[1987,5]]},"1137":{"position":[[2042,5],[3103,7]]},"1154":{"position":[[362,5]]},"1158":{"position":[[438,5]]}}}],["e2",{"_index":2110,"t":{"642":{"position":[[366,3]]},"655":{"position":[[138,3]]},"780":{"position":[[50,4],[101,3]]},"804":{"position":[[92,3]]}}}],["e={λk}k=1n\\mathcal{",{"_index":3549,"t":{"1148":{"position":[[624,21]]}}}],["e_{(x,i",{"_index":3029,"t":{"1001":{"position":[[1519,8]]}}}],["e_{po",{"_index":452,"t":{"91":{"position":[[1667,9],[1723,7]]}}}],["e_{x",{"_index":3034,"t":{"1001":{"position":[[1635,4]]}}}],["each",{"_index":2515,"t":{"821":{"position":[[90,4]]},"1028":{"position":[[30,4]]}}}],["earli",{"_index":348,"t":{"78":{"position":[[133,5],[269,5],[474,5],[815,5]]},"502":{"position":[[341,5],[365,5]]},"504":{"position":[[1243,5],[2415,5]]},"523":{"position":[[101,5],[590,5]]},"537":{"position":[[327,5]]},"698":{"position":[[1572,5]]},"825":{"position":[[746,5]]},"1087":{"position":[[1974,5]]},"1094":{"position":[[225,5],[771,5]]},"1096":{"position":[[1665,5]]},"1125":{"position":[[65,5],[97,5],[206,5]]}}}],["easili",{"_index":3157,"t":{"1047":{"position":[[160,7]]}}}],["ecod",{"_index":1648,"t":{"482":{"position":[[146,7]]}}}],["edg",{"_index":746,"t":{"171":{"position":[[280,5]]}}}],["edit",{"_index":137,"t":{"19":{"position":[[398,4]]},"1030":{"position":[[485,4]]},"1069":{"position":[[18,4]]}}}],["editor",{"_index":115,"t":{"17":{"position":[[312,7]]}}}],["eee",{"_index":478,"t":{"95":{"position":[[115,3],[349,3]]},"688":{"position":[[116,3]]},"718":{"position":[[81,3]]},"819":{"position":[[1575,3]]},"821":{"position":[[723,3]]}}}],["effect",{"_index":349,"t":{"78":{"position":[[150,9]]},"97":{"position":[[272,9]]}}}],["effici",{"_index":944,"t":{"273":{"position":[[259,9]]},"349":{"position":[[130,9],[556,9]]},"396":{"position":[[756,9]]},"416":{"position":[[236,9]]},"418":{"position":[[56,9],[1314,9]]},"451":{"position":[[77,9]]},"457":{"position":[[339,10],[1249,9]]},"502":{"position":[[138,9]]},"504":{"position":[[265,9],[465,9],[1995,9],[2235,9]]},"508":{"position":[[42,9]]},"515":{"position":[[978,9]]},"517":{"position":[[27,9]]},"525":{"position":[[150,9]]},"543":{"position":[[16,9]]},"553":{"position":[[893,9]]},"557":{"position":[[43,9],[179,9]]},"569":{"position":[[159,10]]},"616":{"position":[[331,9]]},"619":{"position":[[385,9]]},"621":{"position":[[308,9]]},"627":{"position":[[358,9],[1386,9]]},"639":{"position":[[121,9]]},"646":{"position":[[329,9]]},"651":{"position":[[30,9],[98,9],[211,9]]},"657":{"position":[[182,9]]},"674":{"position":[[389,9]]},"727":{"position":[[467,9]]},"755":{"position":[[129,9]]},"787":{"position":[[464,9]]},"804":{"position":[[5,10]]},"817":{"position":[[1823,9]]},"836":{"position":[[246,9]]},"844":{"position":[[515,9],[546,9]]},"1137":{"position":[[888,9],[1231,9]]},"1142":{"position":[[811,9],[968,9]]},"1160":{"position":[[191,9],[628,9]]},"1194":{"position":[[14,9]]}}}],["efficientnet",{"_index":171,"t":{"25":{"position":[[244,12]]},"27":{"position":[[34,12],[94,12]]},"31":{"position":[[0,12]]},"33":{"position":[[0,12],[243,12]]},"35":{"position":[[0,12],[146,12]]},"38":{"position":[[74,12],[255,12]]},"40":{"position":[[32,12],[131,12]]},"53":{"position":[[99,12]]},"55":{"position":[[57,12]]},"68":{"position":[[17,13]]},"76":{"position":[[134,12],[192,12]]},"78":{"position":[[782,12]]},"110":{"position":[[53,12]]}}}],["efficientnetn2",{"_index":320,"t":{"60":{"position":[[12,14]]}}}],["efficientnetv2",{"_index":142,"t":{"23":{"position":[[0,15]]},"40":{"position":[[3,14]]},"42":{"position":[[15,14],[46,14],[124,14]]},"44":{"position":[[93,14]]},"55":{"position":[[38,14],[104,14]]},"65":{"position":[[27,14]]},"68":{"position":[[0,14]]}}}],["ek",{"_index":251,"t":{"49":{"position":[[192,5]]}}}],["eleanor",{"_index":2888,"t":{"951":{"position":[[297,8]]}}}],["electr",{"_index":1022,"t":{"302":{"position":[[263,13]]}}}],["elemen",{"_index":3607,"t":{"1152":{"position":[[164,6]]}}}],["element",{"_index":1391,"t":{"427":{"position":[[748,7],[904,7],[2777,7]]},"510":{"position":[[250,7]]},"1137":{"position":[[1127,7]]}}}],["elementum",{"_index":9,"t":{"3":{"position":[[70,9]]},"5":{"position":[[190,9],[369,9],[548,9],[727,9],[906,9],[1085,9],[1264,9],[1443,9],[1622,9],[1801,9],[1980,9],[2159,9],[2338,9],[2517,9],[2696,9],[2875,9]]}}}],["elementwis",{"_index":1437,"t":{"427":{"position":[[2675,11]]}}}],["eleph",{"_index":2458,"t":{"802":{"position":[[233,10]]}}}],["elit",{"_index":7,"t":{"3":{"position":[[51,5]]},"5":{"position":[[171,5],[350,5],[529,5],[708,5],[887,5],[1066,5],[1245,5],[1424,5],[1603,5],[1782,5],[1961,5],[2140,5],[2319,5],[2498,5],[2677,5],[2856,5]]}}}],["elmo",{"_index":2470,"t":{"817":{"position":[[49,4]]}}}],["em",{"_index":2655,"t":{"857":{"position":[[332,4]]},"1174":{"position":[[166,2]]}}}],["ema",{"_index":301,"t":{"53":{"position":[[284,5]]}}}],["embed",{"_index":399,"t":{"91":{"position":[[31,9],[105,9],[581,9],[785,9],[810,9],[1132,9],[1171,9],[1189,9],[1222,9],[1263,9],[1276,9]]},"93":{"position":[[214,9],[236,9]]},"95":{"position":[[94,9],[328,9]]},"97":{"position":[[339,9],[385,9]]},"116":{"position":[[214,9],[235,9],[326,9],[402,9],[438,9],[515,9]]},"171":{"position":[[763,9]]},"174":{"position":[[292,9],[318,10],[422,9],[496,9]]},"176":{"position":[[183,9],[314,9]]},"288":{"position":[[75,9]]},"343":{"position":[[398,10],[533,10]]},"345":{"position":[[210,9],[638,9],[757,9]]},"357":{"position":[[76,9]]},"427":{"position":[[500,9],[3404,10]]},"429":{"position":[[27,10],[223,10]]},"510":{"position":[[179,9]]},"583":{"position":[[7,9],[37,9]]},"595":{"position":[[116,9]]},"627":{"position":[[491,10],[521,9],[770,10]]},"659":{"position":[[357,10]]},"678":{"position":[[129,10]]},"684":{"position":[[87,10],[127,10]]},"686":{"position":[[165,9],[216,10],[400,10],[1703,9]]},"688":{"position":[[106,9],[332,10],[388,10],[656,10],[1115,9]]},"698":{"position":[[1091,10],[1160,9],[1635,10]]},"713":{"position":[[765,9],[798,10]]},"718":{"position":[[65,9],[252,9],[568,10],[631,9]]},"727":{"position":[[63,9],[187,10]]},"730":{"position":[[21,10]]},"773":{"position":[[759,10],[891,10]]},"798":{"position":[[29,9],[50,9],[77,9],[180,9],[226,9],[300,9],[330,9],[413,9]]},"819":{"position":[[742,9],[1066,10],[1219,10],[1532,9],[1545,9],[1752,8]]},"821":{"position":[[134,9],[491,9],[583,9],[735,9]]},"832":{"position":[[399,9],[482,9],[845,9]]},"836":{"position":[[411,8]]},"842":{"position":[[164,9],[346,9],[1067,9]]},"870":{"position":[[223,9]]},"883":{"position":[[749,9]]},"901":{"position":[[1365,9],[2071,8],[2130,9]]},"913":{"position":[[112,9],[143,9]]},"951":{"position":[[550,9]]},"961":{"position":[[117,9]]},"963":{"position":[[426,9]]},"1087":{"position":[[2022,9]]},"1092":{"position":[[437,9],[1304,9],[1476,9]]},"1094":{"position":[[161,9]]},"1096":{"position":[[1186,9],[1395,9],[1601,9],[1688,9],[1763,9],[1971,9]]},"1099":{"position":[[1392,9]]},"1101":{"position":[[136,9]]},"1125":{"position":[[25,9],[153,9]]},"1127":{"position":[[269,9]]},"1203":{"position":[[464,9]]},"1205":{"position":[[21,9],[302,9]]},"1214":{"position":[[192,9]]},"1222":{"position":[[182,9],[548,9],[855,9]]},"1224":{"position":[[141,9]]}}}],["empir",{"_index":867,"t":{"227":{"position":[[248,9]]}}}],["empti",{"_index":2568,"t":{"834":{"position":[[902,5]]}}}],["en",{"_index":3225,"t":{"1073":{"position":[[125,5],[140,6]]}}}],["encl\\textup{enc}_lencl",{"_index":3254,"t":{"1092":{"position":[[156,23],[385,23]]}}}],["encod",{"_index":428,"t":{"91":{"position":[[894,7],[1306,7],[1331,7],[1929,8],[2120,7]]},"120":{"position":[[95,7]]},"132":{"position":[[74,7],[106,7],[140,7]]},"143":{"position":[[282,7]]},"153":{"position":[[749,7]]},"169":{"position":[[10,7],[474,7]]},"171":{"position":[[151,8]]},"176":{"position":[[224,7]]},"180":{"position":[[73,7],[242,7]]},"183":{"position":[[82,7]]},"209":{"position":[[73,7]]},"221":{"position":[[137,8]]},"281":{"position":[[674,7],[827,7]]},"288":{"position":[[209,7]]},"302":{"position":[[520,7],[1077,7]]},"311":{"position":[[141,7]]},"328":{"position":[[52,8],[84,7],[335,7]]},"330":{"position":[[282,7],[372,7],[526,7],[636,7],[679,7],[1294,8],[1357,8],[1434,7]]},"333":{"position":[[77,7]]},"337":{"position":[[0,7]]},"339":{"position":[[304,7]]},"343":{"position":[[204,7],[589,7],[649,7],[744,7],[763,7],[808,7]]},"345":{"position":[[327,7],[938,7]]},"347":{"position":[[9,7]]},"349":{"position":[[65,9],[232,7],[262,7],[443,7],[652,7]]},"353":{"position":[[0,7],[115,7],[176,7]]},"355":{"position":[[8,7],[94,7]]},"357":{"position":[[51,7],[161,7]]},"362":{"position":[[164,7]]},"396":{"position":[[116,7]]},"406":{"position":[[22,7],[208,7]]},"423":{"position":[[221,7]]},"427":{"position":[[1233,7],[2010,7],[2189,7]]},"437":{"position":[[330,7],[349,8],[408,7]]},"441":{"position":[[63,7]]},"465":{"position":[[200,7]]},"482":{"position":[[79,7]]},"510":{"position":[[66,7]]},"523":{"position":[[170,7],[189,8],[304,7]]},"525":{"position":[[510,7],[542,8]]},"569":{"position":[[103,7]]},"648":{"position":[[164,7]]},"688":{"position":[[512,7]]},"730":{"position":[[67,7]]},"768":{"position":[[45,7],[118,7],[179,8],[335,7]]},"775":{"position":[[109,7]]},"819":{"position":[[339,7],[1874,7]]},"823":{"position":[[43,7]]},"836":{"position":[[745,7],[802,7]]},"850":{"position":[[1975,8]]},"901":{"position":[[1257,7]]},"1087":{"position":[[1903,7],[1930,7]]},"1092":{"position":[[146,7],[618,7],[1009,7]]},"1094":{"position":[[38,7]]},"1096":{"position":[[143,7],[211,7],[478,7],[621,7]]},"1099":{"position":[[1369,7]]},"1104":{"position":[[64,7],[95,7],[170,7],[206,7]]},"1179":{"position":[[59,7]]},"1200":{"position":[[86,7],[101,7]]},"1203":{"position":[[326,8],[340,7],[370,7],[417,7]]},"1207":{"position":[[600,8]]},"1214":{"position":[[132,8],[225,7],[401,7]]},"1222":{"position":[[709,7],[817,7],[1279,7],[1334,7],[1430,7],[1445,7]]},"1224":{"position":[[111,7],[193,7]]},"1230":{"position":[[83,7]]}}}],["encv\\textup{enc}_{\\textup{v}}encv",{"_index":3303,"t":{"1094":{"position":[[46,34]]}}}],["encvref\\textup{enc}_{\\textup{v}}^{\\textup{ref}}encvref",{"_index":3259,"t":{"1092":{"position":[[628,55],[1017,55]]}}}],["end",{"_index":824,"t":{"190":{"position":[[265,5],[424,5],[438,5],[449,4],[549,5]]},"279":{"position":[[203,3],[210,3],[288,3],[295,3],[504,3],[511,3],[674,3],[681,3]]},"281":{"position":[[928,3],[935,3],[1051,3],[1058,3],[1763,3],[1770,3],[2060,3],[2067,3],[2220,3],[2227,3]]},"320":{"position":[[15,3],[22,3]]},"324":{"position":[[202,3],[209,3]]},"398":{"position":[[816,5]]},"502":{"position":[[65,5],[877,5]]},"504":{"position":[[904,5]]},"815":{"position":[[237,3],[244,3]]},"817":{"position":[[1619,3],[1626,3]]},"883":{"position":[[620,3],[669,3]]}}}],["endoer",{"_index":735,"t":{"169":{"position":[[50,6]]}}}],["end{align",{"_index":1698,"t":{"515":{"position":[[735,11]]},"688":{"position":[[911,12]]}}}],["end{align}i(t)(wij​)u(t)(wij​)​=β1​i(t−1)(wij​)+(1−β1​)i(t)(wij​)=β2​u(t−1)(wij​)+(1−β2​)∣∣​i(t)(wij​)−i(t)(wij",{"_index":3645,"t":{"1152":{"position":[[1939,120]]}}}],["end{align}​ql​=linearq",{"_index":1565,"t":{"463":{"position":[[689,25]]}}}],["end{array",{"_index":3298,"t":{"1092":{"position":[[2305,11]]},"1094":{"position":[[597,11]]},"1096":{"position":[[2242,11]]}}}],["end{equation}[pl​;tl​]∈r(k+m)×c",{"_index":1542,"t":{"461":{"position":[[824,34]]}}}],["end{equation}h=w(0)x+△x=w(0)x+bax",{"_index":3484,"t":{"1142":{"position":[[217,37]]}}}],["end{equation}h^0:m​=hargmin",{"_index":2210,"t":{"686":{"position":[[2075,29]]}}}],["end{equation}hi​=lmϕ​(zi​,h<i",{"_index":2353,"t":{"766":{"position":[[751,35]]}}}],["end{equation}hi​={pθ​[i,:],lmϕ​(zi​,h<i​),​ifi∈pidx​otherwis",{"_index":2404,"t":{"775":{"position":[[835,66]]}}}],["end{equation}hi​​=mlp([hi",{"_index":2227,"t":{"688":{"position":[[924,27]]}}}],["end{equation}i(wij​)=∣∣​wij​▽wij​​l",{"_index":3629,"t":{"1152":{"position":[[1110,42]]}}}],["end{equation}ip​=projection(concat({im​}m=1m",{"_index":1623,"t":{"465":{"position":[[560,50]]}}}],["end{equation}lln​=−logexp(β(x,y))+∑n=1n​exp(β(x,y^​(n)))exp(β(x,i",{"_index":1383,"t":{"425":{"position":[[2196,71]]}}}],["end{equation}lul​=−∑n=1n​t(n)∑nn​=1∑t=1t(n)​log(1−p(y^​i(n)​∣x,y^​<t(n",{"_index":1359,"t":{"425":{"position":[[667,78]]}}}],["end{equation}plv​=pl​+repeat(ip​)∈rk×c",{"_index":1630,"t":{"465":{"position":[[987,41]]}}}],["end{equation}r(p,q)=∥∥​p⊤p−i∥∥​f2​=∥∥​qq⊤−i∥∥​f2",{"_index":3525,"t":{"1146":{"position":[[1047,53]]}}}],["end{equation}s(t)(wij​)=i(t)(wij​)⋅u(t)(wij",{"_index":3653,"t":{"1152":{"position":[[2575,49]]}}}],["end{equation}sk,i​=s(λk,i​)+d1​1​j=1∑d1​​s(pk,ji​)+d2​1​j=1∑d2​​s(qk,ij",{"_index":3619,"t":{"1152":{"position":[[634,77]]}}}],["end{equation}slg​=[softmax(slk​)⋅gl",{"_index":1599,"t":{"463":{"position":[[1861,38]]}}}],["end{equation}sl​=[slk​;slm+1​]t",{"_index":1584,"t":{"463":{"position":[[1171,34]]}}}],["end{equation}sl​=ql​klt​/c​∈r1×(k+m+1",{"_index":1576,"t":{"463":{"position":[[950,41]]}}}],["end{equation}softmax(dk​​q(lk​⊙kt)​)(lv​⊙v",{"_index":1417,"t":{"427":{"position":[[1687,46]]}}}],["end{equation}tlo​=linearo​(slg​vl​)∈r1×c",{"_index":1606,"t":{"463":{"position":[[2379,43]]}}}],["end{equation}w=w(0)+△=w(0)+ba",{"_index":3418,"t":{"1137":{"position":[[1728,33]]}}}],["end{equation}w=w(0)+△=w(0)+pλq",{"_index":3500,"t":{"1146":{"position":[[182,34]]}}}],["end{equation}{e([p0:i​]),e(x),e([pi+1:m​]),e(i",{"_index":2193,"t":{"686":{"position":[[1358,51]]}}}],["end{equation}{h0​,…hi​,e(x),hi+1​,…hm​,e(i",{"_index":2200,"t":{"686":{"position":[[1602,47]]}}}],["end{equation}λk(t+1)​=t(λ~k(t)​,sk(t)​),witht(λ~k(t)​,sk(t)​)ii​={λ~k,iit​0​sk,it",{"_index":3596,"t":{"1148":{"position":[[2088,83]]}}}],["end{equation}λ~k(t)​=λk(t)​−η▽λk​​l(p(t).e(t),q(t",{"_index":3578,"t":{"1148":{"position":[[1514,55]]}}}],["end{equation}ϕmax",{"_index":2376,"t":{"770":{"position":[[364,19]]}}}],["end{matrix}\\right",{"_index":2403,"t":{"775":{"position":[[815,19]]},"1148":{"position":[[2068,19]]}}}],["engin",{"_index":1712,"t":{"525":{"position":[[303,7],[706,6]]},"678":{"position":[[374,11]]},"680":{"position":[[696,11]]},"842":{"position":[[1858,12]]},"876":{"position":[[86,11],[189,11],[520,11],[889,11],[1243,11]]},"889":{"position":[[135,11],[281,11]]},"891":{"position":[[16,11]]},"903":{"position":[[13,11]]},"917":{"position":[[152,11]]},"933":{"position":[[370,11]]},"935":{"position":[[410,11]]},"937":{"position":[[267,11],[293,11],[440,11],[554,11]]},"947":{"position":[[267,11],[308,11]]},"949":{"position":[[269,11]]},"963":{"position":[[1200,6]]},"969":{"position":[[252,11],[438,11]]},"1198":{"position":[[156,11],[424,11],[584,11]]},"1200":{"position":[[337,11],[912,11],[1693,11],[1950,11]]},"1205":{"position":[[105,11]]},"1209":{"position":[[37,11]]},"1220":{"position":[[132,11]]},"1232":{"position":[[117,11]]},"1240":{"position":[[83,11],[146,11]]},"1242":{"position":[[52,11]]}}}],["english",{"_index":2722,"t":{"883":{"position":[[510,8]]}}}],["english:i",{"_index":2706,"t":{"876":{"position":[[1031,10]]}}}],["enqueu",{"_index":1126,"t":{"343":{"position":[[679,7]]}}}],["ensembl",{"_index":2469,"t":{"815":{"position":[[634,10]]},"817":{"position":[[2381,10],[2654,10]]},"840":{"position":[[6,10],[349,10],[536,10],[628,10]]},"844":{"position":[[579,10]]},"917":{"position":[[7,10],[203,10],[1250,10],[1309,10]]},"943":{"position":[[386,8]]},"963":{"position":[[61,8]]},"975":{"position":[[7,10],[27,10],[267,8],[364,10]]},"1218":{"position":[[240,8]]}}}],["entail",{"_index":791,"t":{"180":{"position":[[527,10]]},"698":{"position":[[164,10]]}}}],["entangl",{"_index":2958,"t":{"969":{"position":[[695,12]]}}}],["entir",{"_index":2481,"t":{"817":{"position":[[1504,6]]},"842":{"position":[[776,9],[833,8],[900,11]]}}}],["entiti",{"_index":2250,"t":{"694":{"position":[[684,6]]},"713":{"position":[[1529,6]]},"716":{"position":[[158,6]]},"740":{"position":[[61,6]]},"905":{"position":[[328,6]]},"909":{"position":[[541,6]]},"923":{"position":[[243,7]]},"949":{"position":[[432,6],[529,6],[562,6]]},"969":{"position":[[480,6]]}}}],["entitiy",{"_index":2796,"t":{"909":{"position":[[307,7]]}}}],["entri",{"_index":1406,"t":{"427":{"position":[[1085,5]]},"1137":{"position":[[1098,5],[1469,5]]},"1146":{"position":[[1673,7]]},"1152":{"position":[[121,7],[273,5],[888,7]]},"1188":{"position":[[55,5]]}}}],["entropi",{"_index":825,"t":{"193":{"position":[[9,7]]},"425":{"position":[[98,7],[1885,7]]},"825":{"position":[[668,7]]},"919":{"position":[[607,7]]},"1222":{"position":[[1241,7]]}}}],["enviro",{"_index":2624,"t":{"850":{"position":[[895,10]]}}}],["environ",{"_index":2649,"t":{"855":{"position":[[191,11]]}}}],["eo",{"_index":1130,"t":{"345":{"position":[[501,5],[623,5]]},"379":{"position":[[289,3]]}}}],["epepep",{"_index":2520,"t":{"821":{"position":[[712,6]]}}}],["episod",{"_index":2612,"t":{"848":{"position":[[318,8]]},"850":{"position":[[1373,8]]}}}],["epoch",{"_index":179,"t":{"25":{"position":[[580,6]]},"53":{"position":[[212,5],[251,5]]},"78":{"position":[[480,6]]},"80":{"position":[[10,5]]},"114":{"position":[[112,6],[151,6],[201,6],[236,6],[290,6],[327,6]]},"143":{"position":[[540,6]]},"475":{"position":[[121,5],[146,5]]},"491":{"position":[[163,5]]},"648":{"position":[[89,6]]},"698":{"position":[[1472,5],[1535,5]]},"784":{"position":[[231,7],[290,6],[453,5],[485,5],[557,5]]},"1001":{"position":[[245,6],[345,5]]},"1179":{"position":[[136,6]]},"1236":{"position":[[53,5],[94,5]]}}}],["epose_{pos}epo",{"_index":459,"t":{"91":{"position":[[1883,16]]}}}],["epos​∈r(n+1)×d",{"_index":458,"t":{"91":{"position":[[1826,14]]}}}],["epos∈r(n+1)×dz_o",{"_index":447,"t":{"91":{"position":[[1565,16]]}}}],["epsilon",{"_index":266,"t":{"49":{"position":[[539,10]]}}}],["eq",{"_index":1375,"t":{"425":{"position":[[1863,3]]},"463":{"position":[[1658,2]]},"635":{"position":[[237,2],[799,2]]},"664":{"position":[[59,2]]},"768":{"position":[[410,3]]},"775":{"position":[[365,3],[923,3]]},"1146":{"position":[[1752,3]]},"1148":{"position":[[841,3]]},"1152":{"position":[[1193,3],[1305,3],[1465,3],[2713,4],[2735,4]]},"1158":{"position":[[341,3]]},"1188":{"position":[[30,3],[138,3]]},"1190":{"position":[[130,3],[253,4],[330,4]]}}}],["equal",{"_index":353,"t":{"78":{"position":[[219,7]]}}}],["equat",{"_index":909,"t":{"248":{"position":[[92,8],[242,8]]}}}],["equivari",{"_index":378,"t":{"86":{"position":[[365,12]]}}}],["ero",{"_index":15,"t":{"3":{"position":[[128,4]]},"5":{"position":[[248,4],[427,4],[606,4],[785,4],[964,4],[1143,4],[1322,4],[1501,4],[1680,4],[1859,4],[2038,4],[2217,4],[2396,4],[2575,4],[2754,4],[2933,4]]}}}],["error",{"_index":2566,"t":{"834":{"position":[[867,5]]},"850":{"position":[[645,6]]},"859":{"position":[[759,6]]}}}],["estim",{"_index":1463,"t":{"437":{"position":[[149,9],[455,9]]}}}],["et",{"_index":1115,"t":{"343":{"position":[[142,2]]},"349":{"position":[[189,2],[313,2]]},"362":{"position":[[1099,2]]},"427":{"position":[[1507,2]]}}}],["eta",{"_index":3573,"t":{"1148":{"position":[[1413,4]]}}}],["etc",{"_index":1284,"t":{"416":{"position":[[318,4]]}}}],["eurosat",{"_index":3822,"t":{"1238":{"position":[[59,7]]}}}],["evalu",{"_index":888,"t":{"240":{"position":[[80,10]]},"366":{"position":[[261,10]]},"368":{"position":[[611,10]]},"379":{"position":[[362,10]]},"398":{"position":[[993,10]]},"408":{"position":[[147,10]]},"423":{"position":[[1223,10]]},"425":{"position":[[1534,10],[1606,10]]},"437":{"position":[[723,10]]},"694":{"position":[[521,11]]},"850":{"position":[[1045,10],[1065,10],[1451,10]]},"853":{"position":[[67,9]]},"857":{"position":[[22,9],[226,9],[393,10],[514,9]]},"863":{"position":[[63,9],[469,9],[523,9]]}}}],["exact",{"_index":1165,"t":{"360":{"position":[[294,5]]},"384":{"position":[[156,5]]},"418":{"position":[[1018,5]]},"857":{"position":[[320,5]]}}}],["exam",{"_index":1230,"t":{"382":{"position":[[145,4]]}}}],["exampl",{"_index":881,"t":{"229":{"position":[[1173,8]]},"259":{"position":[[47,7],[126,7],[158,7]]},"377":{"position":[[191,7]]},"379":{"position":[[212,7]]},"398":{"position":[[132,8],[627,8]]},"416":{"position":[[97,8],[188,8]]},"418":{"position":[[558,7],[675,7],[725,7],[1513,8]]},"421":{"position":[[210,8]]},"423":{"position":[[16,8],[409,8],[634,7]]},"425":{"position":[[1164,7]]},"427":{"position":[[271,8],[322,7],[362,8]]},"431":{"position":[[569,7]]},"437":{"position":[[770,7],[965,8],[1048,7]]},"439":{"position":[[355,8]]},"441":{"position":[[288,7],[381,8]]},"443":{"position":[[160,7]]},"447":{"position":[[208,7]]},"504":{"position":[[105,8]]},"519":{"position":[[182,8]]},"533":{"position":[[381,8]]},"648":{"position":[[21,8]]},"653":{"position":[[13,8]]},"759":{"position":[[640,8]]},"784":{"position":[[439,8]]},"791":{"position":[[65,7]]},"815":{"position":[[194,8]]},"817":{"position":[[532,8]]},"823":{"position":[[358,7]]},"825":{"position":[[622,7]]},"836":{"position":[[352,8],[508,7]]},"840":{"position":[[393,7],[442,7]]}}}],["examplar",{"_index":1216,"t":{"377":{"position":[[165,8]]}}}],["excel",{"_index":2726,"t":{"885":{"position":[[113,13]]},"887":{"position":[[202,12]]}}}],["exemplar",{"_index":870,"t":{"227":{"position":[[282,8]]},"229":{"position":[[488,8]]},"231":{"position":[[159,8]]},"240":{"position":[[38,9],[118,9],[151,9],[226,8]]},"242":{"position":[[175,8],[251,8]]},"254":{"position":[[80,9],[361,9],[447,8],[600,9]]},"269":{"position":[[320,8]]},"271":{"position":[[102,9],[446,8]]},"279":{"position":[[412,8]]},"290":{"position":[[220,8],[249,8],[363,8]]},"292":{"position":[[427,8],[636,8],[720,8],[756,8]]},"294":{"position":[[47,8]]},"300":{"position":[[791,8],[902,8],[931,8],[986,8],[1071,8]]},"302":{"position":[[4,8]]},"304":{"position":[[70,8],[285,8]]},"394":{"position":[[0,8]]}}}],["exp",{"_index":2046,"t":{"633":{"position":[[1231,4]]},"1214":{"position":[[561,4],[619,4]]},"1222":{"position":[[976,4],[1028,4]]}}}],["exp(\\beta(\\text{x",{"_index":1381,"t":{"425":{"position":[[2151,20]]}}}],["expand",{"_index":2744,"t":{"889":{"position":[[373,9]]}}}],["expect",{"_index":2540,"t":{"823":{"position":[[1281,8]]},"842":{"position":[[1447,8]]},"857":{"position":[[280,8]]}}}],["expens",{"_index":163,"t":{"25":{"position":[[128,9]]}}}],["experi",{"_index":2681,"t":{"863":{"position":[[442,10]]}}}],["experiments/blob/main/image%20classification/models/net/efficientnet.pi",{"_index":371,"t":{"80":{"position":[[128,71]]}}}],["expert",{"_index":723,"t":{"163":{"position":[[163,7],[212,7],[242,6]]},"165":{"position":[[277,7],[693,7],[704,6],[965,7],[998,7]]},"169":{"position":[[604,6],[672,6]]},"171":{"position":[[28,7],[53,7],[230,7],[380,6],[400,7],[433,7],[706,7],[869,7]]},"174":{"position":[[3,7],[415,6]]},"176":{"position":[[50,7],[102,7],[132,7],[154,7]]},"183":{"position":[[13,7]]},"197":{"position":[[400,7]]},"202":{"position":[[29,7],[133,7]]},"204":{"position":[[14,6],[123,7]]},"206":{"position":[[36,6],[152,6]]},"219":{"position":[[35,6],[131,7]]},"221":{"position":[[46,7],[102,7],[177,7]]},"223":{"position":[[13,7]]},"408":{"position":[[34,7]]},"457":{"position":[[931,6]]},"502":{"position":[[709,6]]},"504":{"position":[[2028,6],[2079,6],[2146,6],[2568,6],[2587,6]]},"525":{"position":[[314,6],[420,6],[554,6],[653,6],[717,6],[788,6]]},"535":{"position":[[313,6]]},"541":{"position":[[48,6],[114,6],[223,6]]},"543":{"position":[[378,6],[397,6],[477,6]]}}}],["expertis",{"_index":1518,"t":{"457":{"position":[[879,9]]}}}],["explain",{"_index":943,"t":{"273":{"position":[[143,7]]}}}],["explan",{"_index":1260,"t":{"398":{"position":[[96,12],[172,12]]}}}],["explicitli",{"_index":3123,"t":{"1036":{"position":[[279,10]]}}}],["exploit",{"_index":2516,"t":{"821":{"position":[[324,11]]},"895":{"position":[[288,10]]}}}],["explor",{"_index":1784,"t":{"557":{"position":[[118,10]]},"823":{"position":[[570,10]]}}}],["exponenti",{"_index":298,"t":{"53":{"position":[[257,11]]},"1152":{"position":[[2138,11]]},"1165":{"position":[[519,11]]}}}],["export",{"_index":3142,"t":{"1040":{"position":[[135,6]]},"1061":{"position":[[104,6]]}}}],["express",{"_index":3242,"t":{"1085":{"position":[[684,10]]},"1087":{"position":[[398,10],[440,10],[546,11],[1504,11]]},"1090":{"position":[[214,10]]},"1092":{"position":[[350,10]]},"1096":{"position":[[1843,10]]},"1101":{"position":[[158,10]]}}}],["expressionb",{"_index":3240,"t":{"1085":{"position":[[141,13]]}}}],["ext",{"_index":3379,"t":{"1111":{"position":[[36,4]]}}}],["extra",{"_index":2491,"t":{"819":{"position":[[446,5]]}}}],["extract",{"_index":59,"t":{"9":{"position":[[199,9]]},"713":{"position":[[1491,10]]},"716":{"position":[[179,10]]},"740":{"position":[[81,10]]},"905":{"position":[[310,10]]},"921":{"position":[[106,10]]},"949":{"position":[[59,10],[106,10]]},"953":{"position":[[99,10]]},"969":{"position":[[130,10]]},"997":{"position":[[154,11]]}}}],["extrapol",{"_index":2446,"t":{"793":{"position":[[48,13],[68,13],[325,13],[553,13],[614,13],[685,13]]}}}],["e}[pe​;xe​]∈r(p+n)×",{"_index":2512,"t":{"819":{"position":[[1846,20]]}}}],["e}pe​∈rp×",{"_index":2508,"t":{"819":{"position":[[1703,10]]}}}],["e}xe​∈rn×",{"_index":2505,"t":{"819":{"position":[[1620,10]]}}}],["e∈m",{"_index":2164,"t":{"686":{"position":[[181,4]]}}}],["e∈rn×(p2⋅c",{"_index":446,"t":{"91":{"position":[[1552,12],[1813,12]]}}}],["f",{"_index":1290,"t":{"416":{"position":[[603,1]]}}}],["f'_p",{"_index":3317,"t":{"1094":{"position":[[573,4]]},"1096":{"position":[[2197,4]]}}}],["f'_p[i",{"_index":3333,"t":{"1096":{"position":[[2106,8]]}}}],["f'_v",{"_index":3315,"t":{"1094":{"position":[[549,4]]}}}],["f(f(3))f(f(3))f(f(3",{"_index":2895,"t":{"951":{"position":[[673,21]]}}}],["f(x)=x∗xf(x",{"_index":2893,"t":{"951":{"position":[[643,12]]}}}],["f1",{"_index":2580,"t":{"838":{"position":[[582,2],[1122,2]]},"1115":{"position":[[140,2]]},"1137":{"position":[[4703,2]]},"1174":{"position":[[171,2]]},"1184":{"position":[[329,2],[371,3]]}}}],["f\\mathcal{f}f",{"_index":3390,"t":{"1113":{"position":[[112,14],[218,13]]},"1121":{"position":[[142,14]]}}}],["f^{imag",{"_index":3765,"t":{"1214":{"position":[[582,9],[639,9]]},"1222":{"position":[[992,9],[1044,9]]}}}],["f^{text}_c",{"_index":3760,"t":{"1214":{"position":[[272,10],[569,10]]}}}],["f^{text}_j",{"_index":3767,"t":{"1214":{"position":[[627,11]]}}}],["f_",{"_index":3340,"t":{"1096":{"position":[[2435,3]]}}}],["f_p",{"_index":3314,"t":{"1094":{"position":[[541,4],[580,3]]}}}],["f_v",{"_index":3316,"t":{"1094":{"position":[[556,3]]}}}],["f_{p2v",{"_index":3310,"t":{"1094":{"position":[[500,8],[562,8]]}}}],["f_{v2p",{"_index":3311,"t":{"1094":{"position":[[509,7],[586,7]]}}}],["fabul",{"_index":2740,"t":{"887":{"position":[[215,11]]}}}],["face",{"_index":2425,"t":{"784":{"position":[[163,4]]}}}],["facebook",{"_index":3205,"t":{"1061":{"position":[[539,8]]}}}],["facet",{"_index":2658,"t":{"857":{"position":[[559,7]]}}}],["fact",{"_index":2235,"t":{"692":{"position":[[21,4]]},"1016":{"position":[[208,4]]}}}],["factor",{"_index":223,"t":{"38":{"position":[[119,10]]},"427":{"position":[[2224,6]]},"463":{"position":[[1483,6]]},"471":{"position":[[175,6]]},"508":{"position":[[367,6]]},"515":{"position":[[183,6],[440,6],[760,6]]},"519":{"position":[[573,6]]}}}],["factoris",{"_index":778,"t":{"180":{"position":[[125,13]]}}}],["factr",{"_index":2869,"t":{"943":{"position":[[207,5]]}}}],["factual",{"_index":2868,"t":{"943":{"position":[[0,7]]}}}],["failur",{"_index":1727,"t":{"537":{"position":[[621,7]]},"850":{"position":[[949,7]]},"859":{"position":[[421,7]]}}}],["fals",{"_index":75,"t":{"9":{"position":[[456,5]]},"751":{"position":[[294,7],[326,7]]}}}],["fast",{"_index":2018,"t":{"631":{"position":[[870,6]]}}}],["faster",{"_index":696,"t":{"153":{"position":[[48,6],[112,6],[137,6],[346,6],[450,6]]}}}],["fctextf^{text}_cfctext",{"_index":3762,"t":{"1214":{"position":[[320,23]]}}}],["fctext}c=1c",{"_index":3759,"t":{"1214":{"position":[[257,14]]}}}],["fear",{"_index":2800,"t":{"909":{"position":[[469,8]]}}}],["featur",{"_index":34,"t":{"7":{"position":[[39,9]]},"9":{"position":[[20,8]]},"88":{"position":[[410,7]]},"95":{"position":[[40,7],[131,7],[210,7],[292,7]]},"104":{"position":[[381,7]]},"169":{"position":[[178,8],[266,8]]},"176":{"position":[[288,8],[389,8],[505,8]]},"178":{"position":[[12,8],[149,7]]},"180":{"position":[[264,7]]},"221":{"position":[[68,8]]},"302":{"position":[[684,7]]},"343":{"position":[[40,7]]},"461":{"position":[[343,7]]},"463":{"position":[[1044,7]]},"465":{"position":[[240,7],[389,8],[686,7]]},"482":{"position":[[50,7]]},"504":{"position":[[614,7],[1078,7]]},"510":{"position":[[106,7],[217,7]]},"512":{"position":[[179,7]]},"537":{"position":[[48,7]]},"876":{"position":[[78,7],[125,7],[241,7]]},"899":{"position":[[882,7]]},"963":{"position":[[415,7]]},"1049":{"position":[[50,9]]},"1059":{"position":[[99,7],[191,7]]},"1090":{"position":[[579,7]]},"1092":{"position":[[1149,7]]},"1094":{"position":[[109,8],[189,8],[368,8],[683,7]]},"1096":{"position":[[78,8],[254,7],[398,7],[609,8],[901,8],[1157,8],[2379,8]]},"1125":{"position":[[7,8],[293,7],[328,7]]},"1200":{"position":[[638,7]]},"1205":{"position":[[272,7],[288,7]]},"1214":{"position":[[422,7]]},"1222":{"position":[[729,7]]},"1224":{"position":[[213,7]]}}}],["feature/represent",{"_index":594,"t":{"126":{"position":[[645,22]]}}}],["feed",{"_index":1281,"t":{"416":{"position":[[108,7]]},"427":{"position":[[1313,4],[1431,4],[1751,4],[1858,4],[3209,4]]},"1028":{"position":[[95,7]]},"1137":{"position":[[2645,4]]}}}],["feedback",{"_index":1272,"t":{"398":{"position":[[920,9],[968,8]]},"848":{"position":[[271,8],[455,8],[673,8],[690,8]]},"850":{"position":[[349,8],[378,8],[469,8],[770,8],[906,8],[1271,8]]},"859":{"position":[[58,8],[291,8],[310,8],[824,8]]},"863":{"position":[[264,8],[453,8]]},"985":{"position":[[150,8]]},"987":{"position":[[229,8]]},"989":{"position":[[291,8]]},"1013":{"position":[[32,8],[65,8]]},"1016":{"position":[[39,8]]},"1022":{"position":[[315,8]]}}}],["feedforward",{"_index":484,"t":{"97":{"position":[[134,11]]},"551":{"position":[[355,11]]},"777":{"position":[[109,11]]}}}],["feel",{"_index":3108,"t":{"1030":{"position":[[456,4]]}}}],["few",{"_index":532,"t":{"108":{"position":[[0,3],[203,3]]},"112":{"position":[[370,3]]},"126":{"position":[[765,3]]},"143":{"position":[[214,3],[621,3]]},"163":{"position":[[372,3]]},"197":{"position":[[0,3],[227,3],[273,3],[340,3]]},"217":{"position":[[97,3]]},"229":{"position":[[389,3],[471,3],[644,3],[773,3],[1169,3]]},"231":{"position":[[140,3],[439,3]]},"238":{"position":[[59,3]]},"240":{"position":[[15,3],[109,3]]},"254":{"position":[[71,3]]},"259":{"position":[[34,3],[113,3]]},"271":{"position":[[437,3]]},"279":{"position":[[598,3]]},"281":{"position":[[1231,3],[1646,3],[2317,3]]},"288":{"position":[[149,3]]},"290":{"position":[[166,3]]},"292":{"position":[[407,3]]},"306":{"position":[[15,3]]},"313":{"position":[[99,3],[167,3]]},"320":{"position":[[42,3]]},"368":{"position":[[466,3]]},"377":{"position":[[125,3]]},"398":{"position":[[317,3],[752,3]]},"400":{"position":[[116,3]]},"416":{"position":[[0,3],[392,3],[605,3],[696,3]]},"418":{"position":[[458,3],[608,3],[2222,3],[2285,3]]},"421":{"position":[[438,3]]},"423":{"position":[[622,3],[945,3],[1036,3]]},"425":{"position":[[21,3],[2380,3]]},"427":{"position":[[0,3],[80,3],[121,3],[3029,3],[3933,3]]},"429":{"position":[[70,3]]},"431":{"position":[[7,3],[756,3]]},"433":{"position":[[2,3],[57,3]]},"435":{"position":[[47,3],[115,3],[161,3],[236,3],[251,3],[309,3],[373,3],[411,3]]},"437":{"position":[[2,3],[49,3],[935,3]]},"439":{"position":[[12,3],[68,3],[205,3],[487,3]]},"441":{"position":[[2,3],[249,3],[326,3],[363,3],[427,3]]},"443":{"position":[[2,3]]},"445":{"position":[[53,3],[237,3]]},"447":{"position":[[0,3],[51,3],[303,3],[386,3],[436,3]]},"449":{"position":[[2,3],[40,3]]},"451":{"position":[[6,3],[20,3],[94,3],[122,3],[269,3],[384,3],[479,3],[485,3],[666,3],[696,3]]},"557":{"position":[[370,3]]},"616":{"position":[[1588,3]]},"621":{"position":[[194,3]]},"639":{"position":[[80,3]]},"648":{"position":[[374,3]]},"653":{"position":[[0,3],[102,3],[157,3]]},"678":{"position":[[436,3]]},"680":{"position":[[995,3],[1311,3],[1452,3],[1705,3],[1778,3]]},"698":{"position":[[273,3],[426,3],[450,3],[704,3],[867,3],[933,3],[1041,3],[1586,3],[1807,3],[1943,3]]},"702":{"position":[[80,3],[265,3],[515,3],[644,3],[687,3],[1036,3],[1177,3]]},"738":{"position":[[326,3]]},"815":{"position":[[274,3]]},"817":{"position":[[378,3],[916,3],[1680,3]]},"821":{"position":[[356,3]]},"823":{"position":[[1756,3]]},"827":{"position":[[563,3]]},"836":{"position":[[1767,3]]},"895":{"position":[[153,3],[319,3],[380,3],[505,3],[574,3]]},"901":{"position":[[1296,3]]},"919":{"position":[[218,3],[336,3]]},"927":{"position":[[204,3]]},"935":{"position":[[252,3]]},"937":{"position":[[110,3],[490,3]]},"945":{"position":[[76,3]]},"947":{"position":[[369,3],[570,3]]},"955":{"position":[[317,3],[368,3]]},"961":{"position":[[199,3],[227,3]]},"963":{"position":[[296,3],[574,3]]},"979":{"position":[[70,3],[169,3]]},"995":{"position":[[253,3]]},"1049":{"position":[[35,3]]},"1198":{"position":[[254,3]]},"1200":{"position":[[683,3]]},"1205":{"position":[[433,3]]}}}],["few/no",{"_index":2699,"t":{"874":{"position":[[405,6]]}}}],["few/zero",{"_index":2700,"t":{"874":{"position":[[427,8]]}}}],["fewer",{"_index":1452,"t":{"427":{"position":[[3855,5]]},"451":{"position":[[528,5]]}}}],["fewglu",{"_index":2262,"t":{"698":{"position":[[462,9]]}}}],["fewvlm",{"_index":1064,"t":{"313":{"position":[[199,6]]}}}],["fff",{"_index":3195,"t":{"1061":{"position":[[222,7]]}}}],["ffill(x′,z)f_{fill}(x",{"_index":2728,"t":{"885":{"position":[[247,23]]}}}],["ffn",{"_index":3433,"t":{"1137":{"position":[[2667,5]]},"1140":{"position":[[127,3],[789,3]]},"1142":{"position":[[846,3]]},"1160":{"position":[[391,3],[473,3]]},"1192":{"position":[[101,3],[161,3]]}}}],["ffn(x)=relu(xwfi+b1)wf2+b2\\text{ffn}(x",{"_index":3471,"t":{"1140":{"position":[[851,39]]}}}],["fgvcaircraft",{"_index":3823,"t":{"1238":{"position":[[67,12]]}}}],["field",{"_index":572,"t":{"116":{"position":[[727,5],[907,5],[923,5]]}}}],["fietun",{"_index":1239,"t":{"386":{"position":[[146,9]]}}}],["fig",{"_index":830,"t":{"195":{"position":[[0,3]]},"197":{"position":[[287,3]]},"231":{"position":[[200,4]]},"238":{"position":[[0,3]]},"240":{"position":[[136,3]]},"248":{"position":[[81,3]]},"254":{"position":[[218,3],[414,3]]},"269":{"position":[[249,4],[260,3]]},"349":{"position":[[162,4]]},"370":{"position":[[0,3],[22,3]]},"377":{"position":[[210,4]]},"392":{"position":[[162,3]]},"394":{"position":[[108,3],[223,3]]},"427":{"position":[[3741,4]]},"457":{"position":[[597,3]]},"477":{"position":[[0,3],[79,3]]},"521":{"position":[[142,5],[175,4]]},"533":{"position":[[358,4],[444,5],[483,4]]},"539":{"position":[[0,4]]},"541":{"position":[[96,4],[200,4]]},"549":{"position":[[890,3]]},"595":{"position":[[68,3]]},"604":{"position":[[932,3]]},"606":{"position":[[67,3]]},"616":{"position":[[711,4],[1218,5]]},"631":{"position":[[214,4]]},"666":{"position":[[47,3]]},"727":{"position":[[292,3]]},"775":{"position":[[237,4]]},"817":{"position":[[1739,5],[1847,5]]},"825":{"position":[[366,4]]},"827":{"position":[[331,4],[579,4]]},"830":{"position":[[116,4]]},"832":{"position":[[607,4]]},"834":{"position":[[0,4],[214,4],[427,4]]},"836":{"position":[[109,4]]},"840":{"position":[[490,4]]},"975":{"position":[[1034,4]]},"1137":{"position":[[2531,4],[2634,4],[2727,4]]},"1184":{"position":[[0,4]]},"1192":{"position":[[0,4]]}}}],["figur",{"_index":712,"t":{"155":{"position":[[654,6],[672,6],[893,6],[1032,6]]},"157":{"position":[[191,6],[333,6]]},"288":{"position":[[7,6]]},"290":{"position":[[103,6]]},"302":{"position":[[167,6]]},"657":{"position":[[61,6]]},"659":{"position":[[293,6]]},"718":{"position":[[652,6]]},"727":{"position":[[91,7]]},"761":{"position":[[1212,6],[1366,6]]},"764":{"position":[[66,6]]},"766":{"position":[[125,6]]},"768":{"position":[[256,6]]},"804":{"position":[[150,6]]},"850":{"position":[[608,6]]},"891":{"position":[[155,6]]},"1200":{"position":[[208,6],[538,7],[934,7]]},"1211":{"position":[[0,6]]},"1216":{"position":[[377,6],[702,6]]},"1218":{"position":[[143,6]]},"1222":{"position":[[621,6]]},"1230":{"position":[[46,6]]}}}],["file",{"_index":51,"t":{"9":{"position":[[81,5]]},"1030":{"position":[[9,4]]},"1034":{"position":[[18,4]]},"1038":{"position":[[22,5]]},"1040":{"position":[[9,4]]},"1042":{"position":[[9,4]]},"1044":{"position":[[124,6]]},"1046":{"position":[[57,5]]},"1053":{"position":[[66,4]]},"1055":{"position":[[228,4],[311,5]]},"1067":{"position":[[96,5]]},"1075":{"position":[[23,4]]},"1079":{"position":[[96,5]]}}}],["filenam",{"_index":60,"t":{"9":{"position":[[214,10]]}}}],["fill",{"_index":2268,"t":{"698":{"position":[[989,7]]},"885":{"position":[[292,6],[427,6]]},"899":{"position":[[1193,6]]}}}],["film",{"_index":2973,"t":{"983":{"position":[[528,5],[697,5]]}}}],["filter",{"_index":566,"t":{"116":{"position":[[338,6],[347,6],[365,6]]},"186":{"position":[[123,6]]},"398":{"position":[[479,9]]}}}],["fimagef^{image}fimag",{"_index":3763,"t":{"1214":{"position":[[432,21]]},"1222":{"position":[[737,21]]}}}],["final",{"_index":878,"t":{"229":{"position":[[210,5]]},"231":{"position":[[96,5]]},"823":{"position":[[258,5]]},"1165":{"position":[[288,5]]},"1172":{"position":[[300,5]]}}}],["financ",{"_index":2802,"t":{"909":{"position":[[496,10]]}}}],["find",{"_index":3082,"t":{"1026":{"position":[[182,4]]}}}],["fine",{"_index":207,"t":{"31":{"position":[[202,4]]},"63":{"position":[[68,4]]},"91":{"position":[[974,4],[1094,4]]},"93":{"position":[[186,4]]},"97":{"position":[[54,4],[212,4],[303,4]]},"106":{"position":[[131,4]]},"108":{"position":[[161,4]]},"112":{"position":[[344,4]]},"163":{"position":[[358,4]]},"188":{"position":[[87,4]]},"190":{"position":[[67,4]]},"193":{"position":[[39,4]]},"195":{"position":[[50,4]]},"197":{"position":[[258,4]]},"213":{"position":[[34,4],[217,4]]},"345":{"position":[[105,4]]},"416":{"position":[[246,4]]},"418":{"position":[[240,4],[255,4],[356,4],[987,4],[1324,4],[1401,4],[1470,4],[1607,4],[1933,4],[2191,4]]},"423":{"position":[[27,4],[287,4],[646,4]]},"425":{"position":[[30,4]]},"427":{"position":[[3049,4],[3679,4],[3781,4],[3958,4],[4003,4]]},"429":{"position":[[87,4],[462,4],[493,4]]},"441":{"position":[[438,4]]},"451":{"position":[[215,4]]},"455":{"position":[[60,4],[230,4],[625,4]]},"457":{"position":[[119,4],[251,4],[762,4],[1259,4],[1299,4]]},"461":{"position":[[113,4]]},"463":{"position":[[73,4]]},"465":{"position":[[1167,4]]},"469":{"position":[[199,4]]},"471":{"position":[[116,4]]},"475":{"position":[[127,4]]},"479":{"position":[[168,4]]},"491":{"position":[[6,4]]},"494":{"position":[[73,4]]},"504":{"position":[[159,4],[275,4]]},"508":{"position":[[52,4]]},"512":{"position":[[88,4]]},"515":{"position":[[207,4]]},"517":{"position":[[54,4],[323,4]]},"523":{"position":[[18,4],[611,4]]},"525":{"position":[[127,4]]},"537":{"position":[[110,4]]},"543":{"position":[[586,4]]},"547":{"position":[[19,4],[228,4]]},"549":{"position":[[77,4],[1209,4]]},"553":{"position":[[319,4],[650,4],[840,4]]},"593":{"position":[[19,4]]},"610":{"position":[[6,4],[199,4]]},"678":{"position":[[5,4]]},"680":{"position":[[419,4],[1322,4],[1573,4],[1716,4]]},"682":{"position":[[81,4],[142,4],[162,4],[245,4]]},"696":{"position":[[182,4],[284,4],[390,4],[594,4],[671,4],[1189,4]]},"698":{"position":[[1478,4]]},"702":{"position":[[737,4]]},"704":{"position":[[401,4],[493,4]]},"711":{"position":[[401,4],[583,4]]},"713":{"position":[[69,4],[664,4],[1069,4],[1383,4],[1597,4],[1667,4]]},"759":{"position":[[0,4]]},"761":{"position":[[0,4],[316,4]]},"782":{"position":[[69,4],[105,4]]},"784":{"position":[[471,4],[592,4],[693,4]]},"787":{"position":[[327,4]]},"791":{"position":[[402,4],[503,4],[537,4]]},"804":{"position":[[69,4],[196,4],[291,4]]},"811":{"position":[[0,4],[851,4],[1216,4]]},"817":{"position":[[190,5],[277,4],[929,4]]},"823":{"position":[[1075,4]]},"848":{"position":[[101,4]]},"876":{"position":[[387,4],[492,4],[549,4],[727,4],[778,4]]},"931":{"position":[[11,4]]},"963":{"position":[[2200,4]]},"969":{"position":[[553,4]]},"987":{"position":[[190,4],[264,4]]},"989":{"position":[[204,4],[269,4],[397,4],[881,4],[1114,4]]},"993":{"position":[[116,4],[301,4]]},"995":{"position":[[402,4],[524,4]]},"1001":{"position":[[147,4],[208,4],[1241,4],[2156,4]]},"1008":{"position":[[102,4]]},"1010":{"position":[[19,4]]},"1013":{"position":[[404,4]]},"1092":{"position":[[533,4],[1501,4],[1531,4]]},"1125":{"position":[[239,4]]},"1135":{"position":[[62,4],[133,4],[187,4],[403,4]]},"1137":{"position":[[0,4],[221,4],[302,4],[427,4],[732,4],[1515,4],[1977,4],[2177,4],[2217,4],[2446,4],[2605,4],[2675,4],[3318,4],[3498,4],[3854,4],[4612,4]]},"1154":{"position":[[195,4],[659,4]]},"1156":{"position":[[45,4]]},"1160":{"position":[[26,4],[73,4],[201,4],[249,4],[638,4],[731,4]]},"1163":{"position":[[32,4]]},"1170":{"position":[[71,4]]},"1174":{"position":[[95,4]]},"1177":{"position":[[56,4]]},"1181":{"position":[[15,4]]},"1184":{"position":[[47,4]]},"1190":{"position":[[166,4],[385,4],[423,4]]},"1192":{"position":[[19,4]]},"1194":{"position":[[24,4]]},"1203":{"position":[[171,4]]}}}],["finetun",{"_index":673,"t":{"143":{"position":[[689,10]]},"227":{"position":[[365,9]]},"229":{"position":[[281,10],[453,10],[576,10]]},"233":{"position":[[100,10]]},"244":{"position":[[315,10]]},"271":{"position":[[479,10]]},"279":{"position":[[685,10]]},"281":{"position":[[690,10],[774,10],[793,10]]},"284":{"position":[[118,10]]},"288":{"position":[[110,10],[220,10]]},"292":{"position":[[446,10]]},"300":{"position":[[156,10],[583,10]]},"328":{"position":[[389,8],[765,11]]},"330":{"position":[[1617,10]]},"347":{"position":[[498,8]]},"366":{"position":[[15,10],[91,10],[160,10]]},"368":{"position":[[16,10],[50,10],[123,10],[193,10],[432,10]]},"370":{"position":[[72,10],[108,10]]},"373":{"position":[[0,10],[70,10]]},"375":{"position":[[32,10]]},"379":{"position":[[39,10],[105,10]]},"382":{"position":[[55,10]]},"386":{"position":[[9,10],[161,10],[200,10],[415,10],[432,10]]},"388":{"position":[[12,10],[98,10],[128,10],[161,10]]},"390":{"position":[[31,10]]},"392":{"position":[[19,10],[95,10],[190,10],[237,10],[283,10]]},"394":{"position":[[49,10]]},"396":{"position":[[12,10],[155,10],[315,10],[385,10],[498,9],[530,10],[610,10]]},"398":{"position":[[292,10],[794,10],[946,10]]},"400":{"position":[[18,10],[34,10],[74,10],[97,9]]},"402":{"position":[[12,10],[40,10],[238,10]]},"404":{"position":[[4,10],[71,10],[176,10],[241,10]]},"406":{"position":[[163,10],[252,10]]},"408":{"position":[[271,10]]},"410":{"position":[[49,10],[119,10],[188,10]]},"412":{"position":[[12,10],[73,10],[159,10],[216,10]]},"614":{"position":[[620,10]]},"616":{"position":[[0,10],[104,10],[223,10],[439,10],[480,10],[681,10],[1482,10]]},"621":{"position":[[101,9]]},"625":{"position":[[441,10],[456,10]]},"627":{"position":[[204,10]]},"646":{"position":[[29,10]]},"651":{"position":[[40,10]]},"657":{"position":[[86,10]]},"674":{"position":[[476,10]]},"850":{"position":[[1209,10]]},"901":{"position":[[1621,10]]},"911":{"position":[[1195,10]]},"917":{"position":[[1643,9]]},"931":{"position":[[169,10],[290,10]]},"937":{"position":[[39,10],[238,10],[596,10]]},"939":{"position":[[68,10],[129,10]]},"953":{"position":[[406,10]]},"973":{"position":[[134,8]]},"981":{"position":[[39,8]]},"1099":{"position":[[545,10],[1068,10]]},"1207":{"position":[[145,10],[545,10]]}}}],["finnish",{"_index":2721,"t":{"883":{"position":[[496,9]]}}}],["fins∈rn×df_{in",{"_index":3326,"t":{"1096":{"position":[[1196,16]]}}}],["fintun",{"_index":1248,"t":{"392":{"position":[[68,9]]}}}],["first",{"_index":1709,"t":{"523":{"position":[[509,5]]},"633":{"position":[[742,5]]},"680":{"position":[[366,5]]},"863":{"position":[[0,5],[226,5]]},"1030":{"position":[[444,5]]},"1034":{"position":[[74,7]]},"1036":{"position":[[205,7]]},"1236":{"position":[[88,5]]}}}],["first_do",{"_index":3282,"t":{"1092":{"position":[[1629,11]]}}}],["fish",{"_index":1445,"t":{"427":{"position":[[3418,4]]},"619":{"position":[[85,4]]}}}],["fisher",{"_index":1446,"t":{"427":{"position":[[3430,6]]}}}],["fit",{"_index":1657,"t":{"491":{"position":[[62,7],[128,7]]},"817":{"position":[[824,3]]},"931":{"position":[[388,3]]}}}],["five",{"_index":1235,"t":{"384":{"position":[[5,5]]}}}],["fix",{"_index":333,"t":{"63":{"position":[[158,5]]},"418":{"position":[[1743,5]]},"819":{"position":[[1079,5],[1164,5]]},"909":{"position":[[153,5]]},"935":{"position":[[0,5]]},"937":{"position":[[0,5]]},"947":{"position":[[343,5]]},"949":{"position":[[125,5]]},"955":{"position":[[337,5],[409,5]]},"961":{"position":[[48,5]]},"1222":{"position":[[537,5]]}}}],["fixr",{"_index":177,"t":{"25":{"position":[[487,10]]},"31":{"position":[[124,6]]},"78":{"position":[[69,6]]}}}],["fla",{"_index":1269,"t":{"398":{"position":[[642,3]]}}}],["flamingo",{"_index":836,"t":{"197":{"position":[[171,8],[313,8]]},"279":{"position":[[562,8]]},"281":{"position":[[730,8],[2291,8]]},"288":{"position":[[242,8]]},"304":{"position":[[548,8]]},"313":{"position":[[74,9]]},"324":{"position":[[164,8]]}}}],["flamingo80b_{80b}80b",{"_index":1075,"t":{"320":{"position":[[122,21]]}}}],["flan",{"_index":1198,"t":{"368":{"position":[[274,4],[443,4],[495,4]]},"370":{"position":[[91,4],[127,6],[147,4]]},"382":{"position":[[0,4]]},"388":{"position":[[72,4]]},"390":{"position":[[155,4],[244,4],[303,4]]},"394":{"position":[[154,4],[239,4]]},"396":{"position":[[568,4]]},"398":{"position":[[610,4],[688,4],[730,4]]},"406":{"position":[[284,5]]},"408":{"position":[[127,4]]},"412":{"position":[[31,4]]},"1001":{"position":[[2127,5]]}}}],["flat",{"_index":939,"t":{"271":{"position":[[266,4]]},"275":{"position":[[183,4]]}}}],["flatten",{"_index":406,"t":{"91":{"position":[[176,9],[499,7]]},"95":{"position":[[228,7],[318,7]]},"176":{"position":[[304,9]]},"1092":{"position":[[1489,7]]}}}],["flax",{"_index":2547,"t":{"825":{"position":[[881,4]]}}}],["fld",{"_index":3747,"t":{"1203":{"position":[[272,3]]}}}],["flexibl",{"_index":3284,"t":{"1092":{"position":[[1684,9]]}}}],["flip",{"_index":935,"t":{"269":{"position":[[226,4]]},"1200":{"position":[[11,4]]},"1203":{"position":[[134,4]]}}}],["float",{"_index":1487,"t":{"443":{"position":[[84,6]]}}}],["flop",{"_index":203,"t":{"27":{"position":[[451,5]]},"33":{"position":[[76,5],[345,5]]},"60":{"position":[[66,6]]},"437":{"position":[[132,5],[250,5],[292,5],[439,5],[514,5],[643,5]]},"439":{"position":[[175,5],[306,5]]},"441":{"position":[[238,5],[304,5]]},"451":{"position":[[534,5]]},"557":{"position":[[410,5]]}}}],["florenc",{"_index":3746,"t":{"1203":{"position":[[261,8]]}}}],["flower",{"_index":328,"t":{"63":{"position":[[48,8]]}}}],["flowers102",{"_index":501,"t":{"102":{"position":[[208,10]]},"1238":{"position":[[88,10]]}}}],["focal",{"_index":3342,"t":{"1096":{"position":[[2493,5]]}}}],["focu",{"_index":1755,"t":{"553":{"position":[[56,5]]},"836":{"position":[[651,5]]},"1099":{"position":[[659,5]]}}}],["folder",{"_index":52,"t":{"9":{"position":[[91,8],[296,6]]},"1036":{"position":[[57,7]]},"1046":{"position":[[90,7]]},"1047":{"position":[[60,6],[137,6]]},"1065":{"position":[[84,6]]},"1069":{"position":[[58,7]]},"1075":{"position":[[43,7]]}}}],["follow",{"_index":1271,"t":{"398":{"position":[[889,6]]},"455":{"position":[[36,9]]},"457":{"position":[[101,9],[227,9],[743,9],[1155,9]]},"461":{"position":[[103,9]]},"475":{"position":[[37,9],[502,9]]},"479":{"position":[[27,9]]},"502":{"position":[[309,9],[449,9],[564,9],[624,9],[950,9]]},"504":{"position":[[21,9],[141,9],[591,9],[1127,9],[1542,9],[1668,9],[1910,9],[2385,9],[2505,9]]},"508":{"position":[[12,9],[492,9]]},"512":{"position":[[169,9]]},"515":{"position":[[285,9],[864,9]]},"519":{"position":[[302,9],[658,9]]},"521":{"position":[[124,9],[439,9]]},"525":{"position":[[456,9]]},"533":{"position":[[89,9]]},"535":{"position":[[346,9]]},"537":{"position":[[403,9]]},"543":{"position":[[131,9],[240,9],[283,9],[431,9],[519,9]]},"773":{"position":[[524,9]]},"959":{"position":[[377,9]]},"985":{"position":[[119,6]]}}}],["food101",{"_index":3824,"t":{"1238":{"position":[[80,7]]}}}],["footer",{"_index":3077,"t":{"1026":{"position":[[104,6]]}}}],["footprint",{"_index":2604,"t":{"844":{"position":[[352,9]]}}}],["forget",{"_index":989,"t":{"288":{"position":[[407,11]]},"931":{"position":[[265,10]]},"933":{"position":[[302,10]]}}}],["form",{"_index":2615,"t":{"848":{"position":[[418,4]]},"953":{"position":[[213,4]]}}}],["format",{"_index":1302,"t":{"418":{"position":[[1024,10]]},"423":{"position":[[508,6]]}}}],["formul",{"_index":3250,"t":{"1087":{"position":[[1646,11],[1777,11],[2658,11]]}}}],["forward",{"_index":777,"t":{"180":{"position":[[102,7],[397,7]]},"427":{"position":[[1318,7],[1436,7],[1756,7],[1863,7],[3214,7]]},"563":{"position":[[751,7]]},"840":{"position":[[422,7]]},"1137":{"position":[[2650,7]]},"1142":{"position":[[111,7]]}}}],["fozen",{"_index":1079,"t":{"322":{"position":[[146,5]]}}}],["fp16",{"_index":815,"t":{"188":{"position":[[303,4],[383,4]]},"362":{"position":[[1114,5],[1178,5]]}}}],["fp2v,fv2p=bi",{"_index":3307,"t":{"1094":{"position":[[424,12]]}}}],["fp32",{"_index":816,"t":{"188":{"position":[[339,4]]},"362":{"position":[[1217,5]]}}}],["fp={enclrefexpress",{"_index":3285,"t":{"1092":{"position":[[1933,21]]}}}],["fprompt",{"_index":2842,"t":{"917":{"position":[[1570,8]]}}}],["fprompt(x)f_{prompt}(x)fprompt​(x",{"_index":2718,"t":{"883":{"position":[[12,34]]},"889":{"position":[[214,34]]},"891":{"position":[[80,34]]}}}],["fprompt(⋅)f_{prompt}(\\cdot)fprompt",{"_index":2719,"t":{"883":{"position":[[82,38]]}}}],["fprompt,i(⋅)f_{prompt",{"_index":2829,"t":{"917":{"position":[[430,22]]}}}],["fp′=fp+fv2p(1)\\left",{"_index":3309,"t":{"1094":{"position":[[461,20]]}}}],["fp′f'_pfp",{"_index":3328,"t":{"1096":{"position":[[1698,11],[1981,11]]}}}],["fp′​=fp​+fv2p​​(1",{"_index":3320,"t":{"1094":{"position":[[664,18]]}}}],["fp∈r1024×df_p",{"_index":3279,"t":{"1092":{"position":[[1411,13]]}}}],["fp∈rl×df_p",{"_index":3257,"t":{"1092":{"position":[[447,10]]}}}],["fr",{"_index":3223,"t":{"1073":{"position":[[51,2],[147,6]]},"1077":{"position":[[64,2]]},"1081":{"position":[[65,2]]}}}],["frac",{"_index":1900,"t":{"604":{"position":[[565,8]]},"1214":{"position":[[554,6]]},"1222":{"position":[[969,6]]}}}],["frac{1}{\\binom{k}{2}}e_{(x,y_w,y_l",{"_index":3012,"t":{"1001":{"position":[[720,36]]}}}],["frac{1}{d_1",{"_index":3613,"t":{"1152":{"position":[[545,13]]}}}],["frac{1}{d_2",{"_index":3616,"t":{"1152":{"position":[[590,13]]}}}],["frac{1}{k",{"_index":2825,"t":{"917":{"position":[[354,11],[1426,11]]}}}],["frac{1}{l",{"_index":3334,"t":{"1096":{"position":[[2170,11]]}}}],["frac{1}{t",{"_index":1340,"t":{"425":{"position":[[145,11]]}}}],["frac{1}{t}\\sum^t_{t=1",{"_index":1373,"t":{"425":{"position":[[1767,23]]}}}],["frac{1}{z",{"_index":2045,"t":{"633":{"position":[[1219,11]]}}}],["frac{\\exp(\\beta(\\text{x",{"_index":1378,"t":{"425":{"position":[[2065,26]]}}}],["frac{\\sum^n_n=1",{"_index":1355,"t":{"425":{"position":[[547,16]]}}}],["frac{q(l_k",{"_index":1413,"t":{"427":{"position":[[1628,11]]}}}],["framework",{"_index":1995,"t":{"627":{"position":[[1405,9]]},"629":{"position":[[4,9]]},"855":{"position":[[311,9]]},"857":{"position":[[10,9]]},"859":{"position":[[119,9]]},"1200":{"position":[[28,9]]},"1203":{"position":[[538,9]]}}}],["free",{"_index":2147,"t":{"680":{"position":[[1010,4]]},"761":{"position":[[1342,4]]},"775":{"position":[[430,4]]},"798":{"position":[[89,4]]},"823":{"position":[[879,5]]},"848":{"position":[[413,4]]},"933":{"position":[[7,4],[158,4],[216,4]]},"935":{"position":[[209,4],[277,4]]},"953":{"position":[[208,4]]},"983":{"position":[[442,4],[846,4]]},"1030":{"position":[[461,4]]},"1047":{"position":[[172,4]]}}}],["freez",{"_index":849,"t":{"213":{"position":[[4,8],[59,8],[150,8]]},"455":{"position":[[140,8]]},"457":{"position":[[327,8],[656,8]]},"508":{"position":[[88,8]]},"531":{"position":[[276,8]]},"547":{"position":[[107,6]]},"549":{"position":[[880,6]]},"563":{"position":[[560,6]]},"569":{"position":[[233,6]]},"579":{"position":[[31,8]]},"668":{"position":[[183,9]]},"696":{"position":[[769,8]]},"711":{"position":[[38,8]]},"713":{"position":[[356,8]]},"759":{"position":[[281,8]]},"761":{"position":[[364,8]]},"817":{"position":[[590,8]]},"836":{"position":[[2238,8]]},"1137":{"position":[[452,8]]}}}],["french",{"_index":2710,"t":{"876":{"position":[[1064,7]]},"1071":{"position":[[33,7]]},"1075":{"position":[[250,7]]},"1077":{"position":[[23,6]]}}}],["frequenc",{"_index":1151,"t":{"349":{"position":[[795,9]]}}}],["frobeniu",{"_index":1921,"t":{"608":{"position":[[278,9]]}}}],["front",{"_index":3159,"t":{"1051":{"position":[[51,5]]}}}],["frozem",{"_index":1060,"t":{"313":{"position":[[40,6]]}}}],["frozen",{"_index":965,"t":{"281":{"position":[[950,6]]},"288":{"position":[[172,6]]},"290":{"position":[[147,6]]},"313":{"position":[[84,7]]},"316":{"position":[[25,6],[87,6]]},"328":{"position":[[628,6]]},"504":{"position":[[239,6],[954,6]]},"515":{"position":[[66,6]]},"523":{"position":[[156,6]]},"549":{"position":[[1176,6]]},"571":{"position":[[64,6]]},"718":{"position":[[449,6]]},"738":{"position":[[93,6]]},"815":{"position":[[46,6],[438,6],[560,6]]},"817":{"position":[[56,6],[433,6],[1253,6],[1497,6],[1808,6]]},"819":{"position":[[765,6],[1059,6]]},"821":{"position":[[186,6]]},"823":{"position":[[778,6],[1229,6],[1657,6]]},"825":{"position":[[0,6]]},"836":{"position":[[2140,6]]},"838":{"position":[[0,6]]},"840":{"position":[[597,6]]},"842":{"position":[[280,6]]},"844":{"position":[[16,6],[461,6]]},"901":{"position":[[389,6],[1213,6]]}}}],["ft",{"_index":1870,"t":{"595":{"position":[[54,2]]},"616":{"position":[[115,4]]},"646":{"position":[[40,4]]},"657":{"position":[[97,5]]},"696":{"position":[[606,4],[649,2],[689,3],[716,2],[823,2],[909,2],[995,2],[1180,2],[1322,2]]},"698":{"position":[[1172,2],[1648,2],[1877,2],[1908,2]]},"700":{"position":[[110,2],[446,2]]},"704":{"position":[[232,2]]},"713":{"position":[[81,4],[937,2]]},"718":{"position":[[833,2]]},"721":{"position":[[83,2]]},"723":{"position":[[66,2],[135,2]]},"725":{"position":[[273,2]]},"734":{"position":[[36,2]]},"738":{"position":[[77,2]]},"746":{"position":[[175,2],[266,2],[338,2],[383,2],[438,2]]},"748":{"position":[[45,2]]},"755":{"position":[[82,2]]},"759":{"position":[[12,4],[91,2],[218,2],[599,2]]},"761":{"position":[[12,4],[116,2],[546,2],[959,2],[1381,2]]},"770":{"position":[[5,2]]},"782":{"position":[[81,3]]},"787":{"position":[[127,2],[181,2]]},"789":{"position":[[39,2],[95,2]]},"793":{"position":[[547,2]]}}}],["fttop2",{"_index":2423,"t":{"782":{"position":[[117,9]]}}}],["fttop2\\text{ft}^{top2}fttop2",{"_index":1836,"t":{"577":{"position":[[39,28]]}}}],["full",{"_index":1308,"t":{"418":{"position":[[2186,4]]},"427":{"position":[[3674,4],[3776,4],[3953,4],[3998,4]]},"451":{"position":[[210,4]]},"469":{"position":[[194,4]]},"549":{"position":[[732,4],[1204,4]]},"553":{"position":[[645,4]]},"563":{"position":[[70,4]]},"565":{"position":[[44,4]]},"593":{"position":[[14,4]]},"614":{"position":[[615,4]]},"616":{"position":[[85,4],[218,4],[434,4],[475,4],[1477,4]]},"639":{"position":[[55,4]]},"646":{"position":[[24,4]]},"657":{"position":[[81,4]]},"674":{"position":[[471,4]]},"736":{"position":[[49,4]]},"759":{"position":[[145,4],[561,4]]},"770":{"position":[[0,4]]},"782":{"position":[[64,4],[85,6]]},"787":{"position":[[174,6]]},"789":{"position":[[90,4]]},"804":{"position":[[286,4]]},"817":{"position":[[1644,4]]},"838":{"position":[[1046,4]]},"927":{"position":[[166,4]]},"1137":{"position":[[216,4],[727,4],[1510,4],[2172,4],[2212,4],[4607,4]]},"1140":{"position":[[112,4]]},"1160":{"position":[[21,4]]}}}],["fulli",{"_index":1846,"t":{"585":{"position":[[76,5]]},"698":{"position":[[254,5],[288,5],[1175,5]]},"738":{"position":[[340,5]]},"876":{"position":[[0,5],[346,5]]}}}],["function",{"_index":385,"t":{"86":{"position":[[699,8]]},"124":{"position":[[102,8],[474,8]]},"126":{"position":[[562,8],[618,8],[1061,8]]},"130":{"position":[[275,8]]},"153":{"position":[[269,8]]},"155":{"position":[[115,10],[251,8]]},"159":{"position":[[153,8]]},"178":{"position":[[321,8]]},"341":{"position":[[77,8]]},"345":{"position":[[478,13]]},"347":{"position":[[384,13]]},"349":{"position":[[775,8]]},"360":{"position":[[613,8]]},"463":{"position":[[795,8],[1693,8],[1937,8]]},"627":{"position":[[803,8]]},"633":{"position":[[1977,8]]},"635":{"position":[[272,8]]},"686":{"position":[[1834,8]]},"766":{"position":[[657,8]]},"775":{"position":[[1098,8]]},"857":{"position":[[202,8],[358,8],[450,8]]},"870":{"position":[[371,9],[401,9],[435,9]]},"876":{"position":[[480,8],[601,8]]},"883":{"position":[[73,8]]},"891":{"position":[[71,8]]},"1001":{"position":[[623,8],[1183,8],[1371,8]]},"1040":{"position":[[150,8]]},"1057":{"position":[[110,8],[218,8]]},"1099":{"position":[[242,8],[685,8]]},"1140":{"position":[[227,8]]},"1152":{"position":[[921,8]]}}}],["fune",{"_index":1671,"t":{"504":{"position":[[1210,6]]}}}],["funtion",{"_index":1141,"t":{"347":{"position":[[254,12]]}}}],["fusc",{"_index":12,"t":{"3":{"position":[[101,5]]},"5":{"position":[[221,5],[400,5],[579,5],[758,5],[937,5],[1116,5],[1295,5],[1474,5],[1653,5],[1832,5],[2011,5],[2190,5],[2369,5],[2548,5],[2727,5],[2906,5]]}}}],["fuse",{"_index":174,"t":{"25":{"position":[[369,5]]},"33":{"position":[[193,5],[267,5],[297,5]]},"38":{"position":[[153,5]]},"40":{"position":[[77,5]]},"76":{"position":[[161,5]]},"78":{"position":[[206,5],[854,5]]},"523":{"position":[[373,6]]}}}],["fusion",{"_index":1665,"t":{"502":{"position":[[371,6]]},"504":{"position":[[1249,6],[2421,6]]},"523":{"position":[[107,6],[596,6]]},"537":{"position":[[333,6]]},"585":{"position":[[295,6]]},"1087":{"position":[[1980,6]]},"1090":{"position":[[587,6]]},"1094":{"position":[[231,6],[719,6],[777,6]]},"1096":{"position":[[1671,6]]},"1125":{"position":[[39,6],[71,6],[103,6],[212,6],[301,6],[336,6]]},"1160":{"position":[[443,6]]}}}],["futur",{"_index":1927,"t":{"610":{"position":[[146,6]]},"859":{"position":[[30,6]]},"1158":{"position":[[544,6]]}}}],["fvf_vfv",{"_index":3304,"t":{"1094":{"position":[[118,8]]}}}],["fv′f'_vfv",{"_index":3325,"t":{"1096":{"position":[[910,11]]}}}],["g",{"_index":3808,"t":{"1222":{"position":[[838,5],[1300,5]]}}}],["g(v_c",{"_index":3810,"t":{"1222":{"position":[[984,7]]}}}],["g(v_j",{"_index":3811,"t":{"1222":{"position":[[1036,7]]}}}],["g(⋅)g",{"_index":3807,"t":{"1222":{"position":[[825,6],[1287,6]]}}}],["g={p∗i,λi,qi∗}\\mathcal{g",{"_index":3514,"t":{"1146":{"position":[[606,25]]}}}],["g={p∗i​,λi​,qi",{"_index":3518,"t":{"1146":{"position":[[665,19]]}}}],["g\\mathcal{g}g",{"_index":3393,"t":{"1113":{"position":[[287,13]]}}}],["g_l",{"_index":1597,"t":{"463":{"position":[[1824,3]]}}}],["gain",{"_index":868,"t":{"227":{"position":[[258,4]]},"1156":{"position":[[152,4]]}}}],["gamma",{"_index":264,"t":{"49":{"position":[[488,8]]},"427":{"position":[[1804,6],[1847,8]]},"1001":{"position":[[1628,6],[1955,8],[1993,8],[2018,8]]},"1148":{"position":[[1005,6]]},"1158":{"position":[[144,9],[179,8],[215,8],[245,8]]},"1165":{"position":[[458,8]]}}}],["gap",{"_index":1146,"t":{"347":{"position":[[507,3]]},"817":{"position":[[1727,3]]},"844":{"position":[[180,3]]},"1096":{"position":[[1951,5]]}}}],["gate",{"_index":847,"t":{"209":{"position":[[181,6]]},"349":{"position":[[768,6]]},"455":{"position":[[375,6]]},"457":{"position":[[568,6],[791,6]]},"463":{"position":[[1476,6]]},"471":{"position":[[168,6]]},"498":{"position":[[82,6]]},"508":{"position":[[360,6],[389,6]]},"515":{"position":[[176,6]]},"519":{"position":[[445,6],[524,7]]},"619":{"position":[[251,6]]}}}],["gaussian",{"_index":1813,"t":{"563":{"position":[[874,8]]},"1142":{"position":[[489,8]]},"1146":{"position":[[838,8]]}}}],["geforc",{"_index":2430,"t":{"784":{"position":[[389,7]]}}}],["gelu",{"_index":441,"t":{"91":{"position":[[1468,4]]}}}],["gener",{"_index":98,"t":{"17":{"position":[[0,8]]},"169":{"position":[[495,9]]},"180":{"position":[[471,10]]},"273":{"position":[[109,11]]},"281":{"position":[[1435,10]]},"296":{"position":[[107,10],[180,10]]},"330":{"position":[[256,10],[392,10],[406,10],[582,10]]},"333":{"position":[[21,10]]},"339":{"position":[[26,10],[257,10]]},"341":{"position":[[175,10]]},"347":{"position":[[115,10],[243,10],[373,10],[458,10]]},"351":{"position":[[58,10]]},"353":{"position":[[39,10],[77,10],[160,10],[222,10]]},"355":{"position":[[279,10]]},"360":{"position":[[846,10]]},"423":{"position":[[312,14],[590,14],[684,14]]},"451":{"position":[[641,10]]},"465":{"position":[[1216,10]]},"475":{"position":[[351,10]]},"504":{"position":[[796,10]]},"537":{"position":[[282,8]]},"557":{"position":[[139,10]]},"573":{"position":[[82,10]]},"619":{"position":[[182,10]]},"642":{"position":[[334,10]]},"680":{"position":[[214,10]]},"696":{"position":[[0,7]]},"759":{"position":[[190,10],[474,10]]},"780":{"position":[[29,10]]},"782":{"position":[[14,10]]},"787":{"position":[[74,10],[478,10],[639,10]]},"802":{"position":[[156,10]]},"817":{"position":[[1223,10]]},"819":{"position":[[48,10],[178,10],[418,10],[1258,10]]},"844":{"position":[[232,14],[250,7]]},"850":{"position":[[1654,10],[2279,10]]},"855":{"position":[[161,10],[282,10],[338,10]]},"870":{"position":[[324,10],[361,9]]},"879":{"position":[[498,10]]},"895":{"position":[[394,10],[555,10]]},"899":{"position":[[654,10]]},"917":{"position":[[652,10],[1270,10],[1281,10]]},"953":{"position":[[435,10]]},"955":{"position":[[5,10]]},"959":{"position":[[168,9]]},"963":{"position":[[1667,10],[2117,11],[2293,10],[2324,10],[2432,10],[2491,10],[2611,10]]},"969":{"position":[[32,10],[91,10]]},"971":{"position":[[265,10],[289,10],[375,10]]},"997":{"position":[[101,11]]},"1044":{"position":[[28,9]]},"1046":{"position":[[67,9]]},"1085":{"position":[[53,10]]},"1087":{"position":[[1951,10],[2455,7]]},"1090":{"position":[[555,10]]},"1092":{"position":[[11,10]]},"1099":{"position":[[24,7]]},"1127":{"position":[[18,10]]},"1135":{"position":[[828,10]]},"1211":{"position":[[45,10]]}}}],["generalis",{"_index":852,"t":{"217":{"position":[[21,14]]}}}],["generalist",{"_index":2482,"t":{"817":{"position":[[2183,12],[2294,10]]}}}],["generation/complet",{"_index":1094,"t":{"328":{"position":[[809,22]]}}}],["genom",{"_index":801,"t":{"186":{"position":[[27,6]]},"193":{"position":[[120,6]]}}}],["geometr",{"_index":511,"t":{"102":{"position":[[350,10]]}}}],["get",{"_index":3234,"t":{"1077":{"position":[[138,7]]}}}],["gi={ai∗,b∗i}\\mathcal{g}_i",{"_index":3489,"t":{"1142":{"position":[[646,25]]}}}],["git",{"_index":838,"t":{"197":{"position":[[306,3]]}}}],["github",{"_index":1095,"t":{"330":{"position":[[25,6]]},"335":{"position":[[42,6]]},"360":{"position":[[7,6],[201,6],[561,6]]}}}],["given",{"_index":1956,"t":{"625":{"position":[[0,6]]},"627":{"position":[[0,6]]},"842":{"position":[[1243,5]]},"1137":{"position":[[911,5]]},"1140":{"position":[[131,5]]},"1148":{"position":[[1601,5]]}}}],["gi​={ai∗​,b∗i",{"_index":3492,"t":{"1142":{"position":[[692,17]]}}}],["gk,i={pk,∗i,λk,i,qk,i∗}\\mathcal{g}_{k,i",{"_index":3540,"t":{"1148":{"position":[[370,40]]}}}],["gk,i\\mathcal{g}_{k,i}gk,i",{"_index":3608,"t":{"1152":{"position":[[360,26],[807,26]]}}}],["gk,i​={pk,∗i​,λk,i​,qk,i",{"_index":3544,"t":{"1148":{"position":[[450,29]]}}}],["gl",{"_index":1601,"t":{"463":{"position":[[2164,3]]}}}],["glg_lgl",{"_index":1591,"t":{"463":{"position":[[1490,8],[1563,8],[1718,8],[1986,8],[2095,8]]}}}],["glip",{"_index":3321,"t":{"1094":{"position":[[760,4]]}}}],["glm",{"_index":2312,"t":{"742":{"position":[[51,3]]},"746":{"position":[[216,3]]}}}],["global",{"_index":1610,"t":{"465":{"position":[[233,6]]},"482":{"position":[[43,6]]},"1096":{"position":[[935,6],[1928,6]]},"1154":{"position":[[248,6]]}}}],["glue",{"_index":1867,"t":{"591":{"position":[[31,4]]},"642":{"position":[[176,4]]},"716":{"position":[[74,4]]},"836":{"position":[[2274,4]]},"838":{"position":[[729,4]]},"1137":{"position":[[4430,6]]},"1156":{"position":[[82,7]]},"1163":{"position":[[54,6]]},"1167":{"position":[[46,4]]}}}],["go",{"_index":1161,"t":{"360":{"position":[[116,3]]}}}],["goal",{"_index":2606,"t":{"848":{"position":[[10,4]]}}}],["gold",{"_index":2947,"t":{"963":{"position":[[3062,4]]},"983":{"position":[[970,4],[1064,4],[1189,4]]}}}],["good",{"_index":2286,"t":{"713":{"position":[[533,6]]},"879":{"position":[[564,5]]},"885":{"position":[[127,7]]}}}],["googl",{"_index":1180,"t":{"362":{"position":[[430,6]]}}}],["gpipe/efficientnet",{"_index":338,"t":{"65":{"position":[[52,19]]}}}],["gpt",{"_index":876,"t":{"227":{"position":[[375,3]]},"242":{"position":[[11,3]]},"244":{"position":[[182,3]]},"322":{"position":[[29,4],[37,3]]},"425":{"position":[[1519,4]]},"435":{"position":[[211,3],[296,3],[346,3]]},"437":{"position":[[224,5]]},"439":{"position":[[188,3],[467,3]]},"441":{"position":[[268,3],[346,3]]},"475":{"position":[[470,3]]},"477":{"position":[[107,3]]},"502":{"position":[[103,3]]},"529":{"position":[[57,3]]},"533":{"position":[[494,3]]},"535":{"position":[[249,3]]},"547":{"position":[[0,3],[242,3],[340,3],[348,3]]},"549":{"position":[[692,3]]},"553":{"position":[[68,3]]},"571":{"position":[[164,3],[335,3]]},"573":{"position":[[19,3]]},"593":{"position":[[48,3]]},"595":{"position":[[0,3]]},"600":{"position":[[37,3]]},"604":{"position":[[1178,3]]},"678":{"position":[[21,3],[213,3],[292,3]]},"680":{"position":[[237,4],[406,3],[925,3],[1163,3],[1199,3],[1485,3],[1624,3],[1734,3]]},"682":{"position":[[0,3],[206,3]]},"690":{"position":[[71,3]]},"694":{"position":[[177,3],[721,3]]},"696":{"position":[[348,3],[1114,3],[1214,3]]},"700":{"position":[[210,3]]},"704":{"position":[[105,3]]},"707":{"position":[[224,3]]},"759":{"position":[[490,3]]},"761":{"position":[[241,3],[265,3],[613,3],[849,4]]},"766":{"position":[[13,3]]},"784":{"position":[[19,3],[34,3]]},"787":{"position":[[617,3],[680,3],[712,3]]},"815":{"position":[[114,3],[266,3]]},"817":{"position":[[143,3],[440,3],[903,3]]},"819":{"position":[[625,3]]},"823":{"position":[[17,3],[1699,3]]},"827":{"position":[[555,3],[605,3],[660,3],[706,3]]},"836":{"position":[[624,3]]},"848":{"position":[[647,3]]},"933":{"position":[[243,3]]},"987":{"position":[[171,3],[324,3]]},"989":{"position":[[261,3],[378,3],[506,3],[578,3],[624,3],[664,3],[752,3],[819,3],[939,3]]},"993":{"position":[[85,3]]},"1001":{"position":[[32,3],[46,3],[112,3],[200,3],[2088,3],[2148,3]]},"1006":{"position":[[5,3]]},"1008":{"position":[[16,3],[51,3]]},"1013":{"position":[[355,4]]},"1016":{"position":[[326,3]]},"1137":{"position":[[83,3]]}}}],["gpt2",{"_index":2274,"t":{"698":{"position":[[1768,4],[1792,4]]},"700":{"position":[[126,4],[138,4],[175,4],[237,4],[359,4],[559,4],[659,4]]},"953":{"position":[[493,5]]},"983":{"position":[[189,5]]}}}],["gpt3",{"_index":157,"t":{"25":{"position":[[0,4]]},"304":{"position":[[619,4]]}}}],["gpu",{"_index":159,"t":{"25":{"position":[[52,4]]},"86":{"position":[[98,3]]},"88":{"position":[[221,3]]},"169":{"position":[[348,3]]},"188":{"position":[[110,3]]},"213":{"position":[[164,3]]},"362":{"position":[[421,4]]},"441":{"position":[[473,3]]},"445":{"position":[[267,3]]},"451":{"position":[[564,3]]},"455":{"position":[[215,3]]},"457":{"position":[[837,3]]},"475":{"position":[[112,3]]},"547":{"position":[[303,3]]},"784":{"position":[[624,3],[675,3]]},"809":{"position":[[98,3]]},"1104":{"position":[[349,4]]},"1158":{"position":[[97,4]]}}}],["gpu/tpu",{"_index":205,"t":{"31":{"position":[[48,7]]}}}],["gradcam",{"_index":1032,"t":{"302":{"position":[[672,7],[789,7]]},"311":{"position":[[177,7],[200,7]]}}}],["grade",{"_index":2656,"t":{"857":{"position":[[337,7]]}}}],["gradient",{"_index":639,"t":{"138":{"position":[[148,8],[185,8]]},"180":{"position":[[376,8]]},"188":{"position":[[150,8]]},"197":{"position":[[182,8]]},"302":{"position":[[889,8]]},"416":{"position":[[133,8]]},"418":{"position":[[225,8],[744,8]]},"423":{"position":[[347,8]]},"445":{"position":[[177,8]]},"549":{"position":[[1091,8]]},"551":{"position":[[287,8]]},"553":{"position":[[391,8]]},"563":{"position":[[569,8]]},"571":{"position":[[315,8]]},"680":{"position":[[1119,8]]},"682":{"position":[[426,8]]},"688":{"position":[[197,8]]},"713":{"position":[[167,8]]},"770":{"position":[[137,8]]},"819":{"position":[[1413,8]]},"850":{"position":[[491,8]]},"899":{"position":[[491,8],[523,8]]},"931":{"position":[[105,8]]},"1001":{"position":[[1289,8],[1312,8]]},"1137":{"position":[[1480,8]]},"1146":{"position":[[1113,8]]},"1148":{"position":[[1265,8]]},"1152":{"position":[[977,8]]},"1160":{"position":[[150,8]]},"1222":{"position":[[1263,8]]}}}],["gradual",{"_index":351,"t":{"78":{"position":[[176,9],[334,9],[592,9]]}}}],["grain",{"_index":1129,"t":{"345":{"position":[[110,7]]},"969":{"position":[[558,7]]},"1092":{"position":[[538,7],[1506,7],[1523,7],[1536,7],[1726,7]]},"1137":{"position":[[3503,7]]},"1203":{"position":[[176,7]]}}}],["graph",{"_index":704,"t":{"153":{"position":[[206,5]]},"427":{"position":[[305,5]]},"969":{"position":[[367,6]]}}}],["grassmann",{"_index":1896,"t":{"604":{"position":[[422,9]]}}}],["greedi",{"_index":641,"t":{"138":{"position":[[427,6]]},"151":{"position":[[173,6]]},"155":{"position":[[603,6]]},"242":{"position":[[117,6]]},"304":{"position":[[524,6]]},"482":{"position":[[157,6]]},"698":{"position":[[1272,6]]}}}],["green",{"_index":2542,"t":{"825":{"position":[[108,5]]},"1061":{"position":[[523,5]]}}}],["green</highlight",{"_index":3202,"t":{"1061":{"position":[[421,17]]}}}],["greet",{"_index":3093,"t":{"1030":{"position":[[86,9],[103,10],[392,11]]}}}],["greetings.md",{"_index":3091,"t":{"1030":{"position":[[33,13],[63,12]]}}}],["ground",{"_index":684,"t":{"149":{"position":[[79,6]]},"281":{"position":[[196,6]]},"302":{"position":[[506,8]]},"311":{"position":[[127,8]]},"977":{"position":[[126,6]]}}}],["group",{"_index":516,"t":{"104":{"position":[[264,5]]},"519":{"position":[[357,6]]},"627":{"position":[[311,5]]},"635":{"position":[[1027,5]]},"637":{"position":[[324,5]]},"1032":{"position":[[14,6]]},"1152":{"position":[[225,5]]}}}],["gsm8k",{"_index":875,"t":{"227":{"position":[[341,5]]},"229":{"position":[[968,5]]},"233":{"position":[[119,6]]},"236":{"position":[[0,5]]},"244":{"position":[[147,5],[407,5]]},"248":{"position":[[118,5]]},"254":{"position":[[239,5],[389,5]]},"390":{"position":[[235,5]]}}}],["gsum",{"_index":2939,"t":{"963":{"position":[[2277,4]]}}}],["gtx",{"_index":2431,"t":{"784":{"position":[[397,3]]}}}],["guid",{"_index":3158,"t":{"1047":{"position":[[217,7]]},"1087":{"position":[[2651,6]]},"1090":{"position":[[420,6]]},"1092":{"position":[[203,6],[341,6],[361,6],[513,6]]},"1096":{"position":[[1727,6],[1854,6],[1874,6]]},"1101":{"position":[[9,6],[169,6],[189,6]]},"1131":{"position":[[17,6]]},"1192":{"position":[[323,5]]}}}],["guidanc",{"_index":2926,"t":{"963":{"position":[[1725,8]]}}}],["guied",{"_index":3249,"t":{"1087":{"position":[[1621,7]]},"1092":{"position":[[2118,8],[2179,8],[2296,8],[2426,8]]}}}],["guiededannot",{"_index":3302,"t":{"1092":{"position":[[2408,17]]}}}],["guiededcategori",{"_index":3301,"t":{"1092":{"position":[[2392,15]]}}}],["guiededenclrefcategori",{"_index":3286,"t":{"1092":{"position":[[1955,22]]}}}],["guiededf_p",{"_index":3289,"t":{"1092":{"position":[[2027,10]]}}}],["guiededmerge(encvref[templ",{"_index":3287,"t":{"1092":{"position":[[1978,30]]}}}],["guo",{"_index":1114,"t":{"343":{"position":[[138,3]]}}}],["gym",{"_index":2641,"t":{"850":{"position":[[2211,3]]}}}],["h",{"_index":752,"t":{"171":{"position":[[582,3]]},"423":{"position":[[779,1]]},"1142":{"position":[[172,1]]}}}],["h,w)(h",{"_index":413,"t":{"91":{"position":[[288,8]]}}}],["h/14",{"_index":531,"t":{"106":{"position":[[196,4]]},"110":{"position":[[4,4]]},"114":{"position":[[214,4]]}}}],["h0,…,hi][h_0",{"_index":2297,"t":{"718":{"position":[[579,14]]}}}],["h0,…hi,e(x),hi+1,…hm,e(y)}\\begin{equ",{"_index":2195,"t":{"686":{"position":[[1491,43]]}}}],["h1>hello",{"_index":3178,"t":{"1057":{"position":[[148,10],[254,10]]}}}],["h1>mi",{"_index":3145,"t":{"1040":{"position":[[193,6]]}}}],["h<i",{"_index":2379,"t":{"770":{"position":[[425,8]]}}}],["h<i(n)]h_{<i",{"_index":2769,"t":{"901":{"position":[[737,14]]}}}],["h<i).\\begin{equ",{"_index":2370,"t":{"770":{"position":[[205,21]]}}}],["h<i=[h<i(1",{"_index":2768,"t":{"901":{"position":[[723,13]]}}}],["h=w(0)h",{"_index":3480,"t":{"1142":{"position":[[77,7]]}}}],["h=w(0)x+△x=w(0)x+bax,\\begin{equ",{"_index":3482,"t":{"1142":{"position":[[134,37]]}}}],["h=w0x+△wx=w0x+bax(3)h",{"_index":1808,"t":{"563":{"position":[[774,21]]}}}],["h=w0xh",{"_index":1806,"t":{"563":{"position":[[726,6]]}}}],["h^0:m=argmin⁡h",{"_index":2204,"t":{"686":{"position":[[1941,14]]}}}],["h^{(1)}_{<i",{"_index":2770,"t":{"901":{"position":[[754,14]]}}}],["h_0",{"_index":2196,"t":{"686":{"position":[[1538,4]]},"718":{"position":[[704,4]]}}}],["h_i",{"_index":2197,"t":{"686":{"position":[[1549,4]]},"688":{"position":[[773,3]]},"718":{"position":[[716,4]]},"766":{"position":[[713,3]]},"775":{"position":[[676,3]]}}}],["h_i][h0​,…,hi",{"_index":2298,"t":{"718":{"position":[[601,15]]}}}],["h_i^{(1",{"_index":2345,"t":{"766":{"position":[[408,11]]}}}],["h_i^{(n)})pϕ​(zi+1",{"_index":2358,"t":{"766":{"position":[[913,19]]}}}],["h_i^{(n)}]hi​=[hi(1)​;⋯;hi(n",{"_index":2346,"t":{"766":{"position":[[428,31]]}}}],["h_m",{"_index":2199,"t":{"686":{"position":[[1582,4]]}}}],["h_{<i",{"_index":2352,"t":{"766":{"position":[[742,8]]},"770":{"position":[[355,8]]},"775":{"position":[[786,8]]}}}],["h_{<i};\\theta;\\phi)\\tag{2}ϕmax​logp(y∣x;θ;ϕ)=ϕmax​yi​∑​logp(yi​,h<i​;θ;ϕ)(2",{"_index":2766,"t":{"901":{"position":[[547,76]]}}}],["h_{\\leq",{"_index":2356,"t":{"766":{"position":[[875,7]]}}}],["h_{i+1",{"_index":2198,"t":{"686":{"position":[[1567,8]]}}}],["h_{k,i",{"_index":2054,"t":{"633":{"position":[[1521,7]]}}}],["h_{k,i}^{(teach",{"_index":2055,"t":{"633":{"position":[[1531,19]]}}}],["hadamard",{"_index":2016,"t":{"631":{"position":[[738,8]]},"635":{"position":[[660,8]]},"674":{"position":[[238,8]]}}}],["hambardzumyan",{"_index":2479,"t":{"817":{"position":[[1338,14],[1905,14]]}}}],["hand",{"_index":2570,"t":{"836":{"position":[[1618,4]]},"1200":{"position":[[357,4],[558,4],[1096,4]]},"1211":{"position":[[523,4]]},"1220":{"position":[[204,4]]},"1232":{"position":[[28,4]]}}}],["handcraft",{"_index":2240,"t":{"692":{"position":[[188,9]]},"694":{"position":[[564,9]]}}}],["handl",{"_index":1686,"t":{"515":{"position":[[313,6]]}}}],["hard",{"_index":1132,"t":{"345":{"position":[[887,4],[1011,4]]},"696":{"position":[[968,4]]},"711":{"position":[[255,4]]},"713":{"position":[[950,4],[1358,4],[1551,4]]},"716":{"position":[[94,4]]},"732":{"position":[[157,4]]},"901":{"position":[[1909,4],[1977,4]]}}}],["harder",{"_index":1135,"t":{"345":{"position":[[1041,6]]}}}],["hardwar",{"_index":1743,"t":{"549":{"position":[[1023,8]]}}}],["harmless",{"_index":3045,"t":{"1003":{"position":[[187,8],[438,8]]}}}],["hat{\\text{y}}^{(n",{"_index":1382,"t":{"425":{"position":[[2172,23]]}}}],["hat{a",{"_index":995,"t":{"296":{"position":[[28,7]]}}}],["hat{a}_j",{"_index":1015,"t":{"300":{"position":[[715,9]]}}}],["hat{h}_{0:m",{"_index":2206,"t":{"686":{"position":[[1982,13]]}}}],["hat{l}_{adpt",{"_index":1852,"t":{"585":{"position":[[499,14]]}}}],["hat{l}_{ln",{"_index":1853,"t":{"585":{"position":[[578,12]]}}}],["hat{l}_{lora",{"_index":1858,"t":{"587":{"position":[[187,14]]}}}],["hat{p}_k",{"_index":2040,"t":{"633":{"position":[[1000,10]]}}}],["hat{q}_j",{"_index":1014,"t":{"300":{"position":[[704,10]]}}}],["hat{y}^{(n)}_{<t}))}{\\sum^n_{n=1}t^{(n",{"_index":1358,"t":{"425":{"position":[[624,42]]}}}],["hat{y}_1",{"_index":1361,"t":{"425":{"position":[[873,11]]}}}],["hat{y}_2",{"_index":1362,"t":{"425":{"position":[[885,10]]}}}],["hat{y}_i^{(n)}|\\text{x",{"_index":1357,"t":{"425":{"position":[[597,26]]}}}],["hat{y}_{t^(n)}y^​(n)=(y^​1​,y^​2​,…,y^​t(n",{"_index":1363,"t":{"425":{"position":[[903,45]]}}}],["head",{"_index":432,"t":{"91":{"position":[[1009,4],[1053,4],[1345,4],[2170,4],[2402,4]]},"97":{"position":[[97,4]]},"116":{"position":[[558,4],[764,4]]},"126":{"position":[[697,4],[1119,4]]},"463":{"position":[[2117,4]]},"688":{"position":[[1001,4],[1063,4],[1142,4]]},"736":{"position":[[22,4],[175,4]]},"751":{"position":[[39,4],[141,4],[217,4],[228,4]]},"836":{"position":[[1194,4]]},"1051":{"position":[[192,7]]},"1096":{"position":[[471,4],[1326,5],[1358,4],[1405,4],[2573,4]]},"1099":{"position":[[1402,4]]},"1140":{"position":[[89,4],[209,4],[727,4]]}}}],["health",{"_index":2801,"t":{"909":{"position":[[485,10]]}}}],["heavi",{"_index":2862,"t":{"933":{"position":[[364,5]]}}}],["height",{"_index":753,"t":{"171":{"position":[[593,7]]}}}],["held",{"_index":1221,"t":{"379":{"position":[[336,4]]},"382":{"position":[[76,4]]},"404":{"position":[[254,4]]},"423":{"position":[[995,4]]},"427":{"position":[[3013,4]]}}}],["hellaswag",{"_index":2996,"t":{"989":{"position":[[912,10]]}}}],["hello",{"_index":3116,"t":{"1034":{"position":[[57,5]]},"1036":{"position":[[188,5],[365,8]]}}}],["hellodocusauru",{"_index":3177,"t":{"1057":{"position":[[119,17],[227,17]]}}}],["help",{"_index":3043,"t":{"1003":{"position":[[170,8],[221,7],[233,7]]}}}],["heurist",{"_index":2626,"t":{"850":{"position":[[927,10],[1479,11]]},"857":{"position":[[440,9]]}}}],["hhh",{"_index":2213,"t":{"688":{"position":[[156,3],[1125,3]]},"1140":{"position":[[205,3]]}}}],["hi",{"_index":3121,"t":{"1036":{"position":[[156,5]]}}}],["hi(0≤i≤m)h_i",{"_index":2201,"t":{"686":{"position":[[1650,12],[1882,12]]}}}],["hi(j)h_i^{(j)}hi(j",{"_index":2347,"t":{"766":{"position":[[503,20]]}}}],["hi(n)]h_i",{"_index":2344,"t":{"766":{"position":[[395,10]]}}}],["hi(n)h_i^{(n)}hi(n",{"_index":2361,"t":{"766":{"position":[[1001,20]]}}}],["hi=[hi(1",{"_index":2343,"t":{"766":{"position":[[383,11]]}}}],["hi=lmϕ(zi,h<i),\\begin{equ",{"_index":2349,"t":{"766":{"position":[[681,31]]}}}],["hi=mlp([h→i",{"_index":2220,"t":{"688":{"position":[[691,11]]}}}],["hi={pθ[i,:],ifi∈pidxlmϕ(zi,h<i),otherwise.\\begin{equ",{"_index":2396,"t":{"775":{"position":[[617,58]]}}}],["hidden",{"_index":433,"t":{"91":{"position":[[1075,6]]},"132":{"position":[[158,6]]},"209":{"position":[[254,6]]},"633":{"position":[[1341,6],[1724,6],[1756,6]]},"648":{"position":[[184,6]]},"664":{"position":[[66,6],[139,6],[355,6]]},"1137":{"position":[[667,6]]},"1160":{"position":[[567,6]]},"1165":{"position":[[161,6]]},"1172":{"position":[[156,6]]}}}],["hiden",{"_index":625,"t":{"132":{"position":[[190,5]]}}}],["hierarch",{"_index":3269,"t":{"1092":{"position":[[1136,12]]},"1094":{"position":[[89,12]]},"1096":{"position":[[221,12]]}}}],["high",{"_index":494,"t":{"102":{"position":[[92,4]]},"165":{"position":[[601,4]]},"171":{"position":[[286,4],[669,4]]},"174":{"position":[[183,4]]},"504":{"position":[[2254,4]]},"515":{"position":[[811,4]]},"521":{"position":[[42,4],[376,4]]},"533":{"position":[[14,4]]},"696":{"position":[[1162,4]]},"802":{"position":[[107,4]]},"844":{"position":[[556,4]]},"1137":{"position":[[3481,4],[3883,4]]},"1146":{"position":[[1320,4]]},"1184":{"position":[[202,4],[339,4]]}}}],["higher",{"_index":1533,"t":{"461":{"position":[[439,6]]},"1148":{"position":[[2462,6]]}}}],["highli",{"_index":1700,"t":{"515":{"position":[[961,6]]}}}],["highlight",{"_index":2935,"t":{"963":{"position":[[1916,11]]},"1057":{"position":[[47,13]]},"1061":{"position":[[117,9],[383,10],[449,10]]}}}],["hih_ihi",{"_index":2217,"t":{"688":{"position":[[343,8],[445,8]]},"766":{"position":[[669,8],[787,8]]},"768":{"position":[[399,8]]},"775":{"position":[[1061,8],[1157,8],[1339,8]]},"901":{"position":[[882,9]]}}}],["histori",{"_index":1227,"t":{"382":{"position":[[115,8]]},"861":{"position":[[195,7]]}}}],["hi​])=mlp([lstm(h0:i",{"_index":2228,"t":{"688":{"position":[[954,22]]}}}],["hi′h_i'hi",{"_index":2219,"t":{"688":{"position":[[667,11]]}}}],["hi∈rdh_i",{"_index":2341,"t":{"766":{"position":[[347,8]]}}}],["hk,i(teacher)h_{k,i}^{(teacher)}hk,i(teach",{"_index":2059,"t":{"633":{"position":[[1624,46]]}}}],["hk,ih_{k,i}hk,i",{"_index":2060,"t":{"633":{"position":[[1673,16]]}}}],["hk,i​−hk,i(teach",{"_index":2057,"t":{"633":{"position":[[1597,20]]}}}],["hk,i−hk,i(teach",{"_index":2052,"t":{"633":{"position":[[1405,18]]}}}],["holist",{"_index":2854,"t":{"923":{"position":[[40,8],[97,8]]}}}],["honest",{"_index":3044,"t":{"1003":{"position":[[179,7],[316,6]]}}}],["hop",{"_index":918,"t":{"257":{"position":[[51,3]]},"375":{"position":[[129,3]]}}}],["horribl",{"_index":2727,"t":{"885":{"position":[[148,11]]}}}],["hotpotqa",{"_index":2102,"t":{"642":{"position":[[257,9]]},"850":{"position":[[1816,8]]}}}],["houlsbi",{"_index":3675,"t":{"1160":{"position":[[349,7]]},"1174":{"position":[[189,7]]}}}],["hour",{"_index":1074,"t":{"320":{"position":[[97,4]]},"457":{"position":[[757,4]]}}}],["howard",{"_index":2472,"t":{"817":{"position":[[314,7]]}}}],["html",{"_index":3153,"t":{"1044":{"position":[[99,5]]}}}],["http://boyangli.org/paper/jiaxian",{"_index":946,"t":{"277":{"position":[[14,33]]}}}],["http://localhost:3000",{"_index":133,"t":{"19":{"position":[[339,23]]},"1047":{"position":[[84,23]]}}}],["http://localhost:3000/blog/greet",{"_index":3112,"t":{"1030":{"position":[[554,37]]}}}],["http://localhost:3000/doc",{"_index":3212,"t":{"1065":{"position":[[201,27]]}}}],["http://localhost:3000/docs/hello",{"_index":3117,"t":{"1034":{"position":[[140,33]]},"1069":{"position":[[110,32]]}}}],["http://localhost:3000/docs/next",{"_index":3213,"t":{"1065":{"position":[[265,32]]}}}],["http://localhost:3000/docs/next/hello",{"_index":3222,"t":{"1069":{"position":[[165,37]]}}}],["http://localhost:3000/fr",{"_index":3233,"t":{"1077":{"position":[[104,25]]}}}],["http://localhost:3000/mi",{"_index":3149,"t":{"1040":{"position":[[290,24]]},"1042":{"position":[[152,24]]}}}],["https://aclanthology.org/2021.acl",{"_index":2322,"t":{"757":{"position":[[14,33]]}}}],["https://arxiv.org/abs/2010.11929v2",{"_index":372,"t":{"82":{"position":[[14,34]]}}}],["https://arxiv.org/abs/2104.00298",{"_index":141,"t":{"21":{"position":[[14,32]]}}}],["https://arxiv.org/pdf/2103.10385.pdf",{"_index":2137,"t":{"676":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2104.08691.pdf",{"_index":2467,"t":{"813":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2106.09685.pdf",{"_index":1733,"t":{"545":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2110.07602.pdf",{"_index":2280,"t":{"709":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2203.02155.pdf",{"_index":2984,"t":{"985":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2204.03649.pdf",{"_index":3730,"t":{"1196":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2205.05638.pdf",{"_index":1279,"t":{"414":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2206.07669v2.pdf",{"_index":576,"t":{"122":{"position":[[14,38]]}}}],["https://arxiv.org/pdf/2210.11416.pdf",{"_index":1193,"t":{"364":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2303.02506.pdf",{"_index":719,"t":{"161":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2303.02861.pdf",{"_index":1928,"t":{"612":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2303.06674v1.pdf",{"_index":3238,"t":{"1083":{"position":[[14,38]]}}}],["https://arxiv.org/pdf/2303.10512.pdf",{"_index":3404,"t":{"1133":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2303.11366v3.pdf",{"_index":2605,"t":{"846":{"position":[[14,38]]}}}],["https://arxiv.org/pdf/2303.16199.pdf",{"_index":1507,"t":{"453":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2304.15010.pdf",{"_index":1664,"t":{"500":{"position":[[14,36]]}}}],["https://arxiv.org/pdf/2305.07922v2.pdf",{"_index":1082,"t":{"326":{"position":[[14,38]]}}}],["https://dl.acm.org/doi/pdf/10.1145/3560815",{"_index":2692,"t":{"872":{"position":[[14,42]]}}}],["https://github.com/joelmarcey",{"_index":3099,"t":{"1030":{"position":[[182,29]]}}}],["https://github.com/joelmarcey.png",{"_index":3101,"t":{"1030":{"position":[[223,33]]}}}],["https://github.com/salesforce/lavis/tree/main/projects/img2llm",{"_index":961,"t":{"279":{"position":[[777,62]]}}}],["https://github.com/slorber.png",{"_index":3106,"t":{"1030":{"position":[[355,30]]}}}],["https://github.com/tonyhuang2022/upl",{"_index":3736,"t":{"1198":{"position":[[698,36]]}}}],["https://github.com/whdnjsdyd111/pap",{"_index":370,"t":{"80":{"position":[[90,37]]}}}],["https://namecensus.com",{"_index":929,"t":{"267":{"position":[[92,25]]}}}],["https://openai.com/blog/chatgpt",{"_index":2985,"t":{"985":{"position":[[51,31]]}}}],["https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4",{"_index":854,"t":{"225":{"position":[[14,91]]}}}],["https://sebastienlorber.com",{"_index":3105,"t":{"1030":{"position":[[316,27]]}}}],["hu",{"_index":395,"t":{"88":{"position":[[445,2]]},"1160":{"position":[[817,4]]}}}],["hug",{"_index":2424,"t":{"784":{"position":[[155,7]]}}}],["huge",{"_index":514,"t":{"104":{"position":[[23,4]]},"1104":{"position":[[50,4]]}}}],["huggigfac",{"_index":3668,"t":{"1158":{"position":[[48,10]]}}}],["huggingfac",{"_index":1861,"t":{"589":{"position":[[33,11]]},"784":{"position":[[96,11]]}}}],["human",{"_index":596,"t":{"126":{"position":[[927,5]]},"398":{"position":[[914,5],[962,5],[987,5]]},"408":{"position":[[141,5]]},"416":{"position":[[757,5]]},"418":{"position":[[689,5],[2321,5]]},"451":{"position":[[408,5]]},"985":{"position":[[144,5]]},"987":{"position":[[223,5]]},"989":{"position":[[285,5]]},"1016":{"position":[[33,5]]},"1022":{"position":[[309,5]]}}}],["humanev",{"_index":2617,"t":{"848":{"position":[[586,9]]},"850":{"position":[[1852,9]]}}}],["huomenta",{"_index":2715,"t":{"879":{"position":[[536,9]]}}}],["hutter",{"_index":1189,"t":{"362":{"position":[[1042,7]]}}}],["hw/p^2n=hw/p2",{"_index":419,"t":{"91":{"position":[[373,13]]}}}],["hybrid",{"_index":477,"t":{"95":{"position":[[68,6]]},"99":{"position":[[13,6]]},"104":{"position":[[363,6]]},"114":{"position":[[20,6],[390,6]]},"680":{"position":[[325,6]]},"901":{"position":[[1926,6]]}}}],["hyp",{"_index":2234,"t":{"688":{"position":[[1408,7]]}}}],["hyper",{"_index":2956,"t":{"969":{"position":[[582,5]]}}}],["hypercomplex",{"_index":1444,"t":{"427":{"position":[[3302,12]]}}}],["hyperparamet",{"_index":1217,"t":{"379":{"position":[[126,14]]},"418":{"position":[[1749,14]]},"421":{"position":[[309,14]]},"425":{"position":[[2413,14],[2531,14]]},"427":{"position":[[4045,14]]},"431":{"position":[[359,14],[679,14]]},"433":{"position":[[117,14]]},"482":{"position":[[177,14]]},"491":{"position":[[77,14]]},"563":{"position":[[1117,14]]},"627":{"position":[[746,15]]},"662":{"position":[[3,14]]},"698":{"position":[[363,14],[660,14],[1252,14],[1613,14]]},"702":{"position":[[804,14]]},"751":{"position":[[174,14]]},"784":{"position":[[214,14]]},"827":{"position":[[48,14]]},"832":{"position":[[27,14]]},"935":{"position":[[366,14]]}}}],["hyperprompt",{"_index":1943,"t":{"619":{"position":[[288,11]]}}}],["hypter",{"_index":3793,"t":{"1222":{"position":[[220,6]]}}}],["hyv",{"_index":2714,"t":{"879":{"position":[[529,6]]}}}],["h←i])=mlp([lstm(h0:i",{"_index":2221,"t":{"688":{"position":[[705,21]]}}}],["h≤i)=softmax(wϕhi(n))p_{\\phi}(z_{i+1",{"_index":2355,"t":{"766":{"position":[[833,38]]}}}],["h≤i​)=softmax(wϕ​hi(n",{"_index":2359,"t":{"766":{"position":[[935,24]]}}}],["i(t)i^{(t)}i(t",{"_index":3650,"t":{"1152":{"position":[[2222,15]]}}}],["i(w_{ij",{"_index":3626,"t":{"1152":{"position":[[1038,9]]}}}],["i(wij)=∣wij▽wijl∣,\\begin{equ",{"_index":3625,"t":{"1152":{"position":[[1003,34]]}}}],["i(x),z<t)p(z_t|x,z_{<t",{"_index":2837,"t":{"917":{"position":[[1398,24]]}}}],["i(x)f_{\\textup{prompt",{"_index":2843,"t":{"917":{"position":[[1579,22]]}}}],["i,:])pθ​[i:0]=mlpθ​(pθ′​[i",{"_index":2418,"t":{"777":{"position":[[260,31]]}}}],["i,j)th(i",{"_index":1404,"t":{"427":{"position":[[1059,10]]}}}],["i.",{"_index":911,"t":{"250":{"position":[[28,5]]},"392":{"position":[[324,5]]},"423":{"position":[[330,5]]},"427":{"position":[[776,5]]},"635":{"position":[[683,4]]},"800":{"position":[[174,5]]},"1137":{"position":[[2953,4]]},"1142":{"position":[[866,5]]},"1146":{"position":[[1533,5]]},"1148":{"position":[[246,4]]},"1150":{"position":[[47,4]]},"1154":{"position":[[111,5]]},"1160":{"position":[[893,5]]}}}],["i18n",{"_index":3068,"t":{"1024":{"position":[[180,5]]},"1073":{"position":[[102,5]]}}}],["i18n/fr",{"_index":3226,"t":{"1075":{"position":[[35,7]]}}}],["i18n/fr/docusauru",{"_index":3228,"t":{"1075":{"position":[[60,18],[125,18],[191,18]]}}}],["i:0",{"_index":2415,"t":{"777":{"position":[[223,5]]}}}],["i^{(t)}(w_{ij",{"_index":3644,"t":{"1152":{"position":[[1884,15]]}}}],["i_m",{"_index":1612,"t":{"465":{"position":[[262,3],[535,3]]}}}],["i_p",{"_index":1618,"t":{"465":{"position":[[485,3]]}}}],["ia)3",{"_index":1496,"t":{"443":{"position":[[470,5]]}}}],["ia)3(ia)^3(ia)3",{"_index":1288,"t":{"416":{"position":[[532,16]]},"418":{"position":[[2114,16],[2134,16]]},"427":{"position":[[2356,16],[2453,16],[2615,16],[2753,16],[2927,16],[2988,16],[3757,16],[3875,16]]},"429":{"position":[[262,16],[404,16]]},"431":{"position":[[77,16],[142,16]]},"443":{"position":[[29,16],[347,16]]},"451":{"position":[[128,16]]}}}],["iamg",{"_index":3743,"t":{"1203":{"position":[[11,5]]}}}],["icl",{"_index":1280,"t":{"416":{"position":[[29,6],[169,3],[401,3]]},"418":{"position":[[529,5],[539,3],[738,3],[819,3],[870,3],[885,3],[975,3],[1081,3],[1163,4],[1566,3],[2235,3]]},"421":{"position":[[96,3]]},"427":{"position":[[9,3],[154,3]]},"433":{"position":[[66,3]]},"435":{"position":[[124,3],[170,3],[245,3],[318,3],[420,3]]},"437":{"position":[[8,3],[944,3],[1035,3]]},"439":{"position":[[21,3],[214,3],[410,3],[473,3]]},"441":{"position":[[258,3],[372,3]]},"443":{"position":[[126,3]]},"451":{"position":[[103,3],[494,3]]}}}],["id",{"_index":3161,"t":{"1051":{"position":[[79,3],[90,2]]},"1115":{"position":[[176,5]]},"1117":{"position":[[55,2]]}}}],["idea",{"_index":2212,"t":{"688":{"position":[[30,4]]}}}],["ideal",{"_index":2565,"t":{"834":{"position":[[641,5]]}}}],["ident",{"_index":774,"t":{"178":{"position":[[312,8]]},"909":{"position":[[203,8]]},"1115":{"position":[[131,8],[158,8]]},"1222":{"position":[[562,9]]}}}],["idf1",{"_index":3396,"t":{"1115":{"position":[[149,6]]}}}],["ie\\triangle^e_i△i",{"_index":2573,"t":{"836":{"position":[[1704,20]]}}}],["iii",{"_index":1892,"t":{"604":{"position":[[269,3],[755,3],[894,3]]},"633":{"position":[[1738,3]]},"766":{"position":[[309,3],[536,3]]},"901":{"position":[[825,3]]},"1140":{"position":[[732,3]]},"1142":{"position":[[597,3],[631,3],[712,3]]},"1146":{"position":[[557,3]]},"1148":{"position":[[501,3]]},"1214":{"position":[[378,3]]}}}],["iiit",{"_index":499,"t":{"102":{"position":[[197,4]]}}}],["iiith",{"_index":2831,"t":{"917":{"position":[[478,5]]}}}],["ik",{"_index":259,"t":{"49":{"position":[[318,5]]}}}],["ilsvrc",{"_index":488,"t":{"102":{"position":[[14,6]]}}}],["ilsvrc2012",{"_index":283,"t":{"53":{"position":[[46,10]]},"58":{"position":[[108,10]]},"63":{"position":[[9,10]]}}}],["imag",{"_index":69,"t":{"9":{"position":[[344,7]]},"27":{"position":[[394,5]]},"78":{"position":[[44,5],[87,5],[294,5],[353,5],[516,5],[611,5]]},"95":{"position":[[5,5]]},"102":{"position":[[44,7],[70,7],[108,7]]},"116":{"position":[[665,5]]},"120":{"position":[[14,5]]},"124":{"position":[[337,5]]},"126":{"position":[[259,5],[479,5],[953,5]]},"128":{"position":[[195,5]]},"130":{"position":[[123,5],[168,5]]},"132":{"position":[[8,5],[68,5],[134,5],[314,5],[911,5]]},"134":{"position":[[9,5]]},"136":{"position":[[24,5],[129,5]]},"138":{"position":[[62,5],[98,5],[263,5]]},"151":{"position":[[41,5]]},"153":{"position":[[582,5]]},"155":{"position":[[821,5],[931,5]]},"157":{"position":[[102,5]]},"159":{"position":[[397,5]]},"165":{"position":[[92,5],[828,5],[846,5]]},"169":{"position":[[78,5]]},"174":{"position":[[346,6]]},"180":{"position":[[496,5]]},"186":{"position":[[101,5],[160,5]]},"190":{"position":[[0,5],[81,5],[178,5]]},"195":{"position":[[65,5]]},"215":{"position":[[56,5],[79,5]]},"281":{"position":[[760,5],[1129,5],[1596,5],[1873,5],[1890,5]]},"284":{"position":[[83,5]]},"290":{"position":[[187,5]]},"292":{"position":[[627,5],[675,5],[701,5]]},"294":{"position":[[4,5]]},"298":{"position":[[134,7],[192,7]]},"300":{"position":[[30,5]]},"302":{"position":[[44,5],[500,5],[574,5],[734,5],[989,5]]},"311":{"position":[[62,5],[121,5]]},"324":{"position":[[0,5]]},"457":{"position":[[1009,5],[1052,5]]},"465":{"position":[[166,5],[712,5],[1044,5]]},"482":{"position":[[23,5]]},"494":{"position":[[0,5]]},"502":{"position":[[419,5],[529,5],[599,5],[772,5]]},"504":{"position":[[824,6],[982,5],[1166,5],[1499,5],[1640,5],[2122,5],[2350,5]]},"510":{"position":[[27,5]]},"519":{"position":[[127,5],[233,5],[370,5],[619,5]]},"521":{"position":[[93,5],[209,5],[414,5]]},"525":{"position":[[52,5],[103,5],[170,5],[230,5],[478,5],[677,5]]},"535":{"position":[[223,5]]},"537":{"position":[[129,5],[186,5],[308,6],[415,5],[519,5],[704,5]]},"539":{"position":[[15,5],[184,5],[260,5]]},"541":{"position":[[152,5],[248,5]]},"543":{"position":[[100,5],[252,5]]},"901":{"position":[[1386,5]]},"961":{"position":[[174,5]]},"963":{"position":[[2837,6]]},"1055":{"position":[[17,6],[79,6],[197,6],[282,6]]},"1085":{"position":[[592,5]]},"1090":{"position":[[566,5]]},"1094":{"position":[[134,5]]},"1099":{"position":[[454,5],[512,5],[1114,5],[1158,5]]},"1107":{"position":[[27,7],[57,7]]},"1198":{"position":[[229,5]]},"1200":{"position":[[49,5],[80,5],[471,5],[858,5],[972,5],[1902,5]]},"1203":{"position":[[118,5],[290,5],[449,5]]},"1205":{"position":[[282,5]]},"1207":{"position":[[180,5],[339,5],[587,7]]},"1209":{"position":[[140,5]]},"1211":{"position":[[165,5]]},"1214":{"position":[[395,5]]},"1216":{"position":[[247,5]]},"1222":{"position":[[671,5],[687,5],[1180,5],[1424,5]]},"1224":{"position":[[163,5],[187,5],[238,5]]},"1238":{"position":[[6,5]]}}}],["image/text",{"_index":808,"t":{"186":{"position":[[177,10]]}}}],["image_url",{"_index":3100,"t":{"1030":{"position":[[212,10],[344,10]]}}}],["imagenet",{"_index":180,"t":{"25":{"position":[[675,8]]},"53":{"position":[[37,8]]},"58":{"position":[[99,8]]},"63":{"position":[[0,8],[91,8]]},"86":{"position":[[306,16]]},"88":{"position":[[544,8],[558,8]]},"102":{"position":[[26,8],[52,8],[154,8],[163,8]]},"112":{"position":[[3,9],[13,8]]},"118":{"position":[[142,8]]},"197":{"position":[[12,8]]},"494":{"position":[[26,8]]},"1198":{"position":[[601,8]]},"1232":{"position":[[8,8],[196,8]]},"1238":{"position":[[35,8]]}}}],["imagenet21k",{"_index":311,"t":{"58":{"position":[[0,11]]}}}],["imageri",{"_index":509,"t":{"102":{"position":[[329,7]]}}}],["img2llm",{"_index":953,"t":{"279":{"position":[[266,7],[475,7]]},"281":{"position":[[1257,7],[1378,7],[1748,7],[1932,7],[2044,7],[2198,7]]},"292":{"position":[[608,7],[849,7]]},"316":{"position":[[0,7]]},"320":{"position":[[0,7],[176,7],[215,7]]},"322":{"position":[[0,7],[76,7]]}}}],["img2llm.pdf",{"_index":949,"t":{"277":{"position":[[58,11]]}}}],["immedi",{"_index":86,"t":{"13":{"position":[[54,11]]}}}],["implement",{"_index":369,"t":{"80":{"position":[[65,11]]},"1137":{"position":[[1347,14],[2322,9]]}}}],["import",{"_index":3140,"t":{"1040":{"position":[[72,6],[99,6]]},"1135":{"position":[[478,10]]},"1137":{"position":[[1158,9],[2887,9],[2998,9],[3167,10]]},"1140":{"position":[[770,9]]},"1144":{"position":[[102,10],[144,10]]},"1148":{"position":[[160,10],[538,10],[1607,10],[2339,10],[2427,9],[2522,10]]},"1152":{"position":[[0,10],[131,10],[428,10],[770,10],[910,10],[1339,10],[2321,10],[2629,10]]},"1188":{"position":[[11,10],[105,10],[244,10]]},"1192":{"position":[[268,10]]},"1194":{"position":[[54,10],[216,10]]}}}],["improv",{"_index":358,"t":{"78":{"position":[[393,8]]},"850":{"position":[[1665,11]]},"853":{"position":[[160,11]]}}}],["impur",{"_index":2691,"t":{"870":{"position":[[394,6]]}}}],["im}m=1m",{"_index":1611,"t":{"465":{"position":[[251,10]]}}}],["im∈r1×ci_m",{"_index":1614,"t":{"465":{"position":[[287,10]]}}}],["includ",{"_index":521,"t":{"106":{"position":[[12,7]]},"1081":{"position":[[90,7]]}}}],["incorpor",{"_index":1666,"t":{"502":{"position":[[402,13]]},"848":{"position":[[699,13]]}}}],["incorrect",{"_index":1303,"t":{"418":{"position":[[1087,9]]},"425":{"position":[[750,9],[801,9],[957,9],[1062,9]]},"431":{"position":[[244,9]]},"451":{"position":[[275,9]]}}}],["increas",{"_index":356,"t":{"78":{"position":[[344,8],[602,8]]}}}],["increment",{"_index":3405,"t":{"1135":{"position":[[237,11],[326,11],[589,11]]},"1137":{"position":[[857,11],[974,11],[2370,11],[3398,11],[3457,11]]},"1142":{"position":[[54,11]]},"1144":{"position":[[43,11]]},"1146":{"position":[[30,11],[1337,11],[2015,11]]},"1148":{"position":[[220,11],[2478,11]]},"1154":{"position":[[77,11],[396,11]]},"1160":{"position":[[685,11]]},"1192":{"position":[[52,11]]},"1194":{"position":[[135,11],[283,11]]}}}],["index",{"_index":2362,"t":{"768":{"position":[[223,8]]},"1028":{"position":[[62,5]]}}}],["indic",{"_index":2339,"t":{"766":{"position":[[236,7]]},"775":{"position":[[293,7],[407,7]]}}}],["induct",{"_index":379,"t":{"86":{"position":[[392,9],[529,9],[544,9],[641,9],[727,9],[798,9]]},"93":{"position":[[97,9]]},"97":{"position":[[460,9]]},"112":{"position":[[90,9],[493,9]]},"120":{"position":[[29,9]]},"273":{"position":[[86,9]]},"876":{"position":[[302,9]]}}}],["infer",{"_index":191,"t":{"27":{"position":[[109,9],[170,9],[459,9]]},"375":{"position":[[161,9]]},"418":{"position":[[2345,9]]},"421":{"position":[[156,9]]},"423":{"position":[[827,9]]},"431":{"position":[[511,9]]},"437":{"position":[[467,9]]},"439":{"position":[[38,9]]},"445":{"position":[[0,9],[59,9]]},"451":{"position":[[506,9]]},"502":{"position":[[675,9]]},"541":{"position":[[29,9]]},"547":{"position":[[392,9]]},"549":{"position":[[1234,9]]},"567":{"position":[[85,9]]},"610":{"position":[[59,9]]},"688":{"position":[[1094,9]]},"713":{"position":[[230,9]]},"811":{"position":[[235,9]]},"821":{"position":[[406,10]]},"840":{"position":[[153,9],[362,9]]},"861":{"position":[[57,9]]},"895":{"position":[[369,10]]},"1163":{"position":[[175,9]]},"1211":{"position":[[587,9]]},"1214":{"position":[[11,9]]},"1226":{"position":[[187,9]]},"1232":{"position":[[50,9]]}}}],["infix",{"_index":1837,"t":{"581":{"position":[[83,10],[236,5]]},"800":{"position":[[235,5],[271,5],[380,5]]}}}],["inflex",{"_index":1083,"t":{"328":{"position":[[126,13]]}}}],["inform",{"_index":1447,"t":{"427":{"position":[[3437,11]]},"465":{"position":[[1070,11]]},"539":{"position":[[103,11]]},"619":{"position":[[316,11]]},"625":{"position":[[761,11]]},"819":{"position":[[452,11]]},"969":{"position":[[118,11],[327,11]]},"1137":{"position":[[3527,11]]}}}],["infus",{"_index":1432,"t":{"427":{"position":[[2381,8]]}}}],["inhibit",{"_index":1433,"t":{"427":{"position":[[2401,10]]}}}],["init",{"_index":106,"t":{"17":{"position":[[155,4]]},"489":{"position":[[117,4],[239,4]]}}}],["initi",{"_index":565,"t":{"116":{"position":[[311,7]]},"455":{"position":[[341,11],[648,11]]},"457":{"position":[[528,11],[779,11],[1215,11]]},"463":{"position":[[179,11],[2431,11]]},"467":{"position":[[5,11]]},"469":{"position":[[126,11]]},"471":{"position":[[36,11],[83,11]]},"477":{"position":[[159,11]]},"489":{"position":[[5,11],[67,11],[195,11]]},"496":{"position":[[81,11]]},"498":{"position":[[111,11]]},"504":{"position":[[210,11]]},"508":{"position":[[275,11]]},"515":{"position":[[21,11]]},"519":{"position":[[433,11]]},"523":{"position":[[543,11]]},"698":{"position":[[1076,7]]},"736":{"position":[[148,11]]},"802":{"position":[[26,14],[73,14],[292,14],[336,14],[378,14]]},"804":{"position":[[29,14],[249,14],[357,14]]},"821":{"position":[[24,10],[55,14],[147,14],[269,14]]},"832":{"position":[[56,14],[93,14],[181,12],[325,14],[627,14],[668,14],[712,14],[771,14]]},"840":{"position":[[32,14]]},"901":{"position":[[1424,11]]},"1024":{"position":[[76,7]]},"1142":{"position":[[498,14]]},"1154":{"position":[[287,7]]}}}],["inject",{"_index":1512,"t":{"455":{"position":[[422,7]]}}}],["inner",{"_index":1435,"t":{"427":{"position":[[2427,5]]},"451":{"position":[[181,5]]}}}],["inport",{"_index":3438,"t":{"1137":{"position":[[3559,10]]}}}],["input",{"_index":420,"t":{"91":{"position":[[419,5]]},"104":{"position":[[74,5],[121,5]]},"128":{"position":[[33,5]]},"130":{"position":[[320,5]]},"132":{"position":[[14,5],[905,5]]},"169":{"position":[[66,5]]},"176":{"position":[[164,5]]},"178":{"position":[[143,5],[242,5]]},"190":{"position":[[131,5]]},"211":{"position":[[158,5]]},"229":{"position":[[475,5],[614,5],[729,7]]},"238":{"position":[[12,5]]},"286":{"position":[[133,5]]},"300":{"position":[[175,5]]},"304":{"position":[[588,5]]},"337":{"position":[[8,5]]},"343":{"position":[[332,5],[414,5],[427,5]]},"345":{"position":[[422,5],[520,5]]},"347":{"position":[[159,5],[181,5],[280,5],[316,5]]},"355":{"position":[[16,5]]},"379":{"position":[[272,5]]},"398":{"position":[[272,5],[832,5]]},"416":{"position":[[70,5]]},"418":{"position":[[568,9],[629,5],[933,5]]},"425":{"position":[[232,5]]},"427":{"position":[[3370,5]]},"437":{"position":[[839,5]]},"439":{"position":[[86,5]]},"457":{"position":[[414,5],[1015,5]]},"461":{"position":[[635,5]]},"463":{"position":[[400,5]]},"465":{"position":[[52,5],[160,5],[1139,5]]},"482":{"position":[[17,5]]},"502":{"position":[[33,5]]},"510":{"position":[[308,5]]},"517":{"position":[[255,5],[286,5]]},"523":{"position":[[148,5],[486,5]]},"525":{"position":[[472,5]]},"537":{"position":[[75,5]]},"551":{"position":[[63,5]]},"555":{"position":[[41,5]]},"563":{"position":[[672,5]]},"565":{"position":[[134,5]]},"581":{"position":[[0,5]]},"619":{"position":[[143,5]]},"627":{"position":[[485,5],[541,5],[764,5],[962,5]]},"633":{"position":[[1745,5]]},"684":{"position":[[34,5],[81,5]]},"686":{"position":[[48,5],[210,5]]},"688":{"position":[[650,5]]},"713":{"position":[[787,5],[1240,5]]},"718":{"position":[[197,5],[246,5],[625,5]]},"725":{"position":[[129,5]]},"727":{"position":[[57,5],[181,5]]},"761":{"position":[[775,5],[988,5],[1134,5]]},"764":{"position":[[0,5]]},"773":{"position":[[302,5],[336,5]]},"789":{"position":[[306,5]]},"817":{"position":[[789,5],[1367,5],[1550,5]]},"819":{"position":[[67,5],[497,5],[1761,5]]},"821":{"position":[[207,5]]},"823":{"position":[[112,5],[372,5],[868,5],[1506,5]]},"825":{"position":[[290,5]]},"834":{"position":[[875,5]]},"836":{"position":[[420,5],[502,5],[986,5],[1171,5],[1306,5],[1345,5],[1656,5],[2451,5],[2546,5],[2579,5]]},"838":{"position":[[97,5]]},"870":{"position":[[476,5]]},"874":{"position":[[70,5],[174,5]]},"879":{"position":[[31,5],[187,5],[350,5],[517,5]]},"883":{"position":[[0,5],[174,5],[189,5],[244,5]]},"893":{"position":[[311,5],[358,5]]},"899":{"position":[[55,5],[459,5],[858,5],[954,5],[1141,5]]},"901":{"position":[[324,5],[1088,5],[1380,5],[1702,5],[2080,5]]},"909":{"position":[[410,5]]},"919":{"position":[[55,5],[385,5]]},"923":{"position":[[25,5],[184,5]]},"937":{"position":[[319,5]]},"943":{"position":[[178,5]]},"949":{"position":[[300,5]]},"953":{"position":[[50,5]]},"955":{"position":[[462,5]]},"959":{"position":[[136,5],[508,5],[597,5],[608,5],[888,5]]},"963":{"position":[[691,5],[802,5],[904,5],[1680,5],[2034,5],[2170,5],[2575,5]]},"969":{"position":[[353,5]]},"975":{"position":[[454,5],[743,5]]},"983":{"position":[[447,5],[466,7],[511,6],[556,6],[616,5],[635,7],[680,6],[725,6],[851,5],[952,5]]},"995":{"position":[[541,5]]},"1085":{"position":[[343,5]]},"1087":{"position":[[1381,5]]},"1096":{"position":[[72,5],[264,5],[556,5],[677,5]]},"1137":{"position":[[658,5]]},"1140":{"position":[[137,5]]},"1160":{"position":[[586,6]]}}}],["input(head",{"_index":2759,"t":{"899":{"position":[[1073,10]]}}}],["insert",{"_index":1534,"t":{"461":{"position":[[521,8]]},"463":{"position":[[214,8]]},"465":{"position":[[759,8]]},"469":{"position":[[90,8]]},"523":{"position":[[247,8]]}}}],["insid",{"_index":3188,"t":{"1061":{"position":[[87,6]]}}}],["inspir",{"_index":3083,"t":{"1026":{"position":[[187,12]]}}}],["instal",{"_index":92,"t":{"15":{"position":[[37,10]]},"17":{"position":[[337,8]]}}}],["instanc",{"_index":582,"t":{"124":{"position":[[293,8]]},"126":{"position":[[436,8],[904,8]]},"128":{"position":[[154,8]]},"130":{"position":[[80,8],[781,8],[821,8]]},"140":{"position":[[471,8]]},"143":{"position":[[146,8],[186,8]]},"147":{"position":[[333,8]]},"149":{"position":[[11,8]]},"151":{"position":[[18,8]]},"155":{"position":[[704,8]]},"157":{"position":[[58,8],[277,8]]},"159":{"position":[[817,8]]},"165":{"position":[[633,9]]},"174":{"position":[[251,8],[309,8]]},"1085":{"position":[[17,8],[89,8],[275,8],[464,8],[628,8],[777,8]]},"1087":{"position":[[84,8],[265,8],[748,8],[777,8],[814,8],[1179,8],[1253,8],[1350,8],[1456,8],[1714,8],[1757,8],[1819,8],[2072,8],[2118,8],[2180,8],[2226,8],[2271,8],[2506,8],[2615,8],[2682,8],[2840,8]]},"1090":{"position":[[27,8],[93,8],[179,8],[385,8]]},"1096":{"position":[[89,8],[180,8],[362,8],[389,8],[718,8],[1177,8],[1286,8],[1349,8],[1500,8],[2348,8],[2587,8]]},"1099":{"position":[[754,8]]},"1101":{"position":[[56,8],[127,8]]},"1107":{"position":[[92,8]]},"1115":{"position":[[25,8]]},"1131":{"position":[[47,8]]}}}],["instris",{"_index":1787,"t":{"563":{"position":[[146,9]]}}}],["instruct",{"_index":1041,"t":{"304":{"position":[[44,12],[111,11]]},"328":{"position":[[670,11],[777,11]]},"330":{"position":[[1533,11],[1630,11]]},"366":{"position":[[0,11],[79,11]]},"368":{"position":[[4,11],[38,11],[111,11],[181,11],[420,11],[572,11]]},"370":{"position":[[36,11],[60,11]]},"373":{"position":[[53,11]]},"377":{"position":[[40,13],[98,11]]},"379":{"position":[[27,11]]},"386":{"position":[[134,11]]},"388":{"position":[[0,11]]},"392":{"position":[[7,11],[351,11]]},"394":{"position":[[37,11]]},"396":{"position":[[0,11],[143,11],[218,11],[303,11],[373,11],[517,11],[598,11],[672,11]]},"398":{"position":[[280,11],[782,11],[896,12]]},"400":{"position":[[6,11],[85,11]]},"402":{"position":[[0,11],[226,11]]},"406":{"position":[[151,11],[240,11]]},"408":{"position":[[259,11]]},"410":{"position":[[37,11],[107,11],[176,11]]},"412":{"position":[[0,11],[147,11]]},"418":{"position":[[710,12]]},"431":{"position":[[579,11]]},"455":{"position":[[24,11],[108,11],[389,11],[498,11]]},"457":{"position":[[18,11],[89,11],[215,11],[292,11],[420,11],[731,11],[974,11],[991,11],[1143,11]]},"461":{"position":[[4,11],[91,11],[641,11],[875,11]]},"463":{"position":[[1611,11],[2509,13]]},"465":{"position":[[5,11]]},"467":{"position":[[53,11]]},"475":{"position":[[25,11],[55,11],[490,11]]},"479":{"position":[[15,11]]},"498":{"position":[[136,11]]},"502":{"position":[[78,11],[155,11],[297,11],[437,11],[552,11],[612,11],[895,11],[938,11]]},"504":{"position":[[9,11],[93,11],[129,11],[367,11],[482,11],[579,11],[657,11],[692,11],[922,11],[1115,11],[1198,11],[1530,11],[1619,11],[1656,11],[1730,11],[1898,11],[2207,11],[2276,11],[2331,11],[2373,11],[2446,11],[2493,11]]},"508":{"position":[[0,11],[480,11]]},"512":{"position":[[157,11]]},"515":{"position":[[273,11],[824,11],[852,11]]},"519":{"position":[[170,11],[256,11],[290,11],[474,11],[646,11]]},"521":{"position":[[67,11],[112,11],[271,11],[389,11],[427,11]]},"525":{"position":[[444,11]]},"529":{"position":[[35,11],[147,11]]},"533":{"position":[[27,11],[77,11]]},"535":{"position":[[28,11],[129,11],[177,11],[334,11]]},"537":{"position":[[391,11],[456,11]]},"539":{"position":[[279,11]]},"543":{"position":[[33,12],[119,11],[188,11],[228,11],[271,11],[419,11],[548,11]]},"761":{"position":[[747,11]]},"773":{"position":[[491,11],[645,11],[725,11]]},"895":{"position":[[427,13]]},"919":{"position":[[410,11]]},"959":{"position":[[250,11],[804,11]]},"985":{"position":[[126,12]]},"989":{"position":[[244,14]]},"995":{"position":[[130,8],[264,11]]}}}],["instructgpt",{"_index":1273,"t":{"398":{"position":[[930,12]]},"504":{"position":[[69,11]]},"987":{"position":[[294,11]]},"989":{"position":[[327,13],[589,11],[610,11],[650,11],[1065,11],[1095,11],[1148,11]]},"995":{"position":[[56,11]]},"997":{"position":[[56,11]]},"1001":{"position":[[2041,11],[2113,11]]},"1006":{"position":[[18,11],[90,11]]},"1008":{"position":[[0,11],[35,11]]},"1010":{"position":[[0,11],[64,11]]},"1013":{"position":[[363,11]]},"1016":{"position":[[0,11],[119,11],[219,11],[304,11]]},"1018":{"position":[[10,11]]},"1020":{"position":[[0,11],[56,11]]}}}],["integ",{"_index":1491,"t":{"443":{"position":[[190,10]]}}}],["integr",{"_index":113,"t":{"17":{"position":[[279,10]]},"504":{"position":[[2553,11]]}}}],["intens",{"_index":2633,"t":{"850":{"position":[[1631,10]]},"1137":{"position":[[4286,9]]},"1146":{"position":[[1417,9]]}}}],["inter",{"_index":1464,"t":{"437":{"position":[[230,9]]}}}],["interact",{"_index":41,"t":{"7":{"position":[[99,11]]},"1061":{"position":[[37,11]]}}}],["interest",{"_index":710,"t":{"155":{"position":[[508,8]]}}}],["interfac",{"_index":578,"t":{"124":{"position":[[184,9],[389,9]]},"126":{"position":[[228,9],[841,9],[1001,9]]},"130":{"position":[[345,9],[414,9]]},"279":{"position":[[659,9]]}}}],["intermedi",{"_index":859,"t":{"227":{"position":[[19,12]]},"229":{"position":[[295,12]]},"231":{"position":[[62,12],[230,12]]},"250":{"position":[[34,12],[215,12]]},"273":{"position":[[54,12]]},"290":{"position":[[32,12]]},"292":{"position":[[346,12]]},"418":{"position":[[2053,12]]},"427":{"position":[[1336,12]]},"445":{"position":[[127,12]]},"633":{"position":[[1786,12]]},"817":{"position":[[1980,12]]},"836":{"position":[[534,12]]}}}],["intern",{"_index":563,"t":{"116":{"position":[[27,8],[59,8],[261,8]]}}}],["interpol",{"_index":263,"t":{"49":{"position":[[382,13]]},"97":{"position":[[403,15]]},"343":{"position":[[780,13]]}}}],["interpret",{"_index":2635,"t":{"850":{"position":[[1712,11]]}}}],["intial",{"_index":3657,"t":{"1154":{"position":[[417,6]]}}}],["intrins",{"_index":1448,"t":{"427":{"position":[[3484,9]]},"549":{"position":[[393,9],[471,10]]},"602":{"position":[[138,10]]},"606":{"position":[[129,10]]},"811":{"position":[[824,9]]}}}],["intro",{"_index":3127,"t":{"1036":{"position":[[356,8]]}}}],["introduc",{"_index":1451,"t":{"427":{"position":[[3845,9]]}}}],["introduct",{"_index":3251,"t":{"1090":{"position":[[0,12]]}}}],["intuit",{"_index":2382,"t":{"773":{"position":[[224,9]]}}}],["invit",{"_index":2525,"t":{"823":{"position":[[305,8],[507,8]]}}}],["involv",{"_index":3085,"t":{"1026":{"position":[[231,8]]}}}],["iou",{"_index":702,"t":{"153":{"position":[[190,3]]},"1109":{"position":[[89,3]]}}}],["ip=projection(concat({im}m=1m))\\begin{equ",{"_index":1617,"t":{"465":{"position":[[437,47]]}}}],["ipi_pip",{"_index":1626,"t":{"465":{"position":[[730,8]]}}}],["ipsum",{"_index":1,"t":{"3":{"position":[[6,5],[115,5],[158,5]]},"5":{"position":[[126,5],[235,5],[278,5],[305,5],[414,5],[457,5],[484,5],[593,5],[636,5],[663,5],[772,5],[815,5],[842,5],[951,5],[994,5],[1021,5],[1130,5],[1173,5],[1200,5],[1309,5],[1352,5],[1379,5],[1488,5],[1531,5],[1558,5],[1667,5],[1710,5],[1737,5],[1846,5],[1889,5],[1916,5],[2025,5],[2068,5],[2095,5],[2204,5],[2247,5],[2274,5],[2383,5],[2426,5],[2453,5],[2562,5],[2605,5],[2632,5],[2741,5],[2784,5],[2811,5],[2920,5],[2963,5]]}}}],["ip∈r1×ci_p",{"_index":1624,"t":{"465":{"position":[[611,10]]}}}],["it",{"_index":1028,"t":{"302":{"position":[[528,5],[568,3],[663,3],[837,3],[1282,3]]}}}],["item",{"_index":1018,"t":{"302":{"position":[[196,5]]},"1026":{"position":[[111,5]]},"1036":{"position":[[413,6]]},"1067":{"position":[[167,6]]},"1079":{"position":[[167,6]]}}}],["iter",{"_index":3674,"t":{"1158":{"position":[[551,10]]}}}],["ithi^{th}ith",{"_index":2179,"t":{"686":{"position":[[939,12]]}}}],["it’",{"_index":2749,"t":{"895":{"position":[[441,4]]}}}],["i}(\\cdot)fprompt,i",{"_index":2830,"t":{"917":{"position":[[453,22]]}}}],["i}(x))p(z∣x):=k1​∑ik​p(z∣fprompt,i​(x",{"_index":2828,"t":{"917":{"position":[[390,39]]}}}],["i}1≤i≤r",{"_index":3507,"t":{"1146":{"position":[[439,11]]}}}],["i}pk,∗i",{"_index":3621,"t":{"1152":{"position":[[731,9]]}}}],["i}}(x",{"_index":2839,"t":{"917":{"position":[[1472,7]]}}}],["i}}(x)fprompt",{"_index":2844,"t":{"917":{"position":[[1602,14]]}}}],["i​(x",{"_index":2845,"t":{"917":{"position":[[1617,5]]}}}],["i​(x),z<t",{"_index":2841,"t":{"917":{"position":[[1524,11]]}}}],["i‾(t)(wij)=β1i‾(t−1)(wij)+(1−β1)i(t)(wij)u‾(t)(wij)=β2u‾(t−1)(wij)+(1−β2)∣i(t)(wij)−i‾(t)(wij)∣,\\begin{align",{"_index":3635,"t":{"1152":{"position":[[1586,109]]}}}],["i‾(t)\\overline{i}^{(t)}i(t",{"_index":3648,"t":{"1152":{"position":[[2108,27],[2240,27],[2334,27]]}}}],["i∈pidxi",{"_index":2406,"t":{"775":{"position":[[1111,7]]}}}],["i∈xidxi",{"_index":2363,"t":{"768":{"position":[[278,7]]}}}],["i∈yidxi",{"_index":2365,"t":{"768":{"position":[[351,7]]}}}],["i∈{0,1,...,c−1}category1l∑i=0lfp′(i,j)expression/annotationw",{"_index":3332,"t":{"1096":{"position":[[2016,60]]}}}],["i∈{0,1,...,c−1}l1​∑i=0l​fp′​(i,j)​categoryexpression/annot",{"_index":3338,"t":{"1096":{"position":[[2276,64]]}}}],["i∉pidxi",{"_index":2409,"t":{"775":{"position":[[1209,7]]}}}],["i∣|\\lambda_i|∣λi",{"_index":3723,"t":{"1188":{"position":[[203,20]]}}}],["j",{"_index":1077,"t":{"322":{"position":[[34,2]]},"604":{"position":[[560,2],[628,3]]},"1096":{"position":[[2206,2]]}}}],["j&f\\mathcal{j",{"_index":3391,"t":{"1113":{"position":[[142,14]]},"1121":{"position":[[172,14]]}}}],["j)^{th}(i,j)th",{"_index":1405,"t":{"427":{"position":[[1070,14]]}}}],["j\\mathcal{j}j",{"_index":3388,"t":{"1113":{"position":[[80,14],[202,13]]},"1121":{"position":[[110,14]]}}}],["jamstack",{"_index":3152,"t":{"1044":{"position":[[51,10]]}}}],["java",{"_index":1158,"t":{"360":{"position":[[92,5]]}}}],["javascript",{"_index":1160,"t":{"360":{"position":[[104,11]]},"1044":{"position":[[105,10]]}}}],["jax",{"_index":2545,"t":{"825":{"position":[[785,3]]}}}],["jft",{"_index":397,"t":{"88":{"position":[[573,3]]},"102":{"position":[[78,3]]},"112":{"position":[[27,3],[58,3],[243,3]]},"120":{"position":[[142,3]]}}}],["jitter",{"_index":675,"t":{"145":{"position":[[168,9]]}}}],["jjj",{"_index":1895,"t":{"604":{"position":[[372,3],[900,3]]},"633":{"position":[[1278,3]]},"766":{"position":[[544,3]]}}}],["joel",{"_index":3095,"t":{"1030":{"position":[[131,4]]}}}],["joinli",{"_index":1725,"t":{"535":{"position":[[148,6]]}}}],["joint",{"_index":1667,"t":{"502":{"position":[[466,5]]},"504":{"position":[[1563,5],[1701,5],[2538,5]]},"519":{"position":[[201,5]]},"521":{"position":[[0,5]]},"523":{"position":[[664,5]]},"537":{"position":[[342,5]]},"543":{"position":[[82,5]]},"1099":{"position":[[466,5],[977,5]]}}}],["jointli",{"_index":1274,"t":{"404":{"position":[[168,7]]},"412":{"position":[[208,7]]}}}],["joy",{"_index":2798,"t":{"909":{"position":[[451,6]]}}}],["jsx",{"_index":3175,"t":{"1057":{"position":[[61,6]]}}}],["judgment",{"_index":3055,"t":{"1016":{"position":[[66,8]]}}}],["k",{"_index":252,"t":{"49":{"position":[[198,1]]},"302":{"position":[[976,1],[1191,1]]},"1148":{"position":[[2270,1]]}}}],["k(t)=λk(t)−η▽λkl(p(t).e(t),q(t)),\\begin{equ",{"_index":3570,"t":{"1148":{"position":[[1317,51]]}}}],["k(t)\\lambda^{(t)}_kλk(t",{"_index":3567,"t":{"1148":{"position":[[1195,26]]}}}],["k(t)\\lambda_k^{(t)}λk(t",{"_index":3569,"t":{"1148":{"position":[[1285,26]]}}}],["k(t+1)=t(λ~k(t),sk(t)),witht(λ~k(t),sk(t))ii={λ~k,iitsk,it",{"_index":3582,"t":{"1148":{"position":[[1681,59]]}}}],["k)r≪min(d,k",{"_index":1802,"t":{"563":{"position":[[525,12]]}}}],["k+m+1",{"_index":1575,"t":{"463":{"position":[[941,8]]}}}],["k+m+1k+m+1k+m+1",{"_index":1578,"t":{"463":{"position":[[1018,15]]}}}],["k<n−lk",{"_index":1674,"t":{"504":{"position":[[1432,6]]}}}],["k=1,…,nk",{"_index":3537,"t":{"1148":{"position":[[309,8],[1138,8]]}}}],["k=10k=10k=10",{"_index":1640,"t":{"475":{"position":[[289,12]]}}}],["k=16k",{"_index":3780,"t":{"1216":{"position":[[877,5]]}}}],["k=pkλkqk\\triangle_k",{"_index":3533,"t":{"1148":{"position":[[251,20]]}}}],["k\\triangle_k△k",{"_index":3545,"t":{"1148":{"position":[[482,16]]}}}],["k][2,k",{"_index":2074,"t":{"635":{"position":[[426,7]]}}}],["k^t)}{\\sqrt{d_k",{"_index":1414,"t":{"427":{"position":[[1646,17]]}}}],["k_l",{"_index":1561,"t":{"463":{"position":[[592,3]]}}}],["k_l^t",{"_index":1573,"t":{"463":{"position":[[899,5]]}}}],["kd×k",{"_index":483,"t":{"97":{"position":[[127,4]]}}}],["kernel",{"_index":241,"t":{"40":{"position":[[116,6]]},"78":{"position":[[907,6]]}}}],["key",{"_index":708,"t":{"155":{"position":[[485,3]]},"176":{"position":[[549,3]]},"427":{"position":[[1266,4]]},"439":{"position":[[377,3]]},"463":{"position":[[424,4]]},"1140":{"position":[[701,3]]},"1200":{"position":[[713,3]]},"1205":{"position":[[368,3]]}}}],["keypoint",{"_index":583,"t":{"124":{"position":[[316,8]]},"126":{"position":[[493,8],[514,9],[933,8]]},"128":{"position":[[176,8]]},"130":{"position":[[137,8],[158,9],[1039,8],[1095,8],[1109,8],[1374,8],[1448,8]]},"140":{"position":[[712,8],[733,8]]},"143":{"position":[[200,9]]},"149":{"position":[[532,8]]},"151":{"position":[[60,8]]},"153":{"position":[[381,8]]},"155":{"position":[[458,8],[1000,8]]},"157":{"position":[[81,8],[301,8]]},"159":{"position":[[780,8]]}}}],["keyword",{"_index":2932,"t":{"963":{"position":[[1874,8]]}}}],["kkk",{"_index":485,"t":{"97":{"position":[[162,3]]},"461":{"position":[[284,3]]},"463":{"position":[[1252,3]]},"465":{"position":[[741,3],[792,3]]},"504":{"position":[[1416,3]]},"631":{"position":[[162,3],[380,3],[547,3]]},"633":{"position":[[234,3]]},"635":{"position":[[437,3],[469,3]]},"648":{"position":[[399,3]]},"653":{"position":[[22,4]]},"753":{"position":[[111,3]]},"817":{"position":[[1574,3]]},"911":{"position":[[922,3],[994,3]]},"917":{"position":[[507,3]]},"1148":{"position":[[214,3]]},"1200":{"position":[[1276,3],[1833,3]]},"1211":{"position":[[319,3]]},"1216":{"position":[[778,3]]}}}],["kl",{"_index":2027,"t":{"633":{"position":[[656,2],[916,2]]},"1001":{"position":[[1164,2],[1936,2]]}}}],["kl=lineark",{"_index":1555,"t":{"463":{"position":[[486,13]]}}}],["klk_lkl",{"_index":1570,"t":{"463":{"position":[[818,8]]}}}],["kl​=lineark",{"_index":1566,"t":{"463":{"position":[[719,15]]}}}],["knoledg",{"_index":2236,"t":{"692":{"position":[[94,8]]}}}],["knowladg",{"_index":853,"t":{"223":{"position":[[109,9]]}}}],["knowledg",{"_index":724,"t":{"163":{"position":[[249,9]]},"165":{"position":[[328,9],[390,9],[495,9],[547,9]]},"169":{"position":[[527,9]]},"171":{"position":[[169,9]]},"176":{"position":[[410,9]]},"202":{"position":[[75,9]]},"204":{"position":[[146,9]]},"213":{"position":[[114,9]]},"252":{"position":[[186,9]]},"281":{"position":[[378,9]]},"284":{"position":[[158,9]]},"382":{"position":[[18,9]]},"386":{"position":[[298,9],[343,9]]},"455":{"position":[[449,9]]},"457":{"position":[[938,9]]},"461":{"position":[[887,9]]},"463":{"position":[[2031,9],[2562,9]]},"498":{"position":[[188,9]]},"502":{"position":[[392,9]]},"504":{"position":[[302,9],[1266,9],[1920,9]]},"508":{"position":[[242,9]]},"515":{"position":[[91,9]]},"533":{"position":[[171,9]]},"614":{"position":[[232,9],[359,9]]},"616":{"position":[[1102,9]]},"619":{"position":[[794,9]]},"623":{"position":[[0,9],[319,9]]},"625":{"position":[[553,9],[616,9]]},"627":{"position":[[1294,9]]},"629":{"position":[[271,9]]},"631":{"position":[[55,9],[135,9],[955,9]]},"633":{"position":[[184,9],[531,9]]},"635":{"position":[[244,9]]},"655":{"position":[[270,9]]},"659":{"position":[[40,9],[117,9]]},"662":{"position":[[347,9],[548,9]]},"674":{"position":[[92,9]]},"678":{"position":[[177,9]]},"680":{"position":[[1228,9],[1758,9]]},"690":{"position":[[15,9]]},"692":{"position":[[0,9]]},"694":{"position":[[987,9]]},"696":{"position":[[240,9],[933,9],[1094,9]]},"836":{"position":[[1564,9]]},"850":{"position":[[1621,9]]},"895":{"position":[[81,9]]},"899":{"position":[[1034,9]]},"917":{"position":[[1052,9],[1103,9]]},"935":{"position":[[237,9]]},"963":{"position":[[633,9],[2858,9]]},"975":{"position":[[86,9],[162,9]]},"1087":{"position":[[949,9]]},"1200":{"position":[[315,9]]},"1220":{"position":[[113,9]]},"1222":{"position":[[1348,9]]}}}],["k{−1,1}k",{"_index":537,"t":{"108":{"position":[[71,11]]}}}],["k}a∈rr×k",{"_index":1798,"t":{"563":{"position":[[479,8]]}}}],["k}w0​∈rd×k",{"_index":1790,"t":{"563":{"position":[[299,10]]}}}],["k′=20k",{"_index":1058,"t":{"311":{"position":[[215,7]]}}}],["l",{"_index":321,"t":{"60":{"position":[[27,1],[35,1]]},"65":{"position":[[42,1]]},"91":{"position":[[2106,1],[2396,1]]},"197":{"position":[[371,1]]},"427":{"position":[[2874,2]]},"583":{"position":[[202,1]]},"637":{"position":[[223,2],[397,2]]},"780":{"position":[[261,1]]},"1222":{"position":[[409,2]]}}}],["l(2dk+2dv+2dff)l(2d_k",{"_index":1428,"t":{"427":{"position":[[2113,21]]}}}],["l(dk+dv+dff)l(d_k",{"_index":1425,"t":{"427":{"position":[[2020,17]]}}}],["l(m(x,i",{"_index":2211,"t":{"686":{"position":[[2105,11]]}}}],["l(m(x,y))\\begin{equ",{"_index":2205,"t":{"686":{"position":[[1956,25]]}}}],["l(p,e,q)=c(p,e,q)+γ∑k=1nr(pk,qk)\\mathcal{l}(\\mathcal{p",{"_index":3557,"t":{"1148":{"position":[[867,56]]}}}],["l)(l≤l",{"_index":1532,"t":{"461":{"position":[[413,7],[549,7]]}}}],["l/14",{"_index":799,"t":{"183":{"position":[[286,4]]},"1218":{"position":[[118,4]]},"1230":{"position":[[226,4]]}}}],["l/16",{"_index":183,"t":{"25":{"position":[[737,4]]},"104":{"position":[[108,4]]},"106":{"position":[[180,5]]},"110":{"position":[[15,4]]},"114":{"position":[[180,4],[269,4],[305,4]]}}}],["l/17",{"_index":560,"t":{"114":{"position":[[208,5]]}}}],["l/32",{"_index":558,"t":{"114":{"position":[[174,5],[263,5]]},"116":{"position":[[298,4],[386,4]]}}}],["l2",{"_index":1122,"t":{"343":{"position":[[489,2]]}}}],["l=100l",{"_index":2126,"t":{"666":{"position":[[9,6]]}}}],["l=16l",{"_index":3816,"t":{"1234":{"position":[[79,5]]}}}],["l=300l",{"_index":2128,"t":{"666":{"position":[[79,6]]}}}],["l=30l=30l=30",{"_index":1641,"t":{"475":{"position":[[327,12]]},"523":{"position":[[467,13]]}}}],["l=−∑t=1t",{"_index":779,"t":{"180":{"position":[[142,8]]}}}],["l\\mathcal{l}l",{"_index":2203,"t":{"686":{"position":[[1843,13]]}}}],["l^adpt\\hat{l}_{adpt}l^adpt",{"_index":1855,"t":{"585":{"position":[[664,27]]}}}],["l^adpt×(2×dmodel×r+r+dmodel)+2×l^ln×dmodel|\\theta",{"_index":1851,"t":{"585":{"position":[[442,54]]}}}],["l^ln\\hat{l}_{ln}l^ln",{"_index":1856,"t":{"585":{"position":[[710,21]]}}}],["l^lora\\hat{l}_{lora}l^lora",{"_index":1860,"t":{"587":{"position":[[251,27]]}}}],["l_i)∣θ∣=dmodel​×(lp​+li",{"_index":1841,"t":{"581":{"position":[[181,25]]}}}],["l_i)∣θ∣=l×dmodel​×+(lp​+li",{"_index":1845,"t":{"583":{"position":[[237,28]]}}}],["l_p",{"_index":1840,"t":{"581":{"position":[[174,4]]},"583":{"position":[[230,4]]}}}],["l_v",{"_index":1416,"t":{"427":{"position":[[1673,4]]}}}],["l_{\\textup{box",{"_index":3349,"t":{"1099":{"position":[[345,16],[882,16],[1505,16]]}}}],["l_{\\textup{emb",{"_index":3371,"t":{"1099":{"position":[[1544,18]]}}}],["l_{\\textup{mask",{"_index":3357,"t":{"1099":{"position":[[901,17],[1524,17]]}}}],["l_{\\textup{mask}}^{\\textup{boxinst",{"_index":3350,"t":{"1099":{"position":[[364,36]]}}}],["l_{\\textup{retriev",{"_index":3348,"t":{"1099":{"position":[[321,21],[858,21],[1481,21]]}}}],["l_{\\text{ln",{"_index":1377,"t":{"425":{"position":[[2042,13]]}}}],["l_{\\text{ul",{"_index":1354,"t":{"425":{"position":[[530,13]]}}}],["l_{l=1}{pl​}l=1l",{"_index":1525,"t":{"461":{"position":[[179,20]]}}}],["labal",{"_index":3776,"t":{"1216":{"position":[[406,7]]}}}],["label",{"_index":317,"t":{"58":{"position":[[193,6]]},"112":{"position":[[220,5]]},"126":{"position":[[430,5]]},"130":{"position":[[74,5],[1383,5]]},"143":{"position":[[637,5]]},"165":{"position":[[653,6]]},"169":{"position":[[92,5],[98,6],[679,6]]},"171":{"position":[[320,7],[341,7],[354,7],[484,6]]},"174":{"position":[[11,6],[203,6]]},"197":{"position":[[408,5]]},"204":{"position":[[54,6]]},"219":{"position":[[93,5]]},"223":{"position":[[74,6]]},"418":{"position":[[110,7],[1097,6],[1644,5]]},"421":{"position":[[202,7],[416,7]]},"423":{"position":[[8,7],[626,7],[1104,5],[1376,5]]},"447":{"position":[[185,5]]},"616":{"position":[[1575,5]]},"711":{"position":[[269,8]]},"713":{"position":[[565,5],[964,8]]},"716":{"position":[[48,5],[108,8]]},"725":{"position":[[146,5]]},"732":{"position":[[171,8]]},"736":{"position":[[82,8]]},"740":{"position":[[127,8]]},"744":{"position":[[89,9]]},"751":{"position":[[202,5]]},"793":{"position":[[186,5]]},"815":{"position":[[186,7]]},"817":{"position":[[1649,7]]},"819":{"position":[[228,5],[311,5]]},"825":{"position":[[203,6]]},"832":{"position":[[319,5],[452,5],[554,5],[765,5],[796,5]]},"834":{"position":[[814,5]]},"842":{"position":[[1171,6],[1200,5],[1249,5],[1269,5],[1380,5]]},"874":{"position":[[412,7]]},"879":{"position":[[119,6],[279,5],[307,5],[384,5],[454,5]]},"911":{"position":[[630,5],[756,5],[1230,5],[1246,5]]},"913":{"position":[[76,5]]},"949":{"position":[[214,5],[671,5]]},"977":{"position":[[139,6]]},"983":{"position":[[299,5],[382,5]]},"1036":{"position":[[103,5],[394,6]]},"1061":{"position":[[329,5]]},"1085":{"position":[[418,5]]},"1087":{"position":[[1071,5]]},"1096":{"position":[[2644,5]]},"1170":{"position":[[107,8]]},"1200":{"position":[[990,5],[1015,5],[1367,5],[1411,5],[1447,5],[1591,5],[1798,8]]},"1205":{"position":[[442,7]]},"1207":{"position":[[90,5],[104,7],[436,5]]},"1209":{"position":[[158,5]]},"1211":{"position":[[39,5],[180,5],[226,5],[476,5]]},"1216":{"position":[[543,5],[661,5]]},"1218":{"position":[[201,5],[234,5],[484,5],[593,7]]},"1220":{"position":[[236,7]]},"1222":{"position":[[37,7],[663,7],[1227,5]]},"1230":{"position":[[125,5],[303,5]]},"1232":{"position":[[83,5],[178,5]]},"1240":{"position":[[238,8]]}}}],["labeld",{"_index":711,"t":{"155":{"position":[[566,6]]},"1207":{"position":[[126,6]]}}}],["ladder",{"_index":1945,"t":{"619":{"position":[[353,6]]}}}],["lama",{"_index":2139,"t":{"678":{"position":[[195,6]]},"680":{"position":[[1223,4],[1753,4]]},"686":{"position":[[693,5]]},"690":{"position":[[10,4]]},"692":{"position":[[79,4]]},"694":{"position":[[10,4],[105,4],[130,4],[228,4],[285,4],[537,4],[764,4]]},"696":{"position":[[32,4],[66,4],[561,4],[778,4]]},"895":{"position":[[65,4]]},"933":{"position":[[236,4]]},"943":{"position":[[198,4]]}}}],["lambda",{"_index":279,"t":{"49":{"position":[[850,9]]},"633":{"position":[[2071,7],[2314,9]]},"1137":{"position":[[3999,7],[4050,9]]},"1146":{"position":[[171,7],[451,7],[695,9],[755,9],[1149,9]]}}}],["lambda)x_ix~i​=λxj​+(1−λ)xi",{"_index":275,"t":{"49":{"position":[[726,29]]}}}],["lambda)y_iy~​i​=λyj​+(1−λ)yi",{"_index":278,"t":{"49":{"position":[[807,30]]}}}],["lambda_k",{"_index":3535,"t":{"1148":{"position":[[278,9],[651,9]]}}}],["lambda_k^{(t",{"_index":3572,"t":{"1148":{"position":[[1395,15]]}}}],["lambda_k^{(t+1",{"_index":3585,"t":{"1148":{"position":[[1794,17]]}}}],["lambda_{i",{"_index":3516,"t":{"1146":{"position":[[645,12]]}}}],["lambda_{k,i",{"_index":3542,"t":{"1148":{"position":[[426,14]]}}}],["lambda_{k,i}sk,i​=λk,i",{"_index":3605,"t":{"1150":{"position":[[71,24]]}}}],["lambda{x}_j",{"_index":274,"t":{"49":{"position":[[708,12]]}}}],["lambda{y}_j",{"_index":277,"t":{"49":{"position":[[789,12]]}}}],["lamda",{"_index":895,"t":{"242":{"position":[[42,5],[140,5]]},"244":{"position":[[418,5]]},"254":{"position":[[226,5]]}}}],["langaug",{"_index":3731,"t":{"1198":{"position":[[21,8]]}}}],["languag",{"_index":589,"t":{"126":{"position":[[219,8]]},"130":{"position":[[195,8]]},"163":{"position":[[10,8],[97,8],[278,8]]},"165":{"position":[[81,8],[522,8]]},"169":{"position":[[224,8],[397,8],[722,8],[750,8],[778,8]]},"171":{"position":[[70,8]]},"176":{"position":[[198,8]]},"178":{"position":[[52,8],[399,8],[466,8],[486,8]]},"180":{"position":[[280,8],[462,8]]},"183":{"position":[[109,8]]},"279":{"position":[[6,8]]},"281":{"position":[[25,8],[505,8],[538,8],[617,8],[1399,8],[1723,8],[1958,8],[1992,8]]},"286":{"position":[[410,8]]},"288":{"position":[[66,8],[179,8]]},"292":{"position":[[359,8]]},"300":{"position":[[843,8]]},"302":{"position":[[1432,8]]},"313":{"position":[[245,8]]},"368":{"position":[[334,8]]},"373":{"position":[[11,8]]},"375":{"position":[[152,8]]},"382":{"position":[[246,8],[280,9]]},"396":{"position":[[443,8]]},"398":{"position":[[870,8]]},"416":{"position":[[48,8]]},"418":{"position":[[384,9],[438,8]]},"423":{"position":[[176,8],[818,8]]},"431":{"position":[[199,8]]},"457":{"position":[[1187,8]]},"461":{"position":[[467,8]]},"465":{"position":[[1130,8]]},"467":{"position":[[92,8]]},"471":{"position":[[203,8]]},"484":{"position":[[30,8]]},"502":{"position":[[924,8]]},"504":{"position":[[353,8],[735,8],[1041,8],[1189,8],[2198,8],[2267,8]]},"510":{"position":[[170,8]]},"519":{"position":[[33,8],[156,8],[465,8]]},"521":{"position":[[257,8]]},"523":{"position":[[9,8]]},"533":{"position":[[244,8]]},"535":{"position":[[19,8],[65,8],[115,8]]},"537":{"position":[[382,8]]},"539":{"position":[[117,8],[318,8]]},"547":{"position":[[413,8]]},"557":{"position":[[150,8]]},"573":{"position":[[52,8]]},"614":{"position":[[92,8]]},"616":{"position":[[22,8]]},"619":{"position":[[567,8]]},"678":{"position":[[41,8]]},"680":{"position":[[122,8],[177,8],[205,8],[256,8],[284,8],[332,8],[458,8]]},"694":{"position":[[646,8],[743,8]]},"698":{"position":[[908,8],[1016,8],[1918,8]]},"711":{"position":[[16,8],[133,8]]},"713":{"position":[[376,8]]},"718":{"position":[[495,8]]},"738":{"position":[[100,8]]},"759":{"position":[[37,8],[96,8],[181,8]]},"761":{"position":[[37,8],[733,8]]},"766":{"position":[[61,8]]},"773":{"position":[[477,8]]},"815":{"position":[[53,8]]},"817":{"position":[[262,8],[357,9]]},"821":{"position":[[397,8]]},"823":{"position":[[709,8]]},"836":{"position":[[2359,8]]},"842":{"position":[[40,8]]},"844":{"position":[[268,8]]},"848":{"position":[[131,8],[232,8],[423,9],[530,8]]},"876":{"position":[[408,8]]},"883":{"position":[[696,8]]},"895":{"position":[[133,8],[360,8],[418,8],[480,8]]},"901":{"position":[[1277,8]]},"969":{"position":[[600,8]]},"975":{"position":[[872,8]]},"985":{"position":[[100,8]]},"987":{"position":[[6,8]]},"989":{"position":[[10,8],[184,8]]},"997":{"position":[[180,8]]},"1001":{"position":[[15,8]]},"1079":{"position":[[30,10]]},"1085":{"position":[[132,8],[659,8]]},"1087":{"position":[[537,8],[1495,8]]},"1092":{"position":[[137,8]]},"1094":{"position":[[710,8]]},"1135":{"position":[[18,8],[769,8],[819,8]]},"1163":{"position":[[166,8]]},"1198":{"position":[[305,8]]},"1203":{"position":[[148,8]]}}}],["larg",{"_index":344,"t":{"78":{"position":[[38,5]]},"104":{"position":[[16,6],[135,7]]},"110":{"position":[[47,5]]},"183":{"position":[[204,6],[274,5]]},"279":{"position":[[0,5]]},"300":{"position":[[146,5]]},"423":{"position":[[154,5]]},"447":{"position":[[241,5]]},"467":{"position":[[108,5]]},"555":{"position":[[78,5]]},"571":{"position":[[28,5]]},"589":{"position":[[102,5]]},"593":{"position":[[63,5]]},"614":{"position":[[86,5]]},"644":{"position":[[241,5]]},"655":{"position":[[107,5]]},"680":{"position":[[535,5]]},"698":{"position":[[1784,5]]},"700":{"position":[[23,5],[331,5]]},"742":{"position":[[12,6],[27,6]]},"759":{"position":[[19,5]]},"761":{"position":[[19,5]]},"777":{"position":[[103,5]]},"784":{"position":[[40,5],[79,5]]},"787":{"position":[[686,5]]},"827":{"position":[[698,5]]},"834":{"position":[[749,5]]},"836":{"position":[[2230,5]]},"899":{"position":[[107,5]]},"989":{"position":[[4,5]]},"1104":{"position":[[38,5]]},"1111":{"position":[[5,5]]},"1135":{"position":[[0,5]]},"1137":{"position":[[520,5],[3866,5],[4498,5]]},"1156":{"position":[[37,5]]},"1177":{"position":[[46,5]]}}}],["larger",{"_index":2271,"t":{"698":{"position":[[1490,6]]},"746":{"position":[[188,6]]},"838":{"position":[[593,6]]},"919":{"position":[[957,6]]},"963":{"position":[[665,6],[827,6]]},"1146":{"position":[[1961,6]]}}}],["lasot",{"_index":3361,"t":{"1099":{"position":[[1241,6]]},"1111":{"position":[[23,6],[30,5]]}}}],["last",{"_index":365,"t":{"78":{"position":[[890,4]]},"269":{"position":[[141,4]]},"345":{"position":[[579,4]]},"463":{"position":[[114,4]]},"475":{"position":[[322,4]]},"504":{"position":[[1320,4]]},"523":{"position":[[445,4]]},"531":{"position":[[76,4]]},"766":{"position":[[798,4]]},"823":{"position":[[331,4],[540,4]]}}}],["late",{"_index":1707,"t":{"519":{"position":[[493,4]]},"823":{"position":[[1789,4]]}}}],["latenc",{"_index":1468,"t":{"437":{"position":[[559,8]]},"547":{"position":[[402,7]]},"549":{"position":[[1244,7]]},"555":{"position":[[93,7]]},"557":{"position":[[278,7],[440,7]]},"567":{"position":[[95,7]]},"610":{"position":[[69,7]]}}}],["latent",{"_index":421,"t":{"91":{"position":[[464,6],[599,6],[616,6]]},"176":{"position":[[356,6],[438,6],[524,6]]}}}],["later",{"_index":350,"t":{"78":{"position":[[163,5]]}}}],["layer",{"_index":168,"t":{"25":{"position":[[179,5]]},"78":{"position":[[139,6]]},"86":{"position":[[661,5],[674,5]]},"91":{"position":[[1082,5],[1117,5],[1384,5],[2136,5]]},"97":{"position":[[146,5]]},"104":{"position":[[497,5]]},"116":{"position":[[741,5],[821,5]]},"174":{"position":[[46,5],[89,6],[163,5],[458,5]]},"178":{"position":[[82,5]]},"209":{"position":[[145,5]]},"288":{"position":[[304,5]]},"311":{"position":[[167,5]]},"330":{"position":[[1335,5],[1460,5]]},"343":{"position":[[383,5],[476,5]]},"345":{"position":[[220,5],[250,5],[314,5],[777,5]]},"349":{"position":[[491,5],[542,5],[595,5],[619,5],[678,5],[832,5]]},"355":{"position":[[130,6]]},"427":{"position":[[1906,5],[1986,5],[2090,5],[3247,5],[3693,5]]},"437":{"position":[[374,5]]},"455":{"position":[[311,5]]},"457":{"position":[[375,5],[491,5]]},"461":{"position":[[34,5],[218,5],[292,5],[394,5],[530,5],[929,6]]},"463":{"position":[[135,6],[223,5],[2224,5],[2259,5]]},"465":{"position":[[780,5],[840,5]]},"469":{"position":[[39,5],[99,5]]},"475":{"position":[[243,5],[340,5]]},"487":{"position":[[12,5],[31,5]]},"502":{"position":[[351,5]]},"504":{"position":[[1020,5],[1329,5],[1420,5],[1486,6],[1776,6],[1814,5]]},"508":{"position":[[136,5],[164,5]]},"510":{"position":[[138,5],[239,5]]},"512":{"position":[[80,5]]},"515":{"position":[[351,6],[394,5],[460,5],[568,5]]},"519":{"position":[[417,5]]},"523":{"position":[[229,5],[256,5],[365,5],[454,6],[527,5]]},"531":{"position":[[15,6],[84,6],[153,5],[178,7],[193,5]]},"547":{"position":[[126,5]]},"549":{"position":[[602,5],[667,5]]},"551":{"position":[[55,5]]},"555":{"position":[[30,5],[47,5]]},"557":{"position":[[112,5],[227,5],[250,5],[301,5],[329,5],[482,5]]},"563":{"position":[[19,6]]},"577":{"position":[[24,5]]},"583":{"position":[[67,5],[96,5],[284,6]]},"585":{"position":[[49,5],[66,5],[92,5],[188,5],[374,5],[702,5]]},"595":{"position":[[153,5]]},"600":{"position":[[216,5]]},"619":{"position":[[27,6]]},"686":{"position":[[175,5]]},"688":{"position":[[592,5]]},"713":{"position":[[1246,5],[1278,5]]},"718":{"position":[[75,5]]},"727":{"position":[[310,6],[489,6]]},"748":{"position":[[267,5]]},"753":{"position":[[56,5],[115,6],[166,5],[190,5],[253,5],[309,6],[347,5]]},"761":{"position":[[453,6],[489,6]]},"766":{"position":[[491,6],[551,5],[803,5]]},"773":{"position":[[817,6],[985,6]]},"782":{"position":[[98,6]]},"798":{"position":[[122,6],[190,5],[310,5]]},"809":{"position":[[280,5]]},"811":{"position":[[410,5],[577,5]]},"817":{"position":[[87,5],[1289,5],[1993,5],[2032,7]]},"825":{"position":[[296,5]]},"836":{"position":[[288,5],[343,5],[547,5],[992,5],[1055,5],[1676,5],[2126,6],[2167,5]]},"1001":{"position":[[495,5]]},"1094":{"position":[[726,5],[747,5]]},"1104":{"position":[[214,5],[232,5]]},"1137":{"position":[[674,5],[2495,6],[2596,6],[2742,6],[2776,6]]},"1140":{"position":[[1109,5]]},"1148":{"position":[[41,5]]},"1160":{"position":[[305,5],[548,5]]},"1179":{"position":[[77,5]]},"1192":{"position":[[111,6],[196,6]]},"1207":{"position":[[537,5]]}}}],["layernorm",{"_index":437,"t":{"91":{"position":[[1395,9]]},"557":{"position":[[240,9]]},"585":{"position":[[211,9],[744,10]]},"1160":{"position":[[486,9]]}}}],["layout",{"_index":3080,"t":{"1026":{"position":[[158,6]]},"1040":{"position":[[106,6],[184,8],[244,9]]}}}],["leanabl",{"_index":1683,"t":{"508":{"position":[[177,8]]}}}],["learn",{"_index":153,"t":{"23":{"position":[[161,8]]},"25":{"position":[[478,8],[565,8]]},"27":{"position":[[311,8]]},"44":{"position":[[19,8]]},"47":{"position":[[416,8]]},"49":{"position":[[31,8]]},"53":{"position":[[360,8]]},"72":{"position":[[12,8]]},"76":{"position":[[60,8],[89,8]]},"78":{"position":[[424,9]]},"86":{"position":[[499,8]]},"102":{"position":[[142,8]]},"104":{"position":[[346,8]]},"112":{"position":[[460,8],[522,8]]},"118":{"position":[[178,8]]},"163":{"position":[[381,8]]},"176":{"position":[[516,7]]},"206":{"position":[[226,8]]},"229":{"position":[[398,8]]},"273":{"position":[[121,8]]},"288":{"position":[[158,8]]},"294":{"position":[[24,8]]},"300":{"position":[[780,8]]},"328":{"position":[[512,9]]},"330":{"position":[[1101,8]]},"341":{"position":[[238,9]]},"347":{"position":[[525,8]]},"379":{"position":[[69,8]]},"416":{"position":[[20,8],[485,7]]},"418":{"position":[[520,8],[2080,7],[2294,8]]},"427":{"position":[[468,7],[730,7],[865,7],[1170,7],[2506,7]]},"431":{"position":[[379,8],[765,8]]},"435":{"position":[[76,8],[392,8]]},"437":{"position":[[58,8]]},"447":{"position":[[9,8]]},"451":{"position":[[29,8],[163,7],[705,8]]},"475":{"position":[[168,8]]},"504":{"position":[[1742,8]]},"549":{"position":[[349,7]]},"557":{"position":[[62,8],[198,10]]},"616":{"position":[[350,8],[1597,8]]},"621":{"position":[[10,8],[163,8],[261,8]]},"623":{"position":[[80,9],[284,8]]},"625":{"position":[[730,8]]},"627":{"position":[[1357,8]]},"635":{"position":[[865,8],[1046,8]]},"653":{"position":[[166,8]]},"674":{"position":[[408,8]]},"678":{"position":[[311,8]]},"694":{"position":[[1054,8]]},"698":{"position":[[1212,8],[1375,8],[1595,8],[1816,8]]},"702":{"position":[[89,8],[274,8],[653,9]]},"734":{"position":[[11,8]]},"748":{"position":[[338,8]]},"751":{"position":[[75,8]]},"761":{"position":[[659,8],[695,8],[891,8],[1469,7]]},"784":{"position":[[187,8],[251,8],[338,8]]},"815":{"position":[[248,7],[283,8]]},"817":{"position":[[2418,7]]},"823":{"position":[[604,8]]},"825":{"position":[[718,8]]},"827":{"position":[[63,9]]},"832":{"position":[[810,7]]},"836":{"position":[[19,8],[1785,8]]},"842":{"position":[[203,7],[424,7],[1771,7]]},"844":{"position":[[319,8]]},"848":{"position":[[71,8]]},"850":{"position":[[1162,8]]},"874":{"position":[[30,8],[61,8],[143,8],[441,8]]},"876":{"position":[[17,8]]},"879":{"position":[[20,8]]},"881":{"position":[[11,8],[63,8]]},"895":{"position":[[583,8]]},"901":{"position":[[1017,8],[1305,8]]},"915":{"position":[[13,8],[38,8]]},"919":{"position":[[36,8],[972,8]]},"927":{"position":[[10,8],[142,8],[176,8],[213,8],[412,8]]},"929":{"position":[[26,8]]},"933":{"position":[[139,8],[397,8]]},"943":{"position":[[355,8],[395,8]]},"945":{"position":[[186,8]]},"949":{"position":[[615,8]]},"955":{"position":[[218,8]]},"957":{"position":[[29,8]]},"961":{"position":[[19,8],[208,8]]},"963":{"position":[[13,8],[32,8],[70,8],[305,8],[380,8],[436,8],[498,8],[680,8],[842,8],[1025,8],[1247,8],[1353,8],[2226,8],[2511,8],[2649,8],[2923,8]]},"965":{"position":[[13,8]]},"967":{"position":[[27,8],[105,8]]},"969":{"position":[[58,8]]},"971":{"position":[[395,8]]},"975":{"position":[[276,8],[923,8],[1078,8]]},"977":{"position":[[28,8]]},"979":{"position":[[79,8]]},"981":{"position":[[168,8]]},"993":{"position":[[104,8]]},"1001":{"position":[[176,8],[259,8],[1110,8],[1350,8]]},"1024":{"position":[[14,7]]},"1137":{"position":[[1378,8]]},"1142":{"position":[[830,9]]},"1148":{"position":[[1587,8]]},"1158":{"position":[[262,8]]},"1165":{"position":[[603,8]]},"1172":{"position":[[427,8]]},"1198":{"position":[[45,8],[73,8],[273,8],[473,8],[509,8],[527,8]]},"1200":{"position":[[1753,8],[1771,8]]},"1203":{"position":[[52,8],[507,8]]},"1205":{"position":[[137,8]]},"1207":{"position":[[36,8]]},"1216":{"position":[[128,8]]},"1220":{"position":[[21,8]]},"1236":{"position":[[26,8]]},"1242":{"position":[[25,8]]}}}],["learnabl",{"_index":846,"t":{"209":{"position":[[171,9]]},"211":{"position":[[80,9],[100,9]]},"455":{"position":[[180,9],[257,9]]},"457":{"position":[[383,9],[558,9]]},"461":{"position":[[130,9],[674,9]]},"463":{"position":[[1293,9],[1466,9]]},"465":{"position":[[405,9]]},"471":{"position":[[184,9]]},"479":{"position":[[39,9]]},"482":{"position":[[94,9]]},"502":{"position":[[216,9],[495,9]]},"504":{"position":[[1836,9]]},"510":{"position":[[117,9]]},"515":{"position":[[405,9]]},"523":{"position":[[201,9]]},"533":{"position":[[214,9]]},"627":{"position":[[422,9],[673,9]]},"836":{"position":[[127,9],[1038,9],[1277,9],[1685,9],[1796,9]]},"901":{"position":[[1944,9]]},"955":{"position":[[437,9],[542,9]]},"963":{"position":[[2082,9]]},"1200":{"position":[[1024,9]]},"1211":{"position":[[386,9]]},"1222":{"position":[[86,9],[1373,9]]}}}],["learner",{"_index":1206,"t":{"373":{"position":[[41,9]]},"418":{"position":[[428,9],[467,9]]},"698":{"position":[[942,9],[1050,9],[1952,10]]},"817":{"position":[[387,9]]},"823":{"position":[[1765,7]]},"895":{"position":[[162,8],[514,8]]}}}],["leetcod",{"_index":2639,"t":{"850":{"position":[[2185,8]]}}}],["leetcodehardgym",{"_index":2638,"t":{"850":{"position":[[2133,15]]}}}],["left",{"_index":1620,"t":{"465":{"position":[[509,6]]},"766":{"position":[[611,4]]},"768":{"position":[[194,4]]},"775":{"position":[[1282,4]]},"893":{"position":[[133,4]]},"1092":{"position":[[2040,5]]},"1096":{"position":[[2079,5]]},"1146":{"position":[[959,5],[1004,5]]},"1152":{"position":[[1050,5],[1876,5]]}}}],["left/right",{"_index":1918,"t":{"608":{"position":[[170,10]]},"1137":{"position":[[4136,10]]},"1146":{"position":[[329,10]]}}}],["left\\{\\begin{matrix",{"_index":2397,"t":{"775":{"position":[[682,21]]},"1148":{"position":[[1931,21]]}}}],["legal",{"_index":2519,"t":{"821":{"position":[[616,5]]},"834":{"position":[[802,5]]}}}],["length",{"_index":486,"t":{"97":{"position":[[291,6]]},"104":{"position":[[155,6],[443,6],[527,6]]},"398":{"position":[[405,6]]},"418":{"position":[[2013,6]]},"425":{"position":[[1395,6],[1426,6],[1547,6],[1588,6],[1675,6],[1932,6]]},"427":{"position":[[990,6]]},"431":{"position":[[309,6]]},"437":{"position":[[900,6],[1019,6]]},"441":{"position":[[91,6]]},"449":{"position":[[197,6]]},"451":{"position":[[352,6]]},"461":{"position":[[310,6],[616,6]]},"465":{"position":[[796,6]]},"475":{"position":[[282,6]]},"531":{"position":[[128,6]]},"589":{"position":[[153,6]]},"610":{"position":[[92,6]]},"727":{"position":[[138,6]]},"732":{"position":[[7,6],[74,6]]},"775":{"position":[[358,6]]},"784":{"position":[[274,6],[362,6],[803,6]]},"819":{"position":[[1733,6]]},"821":{"position":[[677,6],[768,6]]},"823":{"position":[[1876,6]]},"825":{"position":[[234,6]]},"830":{"position":[[69,6],[149,6]]},"832":{"position":[[511,7]]},"909":{"position":[[159,6]]},"963":{"position":[[1766,6]]},"1179":{"position":[[150,6]]},"1234":{"position":[[72,6]]}}}],["leq",{"_index":1531,"t":{"461":{"position":[[408,4],[544,4]]},"604":{"position":[[243,4],[250,4],[344,4],[351,4]]},"686":{"position":[[1666,4],[1673,4],[1898,4],[1905,4]]},"1146":{"position":[[468,4],[475,4]]},"1148":{"position":[[2265,4],[2272,4],[2282,4],[2289,4]]},"1222":{"position":[[325,4],[332,4]]}}}],["less",{"_index":79,"t":{"11":{"position":[[29,4]]},"418":{"position":[[105,4],[2330,4]]},"1137":{"position":[[2882,4],[3554,4]]},"1148":{"position":[[2422,4]]}}}],["lester",{"_index":2296,"t":{"718":{"position":[[429,7]]},"721":{"position":[[16,7]]},"723":{"position":[[16,7]]},"725":{"position":[[16,7],[252,7]]},"727":{"position":[[16,7]]},"738":{"position":[[153,7]]},"746":{"position":[[74,7],[246,7],[313,7]]},"748":{"position":[[113,7],[160,7]]},"753":{"position":[[16,7]]}}}],["let'",{"_index":77,"t":{"11":{"position":[[0,5]]},"388":{"position":[[196,6]]},"394":{"position":[[166,6]]},"398":{"position":[[201,6]]},"1053":{"position":[[78,5],[128,5],[190,5]]},"1071":{"position":[[0,5]]}}}],["letter",{"_index":932,"t":{"269":{"position":[[146,6]]}}}],["level",{"_index":732,"t":{"165":{"position":[[565,5],[606,5]]},"171":{"position":[[242,5],[291,5],[674,5]]},"174":{"position":[[188,5]]},"360":{"position":[[622,5]]},"377":{"position":[[199,5]]},"461":{"position":[[446,5]]},"963":{"position":[[2543,5]]},"1085":{"position":[[473,5],[598,5],[737,5],[786,5]]},"1087":{"position":[[2515,5],[2691,5]]},"1092":{"position":[[1349,5]]},"1099":{"position":[[460,5],[971,5],[1046,5],[1120,5],[1164,5]]},"1137":{"position":[[1341,5]]},"1165":{"position":[[49,6]]},"1167":{"position":[[90,5]]},"1174":{"position":[[134,5]]},"1181":{"position":[[125,6]]},"1184":{"position":[[20,6],[137,5],[277,6]]},"1186":{"position":[[269,6]]},"1192":{"position":[[386,7]]}}}],["lffl_{ff}lff",{"_index":1424,"t":{"427":{"position":[[1946,13],[2261,13]]}}}],["lff⊙γ(w1x))w2(l_{ff",{"_index":1418,"t":{"427":{"position":[[1776,21]]}}}],["lhidden=∑k∈s∣∑(xi,yi)∈sk",{"_index":2051,"t":{"633":{"position":[[1378,24]]}}}],["li",{"_index":1147,"t":{"349":{"position":[[185,3],[309,3]]},"817":{"position":[[1207,2],[1885,2]]}}}],["liang",{"_index":2476,"t":{"817":{"position":[[1214,6],[1892,6]]}}}],["light",{"_index":2466,"t":{"811":{"position":[[1203,5]]}}}],["lightweight",{"_index":771,"t":{"178":{"position":[[90,11],[119,11]]},"761":{"position":[[304,11],[947,11]]},"787":{"position":[[95,11]]},"838":{"position":[[1009,11]]},"844":{"position":[[330,11]]}}}],["lignuist",{"_index":2878,"t":{"943":{"position":[[622,10]]}}}],["likelihood",{"_index":628,"t":{"132":{"position":[[731,10]]},"140":{"position":[[33,10]]},"180":{"position":[[347,12]]},"190":{"position":[[237,10]]},"197":{"position":[[131,10]]},"770":{"position":[[111,10]]},"819":{"position":[[537,10],[1345,10]]},"832":{"position":[[297,10]]},"901":{"position":[[698,10]]},"911":{"position":[[737,10]]},"989":{"position":[[991,10],[1181,10]]}}}],["lil_ili",{"_index":1843,"t":{"581":{"position":[[225,8]]}}}],["limit",{"_index":27,"t":{"5":{"position":[[81,5]]},"328":{"position":[[242,7]]},"421":{"position":[[194,7],[408,7]]},"423":{"position":[[0,7]]},"823":{"position":[[585,6]]}}}],["line",{"_index":138,"t":{"19":{"position":[[408,6]]},"355":{"position":[[225,4]]}}}],["linear",{"_index":262,"t":{"49":{"position":[[375,6]]},"91":{"position":[[510,6],[1110,6],[1477,9]]},"108":{"position":[[196,6]]},"112":{"position":[[363,6]]},"116":{"position":[[319,6]]},"178":{"position":[[163,9]]},"343":{"position":[[469,6],[773,6]]},"345":{"position":[[770,6]]},"431":{"position":[[407,6]]},"463":{"position":[[448,6],[2241,6]]},"504":{"position":[[1769,6]]},"515":{"position":[[387,6],[453,6],[561,6]]},"531":{"position":[[186,6]]},"744":{"position":[[114,6]]},"751":{"position":[[134,6],[210,6]]},"761":{"position":[[996,10]]},"764":{"position":[[129,10]]},"784":{"position":[[180,6]]},"789":{"position":[[289,10]]},"1140":{"position":[[799,6]]}}}],["linearli",{"_index":2269,"t":{"698":{"position":[[1195,8]]},"1192":{"position":[[457,8]]}}}],["linguist",{"_index":2872,"t":{"943":{"position":[[419,10]]}}}],["link",{"_index":3163,"t":{"1053":{"position":[[17,5]]}}}],["links](./hello.md",{"_index":3162,"t":{"1051":{"position":[[219,19]]}}}],["list",{"_index":29,"t":{"5":{"position":[[109,4]]},"311":{"position":[[449,4]]}}}],["ljxi,jl_j",{"_index":1407,"t":{"427":{"position":[[1093,9]]}}}],["lk<n−l",{"_index":1675,"t":{"504":{"position":[[1445,6]]}}}],["lkl_klk",{"_index":1422,"t":{"427":{"position":[[1925,9],[2240,9]]}}}],["ll",{"_index":1778,"t":{"553":{"position":[[1065,3]]},"563":{"position":[[512,3]]},"571":{"position":[[117,3]]},"1137":{"position":[[1947,3]]},"1142":{"position":[[440,3]]},"1146":{"position":[[511,3]]}}}],["llama",{"_index":1508,"t":{"455":{"position":[[0,5],[16,5],[123,5],[154,5],[403,5],[470,5]]},"457":{"position":[[81,5],[188,5],[207,5],[319,5],[353,5],[581,5],[645,5],[919,5]]},"461":{"position":[[71,5],[323,5]]},"463":{"position":[[1598,5],[2013,5],[2542,5]]},"465":{"position":[[22,5],[1115,5]]},"475":{"position":[[88,5],[266,5]]},"477":{"position":[[9,5],[118,5]]},"479":{"position":[[77,5],[153,5]]},"482":{"position":[[194,5]]},"484":{"position":[[0,5],[64,5],[241,5]]},"489":{"position":[[23,5]]},"491":{"position":[[107,5]]},"498":{"position":[[0,5],[168,5]]},"502":{"position":[[3,5],[175,5],[195,5],[283,5],[688,5],[804,5],[825,5],[844,5]]},"504":{"position":[[121,5],[175,5],[246,5],[512,5],[543,5],[563,5],[780,5],[961,5],[1279,5],[1368,5],[1783,5],[2099,5],[2298,5]]},"508":{"position":[[64,5],[80,5],[144,5],[254,5],[410,5],[434,5]]},"510":{"position":[[278,5]]},"512":{"position":[[0,5],[199,5]]},"515":{"position":[[0,5],[73,5],[326,5],[512,5],[912,5],[938,5]]},"519":{"position":[[8,5],[105,5]]},"521":{"position":[[357,5]]},"523":{"position":[[117,5],[285,5],[425,5]]},"525":{"position":[[77,5],[637,5]]},"529":{"position":[[0,5]]},"531":{"position":[[28,5],[252,5]]},"533":{"position":[[50,5],[69,5],[125,5],[528,5]]},"535":{"position":[[0,5],[86,5],[204,5]]},"537":{"position":[[0,5],[166,5],[363,5],[484,5],[500,5],[546,5],[572,5]]},"541":{"position":[[127,5]]},"543":{"position":[[62,5]]}}}],["llava",{"_index":1670,"t":{"504":{"position":[[339,5]]},"521":{"position":[[33,5]]},"525":{"position":[[11,5]]},"529":{"position":[[125,5]]},"543":{"position":[[462,5]]}}}],["lll",{"_index":635,"t":{"132":{"position":[[940,4]]},"349":{"position":[[607,3]]},"427":{"position":[[1982,3],[2086,3]]},"461":{"position":[[202,3],[390,3],[514,3]]},"463":{"position":[[119,3],[207,3],[2207,3]]},"465":{"position":[[786,3],[833,3]]},"469":{"position":[[45,3]]},"504":{"position":[[1325,3]]},"523":{"position":[[450,3]]},"583":{"position":[[266,3]]},"627":{"position":[[739,4]]},"1092":{"position":[[424,3]]},"1140":{"position":[[25,3]]},"1222":{"position":[[214,3]]}}}],["lll=1",{"_index":1149,"t":{"349":{"position":[[628,11]]}}}],["llm",{"_index":862,"t":{"227":{"position":[[63,3],[181,3]]},"229":{"position":[[162,3],[357,3],[1163,3]]},"242":{"position":[[4,3]]},"244":{"position":[[196,3],[268,3]]},"271":{"position":[[364,3],[561,3]]},"279":{"position":[[21,6],[128,3],[282,3],[359,3],[378,3],[456,3],[641,3],[699,4],[745,4]]},"281":{"position":[[312,4],[447,4],[474,4],[661,3],[837,3],[860,3],[911,3],[971,3],[1033,3],[1171,3],[1290,4],[1534,3],[2112,3],[2174,3]]},"286":{"position":[[0,4],[58,4],[151,3],[351,3]]},"288":{"position":[[97,4],[370,3],[429,4],[460,4]]},"290":{"position":[[154,3],[443,3]]},"292":{"position":[[0,3],[73,4],[105,4],[157,4],[214,4],[459,3],[500,3],[576,3],[796,3],[859,3],[890,4]]},"300":{"position":[[765,3],[1000,3]]},"302":{"position":[[61,3],[367,3],[458,3]]},"304":{"position":[[86,3],[517,3],[584,3]]},"311":{"position":[[289,4],[357,4],[395,4]]},"313":{"position":[[47,3]]},"316":{"position":[[32,4],[94,3]]},"318":{"position":[[0,4],[195,3],[235,3],[274,4]]},"322":{"position":[[25,3],[116,4]]},"328":{"position":[[8,4],[351,4],[649,4]]},"330":{"position":[[0,4],[234,3],[1257,4],[1414,3]]},"333":{"position":[[56,4]]},"349":{"position":[[110,3]]},"451":{"position":[[686,3]]},"457":{"position":[[0,3]]},"479":{"position":[[162,3]]},"491":{"position":[[0,3]]},"502":{"position":[[19,4],[347,3]]},"504":{"position":[[3,3],[1932,3]]},"515":{"position":[[109,3]]},"517":{"position":[[226,3]]},"521":{"position":[[234,3]]},"525":{"position":[[37,3]]},"529":{"position":[[63,3]]},"537":{"position":[[248,3]]},"543":{"position":[[165,3]]},"549":{"position":[[37,3]]},"610":{"position":[[0,3]]},"614":{"position":[[107,5]]},"682":{"position":[[17,3]]},"704":{"position":[[511,3]]},"707":{"position":[[185,3]]},"761":{"position":[[1463,3]]},"817":{"position":[[0,3],[2480,3]]},"848":{"position":[[3,4]]},"850":{"position":[[8,3],[56,4],[409,3],[963,4],[1205,3],[1440,3],[1986,3],[2029,3]]},"855":{"position":[[56,3]]},"857":{"position":[[527,3]]},"859":{"position":[[0,3]]},"861":{"position":[[391,3]]},"863":{"position":[[241,3],[730,3]]},"1200":{"position":[[499,3]]}}}],["llm=−1t∑tlog⁡p(yt∣x,y<t)l_{lm",{"_index":1339,"t":{"425":{"position":[[111,30]]}}}],["llml_{\\text{lm}}llm",{"_index":1384,"t":{"425":{"position":[[2268,21],[2439,20]]},"431":{"position":[[222,21]]}}}],["lln=−log⁡exp⁡(β(x,y))exp⁡(β(x,y))+∑n=1nexp⁡(β(x,y^(n)))\\begin{equ",{"_index":1376,"t":{"425":{"position":[[1970,71]]}}}],["llnl_{\\text{ln}}lln",{"_index":1385,"t":{"425":{"position":[[2313,20]]},"431":{"position":[[332,20]]}}}],["llogit=∑k∈s∣∑(xi,yi)∈skkl",{"_index":2030,"t":{"633":{"position":[[756,25]]}}}],["lm",{"_index":877,"t":{"229":{"position":[[4,2],[437,2]]},"231":{"position":[[485,2]]},"233":{"position":[[0,2],[48,2]]},"254":{"position":[[531,2]]},"269":{"position":[[475,2]]},"271":{"position":[[112,2]]},"275":{"position":[[16,2],[155,2]]},"328":{"position":[[550,2]]},"341":{"position":[[266,2]]},"347":{"position":[[420,2]]},"396":{"position":[[410,2]]},"398":{"position":[[957,2]]},"406":{"position":[[99,3],[128,2]]},"410":{"position":[[0,2]]},"416":{"position":[[63,4]]},"418":{"position":[[12,2],[90,2],[170,2]]},"425":{"position":[[16,2],[84,2]]},"435":{"position":[[207,3],[406,2]]},"437":{"position":[[124,2]]},"547":{"position":[[428,4]]},"553":{"position":[[51,2],[100,2]]},"563":{"position":[[136,2]]},"621":{"position":[[177,2],[293,2]]},"627":{"position":[[19,2],[957,2]]},"680":{"position":[[137,4],[1045,2],[1539,2],[1679,2],[1808,2]]},"686":{"position":[[12,2],[877,2]]},"688":{"position":[[625,2]]},"692":{"position":[[38,2],[214,2]]},"696":{"position":[[222,2],[316,2],[711,2],[756,2],[828,2],[1273,2]]},"702":{"position":[[322,2],[391,2]]},"707":{"position":[[344,2]]},"711":{"position":[[31,4]]},"713":{"position":[[12,2],[291,2],[335,2],[399,2],[512,2],[1270,2]]},"718":{"position":[[0,2],[46,2],[468,2]]},"736":{"position":[[19,2]]},"751":{"position":[[36,2],[225,2]]},"759":{"position":[[111,4],[266,2],[356,2]]},"761":{"position":[[121,2],[177,2],[211,2],[344,2],[448,2],[625,2],[793,2],[1250,2],[1389,2]]},"766":{"position":[[599,2]]},"770":{"position":[[84,2]]},"773":{"position":[[32,2],[71,2],[158,2],[241,2],[623,2]]},"775":{"position":[[31,2],[973,2]]},"793":{"position":[[662,2]]},"802":{"position":[[430,2]]},"809":{"position":[[160,2]]},"811":{"position":[[91,2],[134,2],[470,2],[574,2],[755,2],[794,3]]},"815":{"position":[[68,4]]},"817":{"position":[[1362,2],[1466,2],[1523,2],[2065,2]]},"823":{"position":[[1434,2],[1491,2],[1673,2]]},"825":{"position":[[178,2]]},"834":{"position":[[290,2],[370,2],[506,2],[1087,2]]},"836":{"position":[[1010,2],[1558,2],[2104,2]]},"838":{"position":[[7,2]]},"840":{"position":[[218,2],[316,2]]},"844":{"position":[[35,2]]},"874":{"position":[[340,2],[491,3]]},"876":{"position":[[423,4],[629,2],[680,2],[864,2],[1013,2],[1198,2]]},"885":{"position":[[0,2],[392,2],[706,2]]},"889":{"position":[[61,2],[116,2],[491,2]]},"893":{"position":[[102,2],[166,2]]},"895":{"position":[[76,2]]},"897":{"position":[[265,2]]},"899":{"position":[[1063,2],[1187,2]]},"901":{"position":[[20,2],[64,2],[195,2],[396,2],[666,2],[976,2],[1220,2],[2355,2]]},"905":{"position":[[63,2]]},"909":{"position":[[731,2]]},"911":{"position":[[1190,2]]},"913":{"position":[[199,2]]},"917":{"position":[[1653,2]]},"919":{"position":[[49,2],[428,2]]},"929":{"position":[[65,3],[151,2]]},"931":{"position":[[36,2],[164,2],[285,2],[353,2]]},"933":{"position":[[47,2]]},"935":{"position":[[6,2],[133,2],[232,2]]},"937":{"position":[[13,2],[53,2],[235,2],[609,2]]},"939":{"position":[[30,2]]},"943":{"position":[[65,2],[114,2],[455,2],[599,2]]},"945":{"position":[[70,2],[245,2]]},"947":{"position":[[191,2],[356,2]]},"949":{"position":[[138,2]]},"951":{"position":[[417,2],[562,2],[718,2]]},"953":{"position":[[478,3]]},"955":{"position":[[106,2],[350,2],[415,2],[485,2],[582,2]]},"959":{"position":[[226,3],[848,2]]},"961":{"position":[[54,2],[160,2]]},"963":{"position":[[627,2],[1266,2],[2150,2],[2257,2],[2413,2],[2480,2]]},"967":{"position":[[4,3],[84,2]]},"971":{"position":[[156,3]]},"973":{"position":[[8,4]]},"981":{"position":[[66,3]]},"983":{"position":[[77,3],[171,3],[257,3],[911,3]]},"989":{"position":[[26,5]]},"1137":{"position":[[248,2]]}}}],["lm'",{"_index":2257,"t":{"696":{"position":[[1044,4]]}}}],["ln",{"_index":438,"t":{"91":{"position":[[1405,4],[2156,4]]}}}],["local",{"_index":129,"t":{"19":{"position":[[262,7]]},"86":{"position":[[380,8]]},"93":{"position":[[6,9]]},"102":{"position":[[361,12]]},"116":{"position":[[842,12]]},"153":{"position":[[533,5]]},"157":{"position":[[379,9]]},"688":{"position":[[290,5]]},"842":{"position":[[1727,8]]},"870":{"position":[[115,5]]},"1047":{"position":[[27,8]]},"1073":{"position":[[54,7],[131,8]]},"1077":{"position":[[30,7],[57,6],[72,9],[219,6]]},"1079":{"position":[[47,6],[221,6]]},"1081":{"position":[[31,7],[58,6],[106,7]]},"1090":{"position":[[248,10]]},"1152":{"position":[[2272,5]]}}}],["localedropdown",{"_index":3236,"t":{"1079":{"position":[[184,17]]}}}],["localhost:3000",{"_index":3133,"t":{"1038":{"position":[[91,15]]}}}],["localhost:3000/foo",{"_index":3135,"t":{"1038":{"position":[[126,18]]}}}],["localhost:3000/foo/bar",{"_index":3137,"t":{"1038":{"position":[[168,22]]}}}],["localis",{"_index":1035,"t":{"302":{"position":[[756,12]]}}}],["locat",{"_index":68,"t":{"9":{"position":[[327,6]]},"909":{"position":[[586,10]]}}}],["log",{"_index":631,"t":{"132":{"position":[[826,4]]},"180":{"position":[[151,3],[186,4],[217,3]]},"190":{"position":[[233,3]]},"197":{"position":[[127,3]]},"398":{"position":[[429,3],[545,3]]},"423":{"position":[[1127,3]]},"425":{"position":[[164,4],[585,4],[1693,3],[1791,4],[1950,3],[2060,4]]},"553":{"position":[[559,4],[1252,4]]},"627":{"position":[[883,4]]},"770":{"position":[[107,3],[250,4],[332,4]]},"901":{"position":[[478,4],[694,3]]},"989":{"position":[[987,3],[1177,3]]}}}],["log(\\pi^{rl}_\\phi(i",{"_index":3032,"t":{"1001":{"position":[[1574,20]]}}}],["logist",{"_index":2820,"t":{"911":{"position":[[858,8],[896,8]]}}}],["logit",{"_index":2049,"t":{"633":{"position":[[1287,5]]},"664":{"position":[[127,6],[346,6]]},"766":{"position":[[1035,6]]},"836":{"position":[[1081,5]]}}}],["logo](./img/docusaurus.png",{"_index":3173,"t":{"1055":{"position":[[342,27]]}}}],["logo](/img/docusaurus.png",{"_index":3170,"t":{"1055":{"position":[[152,26]]}}}],["logpϕ​(i",{"_index":2377,"t":{"770":{"position":[[384,8]]}}}],["log⁡pϕ(i",{"_index":2368,"t":{"770":{"position":[[167,8]]}}}],["long",{"_index":20,"t":{"5":{"position":[[30,4]]},"519":{"position":[[28,4]]},"521":{"position":[[290,4]]},"565":{"position":[[129,4]]},"773":{"position":[[1036,4]]},"834":{"position":[[440,4]]},"850":{"position":[[1085,4]]},"861":{"position":[[36,4],[91,4],[264,4]]},"870":{"position":[[145,4]]},"963":{"position":[[2807,4]]},"971":{"position":[[91,4]]}}}],["long.353.pdf",{"_index":2323,"t":{"757":{"position":[[48,12]]}}}],["longer",{"_index":2451,"t":{"796":{"position":[[0,6]]},"832":{"position":[[497,6]]},"842":{"position":[[1545,6]]},"905":{"position":[[361,6]]}}}],["look",{"_index":3067,"t":{"1024":{"position":[[157,4]]}}}],["loop",{"_index":3049,"t":{"1013":{"position":[[41,4],[74,4]]}}}],["lora",{"_index":1450,"t":{"427":{"position":[[3613,4]]},"517":{"position":[[311,4]]},"547":{"position":[[71,4],[261,4],[366,4],[482,4]]},"549":{"position":[[527,6],[709,4],[770,4],[789,4],[840,4],[974,4],[1257,4]]},"551":{"position":[[321,4]]},"553":{"position":[[0,4]]},"565":{"position":[[28,4]]},"571":{"position":[[361,4]]},"573":{"position":[[28,4]]},"587":{"position":[[114,4],[281,4]]},"589":{"position":[[11,4]]},"591":{"position":[[58,4]]},"593":{"position":[[0,4]]},"598":{"position":[[0,4],[94,4]]},"602":{"position":[[19,4]]},"610":{"position":[[44,4],[158,4],[214,4],[230,4]]},"1137":{"position":[[1557,4],[2205,4],[2348,4],[2621,4],[3093,4],[3307,4]]},"1142":{"position":[[0,4],[727,4],[953,4]]},"1146":{"position":[[1483,4],[1819,4]]},"1158":{"position":[[107,4],[329,4],[379,4]]},"1160":{"position":[[611,4],[824,4],[866,4],[1003,4]]},"1165":{"position":[[226,4]]},"1172":{"position":[[232,4]]},"1186":{"position":[[21,4],[238,4],[299,4]]},"1190":{"position":[[123,4],[208,4],[437,4]]}}}],["loraregu_{\\text{regu}}regu",{"_index":3724,"t":{"1190":{"position":[[178,27]]}}}],["lorber",{"_index":3103,"t":{"1030":{"position":[[275,6]]}}}],["lorem",{"_index":0,"t":{"3":{"position":[[0,5],[152,5]]},"5":{"position":[[120,5],[272,5],[299,5],[451,5],[478,5],[630,5],[657,5],[809,5],[836,5],[988,5],[1015,5],[1167,5],[1194,5],[1346,5],[1373,5],[1525,5],[1552,5],[1704,5],[1731,5],[1883,5],[1910,5],[2062,5],[2089,5],[2241,5],[2268,5],[2420,5],[2447,5],[2599,5],[2626,5],[2778,5],[2805,5],[2957,5]]}}}],["loshchilov",{"_index":1188,"t":{"362":{"position":[[1026,11]]}}}],["loss",{"_index":319,"t":{"58":{"position":[[216,4]]},"124":{"position":[[97,4],[469,4]]},"126":{"position":[[557,4],[613,4]]},"130":{"position":[[270,4]]},"132":{"position":[[1000,4]]},"138":{"position":[[141,4]]},"149":{"position":[[391,4]]},"153":{"position":[[264,4]]},"155":{"position":[[246,4],[630,4]]},"159":{"position":[[148,4]]},"188":{"position":[[395,4]]},"193":{"position":[[17,4]]},"418":{"position":[[2040,4]]},"425":{"position":[[70,4],[106,4],[1641,4],[1893,4],[2360,4],[2512,4]]},"431":{"position":[[217,4],[281,4],[327,4]]},"437":{"position":[[749,4]]},"451":{"position":[[374,4]]},"489":{"position":[[219,4],[272,4]]},"627":{"position":[[798,4]]},"633":{"position":[[748,4],[1370,4],[1828,4],[1972,4],[2307,6],[2339,4]]},"635":{"position":[[267,4],[819,4]]},"648":{"position":[[203,4]]},"662":{"position":[[438,4]]},"664":{"position":[[79,4],[224,4],[235,4],[275,4],[296,4],[312,4],[385,4]]},"686":{"position":[[1829,4]]},"796":{"position":[[172,4]]},"825":{"position":[[676,4]]},"876":{"position":[[596,4]]},"1001":{"position":[[358,4],[618,4],[1051,4],[1978,4]]},"1096":{"position":[[2499,4]]},"1099":{"position":[[220,6],[237,4],[652,4],[665,4],[680,4]]},"1137":{"position":[[4226,4]]},"1152":{"position":[[39,4],[1221,4]]},"1222":{"position":[[1249,4]]}}}],["loss(θ)=−1(k2)e(x,yw,yl)∼d[log",{"_index":3010,"t":{"1001":{"position":[[640,32]]}}}],["love",{"_index":2713,"t":{"879":{"position":[[365,4]]},"883":{"position":[[325,4],[400,4]]}}}],["low",{"_index":731,"t":{"165":{"position":[[561,3]]},"171":{"position":[[238,3]]},"427":{"position":[[3282,3],[3501,3],[3641,3]]},"519":{"position":[[587,3]]},"547":{"position":[[50,3]]},"549":{"position":[[389,3],[507,3],[721,3],[1119,3]]},"563":{"position":[[141,4],[318,3]]},"614":{"position":[[483,3]]},"616":{"position":[[976,3],[1183,3]]},"629":{"position":[[179,3],[347,3]]},"631":{"position":[[788,3],[895,3]]},"635":{"position":[[635,3]]},"759":{"position":[[585,3]]},"791":{"position":[[92,3],[202,3],[274,3],[443,3]]},"802":{"position":[[90,3]]},"804":{"position":[[330,3]]},"811":{"position":[[876,3]]},"834":{"position":[[992,3]]},"1135":{"position":[[932,3]]},"1137":{"position":[[1337,3],[1623,3],[3283,3],[4578,3]]},"1154":{"position":[[9,3]]},"1179":{"position":[[27,3]]},"1184":{"position":[[266,3]]}}}],["lower",{"_index":1286,"t":{"416":{"position":[[444,5]]},"451":{"position":[[297,5]]},"1137":{"position":[[3624,5]]}}}],["lpaqa",{"_index":2254,"t":{"696":{"position":[[111,5]]}}}],["lpl_plp",{"_index":1842,"t":{"581":{"position":[[207,8]]}}}],["lplm=∑k∈∣s∣lplmk\\mathcal{l}_{plm",{"_index":2066,"t":{"633":{"position":[[2172,33]]}}}],["lplm=−∑ilog⁡p(yi∣xi",{"_index":1986,"t":{"627":{"position":[[825,19]]}}}],["lr",{"_index":295,"t":{"53":{"position":[[224,3]]},"63":{"position":[[141,3]]},"80":{"position":[[21,3]]},"143":{"position":[[533,2]]},"362":{"position":[[652,7]]},"1236":{"position":[[4,2],[105,2]]}}}],["lst",{"_index":1944,"t":{"619":{"position":[[347,3]]}}}],["lstage1=lretrieve+lbox+lmaskboxinst(2)l_{\\textup{stage1",{"_index":3347,"t":{"1099":{"position":[[261,57]]}}}],["lstage2=lretrieve+lbox+lmask(3)l_{\\textup{stage2",{"_index":3356,"t":{"1099":{"position":[[805,50]]}}}],["lstage3=lretrieve+lbox+lmask+lembed(4)l_{\\textup{stage3",{"_index":3370,"t":{"1099":{"position":[[1421,57]]}}}],["lstm",{"_index":2218,"t":{"688":{"position":[[561,4],[996,4],[1058,4],[1137,4]]}}}],["lstm(hi:m",{"_index":2229,"t":{"688":{"position":[[979,16]]}}}],["lstm(hi:m)])\\begin{equ",{"_index":2222,"t":{"688":{"position":[[729,28]]}}}],["ltotal=lplm+λ(llogits+lhidden)(5)\\mathcal{l}_{tot",{"_index":2061,"t":{"633":{"position":[[1996,52]]}}}],["lul=−∑nn=1∑t=1t(n)log⁡(1−p(y^i(n)∣x,y^<t(n)))∑n=1nt(n)\\begin{equ",{"_index":1353,"t":{"425":{"position":[[459,70]]}}}],["lull_{\\text{ul}}lul",{"_index":1366,"t":{"425":{"position":[[992,20],[2290,20]]},"431":{"position":[[286,20]]}}}],["lvl_vlv",{"_index":1423,"t":{"427":{"position":[[1935,8],[2250,8]]}}}],["lz'_\\varrho",{"_index":461,"t":{"91":{"position":[[1978,11]]}}}],["lz_\\varrho",{"_index":470,"t":{"91":{"position":[[2274,10]]}}}],["lzϱ​=mlp(ln(zϱ′​))+zϱ′​,ϱ=1",{"_index":473,"t":{"91":{"position":[[2364,27]]}}}],["lzϱ′​=msa(ln(zϱ−1​))+zϱ−1",{"_index":465,"t":{"91":{"position":[[2070,27]]}}}],["l}v∈rd×l",{"_index":3792,"t":{"1222":{"position":[[154,8]]}}}],["l×d)(l",{"_index":2084,"t":{"637":{"position":[[107,7]]}}}],["l×d)+(l×d)(l",{"_index":2086,"t":{"637":{"position":[[197,13]]}}}],["l×d)+(l×d)τ(l",{"_index":2090,"t":{"637":{"position":[[370,14]]}}}],["l×d2l",{"_index":2088,"t":{"637":{"position":[[264,5]]}}}],["l×dl",{"_index":2082,"t":{"637":{"position":[[58,4]]}}}],["l×dmodel×+(lp+li)|\\theta",{"_index":1844,"t":{"583":{"position":[[170,29]]}}}],["l∈rdl",{"_index":1397,"t":{"427":{"position":[[836,5]]}}}],["l≤l)(l",{"_index":1530,"t":{"461":{"position":[[400,7],[536,7]]}}}],["l⊙wx=(l⊙w)xl",{"_index":1439,"t":{"427":{"position":[[2849,12]]}}}],["l⊙xl",{"_index":1394,"t":{"427":{"position":[[802,4],[1041,4]]}}}],["m",{"_index":257,"t":{"49":{"position":[[248,1],[258,1],[291,1]]},"55":{"position":[[53,1],[119,1]]},"1184":{"position":[[80,2]]}}}],["m)hi​(0≤i≤m",{"_index":2202,"t":{"686":{"position":[[1678,12],[1910,12]]}}}],["m+1)(m",{"_index":1547,"t":{"463":{"position":[[262,7]]}}}],["m+1)(m+1)(m+1",{"_index":1552,"t":{"463":{"position":[[354,15]]}}}],["m+1m+1m+1",{"_index":1590,"t":{"463":{"position":[[1444,9]]}}}],["m/l",{"_index":243,"t":{"42":{"position":[[61,3]]}}}],["m\\mathcal{m}m",{"_index":2158,"t":{"686":{"position":[[15,13],[880,13],[1727,13]]},"688":{"position":[[76,13],[628,13]]},"718":{"position":[[3,13],[49,13]]}}}],["m_e(\\tau_0)rt​=me​(τ0",{"_index":2672,"t":{"863":{"position":[[90,23]]}}}],["m_{m=1",{"_index":1622,"t":{"465":{"position":[[539,10]]}}}],["m_{m=1}{im​}m=1m",{"_index":1613,"t":{"465":{"position":[[266,20]]}}}],["machin",{"_index":1952,"t":{"623":{"position":[[90,7]]},"1207":{"position":[[284,7]]}}}],["macro",{"_index":1238,"t":{"384":{"position":[[282,6]]}}}],["made",{"_index":3062,"t":{"1024":{"position":[[51,4]]},"1030":{"position":[[434,4]]}}}],["magnitud",{"_index":250,"t":{"49":{"position":[[176,9],[476,9],[527,9],[838,9]]}}}],["maintain",{"_index":3104,"t":{"1030":{"position":[[300,10]]}}}],["major",{"_index":2588,"t":{"840":{"position":[[656,8]]},"917":{"position":[[965,8]]}}}],["make",{"_index":2616,"t":{"848":{"position":[[514,7]]},"850":{"position":[[682,7],[1551,6],[1768,6]]},"857":{"position":[[379,6],[471,6]]},"859":{"position":[[402,6],[702,6],[865,6]]},"1016":{"position":[[200,4]]},"1061":{"position":[[8,4]]}}}],["mam_ama",{"_index":2643,"t":{"853":{"position":[[58,8],[85,8]]}}}],["mamechan",{"_index":1662,"t":{"498":{"position":[[89,11]]}}}],["manag",{"_index":3207,"t":{"1063":{"position":[[15,6]]}}}],["mani",{"_index":2155,"t":{"682":{"position":[[132,4]]},"971":{"position":[[0,4]]}}}],["manual",{"_index":1311,"t":{"421":{"position":[[334,6]]},"680":{"position":[[503,6],[564,6]]},"682":{"position":[[262,6],[298,6]]},"696":{"position":[[540,6],[577,6],[652,6],[695,6]]},"702":{"position":[[26,6],[54,6],[156,6],[196,6],[341,6],[413,6],[491,6],[538,6],[723,6],[943,6],[1000,6]]},"704":{"position":[[323,6]]},"817":{"position":[[1134,6]]},"819":{"position":[[845,6]]}}}],["manut",{"_index":2793,"t":{"909":{"position":[[0,7]]}}}],["map",{"_index":394,"t":{"88":{"position":[[418,3]]},"95":{"position":[[48,3],[139,3],[218,3],[300,3]]},"104":{"position":[[389,3]]},"302":{"position":[[769,3]]},"909":{"position":[[212,7]]}}}],["marcey",{"_index":3096,"t":{"1030":{"position":[[136,6]]}}}],["mark",{"_index":2955,"t":{"969":{"position":[[487,7],[517,5]]}}}],["markdown",{"_index":33,"t":{"7":{"position":[[30,8]]},"9":{"position":[[72,8]]},"1034":{"position":[[9,8]]},"1038":{"position":[[4,8]]},"1042":{"position":[[30,8],[61,8],[83,8],[107,8],[177,8]]},"1049":{"position":[[20,8]]},"1051":{"position":[[0,8],[183,8],[200,8]]},"1053":{"position":[[8,8]]},"1055":{"position":[[8,8],[302,8]]},"1057":{"position":[[0,8]]},"1061":{"position":[[94,9]]}}}],["markup",{"_index":2957,"t":{"969":{"position":[[593,6]]}}}],["mask",{"_index":573,"t":{"118":{"position":[[47,7],[62,6]]},"124":{"position":[[243,4]]},"126":{"position":[[473,5]]},"130":{"position":[[117,5],[830,4]]},"140":{"position":[[542,4],[590,4],[653,4],[683,4]]},"143":{"position":[[173,5]]},"147":{"position":[[139,4]]},"153":{"position":[[334,4],[407,4],[548,4]]},"337":{"position":[[28,4]]},"345":{"position":[[567,4]]},"423":{"position":[[169,6]]},"427":{"position":[[3423,4]]},"686":{"position":[[486,6],[745,8],[816,8]]},"692":{"position":[[176,8]]},"694":{"position":[[639,6],[702,6]]},"713":{"position":[[474,8],[518,6]]},"718":{"position":[[137,9]]},"817":{"position":[[1355,6]]},"823":{"position":[[155,6],[199,6]]},"836":{"position":[[1003,6],[1023,6],[1068,4]]},"893":{"position":[[159,6]]},"937":{"position":[[327,4]]},"947":{"position":[[173,6]]},"1087":{"position":[[114,4],[683,5]]},"1096":{"position":[[1377,5]]},"1099":{"position":[[146,4],[173,4],[622,4],[696,4]]},"1125":{"position":[[244,4],[275,4]]},"1146":{"position":[[1783,7]]}}}],["massiv",{"_index":1200,"t":{"368":{"position":[[315,7]]},"621":{"position":[[145,7]]}}}],["match",{"_index":705,"t":{"153":{"position":[[212,8]]},"328":{"position":[[532,8]]},"341":{"position":[[248,8]]},"345":{"position":[[401,7],[469,8],[721,8],[816,7]]},"357":{"position":[[229,8]]},"360":{"position":[[300,5]]},"384":{"position":[[162,5]]},"857":{"position":[[326,5]]}}}],["math",{"_index":873,"t":{"227":{"position":[[321,4]]},"229":{"position":[[948,4]]},"231":{"position":[[25,4]]},"236":{"position":[[8,4],[43,4],[74,4]]},"254":{"position":[[186,4]]},"328":{"position":[[832,4]]},"382":{"position":[[265,4]]},"390":{"position":[[185,4]]}}}],["mathbb{r}^dhi​∈rd",{"_index":2342,"t":{"766":{"position":[[360,18]]}}}],["mathbb{r}^dl∈rd",{"_index":1398,"t":{"427":{"position":[[846,16]]}}}],["mathbb{r}^duk​∈rl,vk​∈rd",{"_index":2004,"t":{"631":{"position":[[345,25]]}}}],["mathbb{r}^l",{"_index":2002,"t":{"631":{"position":[[323,13]]}}}],["mathbb{r}^{(k+m",{"_index":1541,"t":{"461":{"position":[[796,17]]}}}],["mathbb{r}^{(m+1)\\tim",{"_index":1588,"t":{"463":{"position":[[1400,23]]}}}],["mathbb{r}^{(n",{"_index":453,"t":{"91":{"position":[[1735,14]]}}}],["mathbb{r}^{(p",{"_index":2511,"t":{"819":{"position":[[1819,14]]}}}],["mathbb{r}^{1",{"_index":1550,"t":{"463":{"position":[[317,13],[920,13],[2355,13]]},"465":{"position":[[302,13],[626,13]]},"1096":{"position":[[1801,13]]}}}],["mathbb{r}^{100",{"_index":2114,"t":{"644":{"position":[[160,15]]}}}],["mathbb{r}^{1024",{"_index":3280,"t":{"1092":{"position":[[1429,16]]}}}],["mathbb{r}^{d",{"_index":1789,"t":{"563":{"position":[[278,13],[415,13]]},"1140":{"position":[[549,13],[645,13],[982,13]]}}}],["mathbb{r}^{d_1",{"_index":3420,"t":{"1137":{"position":[[1801,15],[1901,15]]},"1142":{"position":[[294,15],[394,15]]},"1146":{"position":[[230,15]]}}}],["mathbb{r}^{d_m",{"_index":3478,"t":{"1140":{"position":[[1039,15]]}}}],["mathbb{r}^{h",{"_index":404,"t":{"91":{"position":[[133,13]]}}}],["mathbb{r}^{k",{"_index":1527,"t":{"461":{"position":[[252,13]]},"465":{"position":[[963,13]]}}}],["mathbb{r}^{k+1}slk​∈rk+1",{"_index":1586,"t":{"463":{"position":[[1224,25]]}}}],["mathbb{r}^{l",{"_index":1983,"t":{"627":{"position":[[709,13]]},"631":{"position":[[240,13]]},"1092":{"position":[[462,13]]}}}],["mathbb{r}^{m",{"_index":1536,"t":{"461":{"position":[[578,13]]}}}],["mathbb{r}^{n",{"_index":408,"t":{"91":{"position":[[228,13],[1683,13]]},"627":{"position":[[606,13]]},"819":{"position":[[1599,13]]},"1096":{"position":[[1217,13]]},"1140":{"position":[[164,13]]}}}],["mathbb{r}^{p",{"_index":2507,"t":{"819":{"position":[[1682,13]]}}}],["mathbb{r}^{r",{"_index":1797,"t":{"563":{"position":[[458,13]]},"1137":{"position":[[1853,13]]},"1142":{"position":[[346,13]]},"1146":{"position":[[279,13],[391,13]]}}}],["mathbb{r}^{t",{"_index":1400,"t":{"427":{"position":[[944,13]]}}}],["mathcal{",{"_index":2036,"t":{"633":{"position":[[865,11],[1464,11],[2220,14]]},"1148":{"position":[[787,12],[924,12],[977,12]]}}}],["mathcal{c}(\\mathcal{p",{"_index":3559,"t":{"1148":{"position":[[952,24]]}}}],["mathcal{e}^{(t",{"_index":3576,"t":{"1148":{"position":[[1475,18]]}}}],["mathcal{f}j&f",{"_index":3392,"t":{"1113":{"position":[[160,14]]},"1121":{"position":[[190,14]]}}}],["mathcal{l",{"_index":2208,"t":{"686":{"position":[[2029,11]]},"1152":{"position":[[1088,11]]}}}],["mathcal{l}(\\mathcal{p}^{(t",{"_index":3575,"t":{"1148":{"position":[[1444,30]]}}}],["mathcal{l}_{hidden",{"_index":2064,"t":{"633":{"position":[[2104,20]]}}}],["mathcal{l}_{logit",{"_index":2063,"t":{"633":{"position":[[2081,20]]}}}],["mathcal{l}_{plm",{"_index":2062,"t":{"633":{"position":[[2051,17]]}}}],["mathcal{l}_{plm}^klplm​=∑k∈∣s∣​lplmk",{"_index":2067,"t":{"633":{"position":[[2235,38]]}}}],["mathcal{m}(\\text{x",{"_index":2209,"t":{"686":{"position":[[2041,22]]}}}],["mathcal{m}e∈m",{"_index":2165,"t":{"686":{"position":[[190,14]]}}}],["mathcal{p",{"_index":3555,"t":{"1148":{"position":[[773,13]]}}}],["mathcal{q",{"_index":3558,"t":{"1148":{"position":[[937,12],[990,12]]}}}],["mathcal{q})c(p,e,q",{"_index":3556,"t":{"1148":{"position":[[800,20]]}}}],["mathcal{q}^{(t",{"_index":3577,"t":{"1148":{"position":[[1494,19]]}}}],["mathcal{r}^dwc​∈rd",{"_index":3802,"t":{"1222":{"position":[[503,19]]}}}],["mathcal{r}^{(l+n",{"_index":1992,"t":{"627":{"position":[[995,18]]}}}],["mathcal{r}^{d",{"_index":3791,"t":{"1222":{"position":[[132,14],[387,14]]}}}],["mathcal{s_k",{"_index":2038,"t":{"633":{"position":[[901,14],[1500,14]]}}}],["mathcal{s}_1",{"_index":1958,"t":{"625":{"position":[[57,14]]}}}],["mathcal{s}_2",{"_index":1959,"t":{"625":{"position":[[72,14]]}}}],["mathcal{s}_k",{"_index":1960,"t":{"625":{"position":[[94,13]]}}}],["mathcal{t",{"_index":3586,"t":{"1148":{"position":[[1814,11]]}}}],["mathcal{t}(\\tilde{\\lambda}_k^{(t",{"_index":3589,"t":{"1148":{"position":[[1876,36]]}}}],["mathcal{t}_1",{"_index":1963,"t":{"625":{"position":[[179,14]]},"635":{"position":[[941,14]]}}}],["mathcal{t}_2",{"_index":1964,"t":{"625":{"position":[[194,14]]},"635":{"position":[[956,14]]}}}],["mathcal{t}_\\mathcal{t",{"_index":1965,"t":{"625":{"position":[[216,23]]}}}],["mathcal{t}_{\\mathcal{t",{"_index":2081,"t":{"635":{"position":[[978,25]]}}}],["mathcal{v}[pi​]∈v",{"_index":2187,"t":{"686":{"position":[[1190,18]]}}}],["mathcal{v}⊂v",{"_index":2291,"t":{"718":{"position":[[157,13]]}}}],["mathcal{z",{"_index":1770,"t":{"553":{"position":[[529,12],[1222,12]]}}}],["mathcal{z}}{\\textup{search",{"_index":2735,"t":{"885":{"position":[[527,29]]}}}],["mathemat",{"_index":1226,"t":{"382":{"position":[[102,12]]},"951":{"position":[[487,12]]}}}],["matric",{"_index":1436,"t":{"427":{"position":[[2653,8],[3291,8],[3630,8]]},"549":{"position":[[636,8],[1128,8],[1165,8]]},"563":{"position":[[56,8]]},"565":{"position":[[10,8]]},"587":{"position":[[10,8],[40,8],[299,8]]},"604":{"position":[[141,8]]},"698":{"position":[[958,6]]},"1135":{"position":[[312,8],[467,8]]},"1137":{"position":[[1303,8],[1608,8],[2260,8],[2310,8],[2469,8],[2758,8],[2809,8],[2904,8],[3340,8],[3410,8],[3469,8],[3640,8],[3673,8],[3907,8],[4101,8]]},"1142":{"position":[[17,8]]},"1144":{"position":[[55,8]]},"1146":{"position":[[19,8],[1349,8],[2027,8]]},"1148":{"position":[[359,8],[2490,8]]},"1154":{"position":[[89,8]]},"1160":{"position":[[674,8],[794,8],[884,8]]},"1192":{"position":[[181,8],[212,8]]},"1194":{"position":[[124,8],[295,8]]}}}],["matrices/lay",{"_index":3434,"t":{"1137":{"position":[[3066,15]]}}}],["matrix",{"_index":1438,"t":{"427":{"position":[[2810,6]]},"551":{"position":[[170,6],[237,6]]},"563":{"position":[[256,6]]},"569":{"position":[[27,6]]},"598":{"position":[[153,6]]},"602":{"position":[[107,6]]},"608":{"position":[[197,6],[357,6],[470,6]]},"610":{"position":[[255,6]]},"616":{"position":[[950,7],[967,6],[999,6],[1035,6],[1174,6]]},"625":{"position":[[642,6]]},"627":{"position":[[690,6]]},"629":{"position":[[80,6],[123,6],[144,6],[202,6],[262,6],[338,6]]},"631":{"position":[[444,6]]},"633":{"position":[[557,6],[589,6]]},"635":{"position":[[612,6],[651,6]]},"637":{"position":[[297,6]]},"659":{"position":[[339,6]]},"674":{"position":[[197,6],[229,6]]},"775":{"position":[[538,6]]},"777":{"position":[[75,6],[185,6]]},"819":{"position":[[1781,6]]},"901":{"position":[[631,6]]},"1096":{"position":[[1782,6],[1899,6]]},"1137":{"position":[[936,6],[1014,6],[1437,6],[1632,6],[2382,6],[3710,6],[3811,6],[3829,6],[4043,6]]},"1142":{"position":[[859,6]]},"1146":{"position":[[366,6],[1951,6]]},"1148":{"position":[[56,6],[232,6]]},"1150":{"position":[[150,6],[225,6]]},"1154":{"position":[[408,6]]},"1179":{"position":[[95,6]]},"1192":{"position":[[64,6]]}}}],["matter",{"_index":2750,"t":{"895":{"position":[[465,8]]},"1051":{"position":[[57,7]]}}}],["mawp",{"_index":887,"t":{"236":{"position":[[124,5]]},"244":{"position":[[236,5]]},"254":{"position":[[247,5]]}}}],["max",{"_index":983,"t":{"286":{"position":[[266,4]]},"770":{"position":[[161,5]]},"863":{"position":[[718,3]]}}}],["maxim",{"_index":3025,"t":{"1001":{"position":[[1387,8]]}}}],["maximize∑j=1lwjlog⁡p(yj∣x,y1:j−1),(1)\\textup{maxim",{"_index":629,"t":{"132":{"position":[[755,54]]}}}],["maximum",{"_index":700,"t":{"153":{"position":[[156,7]]},"870":{"position":[[164,7]]}}}],["maxiup",{"_index":255,"t":{"49":{"position":[[218,6]]}}}],["max⁡c",{"_index":3770,"t":{"1214":{"position":[[880,5]]}}}],["max⁡θ∑(x,y)∈z∑t=1∣y∣log⁡(pϕ0+△ϕ(θ)(yt∣x,y<t))(2)\\underset{\\theta}{\\max",{"_index":1780,"t":{"553":{"position":[[1134,71]]}}}],["max⁡ϕlog⁡p(y∣x;θ;ϕ)=max⁡ϕ∑yilog⁡p(yi,h<i;θ;ϕ)(2)\\underset{\\phi}{\\max",{"_index":2762,"t":{"901":{"position":[[408,69]]}}}],["max⁡ϕ∑(x,y)∈z∑t=1∣y∣log⁡(pϕ(yt∣x,y<t))(1)\\underset{\\phi}{\\max",{"_index":1768,"t":{"553":{"position":[[450,62]]}}}],["mbconv",{"_index":175,"t":{"25":{"position":[[375,6]]},"33":{"position":[[124,6],[199,6],[229,6],[273,6],[303,6]]},"38":{"position":[[144,8],[159,7]]},"40":{"position":[[61,6],[83,6],[93,6]]},"76":{"position":[[167,6]]},"78":{"position":[[194,6],[212,6],[842,6],[860,6]]}}}],["mdaliti",{"_index":747,"t":{"171":{"position":[[392,7]]}}}],["mdx",{"_index":36,"t":{"7":{"position":[[57,4]]},"1061":{"position":[[0,3]]}}}],["me!</button",{"_index":46,"t":{"7":{"position":[[178,12]]}}}],["mean",{"_index":2050,"t":{"633":{"position":[[1357,4]]},"959":{"position":[[952,4]]},"1152":{"position":[[765,4]]},"1234":{"position":[[29,4]]}}}],["measur",{"_index":1933,"t":{"616":{"position":[[647,7]]},"619":{"position":[[657,7]]},"623":{"position":[[175,7]]},"627":{"position":[[1214,7]]}}}],["median",{"_index":1336,"t":{"423":{"position":[[1351,6],[1481,6]]},"437":{"position":[[1003,6]]}}}],["mediat",{"_index":987,"t":{"286":{"position":[[419,8]]}}}],["medic",{"_index":507,"t":{"102":{"position":[[310,8]]}}}],["medicin",{"_index":1228,"t":{"382":{"position":[[124,8]]}}}],["medium",{"_index":1869,"t":{"593":{"position":[[54,6]]},"698":{"position":[[1797,6]]},"700":{"position":[[143,6],[364,6]]},"723":{"position":[[91,6]]},"784":{"position":[[25,6]]}}}],["megatronlm2",{"_index":2259,"t":{"696":{"position":[[1304,11]]}}}],["mem_em",{"_index":2644,"t":{"853":{"position":[[122,8]]}}}],["memmemmem",{"_index":2653,"t":{"855":{"position":[[436,9]]},"859":{"position":[[238,9],[361,9]]},"863":{"position":[[391,9],[661,9]]}}}],["memori",{"_index":1389,"t":{"427":{"position":[[51,6]]},"445":{"position":[[12,6],[77,6],[205,6]]},"619":{"position":[[413,6]]},"848":{"position":[[327,6]]},"850":{"position":[[1095,6],[1382,6],[1968,6]]},"855":{"position":[[419,6]]},"859":{"position":[[231,6],[637,6],[795,6]]},"861":{"position":[[46,6],[216,6],[274,6],[293,6]]},"863":{"position":[[572,6],[602,6]]},"870":{"position":[[155,6],[286,6]]},"963":{"position":[[485,6]]}}}],["mention",{"_index":2882,"t":{"949":{"position":[[439,7]]}}}],["meta",{"_index":2850,"t":{"919":{"position":[[754,4]]},"963":{"position":[[375,4]]}}}],["metadata",{"_index":3119,"t":{"1036":{"position":[[69,8]]},"1051":{"position":[[24,8]]}}}],["method",{"_index":154,"t":{"23":{"position":[[196,7]]},"47":{"position":[[431,6]]},"78":{"position":[[402,6]]},"313":{"position":[[67,6],[176,6]]},"396":{"position":[[766,6]]},"418":{"position":[[1734,6],[2107,6]]},"423":{"position":[[86,6]]},"427":{"position":[[584,6],[637,6],[3096,7]]},"443":{"position":[[130,6]]},"455":{"position":[[92,6]]},"484":{"position":[[20,7]]},"504":{"position":[[534,6]]},"517":{"position":[[37,6]]},"610":{"position":[[179,6]]},"614":{"position":[[536,6]]},"631":{"position":[[797,6]]},"646":{"position":[[240,6],[339,6]]},"653":{"position":[[147,6]]},"817":{"position":[[1860,6]]},"819":{"position":[[888,6]]},"836":{"position":[[147,6]]},"943":{"position":[[28,6]]},"949":{"position":[[377,6]]},"963":{"position":[[41,6]]},"975":{"position":[[375,6]]},"1160":{"position":[[657,6]]},"1194":{"position":[[36,6]]},"1240":{"position":[[106,6]]}}}],["metric",{"_index":1237,"t":{"384":{"position":[[275,6]]},"655":{"position":[[179,6]]},"659":{"position":[[199,8]]},"842":{"position":[[326,6]]},"844":{"position":[[422,6]]},"1144":{"position":[[155,6]]},"1150":{"position":[[261,6]]},"1152":{"position":[[252,6],[439,6],[2640,7],[2728,6]]},"1174":{"position":[[157,8]]},"1192":{"position":[[279,6]]},"1194":{"position":[[227,6]]}}}],["mgsm",{"_index":1234,"t":{"382":{"position":[[258,4]]},"384":{"position":[[175,4]]},"390":{"position":[[200,4]]}}}],["mha",{"_index":3453,"t":{"1140":{"position":[[104,5],[195,3]]},"1142":{"position":[[737,3]]}}}],["mha(x)=concat(head1,…,headh)wo,head)i=softmax(xwqi(xwki)⊤/dn)xwvi,\\text{mha",{"_index":3456,"t":{"1140":{"position":[[241,76]]}}}],["middl",{"_index":2723,"t":{"883":{"position":[[612,7],[646,6]]},"899":{"position":[[145,6],[193,6]]}}}],["midf1",{"_index":3398,"t":{"1115":{"position":[[207,5]]},"1117":{"position":[[47,5]]}}}],["min",{"_index":1800,"t":{"563":{"position":[[516,4]]},"686":{"position":[[2022,6]]},"1146":{"position":[[515,4]]}}}],["mine",{"_index":1133,"t":{"345":{"position":[[901,6],[1156,6]]},"682":{"position":[[419,6]]},"899":{"position":[[39,6]]},"901":{"position":[[1822,6]]}}}],["mini",{"_index":1125,"t":{"343":{"position":[[607,4],[662,4],[697,4]]},"635":{"position":[[505,4]]},"1152":{"position":[[1383,4]]}}}],["minigpt",{"_index":1669,"t":{"504":{"position":[[327,7]]},"521":{"position":[[21,7]]},"529":{"position":[[113,7]]}}}],["minigpt4",{"_index":1711,"t":{"525":{"position":[[0,8]]}}}],["minim",{"_index":1304,"t":{"418":{"position":[[1265,7]]}}}],["minima",{"_index":2215,"t":{"688":{"position":[[296,6]]},"870":{"position":[[121,6]]}}}],["minut",{"_index":81,"t":{"11":{"position":[[41,8]]},"1024":{"position":[[141,8]]}}}],["miss",{"_index":2707,"t":{"876":{"position":[[1042,6]]}}}],["mix",{"_index":637,"t":{"136":{"position":[[18,5]]},"138":{"position":[[303,6],[325,6],[340,6]]},"151":{"position":[[112,5]]},"188":{"position":[[239,5],[278,5]]},"418":{"position":[[1533,5],[2357,5]]},"421":{"position":[[168,5]]},"427":{"position":[[167,5],[190,5],[532,5],[646,5],[2555,5]]},"648":{"position":[[43,6]]},"825":{"position":[[562,7]]},"836":{"position":[[1908,6]]}}}],["mix&match",{"_index":178,"t":{"25":{"position":[[498,11]]},"27":{"position":[[258,9]]}}}],["mixtur",{"_index":1088,"t":{"328":{"position":[[437,8]]},"386":{"position":[[115,7]]},"388":{"position":[[23,7]]},"390":{"position":[[42,7]]},"418":{"position":[[1923,7]]},"423":{"position":[[267,7],[729,7]]},"429":{"position":[[210,7],[329,7]]},"431":{"position":[[116,7]]},"435":{"position":[[17,7]]},"648":{"position":[[120,7]]}}}],["mixup",{"_index":267,"t":{"49":{"position":[[550,5]]},"53":{"position":[[334,5]]},"78":{"position":[[580,6],[760,5]]}}}],["mkdir",{"_index":3227,"t":{"1075":{"position":[[51,5]]}}}],["mlm",{"_index":2276,"t":{"700":{"position":[[506,3]]}}}],["mlp",{"_index":434,"t":{"91":{"position":[[1090,3],[1367,3],[1462,3],[2398,3]]},"93":{"position":[[40,3]]},"482":{"position":[[132,3]]},"551":{"position":[[351,3]]},"565":{"position":[[94,3]]},"569":{"position":[[125,3],[227,3]]},"585":{"position":[[196,3]]},"688":{"position":[[598,3]]},"730":{"position":[[41,3],[166,3]]}}}],["mlpθ\\text{mlp}_\\thetamlp",{"_index":2413,"t":{"777":{"position":[[136,26],[344,26]]}}}],["mmlu",{"_index":1201,"t":{"368":{"position":[[357,6]]},"382":{"position":[[95,4]]},"384":{"position":[[0,4]]},"390":{"position":[[147,4]]},"396":{"position":[[581,4]]}}}],["mmm",{"_index":1039,"t":{"302":{"position":[[1093,3],[1125,3]]},"461":{"position":[[612,3]]},"465":{"position":[[334,3],[379,3]]},"1218":{"position":[[284,3],[307,3]]}}}],["mmota",{"_index":3397,"t":{"1115":{"position":[[199,5]]}}}],["mmotsa",{"_index":3400,"t":{"1117":{"position":[[31,7]]}}}],["mmotsp",{"_index":3401,"t":{"1117":{"position":[[39,7]]}}}],["mnli",{"_index":1866,"t":{"589":{"position":[[183,4]]},"642":{"position":[[65,4],[207,5]]},"1184":{"position":[[74,5],[240,4]]},"1190":{"position":[[361,4]]}}}],["modal",{"_index":720,"t":{"163":{"position":[[29,5]]},"165":{"position":[[148,5],[428,5],[903,5]]},"169":{"position":[[172,5],[260,5],[442,5],[511,5]]},"171":{"position":[[221,8],[371,8],[424,8],[493,8],[860,8]]},"174":{"position":[[406,8]]},"176":{"position":[[41,8],[282,5],[383,5],[499,5]]},"178":{"position":[[6,5]]},"180":{"position":[[258,5],[456,5],[549,5]]},"202":{"position":[[20,8],[124,8]]},"221":{"position":[[62,5]]},"279":{"position":[[141,8]]},"281":{"position":[[518,8],[1075,8],[1514,8],[1970,8]]},"286":{"position":[[390,5]]},"288":{"position":[[259,8]]},"292":{"position":[[48,8],[303,8]]},"300":{"position":[[1110,8]]},"313":{"position":[[125,5]]},"333":{"position":[[294,5]]},"341":{"position":[[153,5],[220,5]]},"345":{"position":[[91,10],[666,5]]},"347":{"position":[[109,5]]},"465":{"position":[[41,10],[861,5],[1189,5]]},"482":{"position":[[6,5]]},"484":{"position":[[159,5]]},"498":{"position":[[207,5]]},"502":{"position":[[656,5],[889,5]]},"504":{"position":[[296,5],[393,5],[686,5],[916,5],[1613,5],[2440,5]]},"510":{"position":[[6,5]]},"512":{"position":[[230,5]]},"519":{"position":[[68,5]]},"521":{"position":[[61,5],[468,5]]},"523":{"position":[[699,5]]},"525":{"position":[[261,5]]},"535":{"position":[[273,5]]},"537":{"position":[[69,5]]},"543":{"position":[[542,5]]},"961":{"position":[[36,5]]},"1087":{"position":[[1861,10]]},"1092":{"position":[[86,10]]},"1203":{"position":[[219,5]]}}}],["mode",{"_index":950,"t":{"279":{"position":[[15,5]]}}}],["model",{"_index":160,"t":{"25":{"position":[[111,5]]},"27":{"position":[[14,5]]},"38":{"position":[[317,5]]},"76":{"position":[[21,5]]},"95":{"position":[[75,5]]},"106":{"position":[[6,5]]},"149":{"position":[[149,5]]},"153":{"position":[[646,5]]},"155":{"position":[[83,5],[221,5],[360,5]]},"159":{"position":[[200,5],[258,5]]},"165":{"position":[[711,5]]},"169":{"position":[[40,5],[731,8],[759,8]]},"171":{"position":[[750,5]]},"188":{"position":[[35,5],[50,5]]},"229":{"position":[[273,5],[1092,5]]},"244":{"position":[[16,5],[307,5]]},"250":{"position":[[4,5]]},"271":{"position":[[228,5]]},"275":{"position":[[227,5]]},"279":{"position":[[391,5]]},"281":{"position":[[547,8],[1408,5],[1446,5],[1732,5],[2001,8]]},"288":{"position":[[188,7],[443,5]]},"300":{"position":[[852,8]]},"302":{"position":[[1221,5]]},"320":{"position":[[241,5]]},"330":{"position":[[380,6],[435,5]]},"349":{"position":[[344,5]]},"353":{"position":[[16,5],[233,5]]},"355":{"position":[[187,5]]},"362":{"position":[[12,6],[149,5]]},"366":{"position":[[149,5]]},"368":{"position":[[82,5],[593,6]]},"373":{"position":[[20,6]]},"396":{"position":[[331,5],[421,5],[452,8],[663,5],[715,5]]},"398":{"position":[[879,6]]},"400":{"position":[[107,5]]},"416":{"position":[[57,5],[590,5]]},"418":{"position":[[394,6],[447,6],[786,5],[1241,5],[1355,5],[1582,6],[1722,6],[1865,5]]},"421":{"position":[[56,5],[301,5]]},"423":{"position":[[67,5],[185,8]]},"427":{"position":[[2712,5],[2914,5],[3364,5],[3561,5]]},"431":{"position":[[208,8]]},"437":{"position":[[18,6]]},"441":{"position":[[79,5]]},"443":{"position":[[282,5]]},"445":{"position":[[27,5]]},"455":{"position":[[46,5],[132,5],[492,5],[603,5]]},"457":{"position":[[30,5],[111,5],[237,5],[968,5],[1030,5],[1165,5],[1196,6]]},"467":{"position":[[65,5],[114,5]]},"475":{"position":[[512,5]]},"484":{"position":[[39,6]]},"502":{"position":[[167,5],[289,5],[716,6]]},"504":{"position":[[31,5],[81,5],[151,5],[379,5],[494,5],[601,5],[669,5],[744,5],[1522,5],[2035,6],[2086,5],[2219,5],[2594,5]]},"525":{"position":[[29,5],[690,5]]},"531":{"position":[[37,5]]},"533":{"position":[[349,5]]},"535":{"position":[[40,5],[74,5],[189,6]]},"537":{"position":[[146,5],[468,5]]},"541":{"position":[[55,6]]},"543":{"position":[[200,5]]},"547":{"position":[[91,5],[422,5]]},"549":{"position":[[201,5],[376,6],[436,5],[577,5],[812,5],[872,5],[1220,5]]},"553":{"position":[[829,5],[851,5]]},"557":{"position":[[159,5]]},"589":{"position":[[198,5],[221,5]]},"604":{"position":[[65,5]]},"610":{"position":[[116,5]]},"614":{"position":[[28,5],[101,5]]},"616":{"position":[[31,6]]},"621":{"position":[[28,5],[111,5]]},"623":{"position":[[52,5]]},"627":{"position":[[388,5]]},"633":{"position":[[1128,5],[1333,5]]},"646":{"position":[[50,5]]},"657":{"position":[[34,5],[145,5],[224,5]]},"678":{"position":[[25,5]]},"680":{"position":[[131,5],[186,6],[265,6],[341,6],[556,5]]},"682":{"position":[[110,5],[239,5],[454,5]]},"692":{"position":[[241,5]]},"694":{"position":[[655,6],[752,5],[867,6],[926,6]]},"696":{"position":[[370,5],[464,5]]},"698":{"position":[[917,6],[1025,6],[1142,5],[1461,5],[1720,5],[1927,6]]},"700":{"position":[[35,5],[150,5],[577,5],[636,5],[684,5]]},"704":{"position":[[79,5],[115,5],[412,5]]},"707":{"position":[[75,5],[300,5]]},"711":{"position":[[25,5],[210,5]]},"713":{"position":[[106,5],[254,5],[608,5]]},"718":{"position":[[825,5]]},"723":{"position":[[44,5],[104,5]]},"727":{"position":[[200,5],[511,5]]},"738":{"position":[[38,5],[109,5]]},"742":{"position":[[115,5]]},"746":{"position":[[24,5]]},"759":{"position":[[46,6],[105,5]]},"761":{"position":[[46,5],[1430,5]]},"766":{"position":[[70,5]]},"784":{"position":[[369,5],[517,5]]},"815":{"position":[[62,5],[308,5],[445,5],[567,5]]},"817":{"position":[[75,5],[177,5],[224,5],[271,5],[336,5],[367,6],[549,5],[582,5],[635,5],[783,5],[875,5],[1163,5],[1260,5],[1703,5],[1771,5],[1815,5],[1945,5],[2375,5],[2490,5],[2629,5]]},"819":{"position":[[123,8],[734,5]]},"821":{"position":[[110,5]]},"823":{"position":[[718,8],[785,5],[1189,5],[1664,5]]},"825":{"position":[[7,5],[380,5]]},"827":{"position":[[9,5],[120,5],[177,5],[372,5],[496,5]]},"832":{"position":[[698,5]]},"834":{"position":[[177,5],[731,5]]},"836":{"position":[[660,5],[1098,5],[1240,5],[1401,5],[1477,5],[1732,5],[1938,5],[2007,5],[2283,5],[2398,5],[2491,5]]},"838":{"position":[[519,5],[1051,5],[1148,5]]},"840":{"position":[[0,5],[299,7]]},"842":{"position":[[1952,5]]},"844":{"position":[[135,5],[161,5],[480,5]]},"853":{"position":[[30,5],[77,5],[147,5]]},"855":{"position":[[293,5]]},"857":{"position":[[236,5]]},"859":{"position":[[22,5],[272,5]]},"861":{"position":[[247,5]]},"863":{"position":[[313,5],[497,5]]},"876":{"position":[[42,5],[224,5],[417,5]]},"889":{"position":[[184,5]]},"893":{"position":[[50,5]]},"895":{"position":[[142,6],[489,6]]},"963":{"position":[[360,5]]},"985":{"position":[[109,6]]},"989":{"position":[[19,6],[193,5],[450,5]]},"993":{"position":[[147,5],[207,5],[231,5]]},"1001":{"position":[[24,5],[457,8],[607,5],[1861,5]]},"1085":{"position":[[37,5]]},"1087":{"position":[[2815,5]]},"1135":{"position":[[27,6],[109,5],[856,5]]},"1137":{"position":[[444,5],[526,5],[567,5],[650,5],[810,5],[2437,6],[2853,5],[3872,6],[4410,6]]},"1140":{"position":[[17,5]]},"1150":{"position":[[282,5]]},"1160":{"position":[[132,5],[225,5]]},"1198":{"position":[[314,5]]},"1218":{"position":[[18,5],[278,5],[319,5]]}}}],["model'",{"_index":2592,"t":{"842":{"position":[[287,7]]}}}],["modif",{"_index":1291,"t":{"416":{"position":[[651,13]]},"431":{"position":[[703,13]]}}}],["modifi",{"_index":1390,"t":{"427":{"position":[[569,9]]},"1026":{"position":[[32,6]]},"1067":{"position":[[64,6]]},"1073":{"position":[[0,6]]},"1079":{"position":[[64,6]]}}}],["modil",{"_index":3253,"t":{"1092":{"position":[[22,6]]}}}],["modl",{"_index":3728,"t":{"1192":{"position":[[401,5]]}}}],["modul",{"_index":956,"t":{"279":{"position":[[350,6]]},"281":{"position":[[1340,6]]},"288":{"position":[[43,6]]},"328":{"position":[[281,7]]},"416":{"position":[[279,8]]},"457":{"position":[[818,6]]},"508":{"position":[[116,6]]},"512":{"position":[[53,6]]},"525":{"position":[[267,6]]},"551":{"position":[[129,6],[326,6]]},"569":{"position":[[55,6],[129,6]]},"585":{"position":[[200,6]]},"600":{"position":[[15,6]]},"811":{"position":[[597,6]]},"1087":{"position":[[1962,6],[1987,6]]},"1094":{"position":[[238,6],[308,6],[784,6]]},"1137":{"position":[[388,7],[417,7],[602,7],[2485,7],[2585,7],[2705,7],[3008,7],[3178,7]]},"1140":{"position":[[780,6]]},"1160":{"position":[[382,6],[395,6],[477,6],[496,6]]},"1192":{"position":[[165,6],[308,6]]}}}],["modular",{"_index":966,"t":{"281":{"position":[[982,7]]}}}],["module.export",{"_index":3125,"t":{"1036":{"position":[[318,14]]},"1067":{"position":[[123,14]]},"1073":{"position":[[83,14]]},"1079":{"position":[[123,14]]}}}],["moemori",{"_index":2669,"t":{"861":{"position":[[101,7]]}}}],["momentum",{"_index":289,"t":{"53":{"position":[[154,8],[181,8]]},"80":{"position":[[48,8]]},"343":{"position":[[580,8],[640,8],[754,8],[799,8]]},"345":{"position":[[929,8]]}}}],["mono",{"_index":1172,"t":{"362":{"position":[[132,4],[182,4]]}}}],["more",{"_index":3064,"t":{"1024":{"position":[[114,4],[136,4]]},"1061":{"position":[[32,4]]}}}],["morn",{"_index":2716,"t":{"879":{"position":[[570,8]]}}}],["mos&vi",{"_index":3364,"t":{"1099":{"position":[[1276,7]]}}}],["mot",{"_index":3244,"t":{"1087":{"position":[[205,6],[251,7],[1484,4],[1489,5]]},"1090":{"position":[[116,4],[121,4]]},"1096":{"position":[[1423,4],[1428,4]]},"1115":{"position":[[0,3]]},"1117":{"position":[[0,3],[20,4]]}}}],["mota",{"_index":3395,"t":{"1115":{"position":[[123,7]]}}}],["mothod",{"_index":1063,"t":{"313":{"position":[[160,6]]}}}],["move",{"_index":299,"t":{"53":{"position":[[269,6]]},"844":{"position":[[486,6],[508,4]]},"1152":{"position":[[2150,6]]},"1165":{"position":[[531,6]]}}}],["movi",{"_index":2285,"t":{"713":{"position":[[463,8]]},"718":{"position":[[230,7]]},"879":{"position":[[375,6]]},"883":{"position":[[335,7],[381,6],[410,6],[439,7]]}}}],["mp",{"_index":2256,"t":{"696":{"position":[[554,4],[683,3],[1175,2]]}}}],["mp+ft",{"_index":2258,"t":{"696":{"position":[[1228,5]]},"704":{"position":[[258,5],[288,5],[312,5]]}}}],["mprc",{"_index":2585,"t":{"838":{"position":[[823,4]]}}}],["mpt",{"_index":1929,"t":{"614":{"position":[[303,5]]},"616":{"position":[[769,5],[1323,3],[1471,3],[1548,3]]},"623":{"position":[[238,3]]},"625":{"position":[[547,3]]},"627":{"position":[[1415,3]]},"629":{"position":[[0,3]]},"635":{"position":[[884,3]]},"639":{"position":[[23,3]]},"642":{"position":[[0,3]]},"646":{"position":[[0,3]]},"648":{"position":[[99,3],[234,3],[299,3]]},"651":{"position":[[14,3]]},"653":{"position":[[122,3],[197,3]]},"655":{"position":[[170,3]]},"657":{"position":[[51,3],[75,3],[161,3]]},"659":{"position":[[0,3],[315,3]]},"662":{"position":[[25,3],[250,3]]},"672":{"position":[[198,3],[248,3]]}}}],["mpˉ​i​=∑m=1m​pim​/m",{"_index":3788,"t":{"1218":{"position":[[408,19]]}}}],["mrpc",{"_index":1864,"t":{"589":{"position":[[160,5]]},"642":{"position":[[201,5]]},"838":{"position":[[892,5],[1035,4]]}}}],["mrqa",{"_index":2101,"t":{"642":{"position":[[231,4]]},"838":{"position":[[323,4]]}}}],["ms",{"_index":654,"t":{"143":{"position":[[31,2]]}}}],["msa",{"_index":466,"t":{"91":{"position":[[2185,5]]}}}],["mse",{"_index":2124,"t":{"664":{"position":[[231,3]]}}}],["msrm_{sr}msr",{"_index":2646,"t":{"853":{"position":[[222,13]]}}}],["much",{"_index":3063,"t":{"1024":{"position":[[109,4]]},"1030":{"position":[[503,4]]}}}],["muffin",{"_index":1207,"t":{"373":{"position":[[139,6]]},"377":{"position":[[0,7]]},"386":{"position":[[81,7]]}}}],["multi",{"_index":436,"t":{"91":{"position":[[1339,5],[2164,5]]},"155":{"position":[[210,5]]},"157":{"position":[[166,5],[364,5]]},"159":{"position":[[182,5]]},"163":{"position":[[23,5]]},"165":{"position":[[142,5],[422,5],[897,5]]},"169":{"position":[[86,5],[166,5],[254,5],[436,5],[505,5]]},"176":{"position":[[276,5],[377,5],[493,5]]},"178":{"position":[[0,5]]},"180":{"position":[[252,5],[450,5]]},"206":{"position":[[203,5]]},"221":{"position":[[56,5]]},"231":{"position":[[14,5],[217,5]]},"257":{"position":[[45,5]]},"271":{"position":[[4,5]]},"286":{"position":[[384,5]]},"313":{"position":[[119,5]]},"368":{"position":[[323,5]]},"375":{"position":[[123,5]]},"386":{"position":[[123,5]]},"455":{"position":[[486,5]]},"457":{"position":[[962,5],[1024,5]]},"463":{"position":[[2111,5]]},"465":{"position":[[221,5],[855,5],[1183,5]]},"482":{"position":[[0,5],[31,5]]},"484":{"position":[[153,5]]},"498":{"position":[[201,5]]},"502":{"position":[[650,5],[883,5]]},"504":{"position":[[290,5],[387,5],[680,5],[910,5],[1607,5],[2434,5]]},"510":{"position":[[0,5],[87,5]]},"512":{"position":[[224,5]]},"519":{"position":[[62,5]]},"521":{"position":[[55,5],[462,5]]},"523":{"position":[[693,5]]},"525":{"position":[[255,5]]},"535":{"position":[[267,5]]},"537":{"position":[[63,5]]},"543":{"position":[[331,5],[536,5]]},"672":{"position":[[95,5]]},"734":{"position":[[0,5],[92,5]]},"744":{"position":[[0,5]]},"748":{"position":[[327,5]]},"753":{"position":[[50,5]]},"825":{"position":[[550,5]]},"827":{"position":[[190,6],[239,5],[485,5]]},"832":{"position":[[460,5]]},"840":{"position":[[499,5]]},"844":{"position":[[525,5]]},"857":{"position":[[553,5]]},"859":{"position":[[382,5]]},"905":{"position":[[126,5]]},"915":{"position":[[0,5]]},"961":{"position":[[30,5]]},"971":{"position":[[126,5]]},"1087":{"position":[[212,5]]},"1096":{"position":[[284,5],[597,5]]},"1117":{"position":[[63,5]]},"1140":{"position":[[83,5]]},"1203":{"position":[[213,5]]},"1226":{"position":[[78,5]]}}}],["multimod",{"_index":952,"t":{"279":{"position":[[185,10]]},"284":{"position":[[43,10]]},"288":{"position":[[137,11]]},"324":{"position":[[213,10]]},"347":{"position":[[76,10],[447,10]]}}}],["multipl",{"_index":316,"t":{"58":{"position":[[184,8]]},"130":{"position":[[722,8]]},"140":{"position":[[627,8]]},"349":{"position":[[807,8]]},"379":{"position":[[194,8]]},"418":{"position":[[1966,8]]},"423":{"position":[[1253,8]]},"425":{"position":[[1217,8]]},"427":{"position":[[761,14],[917,14],[2542,8],[2687,14],[2790,14],[2817,14],[3315,14]]},"549":{"position":[[3,8]]},"614":{"position":[[309,8],[468,14]]},"616":{"position":[[568,8],[1192,14]]},"621":{"position":[[36,8],[76,8]]},"627":{"position":[[1157,8],[1285,8]]},"629":{"position":[[356,14]]},"674":{"position":[[38,8]]},"836":{"position":[[2313,8]]},"840":{"position":[[223,8]]},"887":{"position":[[113,8]]},"893":{"position":[[302,8]]},"909":{"position":[[329,8],[685,8]]},"917":{"position":[[58,8]]},"949":{"position":[[489,8]]},"953":{"position":[[163,8]]},"955":{"position":[[231,8]]},"971":{"position":[[244,8]]},"975":{"position":[[900,8],[1062,8]]},"1063":{"position":[[22,8]]},"1087":{"position":[[180,8]]},"1115":{"position":[[89,8]]},"1137":{"position":[[155,8]]}}}],["multirc",{"_index":1009,"t":{"300":{"position":[[607,7]]},"642":{"position":[[146,8]]},"698":{"position":[[148,7]]},"700":{"position":[[89,7]]}}}],["multitask",{"_index":1299,"t":{"418":{"position":[[418,9],[1572,9],[1913,9]]},"423":{"position":[[257,9],[710,9]]},"429":{"position":[[200,9],[319,9]]},"431":{"position":[[106,9]]},"557":{"position":[[258,9]]},"614":{"position":[[204,9],[279,9]]},"616":{"position":[[745,9],[778,9],[1351,9]]},"621":{"position":[[0,9],[153,9],[251,9],[332,9]]},"623":{"position":[[274,9]]},"633":{"position":[[0,9]]},"635":{"position":[[213,9],[380,9],[1036,9]]},"670":{"position":[[64,9]]},"674":{"position":[[0,9]]}}}],["mutipl",{"_index":889,"t":{"240":{"position":[[201,7]]},"975":{"position":[[1044,7]]}}}],["mutli",{"_index":792,"t":{"180":{"position":[[543,5]]}}}],["mutlipl",{"_index":2791,"t":{"905":{"position":[[417,8]]},"1129":{"position":[[47,8]]}}}],["myreactpag",{"_index":3143,"t":{"1040":{"position":[[159,13]]}}}],["mϕ[i])m_{\\phi}[i])mϕ​[i",{"_index":2773,"t":{"901":{"position":[[894,25]]}}}],["mϕm_{\\phi}m",{"_index":2767,"t":{"901":{"position":[[638,13],[933,13]]}}}],["n",{"_index":247,"t":{"49":{"position":[[138,1]]},"504":{"position":[[1441,1]]},"819":{"position":[[1836,2]]},"1087":{"position":[[1683,1],[2221,1]]},"1096":{"position":[[631,1],[655,1]]},"1127":{"position":[[147,1],[176,1]]},"1148":{"position":[[2277,2]]}}}],["n/a",{"_index":2975,"t":{"983":{"position":[[563,4],[861,5]]}}}],["n=32n",{"_index":1638,"t":{"475":{"position":[[216,5]]}}}],["n=hw/p2n",{"_index":418,"t":{"91":{"position":[[362,8]]}}}],["n_{i",{"_index":979,"t":{"286":{"position":[[193,7]]}}}],["n_{k=1}e={λk​}k=1n",{"_index":3550,"t":{"1148":{"position":[[661,23]]}}}],["n_{k=1}p={pk​}k=1n",{"_index":3548,"t":{"1148":{"position":[[600,23]]}}}],["n_{k=1}q={qk​}k=1n",{"_index":3553,"t":{"1148":{"position":[[716,22]]}}}],["na",{"_index":146,"t":{"23":{"position":[[42,5]]},"25":{"position":[[390,3]]},"27":{"position":[[388,5]]},"38":{"position":[[65,3]]},"44":{"position":[[72,3]]},"76":{"position":[[15,3]]},"78":{"position":[[941,3]]}}}],["name",{"_index":835,"t":{"197":{"position":[[58,6]]},"360":{"position":[[219,4]]},"713":{"position":[[1523,5]]},"716":{"position":[[152,5]]},"740":{"position":[[55,5]]},"761":{"position":[[1019,6]]},"825":{"position":[[637,5]]},"827":{"position":[[302,4]]},"909":{"position":[[535,5]]},"949":{"position":[[523,5],[556,5]]},"1030":{"position":[[125,5],[259,5]]},"1085":{"position":[[125,6]]},"1087":{"position":[[348,5],[1422,5]]},"1090":{"position":[[143,5]]},"1092":{"position":[[242,5]]},"1096":{"position":[[1756,4]]}}}],["narrativeqa",{"_index":2897,"t":{"953":{"position":[[221,13]]}}}],["natur",{"_index":505,"t":{"102":{"position":[[274,7]]},"130":{"position":[[187,7]]},"375":{"position":[[144,7]]},"423":{"position":[[810,7]]},"537":{"position":[[591,7]]},"573":{"position":[[44,7]]},"619":{"position":[[559,7]]},"642":{"position":[[238,7]]},"678":{"position":[[33,7]]},"680":{"position":[[197,7],[276,7]]},"711":{"position":[[125,7]]},"713":{"position":[[368,7]]},"718":{"position":[[487,7]]},"759":{"position":[[173,7]]},"761":{"position":[[725,7]]},"773":{"position":[[469,7]]},"821":{"position":[[389,7]]},"823":{"position":[[860,7],[918,7],[1515,7],[1550,7]]},"842":{"position":[[32,7]]},"883":{"position":[[688,7]]},"895":{"position":[[352,7],[410,7]]},"997":{"position":[[172,7]]},"1135":{"position":[[761,7],[811,7]]},"1163":{"position":[[158,7]]}}}],["nature/sci",{"_index":2600,"t":{"842":{"position":[[1905,16]]}}}],["navbar",{"_index":3076,"t":{"1026":{"position":[[93,6]]},"1067":{"position":[[157,7],[264,7]]},"1079":{"position":[[157,7],[257,7]]}}}],["navig",{"_index":127,"t":{"19":{"position":[[187,8]]},"1032":{"position":[[73,10]]},"1067":{"position":[[3,8]]},"1079":{"position":[[3,8]]}}}],["near",{"_index":775,"t":{"178":{"position":[[341,4]]}}}],["nearest",{"_index":2590,"t":{"842":{"position":[[260,7],[456,7],[1291,7],[1397,7],[1585,7]]}}}],["necessari",{"_index":116,"t":{"17":{"position":[[350,9]]}}}],["need",{"_index":117,"t":{"17":{"position":[[377,4]]},"19":{"position":[[179,4]]},"300":{"position":[[13,4]]}}}],["neg",{"_index":1113,"t":{"343":{"position":[[95,8],[552,8]]},"345":{"position":[[827,8],[865,8],[892,8],[1016,8],[1048,8],[1145,8],[1166,8]]},"879":{"position":[[439,8]]},"919":{"position":[[470,8]]}}}],["negat",{"_index":2874,"t":{"943":{"position":[[473,9]]}}}],["negative\\n",{"_index":2971,"t":{"983":{"position":[[500,10],[669,10]]}}}],["neighbor",{"_index":2591,"t":{"842":{"position":[[268,9],[464,9],[1299,9],[1405,9],[1593,9]]}}}],["neighborhood",{"_index":2214,"t":{"688":{"position":[[237,12]]}}}],["neo",{"_index":1078,"t":{"322":{"position":[[41,3]]}}}],["ner",{"_index":2804,"t":{"909":{"position":[[560,5]]},"949":{"position":[[719,3]]},"975":{"position":[[533,4]]}}}],["network",{"_index":149,"t":{"23":{"position":[[103,7]]},"78":{"position":[[497,7]]},"80":{"position":[[77,7]]},"116":{"position":[[565,7]]},"155":{"position":[[143,7],[171,7]]},"165":{"position":[[302,7],[748,7]]},"296":{"position":[[118,7]]},"328":{"position":[[100,7]]},"427":{"position":[[1326,7],[1764,7],[1871,7],[3222,8]]},"465":{"position":[[426,7]]},"482":{"position":[[115,7]]},"484":{"position":[[135,7]]},"563":{"position":[[3,7]]},"619":{"position":[[365,7]]},"633":{"position":[[1713,8]]},"680":{"position":[[842,8]]},"694":{"position":[[818,7]]},"773":{"position":[[1017,7]]},"777":{"position":[[128,7]]},"821":{"position":[[193,7]]},"836":{"position":[[761,7]]},"876":{"position":[[216,7],[258,7]]},"901":{"position":[[844,7]]},"1137":{"position":[[2658,8]]},"1205":{"position":[[252,7]]}}}],["netwrok",{"_index":2575,"t":{"836":{"position":[[2159,7]]}}}],["neural",{"_index":143,"t":{"23":{"position":[[16,6]]},"27":{"position":[[361,6]]},"296":{"position":[[160,6]]},"300":{"position":[[76,6]]},"349":{"position":[[398,6]]},"680":{"position":[[835,6]]},"766":{"position":[[54,6],[592,6]]},"777":{"position":[[121,6]]},"876":{"position":[[209,6]]},"899":{"position":[[376,6]]},"901":{"position":[[837,6]]},"975":{"position":[[357,6]]},"1137":{"position":[[381,6],[595,6]]}}}],["neuro",{"_index":879,"t":{"229":{"position":[[335,5]]}}}],["neutral",{"_index":2318,"t":{"751":{"position":[[336,9]]}}}],["new",{"_index":83,"t":{"13":{"position":[[26,3]]},"17":{"position":[[11,3]]},"138":{"position":[[500,3]]},"229":{"position":[[421,3]]},"416":{"position":[[329,3],[521,3],[557,3],[612,3]]},"418":{"position":[[283,3],[1249,3]]},"421":{"position":[[64,3],[221,3],[276,3]]},"427":{"position":[[107,3],[2069,3]]},"429":{"position":[[288,3]]},"447":{"position":[[458,3]]},"455":{"position":[[385,3]]},"463":{"position":[[995,3]]},"508":{"position":[[229,3]]},"515":{"position":[[87,3]]},"549":{"position":[[147,3]]},"616":{"position":[[1133,3]]},"653":{"position":[[49,3]]},"793":{"position":[[351,3],[400,3]]},"821":{"position":[[800,3]]},"1020":{"position":[[78,3]]},"1030":{"position":[[520,3]]},"1034":{"position":[[107,3]]},"1040":{"position":[[261,3]]},"1042":{"position":[[123,3]]},"1152":{"position":[[248,3]]},"1194":{"position":[[212,3]]}}}],["newli",{"_index":125,"t":{"19":{"position":[[141,5]]},"515":{"position":[[885,5]]},"519":{"position":[[548,5]]}}}],["newsqa",{"_index":2103,"t":{"642":{"position":[[267,6]]}}}],["next",{"_index":776,"t":{"180":{"position":[[14,4]]},"355":{"position":[[220,4]]},"398":{"position":[[1056,4]]},"408":{"position":[[53,4]]},"435":{"position":[[186,4]]},"766":{"position":[[811,4]]},"773":{"position":[[366,4]]},"1085":{"position":[[48,4]]}}}],["nfnet",{"_index":162,"t":{"25":{"position":[[121,6]]},"27":{"position":[[126,6]]}}}],["niv2",{"_index":1212,"t":{"373":{"position":[[177,4]]},"377":{"position":[[16,4]]},"386":{"position":[[97,4]]}}}],["nk=1,…,n",{"_index":3539,"t":{"1148":{"position":[[329,8],[1159,8]]}}}],["nl",{"_index":2686,"t":{"870":{"position":[[11,2]]}}}],["nlg",{"_index":1832,"t":{"573":{"position":[[93,6]]},"655":{"position":[[46,3],[127,3],[214,3],[258,3]]},"680":{"position":[[225,5]]},"759":{"position":[[201,5]]},"761":{"position":[[527,3]]},"773":{"position":[[246,3]]},"1137":{"position":[[4526,3]]},"1156":{"position":[[115,3]]},"1177":{"position":[[0,3]]},"1184":{"position":[[216,3]]},"1194":{"position":[[370,3]]}}}],["nli",{"_index":2136,"t":{"672":{"position":[[141,3]]}}}],["nlp",{"_index":373,"t":{"84":{"position":[[0,3]]},"86":{"position":[[262,3]]},"91":{"position":[[15,5]]},"118":{"position":[[0,3]]},"124":{"position":[[0,3]]},"190":{"position":[[294,3]]},"281":{"position":[[355,3]]},"330":{"position":[[1517,3]]},"418":{"position":[[17,3]]},"557":{"position":[[75,5]]},"639":{"position":[[8,3]]},"672":{"position":[[12,3]]},"674":{"position":[[342,3]]},"721":{"position":[[39,3]]},"874":{"position":[[0,3]]},"876":{"position":[[203,3],[334,3]]},"879":{"position":[[0,3]]},"951":{"position":[[114,3]]},"959":{"position":[[14,3]]},"961":{"position":[[6,3]]},"963":{"position":[[1404,3],[1526,3]]},"969":{"position":[[341,3]]},"1001":{"position":[[1260,3]]},"1006":{"position":[[79,3]]},"1008":{"position":[[124,3]]},"1135":{"position":[[80,3]]},"1137":{"position":[[22,3],[133,3]]},"1205":{"position":[[124,3]]}}}],["nlpedia",{"_index":2701,"t":{"874":{"position":[[541,7]]}}}],["nlu",{"_index":1831,"t":{"573":{"position":[[75,6]]},"593":{"position":[[7,3]]},"655":{"position":[[0,3],[208,3],[245,3]]},"678":{"position":[[64,5]]},"680":{"position":[[307,5],[434,3],[580,3],[931,3],[1210,3],[1630,3]]},"688":{"position":[[1204,3]]},"690":{"position":[[0,3],[77,3]]},"698":{"position":[[53,3],[972,3]]},"700":{"position":[[221,3],[644,3]]},"702":{"position":[[1186,3]]},"704":{"position":[[13,3]]},"707":{"position":[[83,3],[237,3]]},"711":{"position":[[156,5],[351,3],[471,3]]},"713":{"position":[[24,3],[1049,3],[1118,3]]},"716":{"position":[[0,3]]},"718":{"position":[[478,3]]},"725":{"position":[[37,3],[351,3]]},"730":{"position":[[87,3]]},"732":{"position":[[47,3]]},"738":{"position":[[46,3]]},"740":{"position":[[14,3]]},"742":{"position":[[83,3]]},"761":{"position":[[521,3]]},"817":{"position":[[2173,3]]},"825":{"position":[[460,3]]},"1137":{"position":[[4426,3]]},"1156":{"position":[[78,3]]},"1163":{"position":[[50,3]]},"1194":{"position":[[360,4]]}}}],["nn.embedding(n",{"_index":3324,"t":{"1096":{"position":[[830,15]]},"1127":{"position":[[54,15]]}}}],["nnn",{"_index":1364,"t":{"425":{"position":[[951,3],[985,3]]},"437":{"position":[[174,3],[493,3]]},"461":{"position":[[30,3]]},"504":{"position":[[1452,3]]},"819":{"position":[[1437,3]]},"840":{"position":[[131,3],[274,3],[408,3]]},"1096":{"position":[[510,3],[966,3],[1488,3]]},"1104":{"position":[[263,3]]},"1148":{"position":[[338,3]]},"1160":{"position":[[807,3]]},"1226":{"position":[[125,3]]}}}],["nocap",{"_index":827,"t":{"193":{"position":[[78,6]]},"195":{"position":[[116,6]]}}}],["node.j",{"_index":88,"t":{"15":{"position":[[0,7],[48,8]]}}}],["nodel",{"_index":3409,"t":{"1135":{"position":[[626,5]]}}}],["nois",{"_index":841,"t":{"204":{"position":[[92,5]]},"206":{"position":[[23,5],[83,5]]},"457":{"position":[[475,5]]}}}],["noisi",{"_index":542,"t":{"110":{"position":[[89,5]]},"165":{"position":[[959,5]]},"1200":{"position":[[1434,5]]},"1203":{"position":[[112,5]]}}}],["nomal",{"_index":229,"t":{"38":{"position":[[336,9]]}}}],["non",{"_index":216,"t":{"35":{"position":[[93,3]]},"91":{"position":[[1473,3]]},"153":{"position":[[152,3],[529,3]]},"159":{"position":[[584,3]]},"178":{"position":[[159,3]]},"211":{"position":[[76,3]]},"386":{"position":[[428,3]]},"392":{"position":[[60,3],[128,3],[227,3],[330,3],[387,3]]},"396":{"position":[[494,3]]},"404":{"position":[[45,3],[63,3],[149,3],[192,3],[281,3]]},"408":{"position":[[30,3]]},"819":{"position":[[862,3]]},"834":{"position":[[637,3],[678,3]]},"870":{"position":[[103,3],[343,3]]},"977":{"position":[[164,3]]}}}],["none",{"_index":2978,"t":{"983":{"position":[[869,6]]}}}],["noninvas",{"_index":2156,"t":{"684":{"position":[[48,13]]}}}],["nonlinear",{"_index":1421,"t":{"427":{"position":[[1879,12]]},"585":{"position":[[109,12]]}}}],["norm",{"_index":291,"t":{"53":{"position":[[176,4]]},"502":{"position":[[236,6]]},"519":{"position":[[541,4]]},"608":{"position":[[288,4]]}}}],["normal",{"_index":165,"t":{"25":{"position":[[144,13]]},"91":{"position":[[2142,13]]},"104":{"position":[[248,13],[270,13]]},"169":{"position":[[126,7]]},"343":{"position":[[492,13]]},"384":{"position":[[256,10]]},"396":{"position":[[349,10]]},"398":{"position":[[412,13]]},"418":{"position":[[2020,13]]},"425":{"position":[[1402,13],[1433,13],[1554,13],[1595,10],[1682,10],[1939,10]]},"427":{"position":[[3699,13]]},"431":{"position":[[316,10]]},"449":{"position":[[204,13]]},"504":{"position":[[1799,14]]},"515":{"position":[[337,13]]},"531":{"position":[[164,13]]},"604":{"position":[[1134,10]]},"606":{"position":[[34,10]]},"633":{"position":[[1305,13]]},"784":{"position":[[810,13]]},"1001":{"position":[[1078,13]]},"1111":{"position":[[113,10]]},"1140":{"position":[[1115,13]]}}}],["nositi",{"_index":3741,"t":{"1200":{"position":[[1521,6]]}}}],["notat",{"_index":1403,"t":{"427":{"position":[[1024,9]]},"768":{"position":[[245,8]]}}}],["notin",{"_index":2410,"t":{"775":{"position":[[1217,6]]}}}],["noun",{"_index":1000,"t":{"298":{"position":[[84,4]]}}}],["novel",{"_index":1305,"t":{"418":{"position":[[1802,6]]}}}],["now",{"_index":3110,"t":{"1030":{"position":[[537,3]]},"1034":{"position":[[123,3]]},"1040":{"position":[[273,3]]},"1042":{"position":[[135,3]]},"1047":{"position":[[70,3],[116,3]]},"1065":{"position":[[173,3]]},"1079":{"position":[[237,3]]}}}],["npm",{"_index":105,"t":{"17":{"position":[[151,3]]},"19":{"position":[[42,3],[220,3]]},"1046":{"position":[[32,3]]},"1047":{"position":[[36,3]]},"1065":{"position":[[39,3]]},"1077":{"position":[[38,3]]},"1081":{"position":[[39,3],[123,3]]}}}],["nr=b(0)/n",{"_index":3660,"t":{"1154":{"position":[[453,9]]}}}],["nucleu",{"_index":644,"t":{"140":{"position":[[114,7]]}}}],["null",{"_index":2865,"t":{"937":{"position":[[377,4]]}}}],["number",{"_index":1195,"t":{"366":{"position":[[120,6]]},"465":{"position":[[346,6]]},"504":{"position":[[1464,6]]},"583":{"position":[[291,6]]},"637":{"position":[[188,6],[361,6],[448,6]]}}}],["nvidia",{"_index":819,"t":{"188":{"position":[[473,6]]},"441":{"position":[[461,6]]},"451":{"position":[[552,6]]},"1158":{"position":[[85,6]]}}}],["o(min⁡(d1,d2)d1d2)o(\\min",{"_index":3527,"t":{"1146":{"position":[[1245,24]]}}}],["obama",{"_index":2380,"t":{"773":{"position":[[87,6]]}}}],["obj",{"_index":2251,"t":{"694":{"position":[[889,4],[948,4]]}}}],["object",{"_index":200,"t":{"27":{"position":[[416,6]]},"124":{"position":[[275,6]]},"126":{"position":[[389,6],[886,6],[1054,6]]},"128":{"position":[[137,6]]},"130":{"position":[[33,6],[479,6],[513,6],[579,6],[731,6]]},"132":{"position":[[409,6]]},"143":{"position":[[102,6],[139,6],[391,6]]},"147":{"position":[[326,6]]},"149":{"position":[[132,6]]},"151":{"position":[[0,6]]},"153":{"position":[[0,6]]},"155":{"position":[[105,9],[685,6]]},"157":{"position":[[40,6],[203,6]]},"169":{"position":[[616,7],[639,6]]},"171":{"position":[[313,6]]},"174":{"position":[[244,6]]},"223":{"position":[[57,6]]},"298":{"position":[[104,6]]},"328":{"position":[[424,10],[451,10]]},"333":{"position":[[151,10],[374,9]]},"347":{"position":[[534,9]]},"396":{"position":[[55,9],[253,9],[461,9]]},"398":{"position":[[1078,9]]},"406":{"position":[[80,10]]},"408":{"position":[[75,9]]},"423":{"position":[[194,9]]},"431":{"position":[[177,9]]},"504":{"position":[[2395,6]]},"553":{"position":[[16,9],[373,9]]},"680":{"position":[[94,10]]},"696":{"position":[[628,6]]},"770":{"position":[[122,9]]},"775":{"position":[[911,9]]},"823":{"position":[[78,9],[685,9],[1494,9]]},"834":{"position":[[29,6],[101,9],[509,9],[1041,9]]},"876":{"position":[[470,9],[510,9],[565,9],[882,6]]},"1001":{"position":[[1361,9]]},"1085":{"position":[[609,7],[743,6]]},"1087":{"position":[[66,6],[189,6],[218,6],[487,6],[584,6],[613,6],[1049,6],[1127,6],[1437,7],[1688,6],[2162,6],[2299,6]]},"1090":{"position":[[75,6],[594,6]]},"1096":{"position":[[660,6],[701,6],[1120,6]]},"1099":{"position":[[90,6],[736,6],[1007,6]]},"1104":{"position":[[246,6]]},"1107":{"position":[[73,6]]},"1115":{"position":[[98,6]]},"1119":{"position":[[69,6]]},"1121":{"position":[[57,6]]},"1125":{"position":[[345,6],[427,6]]},"1127":{"position":[[155,6]]},"1148":{"position":[[857,9]]},"1203":{"position":[[555,6]]},"1207":{"position":[[202,6]]}}}],["object365",{"_index":3344,"t":{"1099":{"position":[[113,9],[134,9]]},"1104":{"position":[[309,9]]}}}],["objective(ϕ)=e(x,y)∼dπϕrl[rθ(x,y)−βlog(πϕrl(i",{"_index":3026,"t":{"1001":{"position":[[1400,45]]}}}],["objects365dataset",{"_index":662,"t":{"143":{"position":[[370,17]]}}}],["occlus",{"_index":621,"t":{"130":{"position":[[1487,10]]}}}],["ocr",{"_index":744,"t":{"169":{"position":[[590,3]]},"504":{"position":[[2067,3]]},"525":{"position":[[290,3],[413,3]]},"541":{"position":[[219,3]]}}}],["odot",{"_index":1395,"t":{"427":{"position":[[807,5],[894,7],[1046,5],[1640,5],[1678,5],[1798,5],[2862,5],[2877,5]]}}}],["offer",{"_index":3065,"t":{"1024":{"position":[[122,6]]}}}],["offici",{"_index":3074,"t":{"1026":{"position":[[9,8]]}}}],["oiou",{"_index":3378,"t":{"1109":{"position":[[93,6]]}}}],["ok",{"_index":1054,"t":{"309":{"position":[[43,2]]},"316":{"position":[[53,3]]},"318":{"position":[[141,2]]},"885":{"position":[[135,5]]}}}],["okvqa",{"_index":960,"t":{"279":{"position":[[589,5]]},"309":{"position":[[74,5]]},"318":{"position":[[152,5]]},"320":{"position":[[167,5]]}}}],["omega",{"_index":2684,"t":{"863":{"position":[[694,8]]}}}],["on",{"_index":908,"t":{"244":{"position":[[593,3]]},"248":{"position":[[182,3]]},"368":{"position":[[399,3]]},"384":{"position":[[109,4]]},"390":{"position":[[389,3]]},"457":{"position":[[753,3]]},"627":{"position":[[46,3]]},"631":{"position":[[440,3]]},"674":{"position":[[211,3]]},"773":{"position":[[543,3]]},"815":{"position":[[434,3]]},"832":{"position":[[424,3]]},"1077":{"position":[[215,3]]},"1137":{"position":[[3570,4]]}}}],["onc",{"_index":3237,"t":{"1081":{"position":[[117,5]]}}}],["onclick",{"_index":43,"t":{"7":{"position":[[131,11]]},"1061":{"position":[[269,11]]}}}],["ood",{"_index":937,"t":{"269":{"position":[[391,5]]},"271":{"position":[[198,3]]}}}],["open",{"_index":134,"t":{"19":{"position":[[363,4]]},"190":{"position":[[419,4],[444,4]]},"333":{"position":[[46,4]]},"398":{"position":[[811,4]]},"502":{"position":[[60,4],[872,4]]},"504":{"position":[[899,4]]},"780":{"position":[[164,4]]}}}],["openai",{"_index":2987,"t":{"987":{"position":[[120,6]]},"995":{"position":[[13,6]]}}}],["openapi",{"_index":3002,"t":{"995":{"position":[[307,7]]}}}],["openbookqa",{"_index":2133,"t":{"672":{"position":[[112,11]]}}}],["opt",{"_index":796,"t":{"183":{"position":[[161,3]]},"281":{"position":[[1719,3]]},"304":{"position":[[614,4]]},"311":{"position":[[316,3]]},"322":{"position":[[10,3]]},"324":{"position":[[62,3]]}}}],["optim",{"_index":286,"t":{"53":{"position":[[127,9]]},"78":{"position":[[258,7]]},"188":{"position":[[0,9]]},"379":{"position":[[181,9],[321,7]]},"427":{"position":[[3529,12]]},"431":{"position":[[454,9]]},"549":{"position":[[990,9],[1066,9]]},"625":{"position":[[473,7]]},"680":{"position":[[891,7]]},"688":{"position":[[275,9]]},"694":{"position":[[613,7],[1080,9]]},"698":{"position":[[1239,9]]},"702":{"position":[[4,7],[135,7],[530,7]]},"711":{"position":[[479,9]]},"713":{"position":[[178,9]]},"784":{"position":[[143,9]]},"825":{"position":[[804,9]]},"827":{"position":[[95,10]]},"834":{"position":[[682,7]]},"870":{"position":[[23,12],[56,12],[107,7]]},"911":{"position":[[42,7]]},"989":{"position":[[478,12]]},"1001":{"position":[[1128,12]]},"1104":{"position":[[273,10]]},"1135":{"position":[[423,7]]},"1172":{"position":[[417,9]]},"1205":{"position":[[181,12]]},"1211":{"position":[[80,12]]}}}],["optimis",{"_index":811,"t":{"188":{"position":[[121,9]]}}}],["option",{"_index":3184,"t":{"1059":{"position":[[107,6],[199,6]]},"1152":{"position":[[2430,6]]}}}],["orang",{"_index":1026,"t":{"302":{"position":[[336,6]]}}}],["order",{"_index":124,"t":{"19":{"position":[[117,5]]},"919":{"position":[[501,8]]}}}],["orient",{"_index":2881,"t":{"949":{"position":[[392,8]]}}}],["origin",{"_index":1441,"t":{"427":{"position":[[2905,8]]},"619":{"position":[[92,8]]},"686":{"position":[[1743,8]]},"688":{"position":[[92,8]]},"694":{"position":[[121,8],[409,8]]},"696":{"position":[[568,8]]},"713":{"position":[[811,8]]},"834":{"position":[[565,9]]},"836":{"position":[[1468,8]]},"943":{"position":[[169,8]]},"1137":{"position":[[3820,8]]},"1146":{"position":[[1942,8]]},"1150":{"position":[[141,8]]}}}],["orthogon",{"_index":3444,"t":{"1137":{"position":[[4090,10],[4182,13]]},"1146":{"position":[[867,13],[1838,10]]},"1190":{"position":[[227,10],[304,10],[479,10]]}}}],["osvaldo",{"_index":931,"t":{"269":{"position":[[87,7]]}}}],["other",{"_index":2105,"t":{"642":{"position":[[285,6]]}}}],["oto_tot",{"_index":2650,"t":{"855":{"position":[[203,8]]}}}],["otp",{"_index":974,"t":{"281":{"position":[[2212,3]]}}}],["out",{"_index":936,"t":{"269":{"position":[[377,3]]},"379":{"position":[[341,3]]},"382":{"position":[[81,3]]},"404":{"position":[[259,3]]},"423":{"position":[[1000,3]]},"427":{"position":[[3018,3]]},"838":{"position":[[395,3],[449,3],[494,3],[947,4]]}}}],["output",{"_index":520,"t":{"104":{"position":[[545,6]]},"124":{"position":[[586,6]]},"126":{"position":[[690,6],[1165,6],[1229,6]]},"130":{"position":[[19,6],[328,6],[451,6]]},"132":{"position":[[31,6],[439,6],[513,6],[552,6],[611,6]]},"140":{"position":[[573,6]]},"159":{"position":[[41,6]]},"169":{"position":[[151,6],[280,6]]},"229":{"position":[[481,6],[620,6],[755,7]]},"238":{"position":[[18,6]]},"339":{"position":[[116,6]]},"343":{"position":[[391,6]]},"345":{"position":[[631,6],[750,6]]},"425":{"position":[[1657,6]]},"437":{"position":[[814,6]]},"451":{"position":[[317,10]]},"457":{"position":[[304,6]]},"461":{"position":[[16,6]]},"463":{"position":[[2232,6]]},"475":{"position":[[67,6]]},"551":{"position":[[71,6]]},"563":{"position":[[688,6]]},"633":{"position":[[698,6],[1136,6]]},"684":{"position":[[120,6]]},"686":{"position":[[393,6]]},"688":{"position":[[1108,6]]},"694":{"position":[[826,6]]},"761":{"position":[[804,6],[1061,6]]},"764":{"position":[[22,6]]},"773":{"position":[[404,6]]},"817":{"position":[[1375,6],[2025,6]]},"819":{"position":[[78,6]]},"821":{"position":[[470,6],[520,6],[607,6],[622,6]]},"823":{"position":[[227,6],[469,6],[1064,6],[1295,6],[1540,6]]},"836":{"position":[[1048,6],[1113,6]]},"842":{"position":[[1456,6],[1492,6]]},"853":{"position":[[100,6]]},"857":{"position":[[56,6],[271,6],[577,6]]},"861":{"position":[[255,6]]},"870":{"position":[[423,6],[482,6]]},"874":{"position":[[87,6],[301,6]]},"879":{"position":[[54,6],[141,6],[195,6],[551,6]]},"885":{"position":[[680,6],[723,6]]},"887":{"position":[[45,6],[97,6],[138,6],[275,6]]},"899":{"position":[[67,6],[1149,6]]},"903":{"position":[[69,6]]},"907":{"position":[[54,6],[75,6]]},"909":{"position":[[236,6]]},"911":{"position":[[206,6],[297,6]]},"917":{"position":[[836,6],[1543,6]]},"987":{"position":[[207,6]]},"989":{"position":[[423,6],[776,6]]},"993":{"position":[[159,6]]},"1001":{"position":[[949,7]]},"1140":{"position":[[583,6]]},"1158":{"position":[[196,6]]}}}],["over",{"_index":1258,"t":{"398":{"position":[[51,4]]},"491":{"position":[[57,4],[123,4]]},"549":{"position":[[357,4]]}}}],["overal",{"_index":2720,"t":{"883":{"position":[[359,8],[417,8]]},"1109":{"position":[[81,7]]},"1113":{"position":[[271,7]]}}}],["overfit",{"_index":2146,"t":{"680":{"position":[[716,11]]},"698":{"position":[[1553,11]]},"702":{"position":[[834,11]]},"707":{"position":[[143,11]]},"796":{"position":[[222,11]]},"838":{"position":[[165,11]]},"844":{"position":[[385,11]]},"1001":{"position":[[365,7],[382,7]]},"1137":{"position":[[3577,11]]}}}],["overhead",{"_index":1742,"t":{"549":{"position":[[959,8]]},"761":{"position":[[1545,8]]},"1137":{"position":[[2161,8]]},"1146":{"position":[[1464,8]]}}}],["overleftarrow{h}_i",{"_index":2224,"t":{"688":{"position":[[820,21]]}}}],["overline{i}^{(t",{"_index":3638,"t":{"1152":{"position":[[1734,16]]}}}],["overline{i}^{(t)}(w_{ij",{"_index":3636,"t":{"1152":{"position":[[1696,26],[1902,26],[2514,26]]}}}],["overline{u}^{(t",{"_index":3643,"t":{"1152":{"position":[[1833,16]]}}}],["overline{u}^{(t)}(w_{ij",{"_index":3641,"t":{"1152":{"position":[[1795,26],[2547,27]]}}}],["overview",{"_index":3755,"t":{"1209":{"position":[[124,8]]}}}],["overwhelm",{"_index":3779,"t":{"1216":{"position":[[810,9],[851,9]]}}}],["ovi",{"_index":3367,"t":{"1099":{"position":[[1300,5]]},"1119":{"position":[[14,4]]}}}],["oxford",{"_index":498,"t":{"102":{"position":[[190,6]]}}}],["oxfordpet",{"_index":3825,"t":{"1238":{"position":[[99,10]]}}}],["p",{"_index":232,"t":{"38":{"position":[[365,1]]},"425":{"position":[[169,1],[595,1]]},"471":{"position":[[63,1],[130,1]]},"475":{"position":[[401,2]]},"496":{"position":[[105,1]]},"627":{"position":[[888,1],[914,2]]},"631":{"position":[[645,3],[661,3]]},"633":{"position":[[364,3],[925,1],[973,1]]},"635":{"position":[[715,3]]},"678":{"position":[[146,1],[356,1],[425,1]]},"680":{"position":[[913,1],[1151,1],[1187,1],[1394,1],[1430,1],[1516,1],[1612,1],[1694,1]]},"684":{"position":[[23,1]]},"686":{"position":[[1414,1]]},"688":{"position":[[433,1]]},"690":{"position":[[60,1]]},"694":{"position":[[838,1]]},"696":{"position":[[21,1],[270,1],[379,1],[472,1],[719,1],[861,1],[898,1],[1021,1],[1120,1],[1247,1],[1342,1]]},"698":{"position":[[0,1],[90,1],[1065,1],[1678,1],[1979,1]]},"700":{"position":[[44,1],[161,1],[252,1],[344,1],[543,1]]},"702":{"position":[[212,1],[563,1],[663,1],[924,1],[989,1],[1094,1],[1166,1]]},"704":{"position":[[57,1],[150,1],[247,1],[271,1],[354,1],[390,1]]},"707":{"position":[[7,1]]},"711":{"position":[[457,1],[553,1]]},"713":{"position":[[1440,1]]},"718":{"position":[[437,1]]},"721":{"position":[[24,1]]},"725":{"position":[[24,1],[260,1],[401,1]]},"727":{"position":[[24,1],[251,1],[348,1]]},"732":{"position":[[16,1]]},"734":{"position":[[105,1]]},"736":{"position":[[106,1],[188,1]]},"738":{"position":[[0,1],[173,2]]},"740":{"position":[[0,1]]},"746":{"position":[[10,1],[82,1],[132,1],[254,1],[357,1]]},"748":{"position":[[15,1],[121,1],[168,1],[349,1]]},"751":{"position":[[89,1]]},"753":{"position":[[26,1]]},"755":{"position":[[0,1],[146,1]]},"836":{"position":[[1266,1],[1390,1]]},"901":{"position":[[2026,1]]},"939":{"position":[[98,1]]},"1075":{"position":[[58,1]]},"1111":{"position":[[168,3]]},"1137":{"position":[[3997,1]]},"1146":{"position":[[169,1],[975,1]]}}}],["p'_\\theta",{"_index":2417,"t":{"777":{"position":[[249,10]]}}}],["p(f_{fill}(x",{"_index":2736,"t":{"885":{"position":[[559,14]]}}}],["p(ffill(x′,z);θ).(1)\\hat{z",{"_index":2733,"t":{"885":{"position":[[481,27]]}}}],["p(ffill​(x′,z);θ).(1",{"_index":2738,"t":{"885":{"position":[[608,21]]}}}],["p(x)p(x)p(x",{"_index":2855,"t":{"927":{"position":[[26,12]]}}}],["p(x;θ)p(x;\\theta)p(x",{"_index":2742,"t":{"889":{"position":[[71,23]]}}}],["p(xt∣[x<t;xdiagnosis];θ)p(x_t",{"_index":2910,"t":{"959":{"position":[[631,29]]}}}],["p(xt∣x<t;θ)p(x_t",{"_index":2907,"t":{"959":{"position":[[531,16]]}}}],["p(y_i",{"_index":2765,"t":{"901":{"position":[[540,6]]}}}],["p(y_j|x,y_{1:j",{"_index":632,"t":{"132":{"position":[[831,14]]}}}],["p(y_t",{"_index":782,"t":{"180":{"position":[[191,5]]}}}],["p(y_t|\\text{x},y_{<t}).β(x,y)=t1​∑t=1t​logp(yt​∣x,y<t",{"_index":1374,"t":{"425":{"position":[[1796,56]]}}}],["p(yi​∣xi",{"_index":2042,"t":{"633":{"position":[[1056,9]]}}}],["p(yi∣xi",{"_index":2031,"t":{"633":{"position":[[784,7]]}}}],["p(yj∣x,y1:j−1)p(y_j|x,y_{1:j",{"_index":642,"t":{"140":{"position":[[48,28]]}}}],["p(yt​∣y<t​,z",{"_index":784,"t":{"180":{"position":[[221,13]]}}}],["p(yt∣y<t,z)l",{"_index":780,"t":{"180":{"position":[[155,12]]}}}],["p(y|x;\\theta;\\phi",{"_index":2763,"t":{"901":{"position":[[483,18]]}}}],["p(y∣x)=∑z∈para(z′)p(z∣x)p(y|x",{"_index":2812,"t":{"911":{"position":[[332,30]]}}}],["p(y∣x)p(y|x)p(y∣x",{"_index":2693,"t":{"874":{"position":[[106,18]]}}}],["p(y∣x;θ)p(y|x",{"_index":1975,"t":{"627":{"position":[[242,14]]}}}],["p(y∣x;θ)p(y|x;\\theta)p(y∣x",{"_index":2711,"t":{"879":{"position":[[73,29]]}}}],["p(z_t|f_{\\textup{prompt",{"_index":2838,"t":{"917":{"position":[[1447,24]]}}}],["p(zt∣x,z<t):=1k∑ikp(zt∣fprompt",{"_index":2836,"t":{"917":{"position":[[1366,31]]}}}],["p(z|f_{prompt",{"_index":2827,"t":{"917":{"position":[[375,14]]}}}],["p(z∣x):=1k∑ikp(z∣fprompt,i(x))p(z|x",{"_index":2824,"t":{"917":{"position":[[314,36]]}}}],["p(⋅;θ)p(\\cdot",{"_index":2730,"t":{"885":{"position":[[395,13]]}}}],["p)(1",{"_index":1990,"t":{"627":{"position":[[949,7]]}}}],["p)(1)\\mathcal{l}_{plm",{"_index":1987,"t":{"627":{"position":[[847,24]]}}}],["p)(p,p",{"_index":417,"t":{"91":{"position":[[338,7]]}}}],["p,p)(p",{"_index":416,"t":{"91":{"position":[[329,8]]}}}],["p0p_0p0",{"_index":2976,"t":{"983":{"position":[[596,8]]}}}],["p1p_1p1",{"_index":2977,"t":{"983":{"position":[[767,8]]}}}],["p3",{"_index":1316,"t":{"423":{"position":[[443,4]]}}}],["p36",{"_index":2175,"t":{"686":{"position":[[704,4]]}}}],["p;t]∈r(l+n)×d[p",{"_index":1991,"t":{"627":{"position":[[970,17]]}}}],["p<0.05p",{"_index":3664,"t":{"1156":{"position":[[159,7]]}}}],["p=0.75",{"_index":1644,"t":{"475":{"position":[[414,6]]}}}],["p=0.75\\text{top",{"_index":1642,"t":{"475":{"position":[[385,15]]}}}],["p={p1,p2,…,,pn}p",{"_index":2494,"t":{"819":{"position":[[648,16]]}}}],["p={p1​,p2​,…,,pn",{"_index":2498,"t":{"819":{"position":[[693,20]]}}}],["p={pk}k=1n\\mathcal{p",{"_index":3547,"t":{"1148":{"position":[[569,21]]}}}],["p>thi",{"_index":3147,"t":{"1040":{"position":[[216,7]]}}}],["p@1",{"_index":2140,"t":{"678":{"position":[[249,5]]},"707":{"position":[[202,5]]}}}],["p\\bold{p}p",{"_index":2173,"t":{"686":{"position":[[595,10]]}}}],["p\\theta_pθp",{"_index":2499,"t":{"819":{"position":[[1003,13],[1396,13]]}}}],["p^2",{"_index":409,"t":{"91":{"position":[[251,3],[1706,3]]}}}],["p^=p∗∘wk=p∗∘(uk⨂vkt)(2)\\hat{p",{"_index":2011,"t":{"631":{"position":[[612,30]]}}}],["p^\\hat{p}p",{"_index":2010,"t":{"631":{"position":[[583,11]]}}}],["p^\\top",{"_index":3522,"t":{"1146":{"position":[[968,6]]}}}],["p^k",{"_index":2033,"t":{"633":{"position":[[820,6],[1097,7]]}}}],["p^k=p∗∘(uk⨂vkt)\\hat{p}_k",{"_index":2023,"t":{"633":{"position":[[337,24]]}}}],["p^k∈r100×d\\hat{p}_k",{"_index":2113,"t":{"644":{"position":[[136,19]]}}}],["p^t=p∗∘(ut⨂vtt)\\hat{p}_t",{"_index":2076,"t":{"635":{"position":[[688,24]]}}}],["p_1",{"_index":2495,"t":{"819":{"position":[[670,4]]}}}],["p_2",{"_index":2496,"t":{"819":{"position":[[675,4]]}}}],["p_\\theta",{"_index":2398,"t":{"775":{"position":[[704,8]]}}}],["p_c",{"_index":3773,"t":{"1214":{"position":[[925,3]]}}}],["p_k",{"_index":3534,"t":{"1148":{"position":[[274,3],[596,3]]}}}],["p_k^{(teacher",{"_index":2039,"t":{"633":{"position":[[953,16]]}}}],["p_l",{"_index":1524,"t":{"461":{"position":[[175,3],[781,5]]},"463":{"position":[[617,5],[668,5]]},"465":{"position":[[934,3]]}}}],["p_l^v",{"_index":1628,"t":{"465":{"position":[[926,5]]}}}],["p_n",{"_index":2497,"t":{"819":{"position":[[689,3]]}}}],["p_{*i",{"_index":3515,"t":{"1146":{"position":[[637,7]]}}}],["p_{\\phi",{"_index":2375,"t":{"770":{"position":[[337,8]]}}}],["p_{\\phi_0",{"_index":1781,"t":{"553":{"position":[[1257,10]]}}}],["p_{\\phi}(i",{"_index":2372,"t":{"770":{"position":[[255,11]]}}}],["p_{\\phi}(y_t",{"_index":1772,"t":{"553":{"position":[[564,13]]}}}],["p_{\\theta}(y_i",{"_index":984,"t":{"286":{"position":[[271,14]]}}}],["p_{k,*i",{"_index":3541,"t":{"1148":{"position":[[416,9]]}}}],["pack",{"_index":1220,"t":{"379":{"position":[[255,7]]}}}],["pad",{"_index":3196,"t":{"1061":{"position":[[230,8]]}}}],["pada",{"_index":2867,"t":{"939":{"position":[[91,4]]}}}],["page",{"_index":136,"t":{"19":{"position":[[388,5]]},"1028":{"position":[[21,4],[68,5]]},"1032":{"position":[[24,5]]},"1038":{"position":[[64,5]]},"1040":{"position":[[265,4],[321,5]]},"1042":{"position":[[92,4],[116,4],[127,4],[186,5]]},"1053":{"position":[[121,6],[216,5]]},"1077":{"position":[[154,4]]}}}],["page.j",{"_index":3139,"t":{"1040":{"position":[[36,8],[64,7]]}}}],["page.md",{"_index":3150,"t":{"1042":{"position":[[39,8],[70,7]]},"1053":{"position":[[172,9]]}}}],["page</h1",{"_index":3146,"t":{"1040":{"position":[[206,9]]}}}],["page</p",{"_index":3148,"t":{"1040":{"position":[[235,8]]}}}],["page](./cr",{"_index":3167,"t":{"1053":{"position":[[155,14]]}}}],["page](/cr",{"_index":3166,"t":{"1053":{"position":[[105,13]]}}}],["pair",{"_index":718,"t":{"159":{"position":[[408,6]]},"238":{"position":[[25,4]]},"343":{"position":[[114,5]]},"345":{"position":[[800,4],[1083,5],[1175,5]]},"418":{"position":[[642,5],[946,5]]},"475":{"position":[[74,5]]},"502":{"position":[[430,4]]},"504":{"position":[[993,5],[2133,4]]},"519":{"position":[[244,5]]},"521":{"position":[[104,5]]},"539":{"position":[[271,5]]},"543":{"position":[[111,5],[263,5]]},"587":{"position":[[61,5]]},"659":{"position":[[155,5]]},"893":{"position":[[279,4]]},"947":{"position":[[412,4]]},"1200":{"position":[[60,4]]},"1214":{"position":[[127,4]]}}}],["palm",{"_index":871,"t":{"227":{"position":[[293,4]]},"229":{"position":[[990,4]]},"242":{"position":[[74,4]]},"244":{"position":[[188,4],[334,4],[542,4],[562,4]]},"261":{"position":[[91,4]]},"269":{"position":[[270,4]]},"366":{"position":[[204,8],[219,6]]},"368":{"position":[[279,4],[378,4],[550,4]]},"379":{"position":[[4,5],[12,4]]},"382":{"position":[[5,4]]},"386":{"position":[[45,4]]},"388":{"position":[[77,4]]},"390":{"position":[[160,4],[249,4],[308,4],[408,4]]},"394":{"position":[[159,4],[232,4],[244,4]]},"396":{"position":[[104,4],[166,4],[211,4],[237,4],[298,4],[658,4]]},"398":{"position":[[603,4],[615,4],[646,4],[693,4],[735,4],[1026,4],[1141,4]]},"406":{"position":[[54,4],[292,6]]},"408":{"position":[[132,4],[234,4]]},"410":{"position":[[91,4]]},"412":{"position":[[36,4]]}}}],["panda",{"_index":1955,"t":{"623":{"position":[[156,5]]}}}],["paper",{"_index":855,"t":{"225":{"position":[[106,5]]}}}],["para",{"_index":2809,"t":{"911":{"position":[[246,4]]}}}],["paradigm",{"_index":1249,"t":{"392":{"position":[[315,8]]},"416":{"position":[[377,8]]},"502":{"position":[[481,8]]},"519":{"position":[[216,8]]},"680":{"position":[[376,9]]},"704":{"position":[[45,8],[480,8]]},"876":{"position":[[397,8]]},"889":{"position":[[387,8]]},"1085":{"position":[[324,8]]}}}],["param",{"_index":215,"t":{"33":{"position":[[336,6]]}}}],["paramet",{"_index":204,"t":{"27":{"position":[[506,9]]},"38":{"position":[[369,9]]},"165":{"position":[[756,9]]},"171":{"position":[[139,9]]},"188":{"position":[[56,10],[140,9]]},"233":{"position":[[38,9]]},"273":{"position":[[249,9]]},"318":{"position":[[5,9]]},"349":{"position":[[405,10],[720,9]]},"355":{"position":[[193,9]]},"412":{"position":[[53,9]]},"416":{"position":[[226,9],[350,9],[561,9]]},"418":{"position":[[175,9],[287,9],[1304,9],[1379,9],[1430,9],[1783,9],[2153,9]]},"423":{"position":[[535,9]]},"427":{"position":[[84,9],[2073,9],[3148,9],[3462,9],[3620,9],[3713,9],[3825,9],[3861,9]]},"429":{"position":[[292,9],[421,9]]},"431":{"position":[[167,9]]},"437":{"position":[[178,9]]},"441":{"position":[[17,9]]},"443":{"position":[[55,9]]},"445":{"position":[[33,9]]},"451":{"position":[[67,9],[247,9]]},"455":{"position":[[190,9]]},"457":{"position":[[622,10],[673,9],[1239,9]]},"469":{"position":[[162,9]]},"475":{"position":[[204,9]]},"479":{"position":[[49,10],[98,10]]},"484":{"position":[[90,9]]},"487":{"position":[[47,9]]},"491":{"position":[[209,9]]},"498":{"position":[[21,9]]},"502":{"position":[[128,9],[226,9],[505,9],[856,9]]},"504":{"position":[[255,9],[455,9],[1592,9],[1689,9],[1846,9],[1947,9],[1985,9],[2225,9],[2526,9]]},"508":{"position":[[32,9]]},"515":{"position":[[116,9],[137,9],[415,9],[897,9],[968,9]]},"517":{"position":[[17,9],[134,9],[208,9]]},"519":{"position":[[347,9]]},"531":{"position":[[218,9],[264,9]]},"533":{"position":[[224,9]]},"543":{"position":[[6,9]]},"547":{"position":[[199,9],[278,9]]},"549":{"position":[[229,9],[1051,9]]},"553":{"position":[[696,9],[741,9],[883,9],[931,9],[1014,9]]},"557":{"position":[[32,10],[169,9],[374,9]]},"563":{"position":[[613,9]]},"569":{"position":[[149,9]]},"571":{"position":[[71,9],[303,9]]},"581":{"position":[[116,9]]},"583":{"position":[[158,9]]},"587":{"position":[[134,9]]},"595":{"position":[[11,9]]},"600":{"position":[[125,9],[197,9],[246,9]]},"610":{"position":[[122,9]]},"614":{"position":[[583,9]]},"616":{"position":[[321,9],[1426,9],[1533,9]]},"619":{"position":[[53,9],[375,9]]},"621":{"position":[[219,9],[298,9]]},"627":{"position":[[27,9],[189,9],[348,9],[394,9],[1118,9],[1376,9]]},"631":{"position":[[103,10]]},"633":{"position":[[620,10]]},"637":{"position":[[169,10],[343,9],[476,9]]},"639":{"position":[[111,9]]},"644":{"position":[[48,10]]},"646":{"position":[[56,10],[319,9]]},"651":{"position":[[20,9],[88,9],[201,9]]},"657":{"position":[[172,9],[208,9]]},"674":{"position":[[379,9],[449,9]]},"680":{"position":[[1015,10]]},"688":{"position":[[252,9]]},"692":{"position":[[249,9]]},"696":{"position":[[759,9],[837,9],[1049,9]]},"704":{"position":[[420,9]]},"711":{"position":[[431,9]]},"713":{"position":[[112,9],[151,10],[260,9],[344,9],[614,9],[920,9],[1466,9],[1641,9]]},"723":{"position":[[30,9]]},"727":{"position":[[161,10],[389,10],[457,9]]},"738":{"position":[[217,10],[260,9],[286,9]]},"746":{"position":[[414,10]]},"751":{"position":[[119,9]]},"753":{"position":[[215,9]]},"755":{"position":[[60,11],[119,9]]},"759":{"position":[[116,9],[269,9],[525,9]]},"761":{"position":[[129,9],[180,9],[254,10],[278,9],[352,9],[384,9],[589,9],[628,9],[1347,9],[1392,9],[1568,9]]},"770":{"position":[[28,9]]},"773":{"position":[[12,9]]},"775":{"position":[[435,9],[950,10],[976,10],[1008,10],[1040,10]]},"777":{"position":[[312,10],[373,9],[492,10]]},"787":{"position":[[21,9],[143,9],[230,9],[502,9]]},"789":{"position":[[11,9],[52,9]]},"791":{"position":[[338,9]]},"793":{"position":[[665,9]]},"796":{"position":[[31,9]]},"798":{"position":[[94,9]]},"811":{"position":[[29,9],[137,9],[367,9],[432,9],[695,9],[951,9],[1091,9],[1122,9]]},"815":{"position":[[339,9]]},"817":{"position":[[230,9],[954,10],[1266,9],[1409,9],[2160,10],[2196,10],[2305,10]]},"819":{"position":[[601,9],[992,10],[1657,9],[1949,10]]},"821":{"position":[[695,9],[804,10]]},"825":{"position":[[342,9],[855,9]]},"827":{"position":[[446,9]]},"836":{"position":[[91,9],[137,9],[214,9],[236,9],[479,9],[885,9],[974,9],[1442,9],[1749,9],[2197,9],[2260,9]]},"840":{"position":[[319,9]]},"844":{"position":[[291,9],[342,9]]},"850":{"position":[[1990,9]]},"879":{"position":[[156,9]]},"889":{"position":[[497,9]]},"901":{"position":[[2358,9]]},"929":{"position":[[154,9],[186,9],[226,9]]},"931":{"position":[[44,9],[358,9]]},"943":{"position":[[117,9]]},"963":{"position":[[2092,9]]},"989":{"position":[[541,9]]},"1087":{"position":[[2821,9]]},"1135":{"position":[[121,9],[376,9],[500,9],[696,9]]},"1137":{"position":[[101,9],[314,9],[495,9],[767,9],[878,9],[1221,9],[2125,9],[2563,9],[2836,9],[2935,9],[2974,10],[3023,9],[3191,9],[3354,9],[4645,9]]},"1142":{"position":[[801,9]]},"1148":{"position":[[555,9]]},"1150":{"position":[[270,9]]},"1152":{"position":[[49,10],[836,9],[1183,9],[1201,9],[1240,9]]},"1154":{"position":[[36,9],[687,9]]},"1160":{"position":[[138,9],[181,9],[535,9],[618,9],[753,9]]},"1165":{"position":[[22,9],[93,10],[120,9],[538,10]]},"1167":{"position":[[80,9],[139,9]]},"1172":{"position":[[4,9],[56,9],[87,9]]},"1174":{"position":[[39,10],[230,9]]},"1181":{"position":[[43,9],[74,9]]},"1192":{"position":[[426,9],[488,9]]},"1194":{"position":[[4,9],[78,9],[264,9]]},"1214":{"position":[[767,9]]},"1222":{"position":[[227,9],[1157,9]]}}}],["parameter",{"_index":1738,"t":{"549":{"position":[[362,13]]},"766":{"position":[[25,13]]},"775":{"position":[[591,14]]},"819":{"position":[[393,12],[783,12],[944,12]]},"838":{"position":[[1179,12]]},"850":{"position":[[2016,12]]},"1135":{"position":[[611,12]]},"1137":{"position":[[1641,12],[4261,16]]},"1146":{"position":[[85,12],[1398,16]]},"1160":{"position":[[707,12]]},"1194":{"position":[[196,12]]}}}],["paramt",{"_index":2572,"t":{"836":{"position":[[1695,8]]}}}],["paraphas",{"_index":2811,"t":{"911":{"position":[[266,10]]}}}],["paraphras",{"_index":2577,"t":{"838":{"position":[[260,10],[738,10]]},"899":{"position":[[241,12],[284,10],[439,10],[470,10]]},"911":{"position":[[105,12],[159,12],[481,11]]},"945":{"position":[[129,12],[263,12]]},"947":{"position":[[466,10]]},"963":{"position":[[932,12]]},"983":{"position":[[1169,12]]},"1163":{"position":[[137,10]]}}}],["pareto",{"_index":2443,"t":{"787":{"position":[[457,6]]}}}],["pari",{"_index":1112,"t":{"343":{"position":[[83,5]]},"553":{"position":[[169,5]]},"1003":{"position":[[519,5]]}}}],["pars",{"_index":2879,"t":{"945":{"position":[[9,7],[94,7]]}}}],["parser",{"_index":998,"t":{"298":{"position":[[14,6]]}}}],["part",{"_index":3803,"t":{"1222":{"position":[[637,5]]}}}],["parti",{"_index":2526,"t":{"823":{"position":[[325,5],[426,5]]}}}],["particularli",{"_index":3171,"t":{"1055":{"position":[[250,12]]}}}],["pass",{"_index":788,"t":{"180":{"position":[[405,4]]},"563":{"position":[[759,4]]},"840":{"position":[[430,4]]},"1142":{"position":[[119,4]]}}}],["pass@1",{"_index":2620,"t":{"848":{"position":[[619,6]]}}}],["past",{"_index":2348,"t":{"766":{"position":[[638,4]]}}}],["patch",{"_index":389,"t":{"88":{"position":[[240,5]]},"91":{"position":[[189,5],[575,5],[795,5],[1183,5],[1856,5]]},"95":{"position":[[11,5],[88,5],[150,5],[172,5],[307,5]]},"97":{"position":[[244,5]]},"104":{"position":[[80,5],[127,5],[164,5],[183,5],[415,5]]},"116":{"position":[[450,5],[532,5]]},"118":{"position":[[69,5]]},"120":{"position":[[0,5]]},"176":{"position":[[25,5]]},"302":{"position":[[911,5],[995,7]]}}}],["path",{"_index":941,"t":{"271":{"position":[[520,4]]},"773":{"position":[[1053,5]]},"899":{"position":[[220,4]]},"1053":{"position":[[48,5],[71,6]]},"1055":{"position":[[60,5]]}}}],["pattern",{"_index":1049,"t":{"306":{"position":[[52,8]]}}}],["paw",{"_index":2108,"t":{"642":{"position":[[324,4]]}}}],["pc(2)\\hat{i",{"_index":3771,"t":{"1214":{"position":[[886,12]]}}}],["pc=exp⁡(<fctext,fimage>/τ)∑j=1cexp⁡(<fjtext,fimage>/τ)(1)p_c",{"_index":3764,"t":{"1214":{"position":[[491,60]]}}}],["pc=exp⁡(<g(vc),fimage>/τ)∑j=1cexp⁡(<g(vj),fimage>/τ)(4)p_c",{"_index":3809,"t":{"1222":{"position":[[908,58]]}}}],["pca",{"_index":762,"t":{"171":{"position":[[805,3]]}}}],["pc​(2",{"_index":3775,"t":{"1214":{"position":[[949,6]]}}}],["pe;xe]∈r(p+n)×e[p_",{"_index":2509,"t":{"819":{"position":[[1788,21]]}}}],["peft",{"_index":1282,"t":{"416":{"position":[[258,6],[407,4],[419,4],[525,4]]},"418":{"position":[[1336,6],[1497,4],[1559,4],[1596,4],[1667,4],[1729,4],[2102,4]]},"421":{"position":[[0,4]]},"423":{"position":[[81,4]]},"425":{"position":[[0,4]]},"427":{"position":[[29,4],[217,4],[579,4],[632,4],[690,4],[3118,4],[3818,4]]},"451":{"position":[[152,4]]},"543":{"position":[[574,4]]},"555":{"position":[[9,4]]},"1137":{"position":[[3226,4]]}}}],["peft/ipet",{"_index":2278,"t":{"702":{"position":[[42,9]]}}}],["pellentesqu",{"_index":8,"t":{"3":{"position":[[57,12]]},"5":{"position":[[177,12],[356,12],[535,12],[714,12],[893,12],[1072,12],[1251,12],[1430,12],[1609,12],[1788,12],[1967,12],[2146,12],[2325,12],[2504,12],[2683,12],[2862,12]]}}}],["penalti",{"_index":3445,"t":{"1137":{"position":[[4244,7]]}}}],["pep_ep",{"_index":2513,"t":{"819":{"position":[[1960,8]]}}}],["per",{"_index":1312,"t":{"421":{"position":[[351,3]]},"431":{"position":[[667,3]]},"437":{"position":[[138,3],[256,3],[298,3],[445,3]]},"727":{"position":[[430,3]]},"817":{"position":[[83,3]]}}}],["per:city_of_death",{"_index":2821,"t":{"911":{"position":[[1322,17]]}}}],["percept",{"_index":728,"t":{"165":{"position":[[201,10]]},"1085":{"position":[[26,10],[98,10],[284,10]]},"1087":{"position":[[786,10],[823,10],[1188,10],[1262,10],[1359,10],[2521,10],[2624,10],[2849,10]]},"1090":{"position":[[36,10],[394,10]]},"1096":{"position":[[727,10]]},"1099":{"position":[[32,10]]},"1131":{"position":[[56,10]]}}}],["perform",{"_index":2145,"t":{"680":{"position":[[613,10]]},"696":{"position":[[8,12]]},"802":{"position":[[94,12]]},"844":{"position":[[109,11],[561,10]]},"863":{"position":[[200,11]]},"1137":{"position":[[2859,11]]},"1150":{"position":[[288,11]]}}}],["period",{"_index":1222,"t":{"379":{"position":[[353,8]]}}}],["persist",{"_index":2663,"t":{"859":{"position":[[220,10],[784,10]]}}}],["person",{"_index":657,"t":{"143":{"position":[[179,6]]},"149":{"position":[[4,6]]},"159":{"position":[[801,6]]},"809":{"position":[[4,15]]},"909":{"position":[[576,9]]},"1092":{"position":[[280,8]]}}}],["person,city,death",{"_index":2822,"t":{"911":{"position":[[1346,19]]}}}],["pet",{"_index":500,"t":{"102":{"position":[[202,5],[284,5]]},"698":{"position":[[1904,3],[1963,3]]},"702":{"position":[[717,3],[964,3],[970,3]]}}}],["pet/ipet",{"_index":2279,"t":{"702":{"position":[[1141,8]]}}}],["petaflops/",{"_index":3051,"t":{"1013":{"position":[[286,11],[338,11]]}}}],["pe∈rp×ep_",{"_index":2506,"t":{"819":{"position":[[1667,10]]}}}],["pf",{"_index":2289,"t":{"713":{"position":[[1033,2],[1127,2]]},"736":{"position":[[37,2]]},"755":{"position":[[37,2]]}}}],["pfeiffer",{"_index":3676,"t":{"1160":{"position":[[450,10]]},"1174":{"position":[[207,8]]}}}],["phi",{"_index":1775,"t":{"553":{"position":[[722,6],[778,9],[964,4],[981,4],[1104,6]]},"604":{"position":[[817,8],[912,6]]},"766":{"position":[[0,6]]},"770":{"position":[[38,6]]},"775":{"position":[[987,6]]}}}],["phi(\\theta",{"_index":1782,"t":{"553":{"position":[[1280,13]]}}}],["phi_0|∣θ∣≪∣ϕ0",{"_index":1779,"t":{"553":{"position":[[1069,18]]}}}],["phiϕ0",{"_index":1767,"t":{"553":{"position":[[439,10]]}}}],["phoeb",{"_index":930,"t":{"269":{"position":[[67,6]]}}}],["photo",{"_index":834,"t":{"197":{"position":[[40,5]]},"1200":{"position":[[233,5]]},"1205":{"position":[[52,5]]},"1214":{"position":[[85,5]]},"1220":{"position":[[38,5]]},"1232":{"position":[[211,5]]}}}],["php",{"_index":1162,"t":{"360":{"position":[[120,4]]}}}],["phrasal/sententi",{"_index":2789,"t":{"905":{"position":[[368,18]]}}}],["phrase",{"_index":2936,"t":{"963":{"position":[[1928,7]]}}}],["pi][\\text{p}_i][pi",{"_index":2180,"t":{"686":{"position":[[967,21],[1425,21]]}}}],["pi]∈v[\\text{p}_i",{"_index":2186,"t":{"686":{"position":[[1167,18]]}}}],["pi^{sft}(i",{"_index":3033,"t":{"1001":{"position":[[1603,11]]}}}],["pi_\\theta",{"_index":2647,"t":{"855":{"position":[[130,15]]}}}],["pica",{"_index":967,"t":{"281":{"position":[[1122,4],[1626,4]]},"290":{"position":[[180,4]]},"313":{"position":[[30,4],[193,5]]},"316":{"position":[[39,4],[80,4]]},"322":{"position":[[139,4]]}}}],["pictur",{"_index":821,"t":{"190":{"position":[[103,7]]},"302":{"position":[[1058,7]]}}}],["pidx\\text{p}_{\\text{idx}}pidx",{"_index":2391,"t":{"775":{"position":[[253,30],[545,30]]}}}],["pidx∣|\\text{p}_{\\text{idx}}|∣pidx",{"_index":2392,"t":{"775":{"position":[[312,36]]}}}],["pidx∣×dim(hi)|\\text{p}_{\\text{idx",{"_index":2394,"t":{"775":{"position":[[459,37]]}}}],["pimp^m_ipim",{"_index":3785,"t":{"1218":{"position":[[331,12]]}}}],["pipelin",{"_index":3756,"t":{"1211":{"position":[[597,8]]}}}],["pix2seq",{"_index":658,"t":{"143":{"position":[[241,7]]},"145":{"position":[[0,7],[86,7]]}}}],["pixel",{"_index":577,"t":{"124":{"position":[[166,5]]},"126":{"position":[[823,5]]},"128":{"position":[[27,5]]}}}],["pj=1zexp⁡(zj/t)p_j",{"_index":2044,"t":{"633":{"position":[[1198,18]]}}}],["pk(t)p^{(t)}_kpk(t",{"_index":3566,"t":{"1148":{"position":[[1173,21]]}}}],["pk(teacher))∣∣p(yi∣xi",{"_index":2032,"t":{"633":{"position":[[794,23]]}}}],["pk(teacher)p_k^{(teacher)}pk(teach",{"_index":2022,"t":{"633":{"position":[[273,38]]}}}],["pk(teacher)​)∣∣p(yi​∣xi",{"_index":2043,"t":{"633":{"position":[[1068,26]]}}}],["pk,∗ip_{k",{"_index":3620,"t":{"1152":{"position":[[720,10]]}}}],["pkp_{k}pk",{"_index":1998,"t":{"631":{"position":[[191,10]]}}}],["pl",{"_index":1156,"t":{"360":{"position":[[79,3]]}}}],["pl;tl;tl",{"_index":1556,"t":{"463":{"position":[[500,10],[525,10]]}}}],["pl;tl][p_l",{"_index":1545,"t":{"463":{"position":[[231,12]]}}}],["pl;tl]∈r(k+m)×c\\begin{equ",{"_index":1539,"t":{"461":{"position":[[748,32]]}}}],["plain",{"_index":3000,"t":{"995":{"position":[[205,5]]}}}],["plan",{"_index":1259,"t":{"398":{"position":[[85,8],[161,8]]},"408":{"position":[[192,8]]}}}],["platform",{"_index":1182,"t":{"362":{"position":[[443,9]]}}}],["platon",{"_index":3631,"t":{"1152":{"position":[[1294,8],[1521,8]]}}}],["play",{"_index":955,"t":{"279":{"position":[[345,4]]},"281":{"position":[[1335,4],[1923,4]]},"1030":{"position":[[469,4]]}}}],["playground",{"_index":3047,"t":{"1003":{"position":[[452,10]]}}}],["pleas",{"_index":1042,"t":{"304":{"position":[[130,7]]},"1024":{"position":[[230,6]]}}}],["plm",{"_index":1931,"t":{"616":{"position":[[38,6],[125,3],[315,3],[381,3]]},"619":{"position":[[101,3]]},"627":{"position":[[479,3],[1102,4]]},"633":{"position":[[1835,4]]},"1135":{"position":[[34,6]]},"1137":{"position":[[11,4],[126,4],[296,3],[369,3]]}}}],["plp_lpl",{"_index":1543,"t":{"461":{"position":[[859,8]]}}}],["plug",{"_index":954,"t":{"279":{"position":[[336,4]]},"281":{"position":[[1326,4],[1914,4]]},"457":{"position":[[869,4]]},"504":{"position":[[2155,8]]}}}],["plugin",{"_index":48,"t":{"9":{"position":[[53,7]]},"1075":{"position":[[79,6],[144,6],[210,6]]}}}],["plv=pl+repeat(ip)∈rk×c\\begin{equ",{"_index":1627,"t":{"465":{"position":[[887,38]]}}}],["plvp_l^vplv",{"_index":1631,"t":{"465":{"position":[[1029,12]]}}}],["pl}l=1l",{"_index":1523,"t":{"461":{"position":[[164,10]]}}}],["pl​;tl​;tl",{"_index":1567,"t":{"463":{"position":[[735,13],[765,13]]}}}],["pl∈rk×cp_l",{"_index":1526,"t":{"461":{"position":[[237,10]]}}}],["pnormp_{norm}pnorm",{"_index":3382,"t":{"1111":{"position":[[134,21]]}}}],["po",{"_index":999,"t":{"298":{"position":[[49,3]]}}}],["point",{"_index":709,"t":{"155":{"position":[[489,5]]},"318":{"position":[[51,5]]},"320":{"position":[[151,5]]},"704":{"position":[[98,6],[126,6]]},"901":{"position":[[1674,5]]},"1096":{"position":[[532,6],[646,6]]},"1240":{"position":[[182,5]]}}}],["pointer",{"_index":3199,"t":{"1061":{"position":[[255,10]]}}}],["polici",{"_index":2629,"t":{"850":{"position":[[1140,6],[1951,6]]},"855":{"position":[[76,6],[123,6]]},"870":{"position":[[16,6],[49,6]]},"993":{"position":[[46,6],[242,6],[286,6]]},"1001":{"position":[[1815,6]]}}}],["polit",{"_index":2803,"t":{"909":{"position":[[507,12]]}}}],["polygon",{"_index":608,"t":{"130":{"position":[[842,7],[891,7],[968,7],[985,7]]},"140":{"position":[[497,7],[580,9]]},"147":{"position":[[0,7]]}}}],["pool",{"_index":227,"t":{"38":{"position":[[242,7]]},"423":{"position":[[427,4]]},"1096":{"position":[[924,7],[1943,7]]},"1127":{"position":[[189,4]]}}}],["posit",{"_index":435,"t":{"91":{"position":[[1123,8],[1142,8],[1162,8],[1213,8],[1254,8],[1918,10]]},"93":{"position":[[205,8],[227,8],[262,8]]},"97":{"position":[[330,8],[376,8]]},"116":{"position":[[393,8],[429,8],[506,8]]},"174":{"position":[[485,10]]},"343":{"position":[[64,8]]},"345":{"position":[[807,8],[1074,8]]},"427":{"position":[[1299,8],[1417,8],[1737,8],[3195,8]]},"694":{"position":[[806,8]]},"698":{"position":[[1113,8]]},"879":{"position":[[428,10]]},"919":{"position":[[460,9]]},"983":{"position":[[373,8],[396,8]]},"1036":{"position":[[113,9]]}}}],["positive\\n",{"_index":2974,"t":{"983":{"position":[[545,10],[714,10]]}}}],["possibl",{"_index":1334,"t":{"423":{"position":[[1095,8]]},"425":{"position":[[1177,8],[1455,8]]},"437":{"position":[[805,8],[851,8]]},"1036":{"position":[[247,8]]},"1069":{"position":[[6,8]]}}}],["post",{"_index":22,"t":{"5":{"position":[[40,5],[92,4]]},"7":{"position":[[5,5],[116,6]]},"9":{"position":[[182,4],[291,4],[339,4]]},"1028":{"position":[[40,5]]},"1030":{"position":[[450,5],[495,4],[529,4]]}}}],["power",{"_index":38,"t":{"7":{"position":[[74,5]]},"9":{"position":[[33,7]]},"273":{"position":[[230,5]]},"437":{"position":[[568,5]]}}}],["powershel",{"_index":111,"t":{"17":{"position":[[244,11]]}}}],["ppo",{"_index":2992,"t":{"989":{"position":[[474,3],[965,3]]},"993":{"position":[[218,3],[260,3]]},"995":{"position":[[554,3]]},"1001":{"position":[[1216,3],[1227,3],[1285,3],[1332,3],[1986,3],[2055,3],[2096,3]]},"1013":{"position":[[320,3]]}}}],["ppp",{"_index":1985,"t":{"627":{"position":[[815,3]]},"819":{"position":[[491,3],[927,3],[1720,3]]},"821":{"position":[[755,3]]},"1137":{"position":[[4110,3],[4170,3]]},"1146":{"position":[[778,3],[855,3]]}}}],["ppt",{"_index":3041,"t":{"1001":{"position":[[2007,3]]}}}],["practic",{"_index":971,"t":{"281":{"position":[[1659,9]]}}}],["pre",{"_index":431,"t":{"91":{"position":[[959,3],[1058,3]]},"97":{"position":[[20,3],[188,3],[316,3],[362,3]]},"112":{"position":[[43,3],[137,3]]},"114":{"position":[[95,3],[134,3],[185,3],[219,3],[274,3],[310,3]]},"120":{"position":[[117,3],[239,3]]},"165":{"position":[[725,3]]},"171":{"position":[[16,3]]},"186":{"position":[[119,3]]},"213":{"position":[[19,3],[68,3]]},"219":{"position":[[10,3],[44,3]]},"252":{"position":[[27,3]]},"396":{"position":[[637,3],[700,3]]},"406":{"position":[[67,3]]},"408":{"position":[[0,3]]},"410":{"position":[[132,3]]},"416":{"position":[[36,3]]},"418":{"position":[[0,3],[78,3],[158,3],[825,3],[1343,3]]},"423":{"position":[[55,3],[206,3]]},"429":{"position":[[40,3],[343,3],[478,3]]},"431":{"position":[[127,3]]},"449":{"position":[[137,3]]},"455":{"position":[[437,3],[591,3]]},"457":{"position":[[633,3],[1281,3]]},"461":{"position":[[59,3]]},"463":{"position":[[2019,3],[2550,3]]},"465":{"position":[[181,3]]},"469":{"position":[[0,3]]},"475":{"position":[[254,3]]},"491":{"position":[[28,3]]},"494":{"position":[[50,3]]},"498":{"position":[[176,3]]},"510":{"position":[[47,3]]},"515":{"position":[[468,3]]},"525":{"position":[[491,3],[623,3]]},"543":{"position":[[153,3]]},"547":{"position":[[79,3]]},"549":{"position":[[189,3],[548,3],[800,3]]},"551":{"position":[[218,3]]},"553":{"position":[[75,3],[334,3],[817,3]]},"563":{"position":[[124,3],[237,3]]},"589":{"position":[[60,3],[209,3]]},"598":{"position":[[56,3]]},"604":{"position":[[53,3]]},"614":{"position":[[16,3]]},"616":{"position":[[609,3]]},"627":{"position":[[7,3]]},"635":{"position":[[139,3]]},"655":{"position":[[92,3]]},"657":{"position":[[22,3]]},"680":{"position":[[8,3],[110,3],[1033,3],[1527,3],[1667,3],[1813,3]]},"684":{"position":[[69,3]]},"686":{"position":[[0,3],[153,3],[419,3]]},"688":{"position":[[122,3],[1070,3]]},"692":{"position":[[43,3],[229,3],[272,3]]},"696":{"position":[[301,3],[1032,3]]},"698":{"position":[[1130,3],[1449,3]]},"702":{"position":[[379,3]]},"707":{"position":[[63,3],[349,3]]},"711":{"position":[[198,3]]},"713":{"position":[[0,3],[323,3],[500,3],[1258,3]]},"718":{"position":[[456,3]]},"738":{"position":[[26,3]]},"759":{"position":[[25,3]]},"761":{"position":[[25,3],[332,3],[436,3]]},"770":{"position":[[16,3]]},"773":{"position":[[611,3]]},"802":{"position":[[418,3]]},"811":{"position":[[355,3],[493,3],[743,3]]},"817":{"position":[[63,3],[570,3],[1511,3],[1759,3]]},"823":{"position":[[90,3],[345,3],[672,3],[829,3],[1001,3],[1236,3],[1397,3],[1822,3]]},"825":{"position":[[15,3]]},"832":{"position":[[275,3]]},"834":{"position":[[16,3],[164,3],[578,3],[1053,3]]},"836":{"position":[[1546,3],[2147,3]]},"840":{"position":[[206,3]]},"844":{"position":[[23,3],[468,3]]},"850":{"position":[[915,3]]},"857":{"position":[[428,3]]},"874":{"position":[[360,3]]},"876":{"position":[[373,3],[441,3],[534,3],[617,3],[668,3],[763,4],[792,4],[831,3]]},"889":{"position":[[49,3]]},"893":{"position":[[194,3]]},"901":{"position":[[654,3],[964,3]]},"905":{"position":[[51,3]]},"929":{"position":[[53,3]]},"933":{"position":[[35,3]]},"1135":{"position":[[6,3],[97,3],[215,3],[293,3],[844,3]]},"1137":{"position":[[836,3],[917,3],[2425,3]]},"1142":{"position":[[32,3]]},"1146":{"position":[[0,3]]},"1160":{"position":[[92,3],[213,3]]},"1172":{"position":[[75,3]]},"1174":{"position":[[27,3]]},"1181":{"position":[[62,3]]},"1203":{"position":[[225,3]]}}}],["pre][prompt",{"_index":2231,"t":{"688":{"position":[[1257,13]]}}}],["precis",{"_index":813,"t":{"188":{"position":[[245,9],[284,9],[308,9]]},"443":{"position":[[74,9]]},"1111":{"position":[[124,9],[158,9]]}}}],["precision@0.5",{"_index":3377,"t":{"1109":{"position":[[65,13]]}}}],["predict",{"_index":481,"t":{"97":{"position":[[86,10]]},"130":{"position":[[1048,10]]},"171":{"position":[[474,9]]},"330":{"position":[[1029,7]]},"398":{"position":[[1067,10]]},"408":{"position":[[64,10]]},"435":{"position":[[196,10]]},"437":{"position":[[783,10]]},"700":{"position":[[510,10]]},"727":{"position":[[206,10],[517,10]]},"768":{"position":[[171,7]]},"876":{"position":[[816,8],[854,7]]},"1096":{"position":[[460,10],[1295,11],[1315,10]]},"1214":{"position":[[835,10]]}}}],["prefix",{"_index":745,"t":{"169":{"position":[[743,6]]},"355":{"position":[[61,6]]},"406":{"position":[[121,6]]},"427":{"position":[[452,6],[3545,6]]},"461":{"position":[[736,6]]},"469":{"position":[[72,6]]},"508":{"position":[[217,6]]},"549":{"position":[[1281,6]]},"559":{"position":[[12,6]]},"565":{"position":[[105,6]]},"581":{"position":[[69,11],[218,6]]},"583":{"position":[[0,6]]},"595":{"position":[[108,7],[146,6]]},"619":{"position":[[227,6]]},"711":{"position":[[518,7]]},"713":{"position":[[1195,7]]},"727":{"position":[[328,6]]},"759":{"position":[[231,6],[250,6],[343,6],[401,6],[444,6],[545,6]]},"761":{"position":[[964,6],[1118,6],[1186,6],[1203,6],[1255,6],[1275,6],[1318,6],[1491,6]]},"773":{"position":[[937,6]]},"775":{"position":[[0,6],[36,6],[131,6],[286,6],[351,6],[400,6],[1001,6],[1259,6]]},"777":{"position":[[513,6]]},"782":{"position":[[33,6]]},"784":{"position":[[267,6],[355,6],[415,6],[576,6],[657,6]]},"787":{"position":[[44,6],[197,6],[266,6],[377,6],[423,6],[541,6],[601,6]]},"789":{"position":[[23,6],[74,6],[139,6]]},"791":{"position":[[40,6],[286,6],[386,6],[487,6],[587,6]]},"793":{"position":[[492,6],[594,6]]},"796":{"position":[[7,6],[58,6],[151,6]]},"798":{"position":[[430,6]]},"800":{"position":[[286,6],[326,6]]},"802":{"position":[[4,6],[409,6],[479,6]]},"804":{"position":[[50,6],[180,6],[270,6]]},"807":{"position":[[11,6],[173,6]]},"809":{"position":[[26,6],[45,6],[137,6],[195,6],[365,6]]},"811":{"position":[[52,6],[202,6],[318,6],[454,6],[484,6],[653,6],[727,6],[1011,6],[1061,6]]},"815":{"position":[[499,6]]},"817":{"position":[[1191,7],[1321,6],[1869,7],[1999,8]]},"823":{"position":[[1528,6]]},"825":{"position":[[241,6]]},"827":{"position":[[319,6]]},"836":{"position":[[256,6],[321,6],[608,6],[729,6],[774,6],[823,6],[850,6]]},"883":{"position":[[653,6]]},"893":{"position":[[18,6],[112,6],[251,6]]},"895":{"position":[[263,6]]},"901":{"position":[[291,6],[305,6],[875,6],[1004,6],[1339,6]]},"905":{"position":[[190,6]]},"927":{"position":[[72,6]]},"935":{"position":[[154,6]]},"955":{"position":[[61,6],[447,6],[552,6]]},"957":{"position":[[142,6]]},"1137":{"position":[[613,6],[703,6]]},"1142":{"position":[[937,6]]}}}],["prefix;x;y][\\text{prefix",{"_index":2452,"t":{"800":{"position":[[81,27]]}}}],["prepend",{"_index":2477,"t":{"817":{"position":[[1297,9],[1595,7]]},"819":{"position":[[509,7]]},"823":{"position":[[1386,7]]},"836":{"position":[[311,9],[428,7],[1806,9]]}}}],["preprocess",{"_index":2537,"t":{"823":{"position":[[969,13]]}}}],["pretrain",{"_index":663,"t":{"143":{"position":[[414,10],[678,8]]},"159":{"position":[[420,11]]},"165":{"position":[[0,11]]},"169":{"position":[[377,10]]},"171":{"position":[[189,11],[734,10]]},"174":{"position":[[358,10],[474,10]]},"176":{"position":[[345,10]]},"183":{"position":[[92,10]]},"221":{"position":[[22,11]]},"229":{"position":[[262,10]]},"284":{"position":[[94,11]]},"286":{"position":[[396,11]]},"290":{"position":[[77,11]]},"292":{"position":[[198,11]]},"300":{"position":[[132,10],[1004,11]]},"313":{"position":[[131,11]]},"328":{"position":[[230,11],[380,8],[412,11],[553,11]]},"330":{"position":[[41,8],[165,11],[851,9],[1057,8],[1205,8],[1270,10]]},"333":{"position":[[142,8],[205,11],[249,8],[266,11],[346,8],[365,8]]},"341":{"position":[[39,8]]},"347":{"position":[[489,8]]},"349":{"position":[[8,11],[99,10],[140,11],[432,8]]},"351":{"position":[[0,11]]},"360":{"position":[[46,11],[525,10],[656,8],[773,8]]},"362":{"position":[[28,8]]},"386":{"position":[[322,11]]},"396":{"position":[[192,11],[282,11]]},"398":{"position":[[1041,11]]},"429":{"position":[[390,11]]},"537":{"position":[[197,11]]},"616":{"position":[[11,10]]},"644":{"position":[[68,10]]},"811":{"position":[[18,10],[116,11]]},"874":{"position":[[480,10],[549,8]]},"885":{"position":[[381,10]]},"889":{"position":[[105,10]]},"901":{"position":[[184,10],[2344,10]]},"931":{"position":[[25,10],[153,10]]},"935":{"position":[[122,10]]},"937":{"position":[[25,11]]},"939":{"position":[[19,10],[115,11]]},"943":{"position":[[444,10]]},"945":{"position":[[234,10]]},"947":{"position":[[180,10]]},"951":{"position":[[406,10],[539,10]]},"953":{"position":[[390,10],[467,10]]},"955":{"position":[[95,10],[474,10],[571,10]]},"957":{"position":[[54,10],[110,11]]},"959":{"position":[[837,10]]},"961":{"position":[[149,10]]},"963":{"position":[[616,10],[2139,10],[2402,10],[2469,10]]},"967":{"position":[[73,10]]},"973":{"position":[[123,8]]},"977":{"position":[[324,10]]},"981":{"position":[[28,8],[55,10],[103,11]]},"983":{"position":[[66,10],[160,10],[246,10],[900,10]]},"989":{"position":[[971,11]]},"993":{"position":[[74,10]]},"1001":{"position":[[4,10],[1300,11],[1901,11],[1966,11]]},"1013":{"position":[[256,11]]},"1099":{"position":[[43,11],[125,8],[487,10]]},"1104":{"position":[[319,11]]},"1203":{"position":[[157,11]]},"1205":{"position":[[0,10]]},"1207":{"position":[[353,11]]},"1211":{"position":[[105,10]]},"1216":{"position":[[0,10],[315,11]]}}}],["previous/next",{"_index":3114,"t":{"1032":{"position":[[59,13]]}}}],["prime",{"_index":2474,"t":{"817":{"position":[[421,9]]}}}],["prior",{"_index":2539,"t":{"823":{"position":[[1153,6]]},"1092":{"position":[[839,5],[912,5],[969,5],[2265,6]]}}}],["prior])annot",{"_index":3288,"t":{"1092":{"position":[[2009,17]]}}}],["prior])​express",{"_index":3300,"t":{"1092":{"position":[[2373,18]]}}}],["prioriti",{"_index":3602,"t":{"1148":{"position":[[2469,8]]}}}],["prismer",{"_index":721,"t":{"163":{"position":[[63,7],[111,7],[226,7],[325,7]]},"165":{"position":[[455,7],[806,7],[933,7]]},"169":{"position":[[0,7],[312,7],[688,7],[704,7]]},"171":{"position":[[0,7]]},"180":{"position":[[4,7]]},"183":{"position":[[0,7]]},"195":{"position":[[6,7],[171,7]]},"197":{"position":[[244,7]]},"199":{"position":[[4,7]]},"206":{"position":[[11,9],[135,7]]},"211":{"position":[[180,8]]},"215":{"position":[[11,7]]},"217":{"position":[[61,7]]},"219":{"position":[[56,7]]},"221":{"position":[[12,7],[160,7]]},"223":{"position":[[0,7]]}}}],["prismerz",{"_index":794,"t":{"183":{"position":[[54,8]]}}}],["privaci",{"_index":2463,"t":{"807":{"position":[[60,7]]}}}],["proabil",{"_index":1367,"t":{"425":{"position":[[1260,10]]}}}],["probabl",{"_index":1266,"t":{"398":{"position":[[433,11],[549,11]]},"423":{"position":[[1131,13]]},"425":{"position":[[354,11],[416,11],[1697,11],[1954,11]]},"451":{"position":[[303,11]]},"627":{"position":[[230,11]]},"633":{"position":[[705,11]]},"819":{"position":[[93,11],[1912,11]]},"1170":{"position":[[162,11]]},"1216":{"position":[[520,13]]}}}],["probe",{"_index":2138,"t":{"678":{"position":[[187,7]]},"680":{"position":[[1238,7],[1768,7]]},"690":{"position":[[25,7]]},"692":{"position":[[10,7]]},"694":{"position":[[997,7]]},"696":{"position":[[943,7]]},"895":{"position":[[210,7]]},"943":{"position":[[8,7],[430,7],[633,7]]}}}],["problem",{"_index":342,"t":{"78":{"position":[[0,8]]},"227":{"position":[[331,7]]},"229":{"position":[[958,7]]},"231":{"position":[[35,7]]},"236":{"position":[[18,8],[53,8],[84,8],[115,8],[147,8]]},"248":{"position":[[202,7]]},"254":{"position":[[196,9]]},"273":{"position":[[166,9]]},"390":{"position":[[190,7]]},"817":{"position":[[2615,8]]},"1090":{"position":[[444,7]]},"1170":{"position":[[116,7]]}}}],["process",{"_index":1949,"t":{"619":{"position":[[576,12]]},"1135":{"position":[[778,11]]}}}],["product",{"_index":2017,"t":{"631":{"position":[[747,7]]},"635":{"position":[[669,7]]},"674":{"position":[[247,7]]},"1046":{"position":[[20,11]]},"1047":{"position":[[10,10]]}}}],["proejction",{"_index":1616,"t":{"465":{"position":[[415,10]]}}}],["profici",{"_index":1713,"t":{"525":{"position":[[363,11]]}}}],["program",{"_index":942,"t":{"273":{"position":[[77,8]]},"328":{"position":[[837,11]]},"817":{"position":[[1057,7]]},"850":{"position":[[690,11],[1021,13],[1682,11],[1833,11]]},"857":{"position":[[480,11]]}}}],["progress",{"_index":152,"t":{"23":{"position":[[149,11]]},"25":{"position":[[466,11],[553,11]]},"27":{"position":[[207,11],[235,11]]},"44":{"position":[[7,11]]},"47":{"position":[[404,11]]},"49":{"position":[[19,11]]},"53":{"position":[[348,11]]},"72":{"position":[[0,11]]},"78":{"position":[[412,11]]}}}],["progressivel",{"_index":341,"t":{"76":{"position":[[47,12]]}}}],["project",{"_index":102,"t":{"17":{"position":[[116,7]]},"91":{"position":[[517,10],[558,10]]},"95":{"position":[[104,10],[239,10],[338,10]]},"116":{"position":[[416,10]]},"178":{"position":[[191,10],[269,10]]},"463":{"position":[[455,10],[2248,10]]},"482":{"position":[[104,10]]},"484":{"position":[[124,10]]},"504":{"position":[[1009,10]]},"510":{"position":[[127,10]]},"512":{"position":[[69,10]]},"519":{"position":[[406,10]]},"523":{"position":[[218,10]]},"551":{"position":[[159,10]]},"563":{"position":[[198,10]]},"608":{"position":[[128,7]]},"836":{"position":[[1090,7]]},"1065":{"position":[[30,8]]},"1140":{"position":[[590,10],[713,10]]},"1142":{"position":[[757,11]]},"1160":{"position":[[845,10]]}}}],["promnpt",{"_index":3742,"t":{"1200":{"position":[[1942,7]]}}}],["prompt",{"_index":110,"t":{"17":{"position":[[236,7]]},"124":{"position":[[520,6],[562,6]]},"126":{"position":[[1129,6],[1174,6]]},"132":{"position":[[481,6],[539,6],[625,6],[659,6],[968,6]]},"140":{"position":[[16,6]]},"147":{"position":[[117,6],[317,6]]},"159":{"position":[[25,8],[733,6]]},"190":{"position":[[122,6]]},"217":{"position":[[117,9]]},"227":{"position":[[122,9],[305,9]]},"229":{"position":[[363,9],[508,8],[653,9],[782,9],[849,9],[933,9],[1011,9],[1042,6]]},"231":{"position":[[149,9],[448,9]]},"233":{"position":[[57,9]]},"238":{"position":[[68,9]]},"240":{"position":[[24,9]]},"244":{"position":[[4,9],[114,9],[281,9],[379,9]]},"246":{"position":[[4,9],[27,9]]},"248":{"position":[[4,9],[106,9],[256,9]]},"252":{"position":[[4,9],[76,9]]},"254":{"position":[[52,9],[345,9],[426,9],[479,9],[585,9]]},"261":{"position":[[38,9],[61,9],[112,9]]},"263":{"position":[[4,9]]},"269":{"position":[[286,9],[410,9],[486,9]]},"271":{"position":[[36,9],[254,9],[314,9],[352,9]]},"273":{"position":[[215,9],[269,6],[306,9]]},"275":{"position":[[4,9]]},"279":{"position":[[363,6],[460,6]]},"281":{"position":[[1178,6]]},"286":{"position":[[115,6]]},"292":{"position":[[645,6]]},"300":{"position":[[943,6],[960,6],[1080,6]]},"302":{"position":[[467,6],[1048,6]]},"304":{"position":[[96,6],[203,6],[415,6],[638,6],[713,6]]},"306":{"position":[[45,6]]},"311":{"position":[[20,6]]},"316":{"position":[[106,6]]},"324":{"position":[[97,6]]},"366":{"position":[[226,6]]},"368":{"position":[[600,10]]},"384":{"position":[[44,9],[75,9],[146,9],[198,9],[220,9]]},"390":{"position":[[89,9]]},"392":{"position":[[305,9]]},"416":{"position":[[288,6]]},"418":{"position":[[549,8],[617,9],[924,8],[1009,6],[1896,6]]},"423":{"position":[[435,7],[450,6],[473,8],[486,8],[1289,6],[1333,6]]},"427":{"position":[[436,6],[3348,6],[3397,6],[3982,6]]},"429":{"position":[[3,6],[20,6]]},"431":{"position":[[544,6]]},"447":{"position":[[350,6]]},"455":{"position":[[278,7]]},"457":{"position":[[404,7],[466,6],[696,6],[1078,7]]},"461":{"position":[[151,7],[229,7],[303,6],[361,6],[695,6]]},"463":{"position":[[11,7],[1267,7],[1303,6],[1579,6],[1967,6],[2472,7]]},"465":{"position":[[672,7],[816,6],[867,6],[1099,6]]},"467":{"position":[[44,6]]},"469":{"position":[[63,6]]},"471":{"position":[[144,6]]},"475":{"position":[[275,6],[313,6]]},"504":{"position":[[635,7],[834,6],[1099,7],[1310,7],[1355,7],[1404,6]]},"508":{"position":[[191,6],[317,6]]},"512":{"position":[[135,6]]},"515":{"position":[[57,6],[167,6]]},"517":{"position":[[87,6]]},"519":{"position":[[509,7]]},"523":{"position":[[52,7],[73,7],[141,6],[275,6],[339,6],[415,7],[499,7]]},"531":{"position":[[66,7],[111,7],[121,6]]},"537":{"position":[[31,7],[269,6]]},"539":{"position":[[34,6]]},"614":{"position":[[0,6],[65,6],[184,6],[289,6],[339,6],[395,6],[459,6]]},"616":{"position":[[250,6],[290,6],[410,6],[548,6],[597,6],[621,6],[698,6],[755,6],[843,6],[860,6],[935,6],[942,7],[1028,6],[1065,6],[1090,6],[1167,6],[1269,6],[1361,6],[1419,6]]},"619":{"position":[[127,6],[160,6],[214,7],[337,6],[435,6],[466,6],[541,6],[607,6],[674,6],[712,6],[734,6],[779,6],[875,6]]},"621":{"position":[[342,6]]},"623":{"position":[[253,6]]},"625":{"position":[[322,6],[396,6],[635,6]]},"627":{"position":[[374,6],[432,6],[453,8],[683,6],[1181,6],[1238,6]]},"629":{"position":[[73,6],[116,6],[209,7],[331,6]]},"631":{"position":[[0,6],[184,6],[280,6],[523,6],[576,6],[758,6]]},"633":{"position":[[37,6],[132,6],[175,6],[217,6],[266,6],[330,6],[437,7],[550,6],[582,6],[1907,6],[1937,7]]},"635":{"position":[[41,6],[100,7],[118,6],[298,6],[589,6],[605,6],[644,6]]},"637":{"position":[[23,6],[51,6]]},"644":{"position":[[0,6],[112,6]]},"646":{"position":[[119,6],[147,6],[224,6],[256,7],[282,7]]},"648":{"position":[[134,6],[247,6]]},"655":{"position":[[16,6],[113,6]]},"659":{"position":[[15,6],[68,6],[192,6],[248,6]]},"662":{"position":[[64,6],[83,6],[121,6],[188,6],[202,6],[256,6],[377,6],[453,6],[484,6],[538,6],[584,6]]},"664":{"position":[[0,6],[197,6],[247,6]]},"666":{"position":[[27,6],[65,6]]},"668":{"position":[[31,6]]},"674":{"position":[[10,6],[82,6],[157,6],[174,6],[190,6]]},"678":{"position":[[122,6],[367,6]]},"680":{"position":[[510,6],[571,6],[624,6],[689,6],[746,6],[792,7],[877,7],[969,6],[1060,6],[1081,6],[1099,6],[1266,6]]},"682":{"position":[[269,6],[305,6],[364,7],[494,6]]},"684":{"position":[[9,6]]},"686":{"position":[[588,6],[754,6],[825,6],[952,6],[1148,7],[1798,7],[1875,6]]},"688":{"position":[[11,7],[325,6],[381,6],[505,6],[1021,7],[1241,6]]},"692":{"position":[[198,6]]},"694":{"position":[[319,6],[349,6],[574,6],[593,6],[962,6]]},"696":{"position":[[129,6],[168,6],[206,6],[547,6],[584,6],[659,6],[702,6],[741,6],[1081,6]]},"698":{"position":[[76,6],[1084,6],[1153,6],[1628,6]]},"700":{"position":[[493,6]]},"702":{"position":[[33,8],[61,6],[115,6],[163,6],[203,6],[244,6],[313,6],[348,6],[396,6],[420,6],[498,6],[545,6],[593,6],[730,6],[950,6],[1007,6],[1024,6]]},"704":{"position":[[330,6],[375,6],[448,6]]},"707":{"position":[[44,6],[121,6]]},"711":{"position":[[0,6],[65,6],[173,6],[237,6],[328,6],[504,6],[539,8]]},"713":{"position":[[311,9],[385,6],[486,6],[574,9],[652,9],[699,6],[729,7],[775,9],[856,7],[890,9],[986,9],[1181,6],[1216,8],[1297,6],[1312,6]]},"718":{"position":[[94,9],[110,6],[413,7],[504,7],[536,7],[779,6]]},"721":{"position":[[0,7]]},"723":{"position":[[0,7]]},"725":{"position":[[0,7],[236,7],[381,6]]},"727":{"position":[[0,7],[48,6],[270,6],[319,6],[502,6]]},"732":{"position":[[0,6],[67,6],[135,6],[191,6]]},"734":{"position":[[60,7]]},"738":{"position":[[137,7],[251,6]]},"744":{"position":[[155,6]]},"746":{"position":[[58,7],[230,7],[297,7]]},"748":{"position":[[97,7],[144,7],[273,6]]},"753":{"position":[[0,7],[73,6],[98,6],[142,6],[227,7],[325,6]]},"759":{"position":[[359,9]]},"761":{"position":[[706,9],[928,9]]},"773":{"position":[[0,9],[918,6]]},"798":{"position":[[252,6],[291,6],[401,9]]},"815":{"position":[[6,6],[81,6],[131,6],[149,6],[355,6],[547,6],[627,6]]},"817":{"position":[[407,6],[457,6],[495,6],[693,6],[770,6],[978,6],[1141,6],[1480,6],[1610,6],[1689,6],[1926,6],[2253,6],[2431,6],[2461,6],[2586,6],[2647,6]]},"819":{"position":[[406,9],[635,6],[804,6],[818,6],[904,6],[920,6],[978,6],[1043,6],[1099,6],[1131,6],[1170,6],[1648,6],[1726,6],[1743,6],[1942,6]]},"821":{"position":[[0,6],[95,6],[177,6],[461,6],[554,6],[670,6],[761,6],[775,6]]},"823":{"position":[[749,6],[1104,6],[1625,6],[1747,6]]},"825":{"position":[[227,6],[404,6],[510,6],[704,6]]},"827":{"position":[[356,6],[416,6],[514,6],[589,6],[611,6],[636,6],[682,6]]},"830":{"position":[[62,6],[104,6],[142,6],[223,6]]},"832":{"position":[[49,6],[415,6],[504,6],[526,6],[568,6],[818,6]]},"834":{"position":[[38,6],[113,6],[938,6]]},"836":{"position":[[11,7],[156,6],[395,6],[445,6],[786,6],[813,6],[967,6],[1155,6],[1220,6],[1297,6],[1353,6],[1430,6],[1502,6],[1519,6],[1592,6],[1609,6],[1632,6],[2053,6],[2517,6]]},"838":{"position":[[14,6],[67,6],[186,6],[478,6],[666,6],[1021,6]]},"840":{"position":[[190,6],[281,6],[342,6],[464,6],[529,6],[588,6],[711,6],[742,6]]},"842":{"position":[[7,6],[117,6],[216,6],[242,6],[365,6],[432,6],[1009,6],[1155,6],[1228,6],[1388,6],[1438,6],[1483,6],[1552,6],[1611,6],[1639,6],[1660,6],[1779,6],[1822,6],[1934,6]]},"844":{"position":[[0,6],[216,6],[572,6]]},"855":{"position":[[47,8]]},"874":{"position":[[17,6],[130,6],[223,6],[385,9],[459,9],[495,6]]},"876":{"position":[[804,7],[842,7],[944,6],[988,6],[1107,6],[1173,6],[1224,6],[1236,6]]},"881":{"position":[[50,6],[94,9]]},"883":{"position":[[49,6],[63,9],[586,6],[637,6],[660,6]]},"885":{"position":[[209,6],[299,6],[318,6],[334,6],[361,6],[434,6]]},"889":{"position":[[14,9],[119,6],[164,6],[267,6],[450,6],[483,7]]},"891":{"position":[[0,6],[61,9],[192,6]]},"893":{"position":[[9,6],[25,6],[119,6],[182,6],[242,6],[258,6],[324,6]]},"895":{"position":[[9,6],[270,6]]},"897":{"position":[[64,6],[130,6],[147,6],[225,6],[256,6],[286,6]]},"899":{"position":[[9,6],[32,6],[234,6],[259,6],[274,6],[317,6],[383,6],[575,6],[647,6],[676,6],[815,6],[1014,6],[1166,6],[1200,6]]},"901":{"position":[[11,6],[80,9],[1045,6],[1450,6],[1466,6],[1485,6],[1505,6],[1578,6],[1815,6],[1847,6],[1919,6],[1954,6],[1982,6],[2051,6],[2097,6],[2123,6],[2208,6]]},"905":{"position":[[153,6],[197,6]]},"913":{"position":[[99,6]]},"915":{"position":[[6,6],[31,6]]},"917":{"position":[[0,6],[40,6],[67,6],[85,6],[106,6],[129,6],[145,6],[196,6],[297,6],[484,6],[513,6],[676,6],[743,6],[787,6],[856,6],[944,6],[1011,6],[1243,6],[1302,6],[1563,6]]},"919":{"position":[[0,6],[119,6],[200,6],[552,6],[629,6],[670,6],[716,9],[740,6],[759,6],[784,6],[871,6],[906,6]]},"921":{"position":[[0,6],[80,6],[224,6],[258,6]]},"923":{"position":[[49,6],[74,6],[106,6],[122,7],[143,7],[262,6],[308,6],[349,6]]},"925":{"position":[[0,6]]},"927":{"position":[[79,6],[344,6]]},"929":{"position":[[0,6],[69,7],[176,6],[207,6]]},"931":{"position":[[95,6],[338,6]]},"933":{"position":[[12,9],[24,6],[95,6],[163,9],[175,6],[221,9],[422,6]]},"935":{"position":[[9,6],[25,6],[96,6],[170,6],[214,9],[282,9],[388,7],[403,6]]},"937":{"position":[[6,6],[80,6],[253,6],[286,6],[382,6],[523,6]]},"939":{"position":[[49,6],[153,6]]},"943":{"position":[[18,9],[160,6],[379,6]]},"945":{"position":[[224,6]]},"947":{"position":[[69,9],[85,6],[136,6],[153,6],[241,6],[251,6],[294,6],[349,6],[392,6],[543,6]]},"949":{"position":[[0,6],[131,6],[182,9],[255,6],[401,6],[498,6],[602,6]]},"953":{"position":[[301,9]]},"955":{"position":[[47,9],[68,6],[151,6],[249,6],[283,6],[343,6],[418,6],[559,6]]},"957":{"position":[[22,6],[149,6]]},"959":{"position":[[0,9]]},"961":{"position":[[12,6],[57,9],[76,6],[255,7]]},"963":{"position":[[0,6],[186,6],[261,6],[547,6],[780,6],[1012,6],[1234,6],[1346,6],[1496,9],[1974,6],[2181,6],[2219,6],[2248,6],[2306,6],[2445,6],[2504,6],[2549,6],[2642,6],[2916,6],[3191,6],[3287,6]]},"965":{"position":[[0,6]]},"967":{"position":[[14,6],[92,6]]},"969":{"position":[[45,6],[177,6],[238,6],[301,9],[525,6],[621,6]]},"971":{"position":[[388,6]]},"973":{"position":[[0,7]]},"975":{"position":[[0,6],[20,6],[42,6],[260,6],[385,6],[431,6],[544,6],[620,7],[654,6],[680,6],[827,6],[886,6],[916,6],[939,6],[981,6],[1071,6],[1092,6]]},"977":{"position":[[15,6],[68,6],[370,6]]},"979":{"position":[[0,6],[26,6],[91,7],[131,6],[206,6]]},"981":{"position":[[0,9],[155,6]]},"983":{"position":[[229,6],[364,6],[457,6],[626,6],[1218,6]]},"987":{"position":[[111,6],[137,6]]},"995":{"position":[[35,6],[87,6],[144,6],[185,6],[367,6]]},"997":{"position":[[74,6],[92,6]]},"1001":{"position":[[511,6],[921,6]]},"1016":{"position":[[167,6]]},"1018":{"position":[[37,6]]},"1022":{"position":[[147,6]]},"1085":{"position":[[349,6]]},"1087":{"position":[[1387,6],[1430,6],[1518,6],[1567,6],[1614,6],[1667,6],[1723,6],[1797,6],[1854,6],[1944,6],[2015,6],[2254,6],[2644,6]]},"1090":{"position":[[151,6],[227,6],[299,6],[342,6],[413,6],[548,6],[572,6]]},"1092":{"position":[[4,6],[39,6],[120,6],[430,6],[1297,6],[1469,6],[1897,6]]},"1094":{"position":[[0,6],[154,6],[200,6],[388,6]]},"1096":{"position":[[14,6],[234,6],[894,6],[1143,6],[1543,6],[1594,6],[1681,6],[1964,6],[2357,6],[2580,6]]},"1101":{"position":[[206,6]]},"1125":{"position":[[18,6],[146,6],[385,6]]},"1127":{"position":[[196,6],[262,6]]},"1131":{"position":[[10,6]]},"1137":{"position":[[629,6]]},"1198":{"position":[[103,6],[149,6],[417,6],[466,6],[520,6],[577,6]]},"1200":{"position":[[193,6],[255,6],[284,6],[330,6],[370,6],[571,6],[591,6],[905,6],[1034,6],[1109,6],[1123,6],[1488,6],[1561,6],[1602,6],[1686,6],[1764,6],[1866,6]]},"1205":{"position":[[38,6],[86,6],[98,6],[130,6],[174,6],[203,6]]},"1207":{"position":[[368,9],[477,6],[620,6]]},"1209":{"position":[[30,6],[186,6]]},"1211":{"position":[[58,6],[396,6],[423,6],[536,6],[550,6]]},"1214":{"position":[[108,6]]},"1218":{"position":[[556,6]]},"1220":{"position":[[63,6],[89,6],[125,6],[164,6],[217,6],[263,6]]},"1222":{"position":[[52,6],[96,6],[361,6],[572,6],[1383,6]]},"1224":{"position":[[0,6]]},"1226":{"position":[[33,6],[84,6],[147,6],[206,6]]},"1232":{"position":[[41,6],[96,6],[110,6],[157,6],[229,6],[283,6]]},"1234":{"position":[[0,6],[111,6]]},"1240":{"position":[[76,6],[139,6]]},"1242":{"position":[[18,6],[45,6]]}}}],["prompt+lm",{"_index":2866,"t":{"939":{"position":[[0,9]]},"955":{"position":[[519,9]]},"963":{"position":[[2190,9]]}}}],["promptless",{"_index":2856,"t":{"931":{"position":[[0,10]]}}}],["promt",{"_index":2786,"t":{"903":{"position":[[0,5]]}}}],["promtpt",{"_index":3006,"t":{"997":{"position":[[34,7]]}}}],["propag",{"_index":2384,"t":{"773":{"position":[[826,10]]},"1222":{"position":[[1316,9]]}}}],["proper",{"_index":2743,"t":{"889":{"position":[[157,6]]},"1198":{"position":[[96,6]]},"1200":{"position":[[277,6]]},"1205":{"position":[[79,6]]},"1220":{"position":[[82,6]]}}}],["proport",{"_index":2117,"t":{"648":{"position":[[30,12]]}}}],["propos",{"_index":1710,"t":{"523":{"position":[[655,8]]},"1087":{"position":[[1695,9],[1740,9],[2235,9],[2280,9]]},"1096":{"position":[[1509,9],[1531,9],[1620,9],[2554,8]]}}}],["prototyp",{"_index":2571,"t":{"836":{"position":[[1639,9]]}}}],["prune",{"_index":1941,"t":{"619":{"position":[[75,7]]},"911":{"position":[[507,5],[562,6],[1019,6],[1137,7]]},"1137":{"position":[[964,7],[1032,7],[1148,7],[1260,7],[2280,7]]},"1146":{"position":[[1501,7],[1539,5],[1613,7],[1632,6]]},"1148":{"position":[[1671,7]]},"1152":{"position":[[194,7]]},"1158":{"position":[[503,6]]},"1186":{"position":[[41,7],[245,7],[304,7]]}}}],["pr⁡(y∣x)\\pr",{"_index":2486,"t":{"819":{"position":[[132,11]]}}}],["pr⁡θ(y∣[p;x])\\pr_\\theta",{"_index":2492,"t":{"819":{"position":[[548,23]]}}}],["pr⁡θ(y∣x)\\pr_\\theta",{"_index":2489,"t":{"819":{"position":[[255,19]]}}}],["pr⁡θ;θp(y∣[p;x])\\pr_{\\theta;\\theta_p}(y|[p;x])prθ;θp​​(y∣[p;x",{"_index":2500,"t":{"819":{"position":[[1271,63]]}}}],["pseudo",{"_index":2194,"t":{"686":{"position":[[1449,6]]},"1200":{"position":[[983,6],[1008,6],[1360,6],[1404,6],[1440,6],[1584,6],[1791,6]]},"1207":{"position":[[83,6],[119,6],[429,6]]},"1209":{"position":[[151,6]]},"1211":{"position":[[32,6],[173,6],[219,6],[469,6]]},"1216":{"position":[[77,6],[399,6],[536,6],[654,6]]},"1218":{"position":[[194,6],[227,6],[477,6],[586,6]]},"1222":{"position":[[30,6],[656,6],[1220,6]]},"1230":{"position":[[118,6],[296,6]]},"1232":{"position":[[76,6],[171,6]]},"1240":{"position":[[231,6]]}}}],["pt",{"_index":1932,"t":{"616":{"position":[[264,4],[376,2],[1337,2]]},"627":{"position":[[657,2],[1081,2]]},"646":{"position":[[133,4]]},"651":{"position":[[134,2]]},"653":{"position":[[128,2],[227,2]]},"655":{"position":[[189,2]]},"657":{"position":[[112,2]]},"713":{"position":[[713,4],[874,2],[981,2]]},"723":{"position":[[61,2],[130,2]]},"725":{"position":[[89,2]]},"746":{"position":[[333,2]]},"751":{"position":[[3,2]]}}}],["ptr",{"_index":2783,"t":{"901":{"position":[[2233,5],[2391,3]]}}}],["ptx",{"_index":3024,"t":{"1001":{"position":[[1336,3],[2011,3],[2059,3]]},"1013":{"position":[[324,4]]}}}],["public",{"_index":1315,"t":{"423":{"position":[[420,6],[1384,6]]},"447":{"position":[[178,6]]},"825":{"position":[[77,6]]}}}],["publicli",{"_index":3667,"t":{"1158":{"position":[[29,8]]}}}],["purpos",{"_index":2603,"t":{"844":{"position":[[258,7]]}}}],["pv",{"_index":235,"t":{"38":{"position":[[440,2]]}}}],["pyramid",{"_index":3270,"t":{"1092":{"position":[[1157,7]]}}}],["python",{"_index":1157,"t":{"360":{"position":[[83,8]]}}}],["pytorch",{"_index":3666,"t":{"1158":{"position":[[4,7]]}}}],["pˉi=∑m=1mpim/m\\bar{p}_i",{"_index":3786,"t":{"1218":{"position":[[362,23]]}}}],["pˉi\\bar{p}_ipˉ​i",{"_index":3789,"t":{"1218":{"position":[[437,17],[500,17]]}}}],["pθ[i:0]=mlpθ(pθ′[i,:])p_\\theta",{"_index":2414,"t":{"777":{"position":[[192,30]]}}}],["pθp_\\thetap",{"_index":2405,"t":{"775":{"position":[[1082,13],[1168,13],[1354,13]]},"777":{"position":[[0,13],[391,13],[520,15]]}}}],["pθ′p'_\\thetap",{"_index":2412,"t":{"777":{"position":[[82,18],[325,16]]}}}],["pθ′p_\\theta'p",{"_index":2419,"t":{"777":{"position":[[407,16]]}}}],["pλq\\triangl",{"_index":3441,"t":{"1137":{"position":[[3980,14]]}}}],["pϕ(i",{"_index":2333,"t":{"766":{"position":[[76,4]]},"768":{"position":[[0,4]]}}}],["pϕ(y∣x)p\\phi(y|x)pϕ(y∣x",{"_index":1757,"t":{"553":{"position":[[103,24]]}}}],["pϕ(zi+1",{"_index":2354,"t":{"766":{"position":[[823,7]]}}}],["pϕp_{\\phi}p",{"_index":2367,"t":{"770":{"position":[[58,13]]}}}],["p∈rd1×rp",{"_index":3501,"t":{"1146":{"position":[[217,8]]}}}],["p∈rl×dp",{"_index":1982,"t":{"627":{"position":[[697,7]]}}}],["p∗p^*p",{"_index":2009,"t":{"631":{"position":[[530,7],[848,7]]},"633":{"position":[[82,7],[447,7],[596,7]]},"635":{"position":[[766,8],[830,8],[1071,7]]}}}],["p∗∈rl×dp",{"_index":1999,"t":{"631":{"position":[[225,10]]}}}],["q",{"_index":3499,"t":{"1146":{"position":[[179,2]]}}}],["q&a",{"_index":2584,"t":{"838":{"position":[[792,3]]}}}],["q)sim(v,q",{"_index":1031,"t":{"302":{"position":[[644,10],[873,10]]}}}],["q:/\"\"a",{"_index":1215,"t":{"377":{"position":[[149,8]]}}}],["q={qk}k=1n\\mathcal{q",{"_index":3551,"t":{"1148":{"position":[[685,21]]}}}],["q^j,a^j}j=1u",{"_index":1013,"t":{"300":{"position":[[688,15]]}}}],["q_k",{"_index":3552,"t":{"1148":{"position":[[712,3]]}}}],["q_k)l(p,e,q)=c(p,e,q)+γ∑k=1n​r(pk​,qk",{"_index":3562,"t":{"1148":{"position":[[1032,39]]}}}],["q_k△k​=pk​λk​qk",{"_index":3536,"t":{"1148":{"position":[[288,16]]}}}],["q_l",{"_index":1559,"t":{"463":{"position":[[554,3],[895,3]]}}}],["q_{i",{"_index":3517,"t":{"1146":{"position":[[658,6]]}}}],["q_{k,i",{"_index":3543,"t":{"1148":{"position":[[441,8]]}}}],["qa",{"_index":968,"t":{"281":{"position":[[1165,2],[1467,2],[1491,2],[1541,2],[1585,2],[1902,2],[2087,2]]},"290":{"position":[[437,2]]},"292":{"position":[[221,2],[438,2],[736,2],[767,2]]},"300":{"position":[[66,2],[294,2],[573,2],[821,2],[911,2],[940,2],[995,2]]},"302":{"position":[[13,2]]},"304":{"position":[[67,2],[282,2]]},"382":{"position":[[214,2]]},"451":{"position":[[635,2]]},"471":{"position":[[21,2]]},"494":{"position":[[104,2]]},"504":{"position":[[888,2]]},"672":{"position":[[108,3]]},"748":{"position":[[63,2],[82,2],[305,2]]},"838":{"position":[[255,2],[315,2],[348,2]]},"953":{"position":[[19,4],[84,2],[110,2],[179,2],[218,2],[420,2],[502,2],[531,2]]},"963":{"position":[[988,2],[1214,2],[1370,2],[1537,2]]},"983":{"position":[[148,2]]},"1137":{"position":[[4439,2]]},"1156":{"position":[[90,2]]},"1170":{"position":[[14,2]]},"1194":{"position":[[365,2]]}}}],["qk(t)q_k^{(t)}qk(t",{"_index":3568,"t":{"1148":{"position":[[1224,20]]}}}],["qk,i∗q_{k,i*}qk,i",{"_index":3622,"t":{"1152":{"position":[[743,19]]}}}],["ql=linearq",{"_index":1553,"t":{"463":{"position":[[471,11]]}}}],["qlq_lql",{"_index":1569,"t":{"463":{"position":[[807,8]]}}}],["qnli",{"_index":2095,"t":{"642":{"position":[[70,4],[218,4]]}}}],["qq^\\top",{"_index":3524,"t":{"1146":{"position":[[1013,7]]}}}],["qqp",{"_index":2096,"t":{"642":{"position":[[75,3],[213,4]]},"838":{"position":[[780,3],[885,4],[994,3]]}}}],["qqq",{"_index":993,"t":{"292":{"position":[[669,3],[816,3]]},"302":{"position":[[603,3]]},"1137":{"position":[[4116,3],[4176,3]]},"1146":{"position":[[784,3],[861,3]]}}}],["qquad",{"_index":3351,"t":{"1099":{"position":[[401,6],[919,6],[1563,6]]}}}],["quad",{"_index":3459,"t":{"1140":{"position":[[379,5]]}}}],["qualiti",{"_index":842,"t":{"204":{"position":[[115,7]]},"504":{"position":[[2259,7]]},"515":{"position":[[816,7]]},"521":{"position":[[47,7],[381,7]]},"533":{"position":[[19,7],[516,7]]},"696":{"position":[[1167,7]]},"787":{"position":[[489,7]]},"817":{"position":[[855,7],[883,7],[1719,7],[2545,7]]},"834":{"position":[[52,7]]},"844":{"position":[[414,7]]}}}],["quantif",{"_index":3634,"t":{"1152":{"position":[[1568,14]]}}}],["quantifi",{"_index":3603,"t":{"1150":{"position":[[18,8],[315,8]]},"1152":{"position":[[74,8],[144,8],[325,8],[2293,8]]}}}],["quantit",{"_index":1646,"t":{"475":{"position":[[454,12]]},"477":{"position":[[88,12]]}}}],["quantiz",{"_index":602,"t":{"130":{"position":[[547,10]]},"143":{"position":[[601,12]]},"149":{"position":[[318,9]]}}}],["queri",{"_index":769,"t":{"176":{"position":[[363,5],[445,5],[531,7]]},"345":{"position":[[377,5],[1113,5]]},"463":{"position":[[415,8]]},"573":{"position":[[113,9]]},"713":{"position":[[404,5]]},"963":{"position":[[882,5],[910,5],[1036,5],[1163,5],[1324,5]]},"1085":{"position":[[179,5]]},"1087":{"position":[[1210,7],[2109,5]]},"1096":{"position":[[174,5],[667,7],[708,7],[771,5],[822,7],[879,7],[1127,7]]},"1104":{"position":[[253,7]]},"1127":{"position":[[12,5],[46,7],[114,7],[162,7],[181,5],[254,7],[312,7]]},"1140":{"position":[[694,6]]},"1142":{"position":[[743,5]]},"1160":{"position":[[831,5]]},"1200":{"position":[[707,5]]},"1205":{"position":[[372,5]]}}}],["query/key/value/output",{"_index":1746,"t":{"551":{"position":[[136,22]]}}}],["question",{"_index":591,"t":{"126":{"position":[[286,8]]},"165":{"position":[[117,8],[875,8]]},"279":{"position":[[72,8],[421,8]]},"281":{"position":[[209,8],[558,8],[1426,8],[1604,8]]},"284":{"position":[[18,8],[254,8]]},"290":{"position":[[302,8]]},"292":{"position":[[660,8],[807,8]]},"294":{"position":[[79,8],[124,8]]},"296":{"position":[[79,8],[98,8],[171,8]]},"298":{"position":[[60,8]]},"300":{"position":[[83,8],[115,8],[648,8],[670,8]]},"302":{"position":[[26,8],[77,8],[181,8],[373,8],[419,8],[541,8],[594,8],[720,8],[1306,8],[1380,8]]},"304":{"position":[[3,8],[19,8],[159,8],[296,10],[404,8],[438,10],[652,8],[668,8],[821,8]]},"309":{"position":[[16,9],[63,8],[99,9],[120,8]]},"311":{"position":[[0,8],[68,8],[87,8],[262,8]]},"316":{"position":[[158,8]]},"318":{"position":[[184,8]]},"324":{"position":[[16,8]]},"382":{"position":[[150,8]]},"398":{"position":[[116,8]]},"539":{"position":[[193,8]]},"623":{"position":[[111,8]]},"642":{"position":[[246,10]]},"698":{"position":[[129,8]]},"704":{"position":[[209,9]]},"713":{"position":[[1502,8]]},"716":{"position":[[190,8]]},"740":{"position":[[92,8]]},"748":{"position":[[241,8]]},"821":{"position":[[342,9]]},"895":{"position":[[176,8],[305,9]]},"905":{"position":[[433,8]]},"909":{"position":[[345,8],[701,8]]},"953":{"position":[[0,8],[56,8],[359,8]]},"963":{"position":[[1415,8],[1476,8]]},"997":{"position":[[113,9]]},"1135":{"position":[[790,8]]}}}],["question]\\textup{[question]}[quest",{"_index":1046,"t":{"304":{"position":[[307,39],[449,40]]}}}],["queu",{"_index":1128,"t":{"343":{"position":[[721,7]]}}}],["queue",{"_index":1134,"t":{"345":{"position":[[953,5],[1136,5]]}}}],["qustion",{"_index":1070,"t":{"318":{"position":[[83,7]]},"533":{"position":[[567,8]]}}}],["q∈rr×d2q",{"_index":3503,"t":{"1146":{"position":[[266,8]]}}}],["q△=pλq",{"_index":3442,"t":{"1137":{"position":[[4007,6]]}}}],["r",{"_index":697,"t":{"153":{"position":[[55,1],[119,1],[144,1],[353,1],[457,1],[553,1]]},"565":{"position":[[56,1]]},"585":{"position":[[548,1],[552,1]]},"1001":{"position":[[673,3],[862,4]]},"1087":{"position":[[507,2],[1536,1]]},"1090":{"position":[[206,1]]},"1099":{"position":[[1308,1]]},"1121":{"position":[[32,1]]}}}],["r(p,q",{"_index":3521,"t":{"1146":{"position":[[950,6]]}}}],["r(p,q)=∥p⊤p−i∥f2=∥qq⊤−i∥f2.\\begin{equ",{"_index":3520,"t":{"1146":{"position":[[906,43]]}}}],["r(p_k",{"_index":3561,"t":{"1148":{"position":[[1025,6]]}}}],["r0r_0r0",{"_index":2673,"t":{"863":{"position":[[128,8],[278,8]]}}}],["r101x1",{"_index":551,"t":{"114":{"position":[[72,7]]}}}],["r152x1",{"_index":552,"t":{"114":{"position":[[80,7]]}}}],["r152x2",{"_index":553,"t":{"114":{"position":[[88,6],[119,7]]}}}],["r200x3",{"_index":555,"t":{"114":{"position":[[127,6]]}}}],["r50",{"_index":562,"t":{"114":{"position":[[297,3]]}}}],["r50+vit",{"_index":561,"t":{"114":{"position":[[243,7]]}}}],["r50x1",{"_index":549,"t":{"114":{"position":[[59,6]]}}}],["r50x2",{"_index":550,"t":{"114":{"position":[[66,5]]}}}],["r=1r",{"_index":1912,"t":{"604":{"position":[[1186,4]]}}}],["r=4r",{"_index":1826,"t":{"571":{"position":[[205,4]]},"600":{"position":[[178,4]]},"608":{"position":[[648,4]]}}}],["r=64r",{"_index":1914,"t":{"606":{"position":[[0,5]]}}}],["r=8r",{"_index":1871,"t":{"600":{"position":[[89,4]]},"1137":{"position":[[2091,4]]}}}],["r=b(0)/nr",{"_index":3658,"t":{"1154":{"position":[[431,9]]}}}],["r\\frac{\\alpha}{r}r",{"_index":1814,"t":{"563":{"position":[[953,21]]}}}],["r_0",{"_index":2677,"t":{"863":{"position":[[339,3]]}}}],["r_{\\theta",{"_index":3015,"t":{"1001":{"position":[[778,11]]}}}],["r_{\\theta}(x",{"_index":3017,"t":{"1001":{"position":[[803,13]]}}}],["race",{"_index":2896,"t":{"953":{"position":[[182,6]]}}}],["raffel",{"_index":2536,"t":{"823":{"position":[[653,7]]}}}],["raft",{"_index":1294,"t":{"416":{"position":[[702,4]]},"418":{"position":[[2308,4]]},"423":{"position":[[931,4],[975,4]]},"447":{"position":[[71,4],[82,4],[136,4]]},"451":{"position":[[394,4]]}}}],["rand",{"_index":1654,"t":{"489":{"position":[[112,4],[234,4]]}}}],["randag",{"_index":303,"t":{"53":{"position":[[323,10]]}}}],["randaug",{"_index":265,"t":{"49":{"position":[[497,11]]},"78":{"position":[[567,12],[748,11]]}}}],["random",{"_index":1656,"t":{"489":{"position":[[164,6]]},"563":{"position":[[191,6],[867,6]]},"608":{"position":[[350,6],[463,6]]},"688":{"position":[[162,6]]},"698":{"position":[[840,6]]},"802":{"position":[[66,6],[285,6],[371,6]]},"804":{"position":[[22,6],[242,6]]},"821":{"position":[[48,6]]},"832":{"position":[[86,6]]},"834":{"position":[[954,6]]},"842":{"position":[[1090,6],[1326,6]]},"1142":{"position":[[482,6]]},"1146":{"position":[[831,6]]},"1226":{"position":[[132,6]]}}}],["randomli",{"_index":2309,"t":{"736":{"position":[[139,8]]}}}],["rangle⟨i",{"_index":2531,"t":{"823":{"position":[[445,10],[529,10]]}}}],["rangle⟨x",{"_index":2529,"t":{"823":{"position":[[404,10],[492,10]]}}}],["rangle⟨z",{"_index":2534,"t":{"823":{"position":[[558,11]]}}}],["rank",{"_index":1267,"t":{"398":{"position":[[453,4]]},"423":{"position":[[1061,5],[1203,4]]},"425":{"position":[[436,4],[1020,4],[1129,7],[1276,7],[1369,4]]},"427":{"position":[[3286,4],[3645,4]]},"437":{"position":[[718,4]]},"517":{"position":[[274,4]]},"519":{"position":[[591,4]]},"547":{"position":[[54,4],[144,4],[449,4]]},"549":{"position":[[482,5],[511,4],[617,4],[725,4],[737,4],[1123,4]]},"563":{"position":[[75,4],[322,4],[488,4]]},"565":{"position":[[49,4],[58,4]]},"587":{"position":[[21,4]]},"598":{"position":[[125,4]]},"600":{"position":[[377,4]]},"602":{"position":[[149,5]]},"606":{"position":[[140,5]]},"610":{"position":[[283,4]]},"614":{"position":[[487,4]]},"616":{"position":[[980,4],[1187,4]]},"629":{"position":[[183,4],[351,4]]},"631":{"position":[[435,4],[792,4],[899,4]]},"635":{"position":[[639,4]]},"674":{"position":[[206,4]]},"1137":{"position":[[1627,4],[2008,4],[2403,4],[3287,4],[3421,4],[3486,4],[3630,4],[3682,4],[3777,4]]},"1144":{"position":[[119,4]]},"1146":{"position":[[1137,4],[1516,4],[1988,4]]},"1150":{"position":[[232,4]]},"1154":{"position":[[0,4],[13,4],[106,4],[424,4]]},"1160":{"position":[[768,4]]},"1165":{"position":[[233,4]]},"1172":{"position":[[239,4],[312,4]]},"1186":{"position":[[52,4]]},"1192":{"position":[[83,4],[359,4]]}}}],["rank/svd",{"_index":3710,"t":{"1179":{"position":[[31,8]]}}}],["rare",{"_index":2876,"t":{"943":{"position":[[562,4]]}}}],["rasley",{"_index":1191,"t":{"362":{"position":[[1091,7]]}}}],["rate",{"_index":254,"t":{"49":{"position":[[210,4],[225,4]]},"53":{"position":[[303,4]]},"153":{"position":[[725,4]]},"379":{"position":[[78,5]]},"431":{"position":[[388,4]]},"635":{"position":[[874,4]]},"694":{"position":[[1063,4]]},"698":{"position":[[1221,4],[1384,4]]},"784":{"position":[[196,4],[260,4],[347,4]]},"825":{"position":[[727,4]]},"827":{"position":[[73,4]]},"1001":{"position":[[268,4]]},"1148":{"position":[[1596,4]]},"1158":{"position":[[271,4]]},"1165":{"position":[[612,4]]},"1172":{"position":[[436,4]]},"1236":{"position":[[35,4]]}}}],["rational",{"_index":880,"t":{"229":{"position":[[545,9]]},"273":{"position":[[99,9]]}}}],["raw",{"_index":2698,"t":{"874":{"position":[[349,3]]},"876":{"position":[[113,3]]}}}],["rcnn",{"_index":706,"t":{"153":{"position":[[339,4],[412,4]]}}}],["rd1×d2\\triangl",{"_index":3419,"t":{"1137":{"position":[[1779,17]]},"1142":{"position":[[272,17]]}}}],["re",{"_index":805,"t":{"186":{"position":[[132,2]]},"1087":{"position":[[464,6],[1531,4]]},"1090":{"position":[[200,3]]},"1099":{"position":[[783,3]]},"1109":{"position":[[6,3],[55,3]]}}}],["react",{"_index":39,"t":{"7":{"position":[[83,5]]},"855":{"position":[[244,5]]},"1038":{"position":[[16,5]]},"1040":{"position":[[30,5],[58,5],[79,5],[90,8],[200,5],[229,5],[315,5]]},"1061":{"position":[[70,5]]}}}],["read",{"_index":743,"t":{"169":{"position":[[579,8]]},"1026":{"position":[[0,4]]},"1047":{"position":[[196,5]]}}}],["readi",{"_index":132,"t":{"19":{"position":[[314,5]]}}}],["real",{"_index":496,"t":{"102":{"position":[[172,4]]},"418":{"position":[[2274,4]]},"423":{"position":[[1023,5]]},"437":{"position":[[522,4]]},"447":{"position":[[34,4],[89,4],[462,4]]},"983":{"position":[[611,4]]}}}],["realtoxicityprompt",{"_index":2993,"t":{"989":{"position":[[712,18]]},"1003":{"position":[[493,19]]}}}],["reason",{"_index":860,"t":{"227":{"position":[[32,9],[77,9],[146,9],[225,9]]},"229":{"position":[[101,9],[168,9],[196,9],[794,9],[903,9]]},"231":{"position":[[399,9]]},"233":{"position":[[16,9]]},"254":{"position":[[566,9]]},"263":{"position":[[37,9]]},"271":{"position":[[62,9],[151,9],[291,9],[418,11],[510,9],[573,9]]},"273":{"position":[[37,9]]},"275":{"position":[[22,9],[104,9],[137,9],[160,9]]},"304":{"position":[[138,6]]},"375":{"position":[[112,10],[133,10]]},"382":{"position":[[30,9]]},"398":{"position":[[41,9],[74,10],[150,10]]},"408":{"position":[[181,10]]},"455":{"position":[[554,9]]},"457":{"position":[[1036,9]]},"498":{"position":[[213,9]]},"502":{"position":[[662,9]]},"504":{"position":[[413,9],[876,9]]},"510":{"position":[[12,9]]},"521":{"position":[[474,9]]},"523":{"position":[[705,9]]},"525":{"position":[[353,9]]},"539":{"position":[[147,9]]},"672":{"position":[[159,9]]},"696":{"position":[[954,9]]},"698":{"position":[[210,9]]},"848":{"position":[[539,10]]},"850":{"position":[[704,9],[1604,9],[1799,9]]},"857":{"position":[[250,9]]},"951":{"position":[[102,9],[500,9]]}}}],["reberta",{"_index":1519,"t":{"457":{"position":[[1355,7]]}}}],["rec",{"_index":3246,"t":{"1087":{"position":[[423,6],[1525,5]]},"1090":{"position":[[195,4]]},"1099":{"position":[[777,3]]},"1109":{"position":[[0,3],[49,3]]}}}],["receni",{"_index":2969,"t":{"983":{"position":[[311,6]]}}}],["recept",{"_index":571,"t":{"116":{"position":[[717,9],[897,9],[913,9]]}}}],["recip",{"_index":1292,"t":{"416":{"position":[[684,6]]},"418":{"position":[[1837,6],[2226,6]]},"421":{"position":[[249,6],[267,6]]},"425":{"position":[[2572,6]]},"429":{"position":[[530,6]]},"431":{"position":[[11,6],[621,6],[726,6]]},"433":{"position":[[6,6],[108,6]]},"445":{"position":[[241,6]]},"451":{"position":[[10,6],[87,6]]}}}],["recogmnit",{"_index":3750,"t":{"1203":{"position":[[635,12]]}}}],["recognit",{"_index":725,"t":{"165":{"position":[[164,12]]},"169":{"position":[[624,12]]},"713":{"position":[[1536,11]]},"716":{"position":[[165,11]]},"740":{"position":[[68,12]]},"905":{"position":[[335,11]]},"909":{"position":[[315,11],[548,11]]},"949":{"position":[[536,11]]},"1198":{"position":[[235,11]]},"1200":{"position":[[477,11],[864,11]]},"1203":{"position":[[603,12]]},"1207":{"position":[[250,12],[270,11]]},"1216":{"position":[[253,11]]}}}],["recommend",{"_index":93,"t":{"15":{"position":[[65,11]]}}}],["recongnit",{"_index":3813,"t":{"1224":{"position":[[244,12]]}}}],["reconstruct",{"_index":2523,"t":{"823":{"position":[[169,14]]}}}],["record",{"_index":2098,"t":{"642":{"position":[[91,6]]},"698":{"position":[[67,6]]}}}],["recoveri",{"_index":2963,"t":{"977":{"position":[[95,8]]}}}],["recurr",{"_index":2393,"t":{"775":{"position":[[373,10]]}}}],["redund",{"_index":3497,"t":{"1144":{"position":[[169,9]]}}}],["ref",{"_index":3368,"t":{"1099":{"position":[[1314,4]]},"1121":{"position":[[0,3],[18,3]]},"1123":{"position":[[66,3]]}}}],["refactor",{"_index":2959,"t":{"975":{"position":[[336,8]]}}}],["refcoco",{"_index":3353,"t":{"1099":{"position":[[570,8],[579,8]]},"1109":{"position":[[12,8],[21,8]]},"1123":{"position":[[44,8]]}}}],["refcoco/g",{"_index":3359,"t":{"1099":{"position":[[1210,12]]}}}],["refcocog",{"_index":3354,"t":{"1099":{"position":[[590,8]]},"1109":{"position":[[32,8]]}}}],["refer",{"_index":366,"t":{"78":{"position":[[901,5]]},"698":{"position":[[182,9]]},"1055":{"position":[[69,9],[187,9]]},"1085":{"position":[[673,10]]},"1087":{"position":[[388,9],[430,9],[471,9],[1543,9],[1888,9],[1913,9]]},"1092":{"position":[[601,9],[992,9]]},"1096":{"position":[[522,9],[636,9]]},"1099":{"position":[[1352,9]]}}}],["reflect",{"_index":2611,"t":{"848":{"position":[[300,10]]},"850":{"position":[[458,10],[657,10],[759,10],[2046,10],[2074,10]]},"853":{"position":[[136,10]]},"859":{"position":[[11,10],[89,11],[261,10],[771,10]]},"861":{"position":[[236,10]]},"863":{"position":[[302,10],[486,10]]}}}],["reflexion",{"_index":2610,"t":{"848":{"position":[[187,9],[259,9],[378,9]]},"850":{"position":[[294,9],[620,9],[1128,9],[1928,9],[2221,9]]},"857":{"position":[[0,9]]},"861":{"position":[[0,9],[370,9]]},"863":{"position":[[590,9]]},"870":{"position":[[274,9]]}}}],["reflxion",{"_index":2685,"t":{"870":{"position":[[0,8]]}}}],["reformul",{"_index":2919,"t":{"963":{"position":[[888,13],[1042,13],[1169,13],[1330,13],[1384,13]]}}}],["region",{"_index":593,"t":{"126":{"position":[[485,7]]},"130":{"position":[[129,7]]},"147":{"position":[[362,6],[404,6]]},"149":{"position":[[39,6],[69,6],[122,6],[168,6]]},"155":{"position":[[517,6]]},"1092":{"position":[[929,6]]},"1113":{"position":[[62,6]]},"1121":{"position":[[92,6]]}}}],["regress",{"_index":539,"t":{"108":{"position":[[135,10]]},"169":{"position":[[213,10]]},"311":{"position":[[412,12]]},"330":{"position":[[1016,12]]},"339":{"position":[[15,10]]},"893":{"position":[[91,10]]}}}],["regular",{"_index":54,"t":{"9":{"position":[[123,7]]},"23":{"position":[[222,14]]},"33":{"position":[[44,7],[170,7]]},"47":{"position":[[72,14],[123,14],[170,14],[322,14],[351,14],[458,14]]},"53":{"position":[[308,14]]},"74":{"position":[[20,14]]},"78":{"position":[[315,14],[378,14],[452,14],[536,14],[639,14],[725,14]]},"108":{"position":[[109,11]]},"112":{"position":[[176,14]]},"635":{"position":[[806,7]]},"1053":{"position":[[0,7]]},"1055":{"position":[[0,7]]},"1137":{"position":[[4198,12]]},"1146":{"position":[[891,11]]},"1148":{"position":[[826,14],[1091,14]]},"1165":{"position":[[431,14]]},"1190":{"position":[[238,14],[315,14],[490,14]]}}}],["reinforc",{"_index":2609,"t":{"848":{"position":[[57,13]]},"853":{"position":[[197,13]]},"1001":{"position":[[1096,13]]}}}],["rel",{"_index":3164,"t":{"1053":{"position":[[57,8]]},"1055":{"position":[[204,8]]}}}],["relat",{"_index":96,"t":{"15":{"position":[[101,7]]},"328":{"position":[[718,7],[891,7]]},"621":{"position":[[45,7]]},"694":{"position":[[64,9]]},"775":{"position":[[384,8]]},"842":{"position":[[968,7]]},"899":{"position":[[1084,8]]},"901":{"position":[[2446,8]]},"905":{"position":[[301,8]]},"921":{"position":[[97,8]]},"949":{"position":[[50,8],[97,8]]},"963":{"position":[[1890,8]]},"969":{"position":[[381,10]]},"975":{"position":[[581,8]]}}}],["releas",{"_index":3208,"t":{"1065":{"position":[[0,7]]}}}],["relev",{"_index":1017,"t":{"302":{"position":[[35,8]]},"899":{"position":[[873,8]]}}}],["relfexion",{"_index":2652,"t":{"855":{"position":[[301,9]]},"859":{"position":[[109,9]]}}}],["reload",{"_index":139,"t":{"19":{"position":[[424,7]]}}}],["relu",{"_index":773,"t":{"178":{"position":[[225,4]]},"688":{"position":[[573,4]]},"1140":{"position":[[830,4]]}}}],["remain",{"_index":3729,"t":{"1192":{"position":[[416,9],[478,9]]}}}],["remov",{"_index":364,"t":{"78":{"position":[[867,6]]}}}],["reparameter",{"_index":2305,"t":{"730":{"position":[[48,18]]},"777":{"position":[[169,15],[473,18]]},"811":{"position":[[892,18]]},"836":{"position":[[857,14],[902,14]]}}}],["replac",{"_index":352,"t":{"78":{"position":[[186,7],[834,7]]}}}],["report",{"_index":3073,"t":{"1024":{"position":[[237,6]]},"1179":{"position":[[126,6]]}}}],["repositori",{"_index":1164,"t":{"360":{"position":[[208,10]]}}}],["represent",{"_index":534,"t":{"108":{"position":[[38,14]]},"116":{"position":[[36,14],[68,14],[143,14],[270,14],[456,14]]},"132":{"position":[[165,14],[196,14],[320,14]]},"281":{"position":[[626,14]]},"290":{"position":[[13,14],[45,14]]},"324":{"position":[[224,14]]},"330":{"position":[[1131,14]]},"333":{"position":[[441,14]]},"343":{"position":[[22,15],[290,14],[440,15],[842,14]]},"345":{"position":[[148,15],[281,14],[347,14],[684,14]]},"360":{"position":[[678,14]]},"461":{"position":[[476,14]]},"773":{"position":[[1068,15]]},"817":{"position":[[93,14]]},"819":{"position":[[716,15]]},"821":{"position":[[7,14],[249,14]]},"832":{"position":[[379,14]]},"836":{"position":[[452,14],[558,15],[1879,14],[1972,14],[2457,14],[2552,14]]},"838":{"position":[[74,14],[103,14]]},"842":{"position":[[378,14],[1030,14],[1667,14]]},"901":{"position":[[1394,14]]},"911":{"position":[[832,14]]},"935":{"position":[[344,14]]},"943":{"position":[[70,14]]},"945":{"position":[[39,14]]},"1087":{"position":[[2463,15]]},"1094":{"position":[[347,15]]},"1096":{"position":[[21,15],[942,14]]},"1200":{"position":[[598,14],[1041,14],[1130,14],[1495,14],[1609,14],[1873,14]]},"1203":{"position":[[37,14],[523,14]]},"1207":{"position":[[484,14],[627,14]]},"1209":{"position":[[193,14]]},"1211":{"position":[[65,14],[403,14],[430,14],[557,14]]},"1214":{"position":[[147,14]]},"1218":{"position":[[563,14]]},"1220":{"position":[[270,14]]},"1222":{"position":[[59,14],[103,14],[579,14],[1390,14]]},"1224":{"position":[[7,14]]},"1226":{"position":[[91,14],[154,14],[213,14]]},"1232":{"position":[[290,14]]},"1234":{"position":[[7,14],[118,14]]}}}],["requir",{"_index":1310,"t":{"421":{"position":[[21,11]]}}}],["resampl",{"_index":767,"t":{"176":{"position":[[110,9],[140,9]]},"183":{"position":[[21,9]]},"211":{"position":[[0,9],[110,9],[132,9],[234,9]]}}}],["rescal",{"_index":1393,"t":{"427":{"position":[[782,10],[1178,9],[1279,9],[1363,9]]},"451":{"position":[[201,8]]}}}],["residu",{"_index":439,"t":{"91":{"position":[[1428,8],[2200,8]]},"178":{"position":[[284,8]]},"209":{"position":[[51,8]]},"585":{"position":[[17,8]]},"811":{"position":[[627,8]]},"1001":{"position":[[279,8]]},"1140":{"position":[[1082,8]]},"1160":{"position":[[415,8]]}}}],["resili",{"_index":2485,"t":{"817":{"position":[[2344,10]]}}}],["resiz",{"_index":194,"t":{"27":{"position":[[247,8]]}}}],["resnet",{"_index":187,"t":{"27":{"position":[[67,7]]},"86":{"position":[[131,6],[331,6]]},"99":{"position":[[0,7]]},"104":{"position":[[214,6],[319,6]]},"106":{"position":[[20,6]]},"112":{"position":[[80,6],[412,6]]},"114":{"position":[[50,8]]},"1104":{"position":[[18,6]]},"1123":{"position":[[7,6]]},"1203":{"position":[[380,7]]},"1218":{"position":[[32,6],[43,6],[67,6],[81,6]]},"1230":{"position":[[0,6],[151,6],[370,6]]},"1240":{"position":[[199,6]]}}}],["resnet50",{"_index":519,"t":{"104":{"position":[[455,8],[474,8]]}}}],["resnet50x16",{"_index":3814,"t":{"1230":{"position":[[175,12]]}}}],["resnet50x4",{"_index":3782,"t":{"1218":{"position":[[55,11]]},"1230":{"position":[[163,11]]}}}],["resnet50x64",{"_index":3815,"t":{"1230":{"position":[[188,12]]}}}],["resnetst",{"_index":188,"t":{"27":{"position":[[75,9]]},"55":{"position":[[88,8]]}}}],["resolut",{"_index":495,"t":{"102":{"position":[[97,10]]},"423":{"position":[[866,10]]},"698":{"position":[[192,10]]}}}],["resourc",{"_index":306,"t":{"55":{"position":[[26,8]]},"834":{"position":[[555,9]]}}}],["respect",{"_index":3220,"t":{"1069":{"position":[[47,10]]}}}],["respons",{"_index":1265,"t":{"398":{"position":[[386,8]]},"461":{"position":[[662,8],[963,8]]},"463":{"position":[[2583,8]]},"465":{"position":[[1150,8]]},"477":{"position":[[34,8]]},"510":{"position":[[321,8]]},"519":{"position":[[42,8]]},"533":{"position":[[507,8]]},"1001":{"position":[[520,8]]}}}],["result",{"_index":1296,"t":{"418":{"position":[[132,7]]},"704":{"position":[[178,7]]},"1053":{"position":[[182,7]]},"1137":{"position":[[3801,9]]},"1154":{"position":[[616,9]]},"1192":{"position":[[73,9]]}}}],["retain",{"_index":3413,"t":{"1137":{"position":[[1189,9]]}}}],["retriev",{"_index":790,"t":{"180":{"position":[[507,9]]},"328":{"position":[[864,9]]},"330":{"position":[[337,9]]},"353":{"position":[[202,9]]},"357":{"position":[[111,9],[199,9]]},"360":{"position":[[834,9]]},"623":{"position":[[141,9]]},"692":{"position":[[26,9]]},"1085":{"position":[[314,9]]},"1087":{"position":[[1636,9]]},"1090":{"position":[[434,9],[615,9]]},"1094":{"position":[[337,9]]},"1096":{"position":[[2563,9]]}}}],["retun",{"_index":1816,"t":{"563":{"position":[[1134,8]]}}}],["return",{"_index":3144,"t":{"1040":{"position":[[175,6]]},"1057":{"position":[[139,6],[247,6]]}}}],["reward",{"_index":233,"t":{"38":{"position":[[405,6]]},"850":{"position":[[1241,6]]},"857":{"position":[[142,6],[195,6],[351,6],[502,6]]},"859":{"position":[[184,6],[328,7]]},"863":{"position":[[175,6]]},"989":{"position":[[443,6]]},"993":{"position":[[140,6],[200,6],[224,6]]},"1001":{"position":[[450,6],[543,6],[600,6],[1939,6]]}}}],["rewrit",{"_index":2753,"t":{"899":{"position":[[390,8]]}}}],["rgb",{"_index":564,"t":{"116":{"position":[[305,3]]},"169":{"position":[[74,3],[160,3]]},"174":{"position":[[342,3],[434,3]]},"183":{"position":[[34,3]]},"206":{"position":[[65,3]]},"211":{"position":[[144,3],[198,3]]}}}],["rhoncu",{"_index":13,"t":{"3":{"position":[[107,7]]},"5":{"position":[[227,7],[406,7],[585,7],[764,7],[943,7],[1122,7],[1301,7],[1480,7],[1659,7],[1838,7],[2017,7],[2196,7],[2375,7],[2554,7],[2733,7],[2912,7]]}}}],["rh×w×c\\mathbb{r}^{h",{"_index":749,"t":{"171":{"position":[[512,19]]}}}],["rich",{"_index":588,"t":{"126":{"position":[[214,4]]}}}],["right",{"_index":1415,"t":{"427":{"position":[[1664,6]]},"465":{"position":[[552,7]]},"604":{"position":[[118,5]]},"775":{"position":[[1301,5]]},"893":{"position":[[141,5]]},"1094":{"position":[[609,7]]},"1146":{"position":[[981,6],[1025,6]]},"1152":{"position":[[1100,6],[1929,6]]},"1222":{"position":[[630,6]]}}}],["right.fp​=⎩⎨⎧​enclref​enclref​merge(encvref​[templ",{"_index":3299,"t":{"1092":{"position":[[2317,55]]}}}],["right.w=⎩⎨⎧​fp′​[i",{"_index":3337,"t":{"1096":{"position":[[2254,21]]}}}],["rightarrow",{"_index":1692,"t":{"515":{"position":[[612,11]]}}}],["rightward",{"_index":2385,"t":{"773":{"position":[[867,9]]}}}],["rl",{"_index":2640,"t":{"850":{"position":[[2208,2]]},"855":{"position":[[89,2]]},"861":{"position":[[175,2]]},"1001":{"position":[[1119,4],[1347,2],[1812,2]]},"1022":{"position":[[36,2]]}}}],["rl\\pi^{rl}_\\phiπϕrl",{"_index":3038,"t":{"1001":{"position":[[1783,22]]}}}],["rlhf",{"_index":2989,"t":{"989":{"position":[[315,4],[844,4],[876,4],[1109,4]]},"995":{"position":[[519,4]]},"1008":{"position":[[97,4]]},"1010":{"position":[[14,4]]},"1013":{"position":[[128,4]]}}}],["rm",{"_index":2991,"t":{"989":{"position":[[456,4],[469,2]]},"993":{"position":[[255,2]]},"995":{"position":[[457,2],[494,2]]},"1001":{"position":[[305,2],[413,2],[466,4],[570,2],[584,2],[937,2],[1048,2],[1073,2],[1194,2]]}}}],["rmsprop",{"_index":285,"t":{"53":{"position":[[119,7]]},"80":{"position":[[57,7]]}}}],["roberta",{"_index":795,"t":{"183":{"position":[[128,7]]},"455":{"position":[[615,9]]},"471":{"position":[[0,7]]},"547":{"position":[[322,8]]},"573":{"position":[[0,8]]},"589":{"position":[[0,7],[72,7],[94,7]]},"742":{"position":[[19,7]]},"931":{"position":[[136,7]]}}}],["robertabase_{base}bas",{"_index":798,"t":{"183":{"position":[[250,23]]}}}],["robertalarge_{large}larg",{"_index":800,"t":{"183":{"position":[[295,26]]},"494":{"position":[[118,26]]}}}],["robust",{"_index":913,"t":{"254":{"position":[[32,10],[539,10],[617,6]]},"271":{"position":[[117,6]]},"815":{"position":[[604,10]]},"817":{"position":[[2555,10]]},"834":{"position":[[652,6]]},"836":{"position":[[683,10],[953,6]]},"838":{"position":[[220,10],[710,10]]},"1200":{"position":[[1530,6]]}}}],["role",{"_index":2310,"t":{"740":{"position":[[122,4]]},"744":{"position":[[84,4]]},"943":{"position":[[496,4]]}}}],["roug",{"_index":2422,"t":{"780":{"position":[[236,5],[245,5],[255,5]]},"1179":{"position":[[107,5]]}}}],["row",{"_index":1705,"t":{"517":{"position":[[270,3]]},"777":{"position":[[426,4]]},"1142":{"position":[[604,4]]}}}],["rr\\mathbb{r}^rrr",{"_index":3519,"t":{"1146":{"position":[[720,16]]}}}],["rrr",{"_index":1038,"t":{"302":{"position":[[921,3]]},"551":{"position":[[335,3]]},"563":{"position":[[493,3],[1015,3],[1104,3]]},"598":{"position":[[130,3]]},"602":{"position":[[11,3]]},"608":{"position":[[66,3],[326,3]]},"1137":{"position":[[2013,3],[2408,3]]},"1160":{"position":[[773,3]]},"1165":{"position":[[238,3]]},"1172":{"position":[[244,3]]}}}],["rr×r\\lambda",{"_index":3505,"t":{"1146":{"position":[[373,13]]}}}],["rss",{"_index":3087,"t":{"1028":{"position":[[91,3]]}}}],["rt=me(τ0)r_t",{"_index":2671,"t":{"863":{"position":[[75,12]]}}}],["rte",{"_index":1324,"t":{"423":{"position":[[849,4]]},"589":{"position":[[166,3]]},"642":{"position":[[183,4]]},"688":{"position":[[1226,3]]},"698":{"position":[[175,3]]},"700":{"position":[[392,3]]},"702":{"position":[[1073,3]]},"730":{"position":[[145,3]]},"751":{"position":[[268,3]]},"753":{"position":[[301,3]]},"1167":{"position":[[178,3]]},"1186":{"position":[[213,3]]}}}],["rtr_trt",{"_index":2674,"t":{"863":{"position":[[142,8]]}}}],["rubi",{"_index":1159,"t":{"360":{"position":[[98,5]]}}}],["ruder",{"_index":2473,"t":{"817":{"position":[[322,6]]}}}],["rule",{"_index":2782,"t":{"901":{"position":[[2227,5]]}}}],["run",{"_index":103,"t":{"17":{"position":[[134,3],[385,3]]},"19":{"position":[[0,3],[46,3],[224,3]]},"1046":{"position":[[36,3]]},"1047":{"position":[[40,3]]},"1065":{"position":[[43,3]]},"1077":{"position":[[42,3]]},"1081":{"position":[[43,3],[127,3]]}}}],["r}b∈rd1​×r",{"_index":3425,"t":{"1137":{"position":[[1924,11]]},"1142":{"position":[[417,11]]}}}],["r}b∈rd×r",{"_index":1795,"t":{"563":{"position":[[436,9]]}}}],["r}p∈rd1​×r",{"_index":3502,"t":{"1146":{"position":[[253,10]]}}}],["r}st={sk,i(t)​}1≤k≤n,1≤i≤r",{"_index":3600,"t":{"1148":{"position":[[2294,27]]}}}],["r}{λi​}1≤i≤r",{"_index":3510,"t":{"1146":{"position":[[480,13]]}}}],["r}λ∈rr×r",{"_index":3506,"t":{"1146":{"position":[[412,8]]}}}],["rθ(x,y)r_\\theta(x",{"_index":3020,"t":{"1001":{"position":[[889,18]]}}}],["r∣θ∣=2×l^lora​×dmodel​×r",{"_index":1859,"t":{"587":{"position":[[226,24]]}}}],["r≪dmodelr",{"_index":1820,"t":{"571":{"position":[[107,9]]}}}],["r≪min⁡(d,k)r",{"_index":1799,"t":{"563":{"position":[[499,12]]}}}],["r≪min⁡(d1,d2)r",{"_index":3511,"t":{"1146":{"position":[[496,14]]}}}],["r≪{d1,d2}r",{"_index":3426,"t":{"1137":{"position":[[1936,10]]},"1142":{"position":[[429,10]]}}}],["r≪{d1​,d2",{"_index":3429,"t":{"1137":{"position":[[1963,13]]},"1142":{"position":[[456,13]]}}}],["s",{"_index":228,"t":{"38":{"position":[[332,1]]},"40":{"position":[[18,1]]},"42":{"position":[[30,1],[139,1]]},"515":{"position":[[628,1],[707,1]]}}}],["s(\\lambda",{"_index":3611,"t":{"1152":{"position":[[525,9]]}}}],["s(p_{k,ji",{"_index":3615,"t":{"1152":{"position":[[576,11]]}}}],["s(q_{k,ij",{"_index":3618,"t":{"1152":{"position":[[621,12]]}}}],["s(t)(wij)=i‾(t)(wij)⋅u‾(t)(wij).\\begin{equ",{"_index":3651,"t":{"1152":{"position":[[2447,48]]}}}],["s(⋅)s(\\cdot)",{"_index":3624,"t":{"1152":{"position":[[862,16],[930,16],[2405,16]]},"1188":{"position":[[146,16]]}}}],["s0",{"_index":260,"t":{"49":{"position":[[341,2]]}}}],["s=finswt",{"_index":3339,"t":{"1096":{"position":[[2423,9]]}}}],["s={s1,s2,…,sk}\\pmb{\\mathcal{",{"_index":1957,"t":{"625":{"position":[[20,31]]}}}],["s={s1,…,sk}\\mathcal{",{"_index":2068,"t":{"635":{"position":[[152,22]]}}}],["s={s1​,…,sk",{"_index":2071,"t":{"635":{"position":[[194,15]]}}}],["s\\mathcal{s}",{"_index":1968,"t":{"625":{"position":[[329,13]]},"631":{"position":[[38,13]]},"633":{"position":[[18,13]]},"635":{"position":[[452,13]]}}}],["s\\pmb{\\mathcal{s}}ss",{"_index":1969,"t":{"625":{"position":[[360,20],[581,20]]}}}],["s\\pmb{\\phi_\\mathcal{s}}ϕs​ϕ",{"_index":1971,"t":{"625":{"position":[[649,30]]}}}],["s^g_l",{"_index":1595,"t":{"463":{"position":[[1787,5]]}}}],["s^{(t)}(w_{ij",{"_index":3652,"t":{"1152":{"position":[[2496,15]]}}}],["s^{t",{"_index":3595,"t":{"1148":{"position":[[2036,6]]}}}],["s^{t}_{k,i",{"_index":3592,"t":{"1148":{"position":[[1982,12]]}}}],["s_1",{"_index":2069,"t":{"635":{"position":[[177,6]]}}}],["s_k^{(t",{"_index":3587,"t":{"1148":{"position":[[1852,11]]}}}],["s_k^{(t)})_{ii",{"_index":3590,"t":{"1148":{"position":[[1913,15]]}}}],["s_l",{"_index":1572,"t":{"463":{"position":[[889,3],[1144,3]]}}}],["s_l^g",{"_index":1605,"t":{"463":{"position":[[2339,6]]}}}],["s_l^k",{"_index":1582,"t":{"463":{"position":[[1150,7]]}}}],["s_l^{m+1}]^t",{"_index":1583,"t":{"463":{"position":[[1158,12]]}}}],["s_{k,i",{"_index":3610,"t":{"1152":{"position":[[515,7]]}}}],["s_{k,i}^{(t",{"_index":3599,"t":{"1148":{"position":[[2245,13]]}}}],["sacl",{"_index":739,"t":{"169":{"position":[[365,5]]},"482":{"position":[[37,5]]}}}],["sad",{"_index":2799,"t":{"909":{"position":[[458,10]]}}}],["salient",{"_index":1025,"t":{"302":{"position":[[328,7]]}}}],["same",{"_index":1481,"t":{"439":{"position":[[339,4]]},"959":{"position":[[961,4]]},"1077":{"position":[[231,4]]},"1137":{"position":[[1074,4]]}}}],["sampl",{"_index":645,"t":{"140":{"position":[[122,8]]},"171":{"position":[[844,8]]},"193":{"position":[[136,7]]},"343":{"position":[[561,7]]},"345":{"position":[[186,6]]},"347":{"position":[[150,6],[293,6]]},"398":{"position":[[343,8]]},"635":{"position":[[337,8],[390,7],[495,7]]},"646":{"position":[[188,6]]},"648":{"position":[[71,8]]},"670":{"position":[[16,8]]},"682":{"position":[[174,6]]},"698":{"position":[[847,6]]},"713":{"position":[[441,6]]},"791":{"position":[[135,6]]},"832":{"position":[[158,7],[584,7]]},"842":{"position":[[1344,7]]},"885":{"position":[[695,8]]},"899":{"position":[[617,6],[800,6]]},"901":{"position":[[1772,6],[2331,6]]},"919":{"position":[[298,6],[479,6],[494,6]]},"1152":{"position":[[1376,6],[1397,6],[1431,8]]},"1200":{"position":[[765,6]]},"1211":{"position":[[498,6]]},"1216":{"position":[[65,6],[173,6],[443,6],[765,6]]},"1232":{"position":[[271,6]]}}}],["samsum",{"_index":1835,"t":{"573":{"position":[[123,6]]}}}],["satellit",{"_index":508,"t":{"102":{"position":[[319,9]]}}}],["save",{"_index":850,"t":{"213":{"position":[[182,4]]}}}],["saycan",{"_index":923,"t":{"257":{"position":[[173,6]]},"259":{"position":[[139,6]]}}}],["sbu",{"_index":803,"t":{"186":{"position":[[63,3]]},"199":{"position":[[125,3]]}}}],["sc",{"_index":1245,"t":{"390":{"position":[[214,2],[262,2],[375,2]]}}}],["sca",{"_index":1173,"t":{"362":{"position":[[202,6]]}}}],["scail",{"_index":147,"t":{"23":{"position":[[50,9]]},"25":{"position":[[346,8],[396,8]]},"35":{"position":[[26,8],[219,8]]},"44":{"position":[[78,8]]},"76":{"position":[[27,8]]},"78":{"position":[[227,8],[949,8]]},"120":{"position":[[263,8]]},"366":{"position":[[107,8],[136,8]]}}}],["scalar",{"_index":2623,"t":{"850":{"position":[[342,6],[1224,6]]},"859":{"position":[[321,6]]},"863":{"position":[[168,6]]},"1001":{"position":[[536,6],[942,6]]}}}],["scale",{"_index":219,"t":{"35":{"position":[[167,5]]},"42":{"position":[[34,5]]},"145":{"position":[[162,5]]},"165":{"position":[[489,5]]},"244":{"position":[[22,5]]},"271":{"position":[[234,7],[271,7],[333,7]]},"273":{"position":[[239,5]]},"275":{"position":[[188,7],[233,7]]},"328":{"position":[[590,5]]},"368":{"position":[[63,7]]},"386":{"position":[[31,7]]},"396":{"position":[[721,5]]},"402":{"position":[[82,7]]},"465":{"position":[[227,5],[340,5],[383,5]]},"502":{"position":[[250,5]]},"504":{"position":[[1827,5]]},"510":{"position":[[93,5]]},"515":{"position":[[434,5],[544,5],[754,5]]},"517":{"position":[[144,5],[218,5]]},"519":{"position":[[567,5]]},"563":{"position":[[996,7],[1075,7],[1094,7]]},"657":{"position":[[230,7]]},"682":{"position":[[104,5]]},"723":{"position":[[50,5]]},"725":{"position":[[342,6]]},"746":{"position":[[30,6],[102,6],[154,6],[195,6],[287,5],[374,5]]},"817":{"position":[[2571,5]]},"825":{"position":[[865,7]]},"827":{"position":[[341,5]]},"844":{"position":[[167,5]]},"1096":{"position":[[290,5],[603,5]]},"1111":{"position":[[11,5]]},"1158":{"position":[[156,7],[353,7]]},"1192":{"position":[[466,7]]}}}],["scaleai",{"_index":3008,"t":{"999":{"position":[[9,7]]}}}],["scali",{"_index":1721,"t":{"531":{"position":[[206,6]]},"555":{"position":[[84,6]]}}}],["scalil",{"_index":218,"t":{"35":{"position":[[105,9]]}}}],["schedul",{"_index":1218,"t":{"379":{"position":[[160,8]]},"431":{"position":[[420,8]]},"784":{"position":[[201,9]]},"1154":{"position":[[262,9],[597,8]]}}}],["schedular",{"_index":3819,"t":{"1236":{"position":[[40,9]]}}}],["scheme",{"_index":647,"t":{"140":{"position":[[256,6]]}}}],["schick",{"_index":2517,"t":{"821":{"position":[[417,6]]}}}],["schütze",{"_index":2518,"t":{"821":{"position":[[428,8]]}}}],["scienc",{"_index":2599,"t":{"842":{"position":[[1835,9]]}}}],["scienceqa",{"_index":1513,"t":{"455":{"position":[[519,9]]},"457":{"position":[[1095,9]]},"482":{"position":[[213,9]]},"484":{"position":[[48,9]]},"487":{"position":[[65,9]]},"498":{"position":[[233,9]]},"510":{"position":[[338,9]]}}}],["scieneceqa",{"_index":1607,"t":{"465":{"position":[[80,10]]}}}],["scientif",{"_index":2601,"t":{"842":{"position":[[1993,11]]}}}],["scitail",{"_index":2107,"t":{"642":{"position":[[314,7]]},"653":{"position":[[92,7]]}}}],["scolor",{"_index":2614,"t":{"848":{"position":[[397,7]]}}}],["score",{"_index":1037,"t":{"302":{"position":[[830,6]]},"345":{"position":[[1000,5]]},"357":{"position":[[238,5]]},"396":{"position":[[592,5]]},"398":{"position":[[445,5],[461,5],[502,5]]},"425":{"position":[[1483,5]]},"463":{"position":[[839,6],[1287,5]]},"533":{"position":[[553,5]]},"633":{"position":[[1293,5]]},"834":{"position":[[843,5]]},"853":{"position":[[109,5]]},"857":{"position":[[149,5],[593,7]]},"863":{"position":[[122,5]]},"885":{"position":[[5,5],[26,5],[672,5]]},"887":{"position":[[12,5]]},"899":{"position":[[1021,7]]},"1001":{"position":[[308,5],[416,5]]},"1113":{"position":[[136,5],[279,5]]},"1115":{"position":[[143,5]]},"1121":{"position":[[166,5]]},"1135":{"position":[[489,5]]},"1148":{"position":[[171,5],[549,5],[1618,5],[2350,5],[2533,5]]},"1152":{"position":[[11,7],[1368,5]]},"1179":{"position":[[119,6]]},"1188":{"position":[[22,5],[116,5],[255,5]]},"1194":{"position":[[65,7]]},"1200":{"position":[[1396,5]]},"1211":{"position":[[248,5],[357,5]]},"1216":{"position":[[152,5],[646,5]]}}}],["scratch",{"_index":2514,"t":{"821":{"position":[[73,7]]}}}],["se",{"_index":248,"t":{"49":{"position":[[151,2]]}}}],["seamlessli",{"_index":3216,"t":{"1067":{"position":[[12,10]]},"1079":{"position":[[12,10]]}}}],["search",{"_index":198,"t":{"27":{"position":[[381,6]]},"38":{"position":[[94,6],[292,6],[398,6]]},"140":{"position":[[147,6]]},"190":{"position":[[52,6],[287,6]]},"482":{"position":[[164,6]]},"525":{"position":[[296,6],[699,6]]},"680":{"position":[[1106,9],[1273,9]]},"682":{"position":[[312,9],[372,9],[435,9]]},"694":{"position":[[326,9]]},"696":{"position":[[136,9]]},"698":{"position":[[1279,6]]},"784":{"position":[[750,6]]},"817":{"position":[[1114,6]]},"819":{"position":[[852,6],[881,6]]},"885":{"position":[[632,6],[657,6]]},"887":{"position":[[257,8]]},"899":{"position":[[506,6],[538,6]]},"911":{"position":[[70,6],[91,6],[518,6],[1026,6],[1119,6]]},"943":{"position":[[297,6]]},"963":{"position":[[1193,6]]},"1026":{"position":[[171,6]]},"1179":{"position":[[197,6]]}}}],["searchqa",{"_index":2104,"t":{"642":{"position":[[276,8]]}}}],["second",{"_index":1996,"t":{"629":{"position":[[41,6]]}}}],["second_do",{"_index":3283,"t":{"1092":{"position":[[1641,11]]}}}],["section",{"_index":1479,"t":{"439":{"position":[[317,7]]},"725":{"position":[[209,8]]},"817":{"position":[[2040,7],[2114,7],[2239,7],[2405,7]]},"889":{"position":[[201,7],[352,7],[396,7],[522,7]]},"1152":{"position":[[2671,7]]},"1186":{"position":[[0,7]]}}}],["sectiopn",{"_index":1331,"t":{"423":{"position":[[955,8]]}}}],["see",{"_index":3165,"t":{"1053":{"position":[[84,3],[134,3],[196,3]]}}}],["seed",{"_index":905,"t":{"242":{"position":[[154,4],[195,4],[211,4]]},"606":{"position":[[21,4]]},"648":{"position":[[346,4],[418,4]]},"899":{"position":[[254,4]]},"935":{"position":[[383,4]]}}}],["seen",{"_index":2447,"t":{"793":{"position":[[226,5],[268,4]]},"1113":{"position":[[234,4]]}}}],["segment",{"_index":202,"t":{"27":{"position":[[434,12]]},"120":{"position":[[169,12]]},"124":{"position":[[302,13]]},"126":{"position":[[445,12],[460,12],[913,13]]},"128":{"position":[[163,12]]},"130":{"position":[[89,12],[104,12],[790,12]]},"140":{"position":[[480,12]]},"143":{"position":[[160,12]]},"151":{"position":[[27,13]]},"153":{"position":[[366,12]]},"155":{"position":[[713,12]]},"157":{"position":[[67,13],[286,12]]},"159":{"position":[[826,12]]},"165":{"position":[[643,9]]},"169":{"position":[[134,12]]},"171":{"position":[[328,12]]},"219":{"position":[[22,12]]},"1085":{"position":[[637,14],[710,13]]},"1087":{"position":[[93,12],[238,12],[274,12],[451,12],[494,12],[620,12],[1465,13]]},"1090":{"position":[[102,13]]},"1099":{"position":[[763,13]]},"1107":{"position":[[101,12]]},"1203":{"position":[[582,13]]},"1207":{"position":[[229,13]]}}}],["select",{"_index":1050,"t":{"306":{"position":[[71,9]]},"919":{"position":[[305,9]]},"949":{"position":[[367,9]]}}}],["self",{"_index":377,"t":{"86":{"position":[[25,4]]},"88":{"position":[[47,4],[87,4],[126,4],[197,4],[276,4],[386,4],[424,4],[464,4],[501,4]]},"91":{"position":[[1350,4]]},"93":{"position":[[59,4]]},"116":{"position":[[601,4],[749,4]]},"118":{"position":[[12,4],[83,4],[107,4]]},"120":{"position":[[204,4]]},"176":{"position":[[0,4],[239,4]]},"343":{"position":[[259,4]]},"345":{"position":[[235,4],[266,4],[552,4]]},"349":{"position":[[476,4]]},"390":{"position":[[101,5]]},"427":{"position":[[1216,4],[2171,5],[3178,4]]},"429":{"position":[[153,4]]},"455":{"position":[[103,4]]},"551":{"position":[[114,4]]},"569":{"position":[[40,4]]},"585":{"position":[[0,4]]},"823":{"position":[[1453,4]]},"850":{"position":[[453,4],[652,4],[999,4],[1040,4],[1446,4],[2041,4],[2069,4]]},"853":{"position":[[131,4],[155,4]]},"859":{"position":[[6,4],[84,4],[256,4],[766,4]]},"861":{"position":[[231,4]]},"863":{"position":[[297,4],[481,4]]},"959":{"position":[[163,4],[267,4],[284,4],[314,4],[350,4],[582,4]]},"1096":{"position":[[307,4]]},"1137":{"position":[[2690,4]]},"1160":{"position":[[367,4]]},"1200":{"position":[[1068,4],[1191,4],[1234,4]]},"1207":{"position":[[0,4],[164,4],[449,4],[512,4]]},"1209":{"position":[[167,4]]},"1216":{"position":[[96,4],[493,4]]}}}],["semant",{"_index":676,"t":{"147":{"position":[[130,8]]},"169":{"position":[[547,8]]},"171":{"position":[[680,8]]},"174":{"position":[[194,8]]},"219":{"position":[[84,8],[115,8]]},"461":{"position":[[452,9]]},"463":{"position":[[1623,9]]},"510":{"position":[[158,9]]},"740":{"position":[[113,8]]},"744":{"position":[[75,8]]},"842":{"position":[[482,8],[1113,8]]},"850":{"position":[[480,10]]},"857":{"position":[[160,8]]},"943":{"position":[[487,8],[517,8]]},"945":{"position":[[0,8],[85,8]]},"1203":{"position":[[573,8]]},"1207":{"position":[[220,8]]}}}],["semi",{"_index":540,"t":{"110":{"position":[[69,4]]},"1207":{"position":[[20,4]]},"1216":{"position":[[112,4]]}}}],["sens",{"_index":1328,"t":{"423":{"position":[[901,5]]},"698":{"position":[[225,5]]},"700":{"position":[[465,5]]}}}],["sensit",{"_index":2277,"t":{"702":{"position":[[16,9]]},"943":{"position":[[501,11]]},"1152":{"position":[[60,11],[95,11],[281,11],[949,11],[1313,11],[1478,11],[1532,11],[2180,11],[2693,11]]},"1188":{"position":[[63,11],[165,11]]}}}],["sentenc",{"_index":1317,"t":{"423":{"position":[[752,8]]},"521":{"position":[[304,9]]},"686":{"position":[[499,8],[540,8]]},"773":{"position":[[203,8],[547,10]]},"905":{"position":[[166,8]]},"959":{"position":[[937,9]]},"963":{"position":[[1939,9]]},"1163":{"position":[[91,8]]}}}],["sentencepiec",{"_index":2557,"t":{"832":{"position":[[206,13]]}}}],["sentiment",{"_index":2282,"t":{"713":{"position":[[416,9]]},"879":{"position":[[328,9]]},"883":{"position":[[280,9]]},"983":{"position":[[489,10],[534,10],[568,13],[658,10],[703,10],[741,12]]}}}],["sentinel",{"_index":2522,"t":{"823":{"position":[[133,8],[241,8],[264,8],[888,8],[1023,8],[1055,8],[1328,8],[1375,8]]},"834":{"position":[[140,8],[185,8],[247,8]]}}}],["separ",{"_index":1453,"t":{"429":{"position":[[183,8]]},"463":{"position":[[1920,8]]},"682":{"position":[[445,8]]},"919":{"position":[[681,9]]}}}],["seq2seq",{"_index":1108,"t":{"339":{"position":[[133,7]]},"351":{"position":[[50,7]]},"353":{"position":[[69,7]]},"953":{"position":[[382,7],[459,7]]},"957":{"position":[[65,7]]},"959":{"position":[[188,7]]},"963":{"position":[[2131,7]]}}}],["sequenc",{"_index":401,"t":{"91":{"position":[[46,8],[197,8],[425,8],[1295,8]]},"95":{"position":[[23,8],[199,8]]},"97":{"position":[[282,8]]},"104":{"position":[[146,8],[434,8],[518,8]]},"120":{"position":[[63,8]]},"124":{"position":[[175,8]]},"126":{"position":[[832,8],[1156,8]]},"130":{"position":[[217,8],[405,8]]},"132":{"position":[[22,8],[84,8],[251,8]]},"134":{"position":[[15,8]]},"136":{"position":[[30,8]]},"138":{"position":[[104,8]]},"140":{"position":[[636,8]]},"145":{"position":[[18,8]]},"149":{"position":[[328,8]]},"159":{"position":[[64,8],[603,8]]},"169":{"position":[[189,8],[301,8]]},"339":{"position":[[87,8],[168,8],[218,8]]},"345":{"position":[[428,8]]},"347":{"position":[[187,8],[322,8]]},"355":{"position":[[50,8]]},"379":{"position":[[229,8],[293,8]]},"425":{"position":[[238,8],[278,8],[767,8],[818,8],[974,8],[1193,8],[1664,8]]},"427":{"position":[[510,8],[1001,8],[2495,8]]},"431":{"position":[[466,8]]},"437":{"position":[[891,8],[1010,8]]},"441":{"position":[[98,8]]},"549":{"position":[[286,8]]},"553":{"position":[[307,8]]},"559":{"position":[[86,8],[141,8]]},"565":{"position":[[140,8]]},"589":{"position":[[144,8]]},"610":{"position":[[83,8]]},"627":{"position":[[547,8]]},"633":{"position":[[1772,8]]},"686":{"position":[[62,8]]},"711":{"position":[[260,8]]},"713":{"position":[[820,8],[955,8],[1556,8]]},"716":{"position":[[99,8],[129,8]]},"718":{"position":[[262,8],[641,8]]},"725":{"position":[[62,8],[108,8],[152,8],[288,8]]},"727":{"position":[[73,8],[129,8]]},"732":{"position":[[162,8]]},"736":{"position":[[73,8]]},"759":{"position":[[331,8]]},"761":{"position":[[1175,8],[1300,8]]},"764":{"position":[[41,8]]},"766":{"position":[[244,8]]},"775":{"position":[[303,8]]},"800":{"position":[[0,8]]},"819":{"position":[[330,8]]},"836":{"position":[[328,8],[1776,8]]},"842":{"position":[[1756,8]]},"909":{"position":[[186,8]]},"917":{"position":[[1340,8]]},"949":{"position":[[306,8]]},"963":{"position":[[2817,8]]},"1096":{"position":[[1912,8]]},"1140":{"position":[[143,8]]},"1170":{"position":[[98,8]]}}}],["sequenti",{"_index":2598,"t":{"842":{"position":[[1684,10]]},"848":{"position":[[493,11]]},"850":{"position":[[1574,10]]}}}],["seri",{"_index":861,"t":{"227":{"position":[[49,6]]}}}],["serv",{"_index":130,"t":{"19":{"position":[[274,6]]},"761":{"position":[[1102,6]]},"815":{"position":[[413,5]]},"817":{"position":[[1833,7]]},"844":{"position":[[444,7],[536,7]]},"1047":{"position":[[44,5],[74,6]]}}}],["server",{"_index":119,"t":{"19":{"position":[[20,7],[306,7]]}}}],["set",{"_index":1086,"t":{"328":{"position":[[250,3]]},"333":{"position":[[333,5]]},"416":{"position":[[366,3]]},"418":{"position":[[297,3],[1764,3]]},"421":{"position":[[447,8]]},"423":{"position":[[1009,3],[1421,3],[1439,3]]},"425":{"position":[[2389,7]]},"427":{"position":[[1161,3],[1967,3],[3942,7]]},"431":{"position":[[746,4],[774,7]]},"439":{"position":[[364,3]]},"447":{"position":[[170,3],[258,3],[270,3]]},"508":{"position":[[198,3]]},"535":{"position":[[54,3]]},"553":{"position":[[706,3],[1024,3]]},"631":{"position":[[825,3]]},"648":{"position":[[434,3]]},"694":{"position":[[443,3],[462,3],[473,3]]},"698":{"position":[[712,3],[880,3]]},"744":{"position":[[67,4]]},"761":{"position":[[394,3]]},"775":{"position":[[961,3]]},"811":{"position":[[442,3]]},"825":{"position":[[494,3]]},"827":{"position":[[549,3]]},"879":{"position":[[285,3],[390,3]]},"895":{"position":[[592,7]]},"911":{"position":[[277,3]]},"927":{"position":[[151,7]]},"983":{"position":[[1201,3]]},"1135":{"position":[[943,7]]},"1137":{"position":[[4589,7]]},"1140":{"position":[[763,3]]},"1148":{"position":[[565,3]]},"1167":{"position":[[11,7],[55,3]]},"1174":{"position":[[12,8]]}}}],["setup",{"_index":368,"t":{"80":{"position":[[0,5]]},"320":{"position":[[290,5]]}}}],["setups(zero/few",{"_index":1197,"t":{"366":{"position":[[233,15]]}}}],["sf",{"_index":1210,"t":{"373":{"position":[[161,2]]},"377":{"position":[[11,2]]},"386":{"position":[[92,2]]}}}],["sft",{"_index":2990,"t":{"989":{"position":[[407,5]]},"995":{"position":[[422,3],[439,3]]},"1001":{"position":[[159,5],[324,3],[335,3],[471,3],[1149,3],[1233,3],[2080,3]]},"1013":{"position":[[309,3]]}}}],["sft+rlhf",{"_index":3057,"t":{"1020":{"position":[[18,13]]}}}],["sft\\pi^{sft}πsft",{"_index":3039,"t":{"1001":{"position":[[1822,17]]}}}],["sgd",{"_index":529,"t":{"106":{"position":[[141,3]]},"688":{"position":[[214,5]]},"1236":{"position":[[0,3]]}}}],["shallow",{"_index":1099,"t":{"330":{"position":[[1348,8],[1426,7]]},"349":{"position":[[253,8]]}}}],["shape",{"_index":2746,"t":{"891":{"position":[[184,5]]},"901":{"position":[[1865,5]]},"903":{"position":[[110,5]]},"905":{"position":[[216,5]]}}}],["shard",{"_index":810,"t":{"188":{"position":[[41,8]]}}}],["share",{"_index":597,"t":{"126":{"position":[[994,6],[1032,6]]},"523":{"position":[[397,6]]},"549":{"position":[[865,6]]},"614":{"position":[[452,6]]},"616":{"position":[[853,6],[960,6],[1021,6],[1160,6]]},"619":{"position":[[868,6]]},"621":{"position":[[229,7]]},"625":{"position":[[609,6]]},"629":{"position":[[137,6],[151,7],[324,6]]},"631":{"position":[[65,7],[273,6],[516,6]]},"633":{"position":[[65,6],[543,6],[575,6],[1900,6]]},"635":{"position":[[291,6],[598,6]]},"637":{"position":[[44,6]]},"648":{"position":[[240,6]]},"659":{"position":[[61,6],[225,6]]},"662":{"position":[[135,6],[288,6]]},"668":{"position":[[24,6],[59,6],[164,6]]},"674":{"position":[[183,6],[272,6]]},"734":{"position":[[42,6]]},"809":{"position":[[153,6],[261,6]]},"815":{"position":[[403,7]]},"840":{"position":[[334,7]]},"975":{"position":[[834,7],[946,7]]}}}],["shared/specif",{"_index":1997,"t":{"629":{"position":[[246,15]]}}}],["sharegpt",{"_index":1717,"t":{"529":{"position":[[177,8]]}}}],["shelf",{"_index":882,"t":{"231":{"position":[[479,5]]},"281":{"position":[[965,5],[1284,5],[2106,5]]},"292":{"position":[[884,5]]},"298":{"position":[[8,5]]},"328":{"position":[[643,5]]},"349":{"position":[[93,5]]}}}],["shift",{"_index":2484,"t":{"817":{"position":[[2332,6],[2609,5]]},"838":{"position":[[209,5],[607,5],[699,5]]}}}],["shin",{"_index":2475,"t":{"817":{"position":[[1026,5]]}}}],["shop",{"_index":2330,"t":{"761":{"position":[[1051,6]]}}}],["short",{"_index":586,"t":{"124":{"position":[[514,5]]},"521":{"position":[[188,5]]},"861":{"position":[[23,5],[83,5],[205,5]]}}}],["shorter",{"_index":1368,"t":{"425":{"position":[[1294,7]]}}}],["shot",{"_index":533,"t":{"108":{"position":[[4,4],[207,4]]},"112":{"position":[[374,4]]},"163":{"position":[[376,4]]},"195":{"position":[[30,4]]},"197":{"position":[[4,4],[231,4],[277,4],[344,4]]},"217":{"position":[[5,4],[101,4]]},"229":{"position":[[393,4],[648,4],[777,4]]},"231":{"position":[[144,4],[443,4]]},"238":{"position":[[63,4]]},"240":{"position":[[19,4],[113,4]]},"254":{"position":[[75,4]]},"259":{"position":[[38,4],[117,4]]},"271":{"position":[[441,4]]},"279":{"position":[[49,4],[102,4],[310,4],[602,4]]},"281":{"position":[[256,4],[435,4],[1235,4],[1302,4],[1650,4],[1674,4],[1813,4],[2123,4],[2259,4],[2321,4]]},"288":{"position":[[153,4]]},"290":{"position":[[170,4],[292,4],[338,4]]},"292":{"position":[[11,4],[411,4],[486,4],[561,4],[917,4]]},"296":{"position":[[207,4]]},"306":{"position":[[8,4],[19,4]]},"311":{"position":[[480,4]]},"313":{"position":[[62,4],[155,4],[171,4]]},"316":{"position":[[15,4],[187,4]]},"320":{"position":[[46,4],[285,4]]},"322":{"position":[[91,4],[134,4]]},"328":{"position":[[759,5]]},"330":{"position":[[1611,5]]},"366":{"position":[[249,5]]},"368":{"position":[[403,4],[460,5],[470,4]]},"373":{"position":[[36,4]]},"377":{"position":[[129,4]]},"384":{"position":[[11,6],[29,5],[114,5],[183,5]]},"388":{"position":[[231,4]]},"390":{"position":[[393,4]]},"394":{"position":[[78,4],[256,4]]},"398":{"position":[[243,4],[267,4],[321,4],[677,4],[756,4],[827,4],[1113,4]]},"400":{"position":[[120,5],[131,4]]},"416":{"position":[[4,4],[396,4]]},"418":{"position":[[462,4],[612,4],[2289,4]]},"421":{"position":[[442,4]]},"423":{"position":[[307,4],[585,4],[1040,4]]},"425":{"position":[[25,4],[2384,4]]},"427":{"position":[[4,4],[125,4],[3033,4],[3937,4]]},"429":{"position":[[74,4]]},"431":{"position":[[760,4]]},"433":{"position":[[61,4]]},"435":{"position":[[71,4],[107,4],[119,4],[165,4],[240,4],[313,4],[387,4],[415,4]]},"437":{"position":[[53,4],[705,4],[939,4]]},"439":{"position":[[16,4],[209,4]]},"441":{"position":[[253,4],[367,4]]},"447":{"position":[[4,4]]},"451":{"position":[[24,4],[98,4],[489,4],[700,4]]},"543":{"position":[[176,4],[216,4],[414,4]]},"616":{"position":[[1592,4]]},"621":{"position":[[187,4],[198,4]]},"639":{"position":[[84,4]]},"648":{"position":[[378,4],[392,4]]},"653":{"position":[[106,4],[161,4]]},"678":{"position":[[440,4]]},"680":{"position":[[1315,4],[1456,4],[1709,4],[1782,4]]},"682":{"position":[[137,4]]},"698":{"position":[[277,4],[430,4],[454,4],[937,4],[1045,4],[1590,4],[1811,4],[1947,4],[1972,4]]},"702":{"position":[[84,4],[269,4],[519,4],[648,4],[691,4],[1040,4],[1181,4]]},"738":{"position":[[330,4]]},"815":{"position":[[278,4]]},"817":{"position":[[382,4],[920,4],[1684,4]]},"821":{"position":[[360,4]]},"823":{"position":[[1760,4]]},"827":{"position":[[567,4]]},"836":{"position":[[1771,4]]},"838":{"position":[[291,4],[976,4]]},"844":{"position":[[192,4]]},"874":{"position":[[436,4]]},"895":{"position":[[157,4],[323,4],[384,4],[509,4],[578,4]]},"901":{"position":[[1300,4]]},"911":{"position":[[1073,4]]},"919":{"position":[[222,4],[340,4]]},"927":{"position":[[5,4],[137,4],[208,4],[407,4]]},"933":{"position":[[322,4]]},"935":{"position":[[256,4],[323,4]]},"937":{"position":[[114,4],[494,4]]},"945":{"position":[[80,4]]},"947":{"position":[[373,4],[574,4]]},"955":{"position":[[321,4],[372,4]]},"961":{"position":[[203,4]]},"963":{"position":[[300,4],[578,4]]},"979":{"position":[[74,4],[173,4]]},"995":{"position":[[257,4]]},"1198":{"position":[[258,5],[268,4],[651,4],[666,4]]},"1200":{"position":[[687,4],[1976,4],[1990,4]]},"1205":{"position":[[437,4]]},"1240":{"position":[[296,4]]}}}],["showcas",{"_index":3084,"t":{"1026":{"position":[[218,8]]}}}],["si",{"_index":258,"t":{"49":{"position":[[301,2]]}}}],["side",{"_index":1946,"t":{"619":{"position":[[360,4]]}}}],["sidebar",{"_index":3113,"t":{"1032":{"position":[[51,7]]},"1036":{"position":[[35,7],[95,7],[271,7]]}}}],["sidebar_label",{"_index":3120,"t":{"1036":{"position":[[141,14]]}}}],["sidebar_posit",{"_index":3122,"t":{"1036":{"position":[[162,17]]}}}],["sidebars.j",{"_index":3124,"t":{"1036":{"position":[[293,12],[306,11]]}}}],["signal",{"_index":733,"t":{"165":{"position":[[578,7],[619,7]]},"169":{"position":[[448,7]]},"171":{"position":[[255,8],[304,8],[689,6]]},"211":{"position":[[164,6]]},"345":{"position":[[368,6]]},"463":{"position":[[2523,7]]},"815":{"position":[[205,7]]},"817":{"position":[[1667,7]]},"848":{"position":[[280,6],[464,6],[682,7]]},"850":{"position":[[500,6],[1076,6]]},"859":{"position":[[191,7],[429,6],[833,6]]},"963":{"position":[[1734,6],[2072,7]]}}}],["sim",{"_index":3013,"t":{"1001":{"position":[[757,4],[1528,4],[1640,4]]}}}],["sim(v,q)\\textup{sim}(v",{"_index":1030,"t":{"302":{"position":[[620,23],[849,23]]}}}],["simiar",{"_index":1579,"t":{"463":{"position":[[1052,11]]}}}],["similar",{"_index":970,"t":{"281":{"position":[[1638,7]]},"345":{"position":[[989,10]]},"604":{"position":[[460,10],[1145,10]]},"606":{"position":[[54,10]]},"616":{"position":[[636,10]]},"619":{"position":[[646,10]]},"623":{"position":[[164,10]]},"627":{"position":[[1203,10]]},"659":{"position":[[171,10],[328,10]]},"842":{"position":[[315,10],[755,7]]},"943":{"position":[[526,10]]},"1113":{"position":[[69,10]]},"1121":{"position":[[99,10]]},"1163":{"position":[[124,10]]},"1214":{"position":[[817,10]]}}}],["simpl",{"_index":337,"t":{"63":{"position":[[198,6]]},"416":{"position":[[677,6]]},"716":{"position":[[20,6]]},"850":{"position":[[881,6]]},"1044":{"position":[[85,6]]},"1150":{"position":[[254,6]]}}}],["simpli",{"_index":49,"t":{"9":{"position":[[61,6]]},"625":{"position":[[352,7]]}}}],["simplic",{"_index":1819,"t":{"569":{"position":[[136,10]]}}}],["simvlm",{"_index":833,"t":{"195":{"position":[[146,6]]}}}],["singal",{"_index":1663,"t":{"498":{"position":[[148,6]]}}}],["singl",{"_index":212,"t":{"33":{"position":[[163,6]]},"126":{"position":[[987,6]]},"140":{"position":[[669,6]]},"143":{"position":[[551,6]]},"153":{"position":[[674,6]]},"155":{"position":[[50,6],[71,6],[353,6]]},"159":{"position":[[794,6]]},"174":{"position":[[142,6]]},"229":{"position":[[1085,6]]},"242":{"position":[[244,6]]},"328":{"position":[[157,6]]},"379":{"position":[[222,6]]},"418":{"position":[[308,6],[658,6],[779,6]]},"427":{"position":[[2590,6]]},"437":{"position":[[1041,6]]},"439":{"position":[[79,6]]},"441":{"position":[[281,6],[407,6],[454,6]]},"443":{"position":[[67,6]]},"445":{"position":[[250,6]]},"451":{"position":[[545,6]]},"529":{"position":[[23,6]]},"614":{"position":[[375,6]]},"616":{"position":[[836,6]]},"619":{"position":[[861,6]]},"621":{"position":[[21,6]]},"625":{"position":[[310,6],[384,6],[628,6]]},"629":{"position":[[61,6]]},"633":{"position":[[1893,6]]},"635":{"position":[[27,6],[284,6]]},"637":{"position":[[137,6],[290,6]]},"659":{"position":[[265,7]]},"674":{"position":[[137,6]]},"694":{"position":[[30,6]]},"713":{"position":[[626,6]]},"748":{"position":[[260,6]]},"773":{"position":[[189,6]]},"817":{"position":[[1752,6]]},"819":{"position":[[215,6],[1774,6]]},"830":{"position":[[158,6],[210,6]]},"836":{"position":[[438,6],[1106,6]]},"840":{"position":[[704,6]]},"850":{"position":[[1642,6]]},"887":{"position":[[162,6]]},"911":{"position":[[643,6]]},"915":{"position":[[24,6]]},"917":{"position":[[549,6]]},"971":{"position":[[349,6]]},"975":{"position":[[851,6]]},"983":{"position":[[963,6]]},"1087":{"position":[[577,6]]},"1092":{"position":[[1760,7]]},"1152":{"position":[[114,6],[881,6]]},"1163":{"position":[[84,6]]},"1240":{"position":[[211,6]]}}}],["singluar",{"_index":3446,"t":{"1137":{"position":[[4328,8]]},"1144":{"position":[[66,8],[179,8]]}}}],["singular",{"_index":1885,"t":{"604":{"position":[[78,8],[124,8],[273,8],[376,8],[759,8]]},"606":{"position":[[205,8]]},"608":{"position":[[181,8],[330,8],[557,8]]},"1135":{"position":[[549,8],[664,8]]},"1137":{"position":[[3744,8],[4063,8],[4147,8],[4355,8]]},"1146":{"position":[[51,8],[340,8],[423,8],[564,8],[1205,8],[1765,8],[1794,8],[1906,8]]},"1148":{"position":[[184,8],[1646,8],[2397,8],[2437,8]]},"1150":{"position":[[114,8]]},"1152":{"position":[[390,8]]},"1154":{"position":[[123,8]]},"1158":{"position":[[479,8]]},"1194":{"position":[[156,8],[241,8]]}}}],["sinl",{"_index":707,"t":{"155":{"position":[[165,5]]}}}],["sis_isi",{"_index":3722,"t":{"1188":{"position":[[189,8]]}}}],["sit",{"_index":3,"t":{"3":{"position":[[18,3],[170,3]]},"5":{"position":[[138,3],[290,3],[317,3],[469,3],[496,3],[648,3],[675,3],[827,3],[854,3],[1006,3],[1033,3],[1185,3],[1212,3],[1364,3],[1391,3],[1543,3],[1570,3],[1722,3],[1749,3],[1901,3],[1928,3],[2080,3],[2107,3],[2259,3],[2286,3],[2438,3],[2465,3],[2617,3],[2644,3],[2796,3],[2823,3],[2975,3]]}}}],["site",{"_index":84,"t":{"13":{"position":[[30,5]]},"17":{"position":[[26,4]]},"19":{"position":[[166,5],[419,4]]},"1026":{"position":[[44,4]]},"1044":{"position":[[23,4],[77,4]]},"1046":{"position":[[11,4]]},"1077":{"position":[[11,4],[82,4]]},"1081":{"position":[[11,4],[82,4]]}}}],["size",{"_index":28,"t":{"5":{"position":[[97,4]]},"38":{"position":[[379,4]]},"63":{"position":[[130,4]]},"78":{"position":[[50,4],[93,4],[300,4],[359,4],[522,4],[617,4],[921,4]]},"97":{"position":[[250,4]]},"106":{"position":[[104,4],[151,4]]},"190":{"position":[[37,4],[380,5],[402,4]]},"209":{"position":[[261,4]]},"366":{"position":[[155,4]]},"368":{"position":[[88,4]]},"379":{"position":[[90,5]]},"429":{"position":[[369,4]]},"431":{"position":[[483,4]]},"441":{"position":[[117,4]]},"475":{"position":[[160,4]]},"698":{"position":[[1417,4]]},"723":{"position":[[98,5]]},"784":{"position":[[245,5],[305,4],[647,4],[903,4]]},"791":{"position":[[249,4]]},"811":{"position":[[1178,4]]},"815":{"position":[[314,4]]},"817":{"position":[[555,4]]},"825":{"position":[[386,4],[741,4]]},"827":{"position":[[402,4]]},"832":{"position":[[704,4]]},"836":{"position":[[666,4]]},"895":{"position":[[455,4]]},"1172":{"position":[[403,4]]},"1179":{"position":[[166,4],[213,4]]},"1236":{"position":[[68,4]]}}}],["sk(t)s_k^{(t)}sk(t",{"_index":3581,"t":{"1148":{"position":[[1624,21]]}}}],["sk,i=s(λk,i)+1d1∑j=1d1s(pk,ji)+1d2∑j=1d2s(qk,ij),\\begin{equ",{"_index":3609,"t":{"1152":{"position":[[449,65]]}}}],["sk,i=λk,is_{k,i",{"_index":3604,"t":{"1150":{"position":[[52,16]]}}}],["sk,is_{k,i}sk,i",{"_index":3623,"t":{"1152":{"position":[[788,16]]}}}],["sk,i∗s_{k,i*}sk,i",{"_index":3546,"t":{"1148":{"position":[[516,19]]}}}],["sk\\mathcal{s}_ksk",{"_index":2019,"t":{"631":{"position":[[917,18]]}}}],["sl=[slk;slm+1]t\\begin{equ",{"_index":1581,"t":{"463":{"position":[[1112,31]]}}}],["sl=qlklt/c∈r1×(k+m+1)\\begin{equ",{"_index":1571,"t":{"463":{"position":[[851,37]]}}}],["slg=[softmax(slk)⋅gl",{"_index":1593,"t":{"463":{"position":[[1732,21]]}}}],["slide",{"_index":2687,"t":{"870":{"position":[[184,7]]}}}],["slks_l^kslk",{"_index":1592,"t":{"463":{"position":[[1518,12]]}}}],["slk∈rk+1s^k_l",{"_index":1585,"t":{"463":{"position":[[1206,13]]}}}],["slm+1∈r(m+1)×1s_l^{m+1",{"_index":1587,"t":{"463":{"position":[[1372,23]]}}}],["slot",{"_index":2695,"t":{"874":{"position":[[206,6]]},"883":{"position":[[149,4],[195,4],[235,4],[262,4]]},"899":{"position":[[1156,4]]}}}],["slow",{"_index":345,"t":{"78":{"position":[[58,4],[125,4]]},"631":{"position":[[834,6]]}}}],["sls_lsl",{"_index":1580,"t":{"463":{"position":[[1077,8]]}}}],["slug",{"_index":3092,"t":{"1030":{"position":[[80,5]]},"1051":{"position":[[155,5]]}}}],["small",{"_index":347,"t":{"78":{"position":[[81,5],[288,5],[510,5]]},"349":{"position":[[646,5]]},"416":{"position":[[360,5]]},"418":{"position":[[1373,5]]},"421":{"position":[[7,5]]},"644":{"position":[[224,5]]},"688":{"position":[[231,5]]},"698":{"position":[[901,6],[1009,6],[1429,5],[1911,6]]},"811":{"position":[[1005,5]]},"825":{"position":[[54,7]]},"827":{"position":[[652,5]]},"834":{"position":[[725,5]]},"836":{"position":[[1946,5],[2109,5]]},"895":{"position":[[474,5]]},"1047":{"position":[[185,5]]},"1137":{"position":[[375,5],[589,5],[2254,5]]},"1142":{"position":[[11,5]]},"1160":{"position":[[668,5]]}}}],["smaller",{"_index":1104,"t":{"333":{"position":[[325,7]]},"435":{"position":[[338,7]]},"549":{"position":[[1111,7]]},"746":{"position":[[94,7],[146,7]]},"761":{"position":[[376,7]]},"777":{"position":[[67,7]]},"791":{"position":[[330,7]]},"832":{"position":[[690,7]]},"1137":{"position":[[1600,7]]}}}],["smallest",{"_index":3440,"t":{"1137":{"position":[[3735,8]]},"1146":{"position":[[1897,8]]}}}],["smooth",{"_index":545,"t":{"112":{"position":[[226,9]]},"633":{"position":[[1158,10]]},"1152":{"position":[[1544,9],[2171,8]]}}}],["snippet",{"_index":1118,"t":{"343":{"position":[[235,7]]},"345":{"position":[[38,7]]},"353":{"position":[[135,8]]}}}],["socialiqa",{"_index":1012,"t":{"300":{"position":[[636,9]]}}}],["soft",{"_index":1684,"t":{"508":{"position":[[186,4]]},"614":{"position":[[179,4]]},"616":{"position":[[592,4],[930,4],[1085,4]]},"619":{"position":[[155,4]]},"625":{"position":[[317,4],[391,4]]},"627":{"position":[[447,5]]},"629":{"position":[[68,4]]},"631":{"position":[[179,4]]},"637":{"position":[[18,4]]},"711":{"position":[[534,4]]},"713":{"position":[[1211,4]]},"815":{"position":[[76,4],[144,4],[542,4]]},"817":{"position":[[1605,4],[2426,4]]},"819":{"position":[[1643,4]]},"821":{"position":[[172,4]]},"836":{"position":[[1514,4],[1528,4]]},"842":{"position":[[211,4]]},"901":{"position":[[1713,4],[1914,4]]},"913":{"position":[[25,4]]},"977":{"position":[[63,4]]}}}],["softmax",{"_index":318,"t":{"58":{"position":[[208,7]]},"425":{"position":[[1871,7]]},"463":{"position":[[787,7],[1685,7],[1929,7]]}}}],["softmax(q(lk⊙kt)dk)(lv⊙v)\\begin{equ",{"_index":1411,"t":{"427":{"position":[[1564,41]]}}}],["softmax(slm+1)]t\\begin{equ",{"_index":1594,"t":{"463":{"position":[[1754,32]]}}}],["softmax(slm+1​)]t",{"_index":1600,"t":{"463":{"position":[[1900,19]]}}}],["solut",{"_index":343,"t":{"78":{"position":[[9,9]]},"240":{"position":[[237,8]]},"269":{"position":[[335,8]]},"857":{"position":[[289,8]]}}}],["solv",{"_index":915,"t":{"254":{"position":[[180,5]]},"273":{"position":[[133,5]]}}}],["sopta",{"_index":2150,"t":{"680":{"position":[[1260,5]]}}}],["sot",{"_index":3248,"t":{"1087":{"position":[[600,6],[1574,5]]},"1090":{"position":[[263,3]]},"1111":{"position":[[71,3]]}}}],["sot&vo",{"_index":3360,"t":{"1099":{"position":[[1223,7],[1339,7]]}}}],["sota",{"_index":150,"t":{"23":{"position":[[114,4]]},"84":{"position":[[108,4]]},"86":{"position":[[153,4]]},"110":{"position":[[26,4]]},"159":{"position":[[362,4]]},"163":{"position":[[335,4]]},"169":{"position":[[325,4]]},"227":{"position":[[354,4]]},"229":{"position":[[1034,4]]},"233":{"position":[[129,5]]},"244":{"position":[[367,4]]},"328":{"position":[[907,4]]},"330":{"position":[[672,4],[989,4],[1689,4]]},"390":{"position":[[137,4],[227,4],[275,4],[315,4],[424,4]]},"416":{"position":[[781,4]]},"418":{"position":[[269,4]]},"447":{"position":[[399,4]]},"616":{"position":[[1264,4]]},"651":{"position":[[56,4]]},"657":{"position":[[167,4]]},"678":{"position":[[462,4]]},"680":{"position":[[1474,4],[1800,4]]},"696":{"position":[[1365,4]]},"702":{"position":[[105,4],[625,4],[696,4]]},"707":{"position":[[327,4]]},"848":{"position":[[640,4]]},"850":{"position":[[2304,4]]},"1107":{"position":[[68,4]]},"1111":{"position":[[64,4]]},"1115":{"position":[[56,4]]},"1119":{"position":[[25,4]]},"1137":{"position":[[4677,4]]},"1160":{"position":[[652,4]]},"1167":{"position":[[197,4]]},"1177":{"position":[[12,4]]}}}],["sourc",{"_index":1107,"t":{"339":{"position":[[80,6],[211,6]]},"355":{"position":[[43,6]]},"614":{"position":[[332,6]]},"616":{"position":[[577,6]]},"619":{"position":[[727,6],[772,6]]},"621":{"position":[[85,6]]},"623":{"position":[[189,6]]},"625":{"position":[[7,6],[485,6]]},"627":{"position":[[1166,6]]},"629":{"position":[[25,6],[99,6]]},"631":{"position":[[26,6],[554,6],[813,6]]},"633":{"position":[[168,6],[241,6],[1930,6],[2280,6]]},"635":{"position":[[34,6],[74,6]]},"642":{"position":[[48,6]]},"646":{"position":[[249,6]]},"648":{"position":[[0,6],[105,6],[305,6]]},"653":{"position":[[247,6]]},"655":{"position":[[73,6],[231,6]]},"662":{"position":[[29,6],[114,6],[410,6],[531,6]]},"668":{"position":[[0,6]]},"672":{"position":[[32,6],[58,6]]},"674":{"position":[[47,6],[75,6]]}}}],["space",{"_index":221,"t":{"38":{"position":[[101,5],[130,5],[299,5]]},"116":{"position":[[671,5]]},"281":{"position":[[641,5]]},"343":{"position":[[48,5]]},"443":{"position":[[111,5],[261,5],[401,5]]},"510":{"position":[[189,5]]},"616":{"position":[[867,5]]},"680":{"position":[[960,5]]},"704":{"position":[[455,5]]},"707":{"position":[[30,5]]},"716":{"position":[[54,5]]},"817":{"position":[[1104,5]]},"819":{"position":[[1555,5]]},"842":{"position":[[174,5],[1077,5]]},"857":{"position":[[169,5]]},"883":{"position":[[740,5]]},"903":{"position":[[42,5]]},"905":{"position":[[264,5],[396,5]]},"907":{"position":[[11,5],[82,5]]},"909":{"position":[[24,5],[100,6],[116,5],[276,6]]},"911":{"position":[[128,5],[186,5],[576,5],[1033,5],[1126,5]]},"947":{"position":[[607,5]]},"949":{"position":[[220,5],[844,5]]},"971":{"position":[[63,5]]},"1154":{"position":[[697,5]]},"1203":{"position":[[474,5]]}}}],["spacif",{"_index":2930,"t":{"963":{"position":[[1773,14]]}}}],["span",{"_index":1089,"t":{"328":{"position":[[485,4]]},"330":{"position":[[928,4]]},"335":{"position":[[103,4]]},"406":{"position":[[103,4],[133,4]]},"823":{"position":[[62,4],[162,4],[811,4],[953,4],[1213,4],[1310,4]]},"834":{"position":[[85,4],[341,4],[487,4],[690,4],[1025,4]]},"905":{"position":[[116,4],[138,5],[250,4]]},"909":{"position":[[166,5]]},"911":{"position":[[1381,4]]},"923":{"position":[[197,4],[218,4],[280,4],[295,4]]},"949":{"position":[[658,4],[734,4]]},"975":{"position":[[511,4],[576,4]]},"1061":{"position":[[154,5],[364,7]]},"1170":{"position":[[146,4]]}}}],["spars",{"_index":387,"t":{"88":{"position":[[150,6]]},"416":{"position":[[303,6]]},"619":{"position":[[107,6]]},"1137":{"position":[[1007,6],[1296,6],[2303,6]]}}}],["special",{"_index":506,"t":{"102":{"position":[[296,11]]},"279":{"position":[[706,10],[733,11]]},"281":{"position":[[806,10]]},"343":{"position":[[341,7]]},"581":{"position":[[16,7]]},"595":{"position":[[94,7]]},"819":{"position":[[1147,7],[1202,7]]},"1059":{"position":[[17,7]]}}}],["specif",{"_index":575,"t":{"120":{"position":[[20,8]]},"126":{"position":[[1110,8]]},"159":{"position":[[249,8]]},"233":{"position":[[91,8]]},"244":{"position":[[298,8]]},"328":{"position":[[30,8]]},"345":{"position":[[392,8]]},"416":{"position":[[632,8]]},"427":{"position":[[878,8],[3238,8],[3388,8],[3593,8]]},"549":{"position":[[220,8]]},"553":{"position":[[922,8]]},"563":{"position":[[96,8]]},"614":{"position":[[323,8],[574,8]]},"616":{"position":[[95,8],[401,8],[990,8],[1410,8]]},"619":{"position":[[307,8]]},"621":{"position":[[210,8]]},"625":{"position":[[752,8]]},"629":{"position":[[193,8]]},"631":{"position":[[126,8],[394,8],[416,8],[946,8]]},"633":{"position":[[478,8],[611,8]]},"635":{"position":[[626,8]]},"637":{"position":[[90,8]]},"648":{"position":[[272,8],[317,8]]},"659":{"position":[[239,8]]},"662":{"position":[[149,8]]},"668":{"position":[[97,8],[126,8]]},"674":{"position":[[66,8],[220,8],[440,8]]},"727":{"position":[[380,8]]},"738":{"position":[[208,8]]},"746":{"position":[[405,8]]},"759":{"position":[[312,8]]},"761":{"position":[[480,8],[580,8],[1158,8],[1482,8]]},"787":{"position":[[12,8]]},"817":{"position":[[115,8],[2016,8],[2151,8]]},"825":{"position":[[333,8]]},"827":{"position":[[437,8]]},"836":{"position":[[82,8],[205,8],[1185,8],[2188,8],[2342,13]]},"842":{"position":[[1960,8]]},"844":{"position":[[367,8]]},"863":{"position":[[191,8]]},"876":{"position":[[33,8],[461,8],[1126,8]]},"901":{"position":[[348,8]]},"977":{"position":[[239,8]]},"1081":{"position":[[22,8]]},"1129":{"position":[[88,8]]},"1137":{"position":[[2576,8],[3518,8]]},"1152":{"position":[[901,8]]}}}],["specifc",{"_index":3411,"t":{"1137":{"position":[[487,7]]}}}],["speech",{"_index":3753,"t":{"1207":{"position":[[243,6]]}}}],["speed",{"_index":145,"t":{"23":{"position":[[36,5]]},"78":{"position":[[654,5]]}}}],["spin",{"_index":1019,"t":{"302":{"position":[[206,8]]}}}],["split",{"_index":3376,"t":{"1107":{"position":[[46,5]]}}}],["sport",{"_index":922,"t":{"257":{"position":[[125,6]]},"793":{"position":[[358,6]]}}}],["spot",{"_index":1948,"t":{"619":{"position":[[512,5],[639,4]]},"646":{"position":[[202,4]]},"653":{"position":[[133,4]]},"659":{"position":[[308,4]]},"821":{"position":[[284,4]]}}}],["sql",{"_index":1834,"t":{"573":{"position":[[108,4]]},"870":{"position":[[251,3]]}}}],["sqrt{c",{"_index":1574,"t":{"463":{"position":[[907,8]]}}}],["sqrt{d_n})xw_{vi,}mha(x)=concat(head1​,…,headh​)wo​,head)i=softmax(xwqi​(xwki​)⊤/dn​​)xwvi",{"_index":3462,"t":{"1140":{"position":[[440,93]]}}}],["squad",{"_index":1520,"t":{"457":{"position":[[1368,5]]},"471":{"position":[[15,5]]},"494":{"position":[[149,5]]},"496":{"position":[[55,5]]},"642":{"position":[[85,5]]},"748":{"position":[[180,5],[215,5]]},"838":{"position":[[433,5]]},"953":{"position":[[113,7]]},"989":{"position":[[899,6]]}}}],["squad2.0",{"_index":1008,"t":{"300":{"position":[[598,8]]},"1137":{"position":[[4657,8]]}}}],["squadv1",{"_index":3447,"t":{"1137":{"position":[[4442,9]]},"1156":{"position":[[93,8]]},"1170":{"position":[[17,8]]}}}],["squadv2",{"_index":3448,"t":{"1137":{"position":[[4452,8]]},"1156":{"position":[[104,8]]},"1170":{"position":[[28,8]]},"1184":{"position":[[83,8],[247,7],[311,7]]}}}],["squar",{"_index":538,"t":{"108":{"position":[[127,7]]},"178":{"position":[[217,7]]},"633":{"position":[[1362,7]]}}}],["sr0sr_0sr0",{"_index":2679,"t":{"863":{"position":[[372,11]]}}}],["src/components/hellodocusaurus.j",{"_index":3180,"t":{"1057":{"position":[[184,33]]}}}],["src/page",{"_index":3130,"t":{"1038":{"position":[[31,9]]}}}],["src/pages/foo.md",{"_index":3134,"t":{"1038":{"position":[[107,16]]}}}],["src/pages/foo/bar.j",{"_index":3136,"t":{"1038":{"position":[[145,20]]}}}],["src/pages/index.j",{"_index":3132,"t":{"1038":{"position":[[70,18]]}}}],["src/pages/mi",{"_index":3138,"t":{"1040":{"position":[[17,12],[45,12]]},"1042":{"position":[[17,12],[48,12]]}}}],["srtsr_tsrt",{"_index":2680,"t":{"863":{"position":[[406,11],[647,11]]}}}],["ss={s1​,s2​,…,sk",{"_index":1961,"t":{"625":{"position":[[108,20]]}}}],["ssf",{"_index":1701,"t":{"517":{"position":[[106,3],[124,3]]}}}],["sss",{"_index":1690,"t":{"515":{"position":[[550,3]]},"1096":{"position":[[2370,3]]}}}],["sst",{"_index":2097,"t":{"642":{"position":[[79,3],[225,3]]},"751":{"position":[[261,3]]},"1186":{"position":[[205,4]]},"1190":{"position":[[353,3]]}}}],["st",{"_index":1865,"t":{"589":{"position":[[172,3]]},"642":{"position":[[194,3]]}}}],["st,0otherwise,\\begin{equ",{"_index":3584,"t":{"1148":{"position":[[1763,30]]}}}],["st,otherwis",{"_index":3597,"t":{"1148":{"position":[[2194,16]]}}}],["st={sk,i(t)}1≤k≤n,1≤i≤rs^{t",{"_index":3598,"t":{"1148":{"position":[[2211,28]]}}}],["stabil",{"_index":1150,"t":{"349":{"position":[[751,9]]}}}],["stack",{"_index":3451,"t":{"1140":{"position":[[29,7]]}}}],["stage",{"_index":222,"t":{"38":{"position":[[109,5]]},"49":{"position":[[260,5],[273,5]]},"78":{"position":[[169,6],[245,5],[275,6],[821,5],[895,5]]},"104":{"position":[[466,5],[485,5],[534,6]]},"153":{"position":[[31,5]]},"188":{"position":[[170,5],[190,5]]},"362":{"position":[[1083,5],[1271,5]]},"537":{"position":[[725,5]]},"629":{"position":[[48,5]]},"823":{"position":[[1794,5]]}}}],["standalon",{"_index":3131,"t":{"1038":{"position":[[53,10]]}}}],["standard",{"_index":517,"t":{"104":{"position":[[286,12]]},"229":{"position":[[924,8],[1002,8]]},"238":{"position":[[50,8]]},"254":{"position":[[470,8]]},"261":{"position":[[29,8]]},"269":{"position":[[401,8]]},"271":{"position":[[245,8]]},"396":{"position":[[434,8]]},"431":{"position":[[190,8]]},"447":{"position":[[341,8]]},"627":{"position":[[168,8]]},"644":{"position":[[16,8]]},"825":{"position":[[653,8]]},"827":{"position":[[0,8]]},"1203":{"position":[[427,8]]}}}],["standfordcar",{"_index":3827,"t":{"1238":{"position":[[117,13]]}}}],["standord",{"_index":1633,"t":{"475":{"position":[[0,8]]}}}],["stanford",{"_index":1514,"t":{"457":{"position":[[63,8]]},"504":{"position":[[51,8]]}}}],["starbuck",{"_index":2328,"t":{"761":{"position":[[1026,9],[1091,10]]}}}],["start",{"_index":82,"t":{"13":{"position":[[4,7]]},"19":{"position":[[50,5],[228,5]]},"901":{"position":[[1665,8]]},"1077":{"position":[[0,5],[46,5],[146,7]]}}}],["state",{"_index":812,"t":{"188":{"position":[[131,6]]},"549":{"position":[[1076,6]]},"571":{"position":[[86,6]]},"633":{"position":[[1348,6],[1731,6],[1799,6]]},"648":{"position":[[191,6]]},"664":{"position":[[73,5],[146,6],[362,5]]},"713":{"position":[[188,6]]},"855":{"position":[[8,5]]}}}],["static",{"_index":1673,"t":{"504":{"position":[[1337,6]]},"531":{"position":[[48,6]]},"1044":{"position":[[16,6],[92,6]]},"1046":{"position":[[50,6]]},"1055":{"position":[[93,6]]},"1096":{"position":[[815,6]]},"1127":{"position":[[39,6],[305,6]]}}}],["static/img/docusaurus.png",{"_index":3169,"t":{"1055":{"position":[[110,28]]}}}],["statu",{"_index":2661,"t":{"859":{"position":[[159,6]]}}}],["stem",{"_index":766,"t":{"174":{"position":[[395,4]]}}}],["step",{"_index":230,"t":{"38":{"position":[[355,4]]},"49":{"position":[[145,5]]},"63":{"position":[[171,5]]},"227":{"position":[[42,4]]},"229":{"position":[[308,5]]},"231":{"position":[[20,4],[75,5],[223,4],[243,4]]},"244":{"position":[[597,4]]},"248":{"position":[[186,4],[197,4]]},"250":{"position":[[228,5]]},"271":{"position":[[10,4]]},"273":{"position":[[67,4],[184,4],[192,4]]},"343":{"position":[[834,4]]},"379":{"position":[[116,4],[329,4],[393,4]]},"388":{"position":[[209,4],[217,5]]},"394":{"position":[[179,4],[187,5]]},"396":{"position":[[274,4]]},"398":{"position":[[214,4],[222,6],[489,4]]},"429":{"position":[[384,5]]},"431":{"position":[[432,4],[494,5]]},"435":{"position":[[191,4]]},"441":{"position":[[130,5]]},"766":{"position":[[318,4],[469,4],[531,4]]},"823":{"position":[[1898,5]]},"825":{"position":[[166,5],[695,5]]},"834":{"position":[[475,5],[597,7]]},"850":{"position":[[1649,4]]},"859":{"position":[[388,4]]},"1146":{"position":[[1129,4],[2008,4]]},"1148":{"position":[[1125,4],[1274,4],[2384,4]]},"1154":{"position":[[482,5]]},"1158":{"position":[[432,5]]}}}],["stochast",{"_index":2072,"t":{"635":{"position":[[320,10]]},"648":{"position":[[55,10]]},"670":{"position":[[0,10]]},"688":{"position":[[186,10]]},"1148":{"position":[[1254,10]]},"1152":{"position":[[1420,10]]}}}],["stop",{"_index":2272,"t":{"698":{"position":[[1578,4]]},"825":{"position":[[752,8]]}}}],["storag",{"_index":1309,"t":{"421":{"position":[[13,7],[135,7]]},"427":{"position":[[41,7]]},"443":{"position":[[13,7]]},"844":{"position":[[434,7]]}}}],["strategi",{"_index":2745,"t":{"889":{"position":[[472,10]]}}}],["strategyqa",{"_index":917,"t":{"257":{"position":[[34,10]]},"259":{"position":[[7,10]]}}}],["stride",{"_index":242,"t":{"40":{"position":[[155,6]]},"78":{"position":[[874,6]]}}}],["string",{"_index":1335,"t":{"423":{"position":[[1110,7]]},"832":{"position":[[372,6]]},"834":{"position":[[908,6]]},"883":{"position":[[167,6]]}}}],["strong",{"_index":694,"t":{"153":{"position":[[22,6]]},"433":{"position":[[50,6]]}}}],["stronger",{"_index":357,"t":{"78":{"position":[[369,8],[630,8]]},"504":{"position":[[2189,8]]},"827":{"position":[[476,8]]}}}],["stroy",{"_index":1320,"t":{"423":{"position":[[788,5]]}}}],["structur",{"_index":510,"t":{"102":{"position":[[337,10]]},"269":{"position":[[344,9]]},"842":{"position":[[1695,9]]},"969":{"position":[[316,10],[392,9]]},"1146":{"position":[[1490,10]]}}}],["student",{"_index":543,"t":{"110":{"position":[[95,7]]},"633":{"position":[[322,7],[429,7],[678,7],[1120,7],[1705,7],[1922,7]]},"664":{"position":[[189,7]]}}}],["studi",{"_index":844,"t":{"209":{"position":[[24,5]]},"211":{"position":[[26,5]]},"311":{"position":[[342,5]]},"644":{"position":[[211,5]]}}}],["style",{"_index":2927,"t":{"963":{"position":[[1743,5]]},"1061":{"position":[[160,8]]}}}],["sub",{"_index":354,"t":{"78":{"position":[[254,3]]},"165":{"position":[[298,3]]},"625":{"position":[[469,3]]},"680":{"position":[[887,3]]},"694":{"position":[[609,3],[881,4],[940,4]]},"702":{"position":[[0,3],[131,3]]},"791":{"position":[[131,3]]},"901":{"position":[[2279,3]]},"911":{"position":[[38,3]]},"921":{"position":[[220,3]]},"923":{"position":[[118,3],[139,3]]},"975":{"position":[[427,3]]},"1087":{"position":[[30,3],[837,3],[2699,3]]},"1135":{"position":[[419,3]]}}}],["subject",{"_index":2249,"t":{"694":{"position":[[676,7]]},"696":{"position":[[613,7]]}}}],["submodul",{"_index":3452,"t":{"1140":{"position":[[65,10]]}}}],["subnetwork",{"_index":2480,"t":{"817":{"position":[[1382,10]]}}}],["suboptim",{"_index":1085,"t":{"328":{"position":[[189,10]]}}}],["subpar",{"_index":2970,"t":{"983":{"position":[[474,6],[643,6]]}}}],["subsequ",{"_index":1544,"t":{"461":{"position":[[941,10]]},"759":{"position":[[379,10]]},"773":{"position":[[847,10]]},"848":{"position":[[341,10]]}}}],["subset",{"_index":1048,"t":{"304":{"position":[[687,6]]},"328":{"position":[[177,6]]},"418":{"position":[[1423,6]]},"427":{"position":[[3472,6]]},"694":{"position":[[240,6]]},"698":{"position":[[487,7]]},"811":{"position":[[1115,6]]}}}],["subspac",{"_index":1449,"t":{"427":{"position":[[3517,8]]},"563":{"position":[[178,8]]},"604":{"position":[[296,8],[395,8],[451,8],[865,8],[1118,8]]},"606":{"position":[[45,8]]},"608":{"position":[[82,8]]},"631":{"position":[[904,8]]}}}],["subspan",{"_index":2567,"t":{"834":{"position":[[884,7]]}}}],["success",{"_index":2660,"t":{"859":{"position":[[151,7]]},"1111":{"position":[[92,7]]}}}],["success/fail",{"_index":2662,"t":{"859":{"position":[[166,14]]}}}],["such",{"_index":35,"t":{"7":{"position":[[49,4]]},"9":{"position":[[225,4]]},"957":{"position":[[174,5]]}}}],["sum^c_{j=1",{"_index":3766,"t":{"1214":{"position":[[606,12]]},"1222":{"position":[[1015,12]]}}}],["sum^k_i",{"_index":2826,"t":{"917":{"position":[[366,8],[1438,8]]}}}],["sum^l_{j=1}w_j",{"_index":630,"t":{"132":{"position":[[810,15]]}}}],["sum^m_{m=1}p^m_i",{"_index":3787,"t":{"1218":{"position":[[388,17]]}}}],["sum^n_{k=1",{"_index":3560,"t":{"1148":{"position":[[1012,12]]}}}],["sum^n_{n=1",{"_index":1380,"t":{"425":{"position":[[2138,12]]}}}],["sum^t_{t=1",{"_index":781,"t":{"180":{"position":[[172,13]]}}}],["sum^{d_1}_{j=1",{"_index":3614,"t":{"1152":{"position":[[559,16]]}}}],["sum^{d_2}_{j=1",{"_index":3617,"t":{"1152":{"position":[[604,16]]}}}],["sum^{t^{(n)}}_{t=1",{"_index":1356,"t":{"425":{"position":[[564,20]]}}}],["sum_i",{"_index":1988,"t":{"627":{"position":[[876,6]]}}}],["sum_t",{"_index":1341,"t":{"425":{"position":[[157,6]]}}}],["sum_{(x,i",{"_index":1769,"t":{"553":{"position":[[513,11],[1206,11]]}}}],["sum_{(x_i",{"_index":2037,"t":{"633":{"position":[[880,11],[1479,11]]}}}],["sum_{i",{"_index":2373,"t":{"770":{"position":[[297,7]]}}}],["sum_{i=0}^{l",{"_index":3335,"t":{"1096":{"position":[[2182,14]]}}}],["sum_{k",{"_index":2035,"t":{"633":{"position":[[853,7],[1452,7],[2208,7]]}}}],["sum_{t=1}^{|i",{"_index":1771,"t":{"553":{"position":[[542,16],[1235,16]]}}}],["sum_{z",{"_index":2813,"t":{"911":{"position":[[365,7]]}}}],["summar",{"_index":1145,"t":{"347":{"position":[[430,13]]},"353":{"position":[[52,13]]},"451":{"position":[[619,13]]},"573":{"position":[[144,14]]},"761":{"position":[[81,14]]},"764":{"position":[[185,13]]},"773":{"position":[[509,10]]},"780":{"position":[[185,13]]},"784":{"position":[[49,13],[503,13],[768,13],[874,13]]},"791":{"position":[[16,13]]},"793":{"position":[[16,13],[301,13],[473,13]]},"796":{"position":[[89,14]]},"802":{"position":[[180,13]]},"876":{"position":[[639,13]]},"997":{"position":[[139,14]]}}}],["summari",{"_index":18,"t":{"5":{"position":[[12,7]]},"764":{"position":[[226,7]]},"863":{"position":[[364,7]]}}}],["sun397",{"_index":3826,"t":{"1238":{"position":[[110,6]]}}}],["super",{"_index":1295,"t":{"416":{"position":[[751,5]]}}}],["superglu",{"_index":1338,"t":{"423":{"position":[[1405,10]]},"591":{"position":[[38,9]]},"616":{"position":[[1297,9]]},"642":{"position":[[134,9]]},"657":{"position":[[4,9]]},"664":{"position":[[97,9],[324,9]]},"668":{"position":[[201,10]]},"670":{"position":[[31,9]]},"678":{"position":[[275,9],[445,9]]},"680":{"position":[[1301,9],[1461,9],[1787,9]]},"688":{"position":[[1189,9]]},"690":{"position":[[35,9]]},"698":{"position":[[16,9],[35,9],[438,9],[475,9]]},"702":{"position":[[70,9],[634,9],[677,9]]},"707":{"position":[[211,9],[314,9]]},"716":{"position":[[81,9]]},"740":{"position":[[31,9]]},"746":{"position":[[45,9]]},"825":{"position":[[433,9],[523,9],[572,9]]},"827":{"position":[[535,9]]},"836":{"position":[[926,9],[1371,9]]},"840":{"position":[[562,9]]},"844":{"position":[[91,9]]}}}],["superviesd",{"_index":2703,"t":{"876":{"position":[[352,10]]}}}],["supervis",{"_index":541,"t":{"110":{"position":[[74,10]]},"118":{"position":[[17,11],[88,11],[112,11],[167,10]]},"120":{"position":[[209,10],[228,10]]},"320":{"position":[[230,10]]},"429":{"position":[[158,10]]},"678":{"position":[[300,10]]},"698":{"position":[[260,10],[294,10],[1181,10]]},"738":{"position":[[346,10]]},"751":{"position":[[64,10]]},"823":{"position":[[1458,10]]},"874":{"position":[[50,10]]},"876":{"position":[[6,10]]},"879":{"position":[[9,10]]},"881":{"position":[[0,10]]},"935":{"position":[[77,11]]},"963":{"position":[[2685,10],[2754,10],[2934,10],[3019,10]]},"987":{"position":[[179,10]]},"989":{"position":[[386,10]]},"993":{"position":[[35,10],[93,10],[275,10]]},"1001":{"position":[[136,10],[165,10],[1842,10]]},"1096":{"position":[[2506,9]]},"1200":{"position":[[404,10],[692,11]]},"1207":{"position":[[25,10]]},"1209":{"position":[[59,10]]},"1216":{"position":[[117,10]]},"1240":{"position":[[95,10]]},"1242":{"position":[[133,10]]}}}],["support",{"_index":31,"t":{"7":{"position":[[11,7]]},"9":{"position":[[361,8]]},"1049":{"position":[[11,8]]},"1053":{"position":[[27,10]]},"1055":{"position":[[28,10]]},"1057":{"position":[[25,9]]},"1073":{"position":[[35,7]]}}}],["suppress",{"_index":701,"t":{"153":{"position":[[164,11]]}}}],["surfac",{"_index":736,"t":{"169":{"position":[[118,7]]},"171":{"position":[[271,8],[645,7]]}}}],["svamp",{"_index":883,"t":{"236":{"position":[[27,5]]}}}],["svd",{"_index":1886,"t":{"604":{"position":[[107,5]]},"1135":{"position":[[578,5],[729,3]]},"1137":{"position":[[3719,3],[3921,3],[3947,3],[4022,3],[4280,3]]},"1144":{"position":[[21,3]]},"1146":{"position":[[1194,3],[1369,3],[1427,3]]},"1148":{"position":[[4,3]]},"1190":{"position":[[25,3],[119,3],[141,3],[402,3],[475,3]]},"1194":{"position":[[185,5]]}}}],["sw",{"_index":234,"t":{"38":{"position":[[435,2]]},"1117":{"position":[[58,2]]}}}],["swag",{"_index":1319,"t":{"423":{"position":[[781,4]]}}}],["swin",{"_index":3749,"t":{"1203":{"position":[[395,4]]}}}],["switch",{"_index":1741,"t":{"549":{"position":[[949,9]]},"1115":{"position":[[167,8]]}}}],["symbol",{"_index":866,"t":{"227":{"position":[[216,8]]},"229":{"position":[[92,8],[341,8],[894,8]]},"231":{"position":[[390,8]]},"263":{"position":[[28,8]]},"271":{"position":[[183,8]]},"275":{"position":[[87,8]]},"390":{"position":[[336,8]]}}}],["syntax",{"_index":3174,"t":{"1057":{"position":[[40,6]]},"1059":{"position":[[25,6]]}}}],["system",{"_index":1084,"t":{"328":{"position":[[164,6]]},"504":{"position":[[2071,7],[2575,7]]},"525":{"position":[[321,6],[427,6],[561,6],[660,6],[724,6],[795,6]]},"529":{"position":[[225,6]]},"533":{"position":[[285,6]]},"535":{"position":[[320,6]]},"543":{"position":[[53,6],[385,6]]},"963":{"position":[[1217,6]]},"1028":{"position":[[80,7]]},"1092":{"position":[[1694,7],[1869,7]]}}}],["sébastien",{"_index":3102,"t":{"1030":{"position":[[265,9]]}}}],["t",{"_index":1293,"t":{"416":{"position":[[694,1]]},"418":{"position":[[2220,1]]},"423":{"position":[[943,1]]},"431":{"position":[[5,1]]},"433":{"position":[[0,1]]},"435":{"position":[[45,1],[249,1],[371,1]]},"437":{"position":[[0,1]]},"439":{"position":[[66,1],[485,1]]},"441":{"position":[[0,1],[324,1],[425,1]]},"443":{"position":[[0,1]]},"445":{"position":[[51,1],[235,1]]},"447":{"position":[[49,1],[301,1],[384,1],[434,1]]},"449":{"position":[[0,1],[38,1]]},"451":{"position":[[4,1],[120,1],[267,1],[382,1],[477,1],[664,1]]},"627":{"position":[[988,2]]}}}],["t0",{"_index":1209,"t":{"373":{"position":[[158,2]]},"377":{"position":[[8,2]]},"386":{"position":[[89,2]]},"416":{"position":[[587,2]]},"418":{"position":[[1862,2]]},"423":{"position":[[111,2],[118,2],[383,2],[521,2],[555,3],[565,4],[575,2],[681,2]]},"427":{"position":[[3061,2]]},"429":{"position":[[304,2]]},"431":{"position":[[30,2],[97,2]]},"433":{"position":[[15,2],[34,2]]},"435":{"position":[[3,2],[61,2],[93,3],[174,3],[379,2]]},"437":{"position":[[319,2]]},"441":{"position":[[433,2]]},"443":{"position":[[374,2],[491,2]]},"449":{"position":[[17,2],[32,2]]}}}],["t5",{"_index":1005,"t":{"300":{"position":[[143,2]]},"313":{"position":[[95,3]]},"330":{"position":[[915,2]]},"349":{"position":[[217,2],[335,2]]},"362":{"position":[[63,2]]},"366":{"position":[[213,3]]},"368":{"position":[[448,2],[485,2],[500,2],[509,2]]},"370":{"position":[[152,3]]},"379":{"position":[[0,3],[248,4]]},"396":{"position":[[138,2],[402,2],[489,2],[573,2]]},"406":{"position":[[44,3]]},"418":{"position":[[1882,2]]},"423":{"position":[[123,2],[282,2]]},"435":{"position":[[403,2]]},"437":{"position":[[324,2]]},"616":{"position":[[1309,2]]},"644":{"position":[[79,2],[221,2],[238,2]]},"648":{"position":[[159,2]]},"655":{"position":[[104,2]]},"657":{"position":[[142,2]]},"815":{"position":[[303,2]]},"817":{"position":[[940,2]]},"819":{"position":[[0,2],[234,2],[1512,2]]},"823":{"position":[[36,2],[107,2],[844,2],[948,2],[1186,2],[1248,2],[1448,2],[1694,2]]},"825":{"position":[[27,2],[153,2]]},"827":{"position":[[30,2],[234,2],[649,2],[695,2]]},"832":{"position":[[201,2]]},"834":{"position":[[80,2],[575,2]]},"836":{"position":[[646,2]]},"840":{"position":[[604,2]]},"899":{"position":[[705,2],[761,2],[851,2]]},"953":{"position":[[401,2],[482,4]]},"983":{"position":[[185,3]]},"1137":{"position":[[73,2]]}}}],["t5+lm",{"_index":1460,"t":{"435":{"position":[[152,5]]}}}],["t5.1.1",{"_index":2541,"t":{"825":{"position":[[84,6]]}}}],["t=100\\triangle_t",{"_index":3672,"t":{"1158":{"position":[[444,17]]}}}],["t=[t1,t2,…,tn]∈rn×dt",{"_index":1977,"t":{"627":{"position":[[556,20]]}}}],["t={[p0:i],x,[pi+1:m],y}t",{"_index":2181,"t":{"686":{"position":[[1001,24]]}}}],["t={[p0:i​],x,[pi+1:m​],i",{"_index":2184,"t":{"686":{"position":[[1087,27]]}}}],["t={t1,t2,…,tt}\\pmb{\\mathcal{t",{"_index":1962,"t":{"625":{"position":[[142,31]]},"635":{"position":[[904,31]]}}}],["t\\mathcal{t}t",{"_index":1994,"t":{"627":{"position":[[1331,13]]},"635":{"position":[[1081,13]]}}}],["t\\pmb{\\mathcal{t}}tt",{"_index":1972,"t":{"625":{"position":[[688,20]]},"627":{"position":[[62,20],[290,20]]}}}],["t\\tau_tτt",{"_index":2683,"t":{"863":{"position":[[539,11]]}}}],["t\\triangle_t△t",{"_index":3671,"t":{"1158":{"position":[[415,16]]}}}],["t_1",{"_index":1978,"t":{"627":{"position":[[579,5]]}}}],["t_2",{"_index":1979,"t":{"627":{"position":[[585,4]]}}}],["t_l",{"_index":1540,"t":{"461":{"position":[[787,4]]},"463":{"position":[[579,4],[623,4],[628,4],[674,4],[679,4]]}}}],["t_l][pl​;tl",{"_index":1546,"t":{"463":{"position":[[244,13]]}}}],["t_l^o",{"_index":1603,"t":{"463":{"position":[[2315,5]]}}}],["t_n",{"_index":1980,"t":{"627":{"position":[[597,4]]}}}],["tabl",{"_index":512,"t":{"104":{"position":[[0,5]]},"110":{"position":[[135,5]]},"157":{"position":[[408,5]]},"360":{"position":[[480,5]]},"437":{"position":[[671,5]]},"447":{"position":[[371,5]]},"479":{"position":[[0,5]]},"489":{"position":[[146,5]]},"533":{"position":[[106,5]]},"557":{"position":[[500,5]]},"595":{"position":[[26,5]]},"600":{"position":[[233,6]]},"606":{"position":[[241,5]]},"608":{"position":[[421,5]]},"637":{"position":[[455,5]]},"639":{"position":[[67,6],[89,6]]},"651":{"position":[[0,5],[68,5],[126,5]]},"653":{"position":[[114,5],[189,5]]},"655":{"position":[[162,5]]},"672":{"position":[[172,5]]},"694":{"position":[[544,5]]},"696":{"position":[[802,6]]},"702":{"position":[[230,6],[437,5],[914,5]]},"704":{"position":[[0,5]]},"725":{"position":[[224,5]]},"736":{"position":[[212,5]]},"746":{"position":[[0,5]]},"748":{"position":[[0,5]]},"759":{"position":[[460,5]]},"761":{"position":[[1007,5],[1582,5]]},"764":{"position":[[105,5],[145,5]]},"773":{"position":[[534,5]]},"780":{"position":[[0,5],[176,5]]},"782":{"position":[[0,5]]},"784":{"position":[[0,5],[721,5],[827,5]]},"787":{"position":[[60,5],[255,5],[573,5],[625,5]]},"789":{"position":[[106,5],[155,5],[214,5],[265,5],[300,5],[348,5]]},"791":{"position":[[0,5],[457,5]]},"793":{"position":[[0,5],[139,5],[171,5],[457,5],[508,5],[518,5],[637,5]]},"796":{"position":[[111,5]]},"798":{"position":[[154,5]]},"800":{"position":[[255,5]]},"819":{"position":[[752,5]]},"838":{"position":[[468,5],[984,5]]},"840":{"position":[[677,5]]},"883":{"position":[[544,5]]},"885":{"position":[[372,5]]},"969":{"position":[[374,6]]},"1186":{"position":[[184,5]]},"1188":{"position":[[94,5]]},"1190":{"position":[[341,5]]}}}],["tag",{"_index":70,"t":{"9":{"position":[[370,4]]},"713":{"position":[[1565,7]]},"725":{"position":[[71,7],[117,7],[297,7]]},"949":{"position":[[587,7]]},"963":{"position":[[1801,4]]},"1028":{"position":[[76,3]]},"1030":{"position":[[386,5]]}}}],["tag{1",{"_index":1693,"t":{"515":{"position":[[660,7]]}}}],["tag{1}lplm​=−i∑​logp(yi​∣xi",{"_index":1989,"t":{"627":{"position":[[917,29]]}}}],["tag{1}maximizej=1∑l​wj​logp(yj​∣x,y1:j−1​),(1",{"_index":633,"t":{"132":{"position":[[851,47]]}}}],["tag{1}pc​=∑j=1c​exp(<fjtext​,fimage>/τ)exp(<fctext​,fimage>/τ)​(1",{"_index":3768,"t":{"1214":{"position":[[662,67]]}}}],["tag{1}z^=z∈zsearch",{"_index":2737,"t":{"885":{"position":[[587,20]]}}}],["tag{1}ϕmax​(x,y)∈z∑​t=1∑∣y∣​log(pϕ​(yt​∣x,y<t​))(1",{"_index":1774,"t":{"553":{"position":[[592,52]]}}}],["tag{2",{"_index":1697,"t":{"515":{"position":[[727,7]]}}}],["tag{2}p^=p∗∘wk​=p∗∘(uk​⨂vkt​)(2",{"_index":2015,"t":{"631":{"position":[[694,33]]}}}],["tag{2}y^​=cargmax",{"_index":3774,"t":{"1214":{"position":[[929,19]]}}}],["tag{2}θmax​(x,y)∈z∑​t=1∑∣y∣​log(pϕ0​+△ϕ(θ)​(yt​∣x,y<t​))(2",{"_index":1783,"t":{"553":{"position":[[1313,60]]}}}],["tag{3}h=w0​x+△wx=w0​x+bax(3",{"_index":1812,"t":{"563":{"position":[[831,29]]}}}],["tag{3}llogit​=k∈s∣∑​(xi​,yi​)∈sk​∑​kl",{"_index":2041,"t":{"633":{"position":[[1015,38]]}}}],["tag{3}vc​=[v,wc​],(3",{"_index":3800,"t":{"1222":{"position":[[467,22]]}}}],["tag{4}lhidden​=k∈s∣∑​(xi​,yi​)∈sk",{"_index":2056,"t":{"633":{"position":[[1557,37]]}}}],["tag{4}pc​=∑j=1c​exp(<g(vj​),fimage>/τ)exp(<g(vc​),fimage>/τ)​(4",{"_index":3812,"t":{"1222":{"position":[[1066,65]]}}}],["tag{4}ϕ(ar=8​,ar=64​,i,j)=min(i,j)∣∣uar=8​i⊤​uar=64​j​∣∣f2​​∈[0,1](4",{"_index":1905,"t":{"604":{"position":[[642,70]]}}}],["tag{5}ltotal​=lplm​+λ(llogits​+lhidden​)(5",{"_index":2065,"t":{"633":{"position":[[2127,44]]}}}],["tail",{"_index":2760,"t":{"899":{"position":[[1093,6]]}}}],["take",{"_index":3066,"t":{"1024":{"position":[[150,4]]},"1059":{"position":[[128,4],[206,4]]}}}],["taken",{"_index":1002,"t":{"298":{"position":[[120,5],[178,5]]}}}],["target",{"_index":476,"t":{"91":{"position":[[2495,6]]},"108":{"position":[[83,6]]},"286":{"position":[[88,6],[157,6]]},"339":{"position":[[109,6]]},"379":{"position":[[280,6]]},"418":{"position":[[34,6],[200,6],[635,6],[939,6]]},"425":{"position":[[271,6],[760,6],[811,6],[967,6],[1186,6]]},"437":{"position":[[860,6],[987,6]]},"439":{"position":[[98,6]]},"523":{"position":[[623,6]]},"553":{"position":[[162,6]]},"614":{"position":[[420,6]]},"616":{"position":[[662,6],[800,6],[1556,6]]},"619":{"position":[[695,6],[824,6]]},"621":{"position":[[122,6]]},"623":{"position":[[204,6]]},"625":{"position":[[129,6]]},"627":{"position":[[50,6],[277,6],[1224,6],[1318,6]]},"629":{"position":[[300,6],[394,6]]},"633":{"position":[[1870,6]]},"635":{"position":[[0,6],[523,6],[546,6],[582,6],[891,6]]},"637":{"position":[[144,6],[312,6],[435,6]]},"642":{"position":[[117,6]]},"646":{"position":[[140,6],[275,6]]},"648":{"position":[[211,6],[260,6]]},"653":{"position":[[262,6]]},"655":{"position":[[39,6]]},"659":{"position":[[83,6],[138,6]]},"662":{"position":[[307,6]]},"668":{"position":[[10,6],[235,6]]},"672":{"position":[[208,6]]},"674":{"position":[[291,6],[353,6]]},"686":{"position":[[367,6],[632,6],[809,6],[845,6]]},"694":{"position":[[799,6]]},"713":{"position":[[88,6]]},"821":{"position":[[567,6]]},"823":{"position":[[220,6],[462,6],[926,6],[1014,6],[1366,6],[1417,6]]},"834":{"position":[[227,6]]},"850":{"position":[[1296,8]]},"876":{"position":[[52,6]]},"917":{"position":[[829,6]]},"1085":{"position":[[155,6]]},"1087":{"position":[[656,6]]},"1092":{"position":[[562,6],[832,6],[905,6],[922,6],[962,6]]},"1154":{"position":[[320,6]]},"1198":{"position":[[358,6]]},"1200":{"position":[[510,6],[815,6],[965,6]]},"1205":{"position":[[328,6],[533,6]]},"1207":{"position":[[409,6]]},"1209":{"position":[[78,6],[133,6]]},"1211":{"position":[[137,6]]},"1214":{"position":[[52,6]]},"1216":{"position":[[35,6],[337,6]]},"1220":{"position":[[315,6]]},"1222":{"position":[[284,6]]},"1224":{"position":[[38,6]]}}}],["task",{"_index":374,"t":{"84":{"position":[[4,4]]},"97":{"position":[[47,4]]},"102":{"position":[[230,4]]},"118":{"position":[[4,4]]},"124":{"position":[[81,4],[154,4],[268,4],[364,4],[427,4],[459,4],[500,4],[529,4],[579,4],[609,4]]},"126":{"position":[[4,4],[110,4],[149,4],[202,4],[358,4],[532,5],[637,4],[678,4],[735,4],[813,4],[880,5],[979,4],[1093,4],[1143,4],[1199,4],[1222,4]]},"128":{"position":[[20,4],[39,5],[92,4],[122,4]]},"130":{"position":[[6,4],[236,4],[315,4],[1582,4]]},"132":{"position":[[355,4],[426,4],[476,4],[502,4]]},"134":{"position":[[2,4],[50,4]]},"136":{"position":[[6,4],[81,4]]},"138":{"position":[[11,4],[51,4],[131,4],[172,4],[351,4],[415,4],[444,4],[467,4],[504,4],[532,4]]},"140":{"position":[[186,4],[217,4],[313,4],[328,4]]},"143":{"position":[[75,4],[461,4]]},"151":{"position":[[161,4]]},"153":{"position":[[229,4],[290,4],[469,4],[611,4],[681,4]]},"155":{"position":[[57,4],[78,4],[132,4],[196,4],[216,4],[230,4],[293,4],[343,4],[401,4],[614,4],[838,4],[862,4],[924,4],[948,4],[1019,4]]},"157":{"position":[[131,4],[172,4],[220,4],[356,4],[370,4]]},"159":{"position":[[8,4],[36,4],[96,4],[164,4],[188,4],[244,4],[898,4],[950,4]]},"180":{"position":[[570,4]]},"197":{"position":[[112,4]]},"206":{"position":[[209,4]]},"213":{"position":[[210,4]]},"227":{"position":[[235,4]]},"229":{"position":[[118,4],[425,4],[804,4],[1125,4],[1184,4]]},"231":{"position":[[7,4],[412,4]]},"233":{"position":[[77,4],[86,4]]},"244":{"position":[[293,4],[360,4]]},"259":{"position":[[83,4]]},"261":{"position":[[3,4],[150,4]]},"265":{"position":[[9,4]]},"267":{"position":[[33,5]]},"269":{"position":[[366,5],[424,4]]},"271":{"position":[[301,4],[381,4]]},"275":{"position":[[170,4]]},"279":{"position":[[34,4],[163,4],[319,4]]},"281":{"position":[[34,4],[334,4],[359,4],[467,4],[581,4],[1097,4],[1544,4],[1554,4],[2019,4]]},"286":{"position":[[40,4],[128,4]]},"292":{"position":[[136,4],[171,4],[231,4],[389,4],[507,4],[582,4],[770,4]]},"300":{"position":[[824,4],[870,4],[1022,4],[1030,4]]},"322":{"position":[[100,4]]},"328":{"position":[[147,4],[223,4],[324,4],[565,5],[874,4],[899,4]]},"330":{"position":[[74,4],[127,4],[177,4],[267,4],[363,4],[417,4],[505,4],[802,4],[893,4],[978,4]]},"333":{"position":[[32,4]]},"335":{"position":[[124,4]]},"339":{"position":[[268,4]]},"341":{"position":[[206,5],[269,4]]},"343":{"position":[[2,5],[177,4],[197,4]]},"345":{"position":[[2,4],[387,4],[730,4]]},"347":{"position":[[2,4],[480,5]]},"351":{"position":[[69,5],[88,5],[116,5],[132,4]]},"353":{"position":[[88,4]]},"355":{"position":[[246,4]]},"357":{"position":[[24,5],[104,4],[121,4],[209,4]]},"360":{"position":[[261,5],[814,4]]},"366":{"position":[[47,4],[130,5]]},"368":{"position":[[74,4],[294,6],[329,4],[542,4]]},"373":{"position":[[83,4],[101,4],[150,7],[169,7],[188,6],[214,4]]},"375":{"position":[[52,4]]},"379":{"position":[[345,5]]},"382":{"position":[[40,4],[85,4],[138,4],[197,4]]},"386":{"position":[[20,4],[129,4],[211,4],[241,5],[275,4]]},"388":{"position":[[188,4]]},"392":{"position":[[136,4],[276,4],[294,4]]},"400":{"position":[[45,4]]},"402":{"position":[[51,4],[114,4],[160,4],[173,4]]},"404":{"position":[[53,4],[118,4],[263,4]]},"412":{"position":[[84,4],[176,4]]},"416":{"position":[[126,4],[333,4],[616,5],[627,4],[733,5]]},"418":{"position":[[41,4],[218,4],[315,4],[349,4],[592,4],[801,4],[1253,4],[1539,4],[1816,4],[1982,5],[2363,4]]},"421":{"position":[[68,4],[174,4],[225,4],[280,4],[355,4]]},"423":{"position":[[374,4],[744,4],[1269,5]]},"425":{"position":[[1233,5]]},"427":{"position":[[111,4],[173,4],[196,4],[335,4],[538,4],[652,4],[873,4],[2514,4],[2561,4],[2597,4],[3022,4],[3233,4],[3383,4],[3588,4]]},"429":{"position":[[79,5],[169,5],[192,4]]},"431":{"position":[[56,4]]},"433":{"position":[[94,4]]},"443":{"position":[[318,4]]},"447":{"position":[[126,4],[473,4]]},"451":{"position":[[606,5],[652,4]]},"455":{"position":[[583,4]]},"465":{"position":[[1227,4]]},"467":{"position":[[101,4]]},"471":{"position":[[24,4],[212,5]]},"494":{"position":[[107,4]]},"504":{"position":[[891,4],[1222,4]]},"517":{"position":[[169,4]]},"525":{"position":[[774,4]]},"547":{"position":[[179,4]]},"549":{"position":[[49,4],[151,4],[181,4],[215,4],[823,4],[918,4],[944,4]]},"553":{"position":[[147,4],[681,4],[917,4]]},"563":{"position":[[105,4]]},"567":{"position":[[14,4]]},"569":{"position":[[256,4]]},"571":{"position":[[384,4]]},"573":{"position":[[36,4]]},"589":{"position":[[18,4],[121,4]]},"614":{"position":[[38,4],[130,4],[227,4],[318,4],[427,4],[569,4]]},"616":{"position":[[58,4],[90,4],[190,4],[396,4],[527,5],[584,5],[669,4],[807,4],[883,4],[923,4],[985,4],[1137,4],[1235,4],[1405,4],[1509,4],[1563,4]]},"619":{"position":[[193,4],[302,4],[597,4],[702,4],[831,4]]},"621":{"position":[[53,5],[92,5],[129,4]]},"623":{"position":[[28,4],[196,4],[211,4],[300,4],[314,4]]},"625":{"position":[[14,5],[136,5],[271,4],[492,4],[604,4],[747,4]]},"627":{"position":[[57,4],[284,5],[1054,4],[1173,5],[1231,4],[1325,5]]},"629":{"position":[[106,4],[132,4],[170,6],[188,4],[241,4],[401,4]]},"631":{"position":[[33,4],[93,4],[121,4],[169,4],[298,5],[375,4],[389,4],[411,4],[561,4],[571,4],[820,4],[941,4]]},"633":{"position":[[94,4],[248,4],[473,4],[526,4],[606,4],[2287,5],[2302,4]]},"635":{"position":[[7,5],[81,5],[331,5],[364,4],[476,5],[553,4],[621,4],[814,4],[898,5]]},"637":{"position":[[2,4],[85,4],[151,4],[319,4],[442,5]]},"642":{"position":[[55,4],[124,4],[345,4]]},"646":{"position":[[82,4]]},"648":{"position":[[66,4],[112,5],[267,4],[312,4]]},"653":{"position":[[53,5],[254,4],[269,4]]},"655":{"position":[[4,4],[50,4],[80,4],[131,4],[238,4],[249,4],[262,4]]},"657":{"position":[[14,4]]},"659":{"position":[[35,4],[56,4],[90,4],[145,4],[220,4],[234,4],[352,4],[374,4]]},"662":{"position":[[130,4],[144,4],[325,4],[342,4],[417,4]]},"668":{"position":[[17,4],[54,4],[92,4],[121,4],[159,4]]},"670":{"position":[[11,4]]},"672":{"position":[[16,4],[39,4],[65,4],[186,4],[237,4]]},"674":{"position":[[54,4],[61,4],[169,4],[215,4],[298,4],[371,4],[435,4]]},"678":{"position":[[70,4]]},"680":{"position":[[438,4],[1555,4]]},"682":{"position":[[74,4]]},"688":{"position":[[1208,4],[1230,4]]},"694":{"position":[[1005,4]]},"698":{"position":[[57,4],[119,4],[497,4],[976,4],[997,4]]},"700":{"position":[[59,4],[69,4],[266,4],[307,4],[376,4],[402,4],[438,4],[486,4],[648,4]]},"702":{"position":[[98,4],[1045,4],[1086,4],[1190,4]]},"704":{"position":[[165,4]]},"711":{"position":[[91,4],[278,4]]},"713":{"position":[[28,5],[95,4],[244,4],[882,4],[973,4],[1053,4],[1363,4],[1573,4],[1589,4],[1624,4],[1707,4]]},"716":{"position":[[4,4],[42,5],[117,5]]},"718":{"position":[[814,4]]},"725":{"position":[[79,4],[168,4],[305,4],[355,4]]},"727":{"position":[[375,4],[434,4]]},"730":{"position":[[104,4]]},"732":{"position":[[51,4],[123,4],[180,4]]},"734":{"position":[[6,4],[25,5],[73,4],[98,4]]},"738":{"position":[[50,4],[203,4]]},"742":{"position":[[87,4]]},"744":{"position":[[6,4],[19,4]]},"746":{"position":[[167,4],[400,4]]},"748":{"position":[[37,4],[66,4],[85,4],[319,4],[333,4]]},"755":{"position":[[72,4]]},"759":{"position":[[66,4],[135,4],[207,5],[307,4]]},"761":{"position":[[70,4],[162,4],[475,4],[575,4],[742,4],[770,4],[799,4],[983,4],[1153,4],[1416,4],[1477,4],[1529,4]]},"773":{"position":[[250,4],[297,4],[331,4],[399,4],[486,4],[575,4]]},"780":{"position":[[14,4],[199,4]]},"782":{"position":[[25,4]]},"784":{"position":[[63,4],[735,4],[782,4]]},"787":{"position":[[7,4]]},"802":{"position":[[209,4]]},"804":{"position":[[96,4]]},"807":{"position":[[39,4],[139,4]]},"809":{"position":[[351,4]]},"811":{"position":[[937,4]]},"815":{"position":[[34,4]]},"817":{"position":[[22,4],[110,4],[510,4],[623,4],[672,4],[731,4],[850,4],[1234,4],[1542,4],[1794,4],[2011,4],[2146,4],[2264,4]]},"819":{"position":[[36,4]]},"821":{"position":[[313,4]]},"823":{"position":[[187,4],[1271,4],[1616,4]]},"825":{"position":[[328,4],[464,4],[533,4],[556,5],[617,4],[632,4]]},"827":{"position":[[162,4],[197,5],[245,4],[277,4],[297,4],[432,4],[491,4]]},"832":{"position":[[357,4]]},"834":{"position":[[792,4]]},"836":{"position":[[77,4],[200,4],[553,4],[936,4],[1180,4],[1843,4],[1874,4],[1967,4],[2048,4],[2183,4],[2337,4]]},"838":{"position":[[249,5],[759,5],[784,4],[828,4],[934,4],[963,4],[1211,4]]},"840":{"position":[[66,4],[267,4],[505,7],[572,4],[691,4]]},"842":{"position":[[16,4]]},"844":{"position":[[51,4],[104,4],[409,4],[531,4]]},"848":{"position":[[488,4]]},"850":{"position":[[714,4],[1558,4],[1614,4],[1694,4],[1750,4],[1775,4],[1809,4],[1845,4]]},"857":{"position":[[117,4],[260,4],[386,4],[492,4],[615,4]]},"863":{"position":[[186,4]]},"876":{"position":[[28,4],[59,4],[456,4],[706,4],[924,4],[1121,4],[1209,4]]},"883":{"position":[[805,4]]},"889":{"position":[[147,4],[293,4]]},"891":{"position":[[41,4],[125,4]]},"893":{"position":[[43,4],[76,4],[207,4]]},"895":{"position":[[218,4],[236,4],[566,4]]},"897":{"position":[[28,4],[111,4]]},"899":{"position":[[994,4],[1051,4]]},"901":{"position":[[31,4],[234,4],[343,4],[1286,4],[1360,4],[2470,4]]},"905":{"position":[[224,4],[455,4]]},"909":{"position":[[383,4],[566,4],[720,4]]},"917":{"position":[[181,4],[663,4],[998,4],[1292,4]]},"921":{"position":[[117,4]]},"927":{"position":[[111,4],[302,4],[333,4],[391,4]]},"929":{"position":[[21,4]]},"931":{"position":[[82,4]]},"935":{"position":[[62,4]]},"937":{"position":[[457,4],[589,4],[628,4]]},"945":{"position":[[107,4]]},"947":{"position":[[21,5]]},"949":{"position":[[37,4],[171,4],[387,4],[595,4]]},"953":{"position":[[423,4],[505,4]]},"955":{"position":[[511,4]]},"957":{"position":[[122,4]]},"959":{"position":[[18,4],[32,4]]},"963":{"position":[[121,4],[400,4],[991,4],[1379,4],[1408,4],[1451,4],[1530,4],[1983,4],[2389,4],[2459,4],[2538,4],[3277,4]]},"965":{"position":[[28,4]]},"969":{"position":[[0,5],[108,4],[157,4],[345,4]]},"971":{"position":[[26,5],[118,5],[276,5]]},"975":{"position":[[449,4],[524,4],[598,4],[858,5],[970,4],[1052,4]]},"977":{"position":[[119,4],[234,4]]},"983":{"position":[[151,4]]},"995":{"position":[[227,4]]},"997":{"position":[[3,4],[189,4]]},"1001":{"position":[[91,4]]},"1085":{"position":[[109,4],[218,4],[295,4],[410,5],[604,4],[668,4],[759,4],[792,4]]},"1087":{"position":[[34,5],[59,4],[354,4],[365,4],[733,5],[841,5],[932,4],[994,4],[1199,5],[1273,5],[1373,5],[1594,5],[2368,4],[2435,4],[2532,5],[2703,5],[2758,4],[2783,5],[2860,5]]},"1090":{"position":[[47,5],[334,5],[405,5]]},"1092":{"position":[[210,5],[368,5],[520,5]]},"1096":{"position":[[61,5],[738,5],[1734,5],[1881,5],[2632,5]]},"1099":{"position":[[1023,5],[1126,5]]},"1101":{"position":[[16,5]]},"1127":{"position":[[89,4],[293,5]]},"1129":{"position":[[3,5],[13,6],[35,5],[56,5],[82,5]]},"1131":{"position":[[67,5]]},"1135":{"position":[[54,5],[164,5]]},"1137":{"position":[[164,5],[201,5],[237,4],[405,4],[464,5],[482,4],[3513,4],[4403,4],[4553,4]]},"1163":{"position":[[115,6],[148,5],[185,5]]},"1170":{"position":[[90,4]]},"1177":{"position":[[4,5]]},"1184":{"position":[[161,4],[220,4]]},"1192":{"position":[[394,4]]},"1194":{"position":[[374,4]]},"1198":{"position":[[247,4]]},"1200":{"position":[[151,4],[489,4],[876,4],[1923,4]]},"1216":{"position":[[265,4]]}}}],["tast",{"_index":2245,"t":{"694":{"position":[[258,7]]}}}],["tau",{"_index":2092,"t":{"637":{"position":[[426,6]]},"1214":{"position":[[596,4],[653,4],[734,6]]},"1222":{"position":[[1006,5],[1058,5],[1136,6]]}}}],["tau_0",{"_index":2676,"t":{"863":{"position":[[331,7]]}}}],["tdec",{"_index":1143,"t":{"347":{"position":[[334,6]]}}}],["teacher",{"_index":2021,"t":{"633":{"position":[[258,7],[688,7],[1110,7],[1325,7],[1695,7]]},"635":{"position":[[92,7]]},"664":{"position":[[179,7]]}}}],["technolog",{"_index":2595,"t":{"842":{"position":[[520,11],[534,10],[547,12],[562,13],[578,15],[594,10],[610,10],[626,12],[644,13],[663,12],[676,13],[692,10],[705,12],[720,13],[736,13],[1845,10]]}}}],["telsa",{"_index":2434,"t":{"784":{"position":[[525,5]]}}}],["temperatur",{"_index":1262,"t":{"398":{"position":[[331,11]]},"475":{"position":[[365,11]]},"633":{"position":[[1179,11]]},"1214":{"position":[[755,11]]},"1222":{"position":[[1145,11]]}}}],["templat",{"_index":100,"t":{"17":{"position":[[49,9],[71,8]]},"296":{"position":[[149,8]]},"370":{"position":[[48,8]]},"377":{"position":[[54,8],[110,8],[134,8]]},"423":{"position":[[457,9],[1296,8],[1340,8]]},"431":{"position":[[551,8]]},"686":{"position":[[652,8],[709,8],[924,8],[1470,8]]},"688":{"position":[[1248,8]]},"694":{"position":[[897,8]]},"883":{"position":[[123,8],[343,8],[677,8]]},"889":{"position":[[126,8],[251,8]]},"891":{"position":[[7,8],[139,8]]},"893":{"position":[[331,8]]},"895":{"position":[[35,8],[116,8],[610,8]]},"897":{"position":[[7,8],[185,8]]},"899":{"position":[[86,8],[168,8],[422,8],[722,8],[734,8],[766,8],[967,8],[1103,8],[1119,8]]},"901":{"position":[[127,8],[173,8],[1111,8],[1562,8],[1635,8],[1718,8],[1741,8],[1793,8],[1854,8],[1888,8],[1961,8],[1989,8],[2170,8],[2254,8],[2283,9],[2298,8],[2397,8]]},"911":{"position":[[1160,8]]},"917":{"position":[[1149,8],[1224,8]]},"919":{"position":[[928,8]]},"937":{"position":[[187,8],[334,8],[422,8],[536,8]]},"943":{"position":[[249,8],[288,8],[346,8]]},"947":{"position":[[258,8],[581,8]]},"949":{"position":[[408,8],[420,8],[704,8],[751,8],[822,8]]},"955":{"position":[[306,8]]},"959":{"position":[[905,8]]},"963":{"position":[[193,8]]},"969":{"position":[[420,8],[711,8],[746,8],[781,8],[842,8]]},"975":{"position":[[1099,8]]},"1024":{"position":[[84,9]]}}}],["tempor",{"_index":14,"t":{"3":{"position":[[121,6]]},"5":{"position":[[241,6],[420,6],[599,6],[778,6],[957,6],[1136,6],[1315,6],[1494,6],[1673,6],[1852,6],[2031,6],[2210,6],[2389,6],[2568,6],[2747,6],[2926,6]]}}}],["tensor",{"_index":751,"t":{"171":{"position":[[557,6]]},"686":{"position":[[1713,7]]}}}],["term",{"_index":1307,"t":{"418":{"position":[[2045,4]]},"425":{"position":[[75,5]]},"850":{"position":[[1090,4]]},"861":{"position":[[29,4],[41,4],[96,4],[211,4],[269,4]]},"870":{"position":[[150,4]]},"1152":{"position":[[2316,4]]}}}],["termin",{"_index":112,"t":{"17":{"position":[[256,9],[290,8]]},"19":{"position":[[200,8]]}}}],["test",{"_index":826,"t":{"193":{"position":[[71,4]]},"281":{"position":[[1591,4]]},"309":{"position":[[34,4],[58,4],[115,4]]},"423":{"position":[[1004,4],[1371,4],[1416,4]]},"447":{"position":[[165,4],[265,4]]},"692":{"position":[[135,4]]},"694":{"position":[[468,4]]},"707":{"position":[[158,4]]},"793":{"position":[[114,4]]},"850":{"position":[[1599,4],[1677,4]]},"1047":{"position":[[0,4]]},"1107":{"position":[[37,4]]},"1224":{"position":[[158,4]]}}}],["text",{"_index":622,"t":{"130":{"position":[[1558,4]]},"140":{"position":[[814,4]]},"143":{"position":[[575,4]]},"159":{"position":[[403,4]]},"169":{"position":[[573,5]]},"171":{"position":[[349,4],[758,4]]},"180":{"position":[[308,4],[502,4]]},"190":{"position":[[137,4]]},"281":{"position":[[766,4]]},"284":{"position":[[89,4]]},"300":{"position":[[350,4],[405,4]]},"302":{"position":[[515,4],[1072,4]]},"304":{"position":[[123,4]]},"311":{"position":[[136,4]]},"328":{"position":[[522,4],[851,4]]},"330":{"position":[[324,4],[1119,4]]},"333":{"position":[[313,4]]},"335":{"position":[[89,4]]},"341":{"position":[[14,4],[59,4]]},"343":{"position":[[10,4],[73,4],[104,4],[223,4],[420,4]]},"345":{"position":[[26,4],[79,4],[342,4],[459,4],[650,4],[790,4]]},"347":{"position":[[38,4],[61,4],[145,4],[368,4]]},"357":{"position":[[186,4],[219,4]]},"360":{"position":[[515,4],[801,4],[821,4]]},"423":{"position":[[142,4],[495,4],[503,4]]},"429":{"position":[[136,4]]},"431":{"position":[[591,4],[599,4]]},"457":{"position":[[986,4]]},"465":{"position":[[0,4]]},"502":{"position":[[425,4],[535,4],[605,4]]},"504":{"position":[[988,4],[1172,4],[1505,4],[2128,4],[2356,4]]},"510":{"position":[[294,4]]},"519":{"position":[[133,4],[239,4],[376,4],[625,4]]},"521":{"position":[[99,4],[420,4]]},"525":{"position":[[58,4],[236,4],[685,4]]},"537":{"position":[[192,4],[710,4]]},"539":{"position":[[266,4]]},"541":{"position":[[261,4]]},"543":{"position":[[106,4],[258,4]]},"678":{"position":[[237,4]]},"680":{"position":[[25,4]]},"694":{"position":[[85,7]]},"707":{"position":[[169,4]]},"718":{"position":[[203,4]]},"759":{"position":[[469,4]]},"761":{"position":[[1070,4],[1591,5]]},"764":{"position":[[114,4],[164,4]]},"780":{"position":[[9,4]]},"782":{"position":[[9,4]]},"784":{"position":[[9,4],[730,4],[836,4]]},"787":{"position":[[69,4],[634,4]]},"789":{"position":[[115,4],[164,4],[223,4],[274,4],[357,4]]},"791":{"position":[[9,4]]},"793":{"position":[[9,4],[148,4],[232,4],[466,4]]},"796":{"position":[[120,4]]},"802":{"position":[[196,4],[204,4]]},"817":{"position":[[293,4],[452,4],[817,4],[1556,4]]},"819":{"position":[[5,4],[13,4],[43,4]]},"821":{"position":[[216,4],[365,4]]},"823":{"position":[[118,4],[234,4],[285,4],[628,4],[874,4],[1290,4],[1523,4],[1558,4],[1735,4]]},"825":{"position":[[595,4],[603,4]]},"827":{"position":[[314,4]]},"848":{"position":[[311,4]]},"850":{"position":[[91,4]]},"853":{"position":[[38,4]]},"855":{"position":[[22,4],[324,4]]},"874":{"position":[[353,4]]},"876":{"position":[[634,4]]},"879":{"position":[[45,5],[126,4],[245,4],[268,4],[493,4]]},"883":{"position":[[214,4],[250,4]]},"885":{"position":[[34,4]]},"893":{"position":[[274,4]]},"895":{"position":[[328,4],[389,4],[528,4],[550,4]]},"899":{"position":[[113,4]]},"909":{"position":[[285,4],[416,4]]},"917":{"position":[[647,4],[1265,4]]},"923":{"position":[[192,4]]},"927":{"position":[[21,4]]},"947":{"position":[[202,4],[407,4],[509,4]]},"949":{"position":[[639,4],[729,4]]},"953":{"position":[[430,4]]},"955":{"position":[[0,4],[397,4]]},"959":{"position":[[387,4]]},"963":{"position":[[1471,4],[1686,4],[2040,4],[2319,4],[2427,4],[2486,4],[2606,4],[2812,4]]},"969":{"position":[[69,4],[143,4],[570,4],[588,4]]},"971":{"position":[[284,4],[370,4]]},"995":{"position":[[30,4]]},"1051":{"position":[[209,4]]},"1087":{"position":[[1898,4]]},"1104":{"position":[[90,4]]},"1198":{"position":[[110,5]]},"1200":{"position":[[55,4],[96,4]]},"1203":{"position":[[17,4],[124,4],[296,4],[335,4],[412,4],[457,4]]},"1205":{"position":[[267,4]]},"1207":{"position":[[345,4],[595,4]]},"1214":{"position":[[220,4]]},"1222":{"position":[[812,4],[1274,4],[1329,4],[1440,4]]},"1224":{"position":[[106,4]]}}}],["text/cod",{"_index":1137,"t":{"345":{"position":[[1126,9]]},"357":{"position":[[66,9]]}}}],["textbook",{"_index":2583,"t":{"838":{"position":[[653,12]]}}}],["textbookqa",{"_index":2578,"t":{"838":{"position":[[546,10],[640,10]]}}}],["textual",{"_index":997,"t":{"296":{"position":[[254,7]]},"300":{"position":[[58,7],[286,7],[565,7]]},"302":{"position":[[586,7]]},"525":{"position":[[571,7]]},"541":{"position":[[74,7]]},"698":{"position":[[156,7]]},"876":{"position":[[936,7]]},"883":{"position":[[159,7]]},"919":{"position":[[809,7]]},"937":{"position":[[179,7]]}}}],["textup{annot",{"_index":3297,"t":{"1092":{"position":[[2277,18]]}}}],["textup{bi",{"_index":3312,"t":{"1094":{"position":[[519,10]]}}}],["textup{categori",{"_index":3293,"t":{"1092":{"position":[[2162,16]]},"1096":{"position":[[2146,17]]}}}],["textup{enc}_\\textup{v}^{\\textup{ref",{"_index":3295,"t":{"1092":{"position":[[2207,39]]}}}],["textup{enc}_l^{\\textup{ref",{"_index":3291,"t":{"1092":{"position":[[2067,29],[2130,29]]}}}],["textup{express",{"_index":3292,"t":{"1092":{"position":[[2099,18]]}}}],["textup{expression/annot",{"_index":3336,"t":{"1096":{"position":[[2211,30]]}}}],["textup{ins}}w^ts=fins​wt",{"_index":3341,"t":{"1096":{"position":[[2439,25]]}}}],["textup{ln}(z^0_l)y=ln(zl0",{"_index":475,"t":{"91":{"position":[[2441,28]]}}}],["textup{merg",{"_index":3294,"t":{"1092":{"position":[[2191,15]]}}}],["textup{mlp}(\\textup{ln}(z'_\\varrho",{"_index":471,"t":{"91":{"position":[[2287,37]]}}}],["textup{msa}(\\textup{ln}(z_{\\varrho",{"_index":462,"t":{"91":{"position":[[1992,35]]}}}],["textup{para}(z')}p(z|x)p(y∣x)=∑z∈para(z′)​p(z∣x",{"_index":2814,"t":{"911":{"position":[[377,49]]}}}],["textup{templ",{"_index":3296,"t":{"1092":{"position":[[2247,17]]}}}],["text{concat",{"_index":1621,"t":{"465":{"position":[[516,13]]}}}],["text{concat}(\\text{head}_1",{"_index":3457,"t":{"1140":{"position":[[324,28]]}}}],["text{dim}(h_i)∣pidx​∣×dim(hi",{"_index":2395,"t":{"775":{"position":[[504,31]]}}}],["text{head})i",{"_index":3460,"t":{"1140":{"position":[[385,13]]}}}],["text{head}_h)w_o",{"_index":3458,"t":{"1140":{"position":[[360,18]]}}}],["text{i",{"_index":1372,"t":{"425":{"position":[[1755,9],[2125,10]]},"686":{"position":[[2064,10]]},"1148":{"position":[[1995,8]]}}}],["text{if",{"_index":2399,"t":{"775":{"position":[[723,9]]}}}],["text{infix",{"_index":2455,"t":{"800":{"position":[[195,13]]}}}],["text{init}(0",{"_index":1695,"t":{"515":{"position":[[690,16]]}}}],["text{init}(1",{"_index":1696,"t":{"515":{"position":[[711,15]]}}}],["text{linear}_k",{"_index":1562,"t":{"463":{"position":[[598,15]]}}}],["text{linear}_o",{"_index":1604,"t":{"463":{"position":[[2323,15]]}}}],["text{linear}_q",{"_index":1560,"t":{"463":{"position":[[560,15]]}}}],["text{linear}_v",{"_index":1564,"t":{"463":{"position":[[649,15]]}}}],["text{lm}_{\\phi",{"_index":2350,"t":{"766":{"position":[[719,16]]}}}],["text{lm}_{\\phi}(z_i",{"_index":2401,"t":{"775":{"position":[[764,21]]}}}],["text{lstm}(h_{i:m",{"_index":2226,"t":{"688":{"position":[[888,22]]}}}],["text{mlp}([\\overrightarrow{h}_i",{"_index":2223,"t":{"688":{"position":[[781,32]]}}}],["text{mlp}([\\text{lstm}(h_{0:i",{"_index":2225,"t":{"688":{"position":[[849,32]]}}}],["text{mlp}_\\theta",{"_index":2416,"t":{"777":{"position":[[231,17]]}}}],["text{of",{"_index":3594,"t":{"1148":{"position":[[2025,10]]}}}],["text{otherwis",{"_index":2402,"t":{"775":{"position":[[797,17]]},"1148":{"position":[[2050,17]]}}}],["text{prefix",{"_index":2387,"t":{"775":{"position":[[67,15],[170,15],[189,15]]}}}],["text{project",{"_index":1619,"t":{"465":{"position":[[491,17]]}}}],["text{p}_{0:i",{"_index":2182,"t":{"686":{"position":[[1031,17]]}}}],["text{p}_{\\text{idx",{"_index":2400,"t":{"775":{"position":[[739,21]]}}}],["text{p}_{\\text{idx}}i∈/pidx",{"_index":2411,"t":{"775":{"position":[[1224,29]]}}}],["text{p}_{\\text{idx}}i∈pidx",{"_index":2407,"t":{"775":{"position":[[1123,28]]}}}],["text{p}_{i+1:m}],\\text{i",{"_index":2183,"t":{"686":{"position":[[1059,27]]}}}],["text{relu}(xw_{fi",{"_index":3472,"t":{"1140":{"position":[[893,19]]}}}],["text{repeat}(i_p",{"_index":1629,"t":{"465":{"position":[[940,18]]}}}],["text{softmax}(s_l^k",{"_index":1596,"t":{"463":{"position":[[1795,22]]}}}],["text{softmax}(s_l^{m+1})]^t",{"_index":1598,"t":{"463":{"position":[[1832,28]]}}}],["text{softmax}(w_{\\phi",{"_index":2357,"t":{"766":{"position":[[889,23]]}}}],["text{softmax}(xw_{qi}(xw_{ki})^\\top",{"_index":3461,"t":{"1140":{"position":[[401,36]]}}}],["text{softmax}\\left",{"_index":1412,"t":{"427":{"position":[[1606,19]]}}}],["text{wher",{"_index":1694,"t":{"515":{"position":[[671,12]]}}}],["text{with",{"_index":3588,"t":{"1148":{"position":[[1864,11]]}}}],["text{x",{"_index":1343,"t":{"425":{"position":[[178,9]]},"515":{"position":[[603,8],[645,8]]},"686":{"position":[[1049,9]]}}}],["text{x}_{\\text{idx}}i∈xidx",{"_index":2364,"t":{"768":{"position":[[290,28]]}}}],["text{y}))}{\\exp(\\beta(\\text{x",{"_index":1379,"t":{"425":{"position":[[2092,32]]}}}],["text{y}_{\\text{idx",{"_index":2374,"t":{"770":{"position":[[309,22]]}}}],["text{y}_{\\text{idx}}i∈yidx",{"_index":2366,"t":{"768":{"position":[[363,28]]}}}],["tft_ftf",{"_index":3663,"t":{"1154":{"position":[[644,8]]}}}],["th",{"_index":1365,"t":{"425":{"position":[[989,2]]},"461":{"position":[[518,2]]},"463":{"position":[[211,2],[280,2],[370,2],[2211,2]]},"465":{"position":[[837,2]]},"631":{"position":[[166,2],[551,2]]},"633":{"position":[[238,2],[1742,2]]},"766":{"position":[[548,2]]},"1142":{"position":[[601,2],[635,2],[716,2]]},"1146":{"position":[[561,2]]},"1148":{"position":[[505,2],[1122,2],[2381,2]]},"1214":{"position":[[350,2]]},"1218":{"position":[[311,2]]},"1222":{"position":[[876,2]]}}}],["thank",{"_index":2524,"t":{"823":{"position":[[290,6],[380,6]]}}}],["theme/layout",{"_index":3141,"t":{"1040":{"position":[[118,16]]}}}],["themeconfig",{"_index":3078,"t":{"1026":{"position":[[122,11]]},"1067":{"position":[[142,12]]},"1079":{"position":[[142,12]]}}}],["theta",{"_index":986,"t":{"286":{"position":[[330,8]]},"553":{"position":[[986,16],[1028,8],[1119,8]]},"627":{"position":[[37,8],[404,8],[906,7]]},"633":{"position":[[945,7],[992,7]]},"775":{"position":[[576,9],[1019,8]]},"819":{"position":[[382,8],[611,8],[772,8],[933,8]]},"879":{"position":[[166,8]]},"885":{"position":[[578,8]]},"901":{"position":[[676,8]]},"1001":{"position":[[962,8]]}}}],["theta)p",{"_index":2731,"t":{"885":{"position":[[409,14]]}}}],["theta)p(xt​∣x<t",{"_index":2909,"t":{"959":{"position":[[558,20]]}}}],["theta)p(y∣x",{"_index":1976,"t":{"627":{"position":[[257,15]]}}}],["thing",{"_index":2914,"t":{"959":{"position":[[966,6]]}}}],["think",{"_index":1243,"t":{"388":{"position":[[203,5]]},"394":{"position":[[173,5]]},"398":{"position":[[208,5]]}}}],["thought",{"_index":858,"t":{"227":{"position":[[9,7],[114,7]]},"229":{"position":[[746,8],[841,7]]},"366":{"position":[[183,7]]},"368":{"position":[[162,8]]},"412":{"position":[[103,7]]},"855":{"position":[[234,7]]}}}],["three",{"_index":362,"t":{"78":{"position":[[710,5]]},"384":{"position":[[22,6]]}}}],["threshold",{"_index":3739,"t":{"1200":{"position":[[1178,9],[1335,9]]},"1211":{"position":[[333,9]]},"1216":{"position":[[139,9],[465,9],[576,9]]}}}],["through",{"_index":131,"t":{"19":{"position":[[284,7]]},"1032":{"position":[[40,8]]}}}],["ti\\mathcal{t}_",{"_index":1967,"t":{"625":{"position":[[276,18]]}}}],["ti\\pmb{\\mathcal{t}}_itti",{"_index":1970,"t":{"625":{"position":[[413,25]]}}}],["tight",{"_index":2593,"t":{"842":{"position":[[476,5]]}}}],["tilde{\\lambda}^{t}_{k,ii",{"_index":3591,"t":{"1148":{"position":[[1953,26]]}}}],["tilde{\\lambda}_k^{(t",{"_index":3571,"t":{"1148":{"position":[[1369,23],[1826,25]]}}}],["tile",{"_index":761,"t":{"171":{"position":[[778,6]]}}}],["time",{"_index":231,"t":{"38":{"position":[[360,4]]},"91":{"position":[[147,6],[156,6],[242,6],[1697,6],[1755,6]]},"97":{"position":[[120,6]]},"171":{"position":[[532,6],[541,6]]},"427":{"position":[[958,6]]},"437":{"position":[[1083,6]]},"439":{"position":[[140,6]]},"461":{"position":[[266,6],[592,6],[814,6]]},"463":{"position":[[331,6],[934,6],[2369,6]]},"465":{"position":[[316,6],[640,6],[977,6]]},"551":{"position":[[404,6]]},"563":{"position":[[292,6],[429,6],[472,6]]},"581":{"position":[[167,6]]},"583":{"position":[[204,6],[221,6]]},"585":{"position":[[514,6],[524,6],[541,6],[571,6],[591,6]]},"587":{"position":[[180,6],[202,6],[219,6]]},"627":{"position":[[620,6],[723,6],[1014,6]]},"631":{"position":[[254,6]]},"637":{"position":[[63,6],[115,6],[211,6],[226,6],[270,6],[385,6],[400,6]]},"644":{"position":[[176,6]]},"766":{"position":[[313,4],[464,4],[526,4]]},"775":{"position":[[497,6]]},"819":{"position":[[1613,6],[1696,6],[1839,6]]},"825":{"position":[[114,8]]},"855":{"position":[[102,4]]},"859":{"position":[[680,4]]},"861":{"position":[[67,4]]},"1077":{"position":[[236,5]]},"1092":{"position":[[476,6],[778,6],[1191,6],[1215,6],[1236,6],[1254,6],[1368,6],[1446,6]]},"1096":{"position":[[1231,6],[1815,6]]},"1137":{"position":[[1817,6],[1867,6],[1917,6]]},"1140":{"position":[[178,6],[563,6],[659,6],[996,6],[1055,6]]},"1142":{"position":[[310,6],[360,6],[410,6]]},"1146":{"position":[[246,6],[293,6],[405,6]]},"1172":{"position":[[449,6]]},"1222":{"position":[[147,6],[402,6]]}}}],["timestep",{"_index":2772,"t":{"901":{"position":[[816,8],[864,8]]}}}],["tine",{"_index":820,"t":{"190":{"position":[[72,6]]}}}],["tini",{"_index":1289,"t":{"416":{"position":[[552,4]]}}}],["tip",{"_index":37,"t":{"7":{"position":[[62,3]]},"1059":{"position":[[68,6],[78,3],[170,3]]},"1198":{"position":[[198,3],[671,3]]},"1200":{"position":[[442,3],[669,3],[1995,3]]},"1205":{"position":[[354,3]]},"1240":{"position":[[120,3],[311,3]]},"1242":{"position":[[118,3]]}}}],["tit_iti",{"_index":1538,"t":{"461":{"position":[[725,8],[980,8]]},"1154":{"position":[[473,8]]}}}],["titan",{"_index":2428,"t":{"784":{"position":[[377,5],[401,5]]}}}],["titl",{"_index":3094,"t":{"1030":{"position":[[96,6],[143,6],[282,6]]},"1051":{"position":[[93,6],[112,5]]}}}],["title=\"src/components/hellodocusaurus.j",{"_index":3176,"t":{"1057":{"position":[[68,41]]}}}],["ti∈rm×ct_i",{"_index":1535,"t":{"461":{"position":[[563,10]]}}}],["tka",{"_index":601,"t":{"130":{"position":[[432,4]]}}}],["tl",{"_index":1554,"t":{"463":{"position":[[483,2],[715,3]]}}}],["tlo=linearo(slgvl)∈r1×c\\begin{equ",{"_index":1602,"t":{"463":{"position":[[2275,39]]}}}],["tlt_ltl",{"_index":1577,"t":{"463":{"position":[[1004,8],[1312,8],[2046,8]]}}}],["tl∈r1×ct_l",{"_index":1549,"t":{"463":{"position":[[302,10]]}}}],["tnl",{"_index":3380,"t":{"1111":{"position":[[55,3]]}}}],["today",{"_index":2709,"t":{"876":{"position":[[1057,6]]}}}],["toek",{"_index":2819,"t":{"911":{"position":[[657,4]]}}}],["token",{"_index":398,"t":{"91":{"position":[[25,5],[748,5],[771,5]]},"124":{"position":[[410,5]]},"130":{"position":[[705,5],[1498,6],[1531,5],[1563,5]]},"132":{"position":[[446,5],[577,5],[632,5]]},"140":{"position":[[243,12],[289,13],[803,5]]},"143":{"position":[[580,6]]},"145":{"position":[[59,5]]},"169":{"position":[[293,5]]},"180":{"position":[[19,5]]},"190":{"position":[[223,5]]},"250":{"position":[[47,8]]},"286":{"position":[[95,5],[164,5]]},"304":{"position":[[567,5]]},"343":{"position":[[349,5]]},"345":{"position":[[409,5],[507,5],[592,5]]},"347":{"position":[[205,5],[341,5]]},"360":{"position":[[171,6],[385,9]]},"379":{"position":[[302,5]]},"396":{"position":[[184,5]]},"398":{"position":[[1061,5]]},"408":{"position":[[58,5]]},"425":{"position":[[778,6],[1322,5],[1498,5]]},"437":{"position":[[142,6],[260,5],[302,5],[400,5],[449,5],[881,9],[1108,5]]},"443":{"position":[[139,9]]},"455":{"position":[[324,5]]},"457":{"position":[[432,5],[1058,6]]},"461":{"position":[[628,6],[704,5]]},"463":{"position":[[51,5],[378,5],[406,6],[1034,6],[1459,6]]},"465":{"position":[[718,5]]},"471":{"position":[[151,5]]},"502":{"position":[[333,5]]},"508":{"position":[[209,5],[329,5]]},"523":{"position":[[319,6],[574,5]]},"553":{"position":[[301,5]]},"581":{"position":[[6,5],[24,5]]},"595":{"position":[[102,5]]},"627":{"position":[[515,5]]},"686":{"position":[[54,5],[374,5],[458,6],[549,5],[959,5],[1456,6]]},"688":{"position":[[1174,6],[1314,5],[1329,5],[1373,6]]},"694":{"position":[[37,5],[709,5],[969,6],[1025,5]]},"713":{"position":[[525,5]]},"716":{"position":[[123,5]]},"718":{"position":[[117,6]]},"725":{"position":[[135,5]]},"727":{"position":[[335,6]]},"736":{"position":[[130,5]]},"759":{"position":[[390,6],[419,7]]},"761":{"position":[[1293,6]]},"764":{"position":[[35,5]]},"766":{"position":[[816,6]]},"773":{"position":[[371,5],[711,5],[858,5]]},"798":{"position":[[9,6]]},"817":{"position":[[1586,6]]},"819":{"position":[[324,5],[484,6],[642,5],[825,5],[1106,6],[1155,6],[1210,6],[1444,6],[1524,5]]},"821":{"position":[[102,5],[534,5],[574,6],[729,5]]},"823":{"position":[[142,6],[897,7]]},"825":{"position":[[218,6],[269,5]]},"830":{"position":[[165,5],[217,5],[257,5]]},"832":{"position":[[242,5],[428,5],[466,5],[476,5],[533,5],[839,5],[886,5]]},"834":{"position":[[149,5]]},"836":{"position":[[1030,5],[1816,5]]},"842":{"position":[[142,5],[249,5],[372,5],[439,5],[1235,5],[1283,5],[1618,6]]},"883":{"position":[[705,5]]},"899":{"position":[[743,5],[775,5]]},"901":{"position":[[2104,5],[2192,5],[2406,5],[2421,5],[2437,5]]},"905":{"position":[[43,5],[84,5],[132,5]]},"909":{"position":[[180,5]]},"911":{"position":[[809,5],[926,5]]},"913":{"position":[[37,5],[106,5],[137,5],[169,5]]},"917":{"position":[[556,5]]},"919":{"position":[[691,5]]},"949":{"position":[[320,5],[649,5],[665,5]]},"955":{"position":[[454,5]]},"963":{"position":[[1749,5]]},"971":{"position":[[132,5]]},"975":{"position":[[498,5]]},"983":{"position":[[331,5]]},"1137":{"position":[[710,6]]},"1170":{"position":[[131,5]]}}}],["token/text",{"_index":2787,"t":{"905":{"position":[[239,10]]}}}],["tokens][hyp]?[prompt",{"_index":2232,"t":{"688":{"position":[[1271,20]]}}}],["tokens][mask",{"_index":2233,"t":{"688":{"position":[[1292,14]]}}}],["tokensequ",{"_index":598,"t":{"128":{"position":[[71,13]]}}}],["toothbrush",{"_index":3256,"t":{"1092":{"position":[[302,11]]}}}],["top",{"_index":740,"t":{"169":{"position":[[408,3]]},"302":{"position":[[972,3],[1187,3]]},"349":{"position":[[603,3]]},"447":{"position":[[360,3]]},"475":{"position":[[381,3]]},"604":{"position":[[265,3],[368,3],[751,3]]},"608":{"position":[[322,3],[553,3]]},"616":{"position":[[719,4]]},"646":{"position":[[164,3]]},"651":{"position":[[8,5]]},"782":{"position":[[92,3]]},"842":{"position":[[450,3]]},"911":{"position":[[918,3],[990,3]]},"981":{"position":[[72,3]]},"1051":{"position":[[40,3]]},"1137":{"position":[[2738,3]]},"1148":{"position":[[1751,3],[2011,3],[2182,3]]},"1192":{"position":[[107,3],[192,3]]},"1200":{"position":[[1272,3],[1829,3]]},"1211":{"position":[[315,3]]},"1216":{"position":[[774,3]]},"1232":{"position":[[254,3]]}}}],["top2",{"_index":2440,"t":{"787":{"position":[[130,5]]}}}],["topic",{"_index":2132,"t":{"672":{"position":[[73,5]]},"759":{"position":[[628,6]]},"793":{"position":[[39,5],[124,5],[177,5]]},"909":{"position":[[478,6]]}}}],["total",{"_index":1676,"t":{"504":{"position":[[1458,5]]},"533":{"position":[[547,5]]},"633":{"position":[[1966,5]]},"637":{"position":[[182,5],[355,5]]},"842":{"position":[[801,7],[863,7],[927,7]]},"1137":{"position":[[2958,5]]},"1154":{"position":[[100,5],[117,5]]},"1172":{"position":[[69,5],[306,5]]},"1174":{"position":[[21,5]]},"1181":{"position":[[56,5]]}}}],["totext",{"_index":2535,"t":{"823":{"position":[[633,6]]}}}],["toward",{"_index":3494,"t":{"1142":{"position":[[774,8]]}}}],["toxic",{"_index":2986,"t":{"987":{"position":[[23,5]]},"989":{"position":[[672,8],[738,8],[770,5]]},"1003":{"position":[[535,8]]},"1008":{"position":[[60,8]]},"1016":{"position":[[184,6],[337,5]]}}}],["toy",{"_index":925,"t":{"265":{"position":[[5,3]]},"269":{"position":[[361,4]]}}}],["tpu",{"_index":964,"t":{"281":{"position":[[747,3]]},"320":{"position":[[93,3]]},"324":{"position":[[184,3]]}}}],["tpuv3",{"_index":544,"t":{"110":{"position":[[110,5]]}}}],["tra",{"_index":2562,"t":{"834":{"position":[[168,6]]}}}],["track",{"_index":3243,"t":{"1085":{"position":[[750,8]]},"1087":{"position":[[196,8],[225,8],[591,8]]},"1099":{"position":[[1014,8]]},"1115":{"position":[[105,8]]}}}],["trackingnet",{"_index":3362,"t":{"1099":{"position":[[1248,11]]},"1111":{"position":[[41,11]]}}}],["trade",{"_index":1737,"t":{"549":{"position":[[318,5]]},"811":{"position":[[1183,5]]}}}],["tradit",{"_index":2185,"t":{"686":{"position":[[1127,11]]},"823":{"position":[[697,11]]},"844":{"position":[[123,11]]}}}],["train",{"_index":193,"t":{"27":{"position":[[158,8],[219,8],[495,8]]},"38":{"position":[[50,8],[346,8]]},"44":{"position":[[57,8]]},"76":{"position":[[0,8]]},"78":{"position":[[19,8],[282,5],[487,5],[667,8],[926,8]]},"91":{"position":[[963,8],[1062,8]]},"97":{"position":[[24,8],[192,8],[320,7],[366,7]]},"102":{"position":[[0,5]]},"106":{"position":[[0,5]]},"112":{"position":[[47,5],[141,5]]},"114":{"position":[[99,5],[138,5],[189,5],[223,5],[278,5],[314,5]]},"120":{"position":[[121,5],[243,8]]},"165":{"position":[[729,7]]},"171":{"position":[[20,7]]},"193":{"position":[[127,8]]},"213":{"position":[[23,8],[72,7]]},"219":{"position":[[14,5],[48,5]]},"229":{"position":[[565,8]]},"252":{"position":[[31,8]]},"254":{"position":[[156,10]]},"279":{"position":[[515,8]]},"281":{"position":[[1062,8],[1774,8],[2071,8]]},"320":{"position":[[26,8]]},"343":{"position":[[825,8]]},"349":{"position":[[742,8]]},"362":{"position":[[82,5]]},"379":{"position":[[203,8]]},"396":{"position":[[46,8],[641,8],[704,8]]},"398":{"position":[[860,9]]},"406":{"position":[[71,8]]},"408":{"position":[[4,7]]},"410":{"position":[[136,8]]},"416":{"position":[[40,7],[88,8],[148,8],[179,8]]},"418":{"position":[[4,7],[82,7],[162,7],[759,8],[829,8],[1347,7]]},"423":{"position":[[59,7],[210,8],[362,8],[386,8],[720,8]]},"425":{"position":[[1155,8],[1577,8],[2345,8]]},"427":{"position":[[130,8],[4109,8]]},"429":{"position":[[44,8],[347,8],[482,8]]},"431":{"position":[[131,8],[500,8]]},"435":{"position":[[8,8]]},"437":{"position":[[273,8],[479,8]]},"441":{"position":[[42,8],[136,8],[330,8]]},"445":{"position":[[93,8]]},"447":{"position":[[199,8]]},"449":{"position":[[141,8],[186,8]]},"455":{"position":[[441,7],[595,7]]},"457":{"position":[[272,8],[637,7],[1285,7]]},"461":{"position":[[63,7]]},"463":{"position":[[33,8],[2023,7],[2554,7]]},"465":{"position":[[185,7]]},"469":{"position":[[4,7]]},"475":{"position":[[258,7]]},"491":{"position":[[32,7]]},"494":{"position":[[54,7]]},"498":{"position":[[180,7]]},"502":{"position":[[472,8],[750,8]]},"504":{"position":[[1569,8],[1707,8],[2458,8],[2544,8]]},"510":{"position":[[51,7]]},"515":{"position":[[472,7]]},"519":{"position":[[207,8]]},"521":{"position":[[6,8]]},"523":{"position":[[670,8]]},"525":{"position":[[495,7]]},"531":{"position":[[230,8]]},"535":{"position":[[155,8]]},"537":{"position":[[348,8]]},"543":{"position":[[88,8],[157,7]]},"547":{"position":[[83,7]]},"549":{"position":[[193,7],[552,7],[804,7]]},"551":{"position":[[222,7]]},"553":{"position":[[7,8],[79,7],[338,7],[821,7]]},"563":{"position":[[128,7],[241,7],[538,8],[931,8]]},"589":{"position":[[64,7],[213,7]]},"591":{"position":[[19,8]]},"598":{"position":[[60,7]]},"604":{"position":[[57,7]]},"614":{"position":[[20,7]]},"616":{"position":[[613,7]]},"619":{"position":[[404,8]]},"627":{"position":[[11,7],[88,8],[1190,8]]},"629":{"position":[[32,8]]},"633":{"position":[[1947,8]]},"635":{"position":[[50,8],[143,8],[223,8]]},"637":{"position":[[249,8]]},"648":{"position":[[7,8],[425,8]]},"653":{"position":[[4,8]]},"655":{"position":[[96,7]]},"657":{"position":[[26,7]]},"662":{"position":[[36,8],[429,8]]},"670":{"position":[[74,8]]},"680":{"position":[[12,8],[85,8],[114,7],[1037,7],[1531,7],[1671,7],[1817,8]]},"682":{"position":[[401,8]]},"684":{"position":[[73,7]]},"686":{"position":[[4,7],[157,7],[423,8]]},"688":{"position":[[21,8],[126,8],[1031,8],[1074,8]]},"692":{"position":[[47,8],[233,7],[276,8]]},"694":{"position":[[300,8],[434,8],[453,8],[1043,8]]},"696":{"position":[[305,8],[1036,7]]},"698":{"position":[[871,8],[1134,7],[1453,7],[1526,8]]},"702":{"position":[[383,7]]},"707":{"position":[[67,7],[353,8]]},"711":{"position":[[80,8],[202,7]]},"713":{"position":[[4,7],[206,8],[327,7],[504,7],[586,8],[834,8],[1262,7],[1686,8]]},"718":{"position":[[460,7]]},"738":{"position":[[30,7]]},"744":{"position":[[58,8]]},"759":{"position":[[29,7],[610,8]]},"761":{"position":[[29,7],[336,7],[440,7]]},"770":{"position":[[20,7]]},"773":{"position":[[615,7]]},"775":{"position":[[902,8]]},"777":{"position":[[453,8]]},"784":{"position":[[126,8]]},"791":{"position":[[56,8]]},"793":{"position":[[103,8],[195,8]]},"796":{"position":[[163,8],[206,8]]},"802":{"position":[[422,7]]},"811":{"position":[[154,8],[359,7],[497,7],[747,7]]},"817":{"position":[[67,7],[574,7],[1065,8],[1515,7],[1632,8],[1763,7]]},"821":{"position":[[81,8]]},"823":{"position":[[94,8],[349,8],[676,8],[833,8],[1005,8],[1240,7],[1401,8],[1469,8],[1826,8]]},"825":{"position":[[19,7]]},"832":{"position":[[279,8]]},"834":{"position":[[20,8],[546,8],[582,8],[1057,8]]},"836":{"position":[[1550,7],[2151,7]]},"838":{"position":[[1163,8]]},"840":{"position":[[210,7]]},"844":{"position":[[27,7],[472,7]]},"874":{"position":[[364,7]]},"876":{"position":[[377,5],[445,6],[538,8],[621,7],[672,7],[768,5],[797,6],[835,6],[1135,8]]},"889":{"position":[[53,7],[463,8]]},"893":{"position":[[198,8]]},"899":{"position":[[46,8],[608,8],[791,8]]},"901":{"position":[[658,7],[968,7],[1763,8],[2322,8]]},"905":{"position":[[55,7]]},"929":{"position":[[57,7]]},"933":{"position":[[39,7]]},"985":{"position":[[91,8]]},"1001":{"position":[[1853,7]]},"1099":{"position":[[472,8],[983,8]]},"1135":{"position":[[10,7],[101,7],[219,7],[297,7],[848,7]]},"1137":{"position":[[840,7],[921,7],[1406,8],[2152,8],[2429,7],[4217,8]]},"1142":{"position":[[36,7],[527,8]]},"1146":{"position":[[4,7],[804,8]]},"1148":{"position":[[149,8],[739,8],[848,8]]},"1150":{"position":[[170,8]]},"1152":{"position":[[30,8],[1454,8]]},"1154":{"position":[[221,8],[500,8]]},"1160":{"position":[[96,7],[217,7]]},"1172":{"position":[[79,7]]},"1174":{"position":[[31,7]]},"1181":{"position":[[66,7]]},"1200":{"position":[[1073,8],[1196,8],[1239,8]]},"1203":{"position":[[229,8]]},"1207":{"position":[[5,8],[169,8],[454,8],[517,8]]},"1209":{"position":[[172,8]]},"1216":{"position":[[101,8],[498,8]]},"1222":{"position":[[1171,8]]}}}],["trainabl",{"_index":851,"t":{"215":{"position":[[27,9]]},"349":{"position":[[686,9]]},"547":{"position":[[134,9],[189,9],[268,9]]},"549":{"position":[[1155,9]]},"563":{"position":[[603,9]]},"581":{"position":[[106,9]]},"583":{"position":[[148,9]]},"585":{"position":[[734,9]]},"587":{"position":[[51,9],[124,9]]},"619":{"position":[[17,9]]},"637":{"position":[[466,9]]},"678":{"position":[[101,9]]},"686":{"position":[[1693,9]]},"713":{"position":[[1631,9]]},"718":{"position":[[515,9],[547,9]]},"730":{"position":[[11,9]]},"770":{"position":[[74,9]]},"775":{"position":[[940,9],[1030,9],[1072,9]]},"777":{"position":[[302,9]]},"796":{"position":[[21,9]]},"800":{"position":[[13,9],[52,9],[138,9]]},"811":{"position":[[587,9],[1081,9]]},"817":{"position":[[1399,9]]},"1137":{"position":[[693,9],[2115,9],[2553,9],[2826,9],[2964,9],[4635,9]]},"1152":{"position":[[1173,9]]},"1160":{"position":[[525,9],[743,9]]},"1165":{"position":[[83,9]]},"1172":{"position":[[46,9]]},"1181":{"position":[[33,9]]}}}],["trainer",{"_index":3060,"t":{"1020":{"position":[[103,7]]}}}],["trainig",{"_index":1714,"t":{"525":{"position":[[627,7]]}}}],["trajectori",{"_index":2654,"t":{"857":{"position":[[91,10]]},"859":{"position":[[207,10]]},"861":{"position":[[184,10]]},"863":{"position":[[35,10]]}}}],["tranasf",{"_index":3732,"t":{"1198":{"position":[[63,9]]}}}],["transfer",{"_index":383,"t":{"86":{"position":[[490,8]]},"102":{"position":[[116,8],[133,8],[262,8]]},"104":{"position":[[337,8]]},"112":{"position":[[451,8],[513,8]]},"330":{"position":[[81,8],[861,8]]},"557":{"position":[[53,8],[189,8]]},"614":{"position":[[382,12]]},"616":{"position":[[341,8],[535,12],[820,8],[1144,8],[1276,8],[1368,8]]},"619":{"position":[[475,15],[522,15]]},"621":{"position":[[136,8],[349,8]]},"623":{"position":[[71,8],[218,8],[260,8]]},"625":{"position":[[721,8]]},"627":{"position":[[1273,11],[1348,8]]},"633":{"position":[[566,8],[1882,8]]},"635":{"position":[[16,8]]},"646":{"position":[[231,8]]},"655":{"position":[[153,8],[280,8]]},"662":{"position":[[53,8]]},"668":{"position":[[40,8]]},"674":{"position":[[144,12],[305,8],[399,8]]},"682":{"position":[[38,15]]},"815":{"position":[[590,8]]},"823":{"position":[[595,8]]},"838":{"position":[[303,8],[768,8],[898,8]]},"844":{"position":[[204,8]]},"1142":{"position":[[821,8]]},"1198":{"position":[[395,8]]},"1200":{"position":[[165,8],[383,8],[1847,8]]},"1209":{"position":[[11,8]]},"1216":{"position":[[272,8]]},"1220":{"position":[[12,8]]},"1222":{"position":[[11,8]]},"1226":{"position":[[10,8]]},"1242":{"position":[[77,8]]}}}],["transfor",{"_index":627,"t":{"132":{"position":[[222,10]]}}}],["transform",{"_index":170,"t":{"25":{"position":[[202,11]]},"84":{"position":[[12,11],[82,11],[132,11]]},"86":{"position":[[190,11],[278,11],[351,11]]},"88":{"position":[[0,11],[157,12],[635,11]]},"91":{"position":[[3,11],[400,11],[437,11],[882,11],[1319,11],[2108,11]]},"93":{"position":[[118,11]]},"95":{"position":[[253,11]]},"114":{"position":[[2,12]]},"116":{"position":[[167,11],[247,11]]},"120":{"position":[[83,11]]},"126":{"position":[[63,11]]},"132":{"position":[[268,11]]},"143":{"position":[[262,11],[292,11]]},"153":{"position":[[70,11],[490,11],[622,11]]},"169":{"position":[[28,11]]},"171":{"position":[[85,11],[566,12]]},"174":{"position":[[446,11]]},"178":{"position":[[70,11]]},"209":{"position":[[133,11]]},"302":{"position":[[799,11]]},"343":{"position":[[371,11]]},"423":{"position":[[237,11]]},"427":{"position":[[1132,11],[1894,11],[1998,11]]},"437":{"position":[[106,11],[206,11]]},"455":{"position":[[299,11]]},"457":{"position":[[363,11]]},"461":{"position":[[40,11],[206,11],[329,11],[370,11],[899,11]]},"463":{"position":[[123,11],[2488,11]]},"465":{"position":[[768,11]]},"469":{"position":[[27,11]]},"475":{"position":[[231,11]]},"487":{"position":[[0,11]]},"504":{"position":[[1474,11]]},"508":{"position":[[152,11]]},"510":{"position":[[227,11]]},"515":{"position":[[371,11]]},"523":{"position":[[353,11],[515,11]]},"531":{"position":[[3,11]]},"547":{"position":[[114,11]]},"551":{"position":[[0,11],[43,11],[339,11]]},"557":{"position":[[83,11],[426,11]]},"561":{"position":[[6,11]]},"569":{"position":[[0,11]]},"571":{"position":[[34,11]]},"583":{"position":[[55,11],[272,11]]},"589":{"position":[[45,12]]},"598":{"position":[[68,11]]},"694":{"position":[[781,11]]},"738":{"position":[[272,11]]},"753":{"position":[[241,11]]},"761":{"position":[[819,11]]},"773":{"position":[[794,11]]},"784":{"position":[[108,12]]},"798":{"position":[[131,11]]},"809":{"position":[[268,11]]},"811":{"position":[[385,11]]},"819":{"position":[[361,11]]},"823":{"position":[[640,12],[1800,14]]},"836":{"position":[[276,11],[591,11],[1825,11],[2022,11]]},"1087":{"position":[[2146,11]]},"1096":{"position":[[199,11],[571,11]]},"1104":{"position":[[158,11]]},"1140":{"position":[[5,11],[806,15]]},"1148":{"position":[[29,11]]},"1158":{"position":[[59,12]]},"1160":{"position":[[278,11]]},"1203":{"position":[[400,11],[436,12]]}}}],["transformation/token",{"_index":600,"t":{"130":{"position":[[357,27]]}}}],["translat",{"_index":1953,"t":{"623":{"position":[[98,12]]},"883":{"position":[[474,11]]},"895":{"position":[[196,11]]},"911":{"position":[[437,11]]},"1071":{"position":[[6,9]]},"1075":{"position":[[181,9]]},"1077":{"position":[[162,11]]}}}],["transprompt",{"_index":1947,"t":{"619":{"position":[[498,13]]}}}],["traslat",{"_index":3754,"t":{"1207":{"position":[[292,10]]}}}],["trasnform",{"_index":2574,"t":{"836":{"position":[[1952,11]]}}}],["tre",{"_index":2248,"t":{"694":{"position":[[418,3]]}}}],["tree",{"_index":2954,"t":{"969":{"position":[[361,5]]}}}],["tresnet",{"_index":189,"t":{"27":{"position":[[85,8]]}}}],["trex",{"_index":2174,"t":{"686":{"position":[[699,4]]},"694":{"position":[[135,4]]}}}],["tri",{"_index":85,"t":{"13":{"position":[[39,3]]}}}],["trial",{"_index":2613,"t":{"848":{"position":[[352,5]]},"850":{"position":[[638,6]]},"859":{"position":[[37,6],[653,5],[752,6]]},"861":{"position":[[342,5]]},"863":{"position":[[6,5],[153,5],[232,5],[420,5],[634,5]]}}}],["triangl",{"_index":1766,"t":{"553":{"position":[[429,9],[710,11],[763,14],[946,17],[971,9],[1092,11],[1270,9]]},"563":{"position":[[358,9],[805,9]]},"1137":{"position":[[993,11],[1042,11],[1113,11],[1417,11],[1453,11],[1581,11],[1702,9],[2389,11],[3966,11],[4122,11]]},"1142":{"position":[[187,9]]},"1146":{"position":[[147,9],[315,11],[790,11],[1174,11]]}}}],["triangledown_{\\lambda_k",{"_index":3574,"t":{"1148":{"position":[[1418,25]]}}}],["triangledown_{w_{ij",{"_index":3628,"t":{"1152":{"position":[[1065,22]]}}}],["trick",{"_index":2460,"t":{"802":{"position":[[351,5]]},"804":{"position":[[372,5]]}}}],["trillion",{"_index":2154,"t":{"682":{"position":[[95,8]]}}}],["tripl",{"_index":2237,"t":{"692":{"position":[[115,6],[148,6]]},"694":{"position":[[93,7],[266,7]]},"963":{"position":[[1899,7]]}}}],["triplet",{"_index":3513,"t":{"1146":{"position":[[596,7]]},"1148":{"position":[[508,7],[2328,8]]},"1150":{"position":[[3,7]]},"1152":{"position":[[214,8],[300,8],[351,8]]},"1158":{"position":[[510,8]]},"1188":{"position":[[38,7]]}}}],["trnasfer",{"_index":3751,"t":{"1205":{"position":[[501,8]]}}}],["trnasform",{"_index":386,"t":{"86":{"position":[[779,11]]}}}],["true",{"_index":2317,"t":{"751":{"position":[[285,6],[318,7]]},"885":{"position":[[343,4]]},"979":{"position":[[164,4]]}}}],["truncat",{"_index":25,"t":{"5":{"position":[[57,8]]},"1137":{"position":[[3761,8]]},"1146":{"position":[[1924,10]]}}}],["truth",{"_index":685,"t":{"149":{"position":[[86,5]]},"281":{"position":[[203,5]]},"977":{"position":[[133,5]]},"989":{"position":[[632,12]]}}}],["truthfulqa",{"_index":3046,"t":{"1003":{"position":[[419,10]]}}}],["tt={t1​,t2​,…,tt",{"_index":1966,"t":{"625":{"position":[[240,20]]},"635":{"position":[[1004,20]]}}}],["tt\\mathcal{t}_ttt",{"_index":2075,"t":{"635":{"position":[[558,18]]}}}],["ttt",{"_index":786,"t":{"180":{"position":[[299,3]]},"427":{"position":[[997,3]]},"633":{"position":[[1191,3]]},"686":{"position":[[661,3],[933,3],[1217,3]]},"855":{"position":[[107,3]]},"859":{"position":[[685,3]]},"863":{"position":[[159,3],[426,3],[640,3]]},"1148":{"position":[[1118,3],[2377,3]]}}}],["tuin",{"_index":3054,"t":{"1013":{"position":[[409,7]]}}}],["tunabl",{"_index":1679,"t":{"504":{"position":[[1874,7]]},"616":{"position":[[271,7],[1525,7]]},"637":{"position":[[161,7],[335,7]]},"727":{"position":[[153,7],[367,7]]},"817":{"position":[[1578,7]]},"901":{"position":[[2000,7],[2373,7]]}}}],["tune",{"_index":208,"t":{"31":{"position":[[207,6]]},"63":{"position":[[73,6]]},"91":{"position":[[979,6],[1099,6]]},"93":{"position":[[191,6]]},"97":{"position":[[59,6],[217,4],[308,4]]},"106":{"position":[[136,4]]},"108":{"position":[[166,6]]},"112":{"position":[[349,6]]},"163":{"position":[[363,6]]},"188":{"position":[[92,6]]},"193":{"position":[[44,6]]},"195":{"position":[[55,6]]},"197":{"position":[[263,6]]},"213":{"position":[[39,6],[222,6]]},"273":{"position":[[276,7]]},"328":{"position":[[682,6],[789,6]]},"330":{"position":[[1545,6],[1642,6]]},"349":{"position":[[566,6]]},"368":{"position":[[584,6]]},"392":{"position":[[363,6]]},"396":{"position":[[230,6]]},"416":{"position":[[251,6],[295,7],[641,6]]},"418":{"position":[[245,6],[260,6],[361,6],[992,6],[1329,6],[1406,6],[1475,6],[1612,6],[1938,6],[2196,6]]},"421":{"position":[[341,6]]},"423":{"position":[[32,6],[292,6],[651,6]]},"425":{"position":[[35,6],[2399,6]]},"427":{"position":[[443,6],[459,6],[3054,6],[3355,6],[3552,6],[3684,6],[3786,6],[3963,6],[3989,6],[4008,6]]},"429":{"position":[[10,6],[92,6],[467,6],[498,6]]},"431":{"position":[[694,6]]},"441":{"position":[[443,6]]},"447":{"position":[[276,6]]},"451":{"position":[[220,6]]},"455":{"position":[[65,6],[235,6],[630,6]]},"457":{"position":[[124,6],[256,6],[767,6],[1264,6],[1304,6]]},"461":{"position":[[118,6],[497,6]]},"463":{"position":[[78,6]]},"465":{"position":[[1172,6]]},"469":{"position":[[204,6]]},"471":{"position":[[65,6],[121,6],[132,6]]},"475":{"position":[[132,6]]},"479":{"position":[[173,6]]},"491":{"position":[[11,6]]},"494":{"position":[[78,6]]},"496":{"position":[[107,6]]},"504":{"position":[[164,6],[280,6],[704,6],[1759,6],[2245,6],[2343,6]]},"508":{"position":[[57,6]]},"512":{"position":[[93,6]]},"515":{"position":[[212,6],[260,6],[802,6]]},"517":{"position":[[5,6],[59,6],[94,6],[246,6],[328,6]]},"523":{"position":[[23,6],[616,6]]},"525":{"position":[[132,6]]},"533":{"position":[[5,6],[200,6]]},"537":{"position":[[115,6]]},"543":{"position":[[46,6],[591,6]]},"547":{"position":[[24,6],[233,6]]},"549":{"position":[[82,6],[1214,5],[1288,6]]},"553":{"position":[[324,6],[655,6],[845,5]]},"559":{"position":[[19,6]]},"563":{"position":[[1053,6]]},"565":{"position":[[112,6]]},"583":{"position":[[17,6]]},"593":{"position":[[24,6]]},"595":{"position":[[126,6],[159,6]]},"610":{"position":[[11,6],[204,6]]},"614":{"position":[[7,6],[296,6],[604,6]]},"616":{"position":[[257,6],[762,6],[1072,6]]},"619":{"position":[[134,6],[234,6],[269,6],[395,6],[548,6],[614,6]]},"627":{"position":[[381,6]]},"633":{"position":[[224,6]]},"635":{"position":[[125,6]]},"644":{"position":[[7,6]]},"646":{"position":[[104,6],[126,6]]},"674":{"position":[[17,6],[325,6],[461,6]]},"678":{"position":[[10,6],[148,6],[358,6],[427,6]]},"680":{"position":[[424,6],[915,6],[1153,6],[1189,6],[1327,6],[1396,6],[1432,6],[1518,6],[1578,6],[1614,6],[1696,6],[1721,6]]},"682":{"position":[[86,6],[147,6],[167,6],[250,6]]},"684":{"position":[[25,6]]},"686":{"position":[[1416,6]]},"688":{"position":[[435,6]]},"690":{"position":[[62,6]]},"694":{"position":[[840,6]]},"696":{"position":[[23,6],[187,6],[272,6],[289,7],[381,6],[395,6],[474,6],[502,6],[599,6],[676,6],[721,6],[849,6],[863,6],[900,6],[1023,6],[1122,6],[1194,6],[1249,6],[1344,6]]},"698":{"position":[[2,6],[92,6],[378,6],[1067,6],[1483,6],[1680,6],[1981,7]]},"700":{"position":[[46,6],[163,6],[254,6],[346,6],[545,6]]},"702":{"position":[[214,6],[565,6],[665,6],[742,6],[819,6],[926,6],[991,6],[1096,6],[1168,6]]},"704":{"position":[[32,6],[59,6],[152,6],[249,6],[273,6],[356,6],[392,6],[406,5],[432,6],[473,6],[498,6]]},"707":{"position":[[9,6]]},"711":{"position":[[7,6],[180,6],[244,6],[335,6],[406,6],[425,5],[459,6],[511,6],[526,7],[555,6],[588,6]]},"713":{"position":[[74,6],[669,6],[706,6],[739,6],[1074,6],[1188,6],[1203,7],[1319,6],[1388,6],[1442,6],[1602,6],[1672,6]]},"718":{"position":[[421,7],[439,7],[786,6]]},"721":{"position":[[8,7],[26,7]]},"723":{"position":[[8,7]]},"725":{"position":[[8,7],[26,7],[244,7],[262,7],[388,6],[403,6]]},"727":{"position":[[8,7],[26,7],[253,6],[277,6],[350,6]]},"732":{"position":[[18,6]]},"734":{"position":[[107,6]]},"736":{"position":[[108,6],[190,6]]},"738":{"position":[[2,6],[145,7],[176,7],[186,6]]},"740":{"position":[[2,6]]},"746":{"position":[[12,6],[66,7],[84,7],[134,6],[238,7],[256,7],[305,7],[359,6]]},"748":{"position":[[17,6],[105,7],[123,7],[152,7],[170,7],[280,6],[351,6]]},"751":{"position":[[91,6],[148,6]]},"753":{"position":[[8,7],[28,6]]},"755":{"position":[[2,6],[148,6]]},"759":{"position":[[5,6],[238,6],[257,6],[451,6],[552,6]]},"761":{"position":[[5,6],[321,6],[400,6],[427,6],[512,6],[971,6],[1125,6],[1424,5]]},"773":{"position":[[944,6]]},"775":{"position":[[7,6]]},"782":{"position":[[40,6],[74,6],[110,6],[135,6]]},"784":{"position":[[422,6],[476,6],[583,6],[597,6],[664,6],[698,6]]},"787":{"position":[[51,6],[204,6],[221,6],[273,6],[332,6],[356,6],[384,6],[430,6],[447,6],[548,6],[608,6]]},"789":{"position":[[30,6],[81,6],[146,6]]},"791":{"position":[[47,6],[293,6],[393,6],[407,6],[494,6],[508,6],[542,6],[594,6]]},"793":{"position":[[499,6],[585,6],[601,6]]},"798":{"position":[[437,6]]},"800":{"position":[[241,6],[277,6],[293,6],[333,6],[386,6]]},"802":{"position":[[486,6]]},"804":{"position":[[57,6],[74,6],[187,6],[201,6],[277,6],[296,6]]},"807":{"position":[[18,6],[180,6]]},"809":{"position":[[33,6],[144,6],[252,6]]},"811":{"position":[[5,6],[59,6],[76,6],[209,6],[226,6],[325,6],[342,6],[446,7],[461,6],[565,6],[660,6],[677,6],[734,6],[784,6],[856,6],[1068,6],[1221,6]]},"815":{"position":[[13,6],[223,6],[362,6],[506,6]]},"817":{"position":[[32,6],[183,6],[196,7],[242,6],[282,6],[342,6],[474,6],[869,5],[934,5],[1169,6],[1199,7],[1278,6],[1487,6],[1709,6],[1877,7],[1933,6],[1951,6],[2468,6],[2496,6],[2593,6],[2635,6]]},"819":{"position":[[911,6],[1138,6]]},"821":{"position":[[789,6]]},"823":{"position":[[756,6],[1080,6],[1632,6]]},"825":{"position":[[248,6],[304,6]]},"827":{"position":[[15,6],[126,6],[170,6],[183,6],[250,6],[287,6],[363,6],[378,6],[423,6],[502,6],[596,6],[643,5],[689,5]]},"834":{"position":[[45,6],[945,6]]},"836":{"position":[[163,6],[263,6],[402,6],[615,6],[736,6],[793,6],[830,6],[1162,6],[1227,6],[1246,6],[1268,6],[1392,6],[1407,6],[2289,6],[2524,6]]},"838":{"position":[[21,6],[193,6],[485,6],[525,6],[673,6],[1057,6],[1154,6]]},"840":{"position":[[197,6]]},"842":{"position":[[124,6],[1277,5]]},"844":{"position":[[7,6],[141,6],[223,6]]},"848":{"position":[[106,6]]},"876":{"position":[[392,4],[497,4],[554,6],[732,6],[783,5]]},"901":{"position":[[298,6],[312,6],[1140,6],[1417,6],[1933,6],[2028,6],[2215,6]]},"929":{"position":[[137,6],[166,6],[238,6]]},"931":{"position":[[16,6],[370,6]]},"933":{"position":[[0,6],[151,6],[209,6]]},"935":{"position":[[16,6],[161,6],[177,6],[202,6],[270,6]]},"937":{"position":[[16,6],[58,6]]},"939":{"position":[[10,6],[100,6]]},"947":{"position":[[359,6]]},"949":{"position":[[141,6]]},"955":{"position":[[353,6],[425,6],[529,6]]},"961":{"position":[[67,6]]},"963":{"position":[[606,6],[2205,6],[2266,6]]},"977":{"position":[[75,6]]},"979":{"position":[[64,5]]},"987":{"position":[[195,4],[269,4]]},"989":{"position":[[209,4],[274,4],[402,4],[886,6],[1119,6]]},"993":{"position":[[121,6],[306,6]]},"995":{"position":[[407,6],[529,6]]},"1001":{"position":[[152,6],[213,6],[1246,6],[2161,6]]},"1008":{"position":[[107,6]]},"1010":{"position":[[24,6]]},"1135":{"position":[[67,6],[138,6],[192,6],[408,6]]},"1137":{"position":[[5,5],[226,6],[307,6],[432,6],[553,6],[620,6],[636,6],[737,6],[1520,6],[1982,6],[2182,6],[2222,6],[2451,6],[2610,6],[2680,6],[3126,8],[3323,6],[3859,6],[4617,6]]},"1142":{"position":[[929,7],[944,6],[978,6]]},"1154":{"position":[[200,6],[664,6]]},"1156":{"position":[[50,6]]},"1158":{"position":[[316,6]]},"1160":{"position":[[31,6],[78,6],[206,6],[254,6],[269,6],[643,6],[736,6]]},"1163":{"position":[[37,6]]},"1170":{"position":[[76,6]]},"1174":{"position":[[100,6]]},"1177":{"position":[[61,6]]},"1181":{"position":[[20,6]]},"1184":{"position":[[52,6]]},"1190":{"position":[[171,6],[390,6],[428,6]]},"1192":{"position":[[24,6]]},"1194":{"position":[[29,6]]}}}],["tupl",{"_index":649,"t":{"140":{"position":[[396,5]]}}}],["turbin",{"_index":1024,"t":{"302":{"position":[[284,7]]}}}],["turn",{"_index":1715,"t":{"529":{"position":[[30,4]]},"543":{"position":[[337,4]]}}}],["tutori",{"_index":3072,"t":{"1024":{"position":[[220,9]]},"1036":{"position":[[401,11],[420,10]]}}}],["tutorialsidebar",{"_index":3126,"t":{"1036":{"position":[[337,16]]}}}],["two",{"_index":910,"t":{"248":{"position":[[193,3]]},"680":{"position":[[372,3]]},"688":{"position":[[588,3]]},"959":{"position":[[933,3]]},"1140":{"position":[[61,3],[795,3]]},"1142":{"position":[[7,3]]},"1160":{"position":[[301,3],[664,3]]},"1170":{"position":[[10,3]]},"1174":{"position":[[153,3]]},"1188":{"position":[[274,3]]},"1190":{"position":[[8,3]]}}}],["tydiqa",{"_index":1203,"t":{"368":{"position":[[390,6]]},"382":{"position":[[205,6]]},"384":{"position":[[102,6]]},"390":{"position":[[398,6]]}}}],["type",{"_index":109,"t":{"17":{"position":[[205,4]]},"78":{"position":[[716,5]]},"744":{"position":[[24,4]]},"761":{"position":[[1038,5]]},"848":{"position":[[721,4]]},"1036":{"position":[[376,5]]},"1067":{"position":[[178,5]]},"1079":{"position":[[178,5]]}}}],["typolog",{"_index":1233,"t":{"382":{"position":[[232,13]]}}}],["u",{"_index":1196,"t":{"366":{"position":[[217,1]]},"379":{"position":[[10,1]]},"396":{"position":[[296,1],[656,1]]},"406":{"position":[[290,1]]}}}],["u,vu",{"_index":1922,"t":{"608":{"position":[[303,5]]}}}],["u/vu/vu/v",{"_index":1917,"t":{"608":{"position":[[140,9]]}}}],["u^{i\\top}_{a_{r=8",{"_index":1901,"t":{"604":{"position":[[574,19]]}}}],["u^{j}_{a_{r=64",{"_index":1902,"t":{"604":{"position":[[594,16]]}}}],["u_k",{"_index":2006,"t":{"631":{"position":[[466,3],[671,4]]},"633":{"position":[[374,4]]}}}],["u_t",{"_index":2077,"t":{"635":{"position":[[725,4]]}}}],["u_{j=1}{a^}j=1u",{"_index":996,"t":{"296":{"position":[[36,19]]}}}],["u_{j=1}{q^​j​,a^j​}j=1u",{"_index":1016,"t":{"300":{"position":[[725,27]]}}}],["uar=64u_{a_{r=64}}uar=64",{"_index":1889,"t":{"604":{"position":[[176,26],[308,26]]}}}],["uar=8i⊤u^{i\\top}_{a_{r=8}}uar=8​i",{"_index":1906,"t":{"604":{"position":[[713,35]]}}}],["uar=8u_{a_{r=8}}uar=8",{"_index":1888,"t":{"604":{"position":[[150,23],[211,23],[783,23]]}}}],["ucf101",{"_index":3828,"t":{"1238":{"position":[[131,6]]}}}],["uk",{"_index":2449,"t":{"793":{"position":[[416,3]]}}}],["uku_kuk",{"_index":2025,"t":{"633":{"position":[[631,8]]}}}],["uk∈rl,vk∈rdu_k",{"_index":2001,"t":{"631":{"position":[[304,14]]}}}],["ul2",{"_index":902,"t":{"242":{"position":[[95,3]]},"396":{"position":[[249,3],[623,3],[686,3]]}}}],["ul2r",{"_index":1277,"t":{"406":{"position":[[265,4]]}}}],["ultrici",{"_index":11,"t":{"3":{"position":[[90,10]]},"5":{"position":[[210,10],[389,10],[568,10],[747,10],[926,10],[1105,10],[1284,10],[1463,10],[1642,10],[1821,10],[2000,10],[2179,10],[2358,10],[2537,10],[2716,10],[2895,10]]}}}],["unansw",{"_index":2823,"t":{"917":{"position":[[29,10]]}}}],["unanswer",{"_index":2316,"t":{"748":{"position":[[228,12]]}}}],["unbalanc",{"_index":245,"t":{"47":{"position":[[112,10],[159,10]]}}}],["uncertainli",{"_index":3633,"t":{"1152":{"position":[[1556,11],[2304,11]]},"1188":{"position":[[77,11]]}}}],["unclear",{"_index":3070,"t":{"1024":{"position":[[195,7]]}}}],["unconfid",{"_index":3777,"t":{"1216":{"position":[[431,11]]}}}],["unconstrain",{"_index":2794,"t":{"909":{"position":[[86,13]]}}}],["underset{\\phi}{\\max",{"_index":2371,"t":{"770":{"position":[[227,22],[275,21]]}}}],["underset{\\phi}{\\max}\\sum_{y_i}\\log",{"_index":2764,"t":{"901":{"position":[[504,35]]}}}],["underset{c}{\\argmax",{"_index":3772,"t":{"1214":{"position":[[901,21]]}}}],["underset{h}{\\text{arg",{"_index":2207,"t":{"686":{"position":[[1998,23]]}}}],["underset{z",{"_index":2734,"t":{"885":{"position":[[511,11]]}}}],["understad",{"_index":1096,"t":{"330":{"position":[[350,12],[492,12]]}}}],["understand",{"_index":921,"t":{"257":{"position":[[94,13],[132,13]]},"330":{"position":[[240,13],[566,13]]},"333":{"position":[[5,13]]},"341":{"position":[[159,13]]},"343":{"position":[[163,13]]},"351":{"position":[[96,13]]},"357":{"position":[[10,13]]},"368":{"position":[[343,13]]},"418":{"position":[[695,14]]},"465":{"position":[[1195,13]]},"502":{"position":[[778,13]]},"519":{"position":[[74,13],[630,13]]},"521":{"position":[[215,13]]},"525":{"position":[[176,13]]},"535":{"position":[[279,13]]},"539":{"position":[[336,13]]},"541":{"position":[[7,13]]},"543":{"position":[[446,13]]},"573":{"position":[[61,13]]},"678":{"position":[[50,13]]},"680":{"position":[[293,13]]},"711":{"position":[[142,13]]},"836":{"position":[[2368,13]]},"844":{"position":[[277,13]]},"943":{"position":[[542,13],[572,13]]}}}],["undetstand",{"_index":2144,"t":{"680":{"position":[[467,13]]}}}],["unembed",{"_index":3009,"t":{"1001":{"position":[[483,11]]}}}],["unext",{"_index":3343,"t":{"1096":{"position":[[2689,5]]}}}],["unfil",{"_index":2694,"t":{"874":{"position":[[194,11]]}}}],["unfreez",{"_index":1687,"t":{"515":{"position":[[360,10]]}}}],["unfrozen",{"_index":1708,"t":{"519":{"position":[[532,8]]}}}],["unidirect",{"_index":2141,"t":{"680":{"position":[[162,14],[541,14]]},"694":{"position":[[728,14],[911,14]]},"696":{"position":[[355,14],[432,15],[1258,14]]},"698":{"position":[[1705,14]]},"700":{"position":[[669,14]]}}}],["unifi",{"_index":599,"t":{"130":{"position":[[337,7]]},"823":{"position":[[620,7]]},"1142":{"position":[[785,7]]}}}],["unifiedqav2",{"_index":991,"t":{"290":{"position":[[449,11]]}}}],["uniform",{"_index":217,"t":{"35":{"position":[[97,7]]},"842":{"position":[[1333,7]]},"917":{"position":[[274,7]]}}}],["unilm",{"_index":2143,"t":{"680":{"position":[[399,6]]}}}],["unimod",{"_index":1102,"t":{"333":{"position":[[111,8],[196,8]]},"335":{"position":[[20,8]]},"360":{"position":[[491,8]]}}}],["unimport",{"_index":3410,"t":{"1135":{"position":[[643,11]]},"1137":{"position":[[1201,11],[4316,11]]}}}],["uninext",{"_index":3239,"t":{"1085":{"position":[[66,7]]},"1087":{"position":[[1327,7],[2421,7],[2745,7]]},"1090":{"position":[[514,7]]},"1096":{"position":[[110,7]]},"1099":{"position":[[55,7],[535,7],[726,7],[1058,7]]},"1101":{"position":[[28,7]]},"1107":{"position":[[0,7]]},"1115":{"position":[[63,7]]},"1119":{"position":[[32,7]]},"1131":{"position":[[0,7],[81,7]]}}}],["unipelt",{"_index":1942,"t":{"619":{"position":[[241,7]]}}}],["uniqu",{"_index":2521,"t":{"823":{"position":[[126,6]]}}}],["unitari",{"_index":1887,"t":{"604":{"position":[[133,7]]}}}],["unitest",{"_index":2628,"t":{"850":{"position":[[1012,8]]}}}],["unitext",{"_index":3241,"t":{"1085":{"position":[[577,7]]}}}],["univers",{"_index":2471,"t":{"817":{"position":[[251,10]]},"1085":{"position":[[7,9]]},"1087":{"position":[[2605,9]]}}}],["unixcod",{"_index":1097,"t":{"330":{"position":[[624,9]]}}}],["unlab",{"_index":3752,"t":{"1207":{"position":[[62,9]]}}}],["unlabel",{"_index":1301,"t":{"418":{"position":[[665,9]]},"423":{"position":[[132,9]]},"429":{"position":[[126,9]]},"437":{"position":[[760,9]]},"698":{"position":[[580,9]]},"917":{"position":[[579,9],[1185,9]]},"1211":{"position":[[155,9],[488,9]]},"1216":{"position":[[55,9]]}}}],["unlikelihood",{"_index":1306,"t":{"418":{"position":[[1998,12]]},"431":{"position":[[268,12]]},"437":{"position":[[736,12]]},"449":{"position":[[173,12]]}}}],["unlock",{"_index":1678,"t":{"504":{"position":[[1858,9]]}}}],["unmask",{"_index":2172,"t":{"686":{"position":[[449,8]]}}}],["unmatch",{"_index":1131,"t":{"345":{"position":[[836,11]]}}}],["unnatur",{"_index":2538,"t":{"823":{"position":[[1043,11]]}}}],["unrealist",{"_index":1500,"t":{"447":{"position":[[225,15]]}}}],["unreleas",{"_index":3215,"t":{"1065":{"position":[[316,10]]}}}],["unseen",{"_index":1194,"t":{"366":{"position":[[40,6]]},"373":{"position":[[94,6]]},"375":{"position":[[45,6]]},"392":{"position":[[269,6]]},"394":{"position":[[122,6]]},"404":{"position":[[38,6]]},"416":{"position":[[119,6],[726,6]]},"418":{"position":[[1809,6]]},"423":{"position":[[1016,6]]},"759":{"position":[[621,6]]},"793":{"position":[[32,6],[255,6],[284,6]]},"811":{"position":[[166,6]]},"1113":{"position":[[241,6]]}}}],["unstructur",{"_index":3414,"t":{"1137":{"position":[[1283,12],[2290,12]]},"1152":{"position":[[181,12]]}}}],["unsupervis",{"_index":1298,"t":{"418":{"position":[[405,12]]},"876":{"position":[[1182,12]]},"1198":{"position":[[453,12],[496,12]]},"1200":{"position":[[1740,12]]},"1218":{"position":[[543,12]]},"1242":{"position":[[5,12]]}}}],["up",{"_index":173,"t":{"25":{"position":[[355,3]]},"35":{"position":[[35,2],[173,2]]},"42":{"position":[[40,2]]},"78":{"position":[[236,2],[660,2]]},"178":{"position":[[266,2]]},"328":{"position":[[596,2]]},"1016":{"position":[[205,2]]},"1154":{"position":[[497,2]]},"1236":{"position":[[78,2]]}}}],["upcom",{"_index":3214,"t":{"1065":{"position":[[306,9]]}}}],["updat",{"_index":1283,"t":{"416":{"position":[[310,7]]},"418":{"position":[[1273,7],[1391,6],[1454,6]]},"427":{"position":[[3160,6],[3835,6]]},"441":{"position":[[8,8]]},"515":{"position":[[147,6]]},"531":{"position":[[241,6]]},"533":{"position":[[181,8]]},"551":{"position":[[296,6]]},"563":{"position":[[578,6]]},"602":{"position":[[100,6]]},"614":{"position":[[492,7]]},"616":{"position":[[1207,7]]},"619":{"position":[[114,6]]},"629":{"position":[[371,6]]},"702":{"position":[[617,7]]},"713":{"position":[[126,6],[866,7]]},"761":{"position":[[141,6],[1404,6]]},"770":{"position":[[146,6]]},"777":{"position":[[22,6]]},"787":{"position":[[33,6],[162,6]]},"811":{"position":[[963,6],[1020,6]]},"819":{"position":[[1023,6],[1232,6],[1422,6],[1971,6]]},"836":{"position":[[576,6]]},"1069":{"position":[[102,7],[157,7]]},"1135":{"position":[[249,6],[338,7],[601,7],[655,6]]},"1137":{"position":[[869,6],[986,6],[1168,7]]},"1142":{"position":[[66,6]]},"1146":{"position":[[42,6]]},"1148":{"position":[[1245,6]]},"1160":{"position":[[159,7],[697,7]]},"1194":{"position":[[147,6]]}}}],["upl",{"_index":3735,"t":{"1198":{"position":[[482,5],[564,3],[643,3]]},"1200":{"position":[[840,3],[947,3],[1722,3]]},"1205":{"position":[[489,3]]},"1207":{"position":[[398,3],[563,3]]},"1209":{"position":[[0,3],[118,3]]},"1211":{"position":[[26,3]]},"1220":{"position":[[295,3]]},"1230":{"position":[[30,3],[273,4],[334,4],[345,3]]},"1240":{"position":[[133,3]]},"1242":{"position":[[34,3]]}}}],["upward",{"_index":940,"t":{"271":{"position":[[326,6]]},"773":{"position":[[837,6]]}}}],["upwork",{"_index":3007,"t":{"999":{"position":[[0,6]]}}}],["url",{"_index":3098,"t":{"1030":{"position":[[177,4],[311,4]]},"1051":{"position":[[172,3]]},"1053":{"position":[[44,3]]}}}],["us",{"_index":23,"t":{"5":{"position":[[46,3]]},"7":{"position":[[66,3]]},"9":{"position":[[446,3]]},"17":{"position":[[31,5]]},"78":{"position":[[706,3]]},"302":{"position":[[247,4]]},"1053":{"position":[[38,5]]},"1055":{"position":[[47,3],[263,6],[317,5]]},"1059":{"position":[[82,3],[174,3]]},"1061":{"position":[[60,5]]},"1077":{"position":[[211,3]]}}}],["usag",{"_index":1469,"t":{"437":{"position":[[574,5]]},"445":{"position":[[19,5],[84,5],[212,5]]}}}],["user",{"_index":2462,"t":{"807":{"position":[[55,4]]},"995":{"position":[[294,4]]}}}],["utu_tut",{"_index":2079,"t":{"635":{"position":[[775,9],[839,9]]}}}],["u‾(t)\\overline{u}^{(t)}u(t",{"_index":3649,"t":{"1152":{"position":[[2192,27],[2364,27]]}}}],["u⊤wv⊤u^{\\top}wv^{\\top}u⊤wv",{"_index":1916,"t":{"608":{"position":[[93,27]]}}}],["u⊤wv⊤∣∣f||u^{\\top}wv^{\\top}||_f∣∣u⊤wv⊤∣∣f",{"_index":1919,"t":{"608":{"position":[[212,44],[371,44]]}}}],["v",{"_index":239,"t":{"38":{"position":[[463,1]]},"427":{"position":[[1684,2]]},"1222":{"position":[[457,3]]}}}],["v.",{"_index":2255,"t":{"696":{"position":[[279,4]]}}}],["v1.1",{"_index":1521,"t":{"457":{"position":[[1374,4]]},"496":{"position":[[61,4]]}}}],["v100",{"_index":2435,"t":{"784":{"position":[[531,4]]},"1158":{"position":[[92,4]]}}}],["v2",{"_index":1632,"t":{"471":{"position":[[72,2],[139,2]]},"496":{"position":[[114,2]]},"502":{"position":[[189,2],[839,2]]},"504":{"position":[[557,2],[1382,2],[2113,2]]},"512":{"position":[[213,2]]},"515":{"position":[[526,2],[952,2]]},"519":{"position":[[22,2],[119,2]]},"521":{"position":[[371,2]]},"523":{"position":[[299,2]]},"525":{"position":[[91,2]]},"529":{"position":[[14,2]]},"533":{"position":[[64,2],[139,2],[542,2]]},"535":{"position":[[100,2],[218,2]]},"537":{"position":[[377,2],[514,2],[586,2]]},"541":{"position":[[141,2]]},"543":{"position":[[76,2]]},"698":{"position":[[1845,2]]},"711":{"position":[[466,2],[562,2]]},"713":{"position":[[1449,2]]},"725":{"position":[[410,2]]},"727":{"position":[[260,2],[357,2]]},"732":{"position":[[25,2]]},"734":{"position":[[114,2]]},"736":{"position":[[115,2],[197,2]]},"738":{"position":[[9,2]]},"740":{"position":[[9,2]]},"746":{"position":[[19,2],[141,2],[366,2]]},"748":{"position":[[24,3],[358,2]]},"751":{"position":[[98,2]]},"753":{"position":[[35,2]]},"755":{"position":[[9,2],[155,2]]}}}],["v2.0",{"_index":1522,"t":{"457":{"position":[[1381,4]]},"496":{"position":[[68,4]]}}}],["v\\mathcal{v}v",{"_index":2178,"t":{"686":{"position":[[909,14],[1763,13]]},"718":{"position":[[32,13]]}}}],["v\\subset",{"_index":2290,"t":{"718":{"position":[[147,9]]}}}],["v_c",{"_index":3805,"t":{"1222":{"position":[[778,3]]},"1224":{"position":[[72,3]]}}}],["v_k",{"_index":2003,"t":{"631":{"position":[[337,3]]}}}],["v_k^t",{"_index":2014,"t":{"631":{"position":[[687,6]]}}}],["v_k^t)p^k​=p∗∘(uk​⨂vkt",{"_index":2024,"t":{"633":{"position":[[390,24]]}}}],["v_k^twk​=uk​⨂vkt",{"_index":2008,"t":{"631":{"position":[[481,17]]}}}],["v_l",{"_index":1563,"t":{"463":{"position":[[643,3],[2346,4]]}}}],["v_t^t)p^t​=p∗∘(ut​⨂vtt",{"_index":2078,"t":{"635":{"position":[[741,24]]}}}],["val2017",{"_index":3375,"t":{"1107":{"position":[[15,7]]}}}],["valid",{"_index":828,"t":{"193":{"position":[[85,11]]},"309":{"position":[[88,10]]},"423":{"position":[[982,10],[1428,10]]},"431":{"position":[[735,10]]},"447":{"position":[[152,10],[247,10]]}}}],["valu",{"_index":256,"t":{"49":{"position":[[230,5]]},"176":{"position":[[555,5]]},"427":{"position":[[1271,5]]},"439":{"position":[[383,5]]},"463":{"position":[[431,6]]},"604":{"position":[[87,5]]},"606":{"position":[[214,5]]},"832":{"position":[[19,5]]},"848":{"position":[[405,5]]},"850":{"position":[[1150,5]]},"857":{"position":[[187,5]]},"1001":{"position":[[1177,5]]},"1016":{"position":[[60,5]]},"1135":{"position":[[558,5],[673,5]]},"1137":{"position":[[3753,5],[4072,6],[4337,6]]},"1140":{"position":[[707,5]]},"1142":{"position":[[751,5]]},"1144":{"position":[[75,5],[188,6]]},"1146":{"position":[[60,5],[432,6],[573,5],[1214,6],[1774,6],[1915,6]]},"1148":{"position":[[193,6],[1655,6],[2406,6],[2446,6]]},"1150":{"position":[[123,6]]},"1152":{"position":[[399,5]]},"1154":{"position":[[132,6]]},"1158":{"position":[[488,6]]},"1160":{"position":[[839,5]]},"1165":{"position":[[587,5]]},"1194":{"position":[[165,5],[250,6]]}}}],["valuabl",{"_index":2659,"t":{"859":{"position":[[49,8]]}}}],["vanilla",{"_index":1516,"t":{"457":{"position":[[499,7]]},"463":{"position":[[145,7]]},"616":{"position":[[1329,7]]},"627":{"position":[[1073,7]]},"635":{"position":[[110,7]]},"637":{"position":[[10,7]]},"646":{"position":[[111,7]]},"653":{"position":[[219,7]]}}}],["variabl",{"_index":912,"t":{"250":{"position":[[170,8]]}}}],["varianc",{"_index":2457,"t":{"802":{"position":[[112,8]]},"834":{"position":[[961,8],[996,8]]}}}],["variant",{"_index":3655,"t":{"1152":{"position":[[2705,7]]},"1188":{"position":[[126,8],[278,8]]}}}],["variat",{"_index":3530,"t":{"1146":{"position":[[1968,9]]},"1152":{"position":[[2278,9]]}}}],["varrho",{"_index":464,"t":{"91":{"position":[[2051,7],[2345,7]]}}}],["vaswani",{"_index":1409,"t":{"427":{"position":[[1499,7]]}}}],["vc=[v,wc],(3)v_c",{"_index":3798,"t":{"1222":{"position":[[438,16]]}}}],["vc}c=1c",{"_index":3804,"t":{"1222":{"position":[[767,10]]},"1224":{"position":[[61,10]]}}}],["vc∈rd×(l+1)v_c",{"_index":3796,"t":{"1222":{"position":[[368,14]]}}}],["vecotr",{"_index":1431,"t":{"427":{"position":[[2298,7]]},"633":{"position":[[487,7]]},"637":{"position":[[99,7]]}}}],["vector",{"_index":422,"t":{"91":{"position":[[471,6],[606,6],[623,6],[1286,6]]},"108":{"position":[[90,6]]},"292":{"position":[[336,6]]},"416":{"position":[[493,6]]},"418":{"position":[[2088,7]]},"427":{"position":[[476,7],[738,6],[887,6],[1188,6],[1289,6],[1373,6],[1960,6],[2519,6],[3602,7]]},"439":{"position":[[389,7]]},"443":{"position":[[339,7]]},"451":{"position":[[171,7]]},"563":{"position":[[695,7]]},"579":{"position":[[5,7]]},"604":{"position":[[282,7],[385,7],[768,7]]},"608":{"position":[[190,6],[339,7]]},"614":{"position":[[72,6],[191,7]]},"616":{"position":[[297,7],[417,7],[555,7]]},"619":{"position":[[167,7]]},"627":{"position":[[439,7]]},"631":{"position":[[403,7],[425,7]]},"633":{"position":[[1763,6]]},"644":{"position":[[119,7]]},"646":{"position":[[154,7]]},"648":{"position":[[281,6]]},"659":{"position":[[273,6]]},"666":{"position":[[34,7]]},"668":{"position":[[106,7],[135,7]]},"759":{"position":[[321,7]]},"761":{"position":[[1167,7]]},"766":{"position":[[338,6],[570,6]]},"811":{"position":[[636,7]]},"842":{"position":[[356,6],[1097,6]]},"850":{"position":[[1234,6]]},"870":{"position":[[216,6]]},"883":{"position":[[783,7]]},"901":{"position":[[357,6]]},"1137":{"position":[[4156,7],[4364,7]]},"1146":{"position":[[349,7],[581,7],[739,6],[1803,7]]},"1152":{"position":[[407,7]]},"1160":{"position":[[239,7]]}}}],["verb",{"_index":1003,"t":{"298":{"position":[[142,4]]}}}],["verbal",{"_index":2308,"t":{"736":{"position":[[0,11]]},"751":{"position":[[20,10],[354,10]]},"821":{"position":[[439,13]]},"850":{"position":[[371,6],[1908,8]]},"853":{"position":[[190,6]]},"859":{"position":[[77,6]]},"863":{"position":[[435,6]]},"911":{"position":[[681,10]]}}}],["veri",{"_index":19,"t":{"5":{"position":[[25,4]]},"78":{"position":[[33,4]]},"1047":{"position":[[180,4]]}}}],["verifi",{"_index":914,"t":{"254":{"position":[[167,9]]}}}],["versatil",{"_index":1785,"t":{"557":{"position":[[129,9]]}}}],["version",{"_index":89,"t":{"15":{"position":[[8,7]]},"825":{"position":[[189,7]]},"1024":{"position":[[165,10]]},"1032":{"position":[[84,10]]},"1063":{"position":[[31,8]]},"1065":{"position":[[10,7],[184,9],[237,7]]},"1067":{"position":[[30,9],[46,7],[231,7]]},"1069":{"position":[[23,9]]}}}],["versioned_docs/vers",{"_index":3210,"t":{"1065":{"position":[[106,22]]},"1069":{"position":[[66,22]]}}}],["versions.json",{"_index":3211,"t":{"1065":{"position":[[137,13]]}}}],["vi",{"_index":3245,"t":{"1087":{"position":[[287,5],[1479,4]]},"1090":{"position":[[128,3]]},"1096":{"position":[[1435,3]]},"1119":{"position":[[8,3]]},"1123":{"position":[[92,3]]},"1125":{"position":[[364,3]]},"1127":{"position":[[85,3]]}}}],["via",{"_index":1786,"t":{"557":{"position":[[165,3]]}}}],["video",{"_index":1685,"t":{"510":{"position":[[35,5]]},"1085":{"position":[[731,5]]},"1087":{"position":[[259,5],[481,5],[607,5]]},"1099":{"position":[[965,5],[1040,5]]},"1203":{"position":[[616,5]]}}}],["view",{"_index":30,"t":{"5":{"position":[[114,5]]},"19":{"position":[[331,4]]},"1142":{"position":[[793,4]]}}}],["violenc",{"_index":2905,"t":{"959":{"position":[[401,9]]}}}],["violent",{"_index":3056,"t":{"1016":{"position":[[191,8]]}}}],["virtual",{"_index":2324,"t":{"759":{"position":[[410,8]]},"761":{"position":[[1284,8]]},"798":{"position":[[0,8]]},"901":{"position":[[2429,7]]}}}],["vis19",{"_index":3366,"t":{"1099":{"position":[[1293,6]]}}}],["vision",{"_index":375,"t":{"84":{"position":[[59,6],[125,6]]},"124":{"position":[[44,6],[74,6],[138,6]]},"126":{"position":[[317,6],[351,6],[585,6],[873,6]]},"128":{"position":[[13,6]]},"132":{"position":[[348,6]]},"143":{"position":[[255,6]]},"159":{"position":[[89,6],[193,6]]},"163":{"position":[[3,6],[90,6],[271,6]]},"165":{"position":[[74,6],[514,7],[571,6],[612,6],[670,6],[686,6]]},"169":{"position":[[59,6],[388,6],[467,6],[771,6]]},"171":{"position":[[61,6],[248,6],[297,6]]},"174":{"position":[[369,6]]},"176":{"position":[[217,6]]},"178":{"position":[[43,6],[457,6],[479,6]]},"180":{"position":[[235,6]]},"183":{"position":[[75,6]]},"197":{"position":[[417,6]]},"281":{"position":[[18,6],[496,6],[608,6],[667,6],[820,6],[1392,6]]},"313":{"position":[[238,6]]},"457":{"position":[[1178,6]]},"465":{"position":[[1123,6]]},"467":{"position":[[83,6]]},"504":{"position":[[728,6],[1034,6]]},"523":{"position":[[0,6]]},"535":{"position":[[58,6],[170,6]]},"539":{"position":[[329,6]]},"1085":{"position":[[652,6]]},"1094":{"position":[[703,6]]},"1198":{"position":[[298,6]]},"1203":{"position":[[141,6],[319,6],[363,6]]},"1222":{"position":[[702,6]]},"1230":{"position":[[76,6],[242,6]]}}}],["visual",{"_index":590,"t":{"126":{"position":[[279,6]]},"153":{"position":[[742,6]]},"165":{"position":[[110,6],[868,6]]},"169":{"position":[[665,6]]},"180":{"position":[[520,6]]},"186":{"position":[[20,6]]},"193":{"position":[[113,6]]},"279":{"position":[[65,6]]},"281":{"position":[[1949,6]]},"288":{"position":[[57,6],[202,6],[352,6],[436,6]]},"292":{"position":[[94,6]]},"302":{"position":[[1423,6]]},"465":{"position":[[143,6],[193,6],[1063,6]]},"482":{"position":[[72,6]]},"502":{"position":[[26,6],[71,6],[148,6],[326,6],[385,6]]},"504":{"position":[[406,6],[475,6],[607,6],[650,6],[869,6],[1002,6],[1071,6],[1259,6],[1303,6],[1397,6],[1723,6],[2324,6]]},"510":{"position":[[59,6],[99,6],[151,6],[210,6],[301,6]]},"512":{"position":[[62,6],[113,6]]},"517":{"position":[[80,6]]},"519":{"position":[[399,6]]},"523":{"position":[[45,6],[134,6],[163,6],[211,6],[312,6],[492,6]]},"525":{"position":[[22,6],[346,6],[437,6],[503,6],[525,6]]},"529":{"position":[[140,6]]},"531":{"position":[[104,6]]},"537":{"position":[[41,6],[449,6]]},"539":{"position":[[96,6]]},"541":{"position":[[0,6],[41,6],[160,6]]},"543":{"position":[[26,6],[181,6],[221,6],[512,6]]},"901":{"position":[[1250,6],[1270,6]]},"1087":{"position":[[1923,6]]},"1092":{"position":[[546,6],[611,6],[1002,6]]},"1094":{"position":[[31,6],[102,6],[182,6]]},"1096":{"position":[[5,6],[1150,6]]},"1099":{"position":[[1362,6]]},"1104":{"position":[[57,6]]},"1125":{"position":[[0,6]]},"1198":{"position":[[12,6]]},"1200":{"position":[[21,6]]},"1203":{"position":[[30,6]]},"1214":{"position":[[415,6]]},"1218":{"position":[[11,6]]},"1222":{"position":[[722,6]]},"1224":{"position":[[206,6]]}}}],["visualtextu",{"_index":1608,"t":{"465":{"position":[[100,13]]},"482":{"position":[[244,13]]}}}],["vit",{"_index":169,"t":{"25":{"position":[[198,3],[733,3]]},"60":{"position":[[31,3]]},"84":{"position":[[144,5]]},"88":{"position":[[301,3]]},"93":{"position":[[34,3]]},"97":{"position":[[6,3],[443,3]]},"99":{"position":[[8,4]]},"104":{"position":[[43,3],[104,3],[396,3]]},"106":{"position":[[176,3],[192,3]]},"110":{"position":[[0,3],[11,3]]},"112":{"position":[[533,3]]},"114":{"position":[[158,3],[301,3],[355,3],[399,3],[414,3]]},"116":{"position":[[0,3],[294,3],[382,3]]},"118":{"position":[[55,3],[100,3],[129,3]]},"120":{"position":[[186,3],[257,3]]},"143":{"position":[[274,4]]},"174":{"position":[[128,3]]},"183":{"position":[[237,3],[282,3]]},"197":{"position":[[359,3],[367,3]]},"455":{"position":[[609,5]]},"457":{"position":[[1293,3]]},"469":{"position":[[12,3],[143,3]]},"494":{"position":[[62,3]]},"1104":{"position":[[46,3]]},"1203":{"position":[[388,3]]},"1218":{"position":[[94,3],[104,3],[114,3]]},"1230":{"position":[[201,3],[211,3],[222,3]]}}}],["vit/deit",{"_index":339,"t":{"65":{"position":[[81,8]]}}}],["viusal",{"_index":3323,"t":{"1096":{"position":[[247,6]]}}}],["vkv_kvk",{"_index":2026,"t":{"633":{"position":[[642,8]]}}}],["vl",{"_index":1061,"t":{"313":{"position":[[92,2]]}}}],["vl=linearv",{"_index":1557,"t":{"463":{"position":[[511,13]]}}}],["vlkd",{"_index":1062,"t":{"313":{"position":[[109,4]]}}}],["vlm",{"_index":789,"t":{"180":{"position":[[421,4]]},"193":{"position":[[152,4]]},"313":{"position":[[103,3]]},"1198":{"position":[[320,6],[389,3]]},"1200":{"position":[[886,3],[1287,3],[1711,3],[1734,3]]},"1203":{"position":[[0,3],[313,3]]},"1205":{"position":[[11,3],[495,3]]},"1207":{"position":[[327,3]]},"1211":{"position":[[116,3],[266,3]]}}}],["vl​=linearv",{"_index":1568,"t":{"463":{"position":[[749,15]]}}}],["vo",{"_index":3247,"t":{"1087":{"position":[[510,4],[633,5],[1538,4],[1580,4]]},"1090":{"position":[[208,3],[269,3]]},"1099":{"position":[[1270,5],[1310,3],[1327,4]]},"1113":{"position":[[0,3],[27,3],[191,3]]},"1121":{"position":[[12,3],[34,3],[81,3]]},"1123":{"position":[[61,4],[78,3]]}}}],["vocab",{"_index":2559,"t":{"832":{"position":[[592,5]]},"838":{"position":[[136,5]]},"842":{"position":[[1352,5]]}}}],["vocabulari",{"_index":623,"t":{"130":{"position":[[1599,10]]},"143":{"position":[[558,10]]},"646":{"position":[[168,12]]},"686":{"position":[[896,10],[1752,10]]},"694":{"position":[[160,10],[190,10]]},"718":{"position":[[19,10]]},"766":{"position":[[1024,10]]},"819":{"position":[[1085,10]]},"821":{"position":[[116,10]]},"832":{"position":[[166,10],[220,10],[262,10]]},"842":{"position":[[295,10],[335,10]]},"905":{"position":[[68,10],[98,10]]},"911":{"position":[[998,10]]},"947":{"position":[[629,10]]},"1085":{"position":[[424,12]]},"1087":{"position":[[1077,12]]},"1096":{"position":[[2650,12]]}}}],["vote",{"_index":2589,"t":{"840":{"position":[[665,6]]},"917":{"position":[[974,6]]}}}],["vpt",{"_index":1658,"t":{"496":{"position":[[15,3]]}}}],["vq2^22a",{"_index":1066,"t":{"313":{"position":[[289,7]]}}}],["vqa",{"_index":822,"t":{"190":{"position":[[172,3]]},"215":{"position":[[74,4]]},"279":{"position":[[91,5],[134,3],[315,3],[630,3],[840,3]]},"281":{"position":[[0,3],[47,3],[142,3],[261,3],[288,3],[440,3],[463,3],[917,3],[990,3],[1307,3],[1818,3],[2012,3],[2128,3],[2264,3],[2326,3]]},"284":{"position":[[0,3],[108,3],[171,3]]},"286":{"position":[[364,3],[428,3]]},"292":{"position":[[16,3],[227,3],[296,3],[922,3]]},"294":{"position":[[0,3]]},"296":{"position":[[234,3]]},"300":{"position":[[22,3],[863,3],[1018,3]]},"306":{"position":[[24,3]]},"309":{"position":[[46,3]]},"311":{"position":[[485,3]]},"313":{"position":[[3,3]]},"316":{"position":[[57,3],[141,3]]},"318":{"position":[[39,3],[144,3],[241,3]]},"322":{"position":[[96,3]]},"484":{"position":[[16,3]]}}}],["vqav2",{"_index":829,"t":{"193":{"position":[[97,5]]},"199":{"position":[[166,5]]},"279":{"position":[[553,5]]},"281":{"position":[[2282,5]]},"309":{"position":[[0,5]]},"320":{"position":[[71,5]]}}}],["vram",{"_index":1823,"t":{"571":{"position":[[152,4],[177,4]]}}}],["vs",{"_index":1938,"t":{"616":{"position":[[1443,2]]},"949":{"position":[[240,2]]},"1013":{"position":[[329,2]]}}}],["vtab",{"_index":504,"t":{"102":{"position":[[235,4]]},"110":{"position":[[158,4]]},"457":{"position":[[1330,4]]},"469":{"position":[[179,4]]},"494":{"position":[[85,4]]}}}],["vtav",{"_index":502,"t":{"102":{"position":[[219,4]]}}}],["vtv_tvt",{"_index":2080,"t":{"635":{"position":[[785,8],[849,8]]}}}],["vu,v",{"_index":1923,"t":{"608":{"position":[[309,4]]}}}],["vvv",{"_index":1029,"t":{"302":{"position":[[580,3]]},"1222":{"position":[[594,3],[1405,3]]},"1224":{"position":[[22,3]]}}}],["v∈rd×lv",{"_index":3790,"t":{"1222":{"position":[[120,7]]}}}],["w",{"_index":237,"t":{"38":{"position":[[452,1]]},"91":{"position":[[154,1]]},"171":{"position":[[539,1],[586,2]]},"427":{"position":[[2868,1],[2883,2]]},"515":{"position":[[595,1],[636,2]]},"563":{"position":[[368,1],[654,1],[917,1]]},"1137":{"position":[[1688,1]]},"1146":{"position":[[133,1]]}}}],["w(0)w^{(0)}w(0",{"_index":3412,"t":{"1137":{"position":[[943,15],[1056,15],[1762,16]]},"1142":{"position":[[255,16]]}}}],["w)(h,w",{"_index":414,"t":{"91":{"position":[[297,7]]}}}],["w0+△w=w0+baw_0",{"_index":1791,"t":{"563":{"position":[[341,14]]}}}],["w0w_0w0",{"_index":1803,"t":{"563":{"position":[[549,8],[628,8]]}}}],["w0∈rd×kw_0",{"_index":1788,"t":{"563":{"position":[[263,10]]}}}],["w=ba\\triangl",{"_index":1804,"t":{"563":{"position":[[639,14],[902,14]]}}}],["w=w(0)+△=w(0)+ba,\\begin{equ",{"_index":3415,"t":{"1137":{"position":[[1654,33]]}}}],["w=w(0)+△=w(0)+pλq,\\begin{equ",{"_index":3498,"t":{"1146":{"position":[[98,34]]}}}],["w={fp′[i",{"_index":3331,"t":{"1096":{"position":[[2005,10]]}}}],["w\\triangl",{"_index":1751,"t":{"551":{"position":[[305,11]]},"563":{"position":[[978,11]]},"598":{"position":[[160,11]]},"600":{"position":[[395,11]]},"602":{"position":[[114,11]]},"608":{"position":[[4,11],[48,11],[152,11],[445,11],[507,11],[587,11]]},"610":{"position":[[265,11]]}}}],["w^{(0",{"_index":3416,"t":{"1137":{"position":[[1692,7],[1714,7]]},"1146":{"position":[[137,7],[159,7]]}}}],["w^{(0)}h=w(0",{"_index":3481,"t":{"1142":{"position":[[87,13]]}}}],["w^{(0)}x",{"_index":3483,"t":{"1142":{"position":[[176,8],[201,8]]}}}],["w_0",{"_index":1792,"t":{"563":{"position":[[372,3]]}}}],["w_0x",{"_index":1809,"t":{"563":{"position":[[798,4],[820,4]]}}}],["w_0xh=w0​x",{"_index":1807,"t":{"563":{"position":[[735,10]]}}}],["w_1",{"_index":1419,"t":{"427":{"position":[[1811,4]]}}}],["w_c",{"_index":3799,"t":{"1222":{"position":[[461,5]]}}}],["w_k",{"_index":2013,"t":{"631":{"position":[[655,3]]},"1148":{"position":[[80,4]]},"1160":{"position":[[920,4]]}}}],["w_k△wk",{"_index":1878,"t":{"600":{"position":[[295,7]]}}}],["w_q",{"_index":1880,"t":{"602":{"position":[[53,4]]}}}],["w_q△wq",{"_index":1876,"t":{"600":{"position":[[271,7]]},"604":{"position":[[1022,8],[1093,8]]},"606":{"position":[[92,7],[173,7]]}}}],["w_v",{"_index":1881,"t":{"602":{"position":[[58,3]]},"1148":{"position":[[85,4]]},"1160":{"position":[[925,4]]}}}],["w_v△wv",{"_index":1910,"t":{"604":{"position":[[997,7],[1068,7]]},"606":{"position":[[115,7]]}}}],["w_{f1}wq​,wk​,wv​,wf1",{"_index":3532,"t":{"1148":{"position":[[90,22]]}}}],["w_{f_1",{"_index":3678,"t":{"1160":{"position":[[930,8]]}}}],["w_{f_2}wq​,wk​,wv​,wf1​​,wf2",{"_index":3679,"t":{"1160":{"position":[[939,31]]}}}],["w_{ij",{"_index":3627,"t":{"1152":{"position":[[1058,6]]}}}],["w_{ki",{"_index":3466,"t":{"1140":{"position":[[626,7]]}}}],["w_{vi",{"_index":3467,"t":{"1140":{"position":[[634,6]]}}}],["want",{"_index":73,"t":{"9":{"position":[[401,4]]}}}],["warm",{"_index":3661,"t":{"1154":{"position":[[492,4]]},"1236":{"position":[[73,4]]}}}],["warmup",{"_index":1458,"t":{"431":{"position":[[437,6]]},"475":{"position":[[139,6]]}}}],["warp",{"_index":2478,"t":{"817":{"position":[[1331,6],[1899,5]]},"836":{"position":[[960,4]]}}}],["wc∈rdw_c",{"_index":3801,"t":{"1222":{"position":[[490,8]]}}}],["weak",{"_index":355,"t":{"78":{"position":[[310,4],[531,4]]}}}],["weaqa",{"_index":1067,"t":{"313":{"position":[[299,5]]}}}],["web",{"_index":729,"t":{"165":{"position":[[485,3]]},"169":{"position":[[361,3]]},"186":{"position":[[34,3],[91,3]]},"969":{"position":[[566,3]]}}}],["webnlg",{"_index":2111,"t":{"642":{"position":[[372,6]]},"655":{"position":[[144,6]]},"780":{"position":[[55,6],[125,6]]},"793":{"position":[[158,6]]}}}],["websit",{"_index":108,"t":{"17":{"position":[[181,7]]},"19":{"position":[[34,7],[254,7]]}}}],["week",{"_index":2527,"t":{"823":{"position":[[336,5],[456,5]]}}}],["weight",{"_index":236,"t":{"38":{"position":[[445,6]]},"53":{"position":[[195,6]]},"80":{"position":[[30,6]]},"106":{"position":[[114,6]]},"112":{"position":[[199,6]]},"116":{"position":[[651,6]]},"132":{"position":[[583,9]]},"138":{"position":[[200,9],[482,9],[511,9],[542,6]]},"149":{"position":[[396,6]]},"151":{"position":[[118,9],[140,6]]},"155":{"position":[[151,6],[179,6],[635,9],[729,6],[751,6],[800,6],[875,9],[962,9],[1048,6]]},"171":{"position":[[209,6],[443,6]]},"178":{"position":[[351,7]]},"188":{"position":[[16,6]]},"355":{"position":[[139,6]]},"427":{"position":[[2646,6]]},"475":{"position":[[183,6]]},"515":{"position":[[480,7]]},"547":{"position":[[97,7]]},"549":{"position":[[455,6],[560,7],[1183,7]]},"551":{"position":[[230,6]]},"553":{"position":[[346,6]]},"563":{"position":[[49,6],[249,6]]},"565":{"position":[[3,6]]},"569":{"position":[[20,6],[193,6]]},"587":{"position":[[3,6],[292,6]]},"600":{"position":[[68,6],[157,6]]},"610":{"position":[[248,6]]},"631":{"position":[[841,6],[877,6]]},"811":{"position":[[1209,6]]},"817":{"position":[[124,6]]},"819":{"position":[[375,6]]},"825":{"position":[[819,6]]},"848":{"position":[[205,6]]},"917":{"position":[[708,8],[729,6],[752,6],[778,6],[865,6],[953,6]]},"963":{"position":[[530,8]]},"1096":{"position":[[1775,6],[1892,6]]},"1099":{"position":[[498,6]]},"1104":{"position":[[296,6]]},"1135":{"position":[[227,7],[305,6],[369,6],[460,6]]},"1137":{"position":[[848,6],[929,6],[2462,6],[2751,6],[2802,6],[2897,6],[3059,6],[3333,6],[3900,6]]},"1142":{"position":[[44,7],[852,6]]},"1146":{"position":[[12,6]]},"1148":{"position":[[49,6],[352,6]]},"1152":{"position":[[156,7],[986,6]]},"1154":{"position":[[719,6]]},"1160":{"position":[[104,7],[787,6],[877,6]]},"1179":{"position":[[88,6]]},"1192":{"position":[[174,6],[205,6]]},"1194":{"position":[[117,6]]},"1205":{"position":[[388,6]]},"1222":{"position":[[1462,6]]}}}],["weightinh",{"_index":640,"t":{"138":{"position":[[367,9]]}}}],["weigt",{"_index":336,"t":{"63":{"position":[[185,5]]}}}],["welcome.md",{"_index":64,"t":{"9":{"position":[[245,10]]}}}],["welcome/index.md",{"_index":65,"t":{"9":{"position":[[267,16]]}}}],["well",{"_index":71,"t":{"9":{"position":[[378,5]]},"1055":{"position":[[236,5]]}}}],["wf1w_{f1}wf1",{"_index":3495,"t":{"1142":{"position":[[872,14]]}}}],["wf1∈rd×dmw_{f1",{"_index":3475,"t":{"1140":{"position":[[962,15]]}}}],["wf2w_{f2}wf2",{"_index":3496,"t":{"1142":{"position":[[887,14]]},"1148":{"position":[[115,13]]}}}],["wf2∈rdm×dw_{f2",{"_index":3477,"t":{"1140":{"position":[[1019,15]]}}}],["whirlpool",{"_index":2980,"t":{"983":{"position":[[1045,10]]}}}],["wic",{"_index":1330,"t":{"423":{"position":[[922,5]]},"642":{"position":[[162,4]]},"700":{"position":[[83,3],[303,3],[430,3],[434,3]]},"702":{"position":[[1068,4]]},"704":{"position":[[196,3]]}}}],["width",{"_index":754,"t":{"171":{"position":[[601,6]]}}}],["wijw_{ij}wij",{"_index":3630,"t":{"1152":{"position":[[1153,13]]}}}],["wiki",{"_index":2109,"t":{"642":{"position":[[329,4]]}}}],["wikidata",{"_index":2241,"t":{"694":{"position":[[55,8]]}}}],["wikipedia",{"_index":976,"t":{"284":{"position":[[203,9]]},"780":{"position":[[152,9]]}}}],["wikisql",{"_index":1833,"t":{"573":{"position":[[100,7]]}}}],["wind",{"_index":1023,"t":{"302":{"position":[[279,4]]}}}],["window",{"_index":2688,"t":{"870":{"position":[[192,6]]}}}],["wingogend",{"_index":2994,"t":{"989":{"position":[[788,11]]}}}],["winogrand",{"_index":1327,"t":{"423":{"position":[[884,11]]},"642":{"position":[[294,11]]}}}],["wise",{"_index":1392,"t":{"427":{"position":[[756,4],[912,4],[1308,4],[1426,4],[1746,4],[2785,4],[3204,4]]},"510":{"position":[[258,6]]},"563":{"position":[[716,4]]},"1137":{"position":[[1135,4]]},"1146":{"position":[[1560,5]]},"1152":{"position":[[171,4],[231,4]]},"1186":{"position":[[36,4]]}}}],["within",{"_index":2448,"t":{"793":{"position":[[393,6]]}}}],["without",{"_index":360,"t":{"78":{"position":[[676,7]]}}}],["wjw_jwj",{"_index":636,"t":{"132":{"position":[[979,8]]}}}],["wk=uk⨂vktw_k",{"_index":2005,"t":{"631":{"position":[[451,12]]}}}],["wk\\triangl",{"_index":1877,"t":{"600":{"position":[[282,12]]}}}],["wkw_kwk",{"_index":1748,"t":{"551":{"position":[[189,9]]},"569":{"position":[[73,9]]},"631":{"position":[[505,8],[884,8]]}}}],["wmt",{"_index":2997,"t":{"989":{"position":[[923,3]]}}}],["wonder",{"_index":2741,"t":{"887":{"position":[[227,13]]}}}],["word",{"_index":874,"t":{"227":{"position":[[326,4]]},"229":{"position":[[953,4]]},"231":{"position":[[30,4]]},"236":{"position":[[13,4],[48,4],[79,4],[110,4],[142,4]]},"254":{"position":[[191,4]]},"273":{"position":[[161,4]]},"423":{"position":[[896,4]]},"455":{"position":[[319,4]]},"461":{"position":[[623,4]]},"463":{"position":[[46,4],[283,4],[373,4],[999,4],[1454,4]]},"508":{"position":[[204,4],[324,4]]},"523":{"position":[[569,4]]},"583":{"position":[[32,4]]},"688":{"position":[[101,4]]},"698":{"position":[[220,4]]},"700":{"position":[[460,4]]},"713":{"position":[[793,4]]},"773":{"position":[[76,4],[196,4],[754,4]]},"798":{"position":[[72,4]]},"817":{"position":[[1090,4]]},"821":{"position":[[239,4]]},"836":{"position":[[1533,5]]},"842":{"position":[[1018,5]]},"899":{"position":[[152,5],[200,5]]},"911":{"position":[[1236,4]]},"937":{"position":[[343,4]]},"943":{"position":[[567,4]]},"983":{"position":[[405,5]]},"1222":{"position":[[177,4],[543,4]]}}}],["work",{"_index":123,"t":{"19":{"position":[[100,7],[126,4]]},"610":{"position":[[153,4]]},"861":{"position":[[409,5]]},"1013":{"position":[[12,4]]}}}],["workaround",{"_index":2563,"t":{"834":{"position":[[262,12]]}}}],["world",{"_index":1225,"t":{"382":{"position":[[12,5]]},"418":{"position":[[2279,5]]},"423":{"position":[[1029,6]]},"437":{"position":[[527,5]]},"447":{"position":[[39,5],[94,5],[467,5]]},"793":{"position":[[408,7]]}}}],["wow_owo",{"_index":1750,"t":{"551":{"position":[[209,8],[252,8]]},"569":{"position":[[93,9]]}}}],["wo∈rd×dw_o",{"_index":3463,"t":{"1140":{"position":[[534,10]]}}}],["wq,wk,wv,wf1,wf2w_q",{"_index":3677,"t":{"1160":{"position":[[899,20]]}}}],["wq,wk,wv,wf1w_q",{"_index":3531,"t":{"1148":{"position":[[63,16]]}}}],["wq,wv",{"_index":1879,"t":{"602":{"position":[[42,10]]}}}],["wq\\triangl",{"_index":1875,"t":{"600":{"position":[[258,12]]},"604":{"position":[[1009,12],[1080,12]]},"606":{"position":[[79,12],[160,12]]}}}],["wqi,wki,wvi∈rd×dhw_{qi",{"_index":3465,"t":{"1140":{"position":[[601,24]]}}}],["wqw_qwq",{"_index":1747,"t":{"551":{"position":[[179,9]]},"569":{"position":[[62,10]]},"571":{"position":[[220,8]]},"587":{"position":[[91,8]]},"600":{"position":[[322,8]]},"602":{"position":[[77,8]]}}}],["wq​,wv",{"_index":1882,"t":{"602":{"position":[[62,11]]}}}],["write",{"_index":2913,"t":{"959":{"position":[[926,6]]}}}],["written",{"_index":2627,"t":{"850":{"position":[[1004,7]]}}}],["wsc",{"_index":1326,"t":{"423":{"position":[[877,4]]},"642":{"position":[[167,3]]},"700":{"position":[[398,3]]},"702":{"position":[[1079,3]]}}}],["wukong",{"_index":3745,"t":{"1203":{"position":[[198,6]]}}}],["wv\\triangl",{"_index":1909,"t":{"604":{"position":[[984,12],[1055,12]]},"606":{"position":[[102,12]]}}}],["wvw_vwv",{"_index":1749,"t":{"551":{"position":[[199,9]]},"569":{"position":[[83,9]]},"571":{"position":[[231,8]]},"587":{"position":[[102,8]]},"600":{"position":[[333,8]]}}}],["www",{"_index":1688,"t":{"515":{"position":[[503,3]]},"551":{"position":[[246,3]]},"598":{"position":[[178,3]]},"608":{"position":[[22,3],[42,3],[316,3],[485,3],[528,3],[547,3],[605,3]]},"1096":{"position":[[1906,3]]},"1137":{"position":[[2029,3]]}}}],["wx",{"_index":1810,"t":{"563":{"position":[[815,2]]}}}],["wϕw_{\\phi}w",{"_index":2360,"t":{"766":{"position":[[985,13]]}}}],["w∈r1×dw",{"_index":3329,"t":{"1096":{"position":[[1789,7]]}}}],["w∣∣||w||∣∣w",{"_index":1920,"t":{"608":{"position":[[259,15]]}}}],["w△w",{"_index":1752,"t":{"551":{"position":[[317,3]]},"563":{"position":[[990,3]]},"598":{"position":[[172,3]]},"600":{"position":[[407,3]]},"602":{"position":[[126,3]]},"608":{"position":[[16,3],[60,3],[164,3],[457,3],[519,3],[599,3]]},"610":{"position":[[277,3]]}}}],["x",{"_index":190,"t":{"27":{"position":[[107,1]]},"174":{"position":[[108,1]]},"199":{"position":[[154,1]]},"427":{"position":[[2870,1]]},"553":{"position":[[580,2],[1301,2]]},"694":{"position":[[422,1],[668,5]]},"766":{"position":[[110,2],[159,3]]},"768":{"position":[[34,2]]},"770":{"position":[[270,2]]},"775":{"position":[[83,2],[186,2]]},"784":{"position":[[407,1]]},"800":{"position":[[109,2]]},"823":{"position":[[402,1],[490,1]]},"883":{"position":[[200,3],[267,3],[354,4],[506,3],[791,3]]},"899":{"position":[[140,4]]},"943":{"position":[[205,1]]},"951":{"position":[[658,1]]},"955":{"position":[[137,4]]},"959":{"position":[[425,4]]},"1001":{"position":[[792,3],[1598,2],[1621,4]]},"1140":{"position":[[318,3]]},"1142":{"position":[[197,1]]}}}],["x)(y,x",{"_index":620,"t":{"130":{"position":[[1362,7]]}}}],["x))]+γex∼dpretrain[log(πϕrl(x))]\\textup{objective}(\\phi",{"_index":3028,"t":{"1001":{"position":[[1460,56]]}}}],["x))]+γex∼dpretrain​​[log(πϕrl​(x",{"_index":3037,"t":{"1001":{"position":[[1747,35]]}}}],["x))]objective(ϕ)=e(x,y)∼dπϕrl​​​[rθ​(x,y)−βlog(πϕrl​(i",{"_index":3036,"t":{"1001":{"position":[[1677,55]]}}}],["x))w_2(lff​⊙γ(w1​x))w2",{"_index":1420,"t":{"427":{"position":[[1816,23]]}}}],["x)/πsft(i",{"_index":3027,"t":{"1001":{"position":[[1448,9],[1735,9]]}}}],["x)=max⁡ϕ∑i∈yidxlog⁡pϕ(zi",{"_index":2369,"t":{"770":{"position":[[178,24]]}}}],["x)=ϕmax​i∈yidx​∑​logpϕ​(zi",{"_index":2378,"t":{"770":{"position":[[395,27]]}}}],["x)p_{\\phi}(i",{"_index":2334,"t":{"766":{"position":[[83,13]]},"768":{"position":[[7,13]]}}}],["x)pϕ​(i",{"_index":2335,"t":{"766":{"position":[[100,7]]},"768":{"position":[[24,7]]}}}],["x,y)=1t∑t=1tlog⁡p(yt∣x,y<t).\\beta(\\text{x",{"_index":1371,"t":{"425":{"position":[[1709,45]]}}}],["x,y)={xi,yi}i=1n(x,i",{"_index":1973,"t":{"627":{"position":[[102,22]]}}}],["x,yw)−rθ(x,yl)))]\\textup{loss}(\\theta",{"_index":3011,"t":{"1001":{"position":[[677,39]]}}}],["x,yw​)−rθ​(x,yl",{"_index":3019,"t":{"1001":{"position":[[867,21]]}}}],["x1",{"_index":2747,"t":{"893":{"position":[[342,5]]}}}],["x1,x2,…,xn}\\{x_1",{"_index":2501,"t":{"819":{"position":[[1451,18]]}}}],["x1:n={x0,x1,…,xn}\\text{x}_{1:n",{"_index":2159,"t":{"686":{"position":[[71,31]]}}}],["x1:n​={x0​,x1​,…,xn",{"_index":2163,"t":{"686":{"position":[[129,23]]}}}],["x1=2pe",{"_index":444,"t":{"91":{"position":[[1527,7]]}}}],["x1=2p​e",{"_index":456,"t":{"91":{"position":[[1785,8]]}}}],["x2",{"_index":2748,"t":{"893":{"position":[[348,4]]}}}],["x;infix;y][x",{"_index":2454,"t":{"800":{"position":[[180,14]]}}}],["x\\text{x}x",{"_index":1345,"t":{"425":{"position":[[247,10]]},"515":{"position":[[490,10]]},"686":{"position":[[332,10],[436,10],[527,10],[620,11]]},"718":{"position":[[208,10]]}}}],["x\\triangl",{"_index":3669,"t":{"1158":{"position":[[114,11]]}}}],["x][z",{"_index":2864,"t":{"937":{"position":[[351,8]]},"959":{"position":[[411,7],[973,7]]}}}],["x^1=2_p\\textup{",{"_index":450,"t":{"91":{"position":[[1622,19]]}}}],["x^1_p\\textup{",{"_index":449,"t":{"91":{"position":[[1604,17]]}}}],["x^\\hat{x}x",{"_index":2697,"t":{"874":{"position":[[277,11]]}}}],["x^n_p\\textup{",{"_index":451,"t":{"91":{"position":[[1648,16]]}}}],["x_0",{"_index":2160,"t":{"686":{"position":[[108,4]]}}}],["x_1",{"_index":2161,"t":{"686":{"position":[[113,4]]}}}],["x_2",{"_index":2502,"t":{"819":{"position":[[1470,4]]}}}],["x_\\textup{class",{"_index":448,"t":{"91":{"position":[[1584,19]]}}}],["x_e",{"_index":2510,"t":{"819":{"position":[[1810,4]]}}}],["x_i",{"_index":1759,"t":{"553":{"position":[[222,5]]},"627":{"position":[[127,6],[895,4]]},"633":{"position":[[935,3],[982,3]]}}}],["x_n",{"_index":2162,"t":{"686":{"position":[[125,3]]}}}],["x_n\\}{x1​,x2​,…,xn",{"_index":2503,"t":{"819":{"position":[[1483,20]]}}}],["x_{<t",{"_index":2908,"t":{"959":{"position":[[550,7]]}}}],["x_{<t};x_{\\textup{diagnosis}}];\\theta)p(xt​∣[x<t​;xdiagnosi",{"_index":2911,"t":{"959":{"position":[[663,66]]}}}],["x_{\\max",{"_index":606,"t":{"130":{"position":[[646,9]]}}}],["x_{\\min",{"_index":604,"t":{"130":{"position":[[626,9]]}}}],["x_{\\textup{class}}z00​=xclass",{"_index":427,"t":{"91":{"position":[[844,30]]}}}],["x_{\\textup{keypoint",{"_index":614,"t":{"130":{"position":[[1204,20],[1256,20]]}}}],["x_{i,j}lj​xi,j",{"_index":1408,"t":{"427":{"position":[[1103,15]]}}}],["xatt",{"_index":3306,"t":{"1094":{"position":[[319,5]]}}}],["xatt(fv,fp)fv′=fv+fp2v",{"_index":3308,"t":{"1094":{"position":[[437,23]]}}}],["xatt(fv​,fp​)fv′​=fv​+fp2v",{"_index":3319,"t":{"1094":{"position":[[635,28]]}}}],["xatt}(f_v",{"_index":3313,"t":{"1094":{"position":[[530,10]]}}}],["xe∈rn×ex_",{"_index":2504,"t":{"819":{"position":[[1584,10]]}}}],["xf(x)=x∗x",{"_index":2894,"t":{"951":{"position":[[662,10]]}}}],["xi,yi)(x_i",{"_index":269,"t":{"49":{"position":[[598,12]]}}}],["xidx\\text{x}_{\\text{idx}}xidx",{"_index":2338,"t":{"766":{"position":[[192,30]]}}}],["xix_ixi",{"_index":1762,"t":{"553":{"position":[[279,8]]}}}],["xj,yj)(x_j",{"_index":271,"t":{"49":{"position":[[627,12]]}}}],["xl",{"_index":1254,"t":{"396":{"position":[[576,2]]},"694":{"position":[[793,2]]},"825":{"position":[[68,3]]},"827":{"position":[[666,2]]},"834":{"position":[[757,2]]}}}],["xlarg",{"_index":2311,"t":{"742":{"position":[[42,6]]}}}],["xlarge/xxlarg",{"_index":2313,"t":{"742":{"position":[[55,14]]}}}],["xlnet",{"_index":2142,"t":{"680":{"position":[[392,6]]}}}],["xl⊙wx=(l⊙w)x",{"_index":1440,"t":{"427":{"position":[[2886,12]]}}}],["xl⊙x",{"_index":1396,"t":{"427":{"position":[[813,4],[1052,4]]}}}],["xp",{"_index":2429,"t":{"784":{"position":[[383,2]]}}}],["xp1e",{"_index":443,"t":{"91":{"position":[[1521,5]]}}}],["xp1​e",{"_index":455,"t":{"91":{"position":[[1778,6]]}}}],["xpne]+epo",{"_index":445,"t":{"91":{"position":[[1540,11]]}}}],["xpn​e]+epo",{"_index":457,"t":{"91":{"position":[[1799,13]]}}}],["xp​∈rn×(p2⋅c",{"_index":412,"t":{"91":{"position":[[263,15]]}}}],["xp∈rn×(p2⋅c)x_p",{"_index":407,"t":{"91":{"position":[[208,15]]}}}],["xsum",{"_index":2421,"t":{"780":{"position":[[228,4]]},"784":{"position":[[542,4]]},"789":{"position":[[130,4],[196,4]]},"1137":{"position":[[4530,5]]},"1156":{"position":[[119,5]]},"1177":{"position":[[101,6]]},"1184":{"position":[[92,5],[156,4]]}}}],["xxl",{"_index":1868,"t":{"591":{"position":[[73,3]]},"817":{"position":[[943,3]]},"825":{"position":[[72,4]]},"827":{"position":[[398,3]]},"830":{"position":[[202,3]]},"832":{"position":[[741,3]]},"834":{"position":[[324,3],[629,3]]},"840":{"position":[[607,3]]}}}],["xxlarg",{"_index":2275,"t":{"698":{"position":[[1837,7]]}}}],["xxx",{"_index":634,"t":{"132":{"position":[[899,3],[923,3]]},"286":{"position":[[139,3]]},"764":{"position":[[6,3],[123,3],[203,3]]},"766":{"position":[[177,3],[225,3]]},"768":{"position":[[98,3],[188,3]]},"773":{"position":[[308,3],[342,3]]},"800":{"position":[[161,3],[342,3]]},"819":{"position":[[196,3],[503,3]]},"874":{"position":[[76,3],[180,3]]},"879":{"position":[[37,3],[273,3],[356,3],[523,3]]},"883":{"position":[[6,3],[180,3],[255,3],[316,3]]},"899":{"position":[[61,3],[180,3],[416,3]]},"919":{"position":[[61,3]]},"923":{"position":[[31,3]]},"1001":{"position":[[928,3]]}}}],["x~i=λxj+(1−λ)xi\\tilde{x}_i",{"_index":273,"t":{"49":{"position":[[679,26]]}}}],["x′x'x",{"_index":2696,"t":{"874":{"position":[[230,6]]},"883":{"position":[[56,6],[388,6]]},"885":{"position":[[216,6]]}}}],["x∈rh×w×cx",{"_index":403,"t":{"91":{"position":[[119,9]]}}}],["x∈rn×dx",{"_index":3454,"t":{"1140":{"position":[[152,7]]}}}],["x∈rt×dx",{"_index":1399,"t":{"427":{"position":[[932,7]]}}}],["x△x",{"_index":3670,"t":{"1158":{"position":[[126,3]]}}}],["x⟩\\langl",{"_index":2528,"t":{"823":{"position":[[391,10],[478,11]]}}}],["y",{"_index":1691,"t":{"515":{"position":[[591,1],[624,1]]},"694":{"position":[[694,5]]},"823":{"position":[[443,1],[527,1]]}}}],["y)rθ​(x,i",{"_index":3021,"t":{"1001":{"position":[[908,10]]}}}],["y,x)(i",{"_index":619,"t":{"130":{"position":[[1353,8]]}}}],["y=(y1,y2,…,yt)\\text{i",{"_index":1347,"t":{"425":{"position":[[287,22]]}}}],["y=ln(zl0)i",{"_index":474,"t":{"91":{"position":[[2428,10]]}}}],["y={yi}i=1ni",{"_index":977,"t":{"286":{"position":[[172,11]]}}}],["y><z′,i",{"_index":2808,"t":{"911":{"position":[[224,8]]}}}],["y\\mathcal{y}i",{"_index":2712,"t":{"879":{"position":[[289,13],[394,13]]},"885":{"position":[[162,13]]},"903":{"position":[[76,13]]},"907":{"position":[[88,13]]},"909":{"position":[[50,13],[655,13]]}}}],["y\\text{y}i",{"_index":2171,"t":{"686":{"position":[[380,10],[473,10],[563,10],[639,10]]}}}],["y][prefix;x;i",{"_index":2453,"t":{"800":{"position":[[112,14]]}}}],["y][x;infix;i",{"_index":2456,"t":{"800":{"position":[[209,14]]}}}],["y]z=[prefix;x;i",{"_index":2388,"t":{"775":{"position":[[86,16]]}}}],["y]z=[prefix;x;prefix′;i",{"_index":2390,"t":{"775":{"position":[[205,24]]}}}],["y]z=[x;i",{"_index":2337,"t":{"766":{"position":[[163,9]]}}}],["y^(n)=(y^1,y^2,…,y^t(n)\\hat{\\text{y}}^{(n",{"_index":1360,"t":{"425":{"position":[[827,43]]}}}],["y^=arg",{"_index":3769,"t":{"1214":{"position":[[873,6]]}}}],["y^\\hat{y}i",{"_index":2717,"t":{"881":{"position":[[117,12]]},"887":{"position":[[52,12]]},"1214":{"position":[[846,12]]}}}],["y_1",{"_index":1348,"t":{"425":{"position":[[312,5]]}}}],["y_2",{"_index":1349,"t":{"425":{"position":[[318,4]]}}}],["y_i",{"_index":978,"t":{"286":{"position":[[189,3]]},"553":{"position":[[228,4]]},"627":{"position":[[890,4]]},"633":{"position":[[892,4],[929,3],[975,4],[1491,4]]}}}],["y_i)(xi​,yi",{"_index":270,"t":{"49":{"position":[[611,13]]}}}],["y_i\\}^n_{i=1}(x,y)={xi​,yi​}i=1n",{"_index":1974,"t":{"627":{"position":[[134,33]]}}}],["y_j)(xj​,yj",{"_index":272,"t":{"49":{"position":[[640,13]]}}}],["y_l)))]loss(θ)=−(2k​)1​e(x,yw​,yl​)∼d​[log",{"_index":3018,"t":{"1001":{"position":[[817,44]]}}}],["y_t",{"_index":1342,"t":{"425":{"position":[[171,4]]},"553":{"position":[[1294,4]]}}}],["y_t)y=(y1​,y2​,…,yt",{"_index":1351,"t":{"425":{"position":[[330,21]]}}}],["y_w",{"_index":3016,"t":{"1001":{"position":[[796,4]]}}}],["y_{<i},c,x)yi​=argmaxpθ​(yi​∣y<i​,c,x",{"_index":985,"t":{"286":{"position":[[288,38]]}}}],["y_{<t",{"_index":1773,"t":{"553":{"position":[[583,8],[1304,8]]}}}],["y_{<t})llm​=−t1​∑t​logp(yt​∣x,y<t",{"_index":1344,"t":{"425":{"position":[[188,35]]}}}],["y_{<t},z)l=−∑t=1t",{"_index":783,"t":{"180":{"position":[[197,19]]}}}],["y_{\\max",{"_index":605,"t":{"130":{"position":[[636,9]]}}}],["y_{\\textup{keypoint",{"_index":613,"t":{"130":{"position":[[1176,22],[1230,20]]}}}],["ye",{"_index":2906,"t":{"959":{"position":[[453,5]]}}}],["yelp",{"_index":2106,"t":{"642":{"position":[[306,4]]}}}],["yi=arg⁡max⁡pθ(yi∣y<i,c,x)y_i",{"_index":981,"t":{"286":{"position":[[230,28]]}}}],["yidx\\text{y}_{\\text{idx}}yidx",{"_index":2340,"t":{"766":{"position":[[259,30]]}}}],["yiy_iyi",{"_index":1763,"t":{"553":{"position":[[290,8]]}}}],["ykeypoint",{"_index":609,"t":{"130":{"position":[[1125,10]]}}}],["yly_lyl",{"_index":3023,"t":{"1001":{"position":[[1003,8]]}}}],["ymin⁡,xmin⁡,ymax⁡,xmax⁡,c][y_{\\min",{"_index":603,"t":{"130":{"position":[[588,37]]}}}],["yn",{"_index":928,"t":{"267":{"position":[[59,5]]}}}],["you'll",{"_index":126,"t":{"19":{"position":[[172,6]]}}}],["you'r",{"_index":122,"t":{"19":{"position":[[93,6]]}}}],["youtub",{"_index":3363,"t":{"1099":{"position":[[1262,7]]},"1113":{"position":[[19,7],[183,7]]},"1119":{"position":[[0,7]]},"1121":{"position":[[4,7]]},"1123":{"position":[[53,7],[70,7],[84,7]]}}}],["youtuv",{"_index":3369,"t":{"1099":{"position":[[1319,7]]}}}],["ywy_wyw",{"_index":3022,"t":{"1001":{"position":[[981,8],[992,8]]}}}],["yyi",{"_index":430,"t":{"91":{"position":[[940,3]]},"132":{"position":[[917,3],[955,3]]},"180":{"position":[[321,3]]},"764":{"position":[[29,3],[158,3],[220,3]]},"766":{"position":[[183,3],[292,3]]},"768":{"position":[[148,3]]},"773":{"position":[[411,3]]},"800":{"position":[[167,3],[348,3],[395,3]]},"819":{"position":[[209,3],[299,3],[531,3],[1339,3],[1906,3]]},"874":{"position":[[94,3],[308,3]]},"879":{"position":[[61,3],[113,3],[313,3],[460,3],[558,3]]},"883":{"position":[[204,3]]},"899":{"position":[[74,3],[186,3]]},"909":{"position":[[243,3]]},"911":{"position":[[636,3],[762,3]]},"1001":{"position":[[977,3]]}}}],["y|[p;x])prθ​(y∣[p;x",{"_index":2493,"t":{"819":{"position":[[572,22]]}}}],["y|x)pr(y∣x",{"_index":2487,"t":{"819":{"position":[[144,12]]}}}],["y|x)prθ​(y∣x",{"_index":2490,"t":{"819":{"position":[[275,14]]}}}],["y~i=λyj+(1−λ)yi\\tilde{y}_i",{"_index":276,"t":{"49":{"position":[[760,26]]}}}],["y⟩\\langl",{"_index":2530,"t":{"823":{"position":[[432,10],[516,10]]}}}],["z",{"_index":2533,"t":{"823":{"position":[[556,1]]},"883":{"position":[[240,3],[377,3],[435,3],[458,3],[519,4],[595,1],[797,3]]},"885":{"position":[[225,3],[574,3]]},"899":{"position":[[158,4]]},"911":{"position":[[805,3],[972,3]]},"917":{"position":[[541,3]]},"919":{"position":[[148,4],[190,4]]},"947":{"position":[[127,5]]},"949":{"position":[[809,3]]},"951":{"position":[[331,3]]},"955":{"position":[[142,5]]},"959":{"position":[[436,3]]}}}],["z'_\\varrho,\\qquad",{"_index":472,"t":{"91":{"position":[[2327,17]]}}}],["z)ffill​(x′,z",{"_index":2729,"t":{"885":{"position":[[271,14]]}}}],["z00=xclassz_{0}^{0",{"_index":426,"t":{"91":{"position":[[822,19]]}}}],["z=[prefix;x;prefix′;y]z",{"_index":2389,"t":{"775":{"position":[[144,23]]}}}],["z=[prefix;x;y]z",{"_index":2386,"t":{"775":{"position":[[49,15]]}}}],["z=[x;y]z",{"_index":2336,"t":{"766":{"position":[[148,8]]}}}],["z={(xi,yi)}i=1,…,n,\\mathcal{z",{"_index":1758,"t":{"553":{"position":[[186,30]]}}}],["z\\mathcal{z}z",{"_index":2725,"t":{"885":{"position":[[97,13]]},"889":{"position":[[303,13]]},"903":{"position":[[48,13]]},"907":{"position":[[17,13]]},"909":{"position":[[30,13],[122,13],[633,13]]},"947":{"position":[[613,13]]},"949":{"position":[[850,13]]}}}],["z^=searchz∈z",{"_index":2732,"t":{"885":{"position":[[468,12]]}}}],["z^\\hat{z}z",{"_index":2724,"t":{"885":{"position":[[39,11]]},"887":{"position":[[30,11]]}}}],["z_i",{"_index":2351,"t":{"766":{"position":[[736,5]]},"770":{"position":[[346,5]]}}}],["z_j/t)pj​=z1​exp(zj​/t",{"_index":2047,"t":{"633":{"position":[[1236,24]]}}}],["z_{<t})p(zt​∣x,z<t​):=k1​∑ik​p(zt​∣fprompt",{"_index":2840,"t":{"917":{"position":[[1480,43]]}}}],["z_{\\varrho",{"_index":463,"t":{"91":{"position":[[2035,10]]}}}],["zer",{"_index":3734,"t":{"1198":{"position":[[264,3]]}}}],["zero",{"_index":595,"t":{"126":{"position":[[759,5]]},"178":{"position":[[346,4]]},"188":{"position":[[165,4],[185,4]]},"195":{"position":[[25,4]]},"217":{"position":[[0,4]]},"279":{"position":[[44,4],[97,4],[305,4]]},"281":{"position":[[251,4],[319,4],[430,4],[1297,4],[1669,4],[1808,4],[2118,4],[2254,4]]},"290":{"position":[[287,4],[333,4]]},"292":{"position":[[6,4],[481,4],[556,4],[912,4]]},"296":{"position":[[202,4]]},"306":{"position":[[3,4]]},"311":{"position":[[475,4]]},"313":{"position":[[57,4],[150,4]]},"316":{"position":[[10,4],[182,4]]},"320":{"position":[[262,4],[280,4]]},"322":{"position":[[86,4],[129,4]]},"328":{"position":[[754,4]]},"330":{"position":[[1606,4]]},"362":{"position":[[1078,4],[1266,4]]},"368":{"position":[[455,4]]},"373":{"position":[[31,4]]},"388":{"position":[[226,4]]},"394":{"position":[[73,4],[251,4]]},"398":{"position":[[238,4],[262,4],[672,4],[822,4],[1108,4]]},"400":{"position":[[126,4]]},"423":{"position":[[302,4],[580,4]]},"435":{"position":[[66,4],[102,4],[382,4]]},"455":{"position":[[336,4],[370,4],[643,4]]},"457":{"position":[[523,4],[774,4],[1210,4]]},"463":{"position":[[174,4],[1552,4],[2426,4]]},"467":{"position":[[0,4]]},"469":{"position":[[121,4]]},"471":{"position":[[31,4],[78,4],[163,4]]},"477":{"position":[[154,4]]},"489":{"position":[[0,4],[62,4],[190,4]]},"496":{"position":[[76,4]]},"498":{"position":[[106,4]]},"504":{"position":[[205,4]]},"508":{"position":[[270,4]]},"515":{"position":[[16,4]]},"519":{"position":[[428,4],[519,4]]},"523":{"position":[[538,4]]},"543":{"position":[[171,4],[211,4],[409,4]]},"621":{"position":[[182,4]]},"698":{"position":[[1967,4]]},"838":{"position":[[286,4],[971,4]]},"844":{"position":[[187,4]]},"911":{"position":[[1068,4]]},"927":{"position":[[0,4],[132,4],[402,4]]},"933":{"position":[[317,4]]},"935":{"position":[[318,4]]},"1234":{"position":[[24,4]]}}}],["ziz_izi",{"_index":2048,"t":{"633":{"position":[[1261,8]]},"766":{"position":[[627,8]]}}}],["zl0z_{l}^{0}zl0",{"_index":429,"t":{"91":{"position":[[912,16],[1016,16]]}}}],["zo=[xclass",{"_index":442,"t":{"91":{"position":[[1509,11]]}}}],["zzz",{"_index":785,"t":{"180":{"position":[[276,3]]},"633":{"position":[[1299,3]]},"883":{"position":[[219,3]]},"885":{"position":[[61,3],[238,3],[459,3]]},"909":{"position":[[230,3]]},"911":{"position":[[662,3],[778,3]]}}}],["zϱ=mlp(ln(zϱ′))+zϱ′,ϱ=1",{"_index":469,"t":{"91":{"position":[[2246,23]]}}}],["zϱ′=msa(ln(zϱ−1))+zϱ−1",{"_index":460,"t":{"91":{"position":[[1946,23]]}}}],["zϱ−1z_{\\varrho",{"_index":467,"t":{"91":{"position":[[2211,14]]}}}],["z′)(z')(z",{"_index":2810,"t":{"911":{"position":[[251,12]]}}}],["z′,y><z",{"_index":2807,"t":{"911":{"position":[[213,10]]}}}],["z′\\mathcal{z}'z",{"_index":2806,"t":{"911":{"position":[[134,16],[540,16],[1039,16],[1088,16]]}}}],["z⟩\\langl",{"_index":2532,"t":{"823":{"position":[[545,10]]}}}]],"pipeline":["stemmer"]}}]